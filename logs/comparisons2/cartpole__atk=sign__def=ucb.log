config = {
    "evaluation": {
        "enabled": True, 
        "number_of_episodes_before_eval": 130, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": 125000, 
            "number_of_episodes": None, 
        }, 
    }, 
    "verbose": True, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "expected_number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": {
        0: 0.1, 
        1: 0.08, 
        2: 0.063, 
        3: 0.05, 
        4: 0.04, 
        5: 0.032, 
        6: 0.025, 
        7: 0.02, 
        8: 0.016, 
        9: 0.012, 
        10: 0.01, 
        11: 0.008, 
        12: 0.0063, 
        13: 0.005, 
        14: 0.004, 
        15: 0.0032, 
        16: 0.0025, 
        17: 0.002, 
        18: 0.0016, 
        19: 0.0012, 
        20: 0.001, 
        21: 0.0008, 
        22: 0.00063, 
        23: 0.0005, 
        24: 0.0004, 
        25: 0.00032, 
        26: 0.00025, 
        27: 0.0002, 
        28: 0.00016, 
        29: 0.00012, 
        30: 1e-05, 
        31: 8e-06, 
        32: 6.3e-06, 
        33: 5e-06, 
        34: 4e-06, 
        35: 3.2e-06, 
        36: 2.5e-06, 
        37: 2e-06, 
        38: 1.6e-06, 
        39: 1.2e-06, 
    }, 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": {0: 0, }, 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0, 
        "min_number_of_episodes": 30, 
        "thresholds": {}, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": {0: 0, 1: 1, 2: 2, }, }, 
            "sequential_options": {
                "t_max": {0: 3, 1: 5, 2: 10, 3: 20, 4: 30, 5: 50, }, 
                "hidden_size": {0: 16, 1: 32, 2: 64, 3: 128, }, 
                "learning_rate": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
                "beta": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
                "beta": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 21000, }, 
    "env_config": {
        "env_name": "CartPole-v1", 
        "learning_rate": 0.001, 
        "beta": 2e-05, 
        "t_max": 5, 
        "activation": 1, 
        "hidden_size": 64, 
        "permaban_threshold": 1000, 
        "variance_scaling_factor": 1, 
    }, 
}
args = {
    "processes": 10, 
    "env": "CartPole-v1", 
    "seed": 1032487892, 
    "outdir": "results", 
    "t_max": 5, 
    "beta": 2e-05, 
    "profile": False, 
    "steps": 21000, 
    "max_frames": (108000, ), 
    "lr": 0.001, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 1000, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 64, 
    "activation": 1, 
}
[starting train_a3c()]
[starting train_agent_async()]
[about to call async_.run_async()]
[starting run_func()]
[starting train_loop()]
Step 0 0 visits [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1 0 visits [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-3.485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2 1 visits [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-3.485, -3.235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 3 2 visits [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 4 q_vals: [-3.485, -3.235, -7.549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 4 3 visits [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 6 q_vals: [-3.485, -3.235, -7.549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 5 4 visits [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 7 q_vals: [-3.485, -3.235, -7.549, 0.0, -4.038, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 6 5 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 10 q_vals: [-3.485, -3.235, -7.549, 0.0, -4.038, -3.48, 0.0, 0.0, 0.0, 0.0]
Step 7 6 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 11 q_vals: [-3.485, -3.235, -7.549, 0.0, -4.038, -3.48, -7.272, 0.0, 0.0, 0.0]
Step 8 7 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 14 q_vals: [-3.485, -3.235, -7.549, 0.0, -4.038, -3.48, -7.272, -7.632, 0.0, 0.0]
Step 9 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 16 q_vals: [-3.485, -3.235, -7.549, 0.0, -4.038, -3.48, -7.272, -7.632, -7.593, 0.0]
Step 10 9 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 18 q_vals: [-3.485, -3.235, -7.549, 0.0, -4.038, -3.48, -7.272, -7.632, -7.593, -10.222]
Step 11 3 visits [1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 19 q_vals: [-3.485, -3.235, -7.549, -2.232, -4.038, -3.48, -7.272, -7.632, -7.593, -10.222]
Step 12 3 visits [1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 22 q_vals: [-3.485, -3.235, -7.549, -2.649, -4.038, -3.48, -7.272, -7.632, -7.593, -10.222]
Step 13 1 visits [1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 23 q_vals: [-3.485, -3.188, -7.549, -2.649, -4.038, -3.48, -7.272, -7.632, -7.593, -10.222]
Step 14 3 visits [1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 29 q_vals: [-3.485, -3.188, -7.549, -2.747, -4.038, -3.48, -7.272, -7.632, -7.593, -10.222]
Step 15 5 visits [1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 29 q_vals: [-3.485, -3.188, -7.549, -2.747, -4.038, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 16 0 visits [2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 30 q_vals: [-4.266, -3.188, -7.549, -2.747, -4.038, -4.456, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 34, "number_of_timesteps": 699, "per_episode_reward": 19.65, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Step 17 3 visits [2.0, 2.0, 1.0, 5.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 34 q_vals: [-4.266, -3.188, -7.549, -2.929, -4.038, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 18 1 visits [2.0, 3.0, 1.0, 5.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 37 q_vals: [-4.266, -3.518, -7.549, -2.929, -4.038, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 19 3 visits [2.0, 3.0, 1.0, 6.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 39 q_vals: [-4.266, -3.518, -7.549, -3.127, -4.038, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 20 4 visits [2.0, 3.0, 1.0, 6.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 41 q_vals: [-4.266, -3.518, -7.549, -3.127, -3.705, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 21 3 visits [2.0, 3.0, 1.0, 7.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 43 q_vals: [-4.266, -3.518, -7.549, -3.177, -3.705, -4.456, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 45, "number_of_timesteps": 905, "per_episode_reward": 19.3, "episode_reward_trend_value": -0.03499999999999979, "biggest_recent_change": NaN},
Step 22 4 visits [2.0, 3.0, 1.0, 7.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 45 q_vals: [-4.266, -3.518, -7.549, -3.177, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 23 1 visits [2.0, 4.0, 1.0, 7.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 48 q_vals: [-4.266, -3.596, -7.549, -3.177, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 24 3 visits [2.0, 4.0, 1.0, 8.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 50 q_vals: [-4.266, -3.596, -7.549, -3.263, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 25 3 visits [2.0, 4.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 51 q_vals: [-4.266, -3.596, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 26 1 visits [2.0, 5.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 54 q_vals: [-4.266, -3.527, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 57, "number_of_timesteps": 1160, "per_episode_reward": 18.2, "episode_reward_trend_value": -0.07249999999999997, "biggest_recent_change": NaN},
Step 27 1 visits [2.0, 6.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 57 q_vals: [-4.266, -3.675, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 28 1 visits [2.0, 7.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 58 q_vals: [-4.266, -3.596, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 29 1 visits [2.0, 8.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 59 q_vals: [-4.266, -3.574, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 30 1 visits [2.0, 9.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 61 q_vals: [-4.266, -3.585, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 31 0 visits [3.0, 9.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 62 q_vals: [-5.475, -3.585, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 32 1 visits [3.0, 10.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 63 q_vals: [-5.475, -3.226, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 67, "number_of_timesteps": 1393, "per_episode_reward": 19.05, "episode_reward_trend_value": -0.019999999999999928, "biggest_recent_change": NaN},
Step 33 1 visits [3.0, 11.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 67 q_vals: [-5.475, -3.203, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 34 1 visits [3.0, 12.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 69 q_vals: [-5.475, -3.241, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 35 1 visits [3.0, 13.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 72 q_vals: [-5.475, -3.151, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 36 1 visits [3.0, 14.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 74 q_vals: [-5.475, -3.494, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 37 1 visits [3.0, 15.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 74 q_vals: [-5.475, -3.323, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 77, "number_of_timesteps": 1620, "per_episode_reward": 18.8, "episode_reward_trend_value": -0.021249999999999946, "biggest_recent_change": NaN},
Step 38 1 visits [3.0, 16.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 77 q_vals: [-5.475, -3.348, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 39 1 visits [3.0, 17.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 80 q_vals: [-5.475, -3.339, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 40 1 visits [3.0, 18.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 80 q_vals: [-5.475, -3.32, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 41 1 visits [3.0, 19.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 82 q_vals: [-5.475, -3.396, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 87, "number_of_timesteps": 1832, "per_episode_reward": 19.45, "episode_reward_trend_value": -0.003999999999999985, "biggest_recent_change": NaN},
Step 42 1 visits [3.0, 20.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 87 q_vals: [-5.475, -3.226, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 43 1 visits [3.0, 21.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 89 q_vals: [-5.475, -3.22, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 44 1 visits [3.0, 22.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 90 q_vals: [-5.475, -3.253, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 45 1 visits [3.0, 23.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 93 q_vals: [-5.475, -3.193, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 46 1 visits [3.0, 24.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 96 q_vals: [-5.475, -3.06, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 97, "number_of_timesteps": 2058, "per_episode_reward": 18.7, "episode_reward_trend_value": -0.01583333333333332, "biggest_recent_change": NaN},
Step 47 1 visits [3.0, 25.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 97 q_vals: [-5.475, -3.084, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 48 1 visits [3.0, 26.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 99 q_vals: [-5.475, -3.099, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 49 1 visits [3.0, 27.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 100 q_vals: [-5.475, -3.189, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 50 1 visits [3.0, 28.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 100 q_vals: [-5.475, -3.198, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 51 1 visits [3.0, 29.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 105 q_vals: [-5.475, -3.196, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 52 1 visits [3.0, 30.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 106 q_vals: [-5.475, -3.19, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 108, "number_of_timesteps": 2322, "per_episode_reward": 19.75, "episode_reward_trend_value": 0.0014285714285714487, "biggest_recent_change": NaN},
Step 53 1 visits [3.0, 31.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 108 q_vals: [-5.475, -3.402, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 54 1 visits [3.0, 32.0, 1.0, 9.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 108 q_vals: [-5.475, -3.414, -7.549, -3.908, -5.141, -4.456, -7.272, -7.632, -7.593, -10.222]
Step 55 5 visits [3.0, 32.0, 1.0, 9.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 110 q_vals: [-5.475, -3.414, -7.549, -3.908, -5.141, -4.204, -7.272, -7.632, -7.593, -10.222]
Step 56 5 visits [3.0, 32.0, 1.0, 9.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 112 q_vals: [-5.475, -3.414, -7.549, -3.908, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 57 1 visits [3.0, 33.0, 1.0, 9.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 116 q_vals: [-5.475, -3.408, -7.549, -3.908, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 120, "number_of_timesteps": 2595, "per_episode_reward": 19.5, "episode_reward_trend_value": -0.0018749999999999821, "biggest_recent_change": NaN},
Step 58 1 visits [3.0, 34.0, 1.0, 9.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 120 q_vals: [-5.475, -3.399, -7.549, -3.908, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 59 1 visits [3.0, 35.0, 1.0, 9.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 120 q_vals: [-5.475, -3.302, -7.549, -3.908, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 60 1 visits [3.0, 36.0, 1.0, 9.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 120 q_vals: [-5.475, -3.427, -7.549, -3.908, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 61 1 visits [3.0, 37.0, 1.0, 9.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 123 q_vals: [-5.475, -3.424, -7.549, -3.908, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 62 1 visits [3.0, 38.0, 1.0, 9.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 127 q_vals: [-5.475, -3.439, -7.549, -3.908, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 63 1 visits [3.0, 39.0, 1.0, 9.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 127 q_vals: [-5.475, -3.455, -7.549, -3.908, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 131, "number_of_timesteps": 2850, "per_episode_reward": 19.1, "episode_reward_trend_value": -0.006111111111111079, "biggest_recent_change": 1.1000000000000014},
Step 64 1 visits [3.0, 40.0, 1.0, 9.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 131 q_vals: [-5.475, -3.444, -7.549, -3.908, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 65 1 visits [3.0, 41.0, 1.0, 9.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 133 q_vals: [-5.475, -3.431, -7.549, -3.908, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 66 1 visits [3.0, 42.0, 1.0, 9.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 135 q_vals: [-5.475, -3.55, -7.549, -3.908, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 67 3 visits [3.0, 42.0, 1.0, 10.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 137 q_vals: [-5.475, -3.55, -7.549, -3.955, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 142, "number_of_timesteps": 3067, "per_episode_reward": 18.95, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 1.1000000000000014},
Step 68 1 visits [3.0, 43.0, 1.0, 10.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 142 q_vals: [-5.475, -3.548, -7.549, -3.955, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 69 1 visits [3.0, 44.0, 1.0, 10.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 144 q_vals: [-5.475, -3.576, -7.549, -3.955, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 70 1 visits [3.0, 45.0, 1.0, 10.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 145 q_vals: [-5.475, -3.589, -7.549, -3.955, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 71 1 visits [3.0, 46.0, 1.0, 10.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 148 q_vals: [-5.475, -3.511, -7.549, -3.955, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 72 1 visits [3.0, 47.0, 1.0, 10.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 151 q_vals: [-5.475, -3.642, -7.549, -3.955, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 152, "number_of_timesteps": 3220, "per_episode_reward": 18.55, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 1.0500000000000007},
Step 73 3 visits [3.0, 47.0, 1.0, 11.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 152 q_vals: [-5.475, -3.642, -7.549, -3.887, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 74 3 visits [3.0, 47.0, 1.0, 12.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 154 q_vals: [-5.475, -3.642, -7.549, -3.847, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 75 3 visits [3.0, 47.0, 1.0, 13.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 157 q_vals: [-5.475, -3.642, -7.549, -3.878, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 76 3 visits [3.0, 47.0, 1.0, 14.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 159 q_vals: [-5.475, -3.642, -7.549, -3.702, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 162, "number_of_timesteps": 3407, "per_episode_reward": 18.75, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 1.0500000000000007},
Step 77 3 visits [3.0, 47.0, 1.0, 15.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 162 q_vals: [-5.475, -3.642, -7.549, -3.718, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 78 3 visits [3.0, 47.0, 1.0, 16.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 164 q_vals: [-5.475, -3.642, -7.549, -4.244, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 79 1 visits [3.0, 48.0, 1.0, 16.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 168 q_vals: [-5.475, -3.627, -7.549, -4.244, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 80 1 visits [3.0, 49.0, 1.0, 16.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 171 q_vals: [-5.475, -3.651, -7.549, -4.244, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 174, "number_of_timesteps": 3635, "per_episode_reward": 18.45, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 1.0500000000000007},
Step 81 1 visits [3.0, 50.0, 1.0, 16.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 174 q_vals: [-5.475, -3.641, -7.549, -4.244, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 82 1 visits [3.0, 51.0, 1.0, 16.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 175 q_vals: [-5.475, -3.644, -7.549, -4.244, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 83 1 visits [3.0, 52.0, 1.0, 16.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 175 q_vals: [-5.475, -3.748, -7.549, -4.244, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 84 1 visits [3.0, 53.0, 1.0, 16.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 179 q_vals: [-5.475, -3.735, -7.549, -4.244, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 85 1 visits [3.0, 54.0, 1.0, 16.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 182 q_vals: [-5.475, -3.666, -7.549, -4.244, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 184, "number_of_timesteps": 3828, "per_episode_reward": 18.35, "episode_reward_trend_value": -0.012222222222222199, "biggest_recent_change": 1.0500000000000007},
Step 86 1 visits [3.0, 55.0, 1.0, 16.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 184 q_vals: [-5.475, -3.662, -7.549, -4.244, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 87 1 visits [3.0, 56.0, 1.0, 16.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 188 q_vals: [-5.475, -3.661, -7.549, -4.244, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 88 1 visits [3.0, 57.0, 1.0, 16.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 188 q_vals: [-5.475, -3.808, -7.549, -4.244, -5.141, -4.514, -7.272, -7.632, -7.593, -10.222]
Step 89 5 visits [3.0, 57.0, 1.0, 16.0, 3.0, 5.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 190 q_vals: [-5.475, -3.808, -7.549, -4.244, -5.141, -4.432, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 194, "number_of_timesteps": 4005, "per_episode_reward": 18.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 1.0500000000000007},
Step 90 5 visits [3.0, 57.0, 1.0, 16.0, 3.0, 6.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 194 q_vals: [-5.475, -3.808, -7.549, -4.244, -5.141, -4.311, -7.272, -7.632, -7.593, -10.222]
Step 91 5 visits [3.0, 57.0, 1.0, 16.0, 3.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 196 q_vals: [-5.475, -3.808, -7.549, -4.244, -5.141, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 92 1 visits [3.0, 58.0, 1.0, 16.0, 3.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 199 q_vals: [-5.475, -3.802, -7.549, -4.244, -5.141, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 93 1 visits [3.0, 59.0, 1.0, 16.0, 3.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 201 q_vals: [-5.475, -3.804, -7.549, -4.244, -5.141, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 94 1 visits [3.0, 60.0, 1.0, 16.0, 3.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 203 q_vals: [-5.475, -3.925, -7.549, -4.244, -5.141, -4.913, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 204, "number_of_timesteps": 4203, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.3999999999999986},
Step 95 1 visits [3.0, 61.0, 1.0, 16.0, 3.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 204 q_vals: [-5.475, -3.917, -7.549, -4.244, -5.141, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 96 1 visits [3.0, 62.0, 1.0, 16.0, 3.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 207 q_vals: [-5.475, -4.022, -7.549, -4.244, -5.141, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 97 3 visits [3.0, 62.0, 1.0, 17.0, 3.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 208 q_vals: [-5.475, -4.022, -7.549, -4.186, -5.141, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 98 3 visits [3.0, 62.0, 1.0, 18.0, 3.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 212 q_vals: [-5.475, -4.022, -7.549, -4.451, -5.141, -4.913, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 214, "number_of_timesteps": 4401, "per_episode_reward": 18.4, "episode_reward_trend_value": -0.012222222222222238, "biggest_recent_change": 0.3999999999999986},
Step 99 1 visits [3.0, 63.0, 1.0, 18.0, 3.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 214 q_vals: [-5.475, -4.169, -7.549, -4.451, -5.141, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 100 1 visits [3.0, 64.0, 1.0, 18.0, 3.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 217 q_vals: [-5.475, -4.183, -7.549, -4.451, -5.141, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 101 4 visits [3.0, 64.0, 1.0, 18.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 221 q_vals: [-5.475, -4.183, -7.549, -4.451, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 102 1 visits [3.0, 65.0, 1.0, 18.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 223 q_vals: [-5.475, -4.119, -7.549, -4.451, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 225, "number_of_timesteps": 4593, "per_episode_reward": 18.1, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.3999999999999986},
Step 103 1 visits [3.0, 66.0, 1.0, 18.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 225 q_vals: [-5.475, -4.136, -7.549, -4.451, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 104 1 visits [3.0, 67.0, 1.0, 18.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 227 q_vals: [-5.475, -4.129, -7.549, -4.451, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 105 1 visits [3.0, 68.0, 1.0, 18.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 231 q_vals: [-5.475, -4.068, -7.549, -4.451, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 106 1 visits [3.0, 69.0, 1.0, 18.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 234 q_vals: [-5.475, -4.074, -7.549, -4.451, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 236, "number_of_timesteps": 4800, "per_episode_reward": 17.9, "episode_reward_trend_value": -0.011666666666666676, "biggest_recent_change": 0.3999999999999986},
Step 107 1 visits [3.0, 70.0, 1.0, 18.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 236 q_vals: [-5.475, -4.06, -7.549, -4.451, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 108 1 visits [3.0, 71.0, 1.0, 18.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 238 q_vals: [-5.475, -4.114, -7.549, -4.451, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 109 1 visits [3.0, 72.0, 1.0, 18.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 241 q_vals: [-5.475, -4.204, -7.549, -4.451, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 110 3 visits [3.0, 72.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 242 q_vals: [-5.475, -4.204, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 111 1 visits [3.0, 73.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 245 q_vals: [-5.475, -4.254, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 248, "number_of_timesteps": 5017, "per_episode_reward": 17.95, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.3000000000000007},
Step 112 1 visits [3.0, 74.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 248 q_vals: [-5.475, -4.197, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 113 1 visits [3.0, 75.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 250 q_vals: [-5.475, -4.194, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 114 1 visits [3.0, 76.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 253 q_vals: [-5.475, -4.277, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 115 1 visits [3.0, 77.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 253 q_vals: [-5.475, -4.263, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 116 1 visits [3.0, 78.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 256 q_vals: [-5.475, -4.238, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 258, "number_of_timesteps": 5224, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.3000000000000007},
Step 117 1 visits [3.0, 79.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 258 q_vals: [-5.475, -4.234, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 118 1 visits [3.0, 80.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 261 q_vals: [-5.475, -4.286, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 119 1 visits [3.0, 81.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 261 q_vals: [-5.475, -4.244, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 120 1 visits [3.0, 82.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 264 q_vals: [-5.475, -4.196, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 268, "number_of_timesteps": 5445, "per_episode_reward": 17.85, "episode_reward_trend_value": -0.006666666666666643, "biggest_recent_change": 0.29999999999999716},
Step 121 1 visits [3.0, 83.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 268 q_vals: [-5.475, -4.194, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 122 1 visits [3.0, 84.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 272 q_vals: [-5.475, -4.144, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 123 1 visits [3.0, 85.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 272 q_vals: [-5.475, -4.135, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 124 1 visits [3.0, 86.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 275 q_vals: [-5.475, -4.129, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 125 1 visits [3.0, 87.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 277 q_vals: [-5.475, -4.081, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 278, "number_of_timesteps": 5606, "per_episode_reward": 17.5, "episode_reward_trend_value": -0.00944444444444446, "biggest_recent_change": 0.3500000000000014},
Step 126 1 visits [3.0, 88.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 278 q_vals: [-5.475, -4.095, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 127 1 visits [3.0, 89.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 281 q_vals: [-5.475, -4.184, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 128 1 visits [3.0, 90.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 285 q_vals: [-5.475, -4.182, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 129 1 visits [3.0, 91.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 286 q_vals: [-5.475, -4.25, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 289, "number_of_timesteps": 5830, "per_episode_reward": 17.4, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3500000000000014},
Step 130 1 visits [3.0, 92.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 289 q_vals: [-5.475, -4.241, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 131 1 visits [3.0, 93.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 293 q_vals: [-5.475, -4.242, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 132 1 visits [3.0, 94.0, 1.0, 19.0, 4.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 294 q_vals: [-5.475, -4.288, -7.549, -4.681, -5.137, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 133 4 visits [3.0, 94.0, 1.0, 19.0, 5.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 296 q_vals: [-5.475, -4.288, -7.549, -4.681, -5.867, -4.913, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 299, "number_of_timesteps": 6006, "per_episode_reward": 17.55, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.3500000000000014},
Step 134 1 visits [3.0, 95.0, 1.0, 19.0, 5.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 299 q_vals: [-5.475, -4.286, -7.549, -4.681, -5.867, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 135 1 visits [3.0, 96.0, 1.0, 19.0, 5.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 303 q_vals: [-5.475, -4.278, -7.549, -4.681, -5.867, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 136 1 visits [3.0, 97.0, 1.0, 19.0, 5.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 303 q_vals: [-5.475, -4.389, -7.549, -4.681, -5.867, -4.913, -7.272, -7.632, -7.593, -10.222]
Step 137 5 visits [3.0, 97.0, 1.0, 19.0, 5.0, 8.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 306 q_vals: [-5.475, -4.389, -7.549, -4.681, -5.867, -4.772, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 310, "number_of_timesteps": 6207, "per_episode_reward": 17.55, "episode_reward_trend_value": -0.00944444444444442, "biggest_recent_change": 0.3500000000000014},
Step 138 5 visits [3.0, 97.0, 1.0, 19.0, 5.0, 9.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 310 q_vals: [-5.475, -4.389, -7.549, -4.681, -5.867, -4.668, -7.272, -7.632, -7.593, -10.222]
Step 139 5 visits [3.0, 97.0, 1.0, 19.0, 5.0, 10.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 311 q_vals: [-5.475, -4.389, -7.549, -4.681, -5.867, -4.725, -7.272, -7.632, -7.593, -10.222]
Step 140 5 visits [3.0, 97.0, 1.0, 19.0, 5.0, 11.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 313 q_vals: [-5.475, -4.389, -7.549, -4.681, -5.867, -4.667, -7.272, -7.632, -7.593, -10.222]
Step 141 5 visits [3.0, 97.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 315 q_vals: [-5.475, -4.389, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 142 1 visits [3.0, 98.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 318 q_vals: [-5.475, -4.376, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 321, "number_of_timesteps": 6419, "per_episode_reward": 17.7, "episode_reward_trend_value": -0.004444444444444468, "biggest_recent_change": 0.3500000000000014},
Step 143 1 visits [3.0, 99.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 321 q_vals: [-5.475, -4.365, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 144 1 visits [3.0, 100.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 324 q_vals: [-5.475, -4.356, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 145 1 visits [3.0, 101.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 325 q_vals: [-5.475, -4.352, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 146 1 visits [3.0, 102.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 329 q_vals: [-5.475, -4.348, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 332, "number_of_timesteps": 6602, "per_episode_reward": 17.55, "episode_reward_trend_value": -0.0038888888888888654, "biggest_recent_change": 0.3500000000000014},
Step 147 1 visits [3.0, 103.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 332 q_vals: [-5.475, -4.388, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 148 1 visits [3.0, 104.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 334 q_vals: [-5.475, -4.385, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 149 1 visits [3.0, 105.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 335 q_vals: [-5.475, -4.358, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 150 1 visits [3.0, 106.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 340 q_vals: [-5.475, -4.365, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 151 1 visits [3.0, 107.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 341 q_vals: [-5.475, -4.36, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 345, "number_of_timesteps": 6847, "per_episode_reward": 17.5, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.3500000000000014},
Step 152 1 visits [3.0, 108.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 345 q_vals: [-5.475, -4.364, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 153 1 visits [3.0, 109.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 346 q_vals: [-5.475, -4.367, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 154 1 visits [3.0, 110.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 349 q_vals: [-5.475, -4.327, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 155 1 visits [3.0, 111.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 353 q_vals: [-5.475, -4.33, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 355, "number_of_timesteps": 7027, "per_episode_reward": 17.35, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.3500000000000014},
Step 156 1 visits [3.0, 112.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 355 q_vals: [-5.475, -4.333, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 157 1 visits [3.0, 113.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 358 q_vals: [-5.475, -4.342, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 158 1 visits [3.0, 114.0, 1.0, 19.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 360 q_vals: [-5.475, -4.398, -7.549, -4.681, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 159 3 visits [3.0, 114.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 364 q_vals: [-5.475, -4.398, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 365, "number_of_timesteps": 7185, "per_episode_reward": 17.4, "episode_reward_trend_value": -0.005000000000000031, "biggest_recent_change": 0.3500000000000014},
Step 160 0 visits [4.0, 114.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 365 q_vals: [-5.101, -4.398, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 161 0 visits [5.0, 114.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 369 q_vals: [-5.05, -4.398, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 162 0 visits [6.0, 114.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 370 q_vals: [-4.983, -4.398, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 163 0 visits [7.0, 114.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 372 q_vals: [-5.12, -4.398, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 164 1 visits [7.0, 115.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 373 q_vals: [-5.12, -4.39, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 375, "number_of_timesteps": 7368, "per_episode_reward": 17.4, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000213},
Step 165 1 visits [7.0, 116.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 375 q_vals: [-5.12, -4.387, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 166 1 visits [7.0, 117.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 376 q_vals: [-5.12, -4.397, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 167 1 visits [7.0, 118.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 377 q_vals: [-5.12, -4.403, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 168 1 visits [7.0, 119.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 381 q_vals: [-5.12, -4.411, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 169 1 visits [7.0, 120.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 384 q_vals: [-5.12, -4.414, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 387, "number_of_timesteps": 7668, "per_episode_reward": 17.45, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.15000000000000213},
Step 170 1 visits [7.0, 121.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 387 q_vals: [-5.12, -4.377, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 171 1 visits [7.0, 122.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 389 q_vals: [-5.12, -4.372, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 172 1 visits [7.0, 123.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 392 q_vals: [-5.12, -4.371, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 173 1 visits [7.0, 124.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 395 q_vals: [-5.12, -4.417, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 174 1 visits [7.0, 125.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 396 q_vals: [-5.12, -4.452, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 399, "number_of_timesteps": 7854, "per_episode_reward": 17.45, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.14999999999999858},
Step 175 1 visits [7.0, 126.0, 1.0, 20.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 399 q_vals: [-5.12, -4.452, -7.549, -4.757, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 176 3 visits [7.0, 126.0, 1.0, 21.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 401 q_vals: [-5.12, -4.452, -7.549, -4.709, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 177 3 visits [7.0, 126.0, 1.0, 22.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 405 q_vals: [-5.12, -4.452, -7.549, -4.673, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 178 3 visits [7.0, 126.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 407 q_vals: [-5.12, -4.452, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 179 1 visits [7.0, 127.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 407 q_vals: [-5.12, -4.511, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 411, "number_of_timesteps": 8080, "per_episode_reward": 17.45, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.14999999999999858},
Step 180 0 visits [8.0, 127.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 411 q_vals: [-5.785, -4.511, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 181 1 visits [8.0, 128.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 412 q_vals: [-5.785, -4.476, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 182 1 visits [8.0, 129.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 414 q_vals: [-5.785, -4.483, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 183 1 visits [8.0, 130.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 417 q_vals: [-5.785, -4.48, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 421, "number_of_timesteps": 8307, "per_episode_reward": 17.45, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
Step 184 1 visits [8.0, 131.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 421 q_vals: [-5.785, -4.477, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 185 1 visits [8.0, 132.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 424 q_vals: [-5.785, -4.443, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 186 1 visits [8.0, 133.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 425 q_vals: [-5.785, -4.409, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 187 1 visits [8.0, 134.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 425 q_vals: [-5.785, -4.4, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 431, "number_of_timesteps": 8456, "per_episode_reward": 17.35, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
Step 188 1 visits [8.0, 135.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 431 q_vals: [-5.785, -4.445, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 189 1 visits [8.0, 136.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 431 q_vals: [-5.785, -4.44, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 190 1 visits [8.0, 137.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 433 q_vals: [-5.785, -4.456, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 191 1 visits [8.0, 138.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 438 q_vals: [-5.785, -4.514, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 192 1 visits [8.0, 139.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 438 q_vals: [-5.785, -4.513, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 193 1 visits [8.0, 140.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 440 q_vals: [-5.785, -4.559, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 444, "number_of_timesteps": 8724, "per_episode_reward": 17.1, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.25},
Step 194 1 visits [8.0, 141.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 444 q_vals: [-5.785, -4.566, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 195 1 visits [8.0, 142.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 446 q_vals: [-5.785, -4.568, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 196 1 visits [8.0, 143.0, 1.0, 23.0, 5.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 448 q_vals: [-5.785, -4.634, -7.549, -5.026, -5.867, -5.039, -7.272, -7.632, -7.593, -10.222]
Step 197 5 visits [8.0, 143.0, 1.0, 23.0, 5.0, 13.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 453 q_vals: [-5.785, -4.634, -7.549, -5.026, -5.867, -4.987, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 455, "number_of_timesteps": 8933, "per_episode_reward": 17.15, "episode_reward_trend_value": -0.002222222222222254, "biggest_recent_change": 0.25},
Step 198 5 visits [8.0, 143.0, 1.0, 23.0, 5.0, 14.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 455 q_vals: [-5.785, -4.634, -7.549, -5.026, -5.867, -5.123, -7.272, -7.632, -7.593, -10.222]
Step 199 1 visits [8.0, 144.0, 1.0, 23.0, 5.0, 14.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 459 q_vals: [-5.785, -4.639, -7.549, -5.026, -5.867, -5.123, -7.272, -7.632, -7.593, -10.222]
Step 200 1 visits [8.0, 145.0, 1.0, 23.0, 5.0, 14.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 462 q_vals: [-5.785, -4.641, -7.549, -5.026, -5.867, -5.123, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 466, "number_of_timesteps": 9073, "per_episode_reward": 16.85, "episode_reward_trend_value": -0.006111111111111079, "biggest_recent_change": 0.29999999999999716},
Step 201 1 visits [8.0, 146.0, 1.0, 23.0, 5.0, 14.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 466 q_vals: [-5.785, -4.646, -7.549, -5.026, -5.867, -5.123, -7.272, -7.632, -7.593, -10.222]
Step 202 1 visits [8.0, 147.0, 1.0, 23.0, 5.0, 14.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 468 q_vals: [-5.785, -4.691, -7.549, -5.026, -5.867, -5.123, -7.272, -7.632, -7.593, -10.222]
Step 203 1 visits [8.0, 148.0, 1.0, 23.0, 5.0, 14.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 469 q_vals: [-5.785, -4.7, -7.549, -5.026, -5.867, -5.123, -7.272, -7.632, -7.593, -10.222]
Step 204 5 visits [8.0, 148.0, 1.0, 23.0, 5.0, 15.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 471 q_vals: [-5.785, -4.7, -7.549, -5.026, -5.867, -5.106, -7.272, -7.632, -7.593, -10.222]
Step 205 1 visits [8.0, 149.0, 1.0, 23.0, 5.0, 15.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 474 q_vals: [-5.785, -4.753, -7.549, -5.026, -5.867, -5.106, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 478, "number_of_timesteps": 9281, "per_episode_reward": 16.95, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.29999999999999716},
Step 206 5 visits [8.0, 149.0, 1.0, 23.0, 5.0, 16.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 478 q_vals: [-5.785, -4.753, -7.549, -5.026, -5.867, -5.069, -7.272, -7.632, -7.593, -10.222]
Step 207 5 visits [8.0, 149.0, 1.0, 23.0, 5.0, 17.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 480 q_vals: [-5.785, -4.753, -7.549, -5.026, -5.867, -5.022, -7.272, -7.632, -7.593, -10.222]
Step 208 5 visits [8.0, 149.0, 1.0, 23.0, 5.0, 18.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 482 q_vals: [-5.785, -4.753, -7.549, -5.026, -5.867, -5.011, -7.272, -7.632, -7.593, -10.222]
Step 209 5 visits [8.0, 149.0, 1.0, 23.0, 5.0, 19.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 485 q_vals: [-5.785, -4.753, -7.549, -5.026, -5.867, -5.255, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 490, "number_of_timesteps": 9478, "per_episode_reward": 16.8, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.29999999999999716},
Step 210 3 visits [8.0, 149.0, 1.0, 24.0, 5.0, 19.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 490 q_vals: [-5.785, -4.753, -7.549, -5.107, -5.867, -5.255, -7.272, -7.632, -7.593, -10.222]
Step 211 1 visits [8.0, 150.0, 1.0, 24.0, 5.0, 19.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 490 q_vals: [-5.785, -4.768, -7.549, -5.107, -5.867, -5.255, -7.272, -7.632, -7.593, -10.222]
Step 212 1 visits [8.0, 151.0, 1.0, 24.0, 5.0, 19.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 493 q_vals: [-5.785, -4.768, -7.549, -5.107, -5.867, -5.255, -7.272, -7.632, -7.593, -10.222]
Step 213 1 visits [8.0, 152.0, 1.0, 24.0, 5.0, 19.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 494 q_vals: [-5.785, -4.817, -7.549, -5.107, -5.867, -5.255, -7.272, -7.632, -7.593, -10.222]
Step 214 1 visits [8.0, 153.0, 1.0, 24.0, 5.0, 19.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 498 q_vals: [-5.785, -4.882, -7.549, -5.107, -5.867, -5.255, -7.272, -7.632, -7.593, -10.222]
Step 215 3 visits [8.0, 153.0, 1.0, 25.0, 5.0, 19.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 499 q_vals: [-5.785, -4.882, -7.549, -5.191, -5.867, -5.255, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 502, "number_of_timesteps": 9734, "per_episode_reward": 16.85, "episode_reward_trend_value": -0.006666666666666643, "biggest_recent_change": 0.29999999999999716},
Step 216 1 visits [8.0, 154.0, 1.0, 25.0, 5.0, 19.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 502 q_vals: [-5.785, -4.88, -7.549, -5.191, -5.867, -5.255, -7.272, -7.632, -7.593, -10.222]
Step 217 1 visits [8.0, 155.0, 1.0, 25.0, 5.0, 19.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 504 q_vals: [-5.785, -4.939, -7.549, -5.191, -5.867, -5.255, -7.272, -7.632, -7.593, -10.222]
Step 218 5 visits [8.0, 155.0, 1.0, 25.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 505 q_vals: [-5.785, -4.939, -7.549, -5.191, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 219 3 visits [8.0, 155.0, 1.0, 26.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 507 q_vals: [-5.785, -4.939, -7.549, -5.041, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 220 3 visits [8.0, 155.0, 1.0, 27.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 510 q_vals: [-5.785, -4.939, -7.549, -5.021, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 512, "number_of_timesteps": 9934, "per_episode_reward": 16.8, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.29999999999999716},
Step 221 3 visits [8.0, 155.0, 1.0, 28.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 512 q_vals: [-5.785, -4.939, -7.549, -5.027, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 222 3 visits [8.0, 155.0, 1.0, 29.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 515 q_vals: [-5.785, -4.939, -7.549, -4.853, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 223 3 visits [8.0, 155.0, 1.0, 30.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 519 q_vals: [-5.785, -4.939, -7.549, -5.163, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 224 3 visits [8.0, 155.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 520 q_vals: [-5.785, -4.939, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 525, "number_of_timesteps": 10175, "per_episode_reward": 16.85, "episode_reward_trend_value": -0.006666666666666643, "biggest_recent_change": 0.29999999999999716},
Step 225 1 visits [8.0, 156.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 525 q_vals: [-5.785, -4.944, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 226 1 visits [8.0, 157.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 526 q_vals: [-5.785, -4.945, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 227 1 visits [8.0, 158.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 528 q_vals: [-5.785, -4.914, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 228 1 visits [8.0, 159.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 530 q_vals: [-5.785, -4.913, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 229 1 visits [8.0, 160.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 533 q_vals: [-5.785, -4.883, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 230 1 visits [8.0, 161.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 534 q_vals: [-5.785, -4.852, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 536, "number_of_timesteps": 10385, "per_episode_reward": 16.8, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.29999999999999716},
Step 231 1 visits [8.0, 162.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 536 q_vals: [-5.785, -4.852, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 232 1 visits [8.0, 163.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 538 q_vals: [-5.785, -4.855, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 233 1 visits [8.0, 164.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 541 q_vals: [-5.785, -4.826, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 234 1 visits [8.0, 165.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 544 q_vals: [-5.785, -4.824, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 547, "number_of_timesteps": 10611, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.29999999999999716},
Step 235 1 visits [8.0, 166.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 547 q_vals: [-5.785, -4.879, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 236 1 visits [8.0, 167.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 548 q_vals: [-5.785, -4.861, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 237 1 visits [8.0, 168.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 551 q_vals: [-5.785, -4.91, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 238 1 visits [8.0, 169.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 553 q_vals: [-5.785, -4.915, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 239 1 visits [8.0, 170.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 555 q_vals: [-5.785, -4.916, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 557, "number_of_timesteps": 10797, "per_episode_reward": 16.7, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.29999999999999716},
Step 240 1 visits [8.0, 171.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 557 q_vals: [-5.785, -4.887, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 241 1 visits [8.0, 172.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 557 q_vals: [-5.785, -4.867, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 242 1 visits [8.0, 173.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 561 q_vals: [-5.785, -4.838, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 243 1 visits [8.0, 174.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 563 q_vals: [-5.785, -4.84, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 244 1 visits [8.0, 175.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 565 q_vals: [-5.785, -4.842, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 245 1 visits [8.0, 176.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 566 q_vals: [-5.785, -4.815, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 569, "number_of_timesteps": 11073, "per_episode_reward": 16.8, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.14999999999999858},
Step 246 1 visits [8.0, 177.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 569 q_vals: [-5.785, -4.872, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 247 1 visits [8.0, 178.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 571 q_vals: [-5.785, -4.86, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 248 1 visits [8.0, 179.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 577 q_vals: [-5.785, -4.859, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 579, "number_of_timesteps": 11258, "per_episode_reward": 16.8, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
Step 249 1 visits [8.0, 180.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 579 q_vals: [-5.785, -4.857, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 250 1 visits [8.0, 181.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 582 q_vals: [-5.785, -4.83, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 251 1 visits [8.0, 182.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 584 q_vals: [-5.785, -4.83, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 252 1 visits [8.0, 183.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 586 q_vals: [-5.785, -4.831, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 589, "number_of_timesteps": 11416, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 253 1 visits [8.0, 184.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 589 q_vals: [-5.785, -4.831, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 254 1 visits [8.0, 185.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 589 q_vals: [-5.785, -4.835, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 255 1 visits [8.0, 186.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 593 q_vals: [-5.785, -4.836, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 256 1 visits [8.0, 187.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 594 q_vals: [-5.785, -4.81, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 599, "number_of_timesteps": 11622, "per_episode_reward": 16.8, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 257 1 visits [8.0, 188.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 599 q_vals: [-5.785, -4.807, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 258 1 visits [8.0, 189.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 601 q_vals: [-5.785, -4.809, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 259 1 visits [8.0, 190.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 603 q_vals: [-5.785, -4.843, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 260 1 visits [8.0, 191.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 608 q_vals: [-5.785, -4.842, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 611, "number_of_timesteps": 11803, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 261 1 visits [8.0, 192.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 611 q_vals: [-5.785, -4.839, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 262 1 visits [8.0, 193.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 611 q_vals: [-5.785, -4.837, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 263 1 visits [8.0, 194.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 615 q_vals: [-5.785, -4.878, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 264 1 visits [8.0, 195.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 616 q_vals: [-5.785, -4.88, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 265 1 visits [8.0, 196.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 618 q_vals: [-5.785, -4.885, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 622, "number_of_timesteps": 11963, "per_episode_reward": 16.7, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
Step 266 1 visits [8.0, 197.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 622 q_vals: [-5.785, -4.893, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 267 1 visits [8.0, 198.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 624 q_vals: [-5.785, -4.896, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 268 1 visits [8.0, 199.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 627 q_vals: [-5.785, -4.904, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 269 1 visits [8.0, 200.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 630 q_vals: [-5.785, -4.909, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 270 1 visits [8.0, 201.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 631 q_vals: [-5.785, -4.919, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 638, "number_of_timesteps": 12263, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
Step 271 1 visits [8.0, 202.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 638 q_vals: [-5.785, -4.975, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 272 1 visits [8.0, 203.0, 1.0, 31.0, 5.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 640 q_vals: [-5.785, -4.986, -7.549, -5.385, -5.867, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 273 4 visits [8.0, 203.0, 1.0, 31.0, 6.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 642 q_vals: [-5.785, -4.986, -7.549, -5.385, -5.957, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 274 1 visits [8.0, 204.0, 1.0, 31.0, 6.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 645 q_vals: [-5.785, -4.992, -7.549, -5.385, -5.957, -5.619, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 648, "number_of_timesteps": 12405, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
Step 275 1 visits [8.0, 205.0, 1.0, 31.0, 6.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 648 q_vals: [-5.785, -5.002, -7.549, -5.385, -5.957, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 276 1 visits [8.0, 206.0, 1.0, 31.0, 6.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 649 q_vals: [-5.785, -5.007, -7.549, -5.385, -5.957, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 277 1 visits [8.0, 207.0, 1.0, 31.0, 6.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 653 q_vals: [-5.785, -5.011, -7.549, -5.385, -5.957, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 278 1 visits [8.0, 208.0, 1.0, 31.0, 6.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 654 q_vals: [-5.785, -5.019, -7.549, -5.385, -5.957, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 279 1 visits [8.0, 209.0, 1.0, 31.0, 6.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 656 q_vals: [-5.785, -5.029, -7.549, -5.385, -5.957, -5.619, -7.272, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 658, "number_of_timesteps": 12577, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000213},
Step 280 1 visits [starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[8.0, 210.0, 1.0, 31.0, 6.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 658 q_vals: [-5.785, -5.096, -7.549, -5.385, -5.957, -5.619, -7.272, -7.632, -7.593, -10.222]
Step 281 6 visits [8.0, 210.0, 1.0, 31.0, 6.0, 20.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 661 q_vals: [-5.785, -5.096, -7.549, -5.385, -5.957, -5.619, -6.664, -7.632, -7.593, -10.222]
Step 282 1 visits [8.0, 211.0, 1.0, 31.0, 6.0, 20.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 664 q_vals: [-5.785, -5.1, -7.549, -5.385, -5.957, -5.619, -6.664, -7.632, -7.593, -10.222]
Step 283 1 visits [8.0, 212.0, 1.0, 31.0, 6.0, 20.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 664 q_vals: [-5.785, -5.169, -7.549, -5.385, -5.957, -5.619, -6.664, -7.632, -7.593, -10.222]
Step 284 0 visits [9.0, 212.0, 1.0, 31.0, 6.0, 20.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 667 q_vals: [-5.918, -5.169, -7.549, -5.385, -5.957, -5.619, -6.664, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 669, "number_of_timesteps": 12803, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000213},
Step 285 3 visits [9.0, 212.0, 1.0, 32.0, 6.0, 20.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 669 q_vals: [-5.918, -5.169, -7.549, -5.406, -5.957, -5.619, -6.664, -7.632, -7.593, -10.222]
Step 286 6 visits [9.0, 212.0, 1.0, 32.0, 6.0, 20.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 670 q_vals: [-5.918, -5.169, -7.549, -5.406, -5.957, -5.619, -9.436, -7.632, -7.593, -10.222]
Step 287 3 visits [9.0, 212.0, 1.0, 33.0, 6.0, 20.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 672 q_vals: [-5.918, -5.169, -7.549, -5.481, -5.957, -5.619, -9.436, -7.632, -7.593, -10.222]
Step 288 4 visits [9.0, 212.0, 1.0, 33.0, 7.0, 20.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 674 q_vals: [-5.918, -5.169, -7.549, -5.481, -7.928, -5.619, -9.436, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 679, "number_of_timesteps": 13022, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000213},
Step 289 1 visits [9.0, 213.0, 1.0, 33.0, 7.0, 20.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 679 q_vals: [-5.918, -5.177, -7.549, -5.481, -7.928, -5.619, -9.436, -7.632, -7.593, -10.222]
Step 290 1 visits [9.0, 214.0, 1.0, 33.0, 7.0, 20.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 683 q_vals: [-5.918, -5.186, -7.549, -5.481, -7.928, -5.619, -9.436, -7.632, -7.593, -10.222]
Step 291 1 visits [9.0, 215.0, 1.0, 33.0, 7.0, 20.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 684 q_vals: [-5.918, -5.254, -7.549, -5.481, -7.928, -5.619, -9.436, -7.632, -7.593, -10.222]
Step 292 3 visits [9.0, 215.0, 1.0, 34.0, 7.0, 20.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 688 q_vals: [-5.918, -5.254, -7.549, -5.815, -7.928, -5.619, -9.436, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 693, "number_of_timesteps": 13254, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000213},
Step 293 5 visits [9.0, 215.0, 1.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 693 q_vals: [-5.918, -5.254, -7.549, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
Step 294 1 visits [9.0, 216.0, 1.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 695 q_vals: [-5.918, -5.236, -7.549, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
Step 295 1 visits [9.0, 217.0, 1.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 696 q_vals: [-5.918, -5.212, -7.549, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
Step 296 1 visits [9.0, 218.0, 1.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 701 q_vals: [-5.918, -5.222, -7.549, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 704, "number_of_timesteps": 13385, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.15000000000000213},
Step 297 1 visits [9.0, 219.0, 1.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 704 q_vals: [-5.918, -5.289, -7.549, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
Step 298 0 visits [10.0, 219.0, 1.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 705 q_vals: [-6.044, -5.289, -7.549, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
Step 299 1 visits [10.0, 220.0, 1.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 711 q_vals: [-6.044, -5.354, -7.549, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 714, "number_of_timesteps": 13545, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000213},
Step 300 2 visits [10.0, 220.0, 2.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 714 q_vals: [-6.044, -5.354, -4.733, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
Step 301 2 visits [10.0, 220.0, 3.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 718 q_vals: [-6.044, -5.354, -5.574, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
Step 302 2 visits [10.0, 220.0, 4.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 722 q_vals: [-6.044, -5.354, -6.156, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 724, "number_of_timesteps": 13660, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000213},
Step 303 2 visits [10.0, 220.0, 5.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 724 q_vals: [-6.044, -5.354, -4.924, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
Step 304 2 visits [10.0, 220.0, 6.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 731 q_vals: [-6.044, -5.354, -5.421, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
Step 305 2 visits [10.0, 220.0, 7.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 731 q_vals: [-6.044, -5.354, -4.728, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
Step 306 2 visits [10.0, 220.0, 8.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 733 q_vals: [-6.044, -5.354, -4.499, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
{"total_number_of_episodes": 738, "number_of_timesteps": 13837, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.006111111111111079, "biggest_recent_change": 0.15000000000000213},
Step 307 2 visits [10.0, 220.0, 9.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 738 q_vals: [-6.044, -5.354, -4.667, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
Step 308 2 visits [10.0, 220.0, 10.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 739 q_vals: [-6.044, -5.354, -5.972, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
Step 309 1 visits [10.0, 221.0, 10.0, 34.0, 7.0, 21.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 742 q_vals: [starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[-6.044, -5.366, -5.972, -5.815, -7.928, -6.147, -9.436, -7.632, -7.593, -10.222]
Step 310 8 visits [10.0, 221.0, 10.0, 34.0, 7.0, 21.0, 3.0, 1.0, 2.0, 1.0]  episode_count: 745 q_vals: [-6.044, -5.366, -5.972, -5.815, -7.928, -6.147, -9.436, -7.632, -11.479, -10.222]
{"total_number_of_episodes": 748, "number_of_timesteps": 14000, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.15000000000000213},
Step 311 1 visits [10.0, 222.0, 10.0, 34.0, 7.0, 21.0, 3.0, 1.0, 2.0, 1.0]  episode_count: 748 q_vals: [-6.044, -5.349, -5.972, -5.815, -7.928, -6.147, -9.436, -7.632, -11.479, -10.222]
Step 312 1 visits [10.0, 223.0, 10.0, 34.0, 7.0, 21.0, 3.0, 1.0, 2.0, 1.0]  episode_count: 751 q_vals: [-6.044, -5.358, -5.972, -5.815, -7.928, -6.147, -9.436, -7.632, -11.479, -10.222]
Step 313 1 visits [10.0, 224.0, 10.0, 34.0, 7.0, 21.0, 3.0, 1.0, 2.0, 1.0]  episode_count: 753 q_vals: [-6.044, -5.369, -5.972, -5.815, -7.928, -6.147, -9.436, -7.632, -11.479, -10.222]
{"total_number_of_episodes": 758, "number_of_timesteps": 14157, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000213},
Step 314 1 visits [10.0, 225.0, 10.0, 34.0, 7.0, 21.0, 3.0, 1.0, 2.0, 1.0]  episode_count: 758 q_vals: [-6.044, -5.375, -5.972, -5.815, -7.928, -6.147, -9.436, -7.632, -11.479, -10.222]
Step 315 2 visits [10.0, 225.0, 11.0, 34.0, 7.0, 21.0, 3.0, 1.0, 2.0, 1.0]  episode_count: 760 q_vals: [-6.044, -5.375, -5.994, -5.815, -7.928, -6.147, -9.436, -7.632, -11.479, -10.222]
Step 316 1 visits [10.0, 226.0, 11.0, 34.0, 7.0, 21.0, 3.0, 1.0, 2.0, 1.0]  episode_count: 764 q_vals: [-6.044, -5.351, -5.994, -5.815, -7.928, -6.147, -9.436, -7.632, -11.479, -10.222]
{"total_number_of_episodes": 769, "number_of_timesteps": 14297, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.14999999999999858},
Step 317 1 visits [10.0, 227.0, 11.0, 34.0, 7.0, 21.0, 3.0, 1.0, 2.0, 1.0]  episode_count: 769 q_vals: [-6.044, -5.362, -5.994, -5.815, -7.928, -6.147, -9.436, -7.632, -11.479, -10.222]
Step 318 1 visits [10.0, 228.0, 11.0, 34.0, 7.0, 21.0, 3.0, 1.0, 2.0, 1.0]  episode_count: 771 q_vals: [-6.044, -5.409, -5.994, -5.815, -7.928, -6.147, -9.436, -7.632, -11.479, -10.222]
Step 319 7 visits [10.0, 228.0, 11.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 772 q_vals: [-6.044, -5.409, -5.994, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 320 1 visits [10.0, 229.0, 11.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 776 q_vals: [-6.044, -5.389, -5.994, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 780, "number_of_timesteps": 14448, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.14999999999999858},
Step 321 1 visits [10.0, 230.0, 11.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 780 q_vals: [-6.044, -5.394, -5.994, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 322 1 visits [10.0, 231.0, 11.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 782 q_vals: [-6.044, -5.398, -5.994, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 323 1 visits [10.0, 232.0, 11.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 784 q_vals: [-6.044, -5.451, -5.994, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 324 2 visits [10.0, 232.0, 12.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 788 q_vals: [-6.044, -5.451, -6.014, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 792, "number_of_timesteps": 14629, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.14999999999999858},
Step 325 0 visits [11.0, 232.0, 12.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 792 q_vals: [-7.086, -5.451, -6.014, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 326 1 visits [11.0, 233.0, 12.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 793 q_vals: [-7.086, -5.459, -6.014, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 327 1 visits [11.0, 234.0, 12.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 797 q_vals: [-7.086, -5.464, -6.014, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 328 1 visits [11.0, 235.0, 12.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 801 q_vals: [-7.086, -5.44, -6.014, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 802, "number_of_timesteps": 14781, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.004444444444444468, "biggest_recent_change": 0.14999999999999858},
Step 329 1 visits [11.0, 236.0, 12.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 802 q_vals: [-7.086, -5.431, -6.014, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 330 1 visits [11.0, 237.0, 12.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 804 q_vals: [-7.086, -5.419, -6.014, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 331 1 visits [11.0, 238.0, 12.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 808 q_vals: [-7.086, -5.472, -6.014, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 332 1 visits [11.0, 239.0, 12.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 810 q_vals: [-7.086, -5.523, -6.014, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 813, "number_of_timesteps": 14950, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.14999999999999858},
Step 333 2 visits [11.0, 239.0, 13.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 813 q_vals: [-7.086, -5.523, -6.159, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 334 1 visits [11.0, 240.0, 13.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 818 q_vals: [-7.086, -5.502, -6.159, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 335 1 visits [11.0, 241.0, 13.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 820 q_vals: [-7.086, -5.512, -6.159, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 823, "number_of_timesteps": 15078, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
Step 336 1 visits [11.0, 242.0, 13.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 823 q_vals: [-7.086, -5.518, -6.159, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 337 1 visits [11.0, 243.0, 13.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 826 q_vals: [-7.086, -5.499, -6.159, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 338 1 visits [11.0, 244.0, 13.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 831 q_vals: [-7.086, -5.481, -6.159, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 833, "number_of_timesteps": 15234, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
Step 339 1 visits [11.0, 245.0, 13.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 833 q_vals: [-7.086, -5.491, -6.159, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 340 1 visits [11.0, 246.0, 13.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 837 q_vals: [-7.086, -5.496, -6.159, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 341 1 visits [11.0, 247.0, 13.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 841 q_vals: [-7.086, -5.505, -6.159, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 843, "number_of_timesteps": 15361, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.005555555555555576, "biggest_recent_change": 0.15000000000000036},
Step 342 1 visits [11.0, 248.0, 13.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 843 q_vals: [-7.086, -5.551, -6.159, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 343 1 visits [11.0, 249.0, 13.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 848 q_vals: [-7.086, -5.533, -6.159, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 344 1 visits [11.0, 250.0, 13.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 852 q_vals: [-7.086, -5.543, -6.159, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 854, "number_of_timesteps": 15497, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.006666666666666643, "biggest_recent_change": 0.15000000000000036},
Step 345 1 visits [11.0, 251.0, 13.0, 34.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 854 q_vals: [-7.086, -5.593, -6.159, -5.815, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 346 3 visits [11.0, 251.0, 13.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 860 q_vals: [-7.086, -5.593, -6.159, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 347 1 visits [11.0, 252.0, 13.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 861 q_vals: [-7.086, -5.576, -6.159, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 868, "number_of_timesteps": 15658, "per_episode_reward": 15.45, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.15000000000000036},
Step 348 1 visits [11.0, 253.0, 13.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 868 q_vals: [-7.086, -5.585, -6.159, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 349 1 visits [11.0, 254.0, 13.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 870 q_vals: [-7.086, -5.591, -6.159, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 350 1 visits [11.0, 255.0, 13.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 873 q_vals: [-7.086, -5.595, -6.159, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 879, "number_of_timesteps": 15779, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.15000000000000036},
Step 351 1 visits [11.0, 256.0, 13.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 879 q_vals: [-7.086, -5.604, -6.159, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 352 1 visits [11.0, 257.0, 13.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 880 q_vals: [-7.086, -5.61, -6.159, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 353 1 visits [11.0, 258.0, 13.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 883 q_vals: [-7.086, -5.615, -6.159, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 354 1 visits [11.0, 259.0, 13.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 888 q_vals: [-7.086, -5.623, -6.159, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 889, "number_of_timesteps": 15903, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
Step 355 1 visits [11.0, 260.0, 13.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 889 q_vals: [-7.086, -5.61, -6.159, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 356 1 visits [11.0, 261.0, 13.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 894 q_vals: [-7.086, -5.614, -6.159, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 357 1 visits [11.0, 262.0, 13.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 897 q_vals: [-7.086, -5.62, -6.159, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 358 1 visits [11.0, 263.0, 13.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 898 q_vals: [-7.086, -5.665, -6.159, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 901, "number_of_timesteps": 16069, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.15000000000000036},
Step 359 2 visits [11.0, 263.0, 14.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 901 q_vals: [-7.086, -5.665, -6.196, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 360 1 visits [11.0, 264.0, 14.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 906 q_vals: [-7.086, -5.671, -6.196, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 361 1 visits [11.0, 265.0, 14.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 908 q_vals: [-7.086, -5.677, -6.196, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 362 1 visits [11.0, 266.0, 14.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 909 q_vals: [-7.086, -5.685, -6.196, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 914, "number_of_timesteps": 16254, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.15000000000000036},
Step 363 1 visits [11.0, 267.0, 14.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 914 q_vals: [-7.086, -5.691, -6.196, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 364 1 visits [11.0, 268.0, 14.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 917 q_vals: [-7.086, -5.699, -6.196, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 365 2 visits [11.0, 268.0, 15.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 919 q_vals: [-7.086, -5.699, -6.234, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 366 1 visits [11.0, 269.0, 15.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 923 q_vals: [-7.086, -5.706, -6.234, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 924, "number_of_timesteps": 16442, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
Step 367 1 visits [11.0, 270.0, 15.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 924 q_vals: [-7.086, -5.715, -6.234, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 368 1 visits [11.0, 271.0, 15.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 928 q_vals: [-7.086, -5.726, -6.234, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 369 1 visits [11.0, 272.0, 15.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 933 q_vals: [-7.086, -5.777, -6.234, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 934, "number_of_timesteps": 16590, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.10000000000000142},
Step 370 2 visits [11.0, 272.0, 16.0, 35.0, 7.0, 21.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 934 q_vals: [-7.086, -5.777, -6.339, -6.205, -7.928, -6.147, -9.436, -11.294, -11.479, -10.222]
Step 371 5 visits [11.0, 272.0, 16.0, 35.0, 7.0, 22.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 936 q_vals: [-7.086, -5.777, -6.339, -6.205, -7.928, -6.2, -9.436, -11.294, -11.479, -10.222]
Step 372 1 visits [11.0, 273.0, 16.0, 35.0, 7.0, 22.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 941 q_vals: [-7.086, -5.825, -6.339, -6.205, -7.928, -6.2, -9.436, -11.294, -11.479, -10.222]
Step 373 1 visits [11.0, 274.0, 16.0, 35.0, 7.0, 22.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 943 q_vals: [-7.086, -5.832, -6.339, -6.205, -7.928, -6.2, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 947, "number_of_timesteps": 16775, "per_episode_reward": 15.15, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
Step 374 5 visits [11.0, 274.0, 16.0, 35.0, 7.0, 23.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 947 q_vals: [-7.086, -5.832, -6.339, -6.205, -7.928, -5.93, -9.436, -11.294, -11.479, -10.222]
Step 375 5 visits [11.0, 274.0, 16.0, 35.0, 7.0, 24.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 950 q_vals: [-7.086, -5.832, -6.339, -6.205, -7.928, -5.683, -9.436, -11.294, -11.479, -10.222]
Step 376 5 visits [11.0, 274.0, 16.0, 35.0, 7.0, 25.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 952 q_vals: [-7.086, -5.832, -6.339, -6.205, -7.928, -6.246, -9.436, -11.294, -11.479, -10.222]
Step 377 1 visits [11.0, 275.0, 16.0, 35.0, 7.0, 25.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 955 q_vals: [-7.086, -5.883, -6.339, -6.205, -7.928, -6.246, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 958, "number_of_timesteps": 16922, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.10000000000000142},
Step 378 2 visits [11.0, 275.0, 17.0, 35.0, 7.0, 25.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 958 q_vals: [-7.086, -5.883, -6.43, -6.205, -7.928, -6.246, -9.436, -11.294, -11.479, -10.222]
Step 379 1 visits [11.0, 276.0, 17.0, 35.0, 7.0, 25.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 963 q_vals: [-7.086, -5.89, -6.43, -6.205, -7.928, -6.246, -9.436, -11.294, -11.479, -10.222]
Step 380 1 visits [11.0, 277.0, 17.0, 35.0, 7.0, 25.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 965 q_vals: [-7.086, -5.897, -6.43, -6.205, -7.928, -6.246, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 970, "number_of_timesteps": 17085, "per_episode_reward": 15.05, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
Step 381 1 visits [11.0, 278.0, 17.0, 35.0, 7.0, 25.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 970 q_vals: [-7.086, -5.905, -6.43, -6.205, -7.928, -6.246, -9.436, -11.294, -11.479, -10.222]
Step 382 1 visits [11.0, 279.0, 17.0, 35.0, 7.0, 25.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 970 q_vals: [-7.086, -5.954, -6.43, -6.205, -7.928, -6.246, -9.436, -11.294, -11.479, -10.222]
Step 383 5 visits [11.0, 279.0, 17.0, 35.0, 7.0, 26.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 976 q_vals: [-7.086, -5.954, -6.43, -6.205, -7.928, -6.3, -9.436, -11.294, -11.479, -10.222]
Step 384 3 visits [11.0, 279.0, 17.0, 36.0, 7.0, 26.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 979 q_vals: [-7.086, -5.954, -6.43, -6.547, -7.928, -6.3, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 982, "number_of_timesteps": 17235, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.10000000000000142},
Step 385 1 visits [11.0, 280.0, 17.0, 36.0, 7.0, 26.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 982 q_vals: [-7.086, -5.961, -6.43, -6.547, -7.928, -6.3, -9.436, -11.294, -11.479, -10.222]
Step 386 1 visits [11.0, 281.0, 17.0, 36.0, 7.0, 26.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 985 q_vals: [-7.086, -5.94, -6.43, -6.547, -7.928, -6.3, -9.436, -11.294, -11.479, -10.222]
Step 387 1 visits [11.0, 282.0, 17.0, 36.0, 7.0, 26.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 989 q_vals: [-7.086, -5.946, -6.43, -6.547, -7.928, -6.3, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 993, "number_of_timesteps": 17394, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
Step 388 1 visits [11.0, 283.0, 17.0, 36.0, 7.0, 26.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 993 q_vals: [-7.086, -5.953, -6.43, -6.547, -7.928, -6.3, -9.436, -11.294, -11.479, -10.222]
Step 389 1 visits [11.0, 284.0, 17.0, 36.0, 7.0, 26.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 996 q_vals: [-7.086, -6.002, -6.43, -6.547, -7.928, -6.3, -9.436, -11.294, -11.479, -10.222]
Step 390 5 visits [11.0, 284.0, 17.0, 36.0, 7.0, 27.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 999 q_vals: [-7.086, -6.002, -6.43, -6.547, -7.928, -6.359, -9.436, -11.294, -11.479, -10.222]
Step 391 2 visits [11.0, 284.0, 18.0, 36.0, 7.0, 27.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1001 q_vals: [-7.086, -6.002, -6.571, -6.547, -7.928, -6.359, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1005, "number_of_timesteps": 17545, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
Step 392 1 visits [11.0, 285.0, 18.0, 36.0, 7.0, 27.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1005 q_vals: [-7.086, -6.05, -6.571, -6.547, -7.928, -6.359, -9.436, -11.294, -11.479, -10.222]
Step 393 5 visits [11.0, 285.0, 18.0, 36.0, 7.0, 28.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1010 q_vals: [-7.086, -6.05, -6.571, -6.547, -7.928, -6.397, -9.436, -11.294, -11.479, -10.222]
Step 394 1 visits [11.0, 286.0, 18.0, 36.0, 7.0, 28.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1011 q_vals: [-7.086, -6.056, -6.571, -6.547, -7.928, -6.397, -9.436, -11.294, -11.479, -10.222]
Step 395 1 visits [11.0, 287.0, 18.0, 36.0, 7.0, 28.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1011 q_vals: [-7.086, -6.063, -6.571, -6.547, -7.928, -6.397, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1016, "number_of_timesteps": 17699, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
Step 396 1 visits [11.0, 288.0, 18.0, 36.0, 7.0, 28.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1016 q_vals: [-7.086, -6.069, -6.571, -6.547, -7.928, -6.397, -9.436, -11.294, -11.479, -10.222]
Step 397 1 visits [11.0, 289.0, 18.0, 36.0, 7.0, 28.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1019 q_vals: [-7.086, -6.048, -6.571, -6.547, -7.928, -6.397, -9.436, -11.294, -11.479, -10.222]
Step 398 1 visits [11.0, 290.0, 18.0, 36.0, 7.0, 28.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1022 q_vals: [-7.086, -6.041, -6.571, -6.547, -7.928, -6.397, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1026, "number_of_timesteps": 17865, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.10000000000000142},
Step 399 1 visits [11.0, 291.0, 18.0, 36.0, 7.0, 28.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1026 q_vals: [-7.086, -6.048, -6.571, -6.547, -7.928, -6.397, -9.436, -11.294, -11.479, -10.222]
Step 400 1 visits [11.0, 292.0, 18.0, 36.0, 7.0, 28.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1030 q_vals: [-7.086, -6.054, -6.571, -6.547, -7.928, -6.397, -9.436, -11.294, -11.479, -10.222]
Step 401 1 visits [11.0, 293.0, 18.0, 36.0, 7.0, 28.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1031 q_vals: [-7.086, -6.06, -6.571, -6.547, -7.928, -6.397, -9.436, -11.294, -11.479, -10.222]
Step 402 1 visits [11.0, 294.0, 18.0, 36.0, 7.0, 28.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1035 q_vals: [-7.086, -6.052, -6.571, -6.547, -7.928, -6.397, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1040, "number_of_timesteps": 18045, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
Step 403 1 visits [11.0, 295.0, 18.0, 36.0, 7.0, 28.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1040 q_vals: [-7.086, -6.099, -6.571, -6.547, -7.928, -6.397, -9.436, -11.294, -11.479, -10.222]
Step 404 5 visits [11.0, 295.0, 18.0, 36.0, 7.0, 29.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1042 q_vals: [-7.086, -6.099, -6.571, -6.547, -7.928, -6.244, -9.436, -11.294, -11.479, -10.222]
Step 405 5 visits [11.0, 295.0, 18.0, 36.0, 7.0, 30.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1047 q_vals: [-7.086, -6.099, -6.571, -6.547, -7.928, -6.3, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1050, "number_of_timesteps": 18168, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.10000000000000142},
Step 406 5 visits [11.0, 295.0, 18.0, 36.0, 7.0, 31.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1050 q_vals: [-7.086, -6.099, -6.571, -6.547, -7.928, -6.192, -9.436, -11.294, -11.479, -10.222]
Step 407 5 visits [11.0, 295.0, 18.0, 36.0, 7.0, 32.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1054 q_vals: [-7.086, -6.099, -6.571, -6.547, -7.928, -6.245, -9.436, -11.294, -11.479, -10.222]
Step 408 5 visits [11.0, 295.0, 18.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1056 q_vals: [-7.086, -6.099, -6.571, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1061, "number_of_timesteps": 18303, "per_episode_reward": 14.65, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
Step 409 1 visits [11.0, 296.0, 18.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1061 q_vals: [-7.086, -6.105, -6.571, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 410 1 visits [11.0, 297.0, 18.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1065 q_vals: [-7.086, -6.151, -6.571, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 411 2 visits [11.0, 297.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1066 q_vals: [-7.086, -6.151, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1071, "number_of_timesteps": 18428, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.15000000000000036},
Step 412 1 visits [11.0, 298.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1071 q_vals: [-7.086, -6.157, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 413 1 visits [11.0, 299.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1075 q_vals: [-7.086, -6.151, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 414 1 visits [11.0, 300.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1079 q_vals: [-7.086, -6.157, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1082, "number_of_timesteps": 18553, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.15000000000000036},
Step 415 1 visits [11.0, 301.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1082 q_vals: [-7.086, -6.163, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 416 1 visits [11.0, 302.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1084 q_vals: [-7.086, -6.142, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 417 1 visits [11.0, 303.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1086 q_vals: [-7.086, -6.148, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 418 1 visits [11.0, 304.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1087 q_vals: [-7.086, -6.153, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 419 1 visits [11.0, 305.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1091 q_vals: [-7.086, -6.158, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1092, "number_of_timesteps": 18715, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
Step 420 1 visits [11.0, 306.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1092 q_vals: [-7.086, -6.163, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 421 1 visits [11.0, 307.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1094 q_vals: [-7.086, -6.169, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 422 1 visits [11.0, 308.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1099 q_vals: [-7.086, -6.174, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1102, "number_of_timesteps": 18923, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
Step 423 1 visits [11.0, 309.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1102 q_vals: [-7.086, -6.218, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 424 1 visits [11.0, 310.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1104 q_vals: [-7.086, -6.21, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 425 1 visits [11.0, 311.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1107 q_vals: [-7.086, -6.215, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 426 1 visits [11.0, 312.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1110 q_vals: [-7.086, -6.259, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1112, "number_of_timesteps": 19069, "per_episode_reward": 14.45, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
Step 427 1 visits [11.0, 313.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1112 q_vals: [-7.086, -6.239, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 428 1 visits [11.0, 314.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1115 q_vals: [-7.086, -6.244, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 429 1 visits [11.0, 315.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1118 q_vals: [-7.086, -6.249, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 430 1 visits [11.0, 316.0, 19.0, 36.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1119 q_vals: [-7.086, -6.292, -7.253, -6.547, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1123, "number_of_timesteps": 19253, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
Step 431 3 visits [11.0, 316.0, 19.0, 37.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1123 q_vals: [-7.086, -6.292, -7.253, -6.516, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 432 3 visits [11.0, 316.0, 19.0, 38.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1126 q_vals: [-7.086, -6.292, -7.253, -6.857, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 433 1 visits [11.0, 317.0, 19.0, 38.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1126 q_vals: [-7.086, -6.287, -7.253, -6.857, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 434 1 visits [11.0, 318.0, 19.0, 38.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1131 q_vals: [-7.086, -6.329, -7.253, -6.857, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1134, "number_of_timesteps": 19439, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
Step 435 1 visits [11.0, 319.0, 19.0, 38.0, 7.0, 33.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1134 q_vals: [-7.086, -6.371, -7.253, -6.857, -7.928, -6.655, -9.436, -11.294, -11.479, -10.222]
Step 436 5 visits [11.0, 319.0, 19.0, 38.0, 7.0, 34.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1136 q_vals: [-7.086, -6.371, -7.253, -6.857, -7.928, -6.691, -9.436, -11.294, -11.479, -10.222]
Step 437 1 visits [11.0, 320.0, 19.0, 38.0, 7.0, 34.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1138 q_vals: [-7.086, -6.376, -7.253, -6.857, -7.928, -6.691, -9.436, -11.294, -11.479, -10.222]
Step 438 1 visits [11.0, 321.0, 19.0, 38.0, 7.0, 34.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1139 q_vals: [-7.086, -6.381, -7.253, -6.857, -7.928, -6.691, -9.436, -11.294, -11.479, -10.222]
Step 439 1 visits [11.0, 322.0, 19.0, 38.0, 7.0, 34.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1142 q_vals: [-7.086, -6.361, -7.253, -6.857, -7.928, -6.691, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1144, "number_of_timesteps": 19619, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
Step 440 1 visits [11.0, 323.0, 19.0, 38.0, 7.0, 34.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1144 q_vals: [-7.086, -6.355, -7.253, -6.857, -7.928, -6.691, -9.436, -11.294, -11.479, -10.222]
Step 441 1 visits [11.0, 324.0, 19.0, 38.0, 7.0, 34.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1148 q_vals: [-7.086, -6.397, -7.253, -6.857, -7.928, -6.691, -9.436, -11.294, -11.479, -10.222]
Step 442 1 visits [11.0, 325.0, 19.0, 38.0, 7.0, 34.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1152 q_vals: [-7.086, -6.401, -7.253, -6.857, -7.928, -6.691, -9.436, -11.294, -11.479, -10.222]
Step 443 1 visits [11.0, 326.0, 19.0, 38.0, 7.0, 34.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1153 q_vals: [-7.086, -6.406, -7.253, -6.857, -7.928, -6.691, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1158, "number_of_timesteps": 19878, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
Step 444 5 visits [11.0, 326.0, 19.0, 38.0, 7.0, 35.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1158 q_vals: [-7.086, -6.406, -7.253, -6.857, -7.928, -6.726, -9.436, -11.294, -11.479, -10.222]
Step 445 1 visits [11.0, 327.0, 19.0, 38.0, 7.0, 35.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1161 q_vals: [-7.086, -6.41, -7.253, -6.857, -7.928, -6.726, -9.436, -11.294, -11.479, -10.222]
Step 446 1 visits [11.0, 328.0, 19.0, 38.0, 7.0, 35.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1161 q_vals: [-7.086, -6.415, -7.253, -6.857, -7.928, -6.726, -9.436, -11.294, -11.479, -10.222]
Step 447 1 visits [11.0, 329.0, 19.0, 38.0, 7.0, 35.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1167 q_vals: [-7.086, -6.419, -7.253, -6.857, -7.928, -6.726, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1168, "number_of_timesteps": 20006, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 448 1 visits [11.0, 330.0, 19.0, 38.0, 7.0, 35.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1168 q_vals: [-7.086, -6.424, -7.253, -6.857, -7.928, -6.726, -9.436, -11.294, -11.479, -10.222]
Step 449 1 visits [11.0, 331.0, 19.0, 38.0, 7.0, 35.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1171 q_vals: [-7.086, -6.464, -7.253, -6.857, -7.928, -6.726, -9.436, -11.294, -11.479, -10.222]
Step 450 5 visits [11.0, 331.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1172 q_vals: [-7.086, -6.464, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 451 1 visits [11.0, 332.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1176 q_vals: [-7.086, -6.469, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1178, "number_of_timesteps": 20202, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 452 1 visits [11.0, 333.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1178 q_vals: [-7.086, -6.473, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 453 1 visits [11.0, 334.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1180 q_vals: [-7.086, -6.513, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 454 0 visits [12.0, 334.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1183 q_vals: [-7.154, -6.513, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 455 1 visits [12.0, 335.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1184 q_vals: [-7.154, -6.517, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 456 1 visits [12.0, 336.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1186 q_vals: [-7.154, -6.521, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1189, "number_of_timesteps": 20392, "per_episode_reward": 14.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 457 1 visits [12.0, 337.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1189 q_vals: [-7.154, -6.525, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 458 1 visits [12.0, 338.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1192 q_vals: [-7.154, -6.506, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 459 1 visits [12.0, 339.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1194 q_vals: [-7.154, -6.51, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 460 1 visits [12.0, 340.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1197 q_vals: [-7.154, -6.514, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1199, "number_of_timesteps": 20606, "per_episode_reward": 14.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 461 1 visits [12.0, 341.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1199 q_vals: [-7.154, -6.518, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 462 1 visits [12.0, 342.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1201 q_vals: [-7.154, -6.522, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 463 1 visits [12.0, 343.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1203 q_vals: [-7.154, -6.525, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 464 1 visits [12.0, 344.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1206 q_vals: [-7.154, -6.528, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 465 1 visits [12.0, 345.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1206 q_vals: [-7.154, -6.532, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 466 1 visits [12.0, 346.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1207 q_vals: [-7.154, -6.536, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1212, "number_of_timesteps": 20851, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 467 1 visits [12.0, 347.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1212 q_vals: [-7.154, -6.574, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 468 0 visits [13.0, 347.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1213 q_vals: [-8.12, -6.574, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 469 1 visits [13.0, 348.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1214 q_vals: [-8.12, -6.578, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 470 1 visits [13.0, 349.0, 19.0, 38.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1217 q_vals: [-8.12, -6.615, -7.253, -6.857, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1222, "number_of_timesteps": 21089, "per_episode_reward": 14.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 471 3 visits [13.0, 349.0, 19.0, 39.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1222 q_vals: [-8.12, -6.615, -7.253, -6.884, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 472 1 visits [13.0, 350.0, 19.0, 39.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1222 q_vals: [-8.12, -6.619, -7.253, -6.884, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 473 1 visits [13.0, 351.0, 19.0, 39.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1222 q_vals: [-8.12, -6.6, -7.253, -6.884, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 474 1 visits [13.0, 352.0, 19.0, 39.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1223 q_vals: [-8.12, -6.59, -7.253, -6.884, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 475 1 visits [13.0, 353.0, 19.0, 39.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1227 q_vals: [-8.12, -6.628, -7.253, -6.884, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 476 3 visits [13.0, 353.0, 19.0, 40.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1228 q_vals: [-8.12, -6.628, -7.253, -6.712, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 477 3 visits [13.0, 353.0, 19.0, 41.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1230 q_vals: [-8.12, -6.628, -7.253, -6.741, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1233, "number_of_timesteps": 21348, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
Step 478 3 visits [13.0, 353.0, 19.0, 42.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1233 q_vals: [-8.12, -6.628, -7.253, -6.769, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 479 3 visits [13.0, 353.0, 19.0, 43.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1234 q_vals: [-8.12, -6.628, -7.253, -6.795, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 480 3 visits [13.0, 353.0, 19.0, 44.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1234 q_vals: [-8.12, -6.628, -7.253, -6.811, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 481 3 visits [13.0, 353.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1238 q_vals: [-8.12, -6.628, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 482 1 visits [13.0, 354.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1240 q_vals: [-8.12, -6.631, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 483 1 visits [13.0, 355.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1240 q_vals: [-8.12, -6.612, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 484 1 visits [13.0, 356.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1242 q_vals: [-8.12, -6.649, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1247, "number_of_timesteps": 21682, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
Step 485 1 visits [13.0, 357.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1247 q_vals: [-8.12, -6.652, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 486 1 visits [13.0, 358.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1247 q_vals: [-8.12, -6.656, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 487 1 visits [13.0, 359.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1251 q_vals: [-8.12, -6.692, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 488 1 visits [13.0, 360.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1253 q_vals: [-8.12, -6.695, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 489 1 visits [13.0, 361.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1254 q_vals: [-8.12, -6.699, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 490 1 visits [13.0, 362.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1256 q_vals: [-8.12, -6.702, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1257, "number_of_timesteps": 21913, "per_episode_reward": 14.75, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.10000000000000142},
Step 491 1 visits [13.0, 363.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1257 q_vals: [-8.12, -6.684, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 492 1 visits [13.0, 364.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1261 q_vals: [-8.12, -6.687, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 493 1 visits [13.0, 365.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1263 q_vals: [-8.12, -6.69, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 494 1 visits [13.0, 366.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1264 q_vals: [-8.12, -6.698, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1267, "number_of_timesteps": 22149, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
Step 495 1 visits [13.0, 367.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1267 q_vals: [-8.12, -6.702, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 496 1 visits [13.0, 368.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1267 q_vals: [-8.12, -6.737, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 497 1 visits [13.0, 369.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1267 q_vals: [-8.12, -6.74, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 498 1 visits [13.0, 370.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1270 q_vals: [-8.12, -6.744, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 499 1 visits [13.0, 371.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1273 q_vals: [-8.12, -6.747, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 500 1 visits [13.0, 372.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1274 q_vals: [-8.12, -6.782, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1277, "number_of_timesteps": 22370, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.10000000000000142},
Step 501 1 visits [13.0, 373.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1277 q_vals: [-8.12, -6.785, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 502 1 visits [13.0, 374.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1280 q_vals: [-8.12, -6.788, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 503 1 visits [13.0, 375.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1281 q_vals: [-8.12, -6.769, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 504 1 visits [13.0, 376.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1286 q_vals: [-8.12, -6.772, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
Step 505 1 visits [13.0, 377.0, 19.0, 45.0, 7.0, 36.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1286 q_vals: [-8.12, -6.807, -7.253, -7.099, -7.928, -7.088, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1288, "number_of_timesteps": 22647, "per_episode_reward": 14.75, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
Step 506 5 visits [13.0, 377.0, 19.0, 45.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1288 q_vals: [-8.12, -6.807, -7.253, -7.099, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 507 1 visits [13.0, 378.0, 19.0, 45.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1289 q_vals: [-8.12, -6.81, -7.253, -7.099, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 508 2 visits [13.0, 378.0, 20.0, 45.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1292 q_vals: [-8.12, -6.81, -7.285, -7.099, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 509 1 visits [13.0, 379.0, 20.0, 45.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1294 q_vals: [-8.12, -6.813, -7.285, -7.099, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 510 1 visits [13.0, 380.0, 20.0, 45.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1294 q_vals: [-8.12, -6.816, -7.285, -7.099, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 511 1 visits [13.0, 381.0, 20.0, 45.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1295 q_vals: [-8.12, -6.798, -7.285, -7.099, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 512 1 visits [13.0, 382.0, 20.0, 45.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1296 q_vals: [-8.12, -6.801, -7.285, -7.099, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1301, "number_of_timesteps": 22993, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 513 1 visits [13.0, 383.0, 20.0, 45.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1301 q_vals: [-8.12, -6.803, -7.285, -7.099, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 514 1 visits [13.0, 384.0, 20.0, 45.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1303 q_vals: [-8.12, -6.806, -7.285, -7.099, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 515 1 visits [13.0, 385.0, 20.0, 45.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1305 q_vals: [-8.12, -6.809, -7.285, -7.099, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 516 1 visits [13.0, 386.0, 20.0, 45.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1307 q_vals: [-8.12, -6.843, -7.285, -7.099, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 517 1 visits [13.0, 387.0, 20.0, 45.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1309 q_vals: [-8.12, -6.876, -7.285, -7.099, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1312, "number_of_timesteps": 23219, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
Step 518 3 visits [13.0, 387.0, 20.0, 46.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1312 q_vals: [-8.12, -6.876, -7.285, -7.116, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 519 2 visits [13.0, 387.0, 21.0, 46.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1315 q_vals: [-8.12, -6.876, -7.315, -7.116, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 520 3 visits [13.0, 387.0, 21.0, 47.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1315 q_vals: [-8.12, -6.876, -7.315, -7.133, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 521 1 visits [13.0, 388.0, 21.0, 47.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1319 q_vals: [-8.12, -6.879, -7.315, -7.133, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 522 1 visits [13.0, 389.0, 21.0, 47.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1321 q_vals: [-8.12, -6.912, -7.315, -7.133, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1326, "number_of_timesteps": 23504, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
Step 523 3 visits [13.0, 389.0, 21.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1326 q_vals: [-8.12, -6.912, -7.315, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 524 2 visits [13.0, 389.0, 22.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1328 q_vals: [-8.12, -6.912, -7.341, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 525 1 visits [13.0, 390.0, 22.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1330 q_vals: [-8.12, -6.914, -7.341, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 526 1 visits [13.0, 391.0, 22.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1333 q_vals: [-8.12, -6.917, -7.341, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1336, "number_of_timesteps": 23658, "per_episode_reward": 14.95, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
Step 527 1 visits [13.0, 392.0, 22.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1336 q_vals: [-8.12, -6.899, -7.341, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 528 1 visits [13.0, 393.0, 22.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1338 q_vals: [-8.12, -6.902, -7.341, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 529 1 visits [13.0, 394.0, 22.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1340 q_vals: [-8.12, -6.904, -7.341, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 530 1 visits [13.0, 395.0, 22.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1340 q_vals: [-8.12, -6.907, -7.341, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 531 1 visits [13.0, 396.0, 22.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1343 q_vals: [-8.12, -6.909, -7.341, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1346, "number_of_timesteps": 23825, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 532 1 visits [13.0, 397.0, 22.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1346 q_vals: [-8.12, -6.912, -7.341, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 533 1 visits [13.0, 398.0, 22.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1347 q_vals: [-8.12, -6.914, -7.341, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 534 1 visits [13.0, 399.0, 22.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1347 q_vals: [-8.12, -6.946, -7.341, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 535 2 visits [13.0, 399.0, 23.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1351 q_vals: [-8.12, -6.946, -7.366, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 536 1 visits [13.0, 400.0, 23.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1352 q_vals: [-8.12, -6.949, -7.366, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 537 1 visits [13.0, 401.0, 23.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1354 q_vals: [-8.12, -6.951, -7.366, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1357, "number_of_timesteps": 24146, "per_episode_reward": 14.95, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 538 1 visits [13.0, 402.0, 23.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1357 q_vals: [-8.12, -6.983, -7.366, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 539 2 visits [13.0, 402.0, 24.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1358 q_vals: [-8.12, -6.983, -7.388, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 540 1 visits [13.0, 403.0, 24.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1362 q_vals: [-8.12, -6.985, -7.388, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 541 1 visits [13.0, 404.0, 24.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1363 q_vals: [-8.12, -6.988, -7.388, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 542 1 visits [13.0, 405.0, 24.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1365 q_vals: [-8.12, -6.99, -7.388, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1369, "number_of_timesteps": 24376, "per_episode_reward": 14.95, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
Step 543 1 visits [13.0, 406.0, 24.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1369 q_vals: [-8.12, -6.992, -7.388, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 544 1 visits [13.0, 407.0, 24.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1370 q_vals: [-8.12, -6.994, -7.388, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 545 1 visits [13.0, 408.0, 24.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1373 q_vals: [-8.12, -6.977, -7.388, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 546 1 visits [13.0, 409.0, 24.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1377 q_vals: [-8.12, -6.979, -7.388, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 547 1 visits [13.0, 410.0, 24.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1378 q_vals: [-8.12, -6.982, -7.388, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1381, "number_of_timesteps": 24588, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
Step 548 1 visits [13.0, 411.0, 24.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1381 q_vals: [-8.12, -6.984, -7.388, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 549 1 visits [13.0, 412.0, 24.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1383 q_vals: [-8.12, -7.015, -7.388, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 550 2 visits [13.0, 412.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1385 q_vals: [-8.12, -7.015, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 551 1 visits [13.0, 413.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1388 q_vals: [-8.12, -6.998, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 552 1 visits [13.0, 414.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1389 q_vals: [-8.12, -7.0, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1394, "number_of_timesteps": 24802, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
Step 553 1 visits [13.0, 415.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1394 q_vals: [-8.12, -7.002, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 554 1 visits [13.0, 416.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1397 q_vals: [-8.12, -7.004, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 555 1 visits [13.0, 417.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1399 q_vals: [-8.12, -7.007, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1404, "number_of_timesteps": 24979, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 556 1 visits [13.0, 418.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1404 q_vals: [-8.12, -7.009, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 557 1 visits [13.0, 419.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1406 q_vals: [-8.12, -7.01, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 558 1 visits [13.0, 420.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1409 q_vals: [-8.12, -7.012, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 559 1 visits [13.0, 421.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1412 q_vals: [-8.12, -7.01, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1414, "number_of_timesteps": 25114, "per_episode_reward": 14.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
Step 560 1 visits [13.0, 422.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1414 q_vals: [-8.12, -7.012, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 561 1 visits [13.0, 423.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1415 q_vals: [-8.12, -7.042, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 562 1 visits [13.0, 424.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1421 q_vals: [-8.12, -7.072, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 563 1 visits [13.0, 425.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1421 q_vals: [-8.12, -7.074, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1424, "number_of_timesteps": 25281, "per_episode_reward": 14.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 564 1 visits [13.0, 426.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1424 q_vals: [-8.12, -7.076, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 565 1 visits [13.0, 427.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1429 q_vals: [-8.12, -7.06, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 566 1 visits [13.0, 428.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1430 q_vals: [-8.12, -7.062, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1434, "number_of_timesteps": 25449, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 567 1 visits [13.0, 429.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1434 q_vals: [-8.12, -7.064, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 568 1 visits [13.0, 430.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1437 q_vals: [-8.12, -7.066, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 569 1 visits [13.0, 431.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1439 q_vals: [-8.12, -7.095, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1445, "number_of_timesteps": 25601, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 570 1 visits [13.0, 432.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1445 q_vals: [-8.12, -7.097, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 571 1 visits [13.0, 433.0, 25.0, 48.0, 7.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1447 q_vals: [-8.12, -7.126, -7.883, -7.396, -7.928, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 572 4 visits [13.0, 433.0, 25.0, 48.0, 8.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1447 q_vals: [-8.12, -7.126, -7.883, -7.396, -7.859, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 573 4 visits [13.0, 433.0, 25.0, 48.0, 9.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1453 q_vals: [-8.12, -7.126, -7.883, -7.396, -7.864, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1455, "number_of_timesteps": 25744, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
 episode_count: 1455 q_vals: [-8.12, -7.128, -7.883, -7.396, -7.864, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 575 1 visits [13.0, 435.0, 25.0, 48.0, 9.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1457 q_vals: [-8.12, -7.13, -7.883, -7.396, -7.864, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 576 1 visits [13.0, 436.0, 25.0, 48.0, 9.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1460 q_vals: [-8.12, -7.131, -7.883, -7.396, -7.864, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 577 1 visits [13.0, 437.0, 25.0, 48.0, 9.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1463 q_vals: [-8.12, -7.133, -7.883, -7.396, -7.864, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1467, "number_of_timesteps": 25937, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
Step 578 1 visits [13.0, 438.0, 25.0, 48.0, 9.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1467 q_vals: [-8.12, -7.117, -7.883, -7.396, -7.864, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 579 1 visits [13.0, 439.0, 25.0, 48.0, 9.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1468 q_vals: [-8.12, -7.116, -7.883, -7.396, -7.864, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 580 1 visits [13.0, 440.0, 25.0, 48.0, 9.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1473 q_vals: [-8.12, -7.118, -7.883, -7.396, -7.864, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 581 1 visits [13.0, 441.0, 25.0, 48.0, 9.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1474 q_vals: [-8.12, -7.12, -7.883, -7.396, -7.864, -7.43, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1478, "number_of_timesteps": 26108, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 582 1 visits [13.0, 442.0, 25.0, 48.0, 9.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1478 q_vals: [-8.12, -7.122, -7.883, -7.396, -7.864, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 583 1 visits [13.0, 443.0, 25.0, 48.0, 9.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1482 q_vals: [-8.12, -7.123, -7.883, -7.396, -7.864, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 584 1 visits [13.0, 444.0, 25.0, 48.0, 9.0, 37.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1482 q_vals: [-8.12, -7.152, -7.883, -7.396, -7.864, -7.43, -9.436, -11.294, -11.479, -10.222]
Step 585 5 visits [13.0, 444.0, 25.0, 48.0, 9.0, 38.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1483 q_vals: [-8.12, -7.152, -7.883, -7.396, -7.864, -7.394, -9.436, -11.294, -11.479, -10.222]
Step 586 5 visits [13.0, 444.0, 25.0, 48.0, 9.0, 39.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1487 q_vals: [-8.12, -7.152, -7.883, -7.396, -7.864, -7.407, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1491, "number_of_timesteps": 26338, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 587 5 visits [13.0, 444.0, 25.0, 48.0, 9.0, 40.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1491 q_vals: [-8.12, -7.152, -7.883, -7.396, -7.864, -7.419, -9.436, -11.294, -11.479, -10.222]
Step 588 5 visits [13.0, 444.0, 25.0, 48.0, 9.0, 41.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1492 q_vals: [-8.12, -7.152, -7.883, -7.396, -7.864, -7.335, -9.436, -11.294, -11.479, -10.222]
Step 589 5 visits [13.0, 444.0, 25.0, 48.0, 9.0, 42.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1499 q_vals: [-8.12, -7.152, -7.883, -7.396, -7.864, -7.348, -9.436, -11.294, -11.479, -10.222]
Step 590 5 visits [13.0, 444.0, 25.0, 48.0, 9.0, 43.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1500 q_vals: [-8.12, -7.152, -7.883, -7.396, -7.864, -7.361, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1502, "number_of_timesteps": 26499, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 591 5 visits [13.0, 444.0, 25.0, 48.0, 9.0, 44.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1502 q_vals: [-8.12, -7.152, -7.883, -7.396, -7.864, -7.373, -9.436, -11.294, -11.479, -10.222]
Step 592 5 visits [13.0, 444.0, 25.0, 48.0, 9.0, 45.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1508 q_vals: [-8.12, -7.152, -7.883, -7.396, -7.864, -7.385, -9.436, -11.294, -11.479, -10.222]
Step 593 5 visits [13.0, 444.0, 25.0, 48.0, 9.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1510 q_vals: [-8.12, -7.152, -7.883, -7.396, -7.864, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1513, "number_of_timesteps": 26632, "per_episode_reward": 14.75, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 594 4 visits [13.0, 444.0, 25.0, 48.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1513 q_vals: [-8.12, -7.152, -7.883, -7.396, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 595 3 visits [13.0, 444.0, 25.0, 49.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1518 q_vals: [-8.12, -7.152, -7.883, -7.406, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 596 1 visits [13.0, 445.0, 25.0, 49.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1520 q_vals: [-8.12, -7.153, -7.883, -7.406, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1523, "number_of_timesteps": 26763, "per_episode_reward": 14.65, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
Step 597 1 visits [13.0, 446.0, 25.0, 49.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1523 q_vals: [-8.12, -7.154, -7.883, -7.406, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 598 1 visits [13.0, 447.0, 25.0, 49.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1526 q_vals: [-8.12, -7.156, -7.883, -7.406, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 599 1 visits [13.0, 448.0, 25.0, 49.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1529 q_vals: [-8.12, -7.156, -7.883, -7.406, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 600 1 visits [13.0, 449.0, 25.0, 49.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1531 q_vals: [-8.12, -7.157, -7.883, -7.406, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1533, "number_of_timesteps": 26913, "per_episode_reward": 14.65, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
Step 601 1 visits [13.0, 450.0, 25.0, 49.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1533 q_vals: [-8.12, -7.159, -7.883, -7.406, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 602 1 visits [13.0, 451.0, 25.0, 49.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1536 q_vals: [-8.12, -7.16, -7.883, -7.406, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 603 1 visits [13.0, 452.0, 25.0, 49.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1541 q_vals: [-8.12, -7.162, -7.883, -7.406, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1543, "number_of_timesteps": 27078, "per_episode_reward": 14.65, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 604 1 visits [13.0, 453.0, 25.0, 49.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1543 q_vals: [-8.12, -7.164, -7.883, -7.406, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 605 3 visits [13.0, 453.0, 25.0, 50.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1545 q_vals: [-8.12, -7.164, -7.883, -7.416, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 606 1 visits [13.0, 454.0, 25.0, 50.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1548 q_vals: [-8.12, -7.165, -7.883, -7.416, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 607 1 visits [13.0, 455.0, 25.0, 50.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1551 q_vals: [-8.12, -7.15, -7.883, -7.416, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1554, "number_of_timesteps": 27250, "per_episode_reward": 14.75, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 608 1 visits [13.0, 456.0, 25.0, 50.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1554 q_vals: [-8.12, -7.151, -7.883, -7.416, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 609 1 visits [13.0, 457.0, 25.0, 50.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1557 q_vals: [-8.12, -7.153, -7.883, -7.416, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 610 1 visits [13.0, 458.0, 25.0, 50.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1561 q_vals: [-8.12, -7.18, -7.883, -7.416, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1564, "number_of_timesteps": 27380, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.09999999999999964},
Step 611 3 visits [13.0, 458.0, 25.0, 51.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1564 q_vals: [-8.12, -7.18, -7.883, -7.425, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 612 1 visits [13.0, 459.0, 25.0, 51.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1568 q_vals: [-8.12, -7.165, -7.883, -7.425, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 613 1 visits [13.0, 460.0, 25.0, 51.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1573 q_vals: [-8.12, -7.192, -7.883, -7.425, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1574, "number_of_timesteps": 27499, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 614 3 visits [13.0, 460.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1574 q_vals: [-8.12, -7.192, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 615 1 visits [13.0, 461.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1576 q_vals: [-8.12, -7.219, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 616 1 visits [13.0, 462.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1583 q_vals: [-8.12, -7.221, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1584, "number_of_timesteps": 27634, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 617 1 visits [13.0, 463.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1584 q_vals: [-8.12, -7.205, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 618 1 visits [13.0, 464.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1586 q_vals: [-8.12, -7.232, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 619 1 visits [13.0, 465.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1591 q_vals: [-8.12, -7.259, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 620 1 visits [13.0, 466.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1592 q_vals: [-8.12, -7.261, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1598, "number_of_timesteps": 27831, "per_episode_reward": 14.65, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 621 1 visits [13.0, 467.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1598 q_vals: [-8.12, -7.262, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 622 1 visits [13.0, 468.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1600 q_vals: [-8.12, -7.289, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 623 1 visits [13.0, 469.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1605 q_vals: [-8.12, -7.273, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1608, "number_of_timesteps": 27948, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 624 1 visits [13.0, 470.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1608 q_vals: [-8.12, -7.274, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 625 1 visits [13.0, 471.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1610 q_vals: [-8.12, -7.259, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 626 1 visits [13.0, 472.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1615 q_vals: [-8.12, -7.26, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 627 1 visits [13.0, 473.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1617 q_vals: [-8.12, -7.262, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1619, "number_of_timesteps": 28095, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 628 1 visits [13.0, 474.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1619 q_vals: [-8.12, -7.263, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 629 1 visits [13.0, 475.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1623 q_vals: [-8.12, -7.264, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 630 1 visits [13.0, 476.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1626 q_vals: [-8.12, -7.266, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1629, "number_of_timesteps": 28233, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
[-8.12, -7.251, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 632 1 visits [13.0, 478.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1633 q_vals: [-8.12, -7.277, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 633 1 visits [13.0, 479.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1635 q_vals: [-8.12, -7.303, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1640, "number_of_timesteps": 28403, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 634 1 visits [13.0, 480.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1640 q_vals: [-8.12, -7.329, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 635 1 visits [13.0, 481.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1643 q_vals: [-8.12, -7.33, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 636 1 visits [13.0, 482.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1646 q_vals: [-8.12, -7.331, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1651, "number_of_timesteps": 28534, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 637 1 visits [13.0, 483.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1651 q_vals: [-8.12, -7.332, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 638 1 visits [13.0, 484.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1654 q_vals: [-8.12, -7.317, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 639 1 visits [13.0, 485.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1660 q_vals: [-8.12, -7.318, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 640 1 visits [13.0, 486.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1660 q_vals: [-8.12, -7.32, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1664, "number_of_timesteps": 28677, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 641 1 visits [13.0, 487.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1664 q_vals: [-8.12, -7.321, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 642 1 visits [13.0, 488.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1669 q_vals: [-8.12, -7.322, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 643 1 visits [13.0, 489.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1671 q_vals: [-8.12, -7.323, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1676, "number_of_timesteps": 28837, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 644 1 visits [13.0, 490.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1676 q_vals: [-8.12, -7.324, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 645 1 visits [13.0, 491.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1679 q_vals: [-8.12, -7.325, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 646 1 visits [13.0, 492.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1682 q_vals: [-8.12, -7.327, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1686, "number_of_timesteps": 28957, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 647 1 visits [13.0, 493.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1686 q_vals: [-8.12, -7.327, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 648 1 visits [13.0, 494.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1690 q_vals: [-8.12, -7.328, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 649 1 visits [13.0, 495.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1693 q_vals: [-8.12, -7.329, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 650 1 visits [13.0, 496.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1695 q_vals: [-8.12, -7.314, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1699, "number_of_timesteps": 29115, "per_episode_reward": 14.45, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 651 1 visits [13.0, 497.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1699 q_vals: [-8.12, -7.315, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 652 1 visits [13.0, 498.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1704 q_vals: [-8.12, -7.316, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 653 1 visits [13.0, 499.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1707 q_vals: [-8.12, -7.318, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1710, "number_of_timesteps": 29248, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 654 1 visits [13.0, 500.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1710 q_vals: [-8.12, -7.319, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 655 1 visits [13.0, 501.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1714 q_vals: [-8.12, -7.344, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 656 1 visits [13.0, 502.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1715 q_vals: [-8.12, -7.345, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 657 1 visits [13.0, 503.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1718 q_vals: [-8.12, -7.346, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1722, "number_of_timesteps": 29404, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 658 1 visits [13.0, 504.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1722 q_vals: [-8.12, -7.347, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 659 1 visits [13.0, 505.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1724 q_vals: [-8.12, -7.348, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 660 1 visits [13.0, 506.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1728 q_vals: [-8.12, -7.349, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 661 1 visits [13.0, 507.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1730 q_vals: [-8.12, -7.374, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1733, "number_of_timesteps": 29582, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 662 1 visits [13.0, 508.0, 25.0, 52.0, 10.0, 46.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1733 q_vals: [-8.12, -7.398, -7.883, -7.663, -9.053, -7.654, -9.436, -11.294, -11.479, -10.222]
Step 663 5 visits [13.0, 508.0, 25.0, 52.0, 10.0, 47.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1734 q_vals: [-8.12, -7.398, -7.883, -7.663, -9.053, -7.659, -9.436, -11.294, -11.479, -10.222]
Step 664 1 visits [13.0, 509.0, 25.0, 52.0, 10.0, 47.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1738 q_vals: [-8.12, -7.399, -7.883, -7.663, -9.053, -7.659, -9.436, -11.294, -11.479, -10.222]
Step 665 1 visits [13.0, 510.0, 25.0, 52.0, 10.0, 47.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1741 q_vals: [-8.12, -7.4, -7.883, -7.663, -9.053, -7.659, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1743, "number_of_timesteps": 29722, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 666 1 visits [13.0, 511.0, 25.0, 52.0, 10.0, 47.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1743 q_vals: [-8.12, -7.401, -7.883, -7.663, -9.053, -7.659, -9.436, -11.294, -11.479, -10.222]
Step 667 5 visits [13.0, 511.0, 25.0, 52.0, 10.0, 48.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1746 q_vals: [-8.12, -7.401, -7.883, -7.663, -9.053, -7.664, -9.436, -11.294, -11.479, -10.222]
Step 668 1 visits [13.0, 512.0, 25.0, 52.0, 10.0, 48.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1748 q_vals: [-8.12, -7.425, -7.883, -7.663, -9.053, -7.664, -9.436, -11.294, -11.479, -10.222]
Step 669 5 visits [13.0, 512.0, 25.0, 52.0, 10.0, 49.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1750 q_vals: [-8.12, -7.425, -7.883, -7.663, -9.053, -7.669, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1755, "number_of_timesteps": 29956, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 670 5 visits [13.0, 512.0, 25.0, 52.0, 10.0, 50.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1755 q_vals: [-8.12, -7.425, -7.883, -7.663, -9.053, -7.674, -9.436, -11.294, -11.479, -10.222]
Step 671 3 visits [13.0, 512.0, 25.0, 53.0, 10.0, 50.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1755 q_vals: [-8.12, -7.425, -7.883, -7.667, -9.053, -7.674, -9.436, -11.294, -11.479, -10.222]
Step 672 1 visits [13.0, 513.0, 25.0, 53.0, 10.0, 50.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1755 q_vals: [-8.12, -7.426, -7.883, -7.667, -9.053, -7.674, -9.436, -11.294, -11.479, -10.222]
Step 673 5 visits [13.0, 513.0, 25.0, 53.0, 10.0, 51.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1756 q_vals: [-8.12, -7.426, -7.883, -7.667, -9.053, -7.523, -9.436, -11.294, -11.479, -10.222]
Step 674 5 visits [13.0, 513.0, 25.0, 53.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1762 q_vals: [-8.12, -7.426, -7.883, -7.667, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1765, "number_of_timesteps": 30165, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 675 1 visits [13.0, 514.0, 25.0, 53.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1765 q_vals: [-8.12, -7.45, -7.883, -7.667, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 676 3 visits [13.0, 514.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1765 q_vals: [-8.12, -7.45, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 677 1 visits [13.0, 515.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1767 q_vals: [-8.12, -7.451, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 678 1 visits [13.0, 516.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1772 q_vals: [-8.12, -7.452, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 679 1 visits [13.0, 517.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1773 q_vals: [-8.12, -7.453, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 680 1 visits [13.0, 518.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1774 q_vals: [-8.12, -7.453, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1776, "number_of_timesteps": 30365, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 681 1 visits [13.0, 519.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1776 q_vals: [-8.12, -7.439, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 682 1 visits [13.0, 520.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1778 q_vals: [-8.12, -7.44, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 683 1 visits [13.0, 521.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1781 q_vals: [-8.12, -7.441, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 684 1 visits [13.0, 522.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1782 q_vals: [-8.12, -7.442, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 685 1 visits [13.0, 523.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1785 q_vals: [-8.12, -7.443, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1787, "number_of_timesteps": 30596, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 686 1 visits [13.0, 524.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1787 q_vals: [-8.12, -7.443, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 687 1 visits [13.0, 525.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1792 q_vals: [-8.12, -7.467, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 688 1 visits [13.0, 526.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1792 q_vals: [-8.12, -7.468, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 689 1 visits [13.0, 527.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1795 q_vals: [-8.12, -7.469, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 690 1 visits [13.0, 528.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1795 q_vals: [-8.12, -7.469, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1798, "number_of_timesteps": 30834, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 691 1 visits [13.0, 529.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1798 q_vals: [-8.12, -7.47, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 692 1 visits [13.0, 530.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1803 q_vals: [-8.12, -7.471, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 693 1 visits [13.0, 531.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1804 q_vals: [-8.12, -7.472, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 694 1 visits [13.0, 532.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1806 q_vals: [-8.12, -7.473, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 695 1 visits [13.0, 533.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1807 q_vals: [-8.12, -7.459, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1810, "number_of_timesteps": 31067, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 696 1 visits [13.0, 534.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1810 q_vals: [-8.12, -7.459, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 697 1 visits [13.0, 535.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1811 q_vals: [-8.12, -7.46, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 698 1 visits [13.0, 536.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1814 q_vals: [-8.12, -7.461, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 699 1 visits [13.0, 537.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1817 q_vals: [-8.12, -7.462, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 700 1 visits [13.0, 538.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1817 q_vals: [-8.12, -7.463, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1821, "number_of_timesteps": 31307, "per_episode_reward": 14.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 701 1 visits [13.0, 539.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1821 q_vals: [-8.12, -7.464, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 702 1 visits [13.0, 540.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1823 q_vals: [-8.12, -7.464, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 703 1 visits [13.0, 541.0, 25.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1826 q_vals: [-8.12, -7.487, -7.883, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 704 2 visits [13.0, 541.0, 26.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1827 q_vals: [-8.12, -7.487, -7.579, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 705 2 visits [13.0, 541.0, 27.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1830 q_vals: [-8.12, -7.487, -7.591, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1835, "number_of_timesteps": 31583, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 706 2 visits [13.0, 541.0, 28.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1835 q_vals: [-8.12, -7.487, -7.602, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 707 2 visits [13.0, 541.0, 29.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1837 q_vals: [-8.12, -7.487, -7.613, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 708 2 visits [13.0, 541.0, 30.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1839 q_vals: [-8.12, -7.487, -8.017, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 709 1 visits [13.0, 542.0, 30.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1839 q_vals: [-8.12, -7.51, -8.017, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 710 1 visits [13.0, 543.0, 30.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1841 q_vals: [-8.12, -7.51, -8.017, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
Step 711 1 visits [13.0, 544.0, 30.0, 54.0, 10.0, 52.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1844 q_vals: [-8.12, -7.533, -8.017, -7.891, -9.053, -7.759, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1846, "number_of_timesteps": 31788, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 712 5 visits [13.0, 544.0, 30.0, 54.0, 10.0, 53.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1846 q_vals: [-8.12, -7.533, -8.017, -7.891, -9.053, -7.761, -9.436, -11.294, -11.479, -10.222]
Step 713 5 visits [13.0, 544.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1850 q_vals: [-8.12, -7.533, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 714 0 visits [14.0, 544.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1851 q_vals: [-8.104, -7.533, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 715 0 visits [15.0, 544.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1852 q_vals: [-8.091, -7.533, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1856, "number_of_timesteps": 31984, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 716 1 visits [15.0, 545.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1856 q_vals: [-8.091, -7.555, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 717 0 visits [16.0, 545.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1858 q_vals: [-8.079, -7.555, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 718 0 visits [17.0, 545.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1859 q_vals: [-7.604, -7.555, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 719 0 visits [18.0, 545.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1863 q_vals: [-7.62, -7.555, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 720 0 visits [19.0, 545.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1863 q_vals: [-7.635, -7.555, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 721 0 visits [20.0, 545.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1865 q_vals: [-7.648, -7.555, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1867, "number_of_timesteps": 32216, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 722 0 visits [21.0, 545.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1867 q_vals: [-8.225, -7.555, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 723 1 visits [21.0, 546.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1868 q_vals: [-8.225, -7.541, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 724 1 visits [21.0, 547.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1871 q_vals: [-8.225, -7.542, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 725 1 visits [21.0, 548.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1873 q_vals: [-8.225, -7.543, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 726 1 visits [21.0, 549.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1875 q_vals: [-8.225, -7.529, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1879, "number_of_timesteps": 32484, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 727 1 visits [21.0, 550.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1879 q_vals: [-8.225, -7.515, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 728 1 visits [21.0, 551.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1880 q_vals: [-8.225, -7.516, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 729 1 visits [21.0, 552.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1882 q_vals: [-8.225, -7.517, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 730 1 visits [21.0, 553.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1886 q_vals: [-8.225, -7.503, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 731 1 visits [21.0, 554.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1888 q_vals: [-8.225, -7.504, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1891, "number_of_timesteps": 32744, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 732 1 visits [21.0, 555.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1891 q_vals: [-8.225, -7.505, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 733 1 visits [21.0, 556.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1891 q_vals: [-8.225, -7.505, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 734 1 visits [21.0, 557.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1891 q_vals: [-8.225, -7.492, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 735 1 visits [21.0, 558.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1895 q_vals: [-8.225, -7.493, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 736 1 visits [21.0, 559.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1897 q_vals: [-8.225, -7.493, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 737 1 visits [21.0, 560.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1900 q_vals: [-8.225, -7.515, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1902, "number_of_timesteps": 33002, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 738 1 visits [21.0, 561.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1902 q_vals: [-8.225, -7.537, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 739 1 visits [21.0, 562.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1903 q_vals: [-8.225, -7.559, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 740 1 visits [21.0, 563.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1903 q_vals: [-8.225, -7.545, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 741 1 visits [21.0, 564.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1907 q_vals: [-8.225, -7.546, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 742 1 visits [21.0, 565.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1908 q_vals: [-8.225, -7.568, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 743 1 visits [21.0, 566.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1910 q_vals: [-8.225, -7.568, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 744 1 visits [21.0, 567.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1911 q_vals: [-8.225, -7.59, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1916, "number_of_timesteps": 33348, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
Step 745 1 visits [21.0, 568.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1916 q_vals: [-8.225, -7.59, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 746 1 visits [21.0, 569.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1917 q_vals: [-8.225, -7.591, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 747 1 visits [21.0, 570.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1917 q_vals: [-8.225, -7.591, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 748 1 visits [21.0, 571.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1919 q_vals: [-8.225, -7.592, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 749 1 visits [21.0, 572.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1921 q_vals: [-8.225, -7.613, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 750 1 visits [21.0, 573.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1924 q_vals: [-8.225, -7.6, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 751 1 visits [21.0, 574.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1925 q_vals: [-8.225, -7.6, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1929, "number_of_timesteps": 33640, "per_episode_reward": 14.75, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
Step 752 1 visits [21.0, 575.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1929 q_vals: [-8.225, -7.621, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 753 1 visits [21.0, 576.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1930 q_vals: [-8.225, -7.622, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 754 1 visits [21.0, 577.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1933 q_vals: [-8.225, -7.643, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 755 1 visits [21.0, 578.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1935 q_vals: [-8.225, -7.643, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 756 1 visits [21.0, 579.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1937 q_vals: [-8.225, -7.644, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1940, "number_of_timesteps": 33864, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
Step 757 1 visits [21.0, 580.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1940 q_vals: [-8.225, -7.644, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 758 1 visits [21.0, 581.0, 30.0, 54.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1941 q_vals: [-8.225, -7.665, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 759 3 visits [21.0, 581.0, 30.0, 55.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1944 q_vals: [-8.225, -7.665, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 760 3 visits [21.0, 581.0, 30.0, 56.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1947 q_vals: [-8.225, -7.665, -8.017, -7.891, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 761 3 visits [21.0, 581.0, 30.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1948 q_vals: [-8.225, -7.665, -8.017, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1952, "number_of_timesteps": 34108, "per_episode_reward": 14.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
Step 762 2 visits [21.0, 581.0, 31.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1952 q_vals: [-8.225, -7.665, -8.014, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 763 2 visits [21.0, 581.0, 32.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1954 q_vals: [-8.225, -7.665, -8.01, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 764 2 visits [21.0, 581.0, 33.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1957 q_vals: [-8.225, -7.665, -7.767, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 765 2 visits [21.0, 581.0, 34.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1960 q_vals: [-8.225, -7.665, -7.539, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1964, "number_of_timesteps": 34298, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
Step 766 2 visits [21.0, 581.0, 35.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1964 q_vals: [-8.225, -7.665, -7.888, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 767 2 visits [21.0, 581.0, 36.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1965 q_vals: [-8.225, -7.665, -7.888, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 768 2 visits [21.0, 581.0, 37.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1969 q_vals: [-8.225, -7.665, -7.889, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 769 2 visits [21.0, 581.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1971 q_vals: [-8.225, -7.665, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1974, "number_of_timesteps": 34452, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
Step 770 1 visits [21.0, 582.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1974 q_vals: [-8.225, -7.666, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 771 1 visits [21.0, 583.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1977 q_vals: [-8.225, -7.666, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 772 1 visits [21.0, 584.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1979 q_vals: [-8.225, -7.666, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 773 1 visits [21.0, 585.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1982 q_vals: [-8.225, -7.687, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1984, "number_of_timesteps": 34633, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
Step 774 1 visits [21.0, 586.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1984 q_vals: [-8.225, -7.687, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 775 1 visits [21.0, 587.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1987 q_vals: [-8.225, -7.688, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 776 1 visits [21.0, 588.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1988 q_vals: [-8.225, -7.675, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 777 1 visits [21.0, 589.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1991 q_vals: [-8.225, -7.675, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 1995, "number_of_timesteps": 34802, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
Step 778 1 visits [21.0, 590.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1995 q_vals: [-8.225, -7.675, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 779 1 visits [21.0, 591.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 1998 q_vals: [-8.225, -7.676, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 780 1 visits [21.0, 592.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2001 q_vals: [-8.225, -7.676, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 781 1 visits [21.0, 593.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2004 q_vals: [-8.225, -7.677, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 2007, "number_of_timesteps": 35012, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
Step 782 1 visits [21.0, 594.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2007 q_vals: [-8.225, -7.677, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 783 1 visits [21.0, 595.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2009 q_vals: [-8.225, -7.677, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 784 1 visits [21.0, 596.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2012 q_vals: [-8.225, -7.678, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 785 1 visits [21.0, 597.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2016 q_vals: [-8.225, -7.678, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 2020, "number_of_timesteps": 35210, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 786 1 visits [21.0, 598.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2020 q_vals: [-8.225, -7.698, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 787 1 visits [21.0, 599.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2022 q_vals: [-8.225, -7.699, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 788 1 visits [21.0, 600.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2022 q_vals: [-8.225, -7.686, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 789 1 visits [21.0, 601.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2025 q_vals: [-8.225, -7.686, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 790 1 visits [21.0, 602.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2029 q_vals: [-8.225, -7.706, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 2033, "number_of_timesteps": 35420, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 791 1 visits [21.0, 603.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2033 q_vals: [-8.225, -7.707, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 792 1 visits [21.0, 604.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2034 q_vals: [-8.225, -7.707, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 793 1 visits [21.0, 605.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2037 q_vals: [-8.225, -7.707, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 794 1 visits [21.0, 606.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2041 q_vals: [-8.225, -7.707, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 2043, "number_of_timesteps": 35572, "per_episode_reward": 14.65, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 795 1 visits [21.0, 607.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2043 q_vals: [-8.225, -7.695, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 796 1 visits [21.0, 608.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2048 q_vals: [-8.225, -7.695, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 797 1 visits [21.0, 609.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2050 q_vals: [-8.225, -7.695, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 798 1 visits [21.0, 610.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2052 q_vals: [-8.225, -7.696, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 2055, "number_of_timesteps": 35753, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 799 1 visits [21.0, 611.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2055 q_vals: [-8.225, -7.696, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 800 1 visits [21.0, 612.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2056 q_vals: [-8.225, -7.696, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 801 1 visits [21.0, 613.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2060 q_vals: [-8.225, -7.697, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 802 1 visits [21.0, 614.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2061 q_vals: [-8.225, -7.684, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 803 1 visits [21.0, 615.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2062 q_vals: [-8.225, -7.704, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 2067, "number_of_timesteps": 35988, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 804 1 visits [21.0, 616.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2067 q_vals: [-8.225, -7.704, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 805 1 visits [21.0, 617.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2068 q_vals: [-8.225, -7.705, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 806 1 visits [21.0, 618.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2070 q_vals: [-8.225, -7.705, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 807 1 visits [21.0, 619.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2072 q_vals: [-8.225, -7.724, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 808 1 visits [21.0, 620.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2073 q_vals: [-8.225, -7.725, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 809 1 visits [21.0, 621.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2076 q_vals: [-8.225, -7.725, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
{"total_number_of_episodes": 2079, "number_of_timesteps": 36258, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 810 1 visits [21.0, 622.0, 38.0, 57.0, 10.0, 54.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2079 q_vals: [-8.225, -7.744, -8.201, -8.099, -9.053, -7.983, -9.436, -11.294, -11.479, -10.222]
Step 811 5 visits [21.0, 622.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 2083 q_vals: [-8.225, -7.744, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -10.222]
Step 812 9 visits [21.0, 622.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 2.0]  episode_count: 2085 q_vals: [-8.225, -7.744, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -5.111]
Step 813 9 visits [21.0, 622.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 3.0]  episode_count: 2087 q_vals: [-8.225, -7.744, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -6.041]
Step 814 9 visits [21.0, 622.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 4.0]  episode_count: 2088 q_vals: [-8.225, -7.744, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -6.506]
{"total_number_of_episodes": 2091, "number_of_timesteps": 36476, "per_episode_reward": 14.65, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 815 9 visits [21.0, 622.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 5.0]  episode_count: 2091 q_vals: [-8.225, -7.744, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -6.785]
Step 816 9 visits [21.0, 622.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 6.0]  episode_count: 2093 q_vals: [-8.225, -7.744, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -6.971]
Step 817 9 visits [21.0, 622.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 7.0]  episode_count: 2095 q_vals: [-8.225, -7.744, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -5.975]
Step 818 9 visits [21.0, 622.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 8.0]  episode_count: 2096 q_vals: [-8.225, -7.744, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -7.697]
Step 819 9 visits [21.0, 622.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 9.0]  episode_count: 2099 q_vals: [-8.225, -7.744, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -7.72]
{"total_number_of_episodes": 2101, "number_of_timesteps": 36683, "per_episode_reward": 14.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 820 9 visits [21.0, 622.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2101 q_vals: [-8.225, -7.744, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 821 1 visits [21.0, 623.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2106 q_vals: [-8.225, -7.744, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 822 1 visits [21.0, 624.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2106 q_vals: [-8.225, -7.745, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 823 1 visits [21.0, 625.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2108 q_vals: [-8.225, -7.745, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2111, "number_of_timesteps": 36895, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.09999999999999964},
Step 824 1 visits [21.0, 626.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2111 q_vals: [-8.225, -7.764, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 825 0 visits [22.0, 626.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2113 q_vals: [-8.21, -7.764, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 826 0 visits [23.0, 626.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2114 q_vals: [-7.853, -7.764, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 827 0 visits [24.0, 626.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2116 q_vals: [-7.855, -7.764, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 828 0 visits [25.0, 626.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2118 q_vals: [-8.331, -7.764, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 829 1 visits [25.0, 627.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2120 q_vals: [-8.331, -7.764, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2123, "number_of_timesteps": 37147, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 830 1 visits [25.0, 628.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2123 q_vals: [-8.331, -7.783, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 831 1 visits [25.0, 629.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2123 q_vals: [-8.331, -7.803, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 832 1 visits [25.0, 630.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2126 q_vals: [-8.331, -7.803, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 833 1 visits [25.0, 631.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2129 q_vals: [-8.331, -7.803, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 834 1 visits [25.0, 632.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2132 q_vals: [-8.331, -7.79, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2134, "number_of_timesteps": 37415, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.09999999999999964},
Step 835 1 visits [25.0, 633.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2134 q_vals: [-8.331, -7.791, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 836 1 visits [25.0, 634.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2135 q_vals: [-8.331, -7.778, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 837 1 visits [25.0, 635.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2138 q_vals: [-8.331, -7.779, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 838 1 visits [25.0, 636.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2142 q_vals: [-8.331, -7.779, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 839 1 visits [25.0, 637.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2142 q_vals: [-8.331, -7.779, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2145, "number_of_timesteps": 37606, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 840 1 visits [25.0, 638.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2145 q_vals: [-8.331, -7.798, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 841 1 visits [25.0, 639.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2145 q_vals: [-8.331, -7.798, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 842 1 visits [25.0, 640.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2148 q_vals: [-8.331, -7.817, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 843 1 visits [25.0, 641.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2148 q_vals: [-8.331, -7.817, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 844 1 visits [25.0, 642.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2150 q_vals: [-8.331, -7.817, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 845 1 visits [25.0, 643.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2152 q_vals: [-8.331, -7.817, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2156, "number_of_timesteps": 37910, "per_episode_reward": 14.95, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
Step 846 1 visits [25.0, 644.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2156 q_vals: [-8.331, -7.817, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 847 1 visits [25.0, 645.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2158 q_vals: [-8.331, -7.836, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 848 1 visits [25.0, 646.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2159 q_vals: [-8.331, -7.854, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 849 1 visits [25.0, 647.0, 38.0, 57.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2160 q_vals: [-8.331, -7.872, -8.201, -8.099, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 850 3 visits [25.0, 647.0, 38.0, 58.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2161 q_vals: [-8.331, -7.872, -8.201, -8.096, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 851 3 visits [25.0, 647.0, 38.0, 59.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2165 q_vals: [-8.331, -7.872, -8.201, -8.093, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2168, "number_of_timesteps": 38174, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 852 3 visits [25.0, 647.0, 38.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2168 q_vals: [-8.331, -7.872, -8.201, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 853 1 visits [25.0, 648.0, 38.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2168 q_vals: [-8.331, -7.86, -8.201, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 854 1 visits [25.0, 649.0, 38.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2169 q_vals: [-8.331, -7.879, -8.201, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 855 1 visits [25.0, 650.0, 38.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2173 q_vals: [-8.331, -7.879, -8.201, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 856 1 visits [25.0, 651.0, 38.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2174 q_vals: [-8.331, -7.879, -8.201, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 857 1 visits [25.0, 652.0, 38.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2174 q_vals: [-8.331, -7.879, -8.201, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 858 1 visits [25.0, 653.0, 38.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2176 q_vals: [-8.331, -7.879, -8.201, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2178, "number_of_timesteps": 38388, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 859 1 visits [25.0, 654.0, 38.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2178 q_vals: [-8.331, -7.879, -8.201, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 860 1 visits [25.0, 655.0, 38.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2182 q_vals: [-8.331, -7.867, -8.201, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 861 1 visits [25.0, 656.0, 38.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2182 q_vals: [-8.331, -7.867, -8.201, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 862 1 visits [25.0, 657.0, 38.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2185 q_vals: [-8.331, -7.867, -8.201, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2189, "number_of_timesteps": 38716, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 863 1 visits [25.0, 658.0, 38.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2189 q_vals: [-8.331, -7.885, -8.201, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 864 2 visits [25.0, 658.0, 39.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2190 q_vals: [-8.331, -7.885, -8.193, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 865 2 visits [25.0, 658.0, 40.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2193 q_vals: [-8.331, -7.885, -8.186, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 866 2 visits [25.0, 658.0, 41.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2196 q_vals: [-8.331, -7.885, -7.986, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 867 2 visits [25.0, 658.0, 42.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2198 q_vals: [-8.331, -7.885, -7.796, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2201, "number_of_timesteps": 38930, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 868 2 visits [25.0, 658.0, 43.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2201 q_vals: [-8.331, -7.885, -7.799, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 869 2 visits [25.0, 658.0, 44.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2204 q_vals: [-8.331, -7.885, -8.07, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 870 2 visits [25.0, 658.0, 45.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2204 q_vals: [-8.331, -7.885, -8.066, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 871 2 visits [25.0, 658.0, 46.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2209 q_vals: [-8.331, -7.885, -7.891, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2212, "number_of_timesteps": 39143, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 872 2 visits [25.0, 658.0, 47.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2212 q_vals: [-8.331, -7.885, -8.143, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 873 2 visits [25.0, 658.0, 48.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2215 q_vals: [-8.331, -7.885, -8.138, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 874 2 visits [25.0, 658.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2217 q_vals: [-8.331, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 875 1 visits [25.0, 659.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2220 q_vals: [-8.331, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2223, "number_of_timesteps": 39302, "per_episode_reward": 14.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 876 1 visits [25.0, 660.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2223 q_vals: [-8.331, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 877 1 visits [25.0, 661.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2225 q_vals: [-8.331, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 878 1 visits [25.0, 662.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2226 q_vals: [-8.331, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 879 1 visits [25.0, 663.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2228 q_vals: [-8.331, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2233, "number_of_timesteps": 39488, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 880 1 visits [25.0, 664.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2233 q_vals: [-8.331, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 881 1 visits [25.0, 665.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2236 q_vals: [-8.331, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 882 1 visits [25.0, 666.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2238 q_vals: [-8.331, -7.903, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 883 1 visits [25.0, 667.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2240 q_vals: [-8.331, -7.921, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 884 0 visits [26.0, 667.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2242 q_vals: [-8.315, -7.921, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2244, "number_of_timesteps": 39678, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 885 0 visits [27.0, 667.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2244 q_vals: [-8.007, -7.921, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 886 0 visits [28.0, 667.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2249 q_vals: [-8.003, -7.921, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 887 0 visits [29.0, 667.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2252 q_vals: [-7.999, -7.921, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2254, "number_of_timesteps": 39842, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 888 0 visits [30.0, 667.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2254 q_vals: [-8.391, -7.921, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 889 1 visits [30.0, 668.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2257 q_vals: [-8.391, -7.909, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 890 1 visits [30.0, 669.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2262 q_vals: [-8.391, -7.897, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 891 1 visits [30.0, 670.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2263 q_vals: [-8.391, -7.897, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2268, "number_of_timesteps": 40025, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
Step 892 1 visits [30.0, 671.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2268 q_vals: [-8.391, -7.897, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 893 1 visits [30.0, 672.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2271 q_vals: [-8.391, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 894 1 visits [30.0, 673.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2273 q_vals: [-8.391, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 895 1 visits [30.0, 674.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2277 q_vals: [-8.391, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2278, "number_of_timesteps": 40184, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
Step 896 1 visits [30.0, 675.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2278 q_vals: [-8.391, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 897 1 visits [30.0, 676.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2279 q_vals: [-8.391, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
q_vals: [-8.391, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 899 1 visits [30.0, 678.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2285 q_vals: [-8.391, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2288, "number_of_timesteps": 40387, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
Step 900 1 visits [30.0, 679.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2288 q_vals: [-8.391, -7.885, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 901 1 visits [30.0, 680.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2291 q_vals: [-8.391, -7.903, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 902 1 visits [30.0, 681.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2292 q_vals: [-8.391, -7.92, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 903 1 visits [30.0, 682.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2295 q_vals: [-8.391, -7.938, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2298, "number_of_timesteps": 40550, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
Step 904 1 visits [30.0, 683.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2298 q_vals: [-8.391, -7.938, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 905 1 visits [30.0, 684.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2302 q_vals: [-8.391, -7.926, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 906 1 visits [30.0, 685.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2305 q_vals: [-8.391, -7.926, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 907 1 visits [30.0, 686.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2306 q_vals: [-8.391, -7.943, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2309, "number_of_timesteps": 40726, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
Step 908 1 visits [30.0, 687.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2309 q_vals: [-8.391, -7.943, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 909 1 visits [30.0, 688.0, 49.0, 60.0, 10.0, 55.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2313 q_vals: [-8.391, -7.96, -8.375, -8.287, -9.053, -8.197, -9.436, -11.294, -11.479, -8.923]
Step 910 5 visits [30.0, 688.0, 49.0, 60.0, 10.0, 56.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2314 q_vals: [-8.391, -7.96, -8.375, -8.287, -9.053, -8.192, -9.436, -11.294, -11.479, -8.923]
Step 911 5 visits [30.0, 688.0, 49.0, 60.0, 10.0, 57.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2314 q_vals: [-8.391, -7.96, -8.375, -8.287, -9.053, -8.187, -9.436, -11.294, -11.479, -8.923]
Step 912 5 visits [30.0, 688.0, 49.0, 60.0, 10.0, 58.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2318 q_vals: [-8.391, -7.96, -8.375, -8.287, -9.053, -8.182, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2319, "number_of_timesteps": 40904, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
Step 913 5 visits [30.0, 688.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2319 q_vals: [-8.391, -7.96, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 914 1 visits [30.0, 689.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2322 q_vals: [-8.391, -7.96, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 915 1 visits [30.0, 690.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2325 q_vals: [-8.391, -7.977, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 916 1 visits [30.0, 691.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2327 q_vals: [-8.391, -7.977, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 917 1 visits [30.0, 692.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2328 q_vals: [-8.391, -7.994, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2333, "number_of_timesteps": 41171, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
Step 918 1 visits [30.0, 693.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2333 q_vals: [-8.391, -8.011, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 919 1 visits [30.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2335 q_vals: [-8.391, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 920 0 visits [31.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2337 q_vals: [-8.375, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 921 0 visits [32.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2341 q_vals: [-8.361, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2343, "number_of_timesteps": 41314, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
Step 922 0 visits [33.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2343 q_vals: [-8.347, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 923 0 visits [34.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2346 q_vals: [-8.333, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 924 0 visits [35.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2347 q_vals: [-8.321, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 925 0 visits [36.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2351 q_vals: [-8.309, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2353, "number_of_timesteps": 41555, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
Step 926 0 visits [37.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2353 q_vals: [-8.085, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 927 0 visits [38.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2354 q_vals: [-8.08, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
[39.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2357 q_vals: [-8.075, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 929 0 visits [40.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2358 q_vals: [-7.874, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 930 0 visits [41.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2361 q_vals: [-7.874, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2364, "number_of_timesteps": 41751, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 931 0 visits [42.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2364 q_vals: [-7.875, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 932 0 visits [43.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2368 q_vals: [-8.151, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 933 0 visits [44.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2369 q_vals: [-8.145, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
Step 934 0 visits [45.0, 694.0, 49.0, 60.0, 10.0, 59.0, 3.0, 2.0, 2.0, 10.0]  episode_count: 2373 q_vals: [-8.403, -8.028, -8.375, -8.287, -9.053, -8.378, -9.436, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2374, "number_of_timesteps": 41953, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 935 6 visits [45.0, 694.0, 49.0, 60.0, 10.0, 59.0, 4.0, 2.0, 2.0, 10.0]  episode_count: 2374 q_vals: [-8.403, -8.028, -8.375, -8.287, -9.053, -8.378, -9.052, -11.294, -11.479, -8.923]
Step 936 6 visits [45.0, 694.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2374 q_vals: [-8.403, -8.028, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 937 1 visits [45.0, 695.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2376 q_vals: [-8.403, -8.028, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 938 1 visits [45.0, 696.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2380 q_vals: [-8.403, -8.016, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 939 1 visits [45.0, 697.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2381 q_vals: [-8.403, -8.016, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2384, "number_of_timesteps": 42170, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 940 1 visits [45.0, 698.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2384 q_vals: [-8.403, -8.016, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 941 1 visits [45.0, 699.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2388 q_vals: [-8.403, -8.016, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 942 1 visits [45.0, 700.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2390 q_vals: [-8.403, -8.016, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 943 1 visits [45.0, 701.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2393 q_vals: [-8.403, -8.032, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2396, "number_of_timesteps": 42371, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 944 1 visits [45.0, 702.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2396 q_vals: [-8.403, -8.032, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 945 1 visits [45.0, 703.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2398 q_vals: [-8.403, -8.032, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 946 1 visits [45.0, 704.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2402 q_vals: [-8.403, -8.021, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2406, "number_of_timesteps": 42538, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 947 1 visits [45.0, 705.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2406 q_vals: [-8.403, -8.02, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 948 1 visits [45.0, 706.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2407 q_vals: [-8.403, -8.037, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 949 1 visits [45.0, 707.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2411 q_vals: [-8.403, -8.037, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 950 1 visits [45.0, 708.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2414 q_vals: [-8.403, -8.037, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2417, "number_of_timesteps": 42687, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 951 1 visits [45.0, 709.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2417 q_vals: [-8.403, -8.037, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 952 1 visits [45.0, 710.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2420 q_vals: [-8.403, -8.036, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 953 1 visits [45.0, 711.0, 49.0, 60.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2424 q_vals: [-8.403, -8.053, -8.375, -8.287, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 954 3 visits [45.0, 711.0, 49.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2426 q_vals: [-8.403, -8.053, -8.375, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2430, "number_of_timesteps": 42881, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 955 1 visits [45.0, 712.0, 49.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2430 q_vals: [-8.403, -8.053, -8.375, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 956 1 visits [45.0, 713.0, 49.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2433 q_vals: [-8.403, -8.069, -8.375, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 957 1 visits [45.0, 714.0, 49.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2437 q_vals: [-8.403, -8.085, -8.375, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 958 1 visits [45.0, 715.0, 49.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2439 q_vals: [-8.403, -8.102, -8.375, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2443, "number_of_timesteps": 43065, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 959 2 visits [45.0, 715.0, 50.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2443 q_vals: [-8.403, -8.102, -8.366, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 960 2 visits [45.0, 715.0, 51.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2445 q_vals: [-8.403, -8.102, -8.357, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 961 2 visits [45.0, 715.0, 52.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2447 q_vals: [-8.403, -8.102, -8.576, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 962 1 visits [45.0, 716.0, 52.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2449 q_vals: [-8.403, -8.101, -8.576, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2454, "number_of_timesteps": 43240, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 963 1 visits [45.0, 717.0, 52.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2454 q_vals: [-8.403, -8.118, -8.576, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 964 0 visits [46.0, 717.0, 52.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2454 q_vals: [-8.392, -8.118, -8.576, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 965 0 visits [47.0, 717.0, 52.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2459 q_vals: [-8.634, -8.118, -8.576, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 966 1 visits [47.0, 718.0, 52.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2462 q_vals: [-8.634, -8.134, -8.576, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 967 1 visits [47.0, 719.0, 52.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2463 q_vals: [-8.634, -8.134, -8.576, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2467, "number_of_timesteps": 43442, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 968 1 visits [47.0, 720.0, 52.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2467 q_vals: [-8.634, -8.133, -8.576, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 969 1 visits [47.0, 721.0, 52.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2470 q_vals: [-8.634, -8.133, -8.576, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 970 1 visits [47.0, 722.0, 52.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2471 q_vals: [-8.634, -8.122, -8.576, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 971 1 visits [47.0, 723.0, 52.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2473 q_vals: [-8.634, -8.121, -8.576, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2477, "number_of_timesteps": 43599, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 972 1 visits [47.0, 724.0, 52.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2477 q_vals: [-8.634, -8.121, -8.576, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 973 1 visits [47.0, 725.0, 52.0, 61.0, 10.0, 59.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2480 q_vals: [-8.634, -8.137, -8.576, -8.475, -9.053, -8.378, -11.193, -11.294, -11.479, -8.923]
Step 974 5 visits [47.0, 725.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2480 q_vals: [-8.634, -8.137, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 975 1 visits [47.0, 726.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2485 q_vals: [-8.634, -8.153, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 976 1 visits [47.0, 727.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2485 q_vals: [-8.634, -8.153, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 977 1 visits [47.0, 728.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2486 q_vals: [-8.634, -8.142, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2487, "number_of_timesteps": 43821, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 978 1 visits [47.0, 729.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2487 q_vals: [-8.634, -8.141, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 979 1 visits [47.0, 730.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2491 q_vals: [-8.634, -8.157, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 980 1 visits [47.0, 731.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2495 q_vals: [-8.634, -8.173, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2497, "number_of_timesteps": 44048, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 981 1 visits [47.0, 732.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2497 q_vals: [-8.634, -8.173, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 982 1 visits [47.0, 733.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2498 q_vals: [-8.634, -8.172, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 983 1 visits [47.0, 734.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2499 q_vals: [-8.634, -8.172, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 984 1 visits [47.0, 735.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2504 q_vals: [-8.634, -8.171, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 985 1 visits [47.0, 736.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2505 q_vals: [-8.634, -8.171, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2507, "number_of_timesteps": 44246, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 986 1 visits [47.0, 737.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2507 q_vals: [-8.634, -8.171, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 987 1 visits [47.0, 738.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2508 q_vals: [-8.634, -8.17, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 988 1 visits [47.0, 739.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2511 q_vals: [-8.634, -8.17, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 989 1 visits [47.0, 740.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2514 q_vals: [-8.634, -8.17, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 990 1 visits [47.0, 741.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2516 q_vals: [-8.634, -8.169, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
{"total_number_of_episodes": 2518, "number_of_timesteps": 44433, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 991 1 visits [47.0, 742.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2518 q_vals: [-8.634, -8.169, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 992 1 visits [47.0, 743.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2519 q_vals: [-8.634, -8.185, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 993 1 visits [47.0, 744.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2521 q_vals: [-8.634, -8.184, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 994 1 visits [47.0, 745.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 10.0]  episode_count: 2523 q_vals: [-8.634, -8.2, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -8.923]
Step 995 9 visits [47.0, 745.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2524 q_vals: [-8.634, -8.2, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2529, "number_of_timesteps": 44722, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 996 1 visits [47.0, 746.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2529 q_vals: [-8.634, -8.199, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 997 1 visits [47.0, 747.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2530 q_vals: [-8.634, -8.199, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 998 1 visits [47.0, 748.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2530 q_vals: [-8.634, -8.214, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 999 1 visits [47.0, 749.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2534 q_vals: [-8.634, -8.214, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1000 1 visits [47.0, 750.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2535 q_vals: [-8.634, -8.213, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1001 1 visits [47.0, 751.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2536 q_vals: [-8.634, -8.213, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2542, "number_of_timesteps": 45012, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1002 1 visits [47.0, 752.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2542 q_vals: [-8.634, -8.213, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1003 1 visits [47.0, 753.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2544 q_vals: [-8.634, -8.212, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1004 1 visits [47.0, 754.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2546 q_vals: [-8.634, -8.212, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1005 1 visits [47.0, 755.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2548 q_vals: [-8.634, -8.211, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1006 1 visits [47.0, 756.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2550 q_vals: [-8.634, -8.211, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1007 1 visits [47.0, 757.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2551 q_vals: [-8.634, -8.211, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2552, "number_of_timesteps": 45192, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1008 1 visits [47.0, 758.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2552 q_vals: [-8.634, -8.21, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1009 1 visits [47.0, 759.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2558 q_vals: [-8.634, -8.225, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1010 1 visits [47.0, 760.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2559 q_vals: [-8.634, -8.225, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2562, "number_of_timesteps": 45391, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1011 1 visits [47.0, 761.0, 52.0, 61.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2562 q_vals: [-8.634, -8.24, -8.576, -8.475, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1012 3 visits [47.0, 761.0, 52.0, 62.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2565 q_vals: [-8.634, -8.24, -8.576, -8.466, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1013 3 visits [47.0, 761.0, 52.0, 63.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2570 q_vals: [-8.634, -8.24, -8.576, -8.457, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1014 3 visits [47.0, 761.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2571 q_vals: [-8.634, -8.24, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2574, "number_of_timesteps": 45596, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1015 1 visits [47.0, 762.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2574 q_vals: [-8.634, -8.229, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1016 1 visits [47.0, 763.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2575 q_vals: [-8.634, -8.229, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1017 1 visits [47.0, 764.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2579 q_vals: [-8.634, -8.228, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1018 1 visits [47.0, 765.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2581 q_vals: [-8.634, -8.228, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1019 1 visits [47.0, 766.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2583 q_vals: [-8.634, -8.217, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2589, "number_of_timesteps": 45832, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1020 1 visits [47.0, 767.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2589 q_vals: [-8.634, -8.232, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1021 1 visits [47.0, 768.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2591 q_vals: [-8.634, -8.222, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1022 1 visits [47.0, 769.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2594 q_vals: [-8.634, -8.221, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2600, "number_of_timesteps": 45985, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1023 1 visits [47.0, 770.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2600 q_vals: [-8.634, -8.221, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1024 1 visits [47.0, 771.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2602 q_vals: [-8.634, -8.235, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1025 1 visits [47.0, 772.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2604 q_vals: [-8.634, -8.234, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2610, "number_of_timesteps": 46107, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1026 1 visits [47.0, 773.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2610 q_vals: [-8.634, -8.249, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1027 1 visits [47.0, 774.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2612 q_vals: [-8.634, -8.249, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1028 1 visits [47.0, 775.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2615 q_vals: [-8.634, -8.248, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2622, "number_of_timesteps": 46249, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1029 1 visits [47.0, 776.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2622 q_vals: [-8.634, -8.248, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1030 1 visits [47.0, 777.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2623 q_vals: [-8.634, -8.247, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1031 1 visits [47.0, 778.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2626 q_vals: [-8.634, -8.247, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1032 1 visits [47.0, 779.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2631 q_vals: [-8.634, -8.246, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1033 1 visits [47.0, 780.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2631 q_vals: [-8.634, -8.246, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2635, "number_of_timesteps": 46422, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1034 1 visits [47.0, 781.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2635 q_vals: [-8.634, -8.235, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1035 1 visits [47.0, 782.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2639 q_vals: [-8.634, -8.235, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1036 1 visits [47.0, 783.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2641 q_vals: [-8.634, -8.235, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2648, "number_of_timesteps": 46596, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1037 1 visits [47.0, 784.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2648 q_vals: [-8.634, -8.224, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1038 1 visits [47.0, 785.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2649 q_vals: [-8.634, -8.224, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1039 1 visits [47.0, 786.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2651 q_vals: [-8.634, -8.223, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2658, "number_of_timesteps": 46715, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 1040 1 visits [47.0, 787.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2658 q_vals: [-8.634, -8.223, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1041 1 visits [47.0, 788.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2658 q_vals: [-8.634, -8.222, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1042 1 visits [47.0, 789.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2660 q_vals: [-8.634, -8.222, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1043 1 visits [47.0, 790.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2661 q_vals: [-8.634, -8.222, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1044 1 visits [47.0, 791.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2662 q_vals: [-8.634, -8.221, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1045 1 visits [47.0, 792.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2665 q_vals: [-8.634, -8.221, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1046 1 visits [47.0, 793.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2666 q_vals: [-8.634, -8.235, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2668, "number_of_timesteps": 46881, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 1047 1 visits [47.0, 794.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2668 q_vals: [-8.634, -8.235, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1048 1 visits [47.0, 795.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2672 q_vals: [-8.634, -8.225, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1049 1 visits [47.0, 796.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2674 q_vals: [-8.634, -8.224, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1050 1 visits [47.0, 797.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2675 q_vals: [-8.634, -8.224, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2679, "number_of_timesteps": 47153, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 1051 1 visits [47.0, 798.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2679 q_vals: [-8.634, -8.223, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1052 1 visits [47.0, 799.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2682 q_vals: [-8.634, -8.223, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1053 1 visits [47.0, 800.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2684 q_vals: [-8.634, -8.223, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1054 1 visits [47.0, 801.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2688 q_vals: [-8.634, -8.222, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2691, "number_of_timesteps": 47333, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 1055 1 visits [47.0, 802.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2691 q_vals: [-8.634, -8.222, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1056 1 visits [47.0, 803.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2692 q_vals: [-8.634, -8.221, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1057 1 visits [47.0, 804.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2697 q_vals: [-8.634, -8.236, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1058 1 visits [47.0, 805.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2699 q_vals: [-8.634, -8.235, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2701, "number_of_timesteps": 47515, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 1059 1 visits [47.0, 806.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2701 q_vals: [-8.634, -8.235, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1060 1 visits [47.0, 807.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2704 q_vals: [-8.634, -8.249, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1061 1 visits [47.0, 808.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2710 q_vals: [-8.634, -8.249, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1062 1 visits [47.0, 809.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2710 q_vals: [-8.634, -8.248, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2713, "number_of_timesteps": 47693, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 1063 1 visits [47.0, 810.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2713 q_vals: [-8.634, -8.248, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1064 1 visits [47.0, 811.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2720 q_vals: [-8.634, -8.247, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1065 1 visits [47.0, 812.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2721 q_vals: [-8.634, -8.247, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2726, "number_of_timesteps": 47842, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1066 1 visits [47.0, 813.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2726 q_vals: [-8.634, -8.261, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1067 1 visits [47.0, 814.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2731 q_vals: [-8.634, -8.261, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1068 1 visits [47.0, 815.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2732 q_vals: [-8.634, -8.26, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2736, "number_of_timesteps": 47956, "per_episode_reward": 14.75, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 1069 1 visits [47.0, 816.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2736 q_vals: [-8.634, -8.25, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1070 1 visits [47.0, 817.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2737 q_vals: [-8.634, -8.25, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1071 1 visits [47.0, 818.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2741 q_vals: [-8.634, -8.249, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1072 1 visits [47.0, 819.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2744 q_vals: [-8.634, -8.249, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2746, "number_of_timesteps": 48105, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
Step 1073 1 visits [47.0, 820.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2746 q_vals: [-8.634, -8.248, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1074 1 visits [47.0, 821.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2750 q_vals: [-8.634, -8.262, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1075 1 visits [47.0, 822.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2752 q_vals: [-8.634, -8.262, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2756, "number_of_timesteps": 48276, "per_episode_reward": 14.75, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 1076 1 visits [47.0, 823.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2756 q_vals: [-8.634, -8.252, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1077 1 visits [47.0, 824.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2760 q_vals: [-8.634, -8.252, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1078 1 visits [47.0, 825.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2763 q_vals: [-8.634, -8.266, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2768, "number_of_timesteps": 48423, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 1079 1 visits [47.0, 826.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2768 q_vals: [-8.634, -8.265, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1080 1 visits [47.0, 827.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2770 q_vals: [-8.634, -8.265, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1081 1 visits [47.0, 828.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2775 q_vals: [-8.634, -8.263, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1082 1 visits [47.0, 829.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2777 q_vals: [-8.634, -8.253, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2781, "number_of_timesteps": 48581, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 1083 1 visits [47.0, 830.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2781 q_vals: [-8.634, -8.267, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1084 1 visits [47.0, 831.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2785 q_vals: [-8.634, -8.266, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1085 1 visits [47.0, 832.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2788 q_vals: [-8.634, -8.266, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2791, "number_of_timesteps": 48703, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 1086 1 visits [47.0, 833.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2791 q_vals: [-8.634, -8.265, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1087 1 visits [47.0, 834.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2795 q_vals: [-8.634, -8.255, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1088 1 visits [47.0, 835.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2799 q_vals: [-8.634, -8.255, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2804, "number_of_timesteps": 48861, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 1089 1 visits [47.0, 836.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2804 q_vals: [-8.634, -8.269, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1090 1 visits [47.0, 837.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2805 q_vals: [-8.634, -8.268, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1091 1 visits [47.0, 838.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2810 q_vals: [-8.634, -8.268, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2814, "number_of_timesteps": 48984, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
Step 1092 1 visits [47.0, 839.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2814 q_vals: [-8.634, -8.281, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1093 1 visits [47.0, 840.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2817 q_vals: [-8.634, -8.281, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1094 1 visits [47.0, 841.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2821 q_vals: [-8.634, -8.281, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2824, "number_of_timesteps": 49096, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
Step 1095 1 visits [47.0, 842.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2824 q_vals: [-8.634, -8.28, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1096 1 visits [47.0, 843.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2827 q_vals: [-8.634, -8.28, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1097 1 visits [47.0, 844.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2831 q_vals: [-8.634, -8.279, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1098 1 visits [47.0, 845.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2833 q_vals: [-8.634, -8.279, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2837, "number_of_timesteps": 49257, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 1099 1 visits [47.0, 846.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2837 q_vals: [-8.634, -8.292, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1100 1 visits [47.0, 847.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2841 q_vals: [-8.634, -8.292, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1101 1 visits [47.0, 848.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2843 q_vals: [-8.634, -8.282, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2847, "number_of_timesteps": 49405, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
Step 1102 1 visits [47.0, 849.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2847 q_vals: [-8.634, -8.282, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1103 1 visits [47.0, 850.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2849 q_vals: [-8.634, -8.272, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1104 1 visits [47.0, 851.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2850 q_vals: [-8.634, -8.271, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2857, "number_of_timesteps": 49563, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 1105 1 visits [47.0, 852.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2857 q_vals: [-8.634, -8.271, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1106 1 visits [47.0, 853.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2858 q_vals: [-8.634, -8.285, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1107 1 visits [47.0, 854.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2861 q_vals: [-8.634, -8.284, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1108 1 visits [47.0, 855.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2866 q_vals: [-8.634, -8.284, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2868, "number_of_timesteps": 49711, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1109 1 visits [47.0, 856.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2868 q_vals: [-8.634, -8.283, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1110 1 visits [47.0, 857.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2870 q_vals: [-8.634, -8.297, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1111 1 visits [47.0, 858.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2873 q_vals: [-8.634, -8.296, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1112 1 visits [47.0, 859.0, 52.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2877 q_vals: [-8.634, -8.309, -8.576, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2879, "number_of_timesteps": 49875, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
Step 1113 2 visits [47.0, 859.0, 53.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2879 q_vals: [-8.634, -8.309, -8.563, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1114 2 visits [47.0, 859.0, 54.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2882 q_vals: [-8.634, -8.309, -8.405, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1115 2 visits [47.0, 859.0, 55.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2885 q_vals: [-8.634, -8.309, -8.396, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1116 2 visits [47.0, 859.0, 56.0, 64.0, 10.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2886 q_vals: [-8.634, -8.309, -8.598, -8.633, -9.053, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1117 4 visits [47.0, 859.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2888 q_vals: [-8.634, -8.309, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2891, "number_of_timesteps": 50069, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 1118 1 visits [47.0, 860.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2891 q_vals: [-8.634, -8.3, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1119 1 visits [47.0, 861.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2896 q_vals: [-8.634, -8.299, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1120 1 visits [47.0, 862.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2898 q_vals: [-8.634, -8.299, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2901, "number_of_timesteps": 50236, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1121 1 visits [47.0, 863.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2901 q_vals: [-8.634, -8.298, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1122 1 visits [47.0, 864.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2902 q_vals: [-8.634, -8.312, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1123 1 visits [47.0, 865.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2907 q_vals: [-8.634, -8.311, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1124 1 visits [47.0, 866.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2910 q_vals: [-8.634, -8.302, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2913, "number_of_timesteps": 50413, "per_episode_reward": 14.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1125 1 visits [47.0, 867.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2913 q_vals: [-8.634, -8.301, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1126 1 visits [47.0, 868.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2916 q_vals: [-8.634, -8.301, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1127 1 visits [47.0, 869.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2919 q_vals: [-8.634, -8.3, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1128 1 visits [47.0, 870.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2921 q_vals: [-8.634, -8.297, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2923, "number_of_timesteps": 50561, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1129 1 visits [47.0, 871.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2923 q_vals: [-8.634, -8.296, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1130 1 visits [47.0, 872.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2927 q_vals: [-8.634, -8.296, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1131 1 visits [47.0, 873.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2931 q_vals: [-8.634, -8.295, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1132 1 visits [47.0, 874.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2931 q_vals: [-8.634, -8.295, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2936, "number_of_timesteps": 50758, "per_episode_reward": 14.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1133 1 visits [47.0, 875.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2936 q_vals: [-8.634, -8.294, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1134 1 visits [47.0, 876.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2940 q_vals: [-8.634, -8.293, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1135 1 visits [47.0, 877.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2944 q_vals: [-8.634, -8.306, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2946, "number_of_timesteps": 50896, "per_episode_reward": 14.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1136 1 visits [47.0, 878.0, 56.0, 64.0, 11.0, 60.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2946 q_vals: [-8.634, -8.319, -8.598, -8.633, -9.908, -8.568, -11.193, -11.294, -11.479, -9.908]
Step 1137 5 visits [47.0, 878.0, 56.0, 64.0, 11.0, 61.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2947 q_vals: [-8.634, -8.319, -8.598, -8.633, -9.908, -8.547, -11.193, -11.294, -11.479, -9.908]
Step 1138 5 visits [47.0, 878.0, 56.0, 64.0, 11.0, 62.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2952 q_vals: [-8.634, -8.319, -8.598, -8.633, -9.908, -8.409, -11.193, -11.294, -11.479, -9.908]
Step 1139 5 visits [47.0, 878.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2953 q_vals: [-8.634, -8.319, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1140 1 visits [47.0, 879.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2955 q_vals: [-8.634, -8.319, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2957, "number_of_timesteps": 51069, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1141 1 visits [47.0, 880.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2957 q_vals: [-8.634, -8.309, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1142 1 visits [47.0, 881.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2959 q_vals: [-8.634, -8.306, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1143 1 visits [47.0, 882.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2961 q_vals: [-8.634, -8.305, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1144 1 visits [47.0, 883.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2965 q_vals: [-8.634, -8.305, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2968, "number_of_timesteps": 51293, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1145 1 visits [47.0, 884.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2968 q_vals: [-8.634, -8.304, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1146 1 visits [47.0, 885.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2970 q_vals: [-8.634, -8.317, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1147 1 visits [47.0, 886.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2971 q_vals: [-8.634, -8.317, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1148 1 visits [47.0, 887.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2973 q_vals: [-8.634, -8.316, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2978, "number_of_timesteps": 51443, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1149 1 visits [47.0, 888.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2978 q_vals: [-8.634, -8.316, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1150 1 visits [47.0, 889.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2981 q_vals: [-8.634, -8.329, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1151 1 visits [47.0, 890.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2981 q_vals: [-8.634, -8.328, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1152 1 visits [47.0, 891.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2983 q_vals: [-8.634, -8.327, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1153 1 visits [47.0, 892.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2987 q_vals: [-8.634, -8.327, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2989, "number_of_timesteps": 51670, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1154 1 visits [47.0, 893.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2989 q_vals: [-8.634, -8.326, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1155 1 visits [47.0, 894.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2992 q_vals: [-8.634, -8.326, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1156 1 visits [47.0, 895.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2994 q_vals: [-8.634, -8.324, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1157 1 visits [47.0, 896.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2995 q_vals: [-8.634, -8.324, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 2999, "number_of_timesteps": 51866, "per_episode_reward": 14.45, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 1158 1 visits [47.0, 897.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 2999 q_vals: [-8.634, -8.323, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1159 1 visits [47.0, 898.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3003 q_vals: [-8.634, -8.323, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1160 1 visits [47.0, 899.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3004 q_vals: [-8.634, -8.323, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1161 1 visits [47.0, 900.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3005 q_vals: [-8.634, -8.322, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1162 1 visits [47.0, 901.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3007 q_vals: [-8.634, -8.322, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3011, "number_of_timesteps": 52077, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1163 1 visits [47.0, 902.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3011 q_vals: [-8.634, -8.321, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1164 1 visits [47.0, 903.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3014 q_vals: [-8.634, -8.321, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1165 1 visits [47.0, 904.0, 56.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3015 q_vals: [-8.634, -8.333, -8.598, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1166 2 visits [47.0, 904.0, 57.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3018 q_vals: [-8.634, -8.333, -8.448, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1167 2 visits [47.0, 904.0, 58.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3020 q_vals: [-8.634, -8.333, -8.438, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3021, "number_of_timesteps": 52271, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1168 2 visits [47.0, 904.0, 59.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3021 q_vals: [-8.634, -8.333, -8.429, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1169 2 visits [47.0, 904.0, 60.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3024 q_vals: [-8.634, -8.333, -8.42, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1170 2 visits [47.0, 904.0, 61.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3027 q_vals: [-8.634, -8.333, -8.606, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1171 1 visits [47.0, 905.0, 61.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3030 q_vals: [-8.634, -8.346, -8.606, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3031, "number_of_timesteps": 52469, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1172 0 visits [48.0, 905.0, 61.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3031 q_vals: [-8.615, -8.346, -8.606, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1173 0 visits [49.0, 905.0, 61.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3032 q_vals: [-8.601, -8.346, -8.606, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1174 0 visits [50.0, 905.0, 61.0, 64.0, 11.0, 63.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3038 q_vals: [-8.824, -8.346, -8.606, -8.633, -9.908, -8.589, -11.193, -11.294, -11.479, -9.908]
Step 1175 5 visits [50.0, 905.0, 61.0, 64.0, 11.0, 64.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3039 q_vals: [-8.824, -8.346, -8.606, -8.633, -9.908, -8.579, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3042, "number_of_timesteps": 52667, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1176 5 visits [50.0, 905.0, 61.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3042 q_vals: [-8.824, -8.346, -8.606, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1177 1 visits [50.0, 906.0, 61.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3044 q_vals: [-8.824, -8.358, -8.606, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1178 2 visits [50.0, 906.0, 62.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3044 q_vals: [-8.824, -8.358, -8.595, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1179 2 visits [50.0, 906.0, 63.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3046 q_vals: [-8.824, -8.358, -8.584, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1180 2 visits [50.0, 906.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3048 q_vals: [-8.824, -8.358, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1181 1 visits [50.0, 907.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3051 q_vals: [-8.824, -8.358, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3054, "number_of_timesteps": 52925, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1182 1 visits [50.0, 908.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3054 q_vals: [-8.824, -8.37, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1183 1 visits [50.0, 909.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3056 q_vals: [-8.824, -8.361, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1184 1 visits [50.0, 910.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3059 q_vals: [-8.824, -8.374, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1185 1 visits [50.0, 911.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3059 q_vals: [-8.824, -8.373, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3064, "number_of_timesteps": 53139, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1186 1 visits [50.0, 912.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3064 q_vals: [-8.824, -8.373, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1187 1 visits [50.0, 913.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3065 q_vals: [-8.824, -8.364, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1188 1 visits [50.0, 914.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3066 q_vals: [-8.824, -8.363, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
visits [50.0, 915.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3071 q_vals: [-8.824, -8.375, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1190 1 visits [50.0, 916.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3072 q_vals: [-8.824, -8.375, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3074, "number_of_timesteps": 53340, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1191 1 visits [50.0, 917.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3074 q_vals: [-8.824, -8.374, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1192 1 visits [50.0, 918.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3074 q_vals: [-8.824, -8.374, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1193 1 visits [50.0, 919.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3077 q_vals: [-8.824, -8.386, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1194 1 visits [50.0, 920.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3077 q_vals: [-8.824, -8.386, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1195 1 visits [50.0, 921.0, 64.0, 64.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3080 q_vals: [-8.824, -8.398, -8.739, -8.633, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1196 3 visits [50.0, 921.0, 64.0, 65.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3082 q_vals: [-8.824, -8.398, -8.739, -8.622, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3086, "number_of_timesteps": 53645, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1197 3 visits [50.0, 921.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3086 q_vals: [-8.824, -8.398, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1198 1 visits [50.0, 922.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3089 q_vals: [-8.824, -8.41, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1199 1 visits [50.0, 923.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3090 q_vals: [-8.824, -8.41, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1200 1 visits [50.0, 924.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3093 q_vals: [-8.824, -8.422, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1201 1 visits [50.0, 925.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3094 q_vals: [-8.824, -8.422, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3096, "number_of_timesteps": 53807, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 1202 1 visits [50.0, 926.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3096 q_vals: [-8.824, -8.412, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1203 1 visits [50.0, 927.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3098 q_vals: [-8.824, -8.412, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1204 1 visits [50.0, 928.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3103 q_vals: [-8.824, -8.411, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1205 1 visits [50.0, 929.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3103 q_vals: [-8.824, -8.411, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1206 1 visits [50.0, 930.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3105 q_vals: [-8.824, -8.41, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3110, "number_of_timesteps": 54097, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1207 1 visits [50.0, 931.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3110 q_vals: [-8.824, -8.41, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1208 1 visits [50.0, 932.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3111 q_vals: [-8.824, -8.422, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1209 1 visits [50.0, 933.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3111 q_vals: [-8.824, -8.421, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1210 1 visits [50.0, 934.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3113 q_vals: [-8.824, -8.421, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1211 1 visits [50.0, 935.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3115 q_vals: [-8.824, -8.42, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1212 1 visits [50.0, 936.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3118 q_vals: [-8.824, -8.42, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3120, "number_of_timesteps": 54333, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1213 1 visits [50.0, 937.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3120 q_vals: [-8.824, -8.419, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1214 1 visits [50.0, 938.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3123 q_vals: [-8.824, -8.419, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1215 1 visits [50.0, 939.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3125 q_vals: [-8.824, -8.418, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1216 1 visits [50.0, 940.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3127 q_vals: [-8.824, -8.417, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3130, "number_of_timesteps": 54528, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1217 1 visits [50.0, 941.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3130 q_vals: [-8.824, -8.43, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1218 1 visits [50.0, 942.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3131 q_vals: [-8.824, -8.429, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
[-8.824, -8.428, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1220 1 visits [50.0, 944.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3138 q_vals: [-8.824, -8.419, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1221 1 visits [50.0, 945.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3138 q_vals: [-8.824, -8.431, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3141, "number_of_timesteps": 54730, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1222 1 visits [50.0, 946.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3141 q_vals: [-8.824, -8.423, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1223 1 visits [50.0, 947.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3145 q_vals: [-8.824, -8.422, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1224 1 visits [50.0, 948.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3147 q_vals: [-8.824, -8.434, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1225 1 visits [50.0, 949.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3148 q_vals: [-8.824, -8.446, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1226 1 visits [50.0, 950.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3150 q_vals: [-8.824, -8.458, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3153, "number_of_timesteps": 54980, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1227 1 visits [50.0, 951.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3153 q_vals: [-8.824, -8.457, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1228 1 visits [50.0, 952.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3155 q_vals: [-8.824, -8.457, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1229 1 visits [50.0, 953.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3158 q_vals: [-8.824, -8.468, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3163, "number_of_timesteps": 55164, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1230 1 visits [50.0, 954.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3163 q_vals: [-8.824, -8.468, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1231 1 visits [50.0, 955.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3164 q_vals: [-8.824, -8.467, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1232 1 visits [50.0, 956.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3169 q_vals: [-8.824, -8.467, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1233 1 visits [50.0, 957.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3171 q_vals: [-8.824, -8.478, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3174, "number_of_timesteps": 55315, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1234 1 visits [50.0, 958.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3174 q_vals: [-8.824, -8.478, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1235 1 visits [50.0, 959.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3177 q_vals: [-8.824, -8.49, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1236 1 visits [50.0, 960.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3179 q_vals: [-8.824, -8.489, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1237 1 visits [50.0, 961.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3181 q_vals: [-8.824, -8.488, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3184, "number_of_timesteps": 55457, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1238 1 visits [50.0, 962.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3184 q_vals: [-8.824, -8.488, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1239 1 visits [50.0, 963.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3186 q_vals: [-8.824, -8.487, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1240 1 visits [50.0, 964.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3189 q_vals: [-8.824, -8.487, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1241 1 visits [50.0, 965.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3192 q_vals: [-8.824, -8.478, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3194, "number_of_timesteps": 55663, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1242 1 visits [50.0, 966.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3194 q_vals: [-8.824, -8.489, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1243 1 visits [50.0, 967.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3197 q_vals: [-8.824, -8.481, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1244 1 visits [50.0, 968.0, 64.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3201 q_vals: [-8.824, -8.492, -8.739, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1245 2 visits [50.0, 968.0, 65.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3203 q_vals: [-8.824, -8.492, -8.726, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1246 2 visits [50.0, 968.0, 66.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3203 q_vals: [-8.824, -8.492, -8.713, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3206, "number_of_timesteps": 55860, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 1247 2 visits [50.0, 968.0, 67.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3206 q_vals: [-8.824, -8.492, -8.701, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1248 2 visits [50.0, 968.0, 68.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3207 q_vals: [-8.824, -8.492, -8.689, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
[50.0, 968.0, 69.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3207 q_vals: [-8.824, -8.492, -8.678, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1250 2 visits [50.0, 968.0, 70.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3210 q_vals: [-8.824, -8.492, -8.667, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1251 2 visits [50.0, 968.0, 71.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3213 q_vals: [-8.824, -8.492, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1252 1 visits [50.0, 969.0, 71.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3214 q_vals: [-8.824, -8.504, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1253 1 visits [50.0, 970.0, 71.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3215 q_vals: [-8.824, -8.503, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3218, "number_of_timesteps": 56163, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 1254 1 visits [50.0, 971.0, 71.0, 66.0, 11.0, 65.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3218 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1255 5 visits [50.0, 971.0, 71.0, 66.0, 11.0, 66.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3218 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.738, -11.193, -11.294, -11.479, -9.908]
Step 1256 5 visits [50.0, 971.0, 71.0, 66.0, 11.0, 67.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3221 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.725, -11.193, -11.294, -11.479, -9.908]
Step 1257 5 visits [50.0, 971.0, 71.0, 66.0, 11.0, 68.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3223 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.713, -11.193, -11.294, -11.479, -9.908]
Step 1258 5 visits [50.0, 971.0, 71.0, 66.0, 11.0, 69.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3224 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.701, -11.193, -11.294, -11.479, -9.908]
Step 1259 5 visits [50.0, 971.0, 71.0, 66.0, 11.0, 70.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3227 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.69, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3231, "number_of_timesteps": 56471, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 1260 5 visits [50.0, 971.0, 71.0, 66.0, 11.0, 71.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3231 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.567, -11.193, -11.294, -11.479, -9.908]
Step 1261 5 visits [50.0, 971.0, 71.0, 66.0, 11.0, 72.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3231 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.448, -11.193, -11.294, -11.479, -9.908]
Step 1262 5 visits [50.0, 971.0, 71.0, 66.0, 11.0, 73.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3236 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.603, -11.193, -11.294, -11.479, -9.908]
Step 1263 5 visits [50.0, 971.0, 71.0, 66.0, 11.0, 74.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3238 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.594, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3241, "number_of_timesteps": 56677, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 1264 5 visits [50.0, 971.0, 71.0, 66.0, 11.0, 75.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3241 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.585, -11.193, -11.294, -11.479, -9.908]
Step 1265 5 visits [50.0, 971.0, 71.0, 66.0, 11.0, 76.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3247 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.731, -11.193, -11.294, -11.479, -9.908]
Step 1266 5 visits [50.0, 971.0, 71.0, 66.0, 11.0, 77.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3248 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.618, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3252, "number_of_timesteps": 56823, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 1267 5 visits [50.0, 971.0, 71.0, 66.0, 11.0, 78.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3252 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.609, -11.193, -11.294, -11.479, -9.908]
Step 1268 5 visits [50.0, 971.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3253 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1269 1 visits [50.0, 972.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3257 q_vals: [-8.824, -8.514, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1270 1 visits [50.0, 973.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3260 q_vals: [-8.824, -8.514, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1271 1 visits [50.0, 974.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3261 q_vals: [-8.824, -8.525, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3264, "number_of_timesteps": 57020, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 1272 1 visits [50.0, 975.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3264 q_vals: [-8.824, -8.525, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1273 1 visits [50.0, 976.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3268 q_vals: [-8.824, -8.524, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1274 1 visits [50.0, 977.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3269 q_vals: [-8.824, -8.523, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1275 1 visits [50.0, 978.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3270 q_vals: [-8.824, -8.523, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3275, "number_of_timesteps": 57227, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 1276 1 visits [50.0, 979.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3275 q_vals: [-8.824, -8.522, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1277 1 visits [50.0, 980.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3279 q_vals: [-8.824, -8.521, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1278 1 visits [50.0, 981.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3281 q_vals: [-8.824, -8.513, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3288, "number_of_timesteps": 57399, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 1279 1 visits [50.0, 982.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3288 q_vals: [-8.824, -8.524, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1280 1 visits [50.0, 983.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3291 q_vals: [-8.824, -8.524, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1281 1 visits [50.0, 984.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3294 q_vals: [-8.824, -8.515, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3300, "number_of_timesteps": 57530, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1282 1 visits [50.0, 985.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3300 q_vals: [-8.824, -8.506, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1283 1 visits [50.0, 986.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3301 q_vals: [-8.824, -8.506, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1284 1 visits [50.0, 987.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3304 q_vals: [-8.824, -8.517, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1285 1 visits [50.0, 988.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3309 q_vals: [-8.824, -8.528, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3311, "number_of_timesteps": 57683, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1286 1 visits [50.0, 989.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3311 q_vals: [-8.824, -8.54, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1287 0 visits [51.0, 989.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3315 q_vals: [-8.805, -8.54, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1288 0 visits [52.0, 989.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3318 q_vals: [-8.788, -8.54, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3321, "number_of_timesteps": 57811, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1289 0 visits [53.0, 989.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3321 q_vals: [-8.771, -8.54, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1290 0 visits [54.0, 989.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3325 q_vals: [-8.755, -8.54, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1291 0 visits [55.0, 989.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3328 q_vals: [-8.74, -8.54, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3332, "number_of_timesteps": 57947, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1292 0 visits [56.0, 989.0, 71.0, 66.0, 11.0, 79.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3332 q_vals: [-8.936, -8.54, -8.823, -8.791, -9.908, -8.75, -11.193, -11.294, -11.479, -9.908]
Step 1293 5 visits [56.0, 989.0, 71.0, 66.0, 11.0, 80.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3337 q_vals: [-8.936, -8.54, -8.823, -8.791, -9.908, -8.887, -11.193, -11.294, -11.479, -9.908]
Step 1294 1 visits [56.0, 990.0, 71.0, 66.0, 11.0, 80.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3339 q_vals: [-8.936, -8.539, -8.823, -8.791, -9.908, -8.887, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3343, "number_of_timesteps": 58073, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1295 1 visits [56.0, 991.0, 71.0, 66.0, 11.0, 80.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3343 q_vals: [-8.936, -8.538, -8.823, -8.791, -9.908, -8.887, -11.193, -11.294, -11.479, -9.908]
Step 1296 1 visits [56.0, 992.0, 71.0, 66.0, 11.0, 80.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3345 q_vals: [-8.936, -8.53, -8.823, -8.791, -9.908, -8.887, -11.193, -11.294, -11.479, -9.908]
Step 1297 1 visits [56.0, 993.0, 71.0, 66.0, 11.0, 80.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3350 q_vals: [-8.936, -8.541, -8.823, -8.791, -9.908, -8.887, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3353, "number_of_timesteps": 58209, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1298 1 visits [56.0, 994.0, 71.0, 66.0, 11.0, 80.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3353 q_vals: [-8.936, -8.54, -8.823, -8.791, -9.908, -8.887, -11.193, -11.294, -11.479, -9.908]
Step 1299 1 visits [56.0, 995.0, 71.0, 66.0, 11.0, 80.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3355 q_vals: [-8.936, -8.54, -8.823, -8.791, -9.908, -8.887, -11.193, -11.294, -11.479, -9.908]
Step 1300 1 visits [56.0, 996.0, 71.0, 66.0, 11.0, 80.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3360 q_vals: [-8.936, -8.539, -8.823, -8.791, -9.908, -8.887, -11.193, -11.294, -11.479, -9.908]
Step 1301 1 visits [56.0, 997.0, 71.0, 66.0, 11.0, 80.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3362 q_vals: [-8.936, -8.55, -8.823, -8.791, -9.908, -8.887, -11.193, -11.294, -11.479, -9.908]
{"total_number_of_episodes": 3365, "number_of_timesteps": 58368, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1302 3 visits [56.0, 997.0, 71.0, 67.0, 11.0, 80.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3365 q_vals: [-8.936, -8.55, -8.823, -8.954, -9.908, -8.887, -11.193, -11.294, -11.479, -9.908]
Step 1303 1 visits [56.0, 998.0, 71.0, 67.0, 11.0, 80.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3367 q_vals: [-8.936, -8.55, -8.823, -8.954, -9.908, -8.887, -11.193, -11.294, -11.479, -9.908]
Step 1304 1 visits [56.0, 999.0, 71.0, 67.0, 11.0, 80.0, 5.0, 2.0, 2.0, 11.0]  episode_count: 3371 q_vals: [-8.936, -8.549, -8.823, -8.954, -9.908, -8.887, -11.193, -11.294, -11.479, -9.908]
Step 1305 1 visits [0.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 3372 q_vals: [0.0, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
{"total_number_of_episodes": 3376, "number_of_timesteps": 58550, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.5},
Step 1306 0 visits [1.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 3376 q_vals: [0.0, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1307 2 visits [1.0, 1000.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 3382 q_vals: [0.0, -inf, -8.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1308 3 visits [1.0, 1000.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 3383 q_vals: [0.0, -inf, -8.75, -8.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
{"total_number_of_episodes": 3389, "number_of_timesteps": 58714, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.01722222222222221, "biggest_recent_change": 1.5},
Step 1309 4 visits [1.0, 1000.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 3389 q_vals: [0.0, -inf, -8.75, -8.75, -8.75, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1310 5 visits [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 3393 q_vals: [0.0, -inf, -8.75, -8.75, -8.75, -21.875, 0.0, 0.0, 0.0, 0.0]
Step 1311 6 visits [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 3395 q_vals: [0.0, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, 0.0, 0.0, 0.0]
Step 1312 7 visits [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 3398 q_vals: [0.0, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, 0.0, 0.0]
{"total_number_of_episodes": 3401, "number_of_timesteps": 58856, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.017777777777777774, "biggest_recent_change": 1.5},
Step 1313 8 visits [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 3401 q_vals: [0.0, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, 0.0]
Step 1314 9 visits [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 3403 q_vals: [0.0, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, 0.0]
Step 1315 0 visits [2.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 3409 q_vals: [-4.375, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, 0.0]
{"total_number_of_episodes": 3412, "number_of_timesteps": 59007, "per_episode_reward": 12.95, "episode_reward_trend_value": -0.018333333333333337, "biggest_recent_change": 1.5},
Step 1316 9 visits [2.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0]  episode_count: 3412 q_vals: [-4.375, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -4.375]
Step 1317 0 visits [3.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0]  episode_count: 3416 q_vals: [-2.917, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -4.375]
Step 1318 0 visits [4.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0]  episode_count: 3421 q_vals: [-2.187, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -4.375]
{"total_number_of_episodes": 3423, "number_of_timesteps": 59120, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.01888888888888888, "biggest_recent_change": 1.5},
Step 1319 0 visits [5.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0]  episode_count: 3423 q_vals: [-3.5, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -4.375]
Step 1320 0 visits [6.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0]  episode_count: 3427 q_vals: [-4.375, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -4.375]
Step 1321 9 visits [6.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0]  episode_count: 3430 q_vals: [-4.375, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -2.917]
{"total_number_of_episodes": 3434, "number_of_timesteps": 59260, "per_episode_reward": 12.95, "episode_reward_trend_value": -0.018333333333333337, "biggest_recent_change": 1.5},
Step 1322 9 visits [6.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3434 q_vals: [-4.375, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1323 0 visits [7.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3437 q_vals: [-3.75, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1324 0 visits [8.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3442 q_vals: [-3.281, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
{"total_number_of_episodes": 3444, "number_of_timesteps": 59375, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.01888888888888888, "biggest_recent_change": 1.5},
Step 1325 0 visits [9.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3444 q_vals: [-3.889, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1326 0 visits [10.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3446 q_vals: [-4.375, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1327 0 visits [11.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3451 q_vals: [-4.773, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1328 0 visits [12.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3453 q_vals: [-5.104, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
{"total_number_of_episodes": 3457, "number_of_timesteps": 59555, "per_episode_reward": 12.95, "episode_reward_trend_value": -0.018333333333333337, "biggest_recent_change": 1.5},
Step 1329 0 visits [13.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3457 q_vals: [-4.712, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1330 0 visits [14.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3461 q_vals: [-5.0, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1331 0 visits [15.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3464 q_vals: [-4.667, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
{"total_number_of_episodes": 3467, "number_of_timesteps": 59675, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.01888888888888888, "biggest_recent_change": 1.5},
Step 1332 0 visits [16.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3467 q_vals: [-4.922, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1333 0 visits [17.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3472 q_vals: [-4.632, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1334 0 visits [18.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3473 q_vals: [-4.861, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1335 0 visits [19.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3473 q_vals: [-5.066, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
{"total_number_of_episodes": 3478, "number_of_timesteps": 59832, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 1336 0 visits [20.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3478 q_vals: [-5.25, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1337 0 visits [21.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3480 q_vals: [-6.042, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1338 0 visits [22.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3483 q_vals: [-6.165, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1339 0 visits [23.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3487 q_vals: [-6.277, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
{"total_number_of_episodes": 3489, "number_of_timesteps": 60007, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 1340 0 visits [24.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3489 q_vals: [-6.38, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1341 0 visits [25.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3493 q_vals: [-6.125, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1342 0 visits [26.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3497 q_vals: [-6.226, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
{"total_number_of_episodes": 3499, "number_of_timesteps": 60162, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1343 0 visits [27.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3499 q_vals: [-5.995, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1344 0 visits [28.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3502 q_vals: [-6.094, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1345 0 visits [29.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3504 q_vals: [-6.185, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1346 0 visits [30.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3508 q_vals: [-6.271, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
{"total_number_of_episodes": 3512, "number_of_timesteps": 60363, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1347 0 visits [31.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3512 q_vals: [-6.069, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1348 0 visits [32.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3515 q_vals: [-6.152, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1349 0 visits [33.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3519 q_vals: [-6.231, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1350 0 visits [34.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3520 q_vals: [-6.048, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
{"total_number_of_episodes": 3522, "number_of_timesteps": 60489, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 1351 0 visits [35.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3522 q_vals: [-6.125, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1352 0 visits [36.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3527 q_vals: [-6.198, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1353 0 visits [37.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3529 q_vals: [-6.267, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1354 0 visits [38.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3531 q_vals: [-6.332, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
{"total_number_of_episodes": 3533, "number_of_timesteps": 60667, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1355 0 visits [39.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3533 q_vals: [-6.394, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1356 0 visits [40.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3535 q_vals: [-6.234, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1357 0 visits [41.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3537 q_vals: [-6.296, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1358 0 visits [42.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3537 q_vals: [-6.354, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1359 0 visits [43.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3540 q_vals: [-6.41, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1360 0 visits [44.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3542 q_vals: [-6.463, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
{"total_number_of_episodes": 3543, "number_of_timesteps": 60883, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 1361 0 visits [45.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3543 q_vals: [-6.514, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1362 0 visits [46.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3546 q_vals: [-6.562, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1363 0 visits [47.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3546 q_vals: [-6.609, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1364 0 visits [48.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3549 q_vals: [-6.471, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
{"total_number_of_episodes": 3553, "number_of_timesteps": 61139, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 1365 0 visits [49.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3553 q_vals: [-6.518, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1366 0 visits [50.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3553 q_vals: [-6.387, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1367 0 visits [51.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3553 q_vals: [-6.434, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1368 0 visits [52.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3553 q_vals: [-6.478, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1369 0 visits [53.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3558 q_vals: [-6.521, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1370 0 visits [54.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3561 q_vals: [-6.4, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1371 0 visits [55.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3562 q_vals: [-6.443, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
{"total_number_of_episodes": 3568, "number_of_timesteps": 61459, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1372 0 visits [56.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3568 q_vals: [-6.484, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1373 0 visits [57.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3568 q_vals: [-6.515, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1374 0 visits [58.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3569 q_vals: [-6.553, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1375 0 visits [59.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3574 q_vals: [-6.591, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1376 0 visits [60.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3575 q_vals: [-6.627, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1377 0 visits [61.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3576 q_vals: [-6.661, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
{"total_number_of_episodes": 3580, "number_of_timesteps": 61728, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1378 0 visits [62.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3580 q_vals: [-6.554, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1379 0 visits [63.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3581 q_vals: [-6.589, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1380 0 visits [64.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3584 q_vals: [-6.623, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1381 0 visits [65.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3586 q_vals: [-6.655, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1382 0 visits [66.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3589 q_vals: [-6.687, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
{"total_number_of_episodes": 3590, "number_of_timesteps": 61919, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 1383 0 visits [67.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3590 q_vals: [-6.587, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1384 0 visits [68.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3590 q_vals: [-6.619, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1385 0 visits [69.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3593 q_vals: [-6.65, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1386 0 visits [70.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 3595 q_vals: [-6.867, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -7.656]
Step 1387 9 visits [70.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0]  episode_count: 3598 q_vals: [-6.867, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -9.976]
{"total_number_of_episodes": 3602, "number_of_timesteps": 62210, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1388 0 visits [71.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0]  episode_count: 3602 q_vals: [-6.894, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -9.976]
Step 1389 0 visits [72.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0]  episode_count: 3603 q_vals: [-6.92, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -9.976]
Step 1390 3 visits [72.0, 1000.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0]  episode_count: 3606 q_vals: [-6.92, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -9.976]
Step 1391 2 visits [72.0, 1000.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0]  episode_count: 3607 q_vals: [-6.92, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -9.976]
{"total_number_of_episodes": 3612, "number_of_timesteps": 62362, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1392 7 visits [72.0, 1000.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 5.0]  episode_count: 3612 q_vals: [-6.92, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -9.976]
Step 1393 4 visits [72.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 5.0]  episode_count: 3613 q_vals: [-6.92, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -8.75, -9.976]
Step 1394 8 visits [72.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 5.0]  episode_count: 3615 q_vals: [-6.92, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -4.375, -9.976]
{"total_number_of_episodes": 3622, "number_of_timesteps": 62525, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 1395 8 visits [72.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3622 q_vals: [-6.92, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1396 0 visits [73.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3623 q_vals: [-6.945, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1397 0 visits [74.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3623 q_vals: [-6.944, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1398 0 visits [75.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3627 q_vals: [-6.968, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1399 0 visits [76.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3631 q_vals: [-6.992, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
{"total_number_of_episodes": 3633, "number_of_timesteps": 62740, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1400 0 visits [77.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3633 q_vals: [-6.901, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1401 0 visits [78.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3636 q_vals: [-6.925, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1402 0 visits [79.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3639 q_vals: [-6.837, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1403 0 visits [80.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3640 q_vals: [-6.861, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
{"total_number_of_episodes": 3645, "number_of_timesteps": 62929, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1404 0 visits [81.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3645 q_vals: [-6.884, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1405 0 visits [82.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3648 q_vals: [-6.895, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1406 0 visits [83.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3648 q_vals: [-6.812, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1407 0 visits [84.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3650 q_vals: [-6.731, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1408 0 visits [85.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3652 q_vals: [-6.755, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
{"total_number_of_episodes": 3656, "number_of_timesteps": 63128, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1409 0 visits [86.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3656 q_vals: [-6.676, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1410 0 visits [87.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3657 q_vals: [-6.7, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1411 0 visits [88.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3660 q_vals: [-6.624, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1412 0 visits [89.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3663 q_vals: [-6.648, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
{"total_number_of_episodes": 3666, "number_of_timesteps": 63317, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1413 0 visits [90.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3666 q_vals: [-6.671, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1414 0 visits [91.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3668 q_vals: [-6.694, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1415 0 visits [92.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3671 q_vals: [-6.716, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1416 0 visits [93.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3674 q_vals: [-6.644, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
{"total_number_of_episodes": 3676, "number_of_timesteps": 63479, "per_episode_reward": 13.05, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1417 0 visits [94.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3676 q_vals: [-6.666, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1418 0 visits [95.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3678 q_vals: [-6.688, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1419 0 visits [96.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3682 q_vals: [-6.71, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1420 0 visits [97.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3682 q_vals: [-6.866, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1421 0 visits [98.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3684 q_vals: [-6.885, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
{"total_number_of_episodes": 3687, "number_of_timesteps": 63682, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 1422 0 visits [99.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3687 q_vals: [-6.904, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1423 0 visits [100.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3687 q_vals: [-7.054, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1424 0 visits [101.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3687 q_vals: [-7.201, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1425 0 visits [102.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3690 q_vals: [-7.216, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1426 0 visits [103.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3692 q_vals: [-7.231, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1427 0 visits [104.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3694 q_vals: [-7.245, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
{"total_number_of_episodes": 3697, "number_of_timesteps": 63951, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 1428 0 visits [105.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3697 q_vals: [-7.26, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1429 0 visits [106.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3698 q_vals: [-7.274, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1430 0 visits [107.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3700 q_vals: [-7.288, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1431 0 visits [108.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3702 q_vals: [-7.22, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1432 0 visits [109.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3706 q_vals: [-7.355, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
{"total_number_of_episodes": 3707, "number_of_timesteps": 64207, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1433 0 visits [110.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3707 q_vals: [-7.367, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1434 0 visits [111.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3708 q_vals: [-7.373, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1435 0 visits [112.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3710 q_vals: [-7.386, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1436 0 visits [113.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3714 q_vals: [-7.32, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1437 0 visits [114.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3715 q_vals: [-7.333, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
{"total_number_of_episodes": 3717, "number_of_timesteps": 64414, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 1438 0 visits [115.0, 1000.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3717 q_vals: [-7.459, -inf, -8.75, -8.75, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1439 3 visits [115.0, 1000.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3718 q_vals: [-7.459, -inf, -8.75, -5.833, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1440 3 visits [115.0, 1000.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3722 q_vals: [-7.459, -inf, -8.75, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1441 2 visits [115.0, 1000.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3726 q_vals: [-7.459, -inf, -5.833, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1442 2 visits [115.0, 1000.0, 4.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3726 q_vals: [-7.459, -inf, -6.562, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
{"total_number_of_episodes": 3730, "number_of_timesteps": 64679, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1443 2 visits [115.0, 1000.0, 5.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3730 q_vals: [-7.459, -inf, -7.0, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1444 2 visits [115.0, 1000.0, 6.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3735 q_vals: [-7.459, -inf, -7.292, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1445 2 visits [115.0, 1000.0, 7.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3736 q_vals: [-7.459, -inf, -6.25, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1446 2 visits [115.0, 1000.0, 8.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3737 q_vals: [-7.459, -inf, -6.562, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
{"total_number_of_episodes": 3742, "number_of_timesteps": 64863, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1447 2 visits [115.0, 1000.0, 9.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3742 q_vals: [-7.459, -inf, -5.833, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1448 2 visits [115.0, 1000.0, 10.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3743 q_vals: [-7.459, -inf, -6.125, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1449 2 visits [115.0, 1000.0, 11.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3744 q_vals: [-7.459, -inf, -6.364, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1450 2 visits [115.0, 1000.0, 12.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3747 q_vals: [-7.459, -inf, -7.656, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1451 2 visits [115.0, 1000.0, 13.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3751 q_vals: [-7.459, -inf, -7.067, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
{"total_number_of_episodes": 3752, "number_of_timesteps": 65065, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1452 2 visits [115.0, 1000.0, 14.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3752 q_vals: [-7.459, -inf, -7.187, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1453 2 visits [115.0, 1000.0, 15.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3756 q_vals: [-7.459, -inf, -6.708, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1454 2 visits [115.0, 1000.0, 16.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3759 q_vals: [-7.459, -inf, -6.289, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1455 2 visits [115.0, 1000.0, 17.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3760 q_vals: [-7.459, -inf, -7.206, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
Step 1456 2 visits [115.0, 1000.0, 18.0, 4.0, 2.0, 1.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 3761 q_vals: [-7.459, -inf, -8.021, -9.844, -8.75, -21.875, -21.875, -8.75, -10.208, -9.976]
{"total_number_of_episodes": 3765, "number_of_timesteps": 65266, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1457 7 visits [115.0, 1000.0, 18.0, 4.0, 2.0, 1.0, 1.0, 3.0, 3.0, 5.0]  episode_count: 3765 q_vals: [-7.459, -inf, -8.021, -9.844, -8.75, -21.875, -21.875, -5.833, -10.208, -9.976]
Step 1458 7 visits [115.0, 1000.0, 18.0, 4.0, 2.0, 1.0, 1.0, 4.0, 3.0, 5.0]  episode_count: 3768 q_vals: [-7.459, -inf, -8.021, -9.844, -8.75, -21.875, -21.875, -6.562, -10.208, -9.976]
Step 1459 7 visits [115.0, 1000.0, 18.0, 4.0, 2.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3769 q_vals: [-7.459, -inf, -8.021, -9.844, -8.75, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1460 4 visits [115.0, 1000.0, 18.0, 4.0, 3.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3771 q_vals: [-7.459, -inf, -8.021, -9.844, -5.833, -21.875, -21.875, -9.625, -10.208, -9.976]
[115.0, 1000.0, 18.0, 4.0, 4.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3773 q_vals: [-7.459, -inf, -8.021, -9.844, -4.375, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1462 4 visits [115.0, 1000.0, 18.0, 4.0, 5.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3774 q_vals: [-7.459, -inf, -8.021, -9.844, -5.25, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3777, "number_of_timesteps": 65486, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1463 4 visits [115.0, 1000.0, 18.0, 4.0, 6.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3777 q_vals: [-7.459, -inf, -8.021, -9.844, -4.375, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1464 4 visits [115.0, 1000.0, 18.0, 4.0, 7.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3780 q_vals: [-7.459, -inf, -8.021, -9.844, -5.0, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1465 4 visits [115.0, 1000.0, 18.0, 4.0, 8.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3782 q_vals: [-7.459, -inf, -8.021, -9.844, -4.375, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1466 4 visits [115.0, 1000.0, 18.0, 4.0, 9.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3784 q_vals: [-7.459, -inf, -8.021, -9.844, -4.861, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1467 4 visits [115.0, 1000.0, 18.0, 4.0, 10.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3785 q_vals: [-7.459, -inf, -8.021, -9.844, -5.25, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3790, "number_of_timesteps": 65792, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1468 4 visits [115.0, 1000.0, 18.0, 4.0, 11.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3790 q_vals: [-7.459, -inf, -8.021, -9.844, -6.761, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1469 4 visits [115.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3792 q_vals: [-7.459, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1470 0 visits [116.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3795 q_vals: [-7.395, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1471 0 visits [117.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3799 q_vals: [-7.407, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3801, "number_of_timesteps": 65974, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1472 0 visits [118.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3801 q_vals: [-7.418, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1473 0 visits [119.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3805 q_vals: [-7.356, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1474 0 visits [120.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3807 q_vals: [-7.367, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1475 0 visits [121.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3809 q_vals: [-7.379, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3814, "number_of_timesteps": 66174, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1476 0 visits [122.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3814 q_vals: [-7.318, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1477 0 visits [123.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3816 q_vals: [-7.33, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1478 0 visits [124.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3816 q_vals: [-7.447, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1479 0 visits [125.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3819 q_vals: [-7.458, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1480 0 visits [126.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3820 q_vals: [-7.468, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3824, "number_of_timesteps": 66362, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1481 0 visits [127.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3824 q_vals: [-7.478, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1482 0 visits [128.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3826 q_vals: [-7.488, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1483 0 visits [129.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3830 q_vals: [-7.498, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1484 0 visits [130.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3831 q_vals: [-7.44, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1485 0 visits [131.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3833 q_vals: [-7.383, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1486 0 visits [132.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3833 q_vals: [-7.394, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3836, "number_of_timesteps": 66600, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1487 0 visits [133.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3836 q_vals: [-7.404, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1488 0 visits [134.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3842 q_vals: [-7.349, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1489 0 visits [135.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3843 q_vals: [-7.359, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3847, "number_of_timesteps": 66801, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1490 0 visits [136.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3847 q_vals: [-7.369, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1491 0 visits [137.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3850 q_vals: [-7.379, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1492 0 visits [138.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3851 q_vals: [-7.326, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1493 0 visits [139.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3854 q_vals: [-7.336, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3859, "number_of_timesteps": 66987, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1494 0 visits [140.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3859 q_vals: [-7.284, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1495 0 visits [141.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3860 q_vals: [-7.294, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1496 0 visits [142.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3862 q_vals: [-7.243, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1497 0 visits [143.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3865 q_vals: [-7.192, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3870, "number_of_timesteps": 67164, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1498 0 visits [144.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3870 q_vals: [-7.203, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1499 0 visits [145.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3872 q_vals: [-7.153, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1500 0 visits [146.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3875 q_vals: [-7.104, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3881, "number_of_timesteps": 67315, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1501 0 visits [147.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3881 q_vals: [-7.056, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1502 0 visits [148.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3882 q_vals: [-7.067, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1503 0 visits [149.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3884 q_vals: [-7.167, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1504 0 visits [150.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3888 q_vals: [-7.119, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3892, "number_of_timesteps": 67469, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1505 0 visits [151.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3892 q_vals: [-7.13, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1506 0 visits [152.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3892 q_vals: [-7.083, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1507 0 visits [153.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3897 q_vals: [-7.094, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1508 0 visits [154.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3900 q_vals: [-7.048, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3903, "number_of_timesteps": 67623, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1509 0 visits [155.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3903 q_vals: [-7.059, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1510 0 visits [156.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3906 q_vals: [-7.069, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1511 0 visits [157.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3909 q_vals: [-7.024, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1512 0 visits [158.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3911 q_vals: [-7.035, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3915, "number_of_timesteps": 67807, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1513 0 visits [159.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3915 q_vals: [-7.046, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1514 0 visits [160.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3918 q_vals: [-7.002, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1515 0 visits [161.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3920 q_vals: [-7.013, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1516 0 visits [162.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3921 q_vals: [-7.024, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3925, "number_of_timesteps": 67962, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1517 0 visits [163.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3925 q_vals: [-7.034, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1518 0 visits [164.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3931 q_vals: [-7.045, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1519 0 visits [165.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3932 q_vals: [-7.055, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1520 0 visits [166.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3934 q_vals: [-7.013, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3941, "number_of_timesteps": 68178, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
[-7.023, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1522 0 visits [168.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3944 q_vals: [-7.033, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1523 0 visits [169.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3946 q_vals: [-7.043, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1524 0 visits [170.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3950 q_vals: [-7.053, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3954, "number_of_timesteps": 68344, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1525 0 visits [171.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3954 q_vals: [-7.063, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1526 0 visits [172.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3956 q_vals: [-7.073, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1527 0 visits [173.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3960 q_vals: [-7.083, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1528 0 visits [174.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3961 q_vals: [-7.092, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3967, "number_of_timesteps": 68521, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1529 0 visits [175.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3967 q_vals: [-7.102, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1530 0 visits [176.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3970 q_vals: [-7.186, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1531 0 visits [177.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3974 q_vals: [-7.195, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1532 0 visits [178.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3976 q_vals: [-7.277, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3979, "number_of_timesteps": 68674, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1533 0 visits [179.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3979 q_vals: [-7.285, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1534 0 visits [180.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3981 q_vals: [-7.293, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1535 0 visits [181.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3985 q_vals: [-7.302, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 3990, "number_of_timesteps": 68857, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1536 0 visits [182.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3990 q_vals: [-7.31, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1537 0 visits [183.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3991 q_vals: [-7.317, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1538 0 visits [184.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3996 q_vals: [-7.396, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1539 0 visits [185.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 3999 q_vals: [-7.475, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4005, "number_of_timesteps": 69037, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1540 0 visits [186.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4005 q_vals: [-7.482, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1541 0 visits [187.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4008 q_vals: [-7.488, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1542 0 visits [188.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4012 q_vals: [-7.495, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4016, "number_of_timesteps": 69160, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1543 0 visits [189.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4016 q_vals: [-7.502, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1544 0 visits [190.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4019 q_vals: [-7.508, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1545 0 visits [191.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4024 q_vals: [-7.469, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4028, "number_of_timesteps": 69289, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1546 0 visits [192.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4028 q_vals: [-7.476, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1547 0 visits [193.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4032 q_vals: [-7.482, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1548 0 visits [194.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4033 q_vals: [-7.444, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1549 0 visits [195.0, 1000.0, 18.0, 4.0, 12.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4037 q_vals: [-7.518, -inf, -8.021, -9.844, -8.021, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4042, "number_of_timesteps": 69458, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1550 4 visits [195.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4042 q_vals: [-7.518, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1551 0 visits [196.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4045 q_vals: [-7.524, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1552 0 visits [197.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4049 q_vals: [-7.486, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4052, "number_of_timesteps": 69584, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1553 0 visits [198.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4052 q_vals: [-7.448, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1554 0 visits [199.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4058 q_vals: [-7.455, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1555 0 visits [200.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4060 q_vals: [-7.461, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4063, "number_of_timesteps": 69711, "per_episode_reward": 12.95, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
Step 1556 0 visits [201.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4063 q_vals: [-7.467, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1557 0 visits [202.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4067 q_vals: [-7.474, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1558 0 visits [203.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4070 q_vals: [-7.48, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4073, "number_of_timesteps": 69836, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
Step 1559 0 visits [204.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4073 q_vals: [-7.443, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1560 0 visits [205.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4075 q_vals: [-7.45, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1561 0 visits [206.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4081 q_vals: [-7.456, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4084, "number_of_timesteps": 69977, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
Step 1562 0 visits [207.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4084 q_vals: [-7.42, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1563 0 visits [208.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4086 q_vals: [-7.426, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1564 0 visits [209.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4090 q_vals: [-7.433, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4094, "number_of_timesteps": 70102, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
Step 1565 0 visits [210.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4094 q_vals: [-7.439, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1566 0 visits [211.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4096 q_vals: [-7.445, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1567 0 visits [212.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4097 q_vals: [-7.451, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1568 0 visits [213.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4101 q_vals: [-7.458, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1569 0 visits [214.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4101 q_vals: [-7.464, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4105, "number_of_timesteps": 70287, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
Step 1570 0 visits [215.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4105 q_vals: [-7.47, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1571 0 visits [216.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4106 q_vals: [-7.475, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1572 0 visits [217.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4108 q_vals: [-7.481, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1573 0 visits [218.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4110 q_vals: [-7.487, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1574 0 visits [219.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4112 q_vals: [-7.493, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4115, "number_of_timesteps": 70494, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
Step 1575 0 visits [220.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4115 q_vals: [-7.459, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1576 0 visits [221.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4115 q_vals: [-7.465, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1577 0 visits [222.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4117 q_vals: [-7.471, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1578 0 visits [223.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4121 q_vals: [-7.476, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1579 0 visits [224.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4123 q_vals: [-7.482, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4125, "number_of_timesteps": 70744, "per_episode_reward": 12.95, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
Step 1580 0 visits [225.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4125 q_vals: [-7.488, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1581 0 visits [226.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4128 q_vals: [-7.493, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1582 0 visits [227.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4131 q_vals: [-7.499, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1583 0 visits [228.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4133 q_vals: [-7.504, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1584 0 visits [229.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4134 q_vals: [-7.471, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4138, "number_of_timesteps": 70969, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
Step 1585 0 visits [230.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4138 q_vals: [-7.477, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1586 0 visits [231.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4139 q_vals: [-7.482, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1587 0 visits [232.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4140 q_vals: [-7.488, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1588 0 visits [233.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4143 q_vals: [-7.456, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1589 0 visits [234.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4146 q_vals: [-7.461, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1590 0 visits [235.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4146 q_vals: [-7.467, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4150, "number_of_timesteps": 71236, "per_episode_reward": 12.95, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 1591 0 visits [236.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4150 q_vals: [-7.472, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1592 0 visits [237.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4151 q_vals: [-7.478, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1593 0 visits [238.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4154 q_vals: [-7.483, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1594 0 visits [239.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4154 q_vals: [-7.488, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1595 0 visits [240.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4158 q_vals: [-7.494, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4160, "number_of_timesteps": 71472, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1596 0 visits [241.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4160 q_vals: [-7.462, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1597 0 visits [242.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4161 q_vals: [-7.522, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1598 0 visits [243.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4162 q_vals: [-7.527, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1599 0 visits [244.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4164 q_vals: [-7.496, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1600 0 visits [245.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4165 q_vals: [-7.555, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4170, "number_of_timesteps": 71715, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1601 0 visits [246.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4170 q_vals: [-7.524, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1602 0 visits [247.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4172 q_vals: [-7.529, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1603 0 visits [248.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4173 q_vals: [-7.534, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1604 0 visits [249.0, 1000.0, 18.0, 4.0, 13.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4175 q_vals: [-7.592, -inf, -8.021, -9.844, -8.077, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1605 4 visits [249.0, 1000.0, 18.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4178 q_vals: [-7.592, -inf, -8.021, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4180, "number_of_timesteps": 71908, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1606 0 visits [250.0, 1000.0, 18.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4180 q_vals: [-7.596, -inf, -8.021, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1607 0 visits [251.0, 1000.0, 18.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4182 q_vals: [-7.601, -inf, -8.021, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1608 0 visits [252.0, 1000.0, 18.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4185 q_vals: [-7.605, -inf, -8.021, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1609 0 visits [253.0, 1000.0, 18.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4186 q_vals: [-7.61, -inf, -8.021, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1610 2 visits [253.0, 1000.0, 19.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4188 q_vals: [-7.61, -inf, -8.059, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4191, "number_of_timesteps": 72143, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1611 0 visits [254.0, 1000.0, 19.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4191 q_vals: [-7.614, -inf, -8.059, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1612 0 visits [255.0, 1000.0, 19.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4194 q_vals: [-7.619, -inf, -8.059, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1613 0 visits [256.0, 1000.0, 19.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4196 q_vals: [-7.623, -inf, -8.059, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1614 0 visits [257.0, 1000.0, 19.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4197 q_vals: [-7.594, -inf, -8.059, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1615 0 visits [258.0, 1000.0, 19.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4199 q_vals: [-7.598, -inf, -8.059, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4202, "number_of_timesteps": 72350, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1616 0 visits [259.0, 1000.0, 19.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4202 q_vals: [-7.603, -inf, -8.059, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1617 0 visits [260.0, 1000.0, 19.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4205 q_vals: [-7.607, -inf, -8.059, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1618 0 visits [261.0, 1000.0, 19.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4205 q_vals: [-7.611, -inf, -8.059, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1619 0 visits [262.0, 1000.0, 19.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4206 q_vals: [-7.616, -inf, -8.059, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1620 0 visits [263.0, 1000.0, 19.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4207 q_vals: [-7.62, -inf, -8.059, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1621 0 visits [264.0, 1000.0, 19.0, 4.0, 14.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4209 q_vals: [-7.674, -inf, -8.059, -9.844, -8.125, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1622 4 visits [264.0, 1000.0, 19.0, 4.0, 15.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4210 q_vals: [-7.674, -inf, -8.059, -9.844, -7.583, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1623 4 visits [264.0, 1000.0, 19.0, 4.0, 16.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4211 q_vals: [-7.674, -inf, -8.059, -9.844, -7.656, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4212, "number_of_timesteps": 72618, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1624 4 visits [264.0, 1000.0, 19.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4212 q_vals: [-7.674, -inf, -8.059, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1625 2 visits [264.0, 1000.0, 20.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4214 q_vals: [-7.674, -inf, -8.094, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1626 0 visits [265.0, 1000.0, 20.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4217 q_vals: [-7.678, -inf, -8.094, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1627 0 visits [266.0, 1000.0, 20.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4219 q_vals: [-7.682, -inf, -8.094, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4222, "number_of_timesteps": 72888, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1628 0 visits [267.0, 1000.0, 20.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4222 q_vals: [-7.686, -inf, -8.094, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1629 0 visits [268.0, 1000.0, 20.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4225 q_vals: [-7.739, -inf, -8.094, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1630 2 visits [268.0, 1000.0, 21.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4227 q_vals: [-7.739, -inf, -7.708, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1631 2 visits [268.0, 1000.0, 22.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4230 q_vals: [-7.739, -inf, -7.358, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4232, "number_of_timesteps": 73119, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1632 2 visits [268.0, 1000.0, 23.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4232 q_vals: [-7.739, -inf, -7.418, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1633 2 visits [268.0, 1000.0, 24.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4233 q_vals: [-7.739, -inf, -7.474, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1634 2 visits [268.0, 1000.0, 25.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4235 q_vals: [-7.739, -inf, -7.525, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1635 2 visits [268.0, 1000.0, 26.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4236 q_vals: [-7.739, -inf, -7.236, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1636 2 visits [268.0, 1000.0, 27.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4238 q_vals: [-7.739, -inf, -7.292, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1637 2 visits [268.0, 1000.0, 28.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4239 q_vals: [-7.739, -inf, -7.344, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4244, "number_of_timesteps": 73383, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1638 2 visits [268.0, 1000.0, 29.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4244 q_vals: [-7.739, -inf, -7.392, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1639 2 visits [268.0, 1000.0, 30.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4246 q_vals: [-7.739, -inf, -7.146, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1640 2 visits [268.0, 1000.0, 31.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4246 q_vals: [-7.739, -inf, -7.198, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1641 2 visits [268.0, 1000.0, 32.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4251 q_vals: [-7.739, -inf, -7.246, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1642 2 visits [268.0, 1000.0, 33.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4253 q_vals: [-7.739, -inf, -7.689, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1643 2 visits [268.0, 1000.0, 34.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4253 q_vals: [-7.739, -inf, -7.721, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4255, "number_of_timesteps": 73572, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1644 2 visits [268.0, 1000.0, 35.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4255 q_vals: [-7.739, -inf, -7.75, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1645 2 visits [268.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4259 q_vals: [-7.739, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1646 0 visits [269.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4260 q_vals: [-7.71, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1647 0 visits [270.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4262 q_vals: [-7.714, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1648 0 visits [271.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4264 q_vals: [-7.718, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4268, "number_of_timesteps": 73903, "per_episode_reward": 13.05, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1649 0 visits [272.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4268 q_vals: [-7.722, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1650 0 visits [273.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4270 q_vals: [-7.726, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1651 0 visits [274.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4271 q_vals: [-7.729, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1652 0 visits [275.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4274 q_vals: [-7.733, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1653 0 visits [276.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4276 q_vals: [-7.737, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1654 0 visits [277.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4277 q_vals: [-7.74, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4280, "number_of_timesteps": 74135, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 1655 0 visits [278.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4280 q_vals: [-7.744, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1656 0 visits [279.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4282 q_vals: [-7.716, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1657 0 visits [280.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4283 q_vals: [-7.72, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1658 0 visits [281.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4284 q_vals: [-7.692, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1659 0 visits [282.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4287 q_vals: [-7.665, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1660 0 visits [283.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4289 q_vals: [-7.638, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4291, "number_of_timesteps": 74380, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1661 0 visits [284.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4291 q_vals: [-7.642, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1662 0 visits [285.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4295 q_vals: [-7.615, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1663 0 visits [286.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4296 q_vals: [-7.589, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1664 0 visits [287.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4298 q_vals: [-7.593, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4302, "number_of_timesteps": 74635, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1665 0 visits [288.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4302 q_vals: [-7.566, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1666 0 visits [289.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4304 q_vals: [-7.57, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1667 0 visits [290.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4307 q_vals: [-7.544, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1668 0 visits [291.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4309 q_vals: [-7.518, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4312, "number_of_timesteps": 74800, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1669 0 visits [292.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4312 q_vals: [-7.523, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1670 0 visits [293.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4313 q_vals: [-7.527, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1671 0 visits [294.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4318 q_vals: [-7.531, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1672 0 visits [295.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4319 q_vals: [-7.535, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1673 0 visits [296.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4320 q_vals: [-7.539, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4323, "number_of_timesteps": 75008, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1674 0 visits [297.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4323 q_vals: [-7.543, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1675 0 visits [298.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4323 q_vals: [-7.518, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1676 0 visits [299.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4325 q_vals: [-7.522, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1677 0 visits [300.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4326 q_vals: [-7.526, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1678 0 visits [301.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4329 q_vals: [-7.501, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1679 0 visits [302.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4329 q_vals: [-7.476, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1680 0 visits [303.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4332 q_vals: [-7.524, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4335, "number_of_timesteps": 75316, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1681 0 visits [304.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4335 q_vals: [-7.528, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1682 0 visits [305.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4336 q_vals: [-7.532, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1683 0 visits [306.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4337 q_vals: [-7.536, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1684 0 visits [307.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4340 q_vals: [-7.583, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1685 0 visits [308.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4342 q_vals: [-7.586, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1686 0 visits [309.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4344 q_vals: [-7.562, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4348, "number_of_timesteps": 75610, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1687 0 visits [310.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4348 q_vals: [-7.566, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1688 0 visits [311.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4350 q_vals: [-7.569, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1689 0 visits [312.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4353 q_vals: [-7.573, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1690 0 visits [313.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4357 q_vals: [-7.573, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4359, "number_of_timesteps": 75806, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1691 0 visits [314.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4359 q_vals: [-7.549, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1692 0 visits [315.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4364 q_vals: [-7.553, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1693 0 visits [316.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4366 q_vals: [-7.557, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4369, "number_of_timesteps": 75937, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1694 0 visits [317.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4369 q_vals: [-7.533, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1695 0 visits [318.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4374 q_vals: [-7.556, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1696 0 visits [319.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4376 q_vals: [-7.56, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4379, "number_of_timesteps": 76057, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1697 0 visits [320.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4379 q_vals: [-7.563, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1698 0 visits [321.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4383 q_vals: [-7.567, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1699 0 visits [322.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4386 q_vals: [-7.544, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4390, "number_of_timesteps": 76193, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1700 0 visits [323.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4390 q_vals: [-7.588, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1701 0 visits [324.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4393 q_vals: [-7.57, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1702 0 visits [325.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4396 q_vals: [-7.547, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4400, "number_of_timesteps": 76313, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1703 0 visits [326.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4400 q_vals: [-7.524, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1704 0 visits [327.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4403 q_vals: [-7.528, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1705 0 visits [328.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4406 q_vals: [-7.531, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1706 0 visits [329.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4408 q_vals: [-7.535, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4411, "number_of_timesteps": 76467, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1707 0 visits [330.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4411 q_vals: [-7.539, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1708 0 visits [331.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4415 q_vals: [-7.542, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1709 0 visits [332.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4419 q_vals: [-7.579, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4422, "number_of_timesteps": 76632, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1710 0 visits [333.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4422 q_vals: [-7.582, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1711 0 visits [334.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4422 q_vals: [-7.586, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1712 0 visits [335.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4425 q_vals: [-7.629, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1713 0 visits [336.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4431 q_vals: [-7.632, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4432, "number_of_timesteps": 76800, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1714 0 visits [337.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4432 q_vals: [-7.609, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1715 0 visits [338.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4434 q_vals: [-7.608, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1716 0 visits [339.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4441 q_vals: [-7.65, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4442, "number_of_timesteps": 76933, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1717 0 visits [340.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4442 q_vals: [-7.654, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1718 0 visits [341.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4446 q_vals: [-7.695, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1719 0 visits [342.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4448 q_vals: [-7.688, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4453, "number_of_timesteps": 77056, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1720 0 visits [343.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4453 q_vals: [-7.691, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1721 0 visits [344.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4457 q_vals: [-7.709, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1722 0 visits [345.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4459 q_vals: [-7.712, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1723 0 visits [346.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4462 q_vals: [-7.69, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4467, "number_of_timesteps": 77247, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1724 0 visits [347.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4467 q_vals: [-7.672, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1725 0 visits [348.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4469 q_vals: [-7.675, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1726 0 visits [349.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4471 q_vals: [-7.678, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1727 0 visits [350.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4476 q_vals: [-7.656, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4478, "number_of_timesteps": 77392, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1728 0 visits [351.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4478 q_vals: [-7.66, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1729 0 visits [352.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4481 q_vals: [-7.654, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1730 0 visits [353.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4483 q_vals: [-7.632, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1731 0 visits [354.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4487 q_vals: [-7.635, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4489, "number_of_timesteps": 77570, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1732 0 visits [355.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4489 q_vals: [-7.638, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1733 0 visits [356.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4494 q_vals: [-7.641, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1734 0 visits [357.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4496 q_vals: [-7.644, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4499, "number_of_timesteps": 77721, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1735 0 visits [358.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4499 q_vals: [-7.684, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1736 0 visits [359.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4503 q_vals: [-7.718, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1737 0 visits [360.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4503 q_vals: [-7.697, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1738 0 visits [361.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4503 q_vals: [-7.689, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1739 0 visits [362.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4507 q_vals: [-7.692, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4509, "number_of_timesteps": 77883, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1740 0 visits [363.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4509 q_vals: [-7.695, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1741 0 visits [364.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4510 q_vals: [-7.698, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1742 0 visits [365.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4512 q_vals: [-7.677, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1743 0 visits [366.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4517 q_vals: [-7.67, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4520, "number_of_timesteps": 78142, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1744 0 visits [367.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4520 q_vals: [-7.649, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1745 0 visits [368.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4521 q_vals: [-7.629, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1746 0 visits [369.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4523 q_vals: [-7.632, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1747 0 visits [370.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4524 q_vals: [-7.635, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1748 0 visits [371.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4527 q_vals: [-7.614, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4531, "number_of_timesteps": 78317, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1749 0 visits [372.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4531 q_vals: [-7.594, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1750 0 visits [373.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4531 q_vals: [-7.597, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1751 0 visits [374.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4534 q_vals: [-7.6, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1752 0 visits [375.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4535 q_vals: [-7.603, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1753 0 visits [376.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4538 q_vals: [-7.641, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4541, "number_of_timesteps": 78565, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 1754 0 visits [377.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4541 q_vals: [-7.636, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1755 0 visits [378.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4541 q_vals: [-7.639, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1756 0 visits [379.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4545 q_vals: [-7.619, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1757 0 visits [380.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4546 q_vals: [-7.622, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1758 0 visits [381.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4550 q_vals: [-7.625, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4551, "number_of_timesteps": 78763, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1759 0 visits [382.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4551 q_vals: [-7.663, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1760 0 visits [383.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4552 q_vals: [-7.665, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1761 0 visits [384.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4554 q_vals: [-7.668, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1762 0 visits [385.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4556 q_vals: [-7.705, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1763 0 visits [386.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4559 q_vals: [-7.685, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1764 0 visits [387.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4560 q_vals: [-7.665, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1765 0 visits [388.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4560 q_vals: [-7.668, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4561, "number_of_timesteps": 78990, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 1766 0 visits [389.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4561 q_vals: [-7.705, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1767 0 visits [390.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4563 q_vals: [-7.685, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1768 0 visits [391.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4563 q_vals: [-7.665, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1769 0 visits [392.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4565 q_vals: [-7.668, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1770 0 visits [393.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4569 q_vals: [-7.671, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4572, "number_of_timesteps": 79341, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 1771 0 visits [394.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4572 q_vals: [-7.673, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1772 0 visits [395.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4575 q_vals: [-7.654, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1773 0 visits [396.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4576 q_vals: [-7.635, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1774 0 visits [397.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4577 q_vals: [-7.615, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1775 0 visits [398.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4580 q_vals: [-7.618, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1776 0 visits [399.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4581 q_vals: [-7.621, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1777 0 visits [400.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4581 q_vals: [-7.624, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4584, "number_of_timesteps": 79576, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1778 0 visits [401.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4584 q_vals: [-7.627, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1779 0 visits [402.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4587 q_vals: [-7.63, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1780 0 visits [403.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4588 q_vals: [-7.632, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1781 0 visits [404.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4591 q_vals: [-7.635, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4594, "number_of_timesteps": 79828, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1782 0 visits [405.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4594 q_vals: [-7.638, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1783 0 visits [406.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4597 q_vals: [-7.641, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1784 0 visits [407.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4599 q_vals: [-7.643, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1785 0 visits [408.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4602 q_vals: [-7.625, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4606, "number_of_timesteps": 80033, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1786 0 visits [409.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4606 q_vals: [-7.627, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1787 0 visits [410.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4608 q_vals: [-7.63, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1788 0 visits [411.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4611 q_vals: [-7.633, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1789 0 visits [412.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4613 q_vals: [-7.636, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
4614 q_vals: [-7.638, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4619, "number_of_timesteps": 80243, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1791 0 visits [414.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4619 q_vals: [-7.62, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1792 0 visits [415.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4622 q_vals: [-7.601, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1793 0 visits [416.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4625 q_vals: [-7.604, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4629, "number_of_timesteps": 80395, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1794 0 visits [417.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4629 q_vals: [-7.607, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1795 0 visits [418.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4633 q_vals: [-7.61, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1796 0 visits [419.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4635 q_vals: [-7.612, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4640, "number_of_timesteps": 80528, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 1797 0 visits [420.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4640 q_vals: [-7.615, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1798 0 visits [421.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4642 q_vals: [-7.618, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1799 0 visits [422.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4647 q_vals: [-7.62, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4650, "number_of_timesteps": 80649, "per_episode_reward": 13.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 1800 0 visits [423.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4650 q_vals: [-7.623, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1801 0 visits [424.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4654 q_vals: [-7.626, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1802 0 visits [425.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4656 q_vals: [-7.628, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1803 0 visits [426.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4659 q_vals: [-7.631, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4663, "number_of_timesteps": 80830, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1804 0 visits [427.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4663 q_vals: [-7.634, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1805 0 visits [428.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4664 q_vals: [-7.616, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1806 0 visits [429.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4668 q_vals: [-7.649, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1807 0 visits [430.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4672 q_vals: [-7.652, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1808 0 visits [431.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4672 q_vals: [-7.654, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4674, "number_of_timesteps": 80995, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1809 0 visits [432.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4674 q_vals: [-7.657, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1810 0 visits [433.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4678 q_vals: [-7.69, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1811 0 visits [434.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4681 q_vals: [-7.672, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4684, "number_of_timesteps": 81181, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1812 0 visits [435.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4684 q_vals: [-7.674, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1813 0 visits [436.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4687 q_vals: [-7.657, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1814 0 visits [437.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4691 q_vals: [-7.689, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4694, "number_of_timesteps": 81320, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1815 0 visits [438.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4694 q_vals: [-7.692, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1816 0 visits [439.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4695 q_vals: [-7.694, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1817 0 visits [440.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4699 q_vals: [-7.696, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4704, "number_of_timesteps": 81466, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
[441.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4704 q_vals: [-7.699, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1819 0 visits [442.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4704 q_vals: [-7.701, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1820 0 visits [443.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4707 q_vals: [-7.704, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1821 0 visits [444.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4713 q_vals: [-7.686, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4714, "number_of_timesteps": 81612, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1822 0 visits [445.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4714 q_vals: [-7.689, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1823 0 visits [446.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4717 q_vals: [-7.691, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1824 0 visits [447.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4719 q_vals: [-7.693, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1825 0 visits [448.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4722 q_vals: [-7.696, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1826 0 visits [449.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4722 q_vals: [-7.727, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4725, "number_of_timesteps": 81777, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1827 0 visits [450.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4725 q_vals: [-7.717, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1828 0 visits [451.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4726 q_vals: [-7.748, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1829 0 visits [452.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4728 q_vals: [-7.731, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1830 0 visits [453.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4731 q_vals: [-7.73, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1831 0 visits [454.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4733 q_vals: [-7.732, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1832 0 visits [455.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4733 q_vals: [-7.734, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4739, "number_of_timesteps": 82104, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1833 0 visits [456.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4739 q_vals: [-7.737, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1834 0 visits [457.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4741 q_vals: [-7.739, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1835 0 visits [458.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4741 q_vals: [-7.741, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1836 0 visits [459.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4743 q_vals: [-7.743, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1837 0 visits [460.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4745 q_vals: [-7.745, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1838 0 visits [461.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4748 q_vals: [-7.748, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4749, "number_of_timesteps": 82312, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1839 0 visits [462.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4749 q_vals: [-7.75, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1840 0 visits [463.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4751 q_vals: [-7.752, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1841 0 visits [464.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4754 q_vals: [-7.754, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1842 0 visits [465.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4755 q_vals: [-7.756, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4760, "number_of_timesteps": 82573, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1843 0 visits [466.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4760 q_vals: [-7.758, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1844 0 visits [467.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4760 q_vals: [-7.742, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1845 0 visits [468.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4762 q_vals: [-7.744, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1846 0 visits [469.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4764 q_vals: [-7.746, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1847 0 visits [470.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4766 q_vals: [-7.73, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1848 0 visits [471.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4769 q_vals: [-7.732, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4771, "number_of_timesteps": 82833, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1849 0 visits [472.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4771 q_vals: [-7.715, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1850 0 visits [473.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4774 q_vals: [-7.718, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1851 0 visits [474.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4776 q_vals: [-7.72, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1852 0 visits [475.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4777 q_vals: [-7.722, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4781, "number_of_timesteps": 83006, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1853 0 visits [476.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4781 q_vals: [-7.724, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1854 0 visits [477.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4782 q_vals: [-7.726, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1855 0 visits [478.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4785 q_vals: [-7.728, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1856 0 visits [479.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4787 q_vals: [-7.731, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1857 0 visits [480.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4787 q_vals: [-7.733, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1858 0 visits [481.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4788 q_vals: [-7.735, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4793, "number_of_timesteps": 83269, "per_episode_reward": 13.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1859 0 visits [482.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4793 q_vals: [-7.737, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1860 0 visits [483.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4795 q_vals: [-7.721, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1861 0 visits [484.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4797 q_vals: [-7.75, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1862 0 visits [485.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4799 q_vals: [-7.752, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4803, "number_of_timesteps": 83473, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1863 0 visits [486.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4803 q_vals: [-7.754, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1864 0 visits [487.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4803 q_vals: [-7.738, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1865 0 visits [488.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4805 q_vals: [-7.737, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1866 0 visits [489.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4805 q_vals: [-7.766, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1867 0 visits [490.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4809 q_vals: [-7.75, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1868 0 visits [491.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4812 q_vals: [-7.746, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4815, "number_of_timesteps": 83783, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1869 0 visits [492.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4815 q_vals: [-7.756, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1870 0 visits [493.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4816 q_vals: [-7.758, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1871 0 visits [494.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4819 q_vals: [-7.76, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1872 0 visits [495.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4819 q_vals: [-7.762, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1873 0 visits [496.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4821 q_vals: [-7.764, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1874 0 visits [497.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4824 q_vals: [-7.766, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4826, "number_of_timesteps": 84005, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1875 0 visits [498.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4826 q_vals: [-7.75, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1876 0 visits [499.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4828 q_vals: [-7.752, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1877 0 visits [500.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4829 q_vals: [-7.754, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1878 0 visits [501.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4832 q_vals: [-7.756, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
[-7.751, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1880 0 visits [503.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4835 q_vals: [-7.735, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4837, "number_of_timesteps": 84255, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1881 0 visits [504.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4837 q_vals: [-7.733, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1882 0 visits [505.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4839 q_vals: [-7.734, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1883 0 visits [506.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4840 q_vals: [-7.736, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1884 0 visits [507.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4844 q_vals: [-7.738, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1885 0 visits [508.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4846 q_vals: [-7.723, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4848, "number_of_timesteps": 84524, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1886 0 visits [509.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4848 q_vals: [-7.725, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1887 0 visits [510.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4849 q_vals: [-7.727, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1888 0 visits [511.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4852 q_vals: [-7.729, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1889 0 visits [512.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4857 q_vals: [-7.731, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4858, "number_of_timesteps": 84746, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1890 0 visits [513.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4858 q_vals: [-7.716, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1891 0 visits [514.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4861 q_vals: [-7.718, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1892 0 visits [515.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4866 q_vals: [-7.72, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4868, "number_of_timesteps": 84869, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1893 0 visits [516.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4868 q_vals: [-7.722, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1894 0 visits [517.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4872 q_vals: [-7.724, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1895 0 visits [518.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4877 q_vals: [-7.726, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1896 0 visits [519.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4877 q_vals: [-7.728, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4882, "number_of_timesteps": 85051, "per_episode_reward": 13.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1897 0 visits [520.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4882 q_vals: [-7.729, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1898 0 visits [521.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4887 q_vals: [-7.715, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1899 0 visits [522.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4888 q_vals: [-7.7, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4893, "number_of_timesteps": 85186, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1900 0 visits [523.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4893 q_vals: [-7.702, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1901 0 visits [524.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4897 q_vals: [-7.704, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1902 0 visits [525.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4901 q_vals: [-7.731, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4906, "number_of_timesteps": 85335, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1903 0 visits [526.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4906 q_vals: [-7.758, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1904 0 visits [527.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4907 q_vals: [-7.76, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1905 0 visits [528.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4914 q_vals: [-7.762, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4916, "number_of_timesteps": 85453, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1906 0 visits [529.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4916 q_vals: [-7.763, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1907 0 visits [530.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4921 q_vals: [-7.765, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1908 0 visits [531.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4925 q_vals: [-7.767, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4929, "number_of_timesteps": 85590, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1909 0 visits [532.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4929 q_vals: [-7.769, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1910 0 visits [533.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4932 q_vals: [-7.771, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1911 0 visits [534.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4936 q_vals: [-7.773, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4940, "number_of_timesteps": 85714, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1912 0 visits [535.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4940 q_vals: [-7.774, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1913 0 visits [536.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4945 q_vals: [-7.76, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1914 0 visits [537.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4946 q_vals: [-7.762, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4950, "number_of_timesteps": 85828, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1915 0 visits [538.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4950 q_vals: [-7.764, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1916 0 visits [539.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4956 q_vals: [-7.749, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1917 0 visits [540.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4959 q_vals: [-7.751, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4962, "number_of_timesteps": 85962, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1918 0 visits [541.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4962 q_vals: [-7.753, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1919 0 visits [542.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4967 q_vals: [-7.755, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1920 0 visits [543.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4971 q_vals: [-7.757, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4973, "number_of_timesteps": 86088, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1921 0 visits [544.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4973 q_vals: [-7.742, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1922 0 visits [545.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4978 q_vals: [-7.744, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1923 0 visits [546.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4982 q_vals: [-7.746, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4987, "number_of_timesteps": 86239, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 1924 0 visits [547.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4987 q_vals: [-7.772, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1925 0 visits [548.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4990 q_vals: [-7.774, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1926 0 visits [549.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4994 q_vals: [-7.775, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 4999, "number_of_timesteps": 86367, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1927 0 visits [550.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 4999 q_vals: [-7.761, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1928 0 visits [551.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5002 q_vals: [-7.747, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1929 0 visits [552.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5008 q_vals: [-7.733, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1930 0 visits [553.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5008 q_vals: [-7.735, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5012, "number_of_timesteps": 86513, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1931 0 visits [554.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5012 q_vals: [-7.737, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1932 0 visits [555.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5016 q_vals: [-7.739, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1933 0 visits [556.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5019 q_vals: [-7.74, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5023, "number_of_timesteps": 86646, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1934 0 visits [557.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5023 q_vals: [-7.742, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1935 0 visits [558.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5029 q_vals: [-7.728, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1936 0 visits [559.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5031 q_vals: [-7.73, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5036, "number_of_timesteps": 86796, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1937 0 visits [560.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5036 q_vals: [-7.732, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1938 0 visits [561.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5040 q_vals: [-7.734, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1939 0 visits [562.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5043 q_vals: [-7.72, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5049, "number_of_timesteps": 86935, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1940 0 visits [563.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5049 q_vals: [-7.722, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1941 0 visits [564.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5050 q_vals: [-7.747, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1942 0 visits [565.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5055 q_vals: [-7.749, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5059, "number_of_timesteps": 87049, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1943 0 visits [566.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5059 q_vals: [-7.751, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1944 0 visits [567.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5062 q_vals: [-7.775, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1945 0 visits [568.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5063 q_vals: [-7.777, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1946 0 visits [569.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5067 q_vals: [-7.779, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5073, "number_of_timesteps": 87235, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1947 0 visits [570.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5073 q_vals: [-7.781, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1948 0 visits [571.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5075 q_vals: [-7.782, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1949 0 visits [572.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5079 q_vals: [-7.784, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5083, "number_of_timesteps": 87352, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1950 0 visits [573.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5083 q_vals: [-7.786, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1951 0 visits [574.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5087 q_vals: [-7.772, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1952 0 visits [575.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5090 q_vals: [-7.774, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5094, "number_of_timesteps": 87480, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1953 0 visits [576.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5094 q_vals: [-7.776, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1954 0 visits [577.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5096 q_vals: [-7.777, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1955 0 visits [578.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5100 q_vals: [-7.764, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5105, "number_of_timesteps": 87618, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1956 0 visits [579.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5105 q_vals: [-7.765, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1957 0 visits [580.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5106 q_vals: [-7.767, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1958 0 visits [581.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5109 q_vals: [-7.769, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1959 0 visits [582.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5114 q_vals: [-7.771, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5115, "number_of_timesteps": 87759, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1960 0 visits [583.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5115 q_vals: [-7.772, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1961 0 visits [584.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5119 q_vals: [-7.774, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1962 0 visits [585.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5121 q_vals: [-7.761, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1963 0 visits [586.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5123 q_vals: [-7.747, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5125, "number_of_timesteps": 87892, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1964 0 visits [587.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5125 q_vals: [-7.771, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1965 0 visits [588.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5127 q_vals: [-7.758, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1966 0 visits [589.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5128 q_vals: [-7.76, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1967 0 visits [590.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5132 q_vals: [-7.762, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5136, "number_of_timesteps": 88141, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1968 0 visits [591.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5136 q_vals: [-7.748, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1969 0 visits [592.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5136 q_vals: [-7.75, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1970 0 visits [593.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5141 q_vals: [-7.752, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1971 0 visits [594.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5145 q_vals: [-7.739, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5147, "number_of_timesteps": 88302, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1972 0 visits [595.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5147 q_vals: [-7.74, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1973 0 visits [596.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5150 q_vals: [-7.742, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1974 0 visits [597.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5153 q_vals: [-7.729, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1975 0 visits [598.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5154 q_vals: [-7.731, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1976 0 visits [599.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5156 q_vals: [-7.718, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5160, "number_of_timesteps": 88518, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1977 0 visits [600.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5160 q_vals: [-7.72, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1978 0 visits [601.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5161 q_vals: [-7.721, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1979 0 visits [602.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5166 q_vals: [-7.723, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1980 0 visits [603.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5169 q_vals: [-7.725, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5170, "number_of_timesteps": 88696, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1981 0 visits [604.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5170 q_vals: [-7.727, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1982 0 visits [605.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5172 q_vals: [-7.714, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1983 0 visits [606.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5176 q_vals: [-7.715, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5180, "number_of_timesteps": 88872, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1984 0 visits [607.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5180 q_vals: [-7.717, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1985 0 visits [608.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5182 q_vals: [-7.719, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1986 0 visits [609.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5186 q_vals: [-7.721, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5190, "number_of_timesteps": 89001, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1987 0 visits [610.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5190 q_vals: [-7.744, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1988 0 visits [611.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5191 q_vals: [-7.745, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1989 0 visits [612.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5191 q_vals: [-7.747, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1990 0 visits [613.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5197 q_vals: [-7.749, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5200, "number_of_timesteps": 89175, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1991 0 visits [614.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5200 q_vals: [-7.772, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1992 0 visits [615.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5201 q_vals: [-7.773, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1993 0 visits [616.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5203 q_vals: [-7.775, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1994 0 visits [617.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5205 q_vals: [-7.776, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1995 0 visits [618.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5209 q_vals: [-7.799, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5212, "number_of_timesteps": 89370, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1996 0 visits [619.0, 1000.0, 36.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5212 q_vals: [-7.822, -inf, -8.142, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1997 2 visits [619.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5212 q_vals: [-7.822, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1998 0 visits [620.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5212 q_vals: [-7.822, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 1999 0 visits [621.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5216 q_vals: [-7.823, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2000 0 visits [622.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5219 q_vals: [-7.825, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2001 0 visits [623.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5219 q_vals: [-7.826, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2002 0 visits [624.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5220 q_vals: [-7.828, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5223, "number_of_timesteps": 89617, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2003 0 visits [625.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5223 q_vals: [-7.815, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2004 0 visits [626.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5226 q_vals: [-7.817, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2005 0 visits [627.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5226 q_vals: [-7.818, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2006 0 visits [628.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5228 q_vals: [-7.82, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2007 0 visits [629.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5230 q_vals: [-7.821, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2008 0 visits [630.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5232 q_vals: [-7.809, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5233, "number_of_timesteps": 89898, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2009 0 visits [631.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5233 q_vals: [-7.81, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2010 0 visits [632.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5236 q_vals: [-7.812, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2011 0 visits [633.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5240 q_vals: [-7.799, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2012 0 visits [634.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5240 q_vals: [-7.787, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5243, "number_of_timesteps": 90101, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2013 0 visits [635.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5243 q_vals: [-7.775, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2014 0 visits [636.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5247 q_vals: [-7.776, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2015 0 visits [637.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5249 q_vals: [-7.778, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2016 0 visits [638.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5250 q_vals: [-7.779, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2017 0 visits [639.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5251 q_vals: [-7.781, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5253, "number_of_timesteps": 90321, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2018 0 visits [640.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5253 q_vals: [-7.782, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2019 0 visits [641.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5254 q_vals: [-7.77, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2020 0 visits [642.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5257 q_vals: [-7.772, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2021 0 visits [643.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5258 q_vals: [-7.76, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2022 0 visits [644.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5262 q_vals: [-7.761, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5266, "number_of_timesteps": 90631, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2023 0 visits [645.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5266 q_vals: [-7.749, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2024 0 visits [646.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5267 q_vals: [-7.751, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2025 0 visits [647.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5270 q_vals: [-7.739, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2026 0 visits [648.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5275 q_vals: [-7.74, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5276, "number_of_timesteps": 90790, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2027 0 visits [649.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5276 q_vals: [-7.742, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2028 0 visits [650.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5278 q_vals: [-7.764, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2029 0 visits [651.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5279 q_vals: [-7.752, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2030 0 visits [652.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5281 q_vals: [-7.753, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2031 0 visits [653.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5284 q_vals: [-7.775, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2032 0 visits [654.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5285 q_vals: [-7.776, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5286, "number_of_timesteps": 90986, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2033 0 visits [655.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5286 q_vals: [-7.778, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2034 0 visits [656.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5290 q_vals: [-7.766, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2035 0 visits [657.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5293 q_vals: [-7.767, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2036 0 visits [658.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5295 q_vals: [-7.763, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5297, "number_of_timesteps": 91209, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2037 0 visits [659.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5297 q_vals: [-7.765, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2038 0 visits [660.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5300 q_vals: [-7.766, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2039 0 visits [661.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5302 q_vals: [-7.768, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2040 0 visits [662.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5303 q_vals: [-7.769, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2041 0 visits [663.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5305 q_vals: [-7.771, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5308, "number_of_timesteps": 91422, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2042 0 visits [664.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5308 q_vals: [-7.772, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2043 0 visits [665.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5310 q_vals: [-7.774, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2044 0 visits [666.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5312 q_vals: [-7.774, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2045 0 visits [667.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5313 q_vals: [-7.762, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2046 0 visits [668.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5314 q_vals: [-7.763, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5318, "number_of_timesteps": 91664, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2047 0 visits [669.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5318 q_vals: [-7.752, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2048 0 visits [670.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5322 q_vals: [-7.74, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2049 0 visits [671.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5322 q_vals: [-7.742, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2050 0 visits [672.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5325 q_vals: [-7.73, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2051 0 visits [673.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5327 q_vals: [-7.732, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2052 0 visits [674.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5327 q_vals: [-7.733, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5329, "number_of_timesteps": 91878, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2053 0 visits [675.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5329 q_vals: [-7.754, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2054 0 visits [676.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5331 q_vals: [-7.756, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2055 0 visits [677.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5331 q_vals: [-7.757, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2056 0 visits [678.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5334 q_vals: [-7.759, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2057 0 visits [679.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5337 q_vals: [-7.76, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5339, "number_of_timesteps": 92129, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2058 0 visits [680.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5339 q_vals: [-7.761, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2059 0 visits [681.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5341 q_vals: [-7.763, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2060 0 visits [682.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5343 q_vals: [-7.764, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2061 0 visits [683.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5345 q_vals: [-7.766, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2062 0 visits [684.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5347 q_vals: [-7.767, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5350, "number_of_timesteps": 92407, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2063 0 visits [685.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5350 q_vals: [-7.769, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2064 0 visits [686.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5352 q_vals: [-7.77, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2065 0 visits [687.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5355 q_vals: [-7.759, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2066 0 visits [688.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5356 q_vals: [-7.76, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2067 0 visits [689.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5357 q_vals: [-7.76, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2068 0 visits [690.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5359 q_vals: [-7.762, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5362, "number_of_timesteps": 92672, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 2069 0 visits [691.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5362 q_vals: [-7.751, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2070 0 visits [692.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5363 q_vals: [-7.752, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2071 0 visits [693.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5363 q_vals: [-7.741, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2072 0 visits [694.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5369 q_vals: [-7.737, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2073 0 visits [695.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5371 q_vals: [-7.738, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5373, "number_of_timesteps": 92926, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2074 0 visits [696.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5373 q_vals: [-7.74, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2075 0 visits [697.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5376 q_vals: [-7.741, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2076 0 visits [698.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5379 q_vals: [-7.742, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2077 0 visits [699.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5382 q_vals: [-7.744, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5384, "number_of_timesteps": 93115, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2078 0 visits [700.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5384 q_vals: [-7.733, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2079 0 visits [701.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5389 q_vals: [-7.734, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2080 0 visits [702.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5391 q_vals: [-7.736, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2081 0 visits [703.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5393 q_vals: [-7.737, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5399, "number_of_timesteps": 93302, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 2082 0 visits [704.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5399 q_vals: [-7.739, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2083 0 visits [705.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5403 q_vals: [-7.74, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2084 0 visits [706.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5405 q_vals: [-7.76, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5409, "number_of_timesteps": 93441, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2085 0 visits [707.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5409 q_vals: [-7.78, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2086 0 visits [708.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5413 q_vals: [-7.769, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
 2087 0 visits [709.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5415 q_vals: [-7.758, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5419, "number_of_timesteps": 93560, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2088 0 visits [710.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5419 q_vals: [-7.759, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2089 0 visits [711.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5424 q_vals: [-7.761, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2090 0 visits [712.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5426 q_vals: [-7.762, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5430, "number_of_timesteps": 93689, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2091 0 visits [713.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5430 q_vals: [-7.764, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2092 0 visits [714.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5434 q_vals: [-7.753, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2093 0 visits [715.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5437 q_vals: [-7.754, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5441, "number_of_timesteps": 93825, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2094 0 visits [716.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5441 q_vals: [-7.743, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2095 0 visits [717.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5444 q_vals: [-7.745, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2096 0 visits [718.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5448 q_vals: [-7.746, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5454, "number_of_timesteps": 93993, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2097 0 visits [719.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5454 q_vals: [-7.748, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2098 0 visits [720.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5455 q_vals: [-7.749, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2099 0 visits [721.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5456 q_vals: [-7.75, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2100 0 visits [722.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5460 q_vals: [-7.74, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5464, "number_of_timesteps": 94150, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 2101 0 visits [723.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5464 q_vals: [-7.741, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2102 0 visits [724.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5466 q_vals: [-7.742, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2103 0 visits [725.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5469 q_vals: [-7.732, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2104 0 visits [726.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5471 q_vals: [-7.733, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5474, "number_of_timesteps": 94301, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2105 0 visits [727.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5474 q_vals: [-7.722, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2106 0 visits [728.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5477 q_vals: [-7.724, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2107 0 visits [729.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5479 q_vals: [-7.725, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2108 0 visits [730.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5482 q_vals: [-7.715, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5485, "number_of_timesteps": 94468, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2109 0 visits [731.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5485 q_vals: [-7.716, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2110 0 visits [732.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5488 q_vals: [-7.718, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2111 0 visits [733.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5491 q_vals: [-7.719, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5495, "number_of_timesteps": 94632, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 2112 0 visits [734.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5495 q_vals: [-7.738, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2113 0 visits [735.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5497 q_vals: [-7.74, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2114 0 visits [736.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5499 q_vals: [-7.741, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5505, "number_of_timesteps": 94782, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2115 0 visits [737.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5505 q_vals: [-7.733, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2116 0 visits [738.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5506 q_vals: [-7.734, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2117 0 visits [739.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5508 q_vals: [-7.753, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2118 0 visits [740.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5512 q_vals: [-7.755, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2119 0 visits [741.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5514 q_vals: [-7.744, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2120 0 visits [742.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5514 q_vals: [-7.746, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5516, "number_of_timesteps": 94955, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2121 0 visits [743.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5516 q_vals: [-7.747, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2122 0 visits [744.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5519 q_vals: [-7.74, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2123 0 visits [745.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5523 q_vals: [-7.73, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2124 0 visits [746.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5523 q_vals: [-7.731, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2125 0 visits [747.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5523 q_vals: [-7.732, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5526, "number_of_timesteps": 95193, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2126 0 visits [748.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5526 q_vals: [-7.734, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2127 0 visits [749.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5530 q_vals: [-7.735, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2128 0 visits [750.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5532 q_vals: [-7.725, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2129 0 visits [751.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5533 q_vals: [-7.719, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2130 0 visits [752.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5533 q_vals: [-7.709, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5537, "number_of_timesteps": 95437, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2131 0 visits [753.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5537 q_vals: [-7.71, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2132 0 visits [754.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5538 q_vals: [-7.712, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2133 0 visits [755.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5541 q_vals: [-7.713, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2134 0 visits [756.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5542 q_vals: [-7.714, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2135 0 visits [757.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5544 q_vals: [-7.716, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5549, "number_of_timesteps": 95715, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2136 0 visits [758.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5549 q_vals: [-7.734, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2137 0 visits [759.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5549 q_vals: [-7.724, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2138 0 visits [760.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5552 q_vals: [-7.725, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2139 0 visits [761.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5553 q_vals: [-7.727, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2140 0 visits [762.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5557 q_vals: [-7.745, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5560, "number_of_timesteps": 95931, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2141 0 visits [763.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5560 q_vals: [-7.747, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2142 0 visits [764.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5562 q_vals: [-7.748, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2143 0 visits [765.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5565 q_vals: [-7.738, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2144 0 visits [766.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5568 q_vals: [-7.728, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2145 0 visits [767.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5568 q_vals: [-7.729, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5572, "number_of_timesteps": 96100, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
[-7.73, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2147 0 visits [769.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5574 q_vals: [-7.72, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2148 0 visits [770.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5579 q_vals: [-7.71, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2149 0 visits [771.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5581 q_vals: [-7.712, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5586, "number_of_timesteps": 96357, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2150 0 visits [772.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5586 q_vals: [-7.713, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2151 0 visits [773.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5588 q_vals: [-7.714, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2152 0 visits [774.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5591 q_vals: [-7.716, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5596, "number_of_timesteps": 96500, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2153 0 visits [775.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5596 q_vals: [-7.717, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2154 0 visits [776.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5598 q_vals: [-7.735, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2155 0 visits [777.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5603 q_vals: [-7.737, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5606, "number_of_timesteps": 96623, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2156 0 visits [778.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5606 q_vals: [-7.738, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2157 0 visits [779.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5611 q_vals: [-7.728, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2158 0 visits [780.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5613 q_vals: [-7.729, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2159 0 visits [781.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5615 q_vals: [-7.719, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5617, "number_of_timesteps": 96770, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2160 0 visits [782.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5617 q_vals: [-7.721, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2161 0 visits [783.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5619 q_vals: [-7.722, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2162 0 visits [784.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5620 q_vals: [-7.723, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2163 0 visits [785.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5624 q_vals: [-7.713, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5629, "number_of_timesteps": 96996, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2164 0 visits [786.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5629 q_vals: [-7.715, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2165 0 visits [787.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5631 q_vals: [-7.716, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2166 0 visits [788.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5633 q_vals: [-7.717, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5639, "number_of_timesteps": 97123, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2167 0 visits [789.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5639 q_vals: [-7.719, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2168 0 visits [790.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5640 q_vals: [-7.72, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2169 0 visits [791.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5645 q_vals: [-7.721, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5649, "number_of_timesteps": 97255, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2170 0 visits [792.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5649 q_vals: [-7.723, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2171 0 visits [793.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5651 q_vals: [-7.724, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2172 0 visits [794.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5655 q_vals: [-7.725, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5659, "number_of_timesteps": 97373, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2173 0 visits [795.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5659 q_vals: [-7.727, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2174 0 visits [796.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5660 q_vals: [-7.728, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2175 0 visits [797.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5665 q_vals: [-7.729, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5669, "number_of_timesteps": 97496, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2176 0 visits [798.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5669 q_vals: [-7.73, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2177 0 visits [799.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5673 q_vals: [-7.732, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2178 0 visits [800.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5678 q_vals: [-7.733, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5681, "number_of_timesteps": 97631, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2179 0 visits [801.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5681 q_vals: [-7.751, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2180 0 visits [802.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5684 q_vals: [-7.752, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2181 0 visits [803.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5689 q_vals: [-7.753, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5691, "number_of_timesteps": 97750, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2182 0 visits [804.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5691 q_vals: [-7.743, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2183 0 visits [805.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5693 q_vals: [-7.745, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2184 0 visits [806.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5699 q_vals: [-7.746, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5702, "number_of_timesteps": 97902, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2185 0 visits [807.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5702 q_vals: [-7.736, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2186 0 visits [808.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5707 q_vals: [-7.754, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2187 0 visits [809.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5710 q_vals: [-7.755, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5712, "number_of_timesteps": 98011, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2188 0 visits [810.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5712 q_vals: [-7.772, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2189 0 visits [811.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5718 q_vals: [-7.79, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2190 0 visits [812.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5719 q_vals: [-7.791, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5722, "number_of_timesteps": 98135, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2191 0 visits [813.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5722 q_vals: [-7.808, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2192 0 visits [814.0, 1000.0, 37.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5728 q_vals: [-7.826, -inf, -8.159, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2193 2 visits [814.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5730 q_vals: [-7.826, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5733, "number_of_timesteps": 98277, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2194 0 visits [815.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5733 q_vals: [-7.827, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2195 0 visits [816.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5737 q_vals: [-7.844, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2196 0 visits [817.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5740 q_vals: [-7.845, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5744, "number_of_timesteps": 98427, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2197 0 visits [818.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5744 q_vals: [-7.846, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2198 0 visits [819.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5746 q_vals: [-7.847, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2199 0 visits [820.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5752 q_vals: [-7.848, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2200 0 visits [821.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5753 q_vals: [-7.85, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5758, "number_of_timesteps": 98599, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2201 0 visits [822.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5758 q_vals: [-7.84, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2202 0 visits [823.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5762 q_vals: [-7.857, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2203 0 visits [824.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5763 q_vals: [-7.848, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
[-7.838, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5772, "number_of_timesteps": 98789, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2205 0 visits [826.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5772 q_vals: [-7.839, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2206 0 visits [827.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5772 q_vals: [-7.84, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2207 0 visits [828.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5777 q_vals: [-7.841, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2208 0 visits [829.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5779 q_vals: [-7.842, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5782, "number_of_timesteps": 98931, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2209 0 visits [830.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5782 q_vals: [-7.843, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2210 0 visits [831.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5785 q_vals: [-7.86, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2211 0 visits [832.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5788 q_vals: [-7.861, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2212 0 visits [833.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5791 q_vals: [-7.863, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5795, "number_of_timesteps": 99106, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2213 0 visits [834.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5795 q_vals: [-7.879, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2214 0 visits [835.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5797 q_vals: [-7.896, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2215 0 visits [836.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5804 q_vals: [-7.897, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5805, "number_of_timesteps": 99248, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2216 0 visits [837.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5805 q_vals: [-7.898, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2217 0 visits [838.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5813 q_vals: [-7.899, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5815, "number_of_timesteps": 99351, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2218 0 visits [839.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5815 q_vals: [-7.9, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2219 0 visits [840.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5819 q_vals: [-7.901, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2220 0 visits [841.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5822 q_vals: [-7.902, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5825, "number_of_timesteps": 99472, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2221 0 visits [842.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5825 q_vals: [-7.903, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2222 0 visits [843.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5830 q_vals: [-7.894, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2223 0 visits [844.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5834 q_vals: [-7.895, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5836, "number_of_timesteps": 99593, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2224 0 visits [845.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5836 q_vals: [-7.896, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2225 0 visits [846.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5840 q_vals: [-7.886, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2226 0 visits [847.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5845 q_vals: [-7.888, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5847, "number_of_timesteps": 99731, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2227 0 visits [848.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5847 q_vals: [-7.889, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2228 0 visits [849.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5851 q_vals: [-7.89, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2229 0 visits [850.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5854 q_vals: [-7.891, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2230 0 visits [851.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5856 q_vals: [-7.892, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5860, "number_of_timesteps": 99901, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2231 0 visits [852.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5860 q_vals: [-7.893, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2232 0 visits [853.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5863 q_vals: [-7.894, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2233 0 visits [854.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5867 q_vals: [-7.895, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5870, "number_of_timesteps": 100032, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2234 0 visits [855.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5870 q_vals: [-7.885, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2235 0 visits [856.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5875 q_vals: [-7.902, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2236 0 visits [857.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5877 q_vals: [-7.918, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5882, "number_of_timesteps": 100187, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2237 0 visits [858.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5882 q_vals: [-7.919, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2238 0 visits [859.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5884 q_vals: [-7.92, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2239 0 visits [860.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5887 q_vals: [-7.921, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5892, "number_of_timesteps": 100321, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2240 0 visits [861.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5892 q_vals: [-7.922, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2241 0 visits [862.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5893 q_vals: [-7.938, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2242 0 visits [863.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5898 q_vals: [-7.939, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5902, "number_of_timesteps": 100455, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2243 0 visits [864.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5902 q_vals: [-7.94, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2244 0 visits [865.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5904 q_vals: [-7.941, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2245 0 visits [866.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5909 q_vals: [-7.942, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2246 0 visits [867.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5911 q_vals: [-7.943, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5917, "number_of_timesteps": 100634, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2247 0 visits [868.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5917 q_vals: [-7.934, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2248 0 visits [869.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5918 q_vals: [-7.935, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2249 0 visits [870.0, 1000.0, 38.0, 4.0, 17.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5922 q_vals: [-7.951, -inf, -8.52, -9.844, -8.493, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2250 4 visits [870.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5925 q_vals: [-7.951, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5929, "number_of_timesteps": 100787, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2251 0 visits [871.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5929 q_vals: [-7.951, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2252 0 visits [872.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5932 q_vals: [-7.967, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2253 0 visits [873.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5937 q_vals: [-7.968, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2254 0 visits [874.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5938 q_vals: [-7.969, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5943, "number_of_timesteps": 100972, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2255 0 visits [875.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5943 q_vals: [-7.97, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2256 0 visits [876.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5946 q_vals: [-7.971, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2257 0 visits [877.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5949 q_vals: [-7.972, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2258 0 visits [878.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5951 q_vals: [-7.973, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5953, "number_of_timesteps": 101090, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2259 0 visits [879.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5953 q_vals: [-7.964, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2260 0 visits [880.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5956 q_vals: [-7.965, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2261 0 visits [881.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5959 q_vals: [-7.965, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2262 0 visits [882.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5962 q_vals: [-7.966, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5965, "number_of_timesteps": 101283, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2263 0 visits [883.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5965 q_vals: [-7.957, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2264 0 visits [884.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5969 q_vals: [-7.948, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2265 0 visits [885.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5973 q_vals: [-7.949, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5976, "number_of_timesteps": 101442, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2266 0 visits [886.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5976 q_vals: [-7.95, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2267 0 visits [887.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5979 q_vals: [-7.951, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2268 0 visits [888.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5982 q_vals: [-7.952, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5986, "number_of_timesteps": 101571, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2269 0 visits [889.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5986 q_vals: [-7.953, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2270 0 visits [890.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5988 q_vals: [-7.954, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2271 0 visits [891.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5990 q_vals: [-7.945, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2272 0 visits [892.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5992 q_vals: [-7.946, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 5997, "number_of_timesteps": 101732, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2273 0 visits [893.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5997 q_vals: [-7.961, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2274 0 visits [894.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 5999 q_vals: [-7.962, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2275 0 visits [895.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6002 q_vals: [-7.963, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2276 0 visits [896.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6005 q_vals: [-7.964, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6008, "number_of_timesteps": 101903, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2277 0 visits [897.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6008 q_vals: [-7.965, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2278 0 visits [898.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6009 q_vals: [-7.966, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2279 0 visits [899.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6012 q_vals: [-7.966, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6018, "number_of_timesteps": 102084, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2280 0 visits [900.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6018 q_vals: [-7.982, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2281 0 visits [901.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6018 q_vals: [-7.997, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2282 0 visits [902.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6022 q_vals: [-7.998, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2283 0 visits [903.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6027 q_vals: [-7.989, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6029, "number_of_timesteps": 102234, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2284 0 visits [904.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6029 q_vals: [-7.99, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2285 0 visits [905.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6033 q_vals: [-7.991, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2286 0 visits [906.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6036 q_vals: [-7.982, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2287 0 visits [907.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6037 q_vals: [-7.997, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6042, "number_of_timesteps": 102405, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2288 0 visits [908.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6042 q_vals: [-7.998, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2289 0 visits [909.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6042 q_vals: [-7.999, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2290 0 visits [910.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6045 q_vals: [-8.0, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2291 0 visits [911.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6048 q_vals: [-8.001, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6052, "number_of_timesteps": 102584, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2292 0 visits [912.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6052 q_vals: [-8.002, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2293 0 visits [913.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6054 q_vals: [-8.017, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2294 0 visits [914.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6057 q_vals: [-8.008, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2295 0 visits [915.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6058 q_vals: [-8.009, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2296 0 visits [916.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6061 q_vals: [-8.01, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6065, "number_of_timesteps": 102795, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2297 0 visits [917.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6065 q_vals: [-8.001, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2298 0 visits [918.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6068 q_vals: [-8.002, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2299 0 visits [919.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6070 q_vals: [-8.003, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6075, "number_of_timesteps": 102945, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2300 0 visits [920.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6075 q_vals: [-8.003, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2301 0 visits [921.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6079 q_vals: [-8.004, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2302 0 visits [922.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6080 q_vals: [-7.995, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2303 0 visits [923.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6081 q_vals: [-7.996, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6089, "number_of_timesteps": 103143, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2304 0 visits [924.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6089 q_vals: [-7.997, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2305 0 visits [925.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6090 q_vals: [-7.998, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2306 0 visits [926.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6095 q_vals: [-7.989, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2307 0 visits [927.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6098 q_vals: [-7.99, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6099, "number_of_timesteps": 103246, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2308 0 visits [928.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6099 q_vals: [-8.005, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2309 0 visits [929.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6104 q_vals: [-8.006, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2310 0 visits [930.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6108 q_vals: [-8.021, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6109, "number_of_timesteps": 103394, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2311 0 visits [931.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6109 q_vals: [-8.036, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2312 0 visits [932.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6114 q_vals: [-8.036, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2313 0 visits [933.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6116 q_vals: [-8.051, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6121, "number_of_timesteps": 103557, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2314 0 visits [934.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6121 q_vals: [-8.052, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2315 0 visits [935.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6124 q_vals: [-8.053, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2316 0 visits [936.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6127 q_vals: [-8.053, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2317 0 visits [937.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6129 q_vals: [-8.054, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6134, "number_of_timesteps": 103724, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2318 0 visits [938.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6134 q_vals: [-8.055, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2319 0 visits [939.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6135 q_vals: [-8.056, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2320 0 visits [940.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6138 q_vals: [-8.056, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2321 0 visits [941.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6140 q_vals: [-8.048, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2322 0 visits [942.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6140 q_vals: [-8.049, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2323 0 visits [943.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6142 q_vals: [-8.04, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6146, "number_of_timesteps": 103942, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2324 0 visits [944.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6146 q_vals: [-8.041, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2325 0 visits [945.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6150 q_vals: [-8.042, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2326 0 visits [946.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6152 q_vals: [-8.042, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2327 0 visits [947.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6154 q_vals: [-8.034, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6157, "number_of_timesteps": 104146, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2328 0 visits [948.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6157 q_vals: [-8.025, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2329 0 visits [949.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6161 q_vals: [-8.026, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2330 0 visits [950.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6162 q_vals: [-8.027, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6167, "number_of_timesteps": 104290, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2331 0 visits [951.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6167 q_vals: [-8.028, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2332 0 visits [952.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6169 q_vals: [-8.042, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2333 0 visits [953.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6172 q_vals: [-8.057, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2334 0 visits [954.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6174 q_vals: [-8.057, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6181, "number_of_timesteps": 104503, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2335 0 visits [955.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6181 q_vals: [-8.058, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2336 0 visits [956.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6181 q_vals: [-8.059, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2337 0 visits [957.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6181 q_vals: [-8.05, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2338 0 visits [958.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6182 q_vals: [-8.051, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2339 0 visits [959.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6184 q_vals: [-8.043, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2340 0 visits [960.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6188 q_vals: [-8.044, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2341 0 visits [961.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6188 q_vals: [-8.044, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6192, "number_of_timesteps": 104759, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2342 0 visits [962.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6192 q_vals: [-8.045, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2343 0 visits [963.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6193 q_vals: [-8.059, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2344 0 visits [964.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6195 q_vals: [-8.074, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2345 0 visits [965.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6196 q_vals: [-8.065, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2346 0 visits [966.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6200 q_vals: [-8.066, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2347 0 visits [967.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6201 q_vals: [-8.067, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6203, "number_of_timesteps": 105011, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2348 0 visits [968.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6203 q_vals: [-8.058, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2349 0 visits [969.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6206 q_vals: [-8.05, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2350 0 visits [970.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6208 q_vals: [-8.051, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2351 0 visits [971.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6209 q_vals: [-8.052, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2352 0 visits [972.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6211 q_vals: [-8.052, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6213, "number_of_timesteps": 105214, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2353 0 visits [973.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6213 q_vals: [-8.053, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2354 0 visits [974.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6216 q_vals: [-8.067, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2355 0 visits [975.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6218 q_vals: [-8.068, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2356 0 visits [976.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6220 q_vals: [-8.069, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2357 0 visits [977.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6220 q_vals: [-8.069, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6224, "number_of_timesteps": 105462, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2358 0 visits [978.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6224 q_vals: [-8.07, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2359 0 visits [979.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6226 q_vals: [-8.071, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2360 0 visits [980.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6227 q_vals: [-8.062, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2361 0 visits [981.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6229 q_vals: [-8.063, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6236, "number_of_timesteps": 105725, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2362 0 visits [982.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6236 q_vals: [-8.064, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2363 0 visits [983.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6237 q_vals: [-8.065, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2364 0 visits [984.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6238 q_vals: [-8.056, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2365 0 visits [985.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6243 q_vals: [-8.057, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2366 0 visits [986.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6245 q_vals: [-8.058, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6249, "number_of_timesteps": 105928, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2367 0 visits [987.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6249 q_vals: [-8.072, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2368 0 visits [988.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6251 q_vals: [-8.072, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2369 0 visits [989.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6252 q_vals: [-8.073, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2370 0 visits [990.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6253 q_vals: [-8.074, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6259, "number_of_timesteps": 106106, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2371 0 visits [991.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6259 q_vals: [-8.074, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2372 0 visits [992.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6262 q_vals: [-8.066, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2373 0 visits [993.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6263 q_vals: [-8.067, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2374 0 visits [994.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6267 q_vals: [-8.068, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6272, "number_of_timesteps": 106308, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2375 0 visits [995.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6272 q_vals: [-8.068, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2376 0 visits [996.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6272 q_vals: [-8.06, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2377 0 visits [997.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6276 q_vals: [-8.061, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2378 0 visits [998.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6279 q_vals: [-8.062, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
Step 2379 0 visits [999.0, 1000.0, 38.0, 4.0, 18.0, 1.0, 1.0, 5.0, 3.0, 5.0]  episode_count: 6281 q_vals: [-8.062, -inf, -8.52, -9.844, -9.236, -21.875, -21.875, -9.625, -10.208, -9.976]
{"total_number_of_episodes": 6284, "number_of_timesteps": 106475, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2380 0 visits [1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 6284 q_vals: [-inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2381 2 visits [1000.0, 1000.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 6286 q_vals: [-inf, -inf, -9.796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2382 3 visits [1000.0, 1000.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 6290 q_vals: [-inf, -inf, -9.796, -24.49, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
{"total_number_of_episodes": 6294, "number_of_timesteps": 106638, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 1.3999999999999986},
Step 2383 4 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 6294 q_vals: [-inf, -inf, -9.796, -24.49, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2384 5 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 6295 q_vals: [-inf, -inf, -9.796, -24.49, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2385 6 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 6300 q_vals: [-inf, -inf, -9.796, -24.49, 0.0, 0.0, -9.796, 0.0, 0.0, 0.0]
{"total_number_of_episodes": 6305, "number_of_timesteps": 106807, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 1.3999999999999986},
Step 2386 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 6305 q_vals: [-inf, -inf, -9.796, -24.49, 0.0, 0.0, -9.796, -9.796, 0.0, 0.0]
Step 2387 8 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 6308 q_vals: [-inf, -inf, -9.796, -24.49, 0.0, 0.0, -9.796, -9.796, -9.796, 0.0]
Step 2388 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6311 q_vals: [-inf, -inf, -9.796, -24.49, 0.0, 0.0, -9.796, -9.796, -9.796, -9.796]
{"total_number_of_episodes": 6317, "number_of_timesteps": 106941, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 1.3999999999999986},
Step 2389 4 visits [1000.0, 1000.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6317 q_vals: [-inf, -inf, -9.796, -24.49, -4.898, 0.0, -9.796, -9.796, -9.796, -9.796]
Step 2390 5 visits [1000.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6318 q_vals: [-inf, -inf, -9.796, -24.49, -4.898, 0.0, -9.796, -9.796, -9.796, -9.796]
Step 2391 5 visits [1000.0, 1000.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6323 q_vals: [-inf, -inf, -9.796, -24.49, -4.898, 0.0, -9.796, -9.796, -9.796, -9.796]
{"total_number_of_episodes": 6328, "number_of_timesteps": 107066, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 1.3999999999999986},
Step 2392 5 visits [1000.0, 1000.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6328 q_vals: [-inf, -inf, -9.796, -24.49, -4.898, -2.449, -9.796, -9.796, -9.796, -9.796]
Step 2393 5 visits [1000.0, 1000.0, 1.0, 1.0, 2.0, 5.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6330 q_vals: [-inf, -inf, -9.796, -24.49, -4.898, -3.909, -9.796, -9.796, -9.796, -9.796]
Step 2394 5 visits [1000.0, 1000.0, 1.0, 1.0, 2.0, 6.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6334 q_vals: [-inf, -inf, -9.796, -24.49, -4.898, -7.339, -9.796, -9.796, -9.796, -9.796]
{"total_number_of_episodes": 6339, "number_of_timesteps": 107192, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 1.3999999999999986},
Step 2395 4 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 6.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6339 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.339, -9.796, -9.796, -9.796, -9.796]
Step 2396 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 7.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6342 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.29, -9.796, -9.796, -9.796, -9.796]
Step 2397 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 8.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6346 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.729, -9.796, -9.796, -9.796, -9.796]
Step 2398 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 9.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6347 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.069, -9.796, -9.796, -9.796, -9.796]
{"total_number_of_episodes": 6354, "number_of_timesteps": 107374, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 1.3999999999999986},
Step 2399 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 10.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6354 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.362, -9.796, -9.796, -9.796, -9.796]
Step 2400 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 11.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6356 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.675, -9.796, -9.796, -9.796, -9.796]
Step 2401 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 12.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6359 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.118, -9.796, -9.796, -9.796, -9.796]
Step 2402 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 13.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6363 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.532, -9.796, -9.796, -9.796, -9.796]
{"total_number_of_episodes": 6365, "number_of_timesteps": 107503, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 1.3999999999999986},
Step 2403 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 14.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6365 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.994, -9.796, -9.796, -9.796, -9.796]
Step 2404 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 15.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6369 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.18, -9.796, -9.796, -9.796, -9.796]
Step 2405 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 16.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6373 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.732, -9.796, -9.796, -9.796, -9.796]
{"total_number_of_episodes": 6375, "number_of_timesteps": 107643, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 1.3999999999999986},
Step 2406 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 17.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6375 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.912, -9.796, -9.796, -9.796, -9.796]
Step 2407 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 18.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6380 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.528, -9.796, -9.796, -9.796, -9.796]
Step 2408 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 19.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6382 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.184, -9.796, -9.796, -9.796, -9.796]
Step 2409 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 20.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6384 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.365, -9.796, -9.796, -9.796, -9.796]
{"total_number_of_episodes": 6389, "number_of_timesteps": 107835, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 1.3999999999999986},
[-inf, -inf, -9.796, -24.49, -11.429, -6.528, -9.796, -9.796, -9.796, -9.796]
Step 2411 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 22.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6392 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.672, -9.796, -9.796, -9.796, -9.796]
Step 2412 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 23.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6396 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.808, -9.796, -9.796, -9.796, -9.796]
{"total_number_of_episodes": 6400, "number_of_timesteps": 107968, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2413 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 24.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6400 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.524, -9.796, -9.796, -9.796, -9.796]
Step 2414 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 25.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6402 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.263, -9.796, -9.796, -9.796, -9.796]
Step 2415 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 26.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6405 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.393, -9.796, -9.796, -9.796, -9.796]
Step 2416 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 27.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6407 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.156, -9.796, -9.796, -9.796, -9.796]
{"total_number_of_episodes": 6412, "number_of_timesteps": 108118, "per_episode_reward": 11.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2417 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 28.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6412 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.286, -9.796, -9.796, -9.796, -9.796]
Step 2418 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 29.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6417 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.07, -9.796, -9.796, -9.796, -9.796]
Step 2419 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 30.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6420 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.194, -9.796, -9.796, -9.796, -9.796]
{"total_number_of_episodes": 6422, "number_of_timesteps": 108234, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2420 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 31.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6422 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.31, -9.796, -9.796, -9.796, -9.796]
Step 2421 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 32.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6427 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.419, -9.796, -9.796, -9.796, -9.796]
Step 2422 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 33.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6429 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.521, -9.796, -9.796, -9.796, -9.796]
{"total_number_of_episodes": 6433, "number_of_timesteps": 108384, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2423 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 34.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6433 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.618, -9.796, -9.796, -9.796, -9.796]
Step 2424 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 35.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6436 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.708, -9.796, -9.796, -9.796, -9.796]
Step 2425 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 36.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6442 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -6.794, -9.796, -9.796, -9.796, -9.796]
{"total_number_of_episodes": 6443, "number_of_timesteps": 108506, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2426 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 37.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6443 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.272, -9.796, -9.796, -9.796, -9.796]
Step 2427 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 38.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6449 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.339, -9.796, -9.796, -9.796, -9.796]
Step 2428 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 39.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6450 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.402, -9.796, -9.796, -9.796, -9.796]
Step 2429 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 40.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6452 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.217, -9.796, -9.796, -9.796, -9.796]
{"total_number_of_episodes": 6453, "number_of_timesteps": 108623, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2430 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 41.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6453 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.041, -9.796, -9.796, -9.796, -9.796]
Step 2431 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 42.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6456 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.106, -9.796, -9.796, -9.796, -9.796]
Step 2432 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 43.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6458 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.168, -9.796, -9.796, -9.796, -9.796]
Step 2433 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 44.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6461 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.228, -9.796, -9.796, -9.796, -9.796]
{"total_number_of_episodes": 6464, "number_of_timesteps": 108844, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2434 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 45.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6464 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.285, -9.796, -9.796, -9.796, -9.796]
Step 2435 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 46.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6465 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.659, -9.796, -9.796, -9.796, -9.796]
Step 2436 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 47.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6468 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.705, -9.796, -9.796, -9.796, -9.796]
Step 2437 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 48.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6469 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -7.748, -9.796, -9.796, -9.796, -9.796]
Step 2438 5 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 49.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 6470 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -8.09, -9.796, -9.796, -9.796, -9.796]
Step 2439 8 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 49.0, 1.0, 1.0, 2.0, 1.0]  episode_count: 6473 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -8.09, -9.796, -9.796, -4.898, -9.796]
 episode_count: 6473 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -8.09, -9.796, -9.796, -11.429, -9.796]
{"total_number_of_episodes": 6478, "number_of_timesteps": 109136, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2441 7 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 49.0, 1.0, 2.0, 3.0, 1.0]  episode_count: 6478 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -9.796]
Step 2442 9 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 49.0, 1.0, 2.0, 3.0, 2.0]  episode_count: 6479 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -4.898]
Step 2443 9 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 49.0, 1.0, 2.0, 3.0, 3.0]  episode_count: 6479 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -6.531]
Step 2444 9 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 49.0, 1.0, 2.0, 3.0, 4.0]  episode_count: 6481 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -7.347]
Step 2445 9 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 49.0, 1.0, 2.0, 3.0, 5.0]  episode_count: 6484 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -5.878]
Step 2446 9 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 49.0, 1.0, 2.0, 3.0, 6.0]  episode_count: 6487 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2447 6 visits [1000.0, 1000.0, 1.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6487 q_vals: [-inf, -inf, -9.796, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6491, "number_of_timesteps": 109449, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2448 2 visits [1000.0, 1000.0, 2.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6491 q_vals: [-inf, -inf, -4.898, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2449 2 visits [1000.0, 1000.0, 3.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6493 q_vals: [-inf, -inf, -6.531, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2450 2 visits [1000.0, 1000.0, 4.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6493 q_vals: [-inf, -inf, -4.898, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2451 2 visits [1000.0, 1000.0, 5.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6495 q_vals: [-inf, -inf, -5.878, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2452 2 visits [1000.0, 1000.0, 6.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6498 q_vals: [-inf, -inf, -6.531, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6501, "number_of_timesteps": 109707, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2453 2 visits [1000.0, 1000.0, 7.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6501 q_vals: [-inf, -inf, -6.997, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2454 2 visits [1000.0, 1000.0, 8.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6504 q_vals: [-inf, -inf, -7.347, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2455 2 visits [1000.0, 1000.0, 9.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6505 q_vals: [-inf, -inf, -6.531, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2456 2 visits [1000.0, 1000.0, 10.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6508 q_vals: [-inf, -inf, -6.857, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2457 2 visits [1000.0, 1000.0, 11.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6509 q_vals: [-inf, -inf, -6.234, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6513, "number_of_timesteps": 109930, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2458 2 visits [1000.0, 1000.0, 12.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6513 q_vals: [-inf, -inf, -6.531, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2459 2 visits [1000.0, 1000.0, 13.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6515 q_vals: [-inf, -inf, -6.782, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2460 2 visits [1000.0, 1000.0, 14.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6516 q_vals: [-inf, -inf, -6.297, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2461 2 visits [1000.0, 1000.0, 15.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6516 q_vals: [-inf, -inf, -6.478, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2462 2 visits [1000.0, 1000.0, 16.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6519 q_vals: [-inf, -inf, -6.073, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2463 2 visits [1000.0, 1000.0, 17.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6520 q_vals: [-inf, -inf, -5.863, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2464 2 visits [1000.0, 1000.0, 18.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6522 q_vals: [-inf, -inf, -6.081, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6523, "number_of_timesteps": 110131, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2465 2 visits [1000.0, 1000.0, 19.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6523 q_vals: [-inf, -inf, -6.277, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2466 2 visits [1000.0, 1000.0, 20.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6524 q_vals: [-inf, -inf, -6.453, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2467 2 visits [1000.0, 1000.0, 21.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6526 q_vals: [-inf, -inf, -6.145, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2468 2 visits [1000.0, 1000.0, 22.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6530 q_vals: [-inf, -inf, -6.311, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2469 2 visits [1000.0, 1000.0, 23.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6532 q_vals: [-inf, -inf, -6.037, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6533, "number_of_timesteps": 110421, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2470 2 visits [1000.0, 1000.0, 24.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6533 q_vals: [-inf, -inf, -5.785, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
 [-inf, -inf, -5.946, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2472 2 visits [1000.0, 1000.0, 26.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6538 q_vals: [-inf, -inf, -6.094, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2473 2 visits [1000.0, 1000.0, 27.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6540 q_vals: [-inf, -inf, -5.868, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2474 2 visits [1000.0, 1000.0, 28.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6541 q_vals: [-inf, -inf, -5.659, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6543, "number_of_timesteps": 110678, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2475 2 visits [1000.0, 1000.0, 29.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6543 q_vals: [-inf, -inf, -5.801, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2476 2 visits [1000.0, 1000.0, 30.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6545 q_vals: [-inf, -inf, -5.934, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2477 2 visits [1000.0, 1000.0, 31.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6546 q_vals: [-inf, -inf, -5.743, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2478 2 visits [1000.0, 1000.0, 32.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6548 q_vals: [-inf, -inf, -5.87, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2479 2 visits [1000.0, 1000.0, 33.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6551 q_vals: [-inf, -inf, -5.989, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6554, "number_of_timesteps": 110932, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2480 2 visits [1000.0, 1000.0, 34.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6554 q_vals: [-inf, -inf, -5.813, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2481 2 visits [1000.0, 1000.0, 35.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6555 q_vals: [-inf, -inf, -5.646, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2482 2 visits [1000.0, 1000.0, 36.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6557 q_vals: [-inf, -inf, -5.759, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2483 2 visits [1000.0, 1000.0, 37.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6560 q_vals: [-inf, -inf, -5.603, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2484 2 visits [1000.0, 1000.0, 38.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6562 q_vals: [-inf, -inf, -5.702, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2485 2 visits [1000.0, 1000.0, 39.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6563 q_vals: [-inf, -inf, -5.799, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6564, "number_of_timesteps": 111164, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2486 2 visits [1000.0, 1000.0, 40.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6564 q_vals: [-inf, -inf, -5.654, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2487 2 visits [1000.0, 1000.0, 41.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6568 q_vals: [-inf, -inf, -5.517, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2488 2 visits [1000.0, 1000.0, 42.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6568 q_vals: [-inf, -inf, -5.612, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2489 2 visits [1000.0, 1000.0, 43.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6570 q_vals: [-inf, -inf, -5.482, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6576, "number_of_timesteps": 111433, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2490 2 visits [1000.0, 1000.0, 44.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6576 q_vals: [-inf, -inf, -5.357, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2491 2 visits [1000.0, 1000.0, 45.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6578 q_vals: [-inf, -inf, -5.238, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2492 2 visits [1000.0, 1000.0, 46.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6578 q_vals: [-inf, -inf, -5.337, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2493 2 visits [1000.0, 1000.0, 47.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6580 q_vals: [-inf, -inf, -5.419, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2494 2 visits [1000.0, 1000.0, 48.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6583 q_vals: [-inf, -inf, -5.306, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2495 2 visits [1000.0, 1000.0, 49.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6585 q_vals: [-inf, -inf, -5.198, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6588, "number_of_timesteps": 111666, "per_episode_reward": 11.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2496 2 visits [1000.0, 1000.0, 50.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6588 q_vals: [-inf, -inf, -5.29, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2497 2 visits [1000.0, 1000.0, 51.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6591 q_vals: [-inf, -inf, -5.186, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2498 2 visits [1000.0, 1000.0, 52.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6593 q_vals: [-inf, -inf, -5.275, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6598, "number_of_timesteps": 111844, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2499 2 visits [1000.0, 1000.0, 53.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6598 q_vals: [-inf, -inf, -5.35, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2500 2 visits [1000.0, 1000.0, 54.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6600 q_vals: [-inf, -inf, -5.432, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2501 2 visits [1000.0, 1000.0, 55.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6604 q_vals: [-inf, -inf, -5.501, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2502 2 visits [1000.0, 1000.0, 56.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6607 q_vals: [-inf, -inf, -5.403, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6610, "number_of_timesteps": 112027, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2503 2 visits [1000.0, 1000.0, 57.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6610 q_vals: [-inf, -inf, -5.308, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2504 2 visits [1000.0, 1000.0, 58.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6612 q_vals: [-inf, -inf, -5.216, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2505 2 visits [1000.0, 1000.0, 59.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6612 q_vals: [-inf, -inf, -5.128, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2506 2 visits [1000.0, 1000.0, 60.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6619 q_vals: [-inf, -inf, -5.043, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2507 2 visits [1000.0, 1000.0, 61.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6619 q_vals: [-inf, -inf, -5.12, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6624, "number_of_timesteps": 112251, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2508 2 visits [1000.0, 1000.0, 62.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6624 q_vals: [-inf, -inf, -5.038, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2509 2 visits [1000.0, 1000.0, 63.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6627 q_vals: [-inf, -inf, -4.958, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2510 2 visits [1000.0, 1000.0, 64.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6627 q_vals: [-inf, -inf, -5.034, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2511 2 visits [1000.0, 1000.0, 65.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6631 q_vals: [-inf, -inf, -4.956, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2512 2 visits [1000.0, 1000.0, 66.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6632 q_vals: [-inf, -inf, -5.029, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6635, "number_of_timesteps": 112413, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2513 2 visits [1000.0, 1000.0, 67.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6635 q_vals: [-inf, -inf, -4.954, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2514 2 visits [1000.0, 1000.0, 68.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6639 q_vals: [-inf, -inf, -5.026, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2515 2 visits [1000.0, 1000.0, 69.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6642 q_vals: [-inf, -inf, -4.953, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6645, "number_of_timesteps": 112587, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2516 2 visits [1000.0, 1000.0, 70.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6645 q_vals: [-inf, -inf, -5.022, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2517 2 visits [1000.0, 1000.0, 71.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6647 q_vals: [-inf, -inf, -4.951, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2518 2 visits [1000.0, 1000.0, 72.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6650 q_vals: [-inf, -inf, -5.018, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2519 2 visits [1000.0, 1000.0, 73.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6652 q_vals: [-inf, -inf, -5.076, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2520 2 visits [1000.0, 1000.0, 74.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6654 q_vals: [-inf, -inf, -5.008, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6657, "number_of_timesteps": 112790, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2521 2 visits [1000.0, 1000.0, 75.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6657 q_vals: [-inf, -inf, -5.07, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2522 2 visits [1000.0, 1000.0, 76.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6658 q_vals: [-inf, -inf, -5.132, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2523 2 visits [1000.0, 1000.0, 77.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6660 q_vals: [-inf, -inf, -5.192, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2524 2 visits [1000.0, 1000.0, 78.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6662 q_vals: [-inf, -inf, -5.251, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2525 2 visits [1000.0, 1000.0, 79.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6666 q_vals: [-inf, -inf, -5.309, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2526 2 visits [1000.0, 1000.0, 80.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6666 q_vals: [-inf, -inf, -5.365, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6670, "number_of_timesteps": 113065, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2527 2 visits [1000.0, 1000.0, 81.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6670 q_vals: [-inf, -inf, -5.42, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2528 2 visits [1000.0, 1000.0, 82.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6670 q_vals: [-inf, -inf, -5.465, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2529 2 visits [1000.0, 1000.0, 83.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6671 q_vals: [-inf, -inf, -5.399, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2530 2 visits [1000.0, 1000.0, 84.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6672 q_vals: [-inf, -inf, -5.335, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2531 2 visits [1000.0, 1000.0, 85.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6679 q_vals: [-inf, -inf, -5.387, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6681, "number_of_timesteps": 113328, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2532 2 visits [1000.0, 1000.0, 86.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6681 q_vals: [-inf, -inf, -5.439, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2533 2 visits [1000.0, 1000.0, 87.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6682 q_vals: [-inf, -inf, -5.376, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2534 2 visits [1000.0, 1000.0, 88.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6684 q_vals: [-inf, -inf, -5.315, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2535 2 visits [1000.0, 1000.0, 89.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6686 q_vals: [-inf, -inf, -5.365, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2536 2 visits [1000.0, 1000.0, 90.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6688 q_vals: [-inf, -inf, -5.415, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6692, "number_of_timesteps": 113511, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2537 2 visits [1000.0, 1000.0, 91.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6692 q_vals: [-inf, -inf, -5.355, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2538 2 visits [1000.0, 1000.0, 92.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6693 q_vals: [-inf, -inf, -5.403, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2539 2 visits [1000.0, 1000.0, 93.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6697 q_vals: [-inf, -inf, -5.451, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2540 2 visits [1000.0, 1000.0, 94.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6699 q_vals: [-inf, -inf, -5.393, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2541 2 visits [1000.0, 1000.0, 95.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6700 q_vals: [-inf, -inf, -5.336, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6704, "number_of_timesteps": 113737, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2542 2 visits [1000.0, 1000.0, 96.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6704 q_vals: [-inf, -inf, -5.382, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2543 2 visits [1000.0, 1000.0, 97.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6705 q_vals: [-inf, -inf, -5.327, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2544 2 visits [1000.0, 1000.0, 98.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6707 q_vals: [-inf, -inf, -5.37, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2545 2 visits [1000.0, 1000.0, 99.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6712 q_vals: [-inf, -inf, -5.315, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2546 2 visits [1000.0, 1000.0, 100.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6713 q_vals: [-inf, -inf, -5.354, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6714, "number_of_timesteps": 113909, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2547 2 visits [1000.0, 1000.0, 101.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6714 q_vals: [-inf, -inf, -5.398, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2548 2 visits [1000.0, 1000.0, 102.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6719 q_vals: [-inf, -inf, -5.433, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2549 2 visits [1000.0, 1000.0, 103.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6722 q_vals: [-inf, -inf, -5.468, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6725, "number_of_timesteps": 114098, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2550 2 visits [1000.0, 1000.0, 104.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6725 q_vals: [-inf, -inf, -5.503, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2551 2 visits [1000.0, 1000.0, 105.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6730 q_vals: [-inf, -inf, -5.536, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2552 2 visits [1000.0, 1000.0, 106.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6732 q_vals: [-inf, -inf, -5.567, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6735, "number_of_timesteps": 114245, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2553 2 visits [1000.0, 1000.0, 107.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6735 q_vals: [-inf, -inf, -5.606, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2554 2 visits [1000.0, 1000.0, 108.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6738 q_vals: [-inf, -inf, -5.645, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2555 2 visits [1000.0, 1000.0, 109.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6743 q_vals: [-inf, -inf, -5.683, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2556 2 visits [1000.0, 1000.0, 110.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6744 q_vals: [-inf, -inf, -5.721, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6748, "number_of_timesteps": 114414, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2557 2 visits [1000.0, 1000.0, 111.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6748 q_vals: [-inf, -inf, -5.669, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2558 2 visits [1000.0, 1000.0, 112.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6751 q_vals: [-inf, -inf, -5.706, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2559 2 visits [1000.0, 1000.0, 113.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6753 q_vals: [-inf, -inf, -5.742, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2560 2 visits [1000.0, 1000.0, 114.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6756 q_vals: [-inf, -inf, -5.77, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6759, "number_of_timesteps": 114587, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2561 2 visits [1000.0, 1000.0, 115.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6759 q_vals: [-inf, -inf, -5.805, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2562 2 visits [1000.0, 1000.0, 116.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6761 q_vals: [-inf, -inf, -5.834, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2563 2 visits [1000.0, 1000.0, 117.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6762 q_vals: [-inf, -inf, -5.868, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2564 2 visits [1000.0, 1000.0, 118.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6762 q_vals: [-inf, -inf, -5.895, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2565 2 visits [1000.0, 1000.0, 119.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6766 q_vals: [-inf, -inf, -5.921, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6769, "number_of_timesteps": 114795, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2566 2 visits [1000.0, 1000.0, 120.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6769 q_vals: [-inf, -inf, -5.953, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2567 2 visits [1000.0, 1000.0, 121.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6769 q_vals: [-inf, -inf, -5.985, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2568 2 visits [1000.0, 1000.0, 122.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6772 q_vals: [-inf, -inf, -5.936, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2569 2 visits [1000.0, 1000.0, 123.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6774 q_vals: [-inf, -inf, -5.888, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2570 2 visits [1000.0, 1000.0, 124.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6776 q_vals: [-inf, -inf, -5.84, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2571 2 visits [1000.0, 1000.0, 125.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6776 q_vals: [-inf, -inf, -5.868, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2572 2 visits [1000.0, 1000.0, 126.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6778 q_vals: [-inf, -inf, -5.899, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6782, "number_of_timesteps": 115096, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2573 2 visits [1000.0, 1000.0, 127.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6782 q_vals: [-inf, -inf, -5.921, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2574 2 visits [1000.0, 1000.0, 128.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6784 q_vals: [-inf, -inf, -5.951, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2575 2 visits [1000.0, 1000.0, 129.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6785 q_vals: [-inf, -inf, -5.981, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2576 2 visits [1000.0, 1000.0, 130.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6787 q_vals: [-inf, -inf, -6.01, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2577 2 visits [1000.0, 1000.0, 131.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6788 q_vals: [-inf, -inf, -5.964, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2578 2 visits [1000.0, 1000.0, 132.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6791 q_vals: [-inf, -inf, -5.919, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6794, "number_of_timesteps": 115405, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2579 2 visits [1000.0, 1000.0, 133.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6794 q_vals: [-inf, -inf, -5.875, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2580 2 visits [1000.0, 1000.0, 134.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6797 q_vals: [-inf, -inf, -5.831, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2581 2 visits [1000.0, 1000.0, 135.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6797 q_vals: [-inf, -inf, -5.86, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2582 2 visits [1000.0, 1000.0, 136.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6799 q_vals: [-inf, -inf, -5.889, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6804, "number_of_timesteps": 115567, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2583 2 visits [1000.0, 1000.0, 137.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6804 q_vals: [-inf, -inf, -5.846, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2584 2 visits [1000.0, 1000.0, 138.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6805 q_vals: [-inf, -inf, -5.875, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2585 2 visits [1000.0, 1000.0, 139.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6806 q_vals: [-inf, -inf, -5.832, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2586 2 visits [1000.0, 1000.0, 140.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6809 q_vals: [-inf, -inf, -5.853, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2587 2 visits [1000.0, 1000.0, 141.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6810 q_vals: [-inf, -inf, -5.873, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6814, "number_of_timesteps": 115792, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2588 2 visits [1000.0, 1000.0, 142.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6814 q_vals: [-inf, -inf, -5.893, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2589 2 visits [1000.0, 1000.0, 143.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6816 q_vals: [-inf, -inf, -5.913, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2590 2 visits [1000.0, 1000.0, 144.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6816 q_vals: [-inf, -inf, -5.935, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2591 2 visits [1000.0, 1000.0, 145.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6819 q_vals: [-inf, -inf, -5.894, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2592 2 visits [1000.0, 1000.0, 146.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6821 q_vals: [-inf, -inf, -5.921, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6824, "number_of_timesteps": 116023, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2593 2 visits [1000.0, 1000.0, 147.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6824 q_vals: [-inf, -inf, -5.939, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2594 2 visits [1000.0, 1000.0, 148.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6827 q_vals: [-inf, -inf, -5.965, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2595 2 visits [1000.0, 1000.0, 149.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6832 q_vals: [-inf, -inf, -5.925, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6834, "number_of_timesteps": 116195, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2596 2 visits [1000.0, 1000.0, 150.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6834 q_vals: [-inf, -inf, -5.951, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2597 2 visits [1000.0, 1000.0, 151.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6838 q_vals: [-inf, -inf, -5.911, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2598 2 visits [1000.0, 1000.0, 152.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6842 q_vals: [-inf, -inf, -5.873, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6844, "number_of_timesteps": 116319, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2599 2 visits [1000.0, 1000.0, 153.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6844 q_vals: [-inf, -inf, -5.898, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2600 2 visits [1000.0, 1000.0, 154.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6847 q_vals: [-inf, -inf, -5.923, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2601 2 visits [1000.0, 1000.0, 155.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6852 q_vals: [-inf, -inf, -5.944, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2602 2 visits [1000.0, 1000.0, 156.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6852 q_vals: [-inf, -inf, -5.906, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6859, "number_of_timesteps": 116525, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2603 2 visits [1000.0, 1000.0, 157.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6859 q_vals: [-inf, -inf, -5.931, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2604 2 visits [1000.0, 1000.0, 158.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6861 q_vals: [-inf, -inf, -5.949, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2605 2 visits [1000.0, 1000.0, 159.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6863 q_vals: [-inf, -inf, -5.966, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2606 2 visits [1000.0, 1000.0, 160.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6866 q_vals: [-inf, -inf, -5.929, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6870, "number_of_timesteps": 116674, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2607 2 visits [1000.0, 1000.0, 161.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6870 q_vals: [-inf, -inf, -5.946, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2608 2 visits [1000.0, 1000.0, 162.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6872 q_vals: [-inf, -inf, -5.909, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2609 2 visits [1000.0, 1000.0, 163.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6875 q_vals: [-inf, -inf, -5.873, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2610 2 visits [1000.0, 1000.0, 164.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6879 q_vals: [-inf, -inf, -5.888, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6880, "number_of_timesteps": 116836, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2611 2 visits [1000.0, 1000.0, 165.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6880 q_vals: [-inf, -inf, -5.904, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2612 2 visits [1000.0, 1000.0, 166.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6884 q_vals: [-inf, -inf, -5.926, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2613 2 visits [1000.0, 1000.0, 167.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6888 q_vals: [-inf, -inf, -5.942, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2614 2 visits [1000.0, 1000.0, 168.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6889 q_vals: [-inf, -inf, -5.907, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6891, "number_of_timesteps": 116997, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2615 2 visits [1000.0, 1000.0, 169.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6891 q_vals: [-inf, -inf, -5.93, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2616 2 visits [1000.0, 1000.0, 170.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6893 q_vals: [-inf, -inf, -5.895, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2617 2 visits [1000.0, 1000.0, 171.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6897 q_vals: [-inf, -inf, -5.918, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6901, "number_of_timesteps": 117180, "per_episode_reward": 11.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2618 2 visits [1000.0, 1000.0, 172.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6901 q_vals: [-inf, -inf, -5.933, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2619 2 visits [1000.0, 1000.0, 173.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6902 q_vals: [-inf, -inf, -5.899, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2620 2 visits [1000.0, 1000.0, 174.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6906 q_vals: [-inf, -inf, -5.918, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6911, "number_of_timesteps": 117323, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2621 2 visits [1000.0, 1000.0, 175.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6911 q_vals: [-inf, -inf, -5.884, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2622 2 visits [1000.0, 1000.0, 176.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6912 q_vals: [-inf, -inf, -5.899, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2623 2 visits [1000.0, 1000.0, 177.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6915 q_vals: [-inf, -inf, -5.921, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2624 2 visits [1000.0, 1000.0, 178.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6916 q_vals: [-inf, -inf, -5.943, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6923, "number_of_timesteps": 117497, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2625 2 visits [1000.0, 1000.0, 179.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6923 q_vals: [-inf, -inf, -5.909, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2626 2 visits [1000.0, 1000.0, 180.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6924 q_vals: [-inf, -inf, -5.931, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2627 2 visits [1000.0, 1000.0, 181.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6927 q_vals: [-inf, -inf, -5.952, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6933, "number_of_timesteps": 117628, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2628 2 visits [1000.0, 1000.0, 182.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6933 q_vals: [-inf, -inf, -5.973, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2629 2 visits [1000.0, 1000.0, 183.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6935 q_vals: [-inf, -inf, -5.941, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2630 2 visits [1000.0, 1000.0, 184.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6939 q_vals: [-inf, -inf, -5.962, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6943, "number_of_timesteps": 117745, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2631 2 visits [1000.0, 1000.0, 185.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6943 q_vals: [-inf, -inf, -5.982, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2632 2 visits [1000.0, 1000.0, 186.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6944 q_vals: [-inf, -inf, -5.95, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2633 2 visits [1000.0, 1000.0, 187.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6949 q_vals: [-inf, -inf, -5.963, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6953, "number_of_timesteps": 117888, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2634 2 visits [1000.0, 1000.0, 188.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6953 q_vals: [-inf, -inf, -5.98, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2635 2 visits [1000.0, 1000.0, 189.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6954 q_vals: [-inf, -inf, -5.995, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2636 2 visits [1000.0, 1000.0, 190.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6961 q_vals: [-inf, -inf, -6.015, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6963, "number_of_timesteps": 118002, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2637 2 visits [1000.0, 1000.0, 191.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6963 q_vals: [-inf, -inf, -6.029, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2638 2 visits [1000.0, 1000.0, 192.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6967 q_vals: [-inf, -inf, -6.049, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2639 2 visits [1000.0, 1000.0, 193.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6969 q_vals: [-inf, -inf, -6.063, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6974, "number_of_timesteps": 118141, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2640 2 visits [1000.0, 1000.0, 194.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6974 q_vals: [-inf, -inf, -6.032, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2641 2 visits [1000.0, 1000.0, 195.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6976 q_vals: [-inf, -inf, -6.051, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2642 2 visits [1000.0, 1000.0, 196.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6979 q_vals: [-inf, -inf, -6.063, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2643 2 visits [1000.0, 1000.0, 197.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6983 q_vals: [-inf, -inf, -6.082, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6988, "number_of_timesteps": 118314, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2644 2 visits [1000.0, 1000.0, 198.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6988 q_vals: [-inf, -inf, -6.051, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2645 2 visits [1000.0, 1000.0, 199.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6991 q_vals: [-inf, -inf, -6.069, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2646 2 visits [1000.0, 1000.0, 200.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6995 q_vals: [-inf, -inf, -6.08, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 6999, "number_of_timesteps": 118437, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2647 2 visits [1000.0, 1000.0, 201.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 6999 q_vals: [-inf, -inf, -6.05, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2648 2 visits [1000.0, 1000.0, 202.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7001 q_vals: [-inf, -inf, -6.068, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2649 2 visits [1000.0, 1000.0, 203.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7004 q_vals: [-inf, -inf, -6.086, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7010, "number_of_timesteps": 118572, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2650 2 visits [1000.0, 1000.0, 204.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7010 q_vals: [-inf, -inf, -6.057, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2651 2 visits [1000.0, 1000.0, 205.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7011 q_vals: [-inf, -inf, -6.027, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2652 2 visits [1000.0, 1000.0, 206.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7016 q_vals: [-inf, -inf, -5.998, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7020, "number_of_timesteps": 118698, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2653 2 visits [1000.0, 1000.0, 207.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7020 q_vals: [-inf, -inf, -6.016, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2654 2 visits [1000.0, 1000.0, 208.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7024 q_vals: [-inf, -inf, -5.987, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2655 2 visits [1000.0, 1000.0, 209.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7026 q_vals: [-inf, -inf, -5.959, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7031, "number_of_timesteps": 118818, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2656 2 visits [1000.0, 1000.0, 210.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7031 q_vals: [-inf, -inf, -5.973, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2657 2 visits [1000.0, 1000.0, 211.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7033 q_vals: [-inf, -inf, -5.945, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2658 2 visits [1000.0, 1000.0, 212.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7037 q_vals: [-inf, -inf, -5.962, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7041, "number_of_timesteps": 118959, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2659 2 visits [1000.0, 1000.0, 213.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7041 q_vals: [-inf, -inf, -5.934, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2660 2 visits [1000.0, 1000.0, 214.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7042 q_vals: [-inf, -inf, -5.906, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2661 2 visits [1000.0, 1000.0, 215.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7046 q_vals: [-inf, -inf, -5.924, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2662 2 visits [1000.0, 1000.0, 216.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7048 q_vals: [-inf, -inf, -5.896, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2663 2 visits [1000.0, 1000.0, 217.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7050 q_vals: [-inf, -inf, -5.914, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7054, "number_of_timesteps": 119133, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2664 2 visits [1000.0, 1000.0, 218.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7054 q_vals: [-inf, -inf, -5.932, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2665 2 visits [1000.0, 1000.0, 219.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7056 q_vals: [-inf, -inf, -5.95, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2666 2 visits [1000.0, 1000.0, 220.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7060 q_vals: [-inf, -inf, -5.967, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2667 2 visits [1000.0, 1000.0, 221.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7062 q_vals: [-inf, -inf, -5.984, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7065, "number_of_timesteps": 119340, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2668 2 visits [1000.0, 1000.0, 222.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7065 q_vals: [-inf, -inf, -5.999, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2669 2 visits [1000.0, 1000.0, 223.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7067 q_vals: [-inf, -inf, -6.017, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2670 2 visits [1000.0, 1000.0, 224.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7071 q_vals: [-inf, -inf, -6.027, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2671 2 visits [1000.0, 1000.0, 225.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7073 q_vals: [-inf, -inf, -6.044, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7075, "number_of_timesteps": 119491, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2672 2 visits [1000.0, 1000.0, 226.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7075 q_vals: [-inf, -inf, -6.054, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2673 2 visits [1000.0, 1000.0, 227.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7080 q_vals: [-inf, -inf, -6.07, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2674 2 visits [1000.0, 1000.0, 228.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7082 q_vals: [-inf, -inf, -6.086, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7087, "number_of_timesteps": 119675, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2675 2 visits [1000.0, 1000.0, 229.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7087 q_vals: [-inf, -inf, -6.06, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2676 2 visits [1000.0, 1000.0, 230.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7090 q_vals: [-inf, -inf, -6.033, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2677 2 visits [1000.0, 1000.0, 231.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7093 q_vals: [-inf, -inf, -6.049, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2678 2 visits [1000.0, 1000.0, 232.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7093 q_vals: [-inf, -inf, -6.058, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7099, "number_of_timesteps": 119845, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2679 2 visits [1000.0, 1000.0, 233.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7099 q_vals: [-inf, -inf, -6.074, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2680 2 visits [1000.0, 1000.0, 234.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7101 q_vals: [-inf, -inf, -6.084, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2681 2 visits [1000.0, 1000.0, 235.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7103 q_vals: [-inf, -inf, -6.093, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2682 2 visits [1000.0, 1000.0, 236.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7108 q_vals: [-inf, -inf, -6.067, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7111, "number_of_timesteps": 120018, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2683 2 visits [1000.0, 1000.0, 237.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7111 q_vals: [-inf, -inf, -6.041, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2684 2 visits [1000.0, 1000.0, 238.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7113 q_vals: [-inf, -inf, -6.051, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2685 2 visits [1000.0, 1000.0, 239.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7117 q_vals: [-inf, -inf, -6.066, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2686 2 visits [1000.0, 1000.0, 240.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7118 q_vals: [-inf, -inf, -6.041, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7124, "number_of_timesteps": 120199, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2687 2 visits [1000.0, 1000.0, 241.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7124 q_vals: [-inf, -inf, -6.056, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2688 2 visits [1000.0, 1000.0, 242.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7128 q_vals: [-inf, -inf, -6.031, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2689 2 visits [1000.0, 1000.0, 243.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7130 q_vals: [-inf, -inf, -6.044, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2690 2 visits [1000.0, 1000.0, 244.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7132 q_vals: [-inf, -inf, -6.059, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7136, "number_of_timesteps": 120341, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2691 2 visits [1000.0, 1000.0, 245.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7136 q_vals: [-inf, -inf, -6.068, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2692 2 visits [1000.0, 1000.0, 246.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7139 q_vals: [-inf, -inf, -6.077, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2693 2 visits [1000.0, 1000.0, 247.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7140 q_vals: [-inf, -inf, -6.053, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2694 2 visits [1000.0, 1000.0, 248.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7141 q_vals: [-inf, -inf, -6.028, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2695 2 visits [1000.0, 1000.0, 249.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7143 q_vals: [-inf, -inf, -6.043, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7146, "number_of_timesteps": 120502, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2696 2 visits [1000.0, 1000.0, 250.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7146 q_vals: [-inf, -inf, -6.019, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2697 2 visits [1000.0, 1000.0, 251.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7148 q_vals: [-inf, -inf, -5.995, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2698 2 visits [1000.0, 1000.0, 252.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7151 q_vals: [-inf, -inf, -6.007, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2699 2 visits [1000.0, 1000.0, 253.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7153 q_vals: [-inf, -inf, -5.984, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2700 2 visits [1000.0, 1000.0, 254.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7155 q_vals: [-inf, -inf, -5.993, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7156, "number_of_timesteps": 120738, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2701 2 visits [1000.0, 1000.0, 255.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7156 q_vals: [-inf, -inf, -5.97, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2702 2 visits [1000.0, 1000.0, 256.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7160 q_vals: [-inf, -inf, -5.978, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2703 2 visits [1000.0, 1000.0, 257.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7161 q_vals: [-inf, -inf, -5.988, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2704 2 visits [1000.0, 1000.0, 258.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7163 q_vals: [-inf, -inf, -5.997, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2705 2 visits [1000.0, 1000.0, 259.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7164 q_vals: [-inf, -inf, -6.006, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7167, "number_of_timesteps": 120975, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2706 2 visits [1000.0, 1000.0, 260.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7167 q_vals: [-inf, -inf, -5.983, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2707 2 visits [1000.0, 1000.0, 261.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7167 q_vals: [-inf, -inf, -5.997, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2708 2 visits [1000.0, 1000.0, 262.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7171 q_vals: [-inf, -inf, -5.974, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2709 2 visits [1000.0, 1000.0, 263.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7173 q_vals: [-inf, -inf, -5.986, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2710 2 visits [1000.0, 1000.0, 264.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7174 q_vals: [-inf, -inf, -5.994, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7177, "number_of_timesteps": 121185, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2711 2 visits [1000.0, 1000.0, 265.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7177 q_vals: [-inf, -inf, -6.008, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2712 2 visits [1000.0, 1000.0, 266.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7179 q_vals: [-inf, -inf, -6.019, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2713 2 visits [1000.0, 1000.0, 267.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7180 q_vals: [-inf, -inf, -6.033, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2714 2 visits [1000.0, 1000.0, 268.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7182 q_vals: [-inf, -inf, -6.039, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2715 2 visits [1000.0, 1000.0, 269.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7185 q_vals: [-inf, -inf, -6.017, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2716 2 visits [1000.0, 1000.0, 270.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7185 q_vals: [-inf, -inf, -6.028, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7188, "number_of_timesteps": 121373, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2717 2 visits [1000.0, 1000.0, 271.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7188 q_vals: [-inf, -inf, -6.034, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2718 2 visits [1000.0, 1000.0, 272.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7190 q_vals: [-inf, -inf, -6.012, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2719 2 visits [1000.0, 1000.0, 273.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7192 q_vals: [-inf, -inf, -5.99, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2720 2 visits [1000.0, 1000.0, 274.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7196 q_vals: [-inf, -inf, -6.004, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7198, "number_of_timesteps": 121642, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2721 2 visits [1000.0, 1000.0, 275.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7198 q_vals: [-inf, -inf, -6.018, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2722 2 visits [1000.0, 1000.0, 276.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7202 q_vals: [-inf, -inf, -6.031, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2723 2 visits [1000.0, 1000.0, 277.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7203 q_vals: [-inf, -inf, -6.045, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2724 2 visits [1000.0, 1000.0, 278.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7206 q_vals: [-inf, -inf, -6.058, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7208, "number_of_timesteps": 121837, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2725 2 visits [1000.0, 1000.0, 279.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7208 q_vals: [-inf, -inf, -6.063, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2726 2 visits [1000.0, 1000.0, 280.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7210 q_vals: [-inf, -inf, -6.076, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2727 2 visits [1000.0, 1000.0, 281.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7214 q_vals: [-inf, -inf, -6.089, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2728 2 visits [1000.0, 1000.0, 282.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7216 q_vals: [-inf, -inf, -6.068, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7218, "number_of_timesteps": 122028, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2729 2 visits [1000.0, 1000.0, 283.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7218 q_vals: [-inf, -inf, -6.081, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2730 2 visits [1000.0, 1000.0, 284.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7220 q_vals: [-inf, -inf, -6.094, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2731 2 visits [1000.0, 1000.0, 285.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7221 q_vals: [-inf, -inf, -6.073, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2732 2 visits [1000.0, 1000.0, 286.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7224 q_vals: [-inf, -inf, -6.08, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7229, "number_of_timesteps": 122250, "per_episode_reward": 11.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2733 2 visits [1000.0, 1000.0, 287.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7229 q_vals: [-inf, -inf, -6.093, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2734 2 visits [1000.0, 1000.0, 288.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7230 q_vals: [-inf, -inf, -6.099, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2735 2 visits [1000.0, 1000.0, 289.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7232 q_vals: [-inf, -inf, -6.078, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2736 2 visits [1000.0, 1000.0, 290.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7235 q_vals: [-inf, -inf, -6.084, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2737 2 visits [1000.0, 1000.0, 291.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7238 q_vals: [-inf, -inf, -6.091, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7241, "number_of_timesteps": 122444, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2738 2 visits [1000.0, 1000.0, 292.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7241 q_vals: [-inf, -inf, -6.098, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2739 2 visits [1000.0, 1000.0, 293.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7243 q_vals: [-inf, -inf, -6.109, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2740 2 visits [1000.0, 1000.0, 294.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7244 q_vals: [-inf, -inf, -6.088, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
[-inf, -inf, -6.095, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7251, "number_of_timesteps": 122610, "per_episode_reward": 11.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2742 2 visits [1000.0, 1000.0, 296.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7251 q_vals: [-inf, -inf, -6.074, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2743 2 visits [1000.0, 1000.0, 297.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7254 q_vals: [-inf, -inf, -6.087, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2744 2 visits [1000.0, 1000.0, 298.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7257 q_vals: [-inf, -inf, -6.094, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2745 2 visits [1000.0, 1000.0, 299.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7260 q_vals: [-inf, -inf, -6.106, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7262, "number_of_timesteps": 122795, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2746 2 visits [1000.0, 1000.0, 300.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7262 q_vals: [-inf, -inf, -6.086, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2747 2 visits [1000.0, 1000.0, 301.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7264 q_vals: [-inf, -inf, -6.098, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2748 2 visits [1000.0, 1000.0, 302.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7267 q_vals: [-inf, -inf, -6.105, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2749 2 visits [1000.0, 1000.0, 303.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7270 q_vals: [-inf, -inf, -6.096, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7274, "number_of_timesteps": 122990, "per_episode_reward": 11.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2750 2 visits [1000.0, 1000.0, 304.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7274 q_vals: [-inf, -inf, -6.108, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2751 2 visits [1000.0, 1000.0, 305.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7277 q_vals: [-inf, -inf, -6.088, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2752 2 visits [1000.0, 1000.0, 306.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7278 q_vals: [-inf, -inf, -6.097, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2753 2 visits [1000.0, 1000.0, 307.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7281 q_vals: [-inf, -inf, -6.077, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7284, "number_of_timesteps": 123147, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2754 2 visits [1000.0, 1000.0, 308.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7284 q_vals: [-inf, -inf, -6.089, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2755 2 visits [1000.0, 1000.0, 309.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7286 q_vals: [-inf, -inf, -6.097, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2756 2 visits [1000.0, 1000.0, 310.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7287 q_vals: [-inf, -inf, -6.102, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2757 2 visits [1000.0, 1000.0, 311.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7291 q_vals: [-inf, -inf, -6.082, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2758 2 visits [1000.0, 1000.0, 312.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7292 q_vals: [-inf, -inf, -6.063, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2759 2 visits [1000.0, 1000.0, 313.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7293 q_vals: [-inf, -inf, -6.072, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7294, "number_of_timesteps": 123358, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2760 2 visits [1000.0, 1000.0, 314.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7294 q_vals: [-inf, -inf, -6.077, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2761 2 visits [1000.0, 1000.0, 315.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7298 q_vals: [-inf, -inf, -6.083, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2762 2 visits [1000.0, 1000.0, 316.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7299 q_vals: [-inf, -inf, -6.092, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2763 2 visits [1000.0, 1000.0, 317.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7300 q_vals: [-inf, -inf, -6.104, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7306, "number_of_timesteps": 123655, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2764 2 visits [1000.0, 1000.0, 318.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7306 q_vals: [-inf, -inf, -6.112, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2765 2 visits [1000.0, 1000.0, 319.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7308 q_vals: [-inf, -inf, -6.124, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2766 2 visits [1000.0, 1000.0, 320.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7310 q_vals: [-inf, -inf, -6.129, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2767 2 visits [1000.0, 1000.0, 321.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7312 q_vals: [-inf, -inf, -6.135, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2768 2 visits [1000.0, 1000.0, 322.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7315 q_vals: [-inf, -inf, -6.115, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7316, "number_of_timesteps": 123810, "per_episode_reward": 11.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2769 2 visits [1000.0, 1000.0, 323.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7316 q_vals: [-inf, -inf, -6.127, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2770 2 visits [1000.0, 1000.0, 324.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7320 q_vals: [-inf, -inf, -6.131, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
[-inf, -inf, -6.143, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7327, "number_of_timesteps": 124015, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2772 2 visits [1000.0, 1000.0, 326.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7327 q_vals: [-inf, -inf, -6.154, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2773 2 visits [1000.0, 1000.0, 327.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7330 q_vals: [-inf, -inf, -6.159, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2774 2 visits [1000.0, 1000.0, 328.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7331 q_vals: [-inf, -inf, -6.14, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2775 2 visits [1000.0, 1000.0, 329.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7336 q_vals: [-inf, -inf, -6.152, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7338, "number_of_timesteps": 124160, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2776 2 visits [1000.0, 1000.0, 330.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7338 q_vals: [-inf, -inf, -6.156, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2777 2 visits [1000.0, 1000.0, 331.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7341 q_vals: [-inf, -inf, -6.138, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2778 2 visits [1000.0, 1000.0, 332.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7344 q_vals: [-inf, -inf, -6.146, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7349, "number_of_timesteps": 124325, "per_episode_reward": 11.25, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2779 2 visits [1000.0, 1000.0, 333.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7349 q_vals: [-inf, -inf, -6.153, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2780 2 visits [1000.0, 1000.0, 334.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7353 q_vals: [-inf, -inf, -6.164, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2781 2 visits [1000.0, 1000.0, 335.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7355 q_vals: [-inf, -inf, -6.173, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7359, "number_of_timesteps": 124436, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2782 2 visits [1000.0, 1000.0, 336.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7359 q_vals: [-inf, -inf, -6.177, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2783 2 visits [1000.0, 1000.0, 337.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7361 q_vals: [-inf, -inf, -6.159, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2784 2 visits [1000.0, 1000.0, 338.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7362 q_vals: [-inf, -inf, -6.166, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2785 2 visits [1000.0, 1000.0, 339.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7366 q_vals: [-inf, -inf, -6.148, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7370, "number_of_timesteps": 124619, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2786 2 visits [1000.0, 1000.0, 340.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7370 q_vals: [-inf, -inf, -6.158, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2787 2 visits [1000.0, 1000.0, 341.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7371 q_vals: [-inf, -inf, -6.169, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2788 2 visits [1000.0, 1000.0, 342.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7374 q_vals: [-inf, -inf, -6.174, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2789 2 visits [1000.0, 1000.0, 343.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7377 q_vals: [-inf, -inf, -6.181, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2790 2 visits [1000.0, 1000.0, 344.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7378 q_vals: [-inf, -inf, -6.184, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7380, "number_of_timesteps": 124764, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2791 2 visits [1000.0, 1000.0, 345.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7380 q_vals: [-inf, -inf, -6.187, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2792 2 visits [1000.0, 1000.0, 346.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7385 q_vals: [-inf, -inf, -6.197, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2793 2 visits [1000.0, 1000.0, 347.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7386 q_vals: [-inf, -inf, -6.208, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2794 2 visits [1000.0, 1000.0, 348.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7387 q_vals: [-inf, -inf, -6.19, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7391, "number_of_timesteps": 124965, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2795 2 visits [1000.0, 1000.0, 349.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7391 q_vals: [-inf, -inf, -6.197, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2796 2 visits [1000.0, 1000.0, 350.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7395 q_vals: [-inf, -inf, -6.179, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2797 2 visits [1000.0, 1000.0, 351.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7395 q_vals: [-inf, -inf, -6.161, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2798 2 visits [1000.0, 1000.0, 352.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7397 q_vals: [-inf, -inf, -6.168, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2799 2 visits [1000.0, 1000.0, 353.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7398 q_vals: [-inf, -inf, -6.178, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7403, "number_of_timesteps": 125228, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
[1000.0, 1000.0, 354.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7403 q_vals: [-inf, -inf, -6.161, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2801 2 visits [1000.0, 1000.0, 355.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7404 q_vals: [-inf, -inf, -6.171, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2802 2 visits [1000.0, 1000.0, 356.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7406 q_vals: [-inf, -inf, -6.181, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2803 2 visits [1000.0, 1000.0, 357.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7408 q_vals: [-inf, -inf, -6.177, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2804 2 visits [1000.0, 1000.0, 358.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7411 q_vals: [-inf, -inf, -6.16, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2805 2 visits [1000.0, 1000.0, 359.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7412 q_vals: [-inf, -inf, -6.143, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7415, "number_of_timesteps": 125484, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2806 2 visits [1000.0, 1000.0, 360.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7415 q_vals: [-inf, -inf, -6.153, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2807 2 visits [1000.0, 1000.0, 361.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7415 q_vals: [-inf, -inf, -6.157, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2808 2 visits [1000.0, 1000.0, 362.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7417 q_vals: [-inf, -inf, -6.14, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2809 2 visits [1000.0, 1000.0, 363.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7419 q_vals: [-inf, -inf, -6.123, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2810 2 visits [1000.0, 1000.0, 364.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7422 q_vals: [-inf, -inf, -6.106, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2811 2 visits [1000.0, 1000.0, 365.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7424 q_vals: [-inf, -inf, -6.111, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7427, "number_of_timesteps": 125793, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2812 2 visits [1000.0, 1000.0, 366.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7427 q_vals: [-inf, -inf, -6.094, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2813 2 visits [1000.0, 1000.0, 367.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7431 q_vals: [-inf, -inf, -6.098, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2814 2 visits [1000.0, 1000.0, 368.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7433 q_vals: [-inf, -inf, -6.101, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2815 2 visits [1000.0, 1000.0, 369.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7435 q_vals: [-inf, -inf, -6.105, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7439, "number_of_timesteps": 125987, "per_episode_reward": 11.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2816 2 visits [1000.0, 1000.0, 370.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7439 q_vals: [-inf, -inf, -6.113, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2817 2 visits [1000.0, 1000.0, 371.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7440 q_vals: [-inf, -inf, -6.121, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2818 2 visits [1000.0, 1000.0, 372.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7444 q_vals: [-inf, -inf, -6.124, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2819 2 visits [1000.0, 1000.0, 373.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7448 q_vals: [-inf, -inf, -6.129, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7450, "number_of_timesteps": 126159, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2820 2 visits [1000.0, 1000.0, 374.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7450 q_vals: [-inf, -inf, -6.112, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2821 2 visits [1000.0, 1000.0, 375.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7453 q_vals: [-inf, -inf, -6.122, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2822 2 visits [1000.0, 1000.0, 376.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7457 q_vals: [-inf, -inf, -6.13, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7460, "number_of_timesteps": 126291, "per_episode_reward": 11.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2823 2 visits [1000.0, 1000.0, 377.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7460 q_vals: [-inf, -inf, -6.139, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2824 2 visits [1000.0, 1000.0, 378.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7462 q_vals: [-inf, -inf, -6.122, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2825 2 visits [1000.0, 1000.0, 379.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7467 q_vals: [-inf, -inf, -6.128, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2826 2 visits [1000.0, 1000.0, 380.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7468 q_vals: [-inf, -inf, -6.135, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7472, "number_of_timesteps": 126449, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2827 2 visits [1000.0, 1000.0, 381.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7472 q_vals: [-inf, -inf, -6.138, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2828 2 visits [1000.0, 1000.0, 382.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7477 q_vals: [-inf, -inf, -6.145, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2829 2 visits [1000.0, 1000.0, 383.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7478 q_vals: [-inf, -inf, -6.151, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7484, "number_of_timesteps": 126601, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
[1000.0, 1000.0, 384.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7484 q_vals: [-inf, -inf, -6.135, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2831 2 visits [1000.0, 1000.0, 385.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7488 q_vals: [-inf, -inf, -6.145, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2832 2 visits [1000.0, 1000.0, 386.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7489 q_vals: [-inf, -inf, -6.153, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7494, "number_of_timesteps": 126732, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2833 2 visits [1000.0, 1000.0, 387.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7494 q_vals: [-inf, -inf, -6.157, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2834 2 visits [1000.0, 1000.0, 388.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7497 q_vals: [-inf, -inf, -6.141, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2835 2 visits [1000.0, 1000.0, 389.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7499 q_vals: [-inf, -inf, -6.151, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7504, "number_of_timesteps": 126863, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2836 2 visits [1000.0, 1000.0, 390.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7504 q_vals: [-inf, -inf, -6.16, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2837 2 visits [1000.0, 1000.0, 391.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7507 q_vals: [-inf, -inf, -6.144, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2838 2 visits [1000.0, 1000.0, 392.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7508 q_vals: [-inf, -inf, -6.152, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2839 2 visits [1000.0, 1000.0, 393.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7512 q_vals: [-inf, -inf, -6.136, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7516, "number_of_timesteps": 127033, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2840 2 visits [1000.0, 1000.0, 394.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7516 q_vals: [-inf, -inf, -6.142, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2841 2 visits [1000.0, 1000.0, 395.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7519 q_vals: [-inf, -inf, -6.151, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2842 2 visits [1000.0, 1000.0, 396.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7520 q_vals: [-inf, -inf, -6.16, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2843 2 visits [1000.0, 1000.0, 397.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7524 q_vals: [-inf, -inf, -6.169, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7527, "number_of_timesteps": 127189, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2844 2 visits [1000.0, 1000.0, 398.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7527 q_vals: [-inf, -inf, -6.172, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2845 2 visits [1000.0, 1000.0, 399.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7528 q_vals: [-inf, -inf, -6.175, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2846 2 visits [1000.0, 1000.0, 400.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7530 q_vals: [-inf, -inf, -6.16, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2847 2 visits [1000.0, 1000.0, 401.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7533 q_vals: [-inf, -inf, -6.164, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2848 2 visits [1000.0, 1000.0, 402.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7535 q_vals: [-inf, -inf, -6.17, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2849 2 visits [1000.0, 1000.0, 403.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7535 q_vals: [-inf, -inf, -6.173, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7539, "number_of_timesteps": 127425, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2850 2 visits [1000.0, 1000.0, 404.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7539 q_vals: [-inf, -inf, -6.176, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2851 2 visits [1000.0, 1000.0, 405.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7540 q_vals: [-inf, -inf, -6.18, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2852 2 visits [1000.0, 1000.0, 406.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7542 q_vals: [-inf, -inf, -6.189, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2853 2 visits [1000.0, 1000.0, 407.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7546 q_vals: [-inf, -inf, -6.173, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2854 2 visits [1000.0, 1000.0, 408.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7547 q_vals: [-inf, -inf, -6.181, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2855 2 visits [1000.0, 1000.0, 409.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7547 q_vals: [-inf, -inf, -6.184, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2856 2 visits [1000.0, 1000.0, 410.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7548 q_vals: [-inf, -inf, -6.189, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7554, "number_of_timesteps": 127784, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2857 2 visits [1000.0, 1000.0, 411.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7554 q_vals: [-inf, -inf, -6.174, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2858 2 visits [1000.0, 1000.0, 412.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7554 q_vals: [-inf, -inf, -6.178, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2859 2 visits [1000.0, 1000.0, 413.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7556 q_vals: [-inf, -inf, -6.181, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2860 2 visits [1000.0, 1000.0, 414.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7561 q_vals: [-inf, -inf, -6.186, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2861 2 visits [1000.0, 1000.0, 415.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7562 q_vals: [-inf, -inf, -6.172, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2862 2 visits [1000.0, 1000.0, 416.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7563 q_vals: [-inf, -inf, -6.179, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7566, "number_of_timesteps": 127997, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2863 2 visits [1000.0, 1000.0, 417.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7566 q_vals: [-inf, -inf, -6.188, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2864 2 visits [1000.0, 1000.0, 418.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7569 q_vals: [-inf, -inf, -6.19, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2865 2 visits [1000.0, 1000.0, 419.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7573 q_vals: [-inf, -inf, -6.197, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2866 2 visits [1000.0, 1000.0, 420.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7574 q_vals: [-inf, -inf, -6.205, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7576, "number_of_timesteps": 128223, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2867 2 visits [1000.0, 1000.0, 421.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7576 q_vals: [-inf, -inf, -6.209, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2868 2 visits [1000.0, 1000.0, 422.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7578 q_vals: [-inf, -inf, -6.211, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2869 2 visits [1000.0, 1000.0, 423.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7583 q_vals: [-inf, -inf, -6.217, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2870 2 visits [1000.0, 1000.0, 424.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7584 q_vals: [-inf, -inf, -6.202, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2871 2 visits [1000.0, 1000.0, 425.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7585 q_vals: [-inf, -inf, -6.188, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7589, "number_of_timesteps": 128455, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2872 2 visits [1000.0, 1000.0, 426.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7589 q_vals: [-inf, -inf, -6.191, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2873 2 visits [1000.0, 1000.0, 427.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7589 q_vals: [-inf, -inf, -6.177, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2874 2 visits [1000.0, 1000.0, 428.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7592 q_vals: [-inf, -inf, -6.179, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2875 2 visits [1000.0, 1000.0, 429.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7595 q_vals: [-inf, -inf, -6.184, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2876 2 visits [1000.0, 1000.0, 430.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7598 q_vals: [-inf, -inf, -6.186, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7601, "number_of_timesteps": 128704, "per_episode_reward": 11.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2877 2 visits [1000.0, 1000.0, 431.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7601 q_vals: [-inf, -inf, -6.185, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2878 2 visits [1000.0, 1000.0, 432.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7604 q_vals: [-inf, -inf, -6.187, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2879 2 visits [1000.0, 1000.0, 433.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7607 q_vals: [-inf, -inf, -6.186, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2880 2 visits [1000.0, 1000.0, 434.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7608 q_vals: [-inf, -inf, -6.195, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2881 2 visits [1000.0, 1000.0, 435.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7610 q_vals: [-inf, -inf, -6.18, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7611, "number_of_timesteps": 128858, "per_episode_reward": 11.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2882 2 visits [1000.0, 1000.0, 436.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7611 q_vals: [-inf, -inf, -6.185, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2883 2 visits [1000.0, 1000.0, 437.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7613 q_vals: [-inf, -inf, -6.188, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2884 2 visits [1000.0, 1000.0, 438.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7617 q_vals: [-inf, -inf, -6.185, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2885 2 visits [1000.0, 1000.0, 439.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7618 q_vals: [-inf, -inf, -6.171, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2886 2 visits [1000.0, 1000.0, 440.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7619 q_vals: [-inf, -inf, -6.179, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7621, "number_of_timesteps": 129101, "per_episode_reward": 11.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2887 2 visits [1000.0, 1000.0, 441.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7621 q_vals: [-inf, -inf, -6.165, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2888 2 visits [1000.0, 1000.0, 442.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7622 q_vals: [-inf, -inf, -6.151, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2889 2 visits [1000.0, 1000.0, 443.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7626 q_vals: [-inf, -inf, -6.137, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2890 2 visits [1000.0, 1000.0, 444.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7627 q_vals: [-inf, -inf, -6.14, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2891 2 visits [1000.0, 1000.0, 445.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7628 q_vals: [-inf, -inf, -6.126, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7632, "number_of_timesteps": 129348, "per_episode_reward": 11.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2892 2 visits [1000.0, 1000.0, 446.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7632 q_vals: [-inf, -inf, -6.128, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2893 2 visits [1000.0, 1000.0, 447.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7635 q_vals: [-inf, -inf, -6.13, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2894 2 visits [1000.0, 1000.0, 448.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7636 q_vals: [-inf, -inf, -6.132, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7642, "number_of_timesteps": 129562, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2895 2 visits [1000.0, 1000.0, 449.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7642 q_vals: [-inf, -inf, -6.135, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2896 2 visits [1000.0, 1000.0, 450.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7643 q_vals: [-inf, -inf, -6.14, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2897 2 visits [1000.0, 1000.0, 451.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7644 q_vals: [-inf, -inf, -6.142, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2898 2 visits [1000.0, 1000.0, 452.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7646 q_vals: [-inf, -inf, -6.146, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2899 2 visits [1000.0, 1000.0, 453.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7648 q_vals: [-inf, -inf, -6.153, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2900 2 visits [1000.0, 1000.0, 454.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7651 q_vals: [-inf, -inf, -6.139, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7654, "number_of_timesteps": 129788, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2901 2 visits [1000.0, 1000.0, 455.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7654 q_vals: [-inf, -inf, -6.143, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2902 2 visits [1000.0, 1000.0, 456.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7657 q_vals: [-inf, -inf, -6.15, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2903 2 visits [1000.0, 1000.0, 457.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7660 q_vals: [-inf, -inf, -6.158, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7664, "number_of_timesteps": 129948, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2904 2 visits [1000.0, 1000.0, 458.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7664 q_vals: [-inf, -inf, -6.145, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2905 2 visits [1000.0, 1000.0, 459.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7666 q_vals: [-inf, -inf, -6.14, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2906 2 visits [1000.0, 1000.0, 460.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7669 q_vals: [-inf, -inf, -6.148, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2907 2 visits [1000.0, 1000.0, 461.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7671 q_vals: [-inf, -inf, -6.135, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2908 2 visits [1000.0, 1000.0, 462.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7671 q_vals: [-inf, -inf, -6.136, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7676, "number_of_timesteps": 130167, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2909 2 visits [1000.0, 1000.0, 463.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7676 q_vals: [-inf, -inf, -6.123, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2910 2 visits [1000.0, 1000.0, 464.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7679 q_vals: [-inf, -inf, -6.11, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2911 2 visits [1000.0, 1000.0, 465.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7683 q_vals: [-inf, -inf, -6.097, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2912 2 visits [1000.0, 1000.0, 466.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7684 q_vals: [-inf, -inf, -6.1, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7687, "number_of_timesteps": 130331, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2913 2 visits [1000.0, 1000.0, 467.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7687 q_vals: [-inf, -inf, -6.102, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2914 2 visits [1000.0, 1000.0, 468.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7692 q_vals: [-inf, -inf, -6.108, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2915 2 visits [1000.0, 1000.0, 469.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7694 q_vals: [-inf, -inf, -6.11, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7698, "number_of_timesteps": 130492, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2916 2 visits [1000.0, 1000.0, 470.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7698 q_vals: [-inf, -inf, -6.113, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2917 2 visits [1000.0, 1000.0, 471.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7699 q_vals: [-inf, -inf, -6.1, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2918 2 visits [1000.0, 1000.0, 472.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7705 q_vals: [-inf, -inf, -6.101, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2919 2 visits [1000.0, 1000.0, 473.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7707 q_vals: [-inf, -inf, -6.088, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7711, "number_of_timesteps": 130668, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2920 2 visits [1000.0, 1000.0, 474.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7711 q_vals: [-inf, -inf, -6.094, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2921 2 visits [1000.0, 1000.0, 475.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7715 q_vals: [-inf, -inf, -6.095, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2922 2 visits [1000.0, 1000.0, 476.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7718 q_vals: [-inf, -inf, -6.097, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2923 2 visits [1000.0, 1000.0, 477.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7720 q_vals: [-inf, -inf, -6.099, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7724, "number_of_timesteps": 130830, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2924 2 visits [1000.0, 1000.0, 478.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7724 q_vals: [-inf, -inf, -6.101, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2925 2 visits [1000.0, 1000.0, 479.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7726 q_vals: [-inf, -inf, -6.106, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2926 2 visits [1000.0, 1000.0, 480.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7728 q_vals: [-inf, -inf, -6.093, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2927 2 visits [1000.0, 1000.0, 481.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7732 q_vals: [-inf, -inf, -6.095, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7736, "number_of_timesteps": 131027, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2928 2 visits [1000.0, 1000.0, 482.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7736 q_vals: [-inf, -inf, -6.096, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2929 2 visits [1000.0, 1000.0, 483.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7739 q_vals: [-inf, -inf, -6.1, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2930 2 visits [1000.0, 1000.0, 484.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7741 q_vals: [-inf, -inf, -6.097, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7748, "number_of_timesteps": 131166, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2931 2 visits [1000.0, 1000.0, 485.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7748 q_vals: [-inf, -inf, -6.084, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2932 2 visits [1000.0, 1000.0, 486.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7749 q_vals: [-inf, -inf, -6.085, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2933 2 visits [1000.0, 1000.0, 487.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7750 q_vals: [-inf, -inf, -6.087, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2934 2 visits [1000.0, 1000.0, 488.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7756 q_vals: [-inf, -inf, -6.092, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2935 2 visits [1000.0, 1000.0, 489.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7757 q_vals: [-inf, -inf, -6.1, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7759, "number_of_timesteps": 131314, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2936 2 visits [1000.0, 1000.0, 490.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7759 q_vals: [-inf, -inf, -6.107, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2937 2 visits [1000.0, 1000.0, 491.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7765 q_vals: [-inf, -inf, -6.109, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2938 2 visits [1000.0, 1000.0, 492.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7768 q_vals: [-inf, -inf, -6.111, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7772, "number_of_timesteps": 131500, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2939 2 visits [1000.0, 1000.0, 493.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7772 q_vals: [-inf, -inf, -6.114, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2940 2 visits [1000.0, 1000.0, 494.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7776 q_vals: [-inf, -inf, -6.121, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2941 2 visits [1000.0, 1000.0, 495.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7778 q_vals: [-inf, -inf, -6.122, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2942 2 visits [1000.0, 1000.0, 496.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7781 q_vals: [-inf, -inf, -6.123, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7783, "number_of_timesteps": 131641, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2943 2 visits [1000.0, 1000.0, 497.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7783 q_vals: [-inf, -inf, -6.126, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2944 2 visits [1000.0, 1000.0, 498.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7788 q_vals: [-inf, -inf, -6.127, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2945 2 visits [1000.0, 1000.0, 499.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7791 q_vals: [-inf, -inf, -6.115, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7793, "number_of_timesteps": 131784, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2946 2 visits [1000.0, 1000.0, 500.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7793 q_vals: [-inf, -inf, -6.122, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2947 2 visits [1000.0, 1000.0, 501.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7796 q_vals: [-inf, -inf, -6.123, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2948 2 visits [1000.0, 1000.0, 502.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7800 q_vals: [-inf, -inf, -6.111, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7804, "number_of_timesteps": 131942, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2949 2 visits [1000.0, 1000.0, 503.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7804 q_vals: [-inf, -inf, -6.117, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2950 2 visits [1000.0, 1000.0, 504.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7806 q_vals: [-inf, -inf, -6.124, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2951 2 visits [1000.0, 1000.0, 505.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7808 q_vals: [-inf, -inf, -6.112, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2952 2 visits [1000.0, 1000.0, 506.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7810 q_vals: [-inf, -inf, -6.118, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2953 2 visits [1000.0, 1000.0, 507.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7812 q_vals: [-inf, -inf, -6.125, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7817, "number_of_timesteps": 132163, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2954 2 visits [1000.0, 1000.0, 508.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7817 q_vals: [-inf, -inf, -6.131, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2955 2 visits [1000.0, 1000.0, 509.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7818 q_vals: [-inf, -inf, -6.134, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2956 2 visits [1000.0, 1000.0, 510.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7820 q_vals: [-inf, -inf, -6.139, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2957 2 visits [1000.0, 1000.0, 511.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7825 q_vals: [-inf, -inf, -6.143, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2958 2 visits [1000.0, 1000.0, 512.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7825 q_vals: [-inf, -inf, -6.144, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7827, "number_of_timesteps": 132321, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2959 2 visits [1000.0, 1000.0, 513.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7827 q_vals: [-inf, -inf, -6.132, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2960 2 visits [1000.0, 1000.0, 514.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7831 q_vals: [-inf, -inf, -6.134, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2961 2 visits [1000.0, 1000.0, 515.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7832 q_vals: [-inf, -inf, -6.14, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2962 2 visits [1000.0, 1000.0, 516.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7832 q_vals: [-inf, -inf, -6.141, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7837, "number_of_timesteps": 132526, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2963 2 visits [1000.0, 1000.0, 517.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7837 q_vals: [-inf, -inf, -6.143, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2964 2 visits [1000.0, 1000.0, 518.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7840 q_vals: [-inf, -inf, -6.146, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2965 2 visits [1000.0, 1000.0, 519.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7841 q_vals: [-inf, -inf, -6.147, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2966 2 visits [1000.0, 1000.0, 520.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7843 q_vals: [-inf, -inf, -6.148, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2967 2 visits [1000.0, 1000.0, 521.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7844 q_vals: [-inf, -inf, -6.15, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7849, "number_of_timesteps": 132742, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2968 2 visits [1000.0, 1000.0, 522.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7849 q_vals: [-inf, -inf, -6.152, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2969 2 visits [1000.0, 1000.0, 523.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7850 q_vals: [-inf, -inf, -6.14, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2970 2 visits [1000.0, 1000.0, 524.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7851 q_vals: [-inf, -inf, -6.142, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2971 2 visits [1000.0, 1000.0, 525.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7853 q_vals: [-inf, -inf, -6.149, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2972 2 visits [1000.0, 1000.0, 526.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7857 q_vals: [-inf, -inf, -6.152, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7859, "number_of_timesteps": 132982, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2973 2 visits [1000.0, 1000.0, 527.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7859 q_vals: [-inf, -inf, -6.154, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2974 2 visits [1000.0, 1000.0, 528.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7860 q_vals: [-inf, -inf, -6.142, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2975 2 visits [1000.0, 1000.0, 529.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7861 q_vals: [-inf, -inf, -6.143, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2976 2 visits [1000.0, 1000.0, 530.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7864 q_vals: [-inf, -inf, -6.15, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2977 2 visits [1000.0, 1000.0, 531.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7864 q_vals: [-inf, -inf, -6.138, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2978 2 visits [1000.0, 1000.0, 532.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7866 q_vals: [-inf, -inf, -6.139, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7870, "number_of_timesteps": 133215, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2979 2 visits [1000.0, 1000.0, 533.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7870 q_vals: [-inf, -inf, -6.127, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2980 2 visits [1000.0, 1000.0, 534.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7870 q_vals: [-inf, -inf, -6.116, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2981 2 visits [1000.0, 1000.0, 535.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7871 q_vals: [-inf, -inf, -6.104, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2982 2 visits [1000.0, 1000.0, 536.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7873 q_vals: [-inf, -inf, -6.093, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2983 2 visits [1000.0, 1000.0, 537.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7876 q_vals: [-inf, -inf, -6.094, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2984 2 visits [1000.0, 1000.0, 538.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7878 q_vals: [-inf, -inf, -6.094, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2985 2 visits [1000.0, 1000.0, 539.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7879 q_vals: [-inf, -inf, -6.083, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7883, "number_of_timesteps": 133539, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2986 2 visits [1000.0, 1000.0, 540.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7883 q_vals: [-inf, -inf, -6.084, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2987 2 visits [1000.0, 1000.0, 541.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7884 q_vals: [-inf, -inf, -6.088, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2988 2 visits [1000.0, 1000.0, 542.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7887 q_vals: [-inf, -inf, -6.09, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2989 2 visits [1000.0, 1000.0, 543.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7891 q_vals: [-inf, -inf, -6.092, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7893, "number_of_timesteps": 133782, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2990 2 visits [1000.0, 1000.0, 544.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7893 q_vals: [-inf, -inf, -6.081, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2991 2 visits [1000.0, 1000.0, 545.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7895 q_vals: [-inf, -inf, -6.081, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2992 2 visits [1000.0, 1000.0, 546.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7899 q_vals: [-inf, -inf, -6.082, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2993 2 visits [1000.0, 1000.0, 547.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7901 q_vals: [-inf, -inf, -6.071, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7903, "number_of_timesteps": 133947, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2994 2 visits [1000.0, 1000.0, 548.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7903 q_vals: [-inf, -inf, -6.06, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2995 2 visits [1000.0, 1000.0, 549.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7908 q_vals: [-inf, -inf, -6.066, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2996 2 visits [1000.0, 1000.0, 550.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7910 q_vals: [-inf, -inf, -6.055, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2997 2 visits [1000.0, 1000.0, 551.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7911 q_vals: [-inf, -inf, -6.062, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7914, "number_of_timesteps": 134122, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2998 2 visits [1000.0, 1000.0, 552.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7914 q_vals: [-inf, -inf, -6.063, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 2999 2 visits [1000.0, 1000.0, 553.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7918 q_vals: [-inf, -inf, -6.069, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3000 2 visits [1000.0, 1000.0, 554.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7921 q_vals: [-inf, -inf, -6.069, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3001 2 visits [1000.0, 1000.0, 555.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7921 q_vals: [-inf, -inf, -6.076, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7925, "number_of_timesteps": 134322, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3002 2 visits [1000.0, 1000.0, 556.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7925 q_vals: [-inf, -inf, -6.083, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3003 2 visits [1000.0, 1000.0, 557.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7928 q_vals: [-inf, -inf, -6.083, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3004 2 visits [1000.0, 1000.0, 558.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7929 q_vals: [-inf, -inf, -6.085, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3005 2 visits [1000.0, 1000.0, 559.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7934 q_vals: [-inf, -inf, -6.074, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7938, "number_of_timesteps": 134546, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3006 2 visits [1000.0, 1000.0, 560.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7938 q_vals: [-inf, -inf, -6.063, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3007 2 visits [1000.0, 1000.0, 561.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7940 q_vals: [-inf, -inf, -6.066, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3008 2 visits [1000.0, 1000.0, 562.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7942 q_vals: [-inf, -inf, -6.069, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3009 2 visits [1000.0, 1000.0, 563.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7944 q_vals: [-inf, -inf, -6.072, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3010 2 visits [1000.0, 1000.0, 564.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7947 q_vals: [-inf, -inf, -6.062, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7949, "number_of_timesteps": 134715, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3011 2 visits [1000.0, 1000.0, 565.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7949 q_vals: [-inf, -inf, -6.062, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3012 2 visits [1000.0, 1000.0, 566.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7953 q_vals: [-inf, -inf, -6.051, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
[1000.0, 1000.0, 567.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7956 q_vals: [-inf, -inf, -6.041, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3014 2 visits [1000.0, 1000.0, 568.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7958 q_vals: [-inf, -inf, -6.047, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7961, "number_of_timesteps": 134920, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3015 2 visits [1000.0, 1000.0, 569.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7961 q_vals: [-inf, -inf, -6.052, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3016 2 visits [1000.0, 1000.0, 570.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7964 q_vals: [-inf, -inf, -6.041, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3017 2 visits [1000.0, 1000.0, 571.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7967 q_vals: [-inf, -inf, -6.046, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3018 2 visits [1000.0, 1000.0, 572.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7970 q_vals: [-inf, -inf, -6.047, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7974, "number_of_timesteps": 135116, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3019 2 visits [1000.0, 1000.0, 573.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7974 q_vals: [-inf, -inf, -6.037, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3020 2 visits [1000.0, 1000.0, 574.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7975 q_vals: [-inf, -inf, -6.026, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3021 2 visits [1000.0, 1000.0, 575.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7978 q_vals: [-inf, -inf, -6.016, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3022 2 visits [1000.0, 1000.0, 576.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7981 q_vals: [-inf, -inf, -6.016, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7984, "number_of_timesteps": 135290, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3023 2 visits [1000.0, 1000.0, 577.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7984 q_vals: [-inf, -inf, -6.019, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3024 2 visits [1000.0, 1000.0, 578.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7985 q_vals: [-inf, -inf, -6.02, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3025 2 visits [1000.0, 1000.0, 579.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7987 q_vals: [-inf, -inf, -6.009, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3026 2 visits [1000.0, 1000.0, 580.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7989 q_vals: [-inf, -inf, -6.01, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 7994, "number_of_timesteps": 135458, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3027 2 visits [1000.0, 1000.0, 581.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7994 q_vals: [-inf, -inf, -6.017, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3028 2 visits [1000.0, 1000.0, 582.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7996 q_vals: [-inf, -inf, -6.017, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3029 2 visits [1000.0, 1000.0, 583.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 7999 q_vals: [-inf, -inf, -6.021, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3030 2 visits [1000.0, 1000.0, 584.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8000 q_vals: [-inf, -inf, -6.021, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3031 2 visits [1000.0, 1000.0, 585.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8002 q_vals: [-inf, -inf, -6.022, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8006, "number_of_timesteps": 135678, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3032 2 visits [1000.0, 1000.0, 586.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8006 q_vals: [-inf, -inf, -6.028, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3033 2 visits [1000.0, 1000.0, 587.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8008 q_vals: [-inf, -inf, -6.018, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3034 2 visits [1000.0, 1000.0, 588.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8008 q_vals: [-inf, -inf, -6.007, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3035 2 visits [1000.0, 1000.0, 589.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8015 q_vals: [-inf, -inf, -6.012, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8016, "number_of_timesteps": 135864, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3036 2 visits [1000.0, 1000.0, 590.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8016 q_vals: [-inf, -inf, -6.013, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3037 2 visits [1000.0, 1000.0, 591.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8016 q_vals: [-inf, -inf, -6.016, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3038 2 visits [1000.0, 1000.0, 592.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8022 q_vals: [-inf, -inf, -6.006, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3039 2 visits [1000.0, 1000.0, 593.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8024 q_vals: [-inf, -inf, -6.007, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3040 2 visits [1000.0, 1000.0, 594.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8024 q_vals: [-inf, -inf, -5.997, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8028, "number_of_timesteps": 136048, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3041 2 visits [1000.0, 1000.0, 595.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8028 q_vals: [-inf, -inf, -5.986, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3042 2 visits [1000.0, 1000.0, 596.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8031 q_vals: [-inf, -inf, -5.992, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
[-inf, -inf, -5.982, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3044 2 visits [1000.0, 1000.0, 598.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8035 q_vals: [-inf, -inf, -5.983, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8039, "number_of_timesteps": 136242, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3045 2 visits [1000.0, 1000.0, 599.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8039 q_vals: [-inf, -inf, -5.973, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3046 2 visits [1000.0, 1000.0, 600.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8039 q_vals: [-inf, -inf, -5.979, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3047 2 visits [1000.0, 1000.0, 601.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8045 q_vals: [-inf, -inf, -5.982, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3048 2 visits [1000.0, 1000.0, 602.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8047 q_vals: [-inf, -inf, -5.989, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8049, "number_of_timesteps": 136443, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3049 2 visits [1000.0, 1000.0, 603.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8049 q_vals: [-inf, -inf, -5.991, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3050 2 visits [1000.0, 1000.0, 604.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8051 q_vals: [-inf, -inf, -5.981, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3051 2 visits [1000.0, 1000.0, 605.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8056 q_vals: [-inf, -inf, -5.983, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8059, "number_of_timesteps": 136579, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3052 2 visits [1000.0, 1000.0, 606.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8059 q_vals: [-inf, -inf, -5.985, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3053 2 visits [1000.0, 1000.0, 607.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8062 q_vals: [-inf, -inf, -5.985, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3054 2 visits [1000.0, 1000.0, 608.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8066 q_vals: [-inf, -inf, -5.987, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8069, "number_of_timesteps": 136716, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3055 2 visits [1000.0, 1000.0, 609.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8069 q_vals: [-inf, -inf, -5.987, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3056 2 visits [1000.0, 1000.0, 610.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8072 q_vals: [-inf, -inf, -5.977, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3057 2 visits [1000.0, 1000.0, 611.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8077 q_vals: [-inf, -inf, -5.979, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8080, "number_of_timesteps": 136851, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3058 2 visits [1000.0, 1000.0, 612.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8080 q_vals: [-inf, -inf, -5.979, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3059 2 visits [1000.0, 1000.0, 613.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8084 q_vals: [-inf, -inf, -5.969, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3060 2 visits [1000.0, 1000.0, 614.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8087 q_vals: [-inf, -inf, -5.96, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8090, "number_of_timesteps": 136970, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3061 2 visits [1000.0, 1000.0, 615.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8090 q_vals: [-inf, -inf, -5.96, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3062 2 visits [1000.0, 1000.0, 616.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8094 q_vals: [-inf, -inf, -5.95, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3063 2 visits [1000.0, 1000.0, 617.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8094 q_vals: [-inf, -inf, -5.957, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3064 2 visits [1000.0, 1000.0, 618.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8099 q_vals: [-inf, -inf, -5.947, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8100, "number_of_timesteps": 137097, "per_episode_reward": 11.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3065 2 visits [1000.0, 1000.0, 619.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8100 q_vals: [-inf, -inf, -5.947, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3066 2 visits [1000.0, 1000.0, 620.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8102 q_vals: [-inf, -inf, -5.937, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3067 2 visits [1000.0, 1000.0, 621.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8109 q_vals: [-inf, -inf, -5.939, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8110, "number_of_timesteps": 137256, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3068 2 visits [1000.0, 1000.0, 622.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8110 q_vals: [-inf, -inf, -5.939, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3069 2 visits [1000.0, 1000.0, 623.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8111 q_vals: [-inf, -inf, -5.93, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3070 2 visits [1000.0, 1000.0, 624.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8119 q_vals: [-inf, -inf, -5.932, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8121, "number_of_timesteps": 137435, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 3071 2 visits [1000.0, 1000.0, 625.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8121 q_vals: [-inf, -inf, -5.932, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3072 2 visits [1000.0, 1000.0, 626.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8125 q_vals: [-inf, -inf, -5.923, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3073 2 visits [1000.0, 1000.0, 627.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8126 q_vals: [-inf, -inf, -5.929, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3074 2 visits [1000.0, 1000.0, 628.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8130 q_vals: [-inf, -inf, -5.929, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8132, "number_of_timesteps": 137567, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 3075 2 visits [1000.0, 1000.0, 629.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8132 q_vals: [-inf, -inf, -5.931, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3076 2 visits [1000.0, 1000.0, 630.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8135 q_vals: [-inf, -inf, -5.937, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3077 2 visits [1000.0, 1000.0, 631.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8139 q_vals: [-inf, -inf, -5.927, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3078 2 visits [1000.0, 1000.0, 632.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8140 q_vals: [-inf, -inf, -5.918, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8144, "number_of_timesteps": 137747, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 3079 2 visits [1000.0, 1000.0, 633.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8144 q_vals: [-inf, -inf, -5.918, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3080 2 visits [1000.0, 1000.0, 634.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8147 q_vals: [-inf, -inf, -5.918, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3081 2 visits [1000.0, 1000.0, 635.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8149 q_vals: [-inf, -inf, -5.909, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3082 2 visits [1000.0, 1000.0, 636.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8151 q_vals: [-inf, -inf, -5.91, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3083 2 visits [1000.0, 1000.0, 637.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8153 q_vals: [-inf, -inf, -5.91, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8157, "number_of_timesteps": 137971, "per_episode_reward": 11.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 3084 2 visits [1000.0, 1000.0, 638.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8157 q_vals: [-inf, -inf, -5.912, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3085 2 visits [1000.0, 1000.0, 639.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8159 q_vals: [-inf, -inf, -5.912, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3086 2 visits [1000.0, 1000.0, 640.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8160 q_vals: [-inf, -inf, -5.909, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3087 2 visits [1000.0, 1000.0, 641.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8160 q_vals: [-inf, -inf, -5.914, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3088 2 visits [1000.0, 1000.0, 642.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8164 q_vals: [-inf, -inf, -5.92, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8169, "number_of_timesteps": 138223, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 3089 2 visits [1000.0, 1000.0, 643.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8169 q_vals: [-inf, -inf, -5.925, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3090 2 visits [1000.0, 1000.0, 644.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8169 q_vals: [-inf, -inf, -5.916, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3091 2 visits [1000.0, 1000.0, 645.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8174 q_vals: [-inf, -inf, -5.906, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3092 2 visits [1000.0, 1000.0, 646.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8175 q_vals: [-inf, -inf, -5.897, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3093 2 visits [1000.0, 1000.0, 647.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8177 q_vals: [-inf, -inf, -5.897, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8180, "number_of_timesteps": 138419, "per_episode_reward": 11.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 3094 2 visits [1000.0, 1000.0, 648.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8180 q_vals: [-inf, -inf, -5.897, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3095 2 visits [1000.0, 1000.0, 649.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8181 q_vals: [-inf, -inf, -5.897, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3096 2 visits [1000.0, 1000.0, 650.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8185 q_vals: [-inf, -inf, -5.897, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3097 2 visits [1000.0, 1000.0, 651.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8187 q_vals: [-inf, -inf, -5.897, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8190, "number_of_timesteps": 138596, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 3098 2 visits [1000.0, 1000.0, 652.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8190 q_vals: [-inf, -inf, -5.899, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3099 2 visits [1000.0, 1000.0, 653.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8193 q_vals: [-inf, -inf, -5.89, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3100 2 visits [1000.0, 1000.0, 654.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8198 q_vals: [-inf, -inf, -5.891, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3101 2 visits [1000.0, 1000.0, 655.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8199 q_vals: [-inf, -inf, -5.892, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8204, "number_of_timesteps": 138795, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 3102 2 visits [1000.0, 1000.0, 656.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8204 q_vals: [-inf, -inf, -5.883, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3103 2 visits [1000.0, 1000.0, 657.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8209 q_vals: [-inf, -inf, -5.883, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3104 2 visits [1000.0, 1000.0, 658.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8210 q_vals: [-inf, -inf, -5.889, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8216, "number_of_timesteps": 138933, "per_episode_reward": 11.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 3105 2 visits [1000.0, 1000.0, 659.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8216 q_vals: [-inf, -inf, -5.89, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3106 2 visits [1000.0, 1000.0, 660.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8219 q_vals: [-inf, -inf, -5.881, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3107 2 visits [1000.0, 1000.0, 661.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8223 q_vals: [-inf, -inf, -5.883, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3108 2 visits [1000.0, 1000.0, 662.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8225 q_vals: [-inf, -inf, -5.885, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8228, "number_of_timesteps": 139080, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3109 2 visits [1000.0, 1000.0, 663.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8228 q_vals: [-inf, -inf, -5.876, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3110 2 visits [1000.0, 1000.0, 664.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8232 q_vals: [-inf, -inf, -5.867, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3111 2 visits [1000.0, 1000.0, 665.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8235 q_vals: [-inf, -inf, -5.858, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3112 2 visits [1000.0, 1000.0, 666.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8236 q_vals: [-inf, -inf, -5.85, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8241, "number_of_timesteps": 139275, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3113 2 visits [1000.0, 1000.0, 667.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8241 q_vals: [-inf, -inf, -5.85, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3114 2 visits [1000.0, 1000.0, 668.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8244 q_vals: [-inf, -inf, -5.85, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3115 2 visits [1000.0, 1000.0, 669.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8247 q_vals: [-inf, -inf, -5.841, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3116 2 visits [1000.0, 1000.0, 670.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8248 q_vals: [-inf, -inf, -5.832, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8251, "number_of_timesteps": 139420, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3117 2 visits [1000.0, 1000.0, 671.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8251 q_vals: [-inf, -inf, -5.838, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3118 2 visits [1000.0, 1000.0, 672.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8256 q_vals: [-inf, -inf, -5.838, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3119 2 visits [1000.0, 1000.0, 673.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8257 q_vals: [-inf, -inf, -5.838, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3120 2 visits [1000.0, 1000.0, 674.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8259 q_vals: [-inf, -inf, -5.84, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8263, "number_of_timesteps": 139607, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3121 2 visits [1000.0, 1000.0, 675.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8263 q_vals: [-inf, -inf, -5.842, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3122 2 visits [1000.0, 1000.0, 676.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8266 q_vals: [-inf, -inf, -5.833, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3123 2 visits [1000.0, 1000.0, 677.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8269 q_vals: [-inf, -inf, -5.833, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3124 2 visits [1000.0, 1000.0, 678.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8272 q_vals: [-inf, -inf, -5.824, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8274, "number_of_timesteps": 139800, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3125 2 visits [1000.0, 1000.0, 679.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8274 q_vals: [-inf, -inf, -5.828, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3126 2 visits [1000.0, 1000.0, 680.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8279 q_vals: [-inf, -inf, -5.829, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3127 2 visits [1000.0, 1000.0, 681.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8280 q_vals: [-inf, -inf, -5.831, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3128 2 visits [1000.0, 1000.0, 682.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8283 q_vals: [-inf, -inf, -5.831, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8287, "number_of_timesteps": 139989, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3129 2 visits [1000.0, 1000.0, 683.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8287 q_vals: [-inf, -inf, -5.822, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3130 2 visits [1000.0, 1000.0, 684.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8287 q_vals: [-inf, -inf, -5.828, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3131 2 visits [1000.0, 1000.0, 685.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8292 q_vals: [-inf, -inf, -5.83, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
[-inf, -inf, -5.822, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3133 2 visits [1000.0, 1000.0, 687.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8296 q_vals: [-inf, -inf, -5.822, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8300, "number_of_timesteps": 140215, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3134 2 visits [1000.0, 1000.0, 688.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8300 q_vals: [-inf, -inf, -5.822, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3135 2 visits [1000.0, 1000.0, 689.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8302 q_vals: [-inf, -inf, -5.814, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3136 2 visits [1000.0, 1000.0, 690.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8306 q_vals: [-inf, -inf, -5.814, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3137 2 visits [1000.0, 1000.0, 691.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8309 q_vals: [-inf, -inf, -5.82, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8311, "number_of_timesteps": 140380, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3138 2 visits [1000.0, 1000.0, 692.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8311 q_vals: [-inf, -inf, -5.82, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3139 2 visits [1000.0, 1000.0, 693.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8314 q_vals: [-inf, -inf, -5.812, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3140 2 visits [1000.0, 1000.0, 694.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8317 q_vals: [-inf, -inf, -5.803, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8322, "number_of_timesteps": 140549, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3141 2 visits [1000.0, 1000.0, 695.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8322 q_vals: [-inf, -inf, -5.803, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3142 2 visits [1000.0, 1000.0, 696.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8324 q_vals: [-inf, -inf, -5.805, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3143 2 visits [1000.0, 1000.0, 697.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8326 q_vals: [-inf, -inf, -5.797, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3144 2 visits [1000.0, 1000.0, 698.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8327 q_vals: [-inf, -inf, -5.799, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3145 2 visits [1000.0, 1000.0, 699.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8328 q_vals: [-inf, -inf, -5.8, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3146 2 visits [1000.0, 1000.0, 700.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8331 q_vals: [-inf, -inf, -5.802, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8333, "number_of_timesteps": 140740, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3147 2 visits [1000.0, 1000.0, 701.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8333 q_vals: [-inf, -inf, -5.802, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3148 2 visits [1000.0, 1000.0, 702.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8334 q_vals: [-inf, -inf, -5.793, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3149 2 visits [1000.0, 1000.0, 703.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8335 q_vals: [-inf, -inf, -5.799, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3150 2 visits [1000.0, 1000.0, 704.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8340 q_vals: [-inf, -inf, -5.791, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3151 2 visits [1000.0, 1000.0, 705.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8341 q_vals: [-inf, -inf, -5.792, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3152 2 visits [1000.0, 1000.0, 706.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8341 q_vals: [-inf, -inf, -5.793, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8344, "number_of_timesteps": 141023, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3153 2 visits [1000.0, 1000.0, 707.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8344 q_vals: [-inf, -inf, -5.785, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3154 2 visits [1000.0, 1000.0, 708.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8346 q_vals: [-inf, -inf, -5.791, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3155 2 visits [1000.0, 1000.0, 709.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8349 q_vals: [-inf, -inf, -5.791, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3156 2 visits [1000.0, 1000.0, 710.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8351 q_vals: [-inf, -inf, -5.79, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3157 2 visits [1000.0, 1000.0, 711.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8353 q_vals: [-inf, -inf, -5.794, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3158 2 visits [1000.0, 1000.0, 712.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8353 q_vals: [-inf, -inf, -5.793, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8356, "number_of_timesteps": 141292, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3159 2 visits [1000.0, 1000.0, 713.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8356 q_vals: [-inf, -inf, -5.798, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3160 2 visits [1000.0, 1000.0, 714.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8359 q_vals: [-inf, -inf, -5.79, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3161 2 visits [1000.0, 1000.0, 715.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8360 q_vals: [-inf, -inf, -5.793, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3162 2 visits [1000.0, 1000.0, 716.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8363 q_vals: [-inf, -inf, -5.785, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8366, "number_of_timesteps": 141522, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3163 2 visits [1000.0, 1000.0, 717.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8366 q_vals: [-inf, -inf, -5.791, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3164 2 visits [1000.0, 1000.0, 718.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8371 q_vals: [-inf, -inf, -5.783, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3165 2 visits [1000.0, 1000.0, 719.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8373 q_vals: [-inf, -inf, -5.775, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3166 2 visits [1000.0, 1000.0, 720.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8374 q_vals: [-inf, -inf, -5.775, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3167 2 visits [1000.0, 1000.0, 721.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8375 q_vals: [-inf, -inf, -5.775, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8377, "number_of_timesteps": 141714, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3168 2 visits [1000.0, 1000.0, 722.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8377 q_vals: [-inf, -inf, -5.777, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3169 2 visits [1000.0, 1000.0, 723.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8380 q_vals: [-inf, -inf, -5.769, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3170 2 visits [1000.0, 1000.0, 724.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8382 q_vals: [-inf, -inf, -5.768, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8387, "number_of_timesteps": 141920, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3171 2 visits [1000.0, 1000.0, 725.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8387 q_vals: [-inf, -inf, -5.766, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3172 2 visits [1000.0, 1000.0, 726.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8388 q_vals: [-inf, -inf, -5.767, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3173 2 visits [1000.0, 1000.0, 727.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8391 q_vals: [-inf, -inf, -5.759, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3174 2 visits [1000.0, 1000.0, 728.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8394 q_vals: [-inf, -inf, -5.762, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3175 2 visits [1000.0, 1000.0, 729.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8395 q_vals: [-inf, -inf, -5.763, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8399, "number_of_timesteps": 142118, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3176 2 visits [1000.0, 1000.0, 730.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8399 q_vals: [-inf, -inf, -5.765, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3177 2 visits [1000.0, 1000.0, 731.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8401 q_vals: [-inf, -inf, -5.767, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3178 2 visits [1000.0, 1000.0, 732.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8403 q_vals: [-inf, -inf, -5.77, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3179 2 visits [1000.0, 1000.0, 733.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8405 q_vals: [-inf, -inf, -5.774, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3180 2 visits [1000.0, 1000.0, 734.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8408 q_vals: [-inf, -inf, -5.776, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8410, "number_of_timesteps": 142320, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3181 2 visits [1000.0, 1000.0, 735.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8410 q_vals: [-inf, -inf, -5.776, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3182 2 visits [1000.0, 1000.0, 736.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8415 q_vals: [-inf, -inf, -5.768, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3183 2 visits [1000.0, 1000.0, 737.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8419 q_vals: [-inf, -inf, -5.76, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8420, "number_of_timesteps": 142507, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3184 2 visits [1000.0, 1000.0, 738.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8420 q_vals: [-inf, -inf, -5.759, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3185 2 visits [1000.0, 1000.0, 739.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8423 q_vals: [-inf, -inf, -5.761, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3186 2 visits [1000.0, 1000.0, 740.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8427 q_vals: [-inf, -inf, -5.753, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3187 2 visits [1000.0, 1000.0, 741.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8428 q_vals: [-inf, -inf, -5.752, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8433, "number_of_timesteps": 142677, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3188 2 visits [1000.0, 1000.0, 742.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8433 q_vals: [-inf, -inf, -5.752, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3189 2 visits [1000.0, 1000.0, 743.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8434 q_vals: [-inf, -inf, -5.752, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3190 2 visits [1000.0, 1000.0, 744.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8435 q_vals: [-inf, -inf, -5.753, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3191 2 visits [1000.0, 1000.0, 745.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8440 q_vals: [-inf, -inf, -5.745, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8443, "number_of_timesteps": 142860, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3192 2 visits [1000.0, 1000.0, 746.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8443 q_vals: [-inf, -inf, -5.745, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3193 2 visits [1000.0, 1000.0, 747.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8445 q_vals: [-inf, -inf, -5.747, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3194 2 visits [1000.0, 1000.0, 748.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8447 q_vals: [-inf, -inf, -5.749, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3195 2 visits [1000.0, 1000.0, 749.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8450 q_vals: [-inf, -inf, -5.752, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8453, "number_of_timesteps": 143007, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3196 2 visits [1000.0, 1000.0, 750.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8453 q_vals: [-inf, -inf, -5.754, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3197 2 visits [1000.0, 1000.0, 751.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8456 q_vals: [-inf, -inf, -5.746, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3198 2 visits [1000.0, 1000.0, 752.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8458 q_vals: [-inf, -inf, -5.746, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3199 2 visits [1000.0, 1000.0, 753.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8462 q_vals: [-inf, -inf, -5.747, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8464, "number_of_timesteps": 143190, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3200 2 visits [1000.0, 1000.0, 754.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8464 q_vals: [-inf, -inf, -5.739, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3201 2 visits [1000.0, 1000.0, 755.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8466 q_vals: [-inf, -inf, -5.745, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3202 2 visits [1000.0, 1000.0, 756.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8472 q_vals: [-inf, -inf, -5.745, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3203 2 visits [1000.0, 1000.0, 757.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8472 q_vals: [-inf, -inf, -5.744, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8475, "number_of_timesteps": 143360, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3204 2 visits [1000.0, 1000.0, 758.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8475 q_vals: [-inf, -inf, -5.748, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3205 2 visits [1000.0, 1000.0, 759.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8479 q_vals: [-inf, -inf, -5.749, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3206 2 visits [1000.0, 1000.0, 760.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8482 q_vals: [-inf, -inf, -5.741, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3207 2 visits [1000.0, 1000.0, 761.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8482 q_vals: [-inf, -inf, -5.747, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3208 2 visits [1000.0, 1000.0, 762.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8484 q_vals: [-inf, -inf, -5.746, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8487, "number_of_timesteps": 143573, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3209 2 visits [1000.0, 1000.0, 763.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8487 q_vals: [-inf, -inf, -5.739, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3210 2 visits [1000.0, 1000.0, 764.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8491 q_vals: [-inf, -inf, -5.74, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3211 2 visits [1000.0, 1000.0, 765.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8492 q_vals: [-inf, -inf, -5.732, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3212 2 visits [1000.0, 1000.0, 766.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8495 q_vals: [-inf, -inf, -5.735, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8498, "number_of_timesteps": 143779, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3213 2 visits [1000.0, 1000.0, 767.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8498 q_vals: [-inf, -inf, -5.732, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3214 2 visits [1000.0, 1000.0, 768.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8499 q_vals: [-inf, -inf, -5.725, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3215 2 visits [1000.0, 1000.0, 769.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8499 q_vals: [-inf, -inf, -5.717, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3216 2 visits [1000.0, 1000.0, 770.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8502 q_vals: [-inf, -inf, -5.718, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3217 2 visits [1000.0, 1000.0, 771.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8504 q_vals: [-inf, -inf, -5.723, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3218 2 visits [1000.0, 1000.0, 772.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8505 q_vals: [-inf, -inf, -5.726, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8508, "number_of_timesteps": 144025, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3219 2 visits [1000.0, 1000.0, 773.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8508 q_vals: [-inf, -inf, -5.726, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3220 2 visits [1000.0, 1000.0, 774.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8510 q_vals: [-inf, -inf, -5.731, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3221 2 visits [1000.0, 1000.0, 775.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8513 q_vals: [-inf, -inf, -5.731, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3222 2 visits [1000.0, 1000.0, 776.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8514 q_vals: [-inf, -inf, -5.723, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3223 2 visits [1000.0, 1000.0, 777.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8517 q_vals: [-inf, -inf, -5.716, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8521, "number_of_timesteps": 144275, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3224 2 visits [1000.0, 1000.0, 778.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8521 q_vals: [-inf, -inf, -5.715, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3225 2 visits [1000.0, 1000.0, 779.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8523 q_vals: [-inf, -inf, -5.715, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3226 2 visits [1000.0, 1000.0, 780.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8524 q_vals: [-inf, -inf, -5.717, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3227 2 visits [1000.0, 1000.0, 781.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8526 q_vals: [-inf, -inf, -5.71, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3228 2 visits [1000.0, 1000.0, 782.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8528 q_vals: [-inf, -inf, -5.709, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3229 2 visits [1000.0, 1000.0, 783.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8530 q_vals: [-inf, -inf, -5.709, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8533, "number_of_timesteps": 144531, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3230 2 visits [1000.0, 1000.0, 784.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8533 q_vals: [-inf, -inf, -5.701, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3231 2 visits [1000.0, 1000.0, 785.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8535 q_vals: [-inf, -inf, -5.701, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3232 2 visits [1000.0, 1000.0, 786.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8538 q_vals: [-inf, -inf, -5.693, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3233 2 visits [1000.0, 1000.0, 787.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8542 q_vals: [-inf, -inf, -5.693, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8544, "number_of_timesteps": 144718, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3234 2 visits [1000.0, 1000.0, 788.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8544 q_vals: [-inf, -inf, -5.698, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3235 2 visits [1000.0, 1000.0, 789.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8548 q_vals: [-inf, -inf, -5.703, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3236 2 visits [1000.0, 1000.0, 790.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8551 q_vals: [-inf, -inf, -5.702, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8554, "number_of_timesteps": 144863, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3237 2 visits [1000.0, 1000.0, 791.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8554 q_vals: [-inf, -inf, -5.707, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3238 2 visits [1000.0, 1000.0, 792.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8557 q_vals: [-inf, -inf, -5.708, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3239 2 visits [1000.0, 1000.0, 793.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8561 q_vals: [-inf, -inf, -5.708, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3240 2 visits [1000.0, 1000.0, 794.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8563 q_vals: [-inf, -inf, -5.7, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8566, "number_of_timesteps": 145025, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3241 2 visits [1000.0, 1000.0, 795.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8566 q_vals: [-inf, -inf, -5.7, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3242 2 visits [1000.0, 1000.0, 796.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8570 q_vals: [-inf, -inf, -5.7, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3243 2 visits [1000.0, 1000.0, 797.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8573 q_vals: [-inf, -inf, -5.7, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8576, "number_of_timesteps": 145171, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3244 2 visits [1000.0, 1000.0, 798.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8576 q_vals: [-inf, -inf, -5.701, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3245 2 visits [1000.0, 1000.0, 799.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8580 q_vals: [-inf, -inf, -5.702, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3246 2 visits [1000.0, 1000.0, 800.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8583 q_vals: [-inf, -inf, -5.703, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3247 2 visits [1000.0, 1000.0, 801.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8585 q_vals: [-inf, -inf, -5.702, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8588, "number_of_timesteps": 145331, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3248 2 visits [1000.0, 1000.0, 802.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8588 q_vals: [-inf, -inf, -5.703, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3249 2 visits [1000.0, 1000.0, 803.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8591 q_vals: [-inf, -inf, -5.696, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3250 2 visits [1000.0, 1000.0, 804.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8593 q_vals: [-inf, -inf, -5.689, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8598, "number_of_timesteps": 145481, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3251 2 visits [1000.0, 1000.0, 805.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8598 q_vals: [-inf, -inf, -5.688, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3252 2 visits [1000.0, 1000.0, 806.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8599 q_vals: [-inf, -inf, -5.688, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3253 2 visits [1000.0, 1000.0, 807.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8602 q_vals: [-inf, -inf, -5.687, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3254 2 visits [1000.0, 1000.0, 808.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8603 q_vals: [-inf, -inf, -5.687, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8608, "number_of_timesteps": 145653, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3255 2 visits [1000.0, 1000.0, 809.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8608 q_vals: [-inf, -inf, -5.687, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3256 2 visits [1000.0, 1000.0, 810.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8611 q_vals: [-inf, -inf, -5.686, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3257 2 visits [1000.0, 1000.0, 811.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8613 q_vals: [-inf, -inf, -5.686, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3258 2 visits [1000.0, 1000.0, 812.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8616 q_vals: [-inf, -inf, -5.686, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8620, "number_of_timesteps": 145816, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3259 2 visits [1000.0, 1000.0, 813.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8620 q_vals: [-inf, -inf, -5.679, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3260 2 visits [1000.0, 1000.0, 814.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8620 q_vals: [-inf, -inf, -5.678, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3261 2 visits [1000.0, 1000.0, 815.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8623 q_vals: [-inf, -inf, -5.68, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3262 2 visits [1000.0, 1000.0, 816.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8629 q_vals: [-inf, -inf, -5.673, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3263 2 visits [1000.0, 1000.0, 817.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8629 q_vals: [-inf, -inf, -5.675, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8632, "number_of_timesteps": 146007, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3264 2 visits [1000.0, 1000.0, 818.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8632 q_vals: [-inf, -inf, -5.674, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3265 2 visits [1000.0, 1000.0, 819.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8636 q_vals: [-inf, -inf, -5.675, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3266 2 visits [1000.0, 1000.0, 820.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8640 q_vals: [-inf, -inf, -5.674, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8644, "number_of_timesteps": 146178, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3267 2 visits [1000.0, 1000.0, 821.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8644 q_vals: [-inf, -inf, -5.667, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3268 2 visits [1000.0, 1000.0, 822.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8647 q_vals: [-inf, -inf, -5.672, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3269 2 visits [1000.0, 1000.0, 823.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8649 q_vals: [-inf, -inf, -5.672, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3270 2 visits [1000.0, 1000.0, 824.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8651 q_vals: [-inf, -inf, -5.672, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3271 2 visits [1000.0, 1000.0, 825.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8652 q_vals: [-inf, -inf, -5.671, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3272 2 visits [1000.0, 1000.0, 826.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8653 q_vals: [-inf, -inf, -5.665, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8660, "number_of_timesteps": 146456, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3273 2 visits [1000.0, 1000.0, 827.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8660 q_vals: [-inf, -inf, -5.664, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3274 2 visits [1000.0, 1000.0, 828.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8662 q_vals: [-inf, -inf, -5.665, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3275 2 visits [1000.0, 1000.0, 829.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8663 q_vals: [-inf, -inf, -5.665, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3276 2 visits [1000.0, 1000.0, 830.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8666 q_vals: [-inf, -inf, -5.67, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3277 2 visits [1000.0, 1000.0, 831.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8668 q_vals: [-inf, -inf, -5.663, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3278 2 visits [1000.0, 1000.0, 832.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8668 q_vals: [-inf, -inf, -5.664, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8670, "number_of_timesteps": 146623, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3279 2 visits [1000.0, 1000.0, 833.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8670 q_vals: [-inf, -inf, -5.657, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3280 2 visits [1000.0, 1000.0, 834.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8675 q_vals: [-inf, -inf, -5.657, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3281 2 visits [1000.0, 1000.0, 835.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8676 q_vals: [-inf, -inf, -5.651, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3282 2 visits [1000.0, 1000.0, 836.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8676 q_vals: [-inf, -inf, -5.644, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8680, "number_of_timesteps": 146829, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3283 2 visits [1000.0, 1000.0, 837.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8680 q_vals: [-inf, -inf, -5.645, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3284 2 visits [1000.0, 1000.0, 838.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8683 q_vals: [-inf, -inf, -5.638, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3285 2 visits [1000.0, 1000.0, 839.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8685 q_vals: [-inf, -inf, -5.641, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3286 2 visits [1000.0, 1000.0, 840.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8686 q_vals: [-inf, -inf, -5.635, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3287 2 visits [1000.0, 1000.0, 841.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8689 q_vals: [-inf, -inf, -5.634, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8691, "number_of_timesteps": 147054, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3288 2 visits [1000.0, 1000.0, 842.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8691 q_vals: [-inf, -inf, -5.633, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3289 2 visits [1000.0, 1000.0, 843.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8693 q_vals: [-inf, -inf, -5.632, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3290 2 visits [1000.0, 1000.0, 844.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8694 q_vals: [-inf, -inf, -5.635, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3291 2 visits [1000.0, 1000.0, 845.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8697 q_vals: [-inf, -inf, -5.64, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8704, "number_of_timesteps": 147326, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3292 2 visits [1000.0, 1000.0, 846.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8704 q_vals: [-inf, -inf, -5.64, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3293 2 visits [1000.0, 1000.0, 847.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8704 q_vals: [-inf, -inf, -5.633, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3294 2 visits [1000.0, 1000.0, 848.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8708 q_vals: [-inf, -inf, -5.627, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3295 2 visits [1000.0, 1000.0, 849.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8710 q_vals: [-inf, -inf, -5.627, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8715, "number_of_timesteps": 147484, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3296 2 visits [1000.0, 1000.0, 850.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8715 q_vals: [-inf, -inf, -5.627, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3297 2 visits [1000.0, 1000.0, 851.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8719 q_vals: [-inf, -inf, -5.62, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3298 2 visits [1000.0, 1000.0, 852.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8721 q_vals: [-inf, -inf, -5.62, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8726, "number_of_timesteps": 147613, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3299 2 visits [1000.0, 1000.0, 853.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8726 q_vals: [-inf, -inf, -5.613, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3300 2 visits [1000.0, 1000.0, 854.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8729 q_vals: [-inf, -inf, -5.613, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3301 2 visits [1000.0, 1000.0, 855.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8732 q_vals: [-inf, -inf, -5.613, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8736, "number_of_timesteps": 147736, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3302 2 visits [1000.0, 1000.0, 856.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8736 q_vals: [-inf, -inf, -5.618, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3303 2 visits [1000.0, 1000.0, 857.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8740 q_vals: [-inf, -inf, -5.618, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3304 2 visits [1000.0, 1000.0, 858.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8741 q_vals: [-inf, -inf, -5.612, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8746, "number_of_timesteps": 147851, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3305 2 visits [1000.0, 1000.0, 859.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8746 q_vals: [-inf, -inf, -5.605, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3306 2 visits [1000.0, 1000.0, 860.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8749 q_vals: [-inf, -inf, -5.599, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3307 2 visits [1000.0, 1000.0, 861.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8752 q_vals: [-inf, -inf, -5.598, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8756, "number_of_timesteps": 147984, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3308 2 visits [1000.0, 1000.0, 862.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8756 q_vals: [-inf, -inf, -5.603, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3309 2 visits [1000.0, 1000.0, 863.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8759 q_vals: [-inf, -inf, -5.603, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3310 2 visits [1000.0, 1000.0, 864.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8762 q_vals: [-inf, -inf, -5.604, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8766, "number_of_timesteps": 148111, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3311 2 visits [1000.0, 1000.0, 865.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8766 q_vals: [-inf, -inf, -5.603, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3312 2 visits [1000.0, 1000.0, 866.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8767 q_vals: [-inf, -inf, -5.602, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3313 2 visits [1000.0, 1000.0, 867.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8771 q_vals: [-inf, -inf, -5.601, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8776, "number_of_timesteps": 148258, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3314 2 visits [1000.0, 1000.0, 868.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8776 q_vals: [-inf, -inf, -5.595, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3315 2 visits [1000.0, 1000.0, 869.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8778 q_vals: [-inf, -inf, -5.588, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3316 2 visits [1000.0, 1000.0, 870.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8780 q_vals: [-inf, -inf, -5.587, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3317 2 visits [1000.0, 1000.0, 871.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8783 q_vals: [-inf, -inf, -5.581, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3318 2 visits [1000.0, 1000.0, 872.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8784 q_vals: [-inf, -inf, -5.58, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8789, "number_of_timesteps": 148462, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3319 2 visits [1000.0, 1000.0, 873.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8789 q_vals: [-inf, -inf, -5.58, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3320 2 visits [1000.0, 1000.0, 874.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8791 q_vals: [-inf, -inf, -5.574, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3321 2 visits [1000.0, 1000.0, 875.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8794 q_vals: [-inf, -inf, -5.573, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3322 2 visits [1000.0, 1000.0, 876.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8797 q_vals: [-inf, -inf, -5.574, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8800, "number_of_timesteps": 148626, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3323 2 visits [1000.0, 1000.0, 877.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8800 q_vals: [-inf, -inf, -5.579, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3324 2 visits [1000.0, 1000.0, 878.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8803 q_vals: [-inf, -inf, -5.573, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3325 2 visits [1000.0, 1000.0, 879.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8806 q_vals: [-inf, -inf, -5.573, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3326 2 visits [1000.0, 1000.0, 880.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8807 q_vals: [-inf, -inf, -5.573, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8810, "number_of_timesteps": 148782, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3327 2 visits [1000.0, 1000.0, 881.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8810 q_vals: [-inf, -inf, -5.572, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3328 2 visits [1000.0, 1000.0, 882.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8813 q_vals: [-inf, -inf, -5.566, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3329 2 visits [1000.0, 1000.0, 883.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8816 q_vals: [-inf, -inf, -5.569, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3330 2 visits [1000.0, 1000.0, 884.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8819 q_vals: [-inf, -inf, -5.563, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8822, "number_of_timesteps": 148987, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3331 2 visits [1000.0, 1000.0, 885.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8822 q_vals: [-inf, -inf, -5.568, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3332 2 visits [1000.0, 1000.0, 886.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8824 q_vals: [-inf, -inf, -5.561, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3333 2 visits [1000.0, 1000.0, 887.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8826 q_vals: [-inf, -inf, -5.562, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3334 2 visits [1000.0, 1000.0, 888.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8829 q_vals: [-inf, -inf, -5.561, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3335 2 visits [1000.0, 1000.0, 889.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8829 q_vals: [-inf, -inf, -5.554, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3336 2 visits [1000.0, 1000.0, 890.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8831 q_vals: [-inf, -inf, -5.555, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8834, "number_of_timesteps": 149201, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3337 2 visits [1000.0, 1000.0, 891.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8834 q_vals: [-inf, -inf, -5.554, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3338 2 visits [1000.0, 1000.0, 892.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8837 q_vals: [-inf, -inf, -5.553, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3339 2 visits [1000.0, 1000.0, 893.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8838 q_vals: [-inf, -inf, -5.547, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3340 2 visits [1000.0, 1000.0, 894.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8840 q_vals: [-inf, -inf, -5.552, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8844, "number_of_timesteps": 149425, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3341 2 visits [1000.0, 1000.0, 895.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8844 q_vals: [-inf, -inf, -5.551, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3342 2 visits [1000.0, 1000.0, 896.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8844 q_vals: [-inf, -inf, -5.55, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3343 2 visits [1000.0, 1000.0, 897.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8844 q_vals: [-inf, -inf, -5.55, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
[1000.0, 1000.0, 898.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8848 q_vals: [-inf, -inf, -5.55, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3345 2 visits [1000.0, 1000.0, 899.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8850 q_vals: [-inf, -inf, -5.549, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3346 2 visits [1000.0, 1000.0, 900.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8852 q_vals: [-inf, -inf, -5.549, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8855, "number_of_timesteps": 149659, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3347 2 visits [1000.0, 1000.0, 901.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8855 q_vals: [-inf, -inf, -5.549, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3348 2 visits [1000.0, 1000.0, 902.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8857 q_vals: [-inf, -inf, -5.548, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3349 2 visits [1000.0, 1000.0, 903.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8861 q_vals: [-inf, -inf, -5.549, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3350 2 visits [1000.0, 1000.0, 904.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8863 q_vals: [-inf, -inf, -5.549, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8867, "number_of_timesteps": 149884, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3351 2 visits [1000.0, 1000.0, 905.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8867 q_vals: [-inf, -inf, -5.543, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3352 2 visits [1000.0, 1000.0, 906.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8867 q_vals: [-inf, -inf, -5.542, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3353 2 visits [1000.0, 1000.0, 907.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8872 q_vals: [-inf, -inf, -5.544, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3354 2 visits [1000.0, 1000.0, 908.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8874 q_vals: [-inf, -inf, -5.544, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3355 2 visits [1000.0, 1000.0, 909.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8875 q_vals: [-inf, -inf, -5.543, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8879, "number_of_timesteps": 150110, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3356 2 visits [1000.0, 1000.0, 910.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8879 q_vals: [-inf, -inf, -5.537, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3357 2 visits [1000.0, 1000.0, 911.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8882 q_vals: [-inf, -inf, -5.537, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3358 2 visits [1000.0, 1000.0, 912.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8883 q_vals: [-inf, -inf, -5.54, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3359 2 visits [1000.0, 1000.0, 913.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8885 q_vals: [-inf, -inf, -5.545, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8889, "number_of_timesteps": 150261, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3360 2 visits [1000.0, 1000.0, 914.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8889 q_vals: [-inf, -inf, -5.543, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3361 2 visits [1000.0, 1000.0, 915.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8890 q_vals: [-inf, -inf, -5.537, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3362 2 visits [1000.0, 1000.0, 916.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8891 q_vals: [-inf, -inf, -5.531, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3363 2 visits [1000.0, 1000.0, 917.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8895 q_vals: [-inf, -inf, -5.525, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3364 2 visits [1000.0, 1000.0, 918.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8897 q_vals: [-inf, -inf, -5.519, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8899, "number_of_timesteps": 150453, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3365 2 visits [1000.0, 1000.0, 919.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8899 q_vals: [-inf, -inf, -5.519, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3366 2 visits [1000.0, 1000.0, 920.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8903 q_vals: [-inf, -inf, -5.518, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3367 2 visits [1000.0, 1000.0, 921.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8906 q_vals: [-inf, -inf, -5.512, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3368 2 visits [1000.0, 1000.0, 922.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8906 q_vals: [-inf, -inf, -5.511, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8909, "number_of_timesteps": 150659, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3369 2 visits [1000.0, 1000.0, 923.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8909 q_vals: [-inf, -inf, -5.51, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3370 2 visits [1000.0, 1000.0, 924.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8913 q_vals: [-inf, -inf, -5.511, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3371 2 visits [1000.0, 1000.0, 925.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8915 q_vals: [-inf, -inf, -5.505, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3372 2 visits [1000.0, 1000.0, 926.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8916 q_vals: [-inf, -inf, -5.499, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8920, "number_of_timesteps": 150868, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3373 2 visits [1000.0, 1000.0, 927.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8920 q_vals: [-inf, -inf, -5.498, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
[-inf, -inf, -5.499, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3375 2 visits [1000.0, 1000.0, 929.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8928 q_vals: [-inf, -inf, -5.499, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8930, "number_of_timesteps": 151031, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3376 2 visits [1000.0, 1000.0, 930.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8930 q_vals: [-inf, -inf, -5.498, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3377 2 visits [1000.0, 1000.0, 931.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8932 q_vals: [-inf, -inf, -5.492, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3378 2 visits [1000.0, 1000.0, 932.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8935 q_vals: [-inf, -inf, -5.493, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3379 2 visits [1000.0, 1000.0, 933.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8938 q_vals: [-inf, -inf, -5.498, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8942, "number_of_timesteps": 151193, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3380 2 visits [1000.0, 1000.0, 934.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8942 q_vals: [-inf, -inf, -5.498, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3381 2 visits [1000.0, 1000.0, 935.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8943 q_vals: [-inf, -inf, -5.498, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3382 2 visits [1000.0, 1000.0, 936.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8946 q_vals: [-inf, -inf, -5.497, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3383 2 visits [1000.0, 1000.0, 937.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8949 q_vals: [-inf, -inf, -5.496, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3384 2 visits [1000.0, 1000.0, 938.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8951 q_vals: [-inf, -inf, -5.49, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8954, "number_of_timesteps": 151399, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3385 2 visits [1000.0, 1000.0, 939.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8954 q_vals: [-inf, -inf, -5.489, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3386 2 visits [1000.0, 1000.0, 940.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8958 q_vals: [-inf, -inf, -5.494, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3387 2 visits [1000.0, 1000.0, 941.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8961 q_vals: [-inf, -inf, -5.488, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8964, "number_of_timesteps": 151552, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3388 2 visits [1000.0, 1000.0, 942.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8964 q_vals: [-inf, -inf, -5.487, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3389 2 visits [1000.0, 1000.0, 943.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8967 q_vals: [-inf, -inf, -5.492, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3390 2 visits [1000.0, 1000.0, 944.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8970 q_vals: [-inf, -inf, -5.491, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3391 2 visits [1000.0, 1000.0, 945.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8970 q_vals: [-inf, -inf, -5.485, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3392 2 visits [1000.0, 1000.0, 946.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8973 q_vals: [-inf, -inf, -5.479, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8974, "number_of_timesteps": 151701, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3393 2 visits [1000.0, 1000.0, 947.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8974 q_vals: [-inf, -inf, -5.478, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3394 2 visits [1000.0, 1000.0, 948.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8979 q_vals: [-inf, -inf, -5.478, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3395 2 visits [1000.0, 1000.0, 949.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8982 q_vals: [-inf, -inf, -5.472, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8985, "number_of_timesteps": 151907, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3396 2 visits [1000.0, 1000.0, 950.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8985 q_vals: [-inf, -inf, -5.471, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3397 2 visits [1000.0, 1000.0, 951.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8987 q_vals: [-inf, -inf, -5.466, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3398 2 visits [1000.0, 1000.0, 952.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8988 q_vals: [-inf, -inf, -5.47, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3399 2 visits [1000.0, 1000.0, 953.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8991 q_vals: [-inf, -inf, -5.469, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3400 2 visits [1000.0, 1000.0, 954.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8994 q_vals: [-inf, -inf, -5.463, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 8996, "number_of_timesteps": 152113, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3401 2 visits [1000.0, 1000.0, 955.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8996 q_vals: [-inf, -inf, -5.458, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3402 2 visits [1000.0, 1000.0, 956.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8996 q_vals: [-inf, -inf, -5.452, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3403 2 visits [1000.0, 1000.0, 957.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 8998 q_vals: [-inf, -inf, -5.446, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
[-inf, -inf, -5.445, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3405 2 visits [1000.0, 1000.0, 959.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9001 q_vals: [-inf, -inf, -5.444, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3406 2 visits [1000.0, 1000.0, 960.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9005 q_vals: [-inf, -inf, -5.444, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 9007, "number_of_timesteps": 152376, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3407 2 visits [1000.0, 1000.0, 961.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9007 q_vals: [-inf, -inf, -5.449, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3408 2 visits [1000.0, 1000.0, 962.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9011 q_vals: [-inf, -inf, -5.454, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3409 2 visits [1000.0, 1000.0, 963.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9013 q_vals: [-inf, -inf, -5.448, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3410 2 visits [1000.0, 1000.0, 964.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9014 q_vals: [-inf, -inf, -5.442, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 9017, "number_of_timesteps": 152532, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3411 2 visits [1000.0, 1000.0, 965.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9017 q_vals: [-inf, -inf, -5.437, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3412 2 visits [1000.0, 1000.0, 966.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9021 q_vals: [-inf, -inf, -5.431, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3413 2 visits [1000.0, 1000.0, 967.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9021 q_vals: [-inf, -inf, -5.43, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3414 2 visits [1000.0, 1000.0, 968.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9025 q_vals: [-inf, -inf, -5.43, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 9027, "number_of_timesteps": 152748, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3415 2 visits [1000.0, 1000.0, 969.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9027 q_vals: [-inf, -inf, -5.43, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3416 2 visits [1000.0, 1000.0, 970.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9027 q_vals: [-inf, -inf, -5.429, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3417 2 visits [1000.0, 1000.0, 971.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9029 q_vals: [-inf, -inf, -5.423, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3418 2 visits [1000.0, 1000.0, 972.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9032 q_vals: [-inf, -inf, -5.422, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3419 2 visits [1000.0, 1000.0, 973.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9033 q_vals: [-inf, -inf, -5.424, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3420 2 visits [1000.0, 1000.0, 974.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9034 q_vals: [-inf, -inf, -5.428, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 9039, "number_of_timesteps": 153021, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3421 2 visits [1000.0, 1000.0, 975.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9039 q_vals: [-inf, -inf, -5.425, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3422 2 visits [1000.0, 1000.0, 976.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9041 q_vals: [-inf, -inf, -5.425, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3423 2 visits [1000.0, 1000.0, 977.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9042 q_vals: [-inf, -inf, -5.426, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3424 2 visits [1000.0, 1000.0, 978.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9044 q_vals: [-inf, -inf, -5.42, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3425 2 visits [1000.0, 1000.0, 979.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9045 q_vals: [-inf, -inf, -5.415, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3426 2 visits [1000.0, 1000.0, 980.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9048 q_vals: [-inf, -inf, -5.413, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 9050, "number_of_timesteps": 153278, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3427 2 visits [1000.0, 1000.0, 981.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9050 q_vals: [-inf, -inf, -5.408, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3428 2 visits [1000.0, 1000.0, 982.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9051 q_vals: [-inf, -inf, -5.407, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3429 2 visits [1000.0, 1000.0, 983.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9053 q_vals: [-inf, -inf, -5.412, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3430 2 visits [1000.0, 1000.0, 984.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9059 q_vals: [-inf, -inf, -5.41, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 9060, "number_of_timesteps": 153500, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3431 2 visits [1000.0, 1000.0, 985.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9060 q_vals: [-inf, -inf, -5.405, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3432 2 visits [1000.0, 1000.0, 986.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9061 q_vals: [-inf, -inf, -5.404, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3433 2 visits [1000.0, 1000.0, 987.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9066 q_vals: [-inf, -inf, -5.399, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3434 2 visits [1000.0, 1000.0, 988.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9068 q_vals: [-inf, -inf, -5.398, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 9070, "number_of_timesteps": 153656, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3435 2 visits [1000.0, 1000.0, 989.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9070 q_vals: [-inf, -inf, -5.398, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3436 2 visits [1000.0, 1000.0, 990.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9072 q_vals: [-inf, -inf, -5.392, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3437 2 visits [1000.0, 1000.0, 991.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9075 q_vals: [-inf, -inf, -5.387, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3438 2 visits [1000.0, 1000.0, 992.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9075 q_vals: [-inf, -inf, -5.387, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3439 2 visits [1000.0, 1000.0, 993.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9079 q_vals: [-inf, -inf, -5.387, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 9081, "number_of_timesteps": 153869, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3440 2 visits [1000.0, 1000.0, 994.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9081 q_vals: [-inf, -inf, -5.388, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3441 2 visits [1000.0, 1000.0, 995.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9082 q_vals: [-inf, -inf, -5.387, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3442 2 visits [1000.0, 1000.0, 996.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9086 q_vals: [-inf, -inf, -5.381, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3443 2 visits [1000.0, 1000.0, 997.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9088 q_vals: [-inf, -inf, -5.379, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3444 2 visits [1000.0, 1000.0, 998.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9089 q_vals: [-inf, -inf, -5.38, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
Step 3445 2 visits [1000.0, 1000.0, 999.0, 1.0, 3.0, 49.0, 2.0, 2.0, 3.0, 6.0]  episode_count: 9090 q_vals: [-inf, -inf, -5.375, -24.49, -11.429, -8.09, -9.796, -9.724, -11.429, -8.98]
{"total_number_of_episodes": 9093, "number_of_timesteps": 154114, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3446 2 visits [1000.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 9093 q_vals: [-inf, -inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
{"total_number_of_episodes": 9103, "number_of_timesteps": 154350, "per_episode_reward": 9.8, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 1.3999999999999986},
{"total_number_of_episodes": 9116, "number_of_timesteps": 154595, "per_episode_reward": 9.8, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 1.3999999999999986},
{"total_number_of_episodes": 9126, "number_of_timesteps": 154777, "per_episode_reward": 9.8, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 1.3999999999999986},
{"total_number_of_episodes": 9139, "number_of_timesteps": 155004, "per_episode_reward": 9.85, "episode_reward_trend_value": -0.014999999999999996, "biggest_recent_change": 1.3999999999999986},
{"total_number_of_episodes": 9150, "number_of_timesteps": 155215, "per_episode_reward": 9.9, "episode_reward_trend_value": -0.014444444444444432, "biggest_recent_change": 1.3999999999999986},
{"total_number_of_episodes": 9163, "number_of_timesteps": 155421, "per_episode_reward": 9.9, "episode_reward_trend_value": -0.014444444444444432, "biggest_recent_change": 1.3999999999999986},
{"total_number_of_episodes": 9175, "number_of_timesteps": 155647, "per_episode_reward": 9.9, "episode_reward_trend_value": -0.014444444444444432, "biggest_recent_change": 1.3999999999999986},
{"total_number_of_episodes": 9185, "number_of_timesteps": 155796, "per_episode_reward": 9.9, "episode_reward_trend_value": -0.014444444444444432, "biggest_recent_change": 1.3999999999999986},
{"total_number_of_episodes": 9195, "number_of_timesteps": 155971, "per_episode_reward": 9.9, "episode_reward_trend_value": -0.014444444444444432, "biggest_recent_change": 1.3999999999999986},
{"total_number_of_episodes": 9206, "number_of_timesteps": 156158, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9217, "number_of_timesteps": 156363, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9227, "number_of_timesteps": 156533, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9238, "number_of_timesteps": 156756, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9249, "number_of_timesteps": 156993, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9260, "number_of_timesteps": 157249, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9271, "number_of_timesteps": 157475, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9281, "number_of_timesteps": 157708, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9292, "number_of_timesteps": 157940, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9303, "number_of_timesteps": 158155, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9315, "number_of_timesteps": 158372, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9325, "number_of_timesteps": 158538, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9335, "number_of_timesteps": 158715, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9347, "number_of_timesteps": 158953, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9357, "number_of_timesteps": 159133, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9367, "number_of_timesteps": 159311, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9377, "number_of_timesteps": 159487, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9388, "number_of_timesteps": 159753, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9398, "number_of_timesteps": 159957, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9408, "number_of_timesteps": 160137, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9420, "number_of_timesteps": 160410, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9431, "number_of_timesteps": 160653, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9442, "number_of_timesteps": 160854, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9454, "number_of_timesteps": 161068, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9464, "number_of_timesteps": 161188, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9479, "number_of_timesteps": 161402, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9493, "number_of_timesteps": 161561, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9503, "number_of_timesteps": 161686, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9513, "number_of_timesteps": 161803, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9524, "number_of_timesteps": 161943, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9538, "number_of_timesteps": 162127, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9548, "number_of_timesteps": 162250, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9560, "number_of_timesteps": 162409, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9571, "number_of_timesteps": 162581, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9582, "number_of_timesteps": 162763, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9595, "number_of_timesteps": 163042, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9605, "number_of_timesteps": 163222, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9619, "number_of_timesteps": 163462, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9630, "number_of_timesteps": 163621, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9644, "number_of_timesteps": 163817, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9654, "number_of_timesteps": 163946, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9667, "number_of_timesteps": 164124, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9678, "number_of_timesteps": 164301, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9690, "number_of_timesteps": 164495, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9701, "number_of_timesteps": 164746, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9713, "number_of_timesteps": 164929, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9724, "number_of_timesteps": 165164, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9734, "number_of_timesteps": 165325, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9744, "number_of_timesteps": 165496, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9755, "number_of_timesteps": 165738, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9768, "number_of_timesteps": 166015, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9778, "number_of_timesteps": 166192, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9789, "number_of_timesteps": 166380, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9800, "number_of_timesteps": 166554, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9810, "number_of_timesteps": 166729, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9820, "number_of_timesteps": 166925, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9830, "number_of_timesteps": 167091, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9842, "number_of_timesteps": 167318, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9852, "number_of_timesteps": 167532, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9862, "number_of_timesteps": 167708, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9872, "number_of_timesteps": 167886, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9883, "number_of_timesteps": 168094, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9895, "number_of_timesteps": 168332, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9906, "number_of_timesteps": 168618, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9919, "number_of_timesteps": 168847, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9929, "number_of_timesteps": 169082, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9939, "number_of_timesteps": 169308, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9949, "number_of_timesteps": 169527, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9959, "number_of_timesteps": 169721, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9969, "number_of_timesteps": 169864, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9982, "number_of_timesteps": 170078, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9993, "number_of_timesteps": 170271, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10005, "number_of_timesteps": 170493, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10017, "number_of_timesteps": 170727, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10028, "number_of_timesteps": 170932, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10039, "number_of_timesteps": 171105, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10050, "number_of_timesteps": 171336, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10061, "number_of_timesteps": 171565, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10072, "number_of_timesteps": 171821, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10082, "number_of_timesteps": 172088, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10094, "number_of_timesteps": 172314, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10104, "number_of_timesteps": 172553, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10114, "number_of_timesteps": 172833, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10125, "number_of_timesteps": 173049, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10135, "number_of_timesteps": 173265, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10146, "number_of_timesteps": 173513, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10159, "number_of_timesteps": 173836, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10172, "number_of_timesteps": 174138, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10182, "number_of_timesteps": 174334, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10192, "number_of_timesteps": 174506, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10204, "number_of_timesteps": 174737, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10215, "number_of_timesteps": 174911, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10225, "number_of_timesteps": 175058, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10236, "number_of_timesteps": 175258, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10247, "number_of_timesteps": 175458, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10257, "number_of_timesteps": 175618, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10269, "number_of_timesteps": 175765, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10280, "number_of_timesteps": 175916, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10293, "number_of_timesteps": 176107, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10304, "number_of_timesteps": 176258, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10316, "number_of_timesteps": 176483, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10328, "number_of_timesteps": 176713, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10339, "number_of_timesteps": 176919, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10354, "number_of_timesteps": 177231, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10364, "number_of_timesteps": 177391, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10374, "number_of_timesteps": 177508, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10386, "number_of_timesteps": 177705, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10398, "number_of_timesteps": 177924, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10411, "number_of_timesteps": 178195, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10424, "number_of_timesteps": 178410, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10434, "number_of_timesteps": 178592, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10445, "number_of_timesteps": 178816, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10457, "number_of_timesteps": 179025, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10467, "number_of_timesteps": 179189, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10477, "number_of_timesteps": 179362, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10487, "number_of_timesteps": 179542, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10498, "number_of_timesteps": 179772, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10508, "number_of_timesteps": 179924, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10519, "number_of_timesteps": 180164, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10529, "number_of_timesteps": 180388, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10539, "number_of_timesteps": 180612, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10550, "number_of_timesteps": 180802, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10560, "number_of_timesteps": 181009, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10573, "number_of_timesteps": 181374, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10583, "number_of_timesteps": 181612, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10593, "number_of_timesteps": 181786, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10605, "number_of_timesteps": 181989, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 10615, "number_of_timesteps": 182182, "per_episode_reward": 9.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 10625, "number_of_timesteps": 182354, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 10636, "number_of_timesteps": 182630, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 10646, "number_of_timesteps": 182818, "per_episode_reward": 9.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 10656, "number_of_timesteps": 183049, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 10667, "number_of_timesteps": 183299, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 10678, "number_of_timesteps": 183488, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 10688, "number_of_timesteps": 183705, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 10699, "number_of_timesteps": 183903, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10709, "number_of_timesteps": 184079, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10723, "number_of_timesteps": 184330, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10735, "number_of_timesteps": 184560, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10745, "number_of_timesteps": 184736, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10756, "number_of_timesteps": 184972, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10766, "number_of_timesteps": 185149, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10778, "number_of_timesteps": 185377, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10789, "number_of_timesteps": 185668, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10800, "number_of_timesteps": 185933, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10811, "number_of_timesteps": 186292, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10821, "number_of_timesteps": 186492, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10831, "number_of_timesteps": 186726, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10841, "number_of_timesteps": 186941, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10851, "number_of_timesteps": 187209, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10863, "number_of_timesteps": 187469, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10873, "number_of_timesteps": 187689, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10883, "number_of_timesteps": 187923, "per_episode_reward": 10.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10894, "number_of_timesteps": 188152, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10907, "number_of_timesteps": 188528, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10918, "number_of_timesteps": 188718, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10930, "number_of_timesteps": 188995, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10942, "number_of_timesteps": 189247, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10952, "number_of_timesteps": 189557, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10962, "number_of_timesteps": 189832, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10973, "number_of_timesteps": 190104, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10983, "number_of_timesteps": 190354, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 10993, "number_of_timesteps": 190601, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11003, "number_of_timesteps": 190831, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11014, "number_of_timesteps": 191101, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11024, "number_of_timesteps": 191296, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11034, "number_of_timesteps": 191466, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11047, "number_of_timesteps": 191725, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11059, "number_of_timesteps": 191982, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11070, "number_of_timesteps": 192216, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11080, "number_of_timesteps": 192520, "per_episode_reward": 10.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11090, "number_of_timesteps": 192879, "per_episode_reward": 10.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11100, "number_of_timesteps": 193078, "per_episode_reward": 10.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11111, "number_of_timesteps": 193299, "per_episode_reward": 10.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11121, "number_of_timesteps": 193547, "per_episode_reward": 10.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11133, "number_of_timesteps": 193924, "per_episode_reward": 10.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11144, "number_of_timesteps": 194192, "per_episode_reward": 10.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11155, "number_of_timesteps": 194473, "per_episode_reward": 10.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11166, "number_of_timesteps": 194748, "per_episode_reward": 10.25, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11176, "number_of_timesteps": 195026, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11189, "number_of_timesteps": 195401, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11199, "number_of_timesteps": 195659, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11209, "number_of_timesteps": 195937, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11220, "number_of_timesteps": 196441, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11231, "number_of_timesteps": 196709, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11241, "number_of_timesteps": 196998, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11251, "number_of_timesteps": 197240, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11263, "number_of_timesteps": 197635, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11273, "number_of_timesteps": 197905, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11283, "number_of_timesteps": 198171, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11293, "number_of_timesteps": 198612, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11303, "number_of_timesteps": 198862, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11313, "number_of_timesteps": 199158, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11323, "number_of_timesteps": 199360, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11335, "number_of_timesteps": 199686, "per_episode_reward": 10.35, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 11347, "number_of_timesteps": 200001, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11357, "number_of_timesteps": 200297, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11367, "number_of_timesteps": 200644, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11378, "number_of_timesteps": 200957, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11389, "number_of_timesteps": 201171, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11399, "number_of_timesteps": 201383, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11409, "number_of_timesteps": 201601, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11419, "number_of_timesteps": 202001, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11430, "number_of_timesteps": 202222, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11440, "number_of_timesteps": 202463, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11452, "number_of_timesteps": 202758, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11462, "number_of_timesteps": 203066, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11472, "number_of_timesteps": 203425, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11482, "number_of_timesteps": 203744, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11492, "number_of_timesteps": 204100, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11503, "number_of_timesteps": 204551, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11513, "number_of_timesteps": 204874, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11524, "number_of_timesteps": 205177, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11534, "number_of_timesteps": 205433, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11544, "number_of_timesteps": 205663, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11556, "number_of_timesteps": 205971, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11567, "number_of_timesteps": 206315, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11579, "number_of_timesteps": 206716, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11589, "number_of_timesteps": 206969, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11600, "number_of_timesteps": 207240, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11612, "number_of_timesteps": 207492, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11622, "number_of_timesteps": 207823, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11633, "number_of_timesteps": 208152, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11644, "number_of_timesteps": 208537, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11654, "number_of_timesteps": 208771, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11665, "number_of_timesteps": 209087, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11675, "number_of_timesteps": 209276, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11687, "number_of_timesteps": 209638, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11697, "number_of_timesteps": 210032, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11708, "number_of_timesteps": 210387, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11719, "number_of_timesteps": 210681, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11729, "number_of_timesteps": 211020, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11740, "number_of_timesteps": 211316, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11750, "number_of_timesteps": 211666, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11760, "number_of_timesteps": 211924, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11770, "number_of_timesteps": 212300, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11780, "number_of_timesteps": 212568, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11790, "number_of_timesteps": 212870, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11801, "number_of_timesteps": 213270, "per_episode_reward": 10.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 11811, "number_of_timesteps": 213720, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11822, "number_of_timesteps": 214110, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11832, "number_of_timesteps": 214679, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11844, "number_of_timesteps": 215092, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11854, "number_of_timesteps": 215473, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11865, "number_of_timesteps": 215935, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11875, "number_of_timesteps": 216393, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11885, "number_of_timesteps": 216742, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11896, "number_of_timesteps": 217200, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11906, "number_of_timesteps": 217574, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11916, "number_of_timesteps": 217995, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11927, "number_of_timesteps": 218511, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11939, "number_of_timesteps": 219093, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11949, "number_of_timesteps": 219338, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11960, "number_of_timesteps": 219743, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11971, "number_of_timesteps": 220248, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11981, "number_of_timesteps": 220565, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11992, "number_of_timesteps": 220974, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12003, "number_of_timesteps": 221483, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12013, "number_of_timesteps": 221938, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12024, "number_of_timesteps": 222557, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12035, "number_of_timesteps": 223027, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12046, "number_of_timesteps": 223462, "per_episode_reward": 10.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12056, "number_of_timesteps": 224062, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12067, "number_of_timesteps": 224529, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12077, "number_of_timesteps": 224884, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12088, "number_of_timesteps": 225435, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12098, "number_of_timesteps": 225802, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12109, "number_of_timesteps": 226369, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12121, "number_of_timesteps": 226847, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12132, "number_of_timesteps": 227313, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12142, "number_of_timesteps": 227603, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 12152, "number_of_timesteps": 228086, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12164, "number_of_timesteps": 228686, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12175, "number_of_timesteps": 228985, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12185, "number_of_timesteps": 229280, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12197, "number_of_timesteps": 229695, "per_episode_reward": 10.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12208, "number_of_timesteps": 230154, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12218, "number_of_timesteps": 230672, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12228, "number_of_timesteps": 231193, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12239, "number_of_timesteps": 231615, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12250, "number_of_timesteps": 232278, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12260, "number_of_timesteps": 232776, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12270, "number_of_timesteps": 233420, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12281, "number_of_timesteps": 234065, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12291, "number_of_timesteps": 234785, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 12301, "number_of_timesteps": 235190, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12311, "number_of_timesteps": 235581, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12321, "number_of_timesteps": 236321, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12331, "number_of_timesteps": 237025, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12342, "number_of_timesteps": 238007, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12353, "number_of_timesteps": 238777, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12364, "number_of_timesteps": 239573, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12374, "number_of_timesteps": 240223, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12384, "number_of_timesteps": 240933, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12394, "number_of_timesteps": 241939, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12404, "number_of_timesteps": 242770, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12417, "number_of_timesteps": 244125, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12427, "number_of_timesteps": 245123, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12437, "number_of_timesteps": 246007, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12447, "number_of_timesteps": 246892, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12457, "number_of_timesteps": 247896, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12467, "number_of_timesteps": 248678, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12477, "number_of_timesteps": 249600, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12487, "number_of_timesteps": 250281, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12497, "number_of_timesteps": 251401, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12507, "number_of_timesteps": 252721, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12517, "number_of_timesteps": 254162, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12527, "number_of_timesteps": 255219, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12537, "number_of_timesteps": 255990, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12547, "number_of_timesteps": 257037, "per_episode_reward": 10.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12557, "number_of_timesteps": 258430, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12567, "number_of_timesteps": 259711, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12578, "number_of_timesteps": 260788, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12588, "number_of_timesteps": 262500, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12598, "number_of_timesteps": 264092, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12608, "number_of_timesteps": 265852, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12618, "number_of_timesteps": 267862, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12628, "number_of_timesteps": 269386, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12638, "number_of_timesteps": 270982, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12649, "number_of_timesteps": 273445, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12659, "number_of_timesteps": 275475, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12669, "number_of_timesteps": 277684, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12679, "number_of_timesteps": 279739, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12689, "number_of_timesteps": 281966, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12699, "number_of_timesteps": 283966, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12710, "number_of_timesteps": 286139, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12721, "number_of_timesteps": 287794, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12731, "number_of_timesteps": 289244, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12741, "number_of_timesteps": 290495, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12751, "number_of_timesteps": 293028, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12761, "number_of_timesteps": 294879, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12771, "number_of_timesteps": 296934, "per_episode_reward": 10.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12781, "number_of_timesteps": 297778, "per_episode_reward": 10.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12791, "number_of_timesteps": 299761, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12801, "number_of_timesteps": 300838, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12813, "number_of_timesteps": 302179, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12823, "number_of_timesteps": 302361, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12833, "number_of_timesteps": 302882, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12844, "number_of_timesteps": 304696, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12855, "number_of_timesteps": 305628, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12865, "number_of_timesteps": 306601, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12876, "number_of_timesteps": 308991, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12886, "number_of_timesteps": 311182, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12896, "number_of_timesteps": 312920, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12907, "number_of_timesteps": 315015, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12917, "number_of_timesteps": 318311, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12927, "number_of_timesteps": 321043, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12937, "number_of_timesteps": 324075, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 12947, "number_of_timesteps": 327284, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12957, "number_of_timesteps": 331203, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12967, "number_of_timesteps": 334636, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12977, "number_of_timesteps": 338279, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12987, "number_of_timesteps": 342606, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12997, "number_of_timesteps": 346913, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13007, "number_of_timesteps": 351701, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13017, "number_of_timesteps": 356387, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13027, "number_of_timesteps": 361205, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13038, "number_of_timesteps": 366327, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13049, "number_of_timesteps": 371533, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13059, "number_of_timesteps": 375825, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13069, "number_of_timesteps": 380566, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13079, "number_of_timesteps": 385310, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13089, "number_of_timesteps": 389843, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13099, "number_of_timesteps": 394330, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13109, "number_of_timesteps": 399123, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13119, "number_of_timesteps": 403432, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13129, "number_of_timesteps": 408432, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13139, "number_of_timesteps": 413170, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13149, "number_of_timesteps": 417751, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13159, "number_of_timesteps": 422484, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13169, "number_of_timesteps": 427346, "per_episode_reward": 11.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13179, "number_of_timesteps": 432346, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13189, "number_of_timesteps": 437172, "per_episode_reward": 11.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13199, "number_of_timesteps": 442172, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13209, "number_of_timesteps": 447172, "per_episode_reward": 11.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13219, "number_of_timesteps": 452172, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13229, "number_of_timesteps": 457100, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13239, "number_of_timesteps": 461741, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13250, "number_of_timesteps": 466719, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13260, "number_of_timesteps": 471719, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13270, "number_of_timesteps": 476719, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13280, "number_of_timesteps": 480730, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13290, "number_of_timesteps": 485730, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13300, "number_of_timesteps": 490450, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},

{"total_number_of_episodes": 13310, "number_of_timesteps": 495041, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13320, "number_of_timesteps": 500041, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 13330, "number_of_timesteps": 505039, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13340, "number_of_timesteps": 509927, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13350, "number_of_timesteps": 514364, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13360, "number_of_timesteps": 519364, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13370, "number_of_timesteps": 524115, "per_episode_reward": 11.35, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 13380, "number_of_timesteps": 529115, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13390, "number_of_timesteps": 533973, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13400, "number_of_timesteps": 538973, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},

{"total_number_of_episodes": 13411, "number_of_timesteps": 543875, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13421, "number_of_timesteps": 548875, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13431, "number_of_timesteps": 553875, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13442, "number_of_timesteps": 559273, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13452, "number_of_timesteps": 564236, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13462, "number_of_timesteps": 569236, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13472, "number_of_timesteps": 574236, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13482, "number_of_timesteps": 579236, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13492, "number_of_timesteps": 584236, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13502, "number_of_timesteps": 588970, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13512, "number_of_timesteps": 593695, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13522, "number_of_timesteps": 598451, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13532, "number_of_timesteps": 603238, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13542, "number_of_timesteps": 608058, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13552, "number_of_timesteps": 613058, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13562, "number_of_timesteps": 617984, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13572, "number_of_timesteps": 622984, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13582, "number_of_timesteps": 627984, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 13592, "number_of_timesteps": 632896, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},

{"total_number_of_episodes": 13602, "number_of_timesteps": 637896, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13612, "number_of_timesteps": 642896, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13622, "number_of_timesteps": 647896, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13632, "number_of_timesteps": 652286, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13642, "number_of_timesteps": 657286, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13652, "number_of_timesteps": 662286, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13662, "number_of_timesteps": 667286, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13672, "number_of_timesteps": 672114, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13682, "number_of_timesteps": 677114, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13692, "number_of_timesteps": 681996, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13702, "number_of_timesteps": 686996, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13712, "number_of_timesteps": 691860, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13722, "number_of_timesteps": 696860, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13732, "number_of_timesteps": 701730, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13742, "number_of_timesteps": 706329, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13752, "number_of_timesteps": 710990, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13762, "number_of_timesteps": 715365, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13772, "number_of_timesteps": 720319, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13782, "number_of_timesteps": 725221, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13792, "number_of_timesteps": 729868, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13802, "number_of_timesteps": 734711, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13812, "number_of_timesteps": 739711, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13822, "number_of_timesteps": 744644, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13832, "number_of_timesteps": 749644, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13842, "number_of_timesteps": 754644, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13852, "number_of_timesteps": 759512, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13862, "number_of_timesteps": 764512, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13872, "number_of_timesteps": 769512, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13882, "number_of_timesteps": 774274, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13892, "number_of_timesteps": 779001, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13902, "number_of_timesteps": 784001, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13912, "number_of_timesteps": 789001, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13922, "number_of_timesteps": 794001, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 13932, "number_of_timesteps": 798675, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13942, "number_of_timesteps": 803675, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13952, "number_of_timesteps": 808675, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13962, "number_of_timesteps": 813675, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13972, "number_of_timesteps": 818675, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13982, "number_of_timesteps": 823607, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13992, "number_of_timesteps": 828607, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14002, "number_of_timesteps": 833337, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14012, "number_of_timesteps": 838337, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14022, "number_of_timesteps": 843337, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14032, "number_of_timesteps": 848337, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14042, "number_of_timesteps": 853337, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14052, "number_of_timesteps": 858337, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14062, "number_of_timesteps": 863337, "per_episode_reward": 11.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},

{"total_number_of_episodes": 14072, "number_of_timesteps": 868156, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14082, "number_of_timesteps": 873151, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14092, "number_of_timesteps": 878151, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14102, "number_of_timesteps": 883151, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14112, "number_of_timesteps": 888151, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14122, "number_of_timesteps": 893151, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14132, "number_of_timesteps": 897986, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14142, "number_of_timesteps": 902636, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14152, "number_of_timesteps": 907562, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 14162, "number_of_timesteps": 912562, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14172, "number_of_timesteps": 917004, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14182, "number_of_timesteps": 921802, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14192, "number_of_timesteps": 926493, "per_episode_reward": 11.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14202, "number_of_timesteps": 931423, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},

{"total_number_of_episodes": 14212, "number_of_timesteps": 936423, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14222, "number_of_timesteps": 941284, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14232, "number_of_timesteps": 946284, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14242, "number_of_timesteps": 950964, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14252, "number_of_timesteps": 955964, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14262, "number_of_timesteps": 960964, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14272, "number_of_timesteps": 965964, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14282, "number_of_timesteps": 970964, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 14292, "number_of_timesteps": 975964, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14302, "number_of_timesteps": 980964, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14312, "number_of_timesteps": 985964, "per_episode_reward": 11.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14322, "number_of_timesteps": 990964, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14332, "number_of_timesteps": 995964, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14342, "number_of_timesteps": 1000964, "per_episode_reward": 11.85, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14352, "number_of_timesteps": 1005964, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14362, "number_of_timesteps": 1010817, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14372, "number_of_timesteps": 1015817, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14382, "number_of_timesteps": 1020817, "per_episode_reward": 11.95, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14392, "number_of_timesteps": 1025817, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14402, "number_of_timesteps": 1030817, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14412, "number_of_timesteps": 1035817, "per_episode_reward": 12.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14422, "number_of_timesteps": 1040527, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14432, "number_of_timesteps": 1045117, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14442, "number_of_timesteps": 1050117, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14452, "number_of_timesteps": 1055117, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14462, "number_of_timesteps": 1060117, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14472, "number_of_timesteps": 1064806, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14482, "number_of_timesteps": 1069806, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14492, "number_of_timesteps": 1074542, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14502, "number_of_timesteps": 1079542, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 14512, "number_of_timesteps": 1084542, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14522, "number_of_timesteps": 1089542, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14532, "number_of_timesteps": 1094173, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14542, "number_of_timesteps": 1099173, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14552, "number_of_timesteps": 1104173, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14562, "number_of_timesteps": 1109173, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14572, "number_of_timesteps": 1114173, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14582, "number_of_timesteps": 1119173, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14592, "number_of_timesteps": 1124173, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14602, "number_of_timesteps": 1129173, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14612, "number_of_timesteps": 1134173, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14622, "number_of_timesteps": 1139173, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14632, "number_of_timesteps": 1144173, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14642, "number_of_timesteps": 1149173, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14652, "number_of_timesteps": 1154173, "per_episode_reward": 12.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14662, "number_of_timesteps": 1159173, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14672, "number_of_timesteps": 1164155, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14682, "number_of_timesteps": 1169155, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14692, "number_of_timesteps": 1174155, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14702, "number_of_timesteps": 1179155, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14712, "number_of_timesteps": 1184155, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14722, "number_of_timesteps": 1189155, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14732, "number_of_timesteps": 1194155, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14742, "number_of_timesteps": 1199155, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 14752, "number_of_timesteps": 1204099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14762, "number_of_timesteps": 1209099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14772, "number_of_timesteps": 1214099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14782, "number_of_timesteps": 1219099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14792, "number_of_timesteps": 1224099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14802, "number_of_timesteps": 1229099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14812, "number_of_timesteps": 1234099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14822, "number_of_timesteps": 1239099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14832, "number_of_timesteps": 1244099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14842, "number_of_timesteps": 1249099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14852, "number_of_timesteps": 1254099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14862, "number_of_timesteps": 1259099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14872, "number_of_timesteps": 1264099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14882, "number_of_timesteps": 1269099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14892, "number_of_timesteps": 1274099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14902, "number_of_timesteps": 1279099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14912, "number_of_timesteps": 1284099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14922, "number_of_timesteps": 1289099, "per_episode_reward": 12.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14932, "number_of_timesteps": 1294099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14942, "number_of_timesteps": 1299099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14952, "number_of_timesteps": 1304099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14962, "number_of_timesteps": 1309099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14972, "number_of_timesteps": 1314099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14982, "number_of_timesteps": 1319099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14992, "number_of_timesteps": 1324099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15002, "number_of_timesteps": 1329099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15012, "number_of_timesteps": 1334099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},

{"total_number_of_episodes": 15022, "number_of_timesteps": 1339099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15032, "number_of_timesteps": 1344099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15042, "number_of_timesteps": 1349099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15052, "number_of_timesteps": 1354099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15062, "number_of_timesteps": 1359099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15072, "number_of_timesteps": 1364099, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15082, "number_of_timesteps": 1368980, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15092, "number_of_timesteps": 1373980, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15102, "number_of_timesteps": 1378980, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15112, "number_of_timesteps": 1383980, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15122, "number_of_timesteps": 1388980, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15132, "number_of_timesteps": 1393980, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15142, "number_of_timesteps": 1398980, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15152, "number_of_timesteps": 1403980, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15162, "number_of_timesteps": 1408980, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15172, "number_of_timesteps": 1413709, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15182, "number_of_timesteps": 1418709, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15192, "number_of_timesteps": 1423709, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15202, "number_of_timesteps": 1428709, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15212, "number_of_timesteps": 1433609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15222, "number_of_timesteps": 1438609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15232, "number_of_timesteps": 1443609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15242, "number_of_timesteps": 1448609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15252, "number_of_timesteps": 1453609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15262, "number_of_timesteps": 1458609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15272, "number_of_timesteps": 1463609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15282, "number_of_timesteps": 1468609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15292, "number_of_timesteps": 1473609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15302, "number_of_timesteps": 1478609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15312, "number_of_timesteps": 1483609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15322, "number_of_timesteps": 1488609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15332, "number_of_timesteps": 1493609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15342, "number_of_timesteps": 1498609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15352, "number_of_timesteps": 1503609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15362, "number_of_timesteps": 1508609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15372, "number_of_timesteps": 1513609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15382, "number_of_timesteps": 1518609, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15392, "number_of_timesteps": 1523369, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15402, "number_of_timesteps": 1528369, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15412, "number_of_timesteps": 1533369, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15422, "number_of_timesteps": 1538369, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15432, "number_of_timesteps": 1543369, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15442, "number_of_timesteps": 1548369, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15452, "number_of_timesteps": 1553369, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15462, "number_of_timesteps": 1558239, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15472, "number_of_timesteps": 1562961, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15482, "number_of_timesteps": 1567961, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15492, "number_of_timesteps": 1572961, "per_episode_reward": 12.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 15502, "number_of_timesteps": 1577961, "per_episode_reward": 12.55, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15512, "number_of_timesteps": 1582961, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15522, "number_of_timesteps": 1587961, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15532, "number_of_timesteps": 1592961, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15542, "number_of_timesteps": 1597961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15552, "number_of_timesteps": 1602961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15562, "number_of_timesteps": 1607961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15572, "number_of_timesteps": 1612961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15582, "number_of_timesteps": 1617961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15592, "number_of_timesteps": 1622961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15602, "number_of_timesteps": 1627961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15612, "number_of_timesteps": 1632961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15622, "number_of_timesteps": 1637961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15632, "number_of_timesteps": 1642961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15642, "number_of_timesteps": 1647961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15652, "number_of_timesteps": 1652961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15662, "number_of_timesteps": 1657961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15672, "number_of_timesteps": 1662961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15682, "number_of_timesteps": 1667961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15692, "number_of_timesteps": 1672961, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 15702, "number_of_timesteps": 1677961, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15712, "number_of_timesteps": 1682961, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15722, "number_of_timesteps": 1687961, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15732, "number_of_timesteps": 1692961, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15742, "number_of_timesteps": 1697961, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15752, "number_of_timesteps": 1702961, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15762, "number_of_timesteps": 1707961, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15772, "number_of_timesteps": 1712961, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15782, "number_of_timesteps": 1717961, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15792, "number_of_timesteps": 1722961, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15802, "number_of_timesteps": 1727961, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15812, "number_of_timesteps": 1732961, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15822, "number_of_timesteps": 1737961, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15832, "number_of_timesteps": 1742961, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15842, "number_of_timesteps": 1747883, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15852, "number_of_timesteps": 1752883, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15862, "number_of_timesteps": 1757883, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15872, "number_of_timesteps": 1762883, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15882, "number_of_timesteps": 1767883, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15892, "number_of_timesteps": 1772883, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15902, "number_of_timesteps": 1777883, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15912, "number_of_timesteps": 1782883, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15922, "number_of_timesteps": 1787713, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15932, "number_of_timesteps": 1792713, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15942, "number_of_timesteps": 1797713, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15952, "number_of_timesteps": 1802713, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15962, "number_of_timesteps": 1807713, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15972, "number_of_timesteps": 1812713, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15982, "number_of_timesteps": 1817713, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15992, "number_of_timesteps": 1822713, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16002, "number_of_timesteps": 1827713, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16012, "number_of_timesteps": 1832713, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16022, "number_of_timesteps": 1837713, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16032, "number_of_timesteps": 1842271, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16042, "number_of_timesteps": 1847271, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16052, "number_of_timesteps": 1852271, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16062, "number_of_timesteps": 1857271, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16072, "number_of_timesteps": 1862271, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16082, "number_of_timesteps": 1867196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16092, "number_of_timesteps": 1872196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16102, "number_of_timesteps": 1877196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16112, "number_of_timesteps": 1882196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16122, "number_of_timesteps": 1887196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16132, "number_of_timesteps": 1892196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16142, "number_of_timesteps": 1897196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16152, "number_of_timesteps": 1902196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16162, "number_of_timesteps": 1907196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16172, "number_of_timesteps": 1912196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16182, "number_of_timesteps": 1917196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16192, "number_of_timesteps": 1922196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16202, "number_of_timesteps": 1927196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16212, "number_of_timesteps": 1932196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16222, "number_of_timesteps": 1937196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16232, "number_of_timesteps": 1942196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16242, "number_of_timesteps": 1947196, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16252, "number_of_timesteps": 1952090, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16262, "number_of_timesteps": 1957090, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 16272, "number_of_timesteps": 1962090, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 16282, "number_of_timesteps": 1967090, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 16292, "number_of_timesteps": 1972061, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 16302, "number_of_timesteps": 1977061, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 16312, "number_of_timesteps": 1982061, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 16322, "number_of_timesteps": 1987061, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 16332, "number_of_timesteps": 1992061, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 16342, "number_of_timesteps": 1997061, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 16352, "number_of_timesteps": 2002061, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16362, "number_of_timesteps": 2007061, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16372, "number_of_timesteps": 2012061, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16382, "number_of_timesteps": 2017061, "per_episode_reward": 13.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16392, "number_of_timesteps": 2022061, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16402, "number_of_timesteps": 2027061, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16412, "number_of_timesteps": 2032061, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16422, "number_of_timesteps": 2037061, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16432, "number_of_timesteps": 2042061, "per_episode_reward": 13.25, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16442, "number_of_timesteps": 2047061, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16452, "number_of_timesteps": 2052061, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16462, "number_of_timesteps": 2057061, "per_episode_reward": 13.35, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16472, "number_of_timesteps": 2062061, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16482, "number_of_timesteps": 2067061, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16492, "number_of_timesteps": 2072061, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16502, "number_of_timesteps": 2077061, "per_episode_reward": 13.45, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16512, "number_of_timesteps": 2082061, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16522, "number_of_timesteps": 2087061, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16532, "number_of_timesteps": 2092061, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16542, "number_of_timesteps": 2097061, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16552, "number_of_timesteps": 2102061, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16562, "number_of_timesteps": 2107061, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16572, "number_of_timesteps": 2112061, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16582, "number_of_timesteps": 2117061, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16592, "number_of_timesteps": 2122061, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16602, "number_of_timesteps": 2127061, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16612, "number_of_timesteps": 2132061, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16622, "number_of_timesteps": 2137061, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16632, "number_of_timesteps": 2142061, "per_episode_reward": 13.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16642, "number_of_timesteps": 2147061, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16652, "number_of_timesteps": 2152061, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16662, "number_of_timesteps": 2157061, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16672, "number_of_timesteps": 2162061, "per_episode_reward": 13.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16682, "number_of_timesteps": 2167061, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16692, "number_of_timesteps": 2172061, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16702, "number_of_timesteps": 2177061, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16712, "number_of_timesteps": 2182061, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16722, "number_of_timesteps": 2187061, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16732, "number_of_timesteps": 2192061, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16742, "number_of_timesteps": 2197061, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16752, "number_of_timesteps": 2202061, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16762, "number_of_timesteps": 2207061, "per_episode_reward": 13.75, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16772, "number_of_timesteps": 2212061, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16782, "number_of_timesteps": 2217061, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16792, "number_of_timesteps": 2222061, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16802, "number_of_timesteps": 2227061, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16812, "number_of_timesteps": 2232061, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16822, "number_of_timesteps": 2237061, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16832, "number_of_timesteps": 2242061, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16842, "number_of_timesteps": 2247061, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16852, "number_of_timesteps": 2252061, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16862, "number_of_timesteps": 2257061, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16872, "number_of_timesteps": 2262061, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16882, "number_of_timesteps": 2267061, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16892, "number_of_timesteps": 2272061, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16902, "number_of_timesteps": 2276898, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16912, "number_of_timesteps": 2281898, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16922, "number_of_timesteps": 2286898, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16932, "number_of_timesteps": 2291898, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16942, "number_of_timesteps": 2296898, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16952, "number_of_timesteps": 2301898, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16962, "number_of_timesteps": 2306898, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16972, "number_of_timesteps": 2311898, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16982, "number_of_timesteps": 2316898, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16992, "number_of_timesteps": 2321898, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17002, "number_of_timesteps": 2326382, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17012, "number_of_timesteps": 2331382, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17022, "number_of_timesteps": 2336382, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17032, "number_of_timesteps": 2341382, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17042, "number_of_timesteps": 2346382, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17052, "number_of_timesteps": 2351382, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17062, "number_of_timesteps": 2356382, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17072, "number_of_timesteps": 2361382, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17082, "number_of_timesteps": 2366382, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17092, "number_of_timesteps": 2371382, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17102, "number_of_timesteps": 2376382, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17112, "number_of_timesteps": 2381382, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17122, "number_of_timesteps": 2386382, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17132, "number_of_timesteps": 2391382, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17142, "number_of_timesteps": 2396382, "per_episode_reward": 13.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 17152, "number_of_timesteps": 2401382, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17162, "number_of_timesteps": 2406382, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17172, "number_of_timesteps": 2411382, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17182, "number_of_timesteps": 2416382, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17192, "number_of_timesteps": 2421382, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17202, "number_of_timesteps": 2426382, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17212, "number_of_timesteps": 2431382, "per_episode_reward": 13.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17222, "number_of_timesteps": 2436382, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17232, "number_of_timesteps": 2441382, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17242, "number_of_timesteps": 2446382, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17252, "number_of_timesteps": 2451382, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17262, "number_of_timesteps": 2456382, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17272, "number_of_timesteps": 2461319, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17282, "number_of_timesteps": 2466319, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17292, "number_of_timesteps": 2471319, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17302, "number_of_timesteps": 2476170, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17312, "number_of_timesteps": 2481170, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17322, "number_of_timesteps": 2486170, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17332, "number_of_timesteps": 2491170, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17342, "number_of_timesteps": 2496170, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17352, "number_of_timesteps": 2501170, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17362, "number_of_timesteps": 2506170, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17372, "number_of_timesteps": 2511170, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 17382, "number_of_timesteps": 2515649, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17392, "number_of_timesteps": 2520649, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17402, "number_of_timesteps": 2525649, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17412, "number_of_timesteps": 2530649, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17422, "number_of_timesteps": 2535649, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17432, "number_of_timesteps": 2540649, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17442, "number_of_timesteps": 2545433, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17452, "number_of_timesteps": 2550433, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17462, "number_of_timesteps": 2555433, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17472, "number_of_timesteps": 2560433, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17482, "number_of_timesteps": 2565433, "per_episode_reward": 14.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},

{"total_number_of_episodes": 17492, "number_of_timesteps": 2570433, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17502, "number_of_timesteps": 2575433, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17512, "number_of_timesteps": 2580277, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17522, "number_of_timesteps": 2585277, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17532, "number_of_timesteps": 2590147, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17542, "number_of_timesteps": 2595147, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17552, "number_of_timesteps": 2600147, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17562, "number_of_timesteps": 2605147, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 17572, "number_of_timesteps": 2610147, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 17582, "number_of_timesteps": 2614864, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 17592, "number_of_timesteps": 2619864, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 17602, "number_of_timesteps": 2624864, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 17612, "number_of_timesteps": 2629864, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 17622, "number_of_timesteps": 2634652, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 17632, "number_of_timesteps": 2639652, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 17642, "number_of_timesteps": 2644652, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 17652, "number_of_timesteps": 2649652, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17662, "number_of_timesteps": 2654652, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17672, "number_of_timesteps": 2659652, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17682, "number_of_timesteps": 2664652, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17692, "number_of_timesteps": 2669652, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17702, "number_of_timesteps": 2674652, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17712, "number_of_timesteps": 2679652, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17722, "number_of_timesteps": 2684652, "per_episode_reward": 14.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 17732, "number_of_timesteps": 2689652, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17742, "number_of_timesteps": 2694342, "per_episode_reward": 14.55, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17752, "number_of_timesteps": 2699342, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17762, "number_of_timesteps": 2704342, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17772, "number_of_timesteps": 2709342, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17782, "number_of_timesteps": 2714342, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17792, "number_of_timesteps": 2719342, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17802, "number_of_timesteps": 2724342, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17812, "number_of_timesteps": 2729342, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17822, "number_of_timesteps": 2734342, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},

{"total_number_of_episodes": 17832, "number_of_timesteps": 2739342, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 17842, "number_of_timesteps": 2744342, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 17852, "number_of_timesteps": 2749342, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 17862, "number_of_timesteps": 2754342, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 17872, "number_of_timesteps": 2759342, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 17882, "number_of_timesteps": 2764342, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 17892, "number_of_timesteps": 2769342, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 17902, "number_of_timesteps": 2774342, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 17912, "number_of_timesteps": 2779342, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17922, "number_of_timesteps": 2784342, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17932, "number_of_timesteps": 2788989, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17942, "number_of_timesteps": 2793989, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17952, "number_of_timesteps": 2798989, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17962, "number_of_timesteps": 2803989, "per_episode_reward": 14.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 17972, "number_of_timesteps": 2808989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17982, "number_of_timesteps": 2813989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17992, "number_of_timesteps": 2818989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18002, "number_of_timesteps": 2823989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18012, "number_of_timesteps": 2828989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18022, "number_of_timesteps": 2833989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18032, "number_of_timesteps": 2838989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18042, "number_of_timesteps": 2843989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18052, "number_of_timesteps": 2848989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18062, "number_of_timesteps": 2853989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18072, "number_of_timesteps": 2858989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18082, "number_of_timesteps": 2863989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18092, "number_of_timesteps": 2868989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18102, "number_of_timesteps": 2873989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18112, "number_of_timesteps": 2878989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18122, "number_of_timesteps": 2883989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18132, "number_of_timesteps": 2888989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18142, "number_of_timesteps": 2893989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18152, "number_of_timesteps": 2898989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18162, "number_of_timesteps": 2903989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18172, "number_of_timesteps": 2908989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18182, "number_of_timesteps": 2913989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18192, "number_of_timesteps": 2918989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18202, "number_of_timesteps": 2923989, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18212, "number_of_timesteps": 2928989, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18222, "number_of_timesteps": 2933787, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18232, "number_of_timesteps": 2938787, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18242, "number_of_timesteps": 2943787, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18252, "number_of_timesteps": 2948779, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18262, "number_of_timesteps": 2953779, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18272, "number_of_timesteps": 2958779, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18282, "number_of_timesteps": 2963779, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18292, "number_of_timesteps": 2968779, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18302, "number_of_timesteps": 2973779, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18312, "number_of_timesteps": 2978779, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18323, "number_of_timesteps": 2984184, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18333, "number_of_timesteps": 2989184, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18343, "number_of_timesteps": 2994184, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18353, "number_of_timesteps": 2999184, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18363, "number_of_timesteps": 3004078, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18373, "number_of_timesteps": 3009078, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18383, "number_of_timesteps": 3014078, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18393, "number_of_timesteps": 3019078, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18403, "number_of_timesteps": 3024078, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18413, "number_of_timesteps": 3029078, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18423, "number_of_timesteps": 3034078, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18433, "number_of_timesteps": 3039078, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18443, "number_of_timesteps": 3044078, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 18454, "number_of_timesteps": 3049306, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 18464, "number_of_timesteps": 3054306, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18474, "number_of_timesteps": 3059306, "per_episode_reward": 15.35, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 18484, "number_of_timesteps": 3064306, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 18494, "number_of_timesteps": 3069306, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 18504, "number_of_timesteps": 3074306, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 18514, "number_of_timesteps": 3079260, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 18524, "number_of_timesteps": 3084260, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 18534, "number_of_timesteps": 3089260, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 18544, "number_of_timesteps": 3094260, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 18554, "number_of_timesteps": 3099260, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 18564, "number_of_timesteps": 3104260, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18574, "number_of_timesteps": 3109260, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18584, "number_of_timesteps": 3113895, "per_episode_reward": 15.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 18594, "number_of_timesteps": 3118895, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18604, "number_of_timesteps": 3123895, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18614, "number_of_timesteps": 3128895, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18624, "number_of_timesteps": 3133895, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18634, "number_of_timesteps": 3138895, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18644, "number_of_timesteps": 3143895, "per_episode_reward": 15.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18654, "number_of_timesteps": 3148895, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18664, "number_of_timesteps": 3153895, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18674, "number_of_timesteps": 3158895, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18684, "number_of_timesteps": 3163895, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18694, "number_of_timesteps": 3168895, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18704, "number_of_timesteps": 3173895, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18714, "number_of_timesteps": 3178895, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18724, "number_of_timesteps": 3183895, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 18734, "number_of_timesteps": 3188895, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 18744, "number_of_timesteps": 3193895, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18754, "number_of_timesteps": 3198895, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18764, "number_of_timesteps": 3203895, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18774, "number_of_timesteps": 3208895, "per_episode_reward": 15.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18784, "number_of_timesteps": 3213895, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18794, "number_of_timesteps": 3218895, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18804, "number_of_timesteps": 3223895, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18814, "number_of_timesteps": 3228895, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18824, "number_of_timesteps": 3233895, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18834, "number_of_timesteps": 3238895, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18844, "number_of_timesteps": 3243895, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18854, "number_of_timesteps": 3248895, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18864, "number_of_timesteps": 3253895, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18874, "number_of_timesteps": 3258895, "per_episode_reward": 15.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 18884, "number_of_timesteps": 3263895, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18894, "number_of_timesteps": 3268895, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18904, "number_of_timesteps": 3273895, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18914, "number_of_timesteps": 3278895, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18924, "number_of_timesteps": 3283895, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18934, "number_of_timesteps": 3288895, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18944, "number_of_timesteps": 3293895, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18954, "number_of_timesteps": 3298895, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18964, "number_of_timesteps": 3303535, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18974, "number_of_timesteps": 3308535, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18984, "number_of_timesteps": 3313535, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18994, "number_of_timesteps": 3318535, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19004, "number_of_timesteps": 3323535, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19014, "number_of_timesteps": 3328535, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19024, "number_of_timesteps": 3333535, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19034, "number_of_timesteps": 3338535, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19044, "number_of_timesteps": 3343069, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19054, "number_of_timesteps": 3348069, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19064, "number_of_timesteps": 3353069, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19074, "number_of_timesteps": 3358069, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19084, "number_of_timesteps": 3363069, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19094, "number_of_timesteps": 3368069, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19104, "number_of_timesteps": 3373069, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19114, "number_of_timesteps": 3378069, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19124, "number_of_timesteps": 3383069, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19134, "number_of_timesteps": 3388069, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19144, "number_of_timesteps": 3393069, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19154, "number_of_timesteps": 3398069, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19164, "number_of_timesteps": 3403069, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19174, "number_of_timesteps": 3408069, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19184, "number_of_timesteps": 3413069, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19194, "number_of_timesteps": 3417810, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19204, "number_of_timesteps": 3422810, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19214, "number_of_timesteps": 3427810, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19224, "number_of_timesteps": 3432492, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19234, "number_of_timesteps": 3437492, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19244, "number_of_timesteps": 3442492, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19254, "number_of_timesteps": 3447096, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19264, "number_of_timesteps": 3452096, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19274, "number_of_timesteps": 3457096, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19284, "number_of_timesteps": 3461890, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19294, "number_of_timesteps": 3466890, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19304, "number_of_timesteps": 3471890, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19314, "number_of_timesteps": 3476890, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19324, "number_of_timesteps": 3481890, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19334, "number_of_timesteps": 3486890, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19344, "number_of_timesteps": 3491459, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19354, "number_of_timesteps": 3496459, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19364, "number_of_timesteps": 3501459, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19374, "number_of_timesteps": 3506459, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19384, "number_of_timesteps": 3511459, "per_episode_reward": 16.65, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19394, "number_of_timesteps": 3516459, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19404, "number_of_timesteps": 3521459, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19414, "number_of_timesteps": 3526459, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19424, "number_of_timesteps": 3531459, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19434, "number_of_timesteps": 3536459, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19444, "number_of_timesteps": 3541459, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19454, "number_of_timesteps": 3546459, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19464, "number_of_timesteps": 3551196, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19474, "number_of_timesteps": 3556196, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19484, "number_of_timesteps": 3561196, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19494, "number_of_timesteps": 3566196, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19504, "number_of_timesteps": 3571196, "per_episode_reward": 16.85, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19514, "number_of_timesteps": 3576196, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19524, "number_of_timesteps": 3581196, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19534, "number_of_timesteps": 3586196, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19544, "number_of_timesteps": 3591064, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19554, "number_of_timesteps": 3596064, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19564, "number_of_timesteps": 3601064, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19574, "number_of_timesteps": 3606064, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19584, "number_of_timesteps": 3611064, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19594, "number_of_timesteps": 3615725, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 19604, "number_of_timesteps": 3620725, "per_episode_reward": 16.95, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19614, "number_of_timesteps": 3625641, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19624, "number_of_timesteps": 3630641, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19634, "number_of_timesteps": 3635575, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19644, "number_of_timesteps": 3640575, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19654, "number_of_timesteps": 3645482, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19664, "number_of_timesteps": 3650482, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19674, "number_of_timesteps": 3655015, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19684, "number_of_timesteps": 3660015, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19694, "number_of_timesteps": 3665015, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19704, "number_of_timesteps": 3670015, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19714, "number_of_timesteps": 3675015, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19724, "number_of_timesteps": 3680015, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19734, "number_of_timesteps": 3685015, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19744, "number_of_timesteps": 3690015, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19754, "number_of_timesteps": 3695015, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19764, "number_of_timesteps": 3700015, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19774, "number_of_timesteps": 3705015, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19784, "number_of_timesteps": 3709830, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19794, "number_of_timesteps": 3714830, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19804, "number_of_timesteps": 3719813, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19814, "number_of_timesteps": 3724813, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19824, "number_of_timesteps": 3729153, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19834, "number_of_timesteps": 3734153, "per_episode_reward": 17.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19844, "number_of_timesteps": 3739153, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19854, "number_of_timesteps": 3743710, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19864, "number_of_timesteps": 3748710, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19874, "number_of_timesteps": 3753710, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19884, "number_of_timesteps": 3758710, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19894, "number_of_timesteps": 3763710, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19904, "number_of_timesteps": 3768710, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19914, "number_of_timesteps": 3773558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19924, "number_of_timesteps": 3778558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19934, "number_of_timesteps": 3783558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19944, "number_of_timesteps": 3788558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19954, "number_of_timesteps": 3793558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19964, "number_of_timesteps": 3798558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19974, "number_of_timesteps": 3803558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19984, "number_of_timesteps": 3808558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19994, "number_of_timesteps": 3813558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20004, "number_of_timesteps": 3818558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20014, "number_of_timesteps": 3823558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20024, "number_of_timesteps": 3828558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20034, "number_of_timesteps": 3833558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20044, "number_of_timesteps": 3838558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20054, "number_of_timesteps": 3843558, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20064, "number_of_timesteps": 3848558, "per_episode_reward": 17.65, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 20074, "number_of_timesteps": 3853558, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20084, "number_of_timesteps": 3858558, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20094, "number_of_timesteps": 3863558, "per_episode_reward": 17.75, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20104, "number_of_timesteps": 3868558, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20114, "number_of_timesteps": 3873558, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20124, "number_of_timesteps": 3878558, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20134, "number_of_timesteps": 3883558, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20144, "number_of_timesteps": 3888558, "per_episode_reward": 17.85, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20154, "number_of_timesteps": 3893558, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20164, "number_of_timesteps": 3898558, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20174, "number_of_timesteps": 3903558, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20184, "number_of_timesteps": 3908558, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20194, "number_of_timesteps": 3913558, "per_episode_reward": 17.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20204, "number_of_timesteps": 3918558, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20214, "number_of_timesteps": 3923558, "per_episode_reward": 18.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20224, "number_of_timesteps": 3928558, "per_episode_reward": 18.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20234, "number_of_timesteps": 3933558, "per_episode_reward": 18.1, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20244, "number_of_timesteps": 3938558, "per_episode_reward": 18.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20254, "number_of_timesteps": 3943558, "per_episode_reward": 18.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20264, "number_of_timesteps": 3948558, "per_episode_reward": 18.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20274, "number_of_timesteps": 3953558, "per_episode_reward": 18.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20284, "number_of_timesteps": 3958558, "per_episode_reward": 18.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20294, "number_of_timesteps": 3963558, "per_episode_reward": 18.15, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20304, "number_of_timesteps": 3968407, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20314, "number_of_timesteps": 3973407, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20324, "number_of_timesteps": 3978407, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20334, "number_of_timesteps": 3983407, "per_episode_reward": 18.25, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20344, "number_of_timesteps": 3988407, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20354, "number_of_timesteps": 3993407, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20364, "number_of_timesteps": 3998407, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20374, "number_of_timesteps": 4003407, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20384, "number_of_timesteps": 4008407, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20394, "number_of_timesteps": 4013264, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20404, "number_of_timesteps": 4018264, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20415, "number_of_timesteps": 4023506, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20425, "number_of_timesteps": 4028506, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20435, "number_of_timesteps": 4033506, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20445, "number_of_timesteps": 4037815, "per_episode_reward": 18.35, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20455, "number_of_timesteps": 4042607, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20465, "number_of_timesteps": 4047607, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20475, "number_of_timesteps": 4052607, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20485, "number_of_timesteps": 4057607, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20495, "number_of_timesteps": 4062607, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20505, "number_of_timesteps": 4067607, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20515, "number_of_timesteps": 4072607, "per_episode_reward": 18.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20525, "number_of_timesteps": 4077607, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20535, "number_of_timesteps": 4082607, "per_episode_reward": 18.55, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20546, "number_of_timesteps": 4087759, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20556, "number_of_timesteps": 4092759, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 20566, "number_of_timesteps": 4097572, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 20576, "number_of_timesteps": 4102572, "per_episode_reward": 18.75, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 20586, "number_of_timesteps": 4107572, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 20596, "number_of_timesteps": 4112572, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 20606, "number_of_timesteps": 4117276, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 20616, "number_of_timesteps": 4122042, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 20626, "number_of_timesteps": 4126862, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 20636, "number_of_timesteps": 4131625, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 20646, "number_of_timesteps": 4136540, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20656, "number_of_timesteps": 4141540, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20666, "number_of_timesteps": 4146540, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20676, "number_of_timesteps": 4151540, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20686, "number_of_timesteps": 4156540, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20696, "number_of_timesteps": 4161540, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20706, "number_of_timesteps": 4166540, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20716, "number_of_timesteps": 4171540, "per_episode_reward": 18.85, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20726, "number_of_timesteps": 4176540, "per_episode_reward": 18.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20736, "number_of_timesteps": 4181540, "per_episode_reward": 18.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20746, "number_of_timesteps": 4186540, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20756, "number_of_timesteps": 4191540, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20766, "number_of_timesteps": 4196540, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20776, "number_of_timesteps": 4201540, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20786, "number_of_timesteps": 4206540, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20796, "number_of_timesteps": 4211540, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20806, "number_of_timesteps": 4216540, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},

{"total_number_of_episodes": 20816, "number_of_timesteps": 4221540, "per_episode_reward": 19.15, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20826, "number_of_timesteps": 4226540, "per_episode_reward": 19.2, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20836, "number_of_timesteps": 4231540, "per_episode_reward": 19.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20846, "number_of_timesteps": 4236540, "per_episode_reward": 19.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20856, "number_of_timesteps": 4241540, "per_episode_reward": 19.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20866, "number_of_timesteps": 4246540, "per_episode_reward": 19.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20876, "number_of_timesteps": 4251540, "per_episode_reward": 19.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20886, "number_of_timesteps": 4256540, "per_episode_reward": 19.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20896, "number_of_timesteps": 4261540, "per_episode_reward": 19.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20906, "number_of_timesteps": 4266540, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20916, "number_of_timesteps": 4271540, "per_episode_reward": 19.35, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20926, "number_of_timesteps": 4276540, "per_episode_reward": 19.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20936, "number_of_timesteps": 4281540, "per_episode_reward": 19.45, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20946, "number_of_timesteps": 4286540, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20956, "number_of_timesteps": 4291540, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20966, "number_of_timesteps": 4296540, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20976, "number_of_timesteps": 4301540, "per_episode_reward": 19.55, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20986, "number_of_timesteps": 4306540, "per_episode_reward": 19.6, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20996, "number_of_timesteps": 4311476, "per_episode_reward": 19.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
exited at update_barrier.wait(): 0, error = 
None
exited at update_barrier.wait(): 6, error = 
None
exited at update_barrier.wait(): 8, error = 
None
exited at all_updated_barrier.wait(): 4, error = 
None
exited at all_updated_barrier.wait(): 7, error = 
None
exited at all_updated_barrier.wait(): 9, error = 
None
exited at all_updated_barrier.wait(): 1, error = 
None
exited at all_updated_barrier.wait(): 5, error = 
None
exited at all_updated_barrier.wait(): 2, error = 
None
[done calling async_.run_async()]
final_eval: {'number_of_steps': 125000, 'number_of_episodes': None, 'mean': 492.4782608695652, 'median': 500.0, 'stdev': 43.23134199046748}
[starting train_a3c()]
[starting train_agent_async()]
[about to call async_.run_async()]
[starting run_func()]
[starting train_loop()]
Step 0 0 visits [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1 0 visits [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-3.476, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2 1 visits [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-3.476, -3.764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 3 2 visits [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 5 q_vals: [-3.476, -3.764, -2.917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 4 3 visits [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 7 q_vals: [-3.476, -3.764, -2.917, -7.965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 5 4 visits [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 8 q_vals: [-3.476, -3.764, -2.917, -7.965, -3.42, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 6 5 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 9 q_vals: [-3.476, -3.764, -2.917, -7.965, -3.42, -8.956, 0.0, 0.0, 0.0, 0.0]
Step 7 6 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 10 q_vals: [-3.476, -3.764, -2.917, -7.965, -3.42, -8.956, -4.137, 0.0, 0.0, 0.0]
Step 8 7 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 10 q_vals: [-3.476, -3.764, -2.917, -7.965, -3.42, -8.956, -4.137, -4.297, 0.0, 0.0]
Step 9 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 14 q_vals: [-3.476, -3.764, -2.917, -7.965, -3.42, -8.956, -4.137, -4.297, -10.28, 0.0]
Step 10 9 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 15 q_vals: [-3.476, -3.764, -2.917, -7.965, -3.42, -8.956, -4.137, -4.297, -10.28, -7.173]
Step 11 2 visits [1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 17 q_vals: [-3.476, -3.764, -5.233, -7.965, -3.42, -8.956, -4.137, -4.297, -10.28, -7.173]
Step 12 4 visits [1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 19 q_vals: [-3.476, -3.764, -5.233, -7.965, -6.194, -8.956, -4.137, -4.297, -10.28, -7.173]
Step 13 0 visits [2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 20 q_vals: [-3.919, -3.764, -5.233, -7.965, -6.194, -8.956, -4.137, -4.297, -10.28, -7.173]
Step 14 1 visits [2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 24 q_vals: [-3.919, -3.732, -5.233, -7.965, -6.194, -8.956, -4.137, -4.297, -10.28, -7.173]
Step 15 6 visits [2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 26 q_vals: [-3.919, -3.732, -5.233, -7.965, -6.194, -8.956, -3.608, -4.297, -10.28, -7.173]
Step 16 6 visits [2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 27 q_vals: [-3.919, -3.732, -5.233, -7.965, -6.194, -8.956, -3.53, -4.297, -10.28, -7.173]
{"total_number_of_episodes": 31, "number_of_timesteps": 669, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Step 17 1 visits [2.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 31 q_vals: [-3.919, -3.444, -5.233, -7.965, -6.194, -8.956, -3.53, -4.297, -10.28, -7.173]
Step 18 1 visits [2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 35 q_vals: [-3.919, -3.795, -5.233, -7.965, -6.194, -8.956, -3.53, -4.297, -10.28, -7.173]
Step 19 6 visits [2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0]  episode_count: 35 q_vals: [-3.919, -3.795, -5.233, -7.965, -6.194, -8.956, -4.962, -4.297, -10.28, -7.173]
Step 20 7 visits [2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 1.0, 1.0]  episode_count: 40 q_vals: [-3.919, -3.795, -5.233, -7.965, -6.194, -8.956, -4.962, -3.812, -10.28, -7.173]
{"total_number_of_episodes": 41, "number_of_timesteps": 869, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.1, "biggest_recent_change": NaN},
Step 21 7 visits [2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 4.0, 3.0, 1.0, 1.0]  episode_count: 41 q_vals: [-3.919, -3.795, -5.233, -7.965, -6.194, -8.956, -4.962, -3.516, -10.28, -7.173]
Step 22 7 visits [2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 41 q_vals: [-3.919, -3.795, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 23 0 visits [3.0, 4.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 43 q_vals: [-3.672, -3.795, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 24 0 visits [4.0, 4.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 45 q_vals: [-3.809, -3.795, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 25 1 visits [4.0, 5.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 49 q_vals: [-3.809, -3.964, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
{"total_number_of_episodes": 51, "number_of_timesteps": 1106, "per_episode_reward": 19.45, "episode_reward_trend_value": -0.032500000000000105, "biggest_recent_change": NaN},
Step 26 0 visits [5.0, 5.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 51 q_vals: [-4.651, -3.964, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 27 1 visits [5.0, 6.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 53 q_vals: [-4.651, -3.304, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 28 1 visits [5.0, 7.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 54 q_vals: [-4.651, -3.266, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 29 1 visits [5.0, 8.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 55 q_vals: [-4.651, -2.858, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 30 1 visits [5.0, 9.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 58 q_vals: [-4.651, -3.354, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 31 1 visits [5.0, 10.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 58 q_vals: [-4.651, -3.348, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
{"total_number_of_episodes": 62, "number_of_timesteps": 1295, "per_episode_reward": 18.8, "episode_reward_trend_value": -0.043333333333333356, "biggest_recent_change": NaN},
Step 32 1 visits [5.0, 11.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 62 q_vals: [-4.651, -3.782, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 33 1 visits [5.0, 12.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 65 q_vals: [-4.651, -4.277, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 34 1 visits [5.0, 13.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 67 q_vals: [-4.651, -3.948, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 35 1 visits [5.0, 14.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 71 q_vals: [-4.651, -3.924, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
{"total_number_of_episodes": 72, "number_of_timesteps": 1556, "per_episode_reward": 19.05, "episode_reward_trend_value": -0.026250000000000016, "biggest_recent_change": NaN},
Step 36 1 visits [5.0, 15.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 72 q_vals: [-4.651, -3.862, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 37 1 visits [5.0, 16.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 74 q_vals: [-4.651, -3.817, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 38 1 visits [5.0, 17.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 76 q_vals: [-4.651, -3.829, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 39 1 visits [5.0, 18.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 78 q_vals: [-4.651, -3.789, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 40 1 visits [5.0, 19.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 79 q_vals: [-4.651, -4.022, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
{"total_number_of_episodes": 82, "number_of_timesteps": 1742, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.037000000000000026, "biggest_recent_change": NaN},
Step 41 1 visits [5.0, 20.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 82 q_vals: [-4.651, -3.821, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 42 1 visits [5.0, 21.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 83 q_vals: [-4.651, -3.783, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 43 1 visits [5.0, 22.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 83 q_vals: [-4.651, -3.611, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 44 1 visits [5.0, 23.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 85 q_vals: [-4.651, -3.593, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 45 1 visits [5.0, 24.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 87 q_vals: [-4.651, -3.571, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 46 1 visits [5.0, 25.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 91 q_vals: [-4.651, -3.565, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
{"total_number_of_episodes": 92, "number_of_timesteps": 1977, "per_episode_reward": 18.5, "episode_reward_trend_value": -0.02666666666666669, "biggest_recent_change": NaN},
Step 47 1 visits [5.0, 26.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 92 q_vals: [-4.651, -3.617, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 48 1 visits [5.0, 27.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 93 q_vals: [-4.651, -3.794, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 49 1 visits [5.0, 28.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 96 q_vals: [-4.651, -3.847, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 50 1 visits [5.0, 29.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 98 q_vals: [-4.651, -3.755, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
{"total_number_of_episodes": 104, "number_of_timesteps": 2232, "per_episode_reward": 18.15, "episode_reward_trend_value": -0.027857142857142896, "biggest_recent_change": NaN},
Step 51 1 visits [5.0, 30.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 104 q_vals: [-4.651, -3.74, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 52 1 visits [5.0, 31.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 104 q_vals: [-4.651, -3.747, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 53 1 visits [5.0, 32.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 106 q_vals: [-4.651, -3.732, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 54 1 visits [5.0, 33.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 110 q_vals: [-4.651, -3.907, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 55 1 visits [5.0, 34.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 112 q_vals: [-4.651, -3.904, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 56 1 visits [5.0, 35.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 113 q_vals: [-4.651, -3.902, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
{"total_number_of_episodes": 115, "number_of_timesteps": 2494, "per_episode_reward": 18.15, "episode_reward_trend_value": -0.024375000000000036, "biggest_recent_change": NaN},
Step 57 1 visits [5.0, 36.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 115 q_vals: [-4.651, -3.9, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 58 1 visits [5.0, 37.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 117 q_vals: [-4.651, -3.914, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 59 1 visits [5.0, 38.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 120 q_vals: [-4.651, -3.914, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 60 1 visits [5.0, 39.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 120 q_vals: [-4.651, -3.909, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 61 1 visits [5.0, 40.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 122 q_vals: [-4.651, -3.914, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 62 1 visits [5.0, 41.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 124 q_vals: [-4.651, -4.015, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
{"total_number_of_episodes": 126, "number_of_timesteps": 2749, "per_episode_reward": 18.15, "episode_reward_trend_value": -0.0216666666666667, "biggest_recent_change": 1.6500000000000021},
Step 63 1 visits [5.0, 42.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 126 q_vals: [-4.651, -4.224, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 64 0 visits [6.0, 42.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 127 q_vals: [-3.876, -4.224, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 65 0 visits [7.0, 42.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 129 q_vals: [-3.778, -4.224, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 66 0 visits [8.0, 42.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 133 q_vals: [-3.729, -4.224, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 67 0 visits [9.0, 42.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 133 q_vals: [-3.734, -4.224, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
{"total_number_of_episodes": 138, "number_of_timesteps": 3026, "per_episode_reward": 18.7, "episode_reward_trend_value": -0.02666666666666669, "biggest_recent_change": 1.6500000000000021},
Step 68 0 visits [10.0, 42.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 138 q_vals: [-4.182, -4.224, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 69 0 visits [11.0, 42.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 140 q_vals: [-4.127, -4.224, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 70 0 visits [12.0, 42.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 141 q_vals: [-4.289, -4.224, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 71 0 visits [13.0, 42.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 142 q_vals: [-4.308, -4.224, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 72 0 visits [14.0, 42.0, 2.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 144 q_vals: [-4.636, -4.224, -5.233, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 73 2 visits [14.0, 42.0, 3.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 147 q_vals: [-4.636, -4.224, -4.552, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 74 2 visits [14.0, 42.0, 4.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 147 q_vals: [-4.636, -4.224, -4.394, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
{"total_number_of_episodes": 150, "number_of_timesteps": 3313, "per_episode_reward": 18.95, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.8000000000000007},
Step 75 2 visits [14.0, 42.0, 5.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 150 q_vals: [-4.636, -4.224, -3.515, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 76 2 visits [14.0, 42.0, 6.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 152 q_vals: [-4.636, -4.224, -2.929, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 77 2 visits [14.0, 42.0, 7.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 153 q_vals: [-4.636, -4.224, -3.992, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 78 2 visits [14.0, 42.0, 8.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 154 q_vals: [-4.636, -4.224, -4.006, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 79 2 visits [14.0, 42.0, 9.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 156 q_vals: [-4.636, -4.224, -3.95, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 80 2 visits [14.0, 42.0, 10.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 158 q_vals: [-4.636, -4.224, -3.902, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 81 2 visits [14.0, 42.0, 11.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 159 q_vals: [-4.636, -4.224, -4.297, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
{"total_number_of_episodes": 162, "number_of_timesteps": 3657, "per_episode_reward": 19.35, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.8000000000000007},
Step 82 2 visits [14.0, 42.0, 12.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 162 q_vals: [-4.636, -4.224, -4.282, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 83 2 visits [14.0, 42.0, 13.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 164 q_vals: [-4.636, -4.224, -4.289, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 84 2 visits [14.0, 42.0, 14.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 167 q_vals: [-4.636, -4.224, -4.226, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 85 2 visits [14.0, 42.0, 15.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 169 q_vals: [-4.636, -4.224, -4.195, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 86 2 visits [14.0, 42.0, 16.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 171 q_vals: [-4.636, -4.224, -3.933, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
{"total_number_of_episodes": 172, "number_of_timesteps": 3861, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.8000000000000007},
Step 87 2 visits [14.0, 42.0, 17.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 172 q_vals: [-4.636, -4.224, -3.736, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 88 2 visits [14.0, 42.0, 18.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 177 q_vals: [-4.636, -4.224, -3.826, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 89 2 visits [14.0, 42.0, 19.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 178 q_vals: [-4.636, -4.224, -3.806, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 90 2 visits [14.0, 42.0, 20.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 180 q_vals: [-4.636, -4.224, -4.066, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
{"total_number_of_episodes": 182, "number_of_timesteps": 4043, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.5500000000000007},
Step 91 2 visits [14.0, 42.0, 21.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 182 q_vals: [-4.636, -4.224, -4.074, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 92 2 visits [14.0, 42.0, 22.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 184 q_vals: [-4.636, -4.224, -4.052, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 93 2 visits [14.0, 42.0, 23.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 185 q_vals: [-4.636, -4.224, -4.026, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 94 2 visits [14.0, 42.0, 24.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 187 q_vals: [-4.636, -4.224, -4.109, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
Step 95 2 visits [14.0, 42.0, 25.0, 1.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 191 q_vals: [-4.636, -4.224, -4.3, -7.965, -6.194, -8.956, -4.962, -4.841, -10.28, -7.173]
{"total_number_of_episodes": 193, "number_of_timesteps": 4331, "per_episode_reward": 19.05, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.5500000000000007},
Step 96 7 visits [14.0, 42.0, 25.0, 1.0, 2.0, 1.0, 4.0, 5.0, 1.0, 1.0]  episode_count: 193 q_vals: [-4.636, -4.224, -4.3, -7.965, -6.194, -8.956, -4.962, -5.784, -10.28, -7.173]
Step 97 2 visits [14.0, 42.0, 26.0, 1.0, 2.0, 1.0, 4.0, 5.0, 1.0, 1.0]  episode_count: 193 q_vals: [-4.636, -4.224, -4.135, -7.965, -6.194, -8.956, -4.962, -5.784, -10.28, -7.173]
Step 98 2 visits [14.0, 42.0, 27.0, 1.0, 2.0, 1.0, 4.0, 5.0, 1.0, 1.0]  episode_count: 197 q_vals: [-4.636, -4.224, -4.178, -7.965, -6.194, -8.956, -4.962, -5.784, -10.28, -7.173]
Step 99 2 visits [14.0, 42.0, 28.0, 1.0, 2.0, 1.0, 4.0, 5.0, 1.0, 1.0]  episode_count: 199 q_vals: [-4.636, -4.224, -4.189, -7.965, -6.194, -8.956, -4.962, -5.784, -10.28, -7.173]
Step 100 2 visits [14.0, 42.0, 29.0, 1.0, 2.0, 1.0, 4.0, 5.0, 1.0, 1.0]  episode_count: 200 q_vals: [-4.636, -4.224, -4.044, -7.965, -6.194, -8.956, -4.962, -5.784, -10.28, -7.173]
Step 101 2 visits [14.0, 42.0, 30.0, 1.0, 2.0, 1.0, 4.0, 5.0, 1.0, 1.0]  episode_count: 202 q_vals: [-4.636, -4.224, -4.079, -7.965, -6.194, -8.956, -4.962, -5.784, -10.28, -7.173]
{"total_number_of_episodes": 203, "number_of_timesteps": 4497, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.00944444444444446, "biggest_recent_change": 0.5500000000000007},
Step 102 2 visits [14.0, 42.0, 31.0, 1.0, 2.0, 1.0, 4.0, 5.0, 1.0, 1.0]  episode_count: 203 q_vals: [-4.636, -4.224, -4.096, -7.965, -6.194, -8.956, -4.962, -5.784, -10.28, -7.173]
Step 103 2 visits [14.0, 42.0, 32.0, 1.0, 2.0, 1.0, 4.0, 5.0, 1.0, 1.0]  episode_count: 207 q_vals: [-4.636, -4.224, -4.115, -7.965, -6.194, -8.956, -4.962, -5.784, -10.28, -7.173]
Step 104 2 visits [14.0, 42.0, 33.0, 1.0, 2.0, 1.0, 4.0, 5.0, 1.0, 1.0]  episode_count: 207 q_vals: [-4.636, -4.224, -4.3, -7.965, -6.194, -8.956, -4.962, -5.784, -10.28, -7.173]
Step 105 6 visits [14.0, 42.0, 33.0, 1.0, 2.0, 1.0, 5.0, 5.0, 1.0, 1.0]  episode_count: 210 q_vals: [-4.636, -4.224, -4.3, -7.965, -6.194, -8.956, -4.908, -5.784, -10.28, -7.173]
Step 106 1 visits [14.0, 43.0, 33.0, 1.0, 2.0, 1.0, 5.0, 5.0, 1.0, 1.0]  episode_count: 212 q_vals: [-4.636, -4.227, -4.3, -7.965, -6.194, -8.956, -4.908, -5.784, -10.28, -7.173]
Step 107 1 visits [14.0, 44.0, 33.0, 1.0, 2.0, 1.0, 5.0, 5.0, 1.0, 1.0]  episode_count: 212 q_vals: [-4.636, -4.483, -4.3, -7.965, -6.194, -8.956, -4.908, -5.784, -10.28, -7.173]
{"total_number_of_episodes": 213, "number_of_timesteps": 4770, "per_episode_reward": 19.25, "episode_reward_trend_value": 0.012222222222222238, "biggest_recent_change": 0.5500000000000007},
Step 108 2 visits [14.0, 44.0, 34.0, 1.0, 2.0, 1.0, 5.0, 5.0, 1.0, 1.0]  episode_count: 213 q_vals: [-4.636, -4.483, -4.174, -7.965, -6.194, -8.956, -4.908, -5.784, -10.28, -7.173]
Step 109 2 visits [14.0, 44.0, 35.0, 1.0, 2.0, 1.0, 5.0, 5.0, 1.0, 1.0]  episode_count: 216 q_vals: [-4.636, -4.483, -4.186, -7.965, -6.194, -8.956, -4.908, -5.784, -10.28, -7.173]
Step 110 2 visits [14.0, 44.0, 36.0, 1.0, 2.0, 1.0, 5.0, 5.0, 1.0, 1.0]  episode_count: 218 q_vals: [-4.636, -4.483, -4.07, -7.965, -6.194, -8.956, -4.908, -5.784, -10.28, -7.173]
Step 111 2 visits [14.0, 44.0, 37.0, 1.0, 2.0, 1.0, 5.0, 5.0, 1.0, 1.0]  episode_count: 219 q_vals: [-4.636, -4.483, -4.308, -7.965, -6.194, -8.956, -4.908, -5.784, -10.28, -7.173]
Step 112 6 visits [14.0, 44.0, 37.0, 1.0, 2.0, 1.0, 6.0, 5.0, 1.0, 1.0]  episode_count: 221 q_vals: [-4.636, -4.483, -4.308, -7.965, -6.194, -8.956, -4.991, -5.784, -10.28, -7.173]
{"total_number_of_episodes": 223, "number_of_timesteps": 5048, "per_episode_reward": 19.7, "episode_reward_trend_value": 0.01722222222222223, "biggest_recent_change": 0.5500000000000007},
Step 113 2 visits [14.0, 44.0, 38.0, 1.0, 2.0, 1.0, 6.0, 5.0, 1.0, 1.0]  episode_count: 223 q_vals: [-4.636, -4.483, -4.559, -7.965, -6.194, -8.956, -4.991, -5.784, -10.28, -7.173]
Step 114 0 visits [15.0, 44.0, 38.0, 1.0, 2.0, 1.0, 6.0, 5.0, 1.0, 1.0]  episode_count: 225 q_vals: [-4.677, -4.483, -4.559, -7.965, -6.194, -8.956, -4.991, -5.784, -10.28, -7.173]
Step 115 6 visits [15.0, 44.0, 38.0, 1.0, 2.0, 1.0, 7.0, 5.0, 1.0, 1.0]  episode_count: 226 q_vals: [-4.677, -4.483, -4.559, -7.965, -6.194, -8.956, -5.046, -5.784, -10.28, -7.173]
Step 116 0 visits [16.0, 44.0, 38.0, 1.0, 2.0, 1.0, 7.0, 5.0, 1.0, 1.0]  episode_count: 229 q_vals: [-4.452, -4.483, -4.559, -7.965, -6.194, -8.956, -5.046, -5.784, -10.28, -7.173]
{"total_number_of_episodes": 233, "number_of_timesteps": 5293, "per_episode_reward": 19.9, "episode_reward_trend_value": 0.013333333333333326, "biggest_recent_change": 0.4499999999999993},
Step 117 0 visits [17.0, 44.0, 38.0, 1.0, 2.0, 1.0, 7.0, 5.0, 1.0, 1.0]  episode_count: 233 q_vals: [-5.25, -4.483, -4.559, -7.965, -6.194, -8.956, -5.046, -5.784, -10.28, -7.173]
Step 118 1 visits [17.0, 45.0, 38.0, 1.0, 2.0, 1.0, 7.0, 5.0, 1.0, 1.0]  episode_count: 234 q_vals: [-5.25, -4.499, -4.559, -7.965, -6.194, -8.956, -5.046, -5.784, -10.28, -7.173]
Step 119 1 visits [17.0, 46.0, 38.0, 1.0, 2.0, 1.0, 7.0, 5.0, 1.0, 1.0]  episode_count: 238 q_vals: [-5.25, -4.516, -4.559, -7.965, -6.194, -8.956, -5.046, -5.784, -10.28, -7.173]
Step 120 1 visits [17.0, 47.0, 38.0, 1.0, 2.0, 1.0, 7.0, 5.0, 1.0, 1.0]  episode_count: 240 q_vals: [-5.25, -4.42, -4.559, -7.965, -6.194, -8.956, -5.046, -5.784, -10.28, -7.173]
Step 121 1 visits [17.0, 48.0, 38.0, 1.0, 2.0, 1.0, 7.0, 5.0, 1.0, 1.0]  episode_count: 242 q_vals: [-5.25, -4.452, -4.559, -7.965, -6.194, -8.956, -5.046, -5.784, -10.28, -7.173]
{"total_number_of_episodes": 243, "number_of_timesteps": 5461, "per_episode_reward": 19.6, "episode_reward_trend_value": 0.007222222222222246, "biggest_recent_change": 0.4499999999999993},
Step 122 1 visits [17.0, 49.0, 38.0, 1.0, 2.0, 1.0, 7.0, 5.0, 1.0, 1.0]  episode_count: 243 q_vals: [-5.25, -4.513, -4.559, -7.965, -6.194, -8.956, -5.046, -5.784, -10.28, -7.173]
Step 123 1 visits [17.0, 50.0, 38.0, 1.0, 2.0, 1.0, 7.0, 5.0, 1.0, 1.0]  episode_count: 245 q_vals: [-5.25, -4.423, -4.559, -7.965, -6.194, -8.956, -5.046, -5.784, -10.28, -7.173]
Step 124 1 visits [17.0, 51.0, 38.0, 1.0, 2.0, 1.0, 7.0, 5.0, 1.0, 1.0]  episode_count: 248 q_vals: [-5.25, -4.617, -4.559, -7.965, -6.194, -8.956, -5.046, -5.784, -10.28, -7.173]
Step 125 2 visits [17.0, 51.0, 39.0, 1.0, 2.0, 1.0, 7.0, 5.0, 1.0, 1.0]  episode_count: 251 q_vals: [-5.25, -4.617, -4.594, -7.965, -6.194, -8.956, -5.046, -5.784, -10.28, -7.173]
Step 126 6 visits [17.0, 51.0, 39.0, 1.0, 2.0, 1.0, 8.0, 5.0, 1.0, 1.0]  episode_count: 252 q_vals: [-5.25, -4.617, -4.594, -7.965, -6.194, -8.956, -4.448, -5.784, -10.28, -7.173]
{"total_number_of_episodes": 255, "number_of_timesteps": 5731, "per_episode_reward": 19.6, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.4499999999999993},
Step 127 6 visits [17.0, 51.0, 39.0, 1.0, 2.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 255 q_vals: [-5.25, -4.617, -4.594, -7.965, -6.194, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 128 2 visits [17.0, 51.0, 40.0, 1.0, 2.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 257 q_vals: [-5.25, -4.617, -4.616, -7.965, -6.194, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 129 2 visits [17.0, 51.0, 41.0, 1.0, 2.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 258 q_vals: [-5.25, -4.617, -4.83, -7.965, -6.194, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 130 1 visits [17.0, 52.0, 41.0, 1.0, 2.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 259 q_vals: [-5.25, -4.624, -4.83, -7.965, -6.194, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 131 1 visits [17.0, 53.0, 41.0, 1.0, 2.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 261 q_vals: [-5.25, -4.65, -4.83, -7.965, -6.194, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 132 1 visits [17.0, 54.0, 41.0, 1.0, 2.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 264 q_vals: [-5.25, -4.825, -4.83, -7.965, -6.194, -8.956, -5.606, -5.784, -10.28, -7.173]
{"total_number_of_episodes": 265, "number_of_timesteps": 5958, "per_episode_reward": 19.4, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.4499999999999993},
Step 133 2 visits [17.0, 54.0, 42.0, 1.0, 2.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 265 q_vals: [-5.25, -4.825, -5.047, -7.965, -6.194, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 134 1 visits [17.0, 55.0, 42.0, 1.0, 2.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 267 q_vals: [-5.25, -4.978, -5.047, -7.965, -6.194, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 135 4 visits [17.0, 55.0, 42.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 268 q_vals: [-5.25, -4.978, -5.047, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 136 1 visits [17.0, 56.0, 42.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 272 q_vals: [-5.25, -4.99, -5.047, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
{"total_number_of_episodes": 275, "number_of_timesteps": 6195, "per_episode_reward": 19.55, "episode_reward_trend_value": 0.008333333333333333, "biggest_recent_change": 0.4499999999999993},
Step 137 1 visits [17.0, 57.0, 42.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 275 q_vals: [-5.25, -5.002, -5.047, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 138 2 visits [17.0, 57.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 276 q_vals: [-5.25, -5.002, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 139 1 visits [17.0, 58.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 278 q_vals: [-5.25, -4.951, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 140 1 visits [17.0, 59.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 280 q_vals: [-5.25, -4.946, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
{"total_number_of_episodes": 285, "number_of_timesteps": 6401, "per_episode_reward": 19.6, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.4499999999999993},
Step 141 1 visits [17.0, 60.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 285 q_vals: [-5.25, -4.948, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 142 1 visits [17.0, 61.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 287 q_vals: [-5.25, -4.947, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 143 1 visits [17.0, 62.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 288 q_vals: [-5.25, -4.963, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 144 1 visits [17.0, 63.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 288 q_vals: [-5.25, -4.885, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 145 1 visits [17.0, 64.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 290 q_vals: [-5.25, -4.886, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 146 1 visits [17.0, 65.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 293 q_vals: [-5.25, -4.889, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
{"total_number_of_episodes": 295, "number_of_timesteps": 6611, "per_episode_reward": 19.6, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.4499999999999993},
Step 147 1 visits [17.0, 66.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 295 q_vals: [-5.25, -4.899, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 148 1 visits [17.0, 67.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 296 q_vals: [-5.25, -5.063, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 149 0 visits [18.0, 67.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 298 q_vals: [-4.958, -5.063, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 150 0 visits [19.0, 67.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 300 q_vals: [-4.977, -5.063, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 151 0 visits [20.0, 67.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 301 q_vals: [-4.837, -5.063, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 152 0 visits [21.0, 67.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 303 q_vals: [-4.983, -5.063, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
{"total_number_of_episodes": 305, "number_of_timesteps": 6859, "per_episode_reward": 19.45, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.4499999999999993},
Step 153 0 visits [22.0, 67.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 305 q_vals: [-5.004, -5.063, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 154 0 visits [23.0, 67.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 307 q_vals: [-5.083, -5.063, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 155 0 visits [24.0, 67.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 309 q_vals: [-5.128, -5.063, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 156 0 visits [25.0, 67.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 310 q_vals: [-4.972, -5.063, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 157 0 visits [26.0, 67.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 313 q_vals: [-5.008, -5.063, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 158 0 visits [27.0, 67.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 314 q_vals: [-5.041, -5.063, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
{"total_number_of_episodes": 315, "number_of_timesteps": 7085, "per_episode_reward": 19.6, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.29999999999999716},
Step 159 0 visits [28.0, 67.0, 43.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 315 q_vals: [-5.446, -5.063, -5.072, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 160 2 visits [28.0, 67.0, 44.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 319 q_vals: [-5.446, -5.063, -5.097, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 161 2 visits [28.0, 67.0, 45.0, 1.0, 3.0, 1.0, 9.0, 5.0, 1.0, 1.0]  episode_count: 321 q_vals: [-5.446, -5.063, -5.258, -7.965, -6.607, -8.956, -5.606, -5.784, -10.28, -7.173]
Step 162 7 visits [28.0, 67.0, 45.0, 1.0, 3.0, 1.0, 9.0, 6.0, 1.0, 1.0]  episode_count: 322 q_vals: [-5.446, -5.063, -5.258, -7.965, -6.607, -8.956, -5.606, -5.727, -10.28, -7.173]
{"total_number_of_episodes": 326, "number_of_timesteps": 7367, "per_episode_reward": 19.7, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.29999999999999716},
Step 163 1 visits [28.0, 68.0, 45.0, 1.0, 3.0, 1.0, 9.0, 6.0, 1.0, 1.0]  episode_count: 326 q_vals: [-5.446, -5.053, -5.258, -7.965, -6.607, -8.956, -5.606, -5.727, -10.28, -7.173]
Step 164 1 visits [28.0, 69.0, 45.0, 1.0, 3.0, 1.0, 9.0, 6.0, 1.0, 1.0]  episode_count: 328 q_vals: [-5.446, -5.061, -5.258, -7.965, -6.607, -8.956, -5.606, -5.727, -10.28, -7.173]
Step 165 1 visits [28.0, 70.0, 45.0, 1.0, 3.0, 1.0, 9.0, 6.0, 1.0, 1.0]  episode_count: 328 q_vals: [-5.446, -5.196, -5.258, -7.965, -6.607, -8.956, -5.606, -5.727, -10.28, -7.173]
Step 166 7 visits [28.0, 70.0, 45.0, 1.0, 3.0, 1.0, 9.0, 7.0, 1.0, 1.0]  episode_count: 330 q_vals: [-5.446, -5.196, -5.258, -7.965, -6.607, -8.956, -5.606, -5.598, -10.28, -7.173]
Step 167 7 visits [28.0, 70.0, 45.0, 1.0, 3.0, 1.0, 9.0, 8.0, 1.0, 1.0]  episode_count: 333 q_vals: [-5.446, -5.196, -5.258, -7.965, -6.607, -8.956, -5.606, -5.501, -10.28, -7.173]
Step 168 7 visits [28.0, 70.0, 45.0, 1.0, 3.0, 1.0, 9.0, 9.0, 1.0, 1.0]  episode_count: 334 q_vals: [-5.446, -5.196, -5.258, -7.965, -6.607, -8.956, -5.606, -5.474, -10.28, -7.173]
Step 169 7 visits [28.0, 70.0, 45.0, 1.0, 3.0, 1.0, 9.0, 10.0, 1.0, 1.0]  episode_count: 334 q_vals: [-5.446, -5.196, -5.258, -7.965, -6.607, -8.956, -5.606, -6.12, -10.28, -7.173]
{"total_number_of_episodes": 336, "number_of_timesteps": 7619, "per_episode_reward": 19.75, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.20000000000000284},
Step 170 6 visits [28.0, 70.0, 45.0, 1.0, 3.0, 1.0, 10.0, 10.0, 1.0, 1.0]  episode_count: 336 q_vals: [-5.446, -5.196, -5.258, -7.965, -6.607, -8.956, -5.308, -6.12, -10.28, -7.173]
Step 171 6 visits [28.0, 70.0, 45.0, 1.0, 3.0, 1.0, 11.0, 10.0, 1.0, 1.0]  episode_count: 338 q_vals: [-5.446, -5.196, -5.258, -7.965, -6.607, -8.956, -4.826, -6.12, -10.28, -7.173]
Step 172 6 visits [28.0, 70.0, 45.0, 1.0, 3.0, 1.0, 12.0, 10.0, 1.0, 1.0]  episode_count: 343 q_vals: [-5.446, -5.196, -5.258, -7.965, -6.607, -8.956, -4.835, -6.12, -10.28, -7.173]
Step 173 6 visits [28.0, 70.0, 45.0, 1.0, 3.0, 1.0, 13.0, 10.0, 1.0, 1.0]  episode_count: 344 q_vals: [-5.446, -5.196, -5.258, -7.965, -6.607, -8.956, -4.849, -6.12, -10.28, -7.173]
{"total_number_of_episodes": 346, "number_of_timesteps": 7889, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.25},
Step 174 6 visits [28.0, 70.0, 45.0, 1.0, 3.0, 1.0, 14.0, 10.0, 1.0, 1.0]  episode_count: 346 q_vals: [-5.446, -5.196, -5.258, -7.965, -6.607, -8.956, -4.862, -6.12, -10.28, -7.173]
Step 175 6 visits [28.0, 70.0, 45.0, 1.0, 3.0, 1.0, 15.0, 10.0, 1.0, 1.0]  episode_count: 349 q_vals: [-5.446, -5.196, -5.258, -7.965, -6.607, -8.956, -5.346, -6.12, -10.28, -7.173]
Step 176 6 visits [28.0, 70.0, 45.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 1.0]  episode_count: 350 q_vals: [-5.446, -5.196, -5.258, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -7.173]
Step 177 9 visits [28.0, 70.0, 45.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 352 q_vals: [-5.446, -5.196, -5.258, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 178 2 visits [28.0, 70.0, 46.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 353 q_vals: [-5.446, -5.196, -5.249, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
{"total_number_of_episodes": 356, "number_of_timesteps": 8074, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.25},
Step 179 2 visits [28.0, 70.0, 47.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 356 q_vals: [-5.446, -5.196, -5.273, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 180 1 visits [28.0, 71.0, 47.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 358 q_vals: [-5.446, -5.281, -5.273, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 181 2 visits [28.0, 71.0, 48.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 358 q_vals: [-5.446, -5.281, -5.258, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 182 2 visits [28.0, 71.0, 49.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 362 q_vals: [-5.446, -5.281, -5.263, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
{"total_number_of_episodes": 366, "number_of_timesteps": 8327, "per_episode_reward": 20.15, "episode_reward_trend_value": 0.006666666666666643, "biggest_recent_change": 0.25},
Step 183 2 visits [28.0, 71.0, 50.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 366 q_vals: [-5.446, -5.281, -5.236, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 184 2 visits [28.0, 71.0, 51.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 368 q_vals: [-5.446, -5.281, -5.218, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 185 2 visits [28.0, 71.0, 52.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 370 q_vals: [-5.446, -5.281, -5.2, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 186 2 visits [28.0, 71.0, 53.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 373 q_vals: [-5.446, -5.281, -5.186, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 187 2 visits [28.0, 71.0, 54.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 373 q_vals: [-5.446, -5.281, -5.183, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 188 2 visits [28.0, 71.0, 55.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 374 q_vals: [-5.446, -5.281, -5.214, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 189 2 visits [28.0, 71.0, 56.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 374 q_vals: [-5.446, -5.281, -5.206, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
{"total_number_of_episodes": 379, "number_of_timesteps": 8592, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.25},
Step 190 2 visits [28.0, 71.0, 57.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 379 q_vals: [-5.446, -5.281, -5.333, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 191 1 visits [28.0, 72.0, 57.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 381 q_vals: [-5.446, -5.412, -5.333, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 192 0 visits [29.0, 72.0, 57.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 383 q_vals: [-5.732, -5.412, -5.333, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 193 2 visits [29.0, 72.0, 58.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 383 q_vals: [-5.732, -5.412, -5.35, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 194 2 visits [29.0, 72.0, 59.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 387 q_vals: [-5.732, -5.412, -5.344, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 195 2 visits [29.0, 72.0, 60.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 387 q_vals: [-5.732, -5.412, -5.351, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 196 2 visits [29.0, 72.0, 61.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 388 q_vals: [-5.732, -5.412, -5.48, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 197 1 visits [29.0, 73.0, 61.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 388 q_vals: [-5.732, -5.411, -5.48, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
{"total_number_of_episodes": 391, "number_of_timesteps": 8877, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.25},
Step 198 1 visits [29.0, 74.0, 61.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 391 q_vals: [-5.732, -5.51, -5.48, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 199 2 visits [29.0, 74.0, 62.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 394 q_vals: [-5.732, -5.51, -5.392, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 200 2 visits [29.0, 74.0, 63.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 396 q_vals: [-5.732, -5.51, -5.381, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 201 2 visits [29.0, 74.0, 64.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 398 q_vals: [-5.732, -5.51, -5.407, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
{"total_number_of_episodes": 402, "number_of_timesteps": 9178, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.25},
Step 202 2 visits [29.0, 74.0, 65.0, 1.0, 3.0, 1.0, 16.0, 10.0, 1.0, 2.0]  episode_count: 402 q_vals: [-5.732, -5.51, -5.509, -7.965, -6.607, -8.956, -5.795, -6.12, -10.28, -9.778]
Step 203 6 visits [29.0, 74.0, 65.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 405 q_vals: [-5.732, -5.51, -5.509, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 204 2 visits [29.0, 74.0, 66.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 406 q_vals: [-5.732, -5.51, -5.426, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 205 2 visits [29.0, 74.0, 67.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 408 q_vals: [-5.732, -5.51, -5.425, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
{"total_number_of_episodes": 412, "number_of_timesteps": 9356, "per_episode_reward": 19.95, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.25},
Step 206 2 visits [29.0, 74.0, 68.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 412 q_vals: [-5.732, -5.51, -5.529, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 207 1 visits [29.0, 75.0, 68.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 413 q_vals: [-5.732, -5.511, -5.529, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 208 1 visits [29.0, 76.0, 68.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 418 q_vals: [-5.732, -5.531, -5.529, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 209 2 visits [29.0, 76.0, 69.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 420 q_vals: [-5.732, -5.531, -5.537, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 210 2 visits [29.0, 76.0, 70.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 421 q_vals: [-5.732, -5.531, -5.531, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
{"total_number_of_episodes": 423, "number_of_timesteps": 9570, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.25},
Step 211 2 visits [29.0, 76.0, 71.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 423 q_vals: [-5.732, -5.531, -5.525, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 212 2 visits [29.0, 76.0, 72.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 425 q_vals: [-5.732, -5.531, -5.519, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 213 2 visits [29.0, 76.0, 73.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 427 q_vals: [-5.732, -5.531, -5.489, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 214 2 visits [29.0, 76.0, 74.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 429 q_vals: [-5.732, -5.531, -5.475, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 215 2 visits [29.0, 76.0, 75.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 432 q_vals: [-5.732, -5.531, -5.666, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
{"total_number_of_episodes": 434, "number_of_timesteps": 9820, "per_episode_reward": 19.9, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.25},
Step 216 1 visits [29.0, 77.0, 75.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 434 q_vals: [-5.732, -5.465, -5.666, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 217 1 visits [29.0, 78.0, 75.0, 1.0, 3.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 436 q_vals: [-5.732, -5.592, -5.666, -7.965, -6.607, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 218 4 visits [29.0, 78.0, 75.0, 1.0, 4.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 436 q_vals: [-5.732, -5.592, -5.666, -7.965, -6.3, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 219 4 visits [29.0, 78.0, 75.0, 1.0, 5.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 437 q_vals: [-5.732, -5.592, -5.666, -7.965, -6.208, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 220 4 visits [29.0, 78.0, 75.0, 1.0, 6.0, 1.0, 17.0, 10.0, 1.0, 2.0]  episode_count: 439 q_vals: [-5.732, -5.592, -5.666, -7.965, -6.282, -8.956, -5.846, -6.12, -10.28, -9.778]
Step 221 6 visits [29.0, 78.0, 75.0, 1.0, 6.0, 1.0, 18.0, 10.0, 1.0, 2.0]  episode_count: 441 q_vals: [-5.732, -5.592, -5.666, -7.965, -6.282, -8.956, -5.862, -6.12, -10.28, -9.778]
Step 222 0 visits [30.0, 78.0, 75.0, 1.0, 6.0, 1.0, 18.0, 10.0, 1.0, 2.0]  episode_count: 441 q_vals: [-5.805, -5.592, -5.666, -7.965, -6.282, -8.956, -5.862, -6.12, -10.28, -9.778]
Step 223 6 visits [30.0, 78.0, 75.0, 1.0, 6.0, 1.0, 19.0, 10.0, 1.0, 2.0]  episode_count: 443 q_vals: [-5.805, -5.592, -5.666, -7.965, -6.282, -8.956, -5.859, -6.12, -10.28, -9.778]
{"total_number_of_episodes": 447, "number_of_timesteps": 10165, "per_episode_reward": 19.9, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.1999999999999993},
Step 224 6 visits [30.0, 78.0, 75.0, 1.0, 6.0, 1.0, 20.0, 10.0, 1.0, 2.0]  episode_count: 447 q_vals: [-5.805, -5.592, -5.666, -7.965, -6.282, -8.956, -5.926, -6.12, -10.28, -9.778]
Step 225 1 visits [30.0, 79.0, 75.0, 1.0, 6.0, 1.0, 20.0, 10.0, 1.0, 2.0]  episode_count: 450 q_vals: [-5.805, -5.599, -5.666, -7.965, -6.282, -8.956, -5.926, -6.12, -10.28, -9.778]
Step 226 4 visits [30.0, 79.0, 75.0, 1.0, 7.0, 1.0, 20.0, 10.0, 1.0, 2.0]  episode_count: 452 q_vals: [-5.805, -5.599, -5.666, -7.965, -6.153, -8.956, -5.926, -6.12, -10.28, -9.778]
Step 227 4 visits [30.0, 79.0, 75.0, 1.0, 8.0, 1.0, 20.0, 10.0, 1.0, 2.0]  episode_count: 454 q_vals: [-5.805, -5.599, -5.666, -7.965, -7.205, -8.956, -5.926, -6.12, -10.28, -9.778]
{"total_number_of_episodes": 457, "number_of_timesteps": 10380, "per_episode_reward": 19.85, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.1999999999999993},
Step 228 1 visits [30.0, 80.0, 75.0, 1.0, 8.0, 1.0, 20.0, 10.0, 1.0, 2.0]  episode_count: 457 q_vals: [-5.805, -5.602, -5.666, -7.965, -7.205, -8.956, -5.926, -6.12, -10.28, -9.778]
Step 229 1 visits [30.0, 81.0, 75.0, 1.0, 8.0, 1.0, 20.0, 10.0, 1.0, 2.0]  episode_count: 460 q_vals: [-5.805, -5.604, -5.666, -7.965, -7.205, -8.956, -5.926, -6.12, -10.28, -9.778]
Step 230 1 visits [30.0, 82.0, 75.0, 1.0, 8.0, 1.0, 20.0, 10.0, 1.0, 2.0]  episode_count: 461 q_vals: [-5.805, -5.75, -5.666, -7.965, -7.205, -8.956, -5.926, -6.12, -10.28, -9.778]
Step 231 0 visits [31.0, 82.0, 75.0, 1.0, 8.0, 1.0, 20.0, 10.0, 1.0, 2.0]  episode_count: 462 q_vals: [-5.813, -5.75, -5.666, -7.965, -7.205, -8.956, -5.926, -6.12, -10.28, -9.778]
Step 232 7 visits [31.0, 82.0, 75.0, 1.0, 8.0, 1.0, 20.0, 11.0, 1.0, 2.0]  episode_count: 465 q_vals: [-5.813, -5.75, -5.666, -7.965, -7.205, -8.956, -5.926, -6.276, -10.28, -9.778]
{"total_number_of_episodes": 468, "number_of_timesteps": 10589, "per_episode_reward": 19.7, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
Step 233 0 visits [32.0, 82.0, 75.0, 1.0, 8.0, 1.0, 20.0, 11.0, 1.0, 2.0]  episode_count: 468 q_vals: [-5.661, -5.75, -5.666, -7.965, -7.205, -8.956, -5.926, -6.276, -10.28, -9.778]
Step 234 0 visits [33.0, 82.0, 75.0, 1.0, 8.0, 1.0, 20.0, 11.0, 1.0, 2.0]  episode_count: 471 q_vals: [-5.691, -5.75, -5.666, -7.965, -7.205, -8.956, -5.926, -6.276, -10.28, -9.778]
Step 235 0 visits [34.0, 82.0, 75.0, 1.0, 8.0, 1.0, 20.0, 11.0, 1.0, 2.0]  episode_count: 473 q_vals: [-6.105, -5.75, -5.666, -7.965, -7.205, -8.956, -5.926, -6.276, -10.28, -9.778]
Step 236 2 visits [34.0, 82.0, 76.0, 1.0, 8.0, 1.0, 20.0, 11.0, 1.0, 2.0]  episode_count: 476 q_vals: [-6.105, -5.75, -5.693, -7.965, -7.205, -8.956, -5.926, -6.276, -10.28, -9.778]
{"total_number_of_episodes": 478, "number_of_timesteps": 10790, "per_episode_reward": 19.75, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.1999999999999993},
Step 237 6 visits [34.0, 82.0, 76.0, 1.0, 8.0, 1.0, 21.0, 11.0, 1.0, 2.0]  episode_count: 478 q_vals: [-6.105, -5.75, -5.693, -7.965, -7.205, -8.956, -5.957, -6.276, -10.28, -9.778]
Step 238 2 visits [34.0, 82.0, 77.0, 1.0, 8.0, 1.0, 21.0, 11.0, 1.0, 2.0]  episode_count: 480 q_vals: [-6.105, -5.75, -5.807, -7.965, -7.205, -8.956, -5.957, -6.276, -10.28, -9.778]
Step 239 6 visits [34.0, 82.0, 77.0, 1.0, 8.0, 1.0, 22.0, 11.0, 1.0, 2.0]  episode_count: 483 q_vals: [-6.105, -5.75, -5.807, -7.965, -7.205, -8.956, -5.958, -6.276, -10.28, -9.778]
Step 240 6 visits [34.0, 82.0, 77.0, 1.0, 8.0, 1.0, 23.0, 11.0, 1.0, 2.0]  episode_count: 487 q_vals: [-6.105, -5.75, -5.807, -7.965, -7.205, -8.956, -5.699, -6.276, -10.28, -9.778]
Step 241 6 visits [34.0, 82.0, 77.0, 1.0, 8.0, 1.0, 24.0, 11.0, 1.0, 2.0]  episode_count: 487 q_vals: [-6.105, -5.75, -5.807, -7.965, -7.205, -8.956, -5.738, -6.276, -10.28, -9.778]
{"total_number_of_episodes": 488, "number_of_timesteps": 10951, "per_episode_reward": 19.6, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000213},
Step 242 6 visits [34.0, 82.0, 77.0, 1.0, 8.0, 1.0, 25.0, 11.0, 1.0, 2.0]  episode_count: 488 q_vals: [-6.105, -5.75, -5.807, -7.965, -7.205, -8.956, -5.555, -6.276, -10.28, -9.778]
Step 243 6 visits [34.0, 82.0, 77.0, 1.0, 8.0, 1.0, 26.0, 11.0, 1.0, 2.0]  episode_count: 492 q_vals: [-6.105, -5.75, -5.807, -7.965, -7.205, -8.956, -5.624, -6.276, -10.28, -9.778]
Step 244 6 visits [34.0, 82.0, 77.0, 1.0, 8.0, 1.0, 27.0, 11.0, 1.0, 2.0]  episode_count: 493 q_vals: [-6.105, -5.75, -5.807, -7.965, -7.205, -8.956, -5.685, -6.276, -10.28, -9.778]
Step 245 6 visits [34.0, 82.0, 77.0, 1.0, 8.0, 1.0, 28.0, 11.0, 1.0, 2.0]  episode_count: 496 q_vals: [-6.105, -5.75, -5.807, -7.965, -7.205, -8.956, -5.709, -6.276, -10.28, -9.778]
{"total_number_of_episodes": 498, "number_of_timesteps": 11151, "per_episode_reward": 19.5, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000213},
Step 246 6 visits [34.0, 82.0, 77.0, 1.0, 8.0, 1.0, 29.0, 11.0, 1.0, 2.0]  episode_count: 498 q_vals: [-6.105, -5.75, -5.807, -7.965, -7.205, -8.956, -5.723, -6.276, -10.28, -9.778]
Step 247 6 visits [34.0, 82.0, 77.0, 1.0, 8.0, 1.0, 30.0, 11.0, 1.0, 2.0]  episode_count: 501 q_vals: [-6.105, -5.75, -5.807, -7.965, -7.205, -8.956, -6.081, -6.276, -10.28, -9.778]
Step 248 1 visits [34.0, 83.0, 77.0, 1.0, 8.0, 1.0, 30.0, 11.0, 1.0, 2.0]  episode_count: 503 q_vals: [-6.105, -5.764, -5.807, -7.965, -7.205, -8.956, -6.081, -6.276, -10.28, -9.778]
Step 249 1 visits [34.0, 84.0, 77.0, 1.0, 8.0, 1.0, 30.0, 11.0, 1.0, 2.0]  episode_count: 507 q_vals: [-6.105, -5.774, -5.807, -7.965, -7.205, -8.956, -6.081, -6.276, -10.28, -9.778]
{"total_number_of_episodes": 509, "number_of_timesteps": 11346, "per_episode_reward": 19.55, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.15000000000000213},
Step 250 1 visits [34.0, 85.0, 77.0, 1.0, 8.0, 1.0, 30.0, 11.0, 1.0, 2.0]  episode_count: 509 q_vals: [-6.105, -5.778, -5.807, -7.965, -7.205, -8.956, -6.081, -6.276, -10.28, -9.778]
Step 251 1 visits [34.0, 86.0, 77.0, 1.0, 8.0, 1.0, 30.0, 11.0, 1.0, 2.0]  episode_count: 512 q_vals: [-6.105, -5.781, -5.807, -7.965, -7.205, -8.956, -6.081, -6.276, -10.28, -9.778]
Step 252 1 visits [34.0, 87.0, 77.0, 1.0, 8.0, 1.0, 30.0, 11.0, 1.0, 2.0]  episode_count: 513 q_vals: [-6.105, -5.8, -5.807, -7.965, -7.205, -8.956, -6.081, -6.276, -10.28, -9.778]
{"total_number_of_episodes": 519, "number_of_timesteps": 11547, "per_episode_reward": 19.45, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.15000000000000213},
Step 253 2 visits [34.0, 87.0, 78.0, 1.0, 8.0, 1.0, 30.0, 11.0, 1.0, 2.0]  episode_count: 519 q_vals: [-6.105, -5.8, -5.809, -7.965, -7.205, -8.956, -6.081, -6.276, -10.28, -9.778]
Step 254 2 visits [34.0, 87.0, 79.0, 1.0, 8.0, 1.0, 30.0, 11.0, 1.0, 2.0]  episode_count: 521 q_vals: [-6.105, -5.8, -5.807, -7.965, -7.205, -8.956, -6.081, -6.276, -10.28, -9.778]
Step 255 2 visits [34.0, 87.0, 80.0, 1.0, 8.0, 1.0, 30.0, 11.0, 1.0, 2.0]  episode_count: 523 q_vals: [-6.105, -5.8, -5.734, -7.965, -7.205, -8.956, -6.081, -6.276, -10.28, -9.778]
Step 256 2 visits [34.0, 87.0, 81.0, 1.0, 8.0, 1.0, 30.0, 11.0, 1.0, 2.0]  episode_count: 527 q_vals: [-6.105, -5.8, -5.844, -7.965, -7.205, -8.956, -6.081, -6.276, -10.28, -9.778]
{"total_number_of_episodes": 529, "number_of_timesteps": 11687, "per_episode_reward": 19.15, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.3000000000000007},
Step 257 1 visits [34.0, 88.0, 81.0, 1.0, 8.0, 1.0, 30.0, 11.0, 1.0, 2.0]  episode_count: 529 q_vals: [-6.105, -5.818, -5.844, -7.965, -7.205, -8.956, -6.081, -6.276, -10.28, -9.778]
Step 258 7 visits [34.0, 88.0, 81.0, 1.0, 8.0, 1.0, 30.0, 12.0, 1.0, 2.0]  episode_count: 533 q_vals: [-6.105, -5.818, -5.844, -7.965, -7.205, -8.956, -6.081, -6.22, -10.28, -9.778]
Step 259 7 visits [34.0, 88.0, 81.0, 1.0, 8.0, 1.0, 30.0, 13.0, 1.0, 2.0]  episode_count: 538 q_vals: [-6.105, -5.818, -5.844, -7.965, -7.205, -8.956, -6.081, -6.88, -10.28, -9.778]
Step 260 1 visits [34.0, 89.0, 81.0, 1.0, 8.0, 1.0, 30.0, 13.0, 1.0, 2.0]  episode_count: 538 q_vals: [-6.105, -5.832, -5.844, -7.965, -7.205, -8.956, -6.081, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 542, "number_of_timesteps": 11878, "per_episode_reward": 19.05, "episode_reward_trend_value": -0.00944444444444442, "biggest_recent_change": 0.3000000000000007},
Step 261 2 visits [34.0, 89.0, 82.0, 1.0, 8.0, 1.0, 30.0, 13.0, 1.0, 2.0]  episode_count: 542 q_vals: [-6.105, -5.832, -5.956, -7.965, -7.205, -8.956, -6.081, -6.88, -10.28, -9.778]
Step 262 1 visits [34.0, 90.0, 82.0, 1.0, 8.0, 1.0, 30.0, 13.0, 1.0, 2.0]  episode_count: 545 q_vals: [-6.105, -5.835, -5.956, -7.965, -7.205, -8.956, -6.081, -6.88, -10.28, -9.778]
Step 263 1 visits [34.0, 91.0, 82.0, 1.0, 8.0, 1.0, 30.0, 13.0, 1.0, 2.0]  episode_count: 547 q_vals: [-6.105, -5.932, -5.956, -7.965, -7.205, -8.956, -6.081, -6.88, -10.28, -9.778]
Step 264 3 visits [34.0, 91.0, 82.0, 2.0, 8.0, 1.0, 30.0, 13.0, 1.0, 2.0]  episode_count: 550 q_vals: [-6.105, -5.932, -5.956, -6.916, -7.205, -8.956, -6.081, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 552, "number_of_timesteps": 12035, "per_episode_reward": 19.0, "episode_reward_trend_value": -0.00944444444444446, "biggest_recent_change": 0.3000000000000007},
Step 265 3 visits [34.0, 91.0, 82.0, 3.0, 8.0, 1.0, 30.0, 13.0, 1.0, 2.0]  episode_count: 552 q_vals: [-6.105, -5.932, -5.956, -4.744, -7.205, -8.956, -6.081, -6.88, -10.28, -9.778]
Step 266 3 visits [34.0, 91.0, 82.0, 4.0, 8.0, 1.0, 30.0, 13.0, 1.0, 2.0]  episode_count: 556 q_vals: [-6.105, -5.932, -5.956, -3.558, -7.205, -8.956, -6.081, -6.88, -10.28, -9.778]
Step 267 3 visits [34.0, 91.0, 82.0, 5.0, 8.0, 1.0, 30.0, 13.0, 1.0, 2.0]  episode_count: 561 q_vals: [-6.105, -5.932, -5.956, -6.466, -7.205, -8.956, -6.081, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 563, "number_of_timesteps": 12198, "per_episode_reward": 19.05, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.3000000000000007},
Step 268 3 visits [34.0, 91.0, 82.0, 6.0, 8.0, 1.0, 30.0, 13.0, 1.0, 2.0]  episode_count: 563 q_vals: [-6.105, -5.932, -5.956, -6.651, -7.205, -8.956, -6.081, -6.88, -10.28, -9.778]
Step 269 6 visits [34.0, 91.0, 82.0, 6.0, 8.0, 1.0, 31.0, 13.0, 1.0, 2.0]  episode_count: 565 q_vals: [-6.105, -5.932, -5.956, -6.651, -7.205, -8.956, -5.913, -6.88, -10.28, -9.778]
Step 270 6 visits [34.0, 91.0, 82.0, 6.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 571 q_vals: [-6.105, -5.932, -5.956, -6.651, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
Step 271 1 visits [34.0, 92.0, 82.0, 6.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 572 q_vals: [-6.105, -5.936, -5.956, -6.651, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 576, "number_of_timesteps": 12353, "per_episode_reward": 18.95, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3000000000000007},
Step 272 3 visits [34.0, 92.0, 82.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 576 q_vals: [-6.105, -5.936, -5.956, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
Step 273 1 visits [34.0, 93.0, 82.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 579 q_vals: [-6.105, -5.872, -5.956, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
Step 274 1 visits [34.0, 94.0, 82.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 582 q_vals: [-6.105, -5.869, -5.956, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 587, "number_of_timesteps": 12518, "per_episode_reward": 18.7, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.3000000000000007},
Step 275 1 visits [34.0, 95.0, 82.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 587 q_vals: [-6.105, -5.818, -5.956, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
Step 276 1 visits [34.0, 96.0, 82.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 589 q_vals: [-6.105, -5.839, -5.956, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
Step 277 1 visits [34.0, 97.0, 82.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 593 q_vals: [-6.105, -5.941, -5.956, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 597, "number_of_timesteps": 12637, "per_episode_reward": 18.4, "episode_reward_trend_value": -0.012222222222222238, "biggest_recent_change": 0.3000000000000007},
Step 278 2 visits [34.0, 97.0, 83.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 597 q_vals: [-6.105, -5.941, -5.974, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
Step 279 0 visits [35.0, 97.0, 83.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 597 q_vals: [-5.957, -5.941, -5.974, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
Step 280 0 visits [36.0, 97.0, 83.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 604 q_vals: [-6.261, -5.941, -5.974, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
Step 281 1 visits [36.0, 98.0, 83.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 606 q_vals: [-6.261, -5.941, -5.974, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 609, "number_of_timesteps": 12806, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.01444444444444445, "biggest_recent_change": 0.3000000000000007},
Step 282 1 visits [36.0, 99.0, 83.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 609[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
 q_vals: [-6.261, -5.956, -5.974, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
Step 283 2 visits [36.0, 99.0, 84.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 610 q_vals: [-6.261, -5.956, -6.124, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
Step 284 1 visits [36.0, 100.0, 84.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 613 q_vals: [-6.261, -5.975, -6.124, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
Step 285 1 visits [36.0, 101.0, 84.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 615 q_vals: [-6.261, -5.977, -6.124, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
Step 286 1 visits [36.0, 102.0, 84.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 617 q_vals: [-6.261, -5.918, -6.124, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 619, "number_of_timesteps": 12993, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.016111111111111104, "biggest_recent_change": 0.3000000000000007},
Step 287 1 visits [36.0, 103.0, 84.0, 7.0, 8.0, 1.0, 32.0, 13.0, 1.0, 2.0]  episode_count: 619 q_vals: [-6.261, -6.053, -6.124, -7.876, -7.205, -8.956, -6.21, -6.88, -10.28, -9.778]
Step 288 6 visits [36.0, 103.0, 84.0, 7.0, 8.0, 1.0, 33.0, 13.0, 1.0, 2.0]  episode_count: 621 q_vals: [-6.261, -6.053, -6.124, -7.876, -7.205, -8.956, -6.216, -6.88, -10.28, -9.778]
Step 289 6 visits [36.0, 103.0, 84.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 626 q_vals: [-6.261, -6.053, -6.124, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 629, "number_of_timesteps": 13185, "per_episode_reward": 17.9, "episode_reward_trend_value": -0.01388888888888889, "biggest_recent_change": 0.3000000000000007},
Step 290 1 visits [36.0, 104.0, 84.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 629 q_vals: [-6.261, -6.063, -6.124, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 291 1 visits [36.0, 105.0, 84.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 631 q_vals: [-6.261, -6.159, -6.124, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 292 0 visits [37.0, 105.0, 84.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 636 q_vals: [-6.578, -6.159, -6.124, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 293 2 visits [37.0, 105.0, 85.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 638 q_vals: [-6.578, -6.159, -6.145, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 643, "number_of_timesteps": 13375, "per_episode_reward": 17.65, "episode_reward_trend_value": -0.015555555555555578, "biggest_recent_change": 0.3000000000000007},
Step 294 2 visits [37.0, 105.0, 86.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 643 q_vals: [-6.578, -6.159, -6.152, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 295 2 visits [37.0, 105.0, 87.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 645 q_vals: [-6.578, -6.159, -6.082, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 296 2 visits [37.0, 105.0, 88.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 648 q_vals: [-6.578, -6.159, -6.093, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 653, "number_of_timesteps": 13510, "per_episode_reward": 17.6, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 0.3000000000000007},
Step 297 2 visits [37.0, 105.0, 89.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 653 q_vals: [-6.578, -6.159, -6.1, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 298 2 visits [37.0, 105.0, 90.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 654 q_vals: [-6.578, -6.159, -6.252, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 299 1 visits [37.0, 106.0, 90.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 656 q_vals: [-6.578, -6.115, -6.252, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 663, "number_of_timesteps": 13648, "per_episode_reward": 17.45, "episode_reward_trend_value": -0.01777777777777779, "biggest_recent_change": 0.3000000000000007},
Step 300 1 visits [37.0, 107.0, 90.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 663 q_vals: [-6.578, -6.212, -6.252, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 301 1 visits [37.0, 108.0, 90.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 664 q_vals: [-6.578, -6.217, -6.252, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 302 1 visits [37.0, 109.0, 90.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 667 q_vals: [-6.578, -6.334, -6.252, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 303 2 visits [37.0, 109.0, 91.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 670 q_vals: [-6.578, -6.334, -6.27, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 674, "number_of_timesteps": 13796, "per_episode_reward": 17.25, "episode_reward_trend_value": -0.01888888888888888, "biggest_recent_change": 0.3000000000000007},
Step 304 2 visits [37.0, 109.0, 92.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 674 q_vals: [-6.578, -6.334, -6.394, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 305 1 visits [37.0, 110.0, 92.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 677 q_vals: [-6.578, -6.349, -6.394, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 306 1 visits [37.0, 111.0, 92.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 680 q_vals: [-6.578, -6.353, -6.394, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 307 1 visits [37.0, 112.0, 92.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 683 q_vals: [-6.578, -6.352, -6.394, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 687, "number_of_timesteps": 13963, "per_episode_reward": 17.1, "episode_reward_trend_value": -0.017777777777777753, "biggest_recent_change": 0.3000000000000007},
Step 308 1 visits [37.0, 113.0, 92.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 687 q_vals: [-6.578, -6.365, -6.394, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 309 1 visits [37.0, 114.0, 92.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 688 q_vals: [-6.578, -6.476, -6.394, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 310 2 visits [37.0, 114.0, 93.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 691 q_vals: [-6.578, -6.476, -6.41, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 311 2 visits [37.0, 114.0, 94.0, 7.0, 8.0, 1.0, 34.0, 13.0, 1.0, 2.0]  episode_count: 695 q_vals: [-6.578, -6.476, -6.424, -7.876, -7.205, -8.956, -6.578, -6.88, -10.28, -9.778]
Step 312 6 visits [37.0, 114.0, 94.0, 7.0, 8.0, 1.0, 35.0, 13.0, 1.0, 2.0]  episode_count: 695 [starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
q_vals: [-6.578, -6.476, -6.424, -7.876, -7.205, -8.956, -6.616, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 699, "number_of_timesteps": 14141, "per_episode_reward": 16.8, "episode_reward_trend_value": -0.017777777777777753, "biggest_recent_change": 0.3000000000000007},
Step 313 2 visits [37.0, 114.0, 95.0, 7.0, 8.0, 1.0, 35.0, 13.0, 1.0, 2.0]  episode_count: 699 q_vals: [-6.578, -6.476, -6.439, -7.876, -7.205, -8.956, -6.616, -6.88, -10.28, -9.778]
Step 314 0 visits [38.0, 114.0, 95.0, 7.0, 8.0, 1.0, 35.0, 13.0, 1.0, 2.0]  episode_count: 701 q_vals: [-6.609, -6.476, -6.439, -7.876, -7.205, -8.956, -6.616, -6.88, -10.28, -9.778]
Step 315 2 visits [38.0, 114.0, 96.0, 7.0, 8.0, 1.0, 35.0, 13.0, 1.0, 2.0]  episode_count: 705 q_vals: [-6.609, -6.476, -6.376, -7.876, -7.205, -8.956, -6.616, -6.88, -10.28, -9.778]
Step 316 2 visits [38.0, 114.0, 97.0, 7.0, 8.0, 1.0, 35.0, 13.0, 1.0, 2.0]  episode_count: 707 q_vals: [-6.609, -6.476, -6.49, -7.876, -7.205, -8.956, -6.616, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 709, "number_of_timesteps": 14321, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.3000000000000007},
Step 317 6 visits [38.0, 114.0, 97.0, 7.0, 8.0, 1.0, 36.0, 13.0, 1.0, 2.0]  episode_count: 709 q_vals: [-6.609, -6.476, -6.49, -7.876, -7.205, -8.956, -6.598, -6.88, -10.28, -9.778]
Step 318 6 visits [38.0, 114.0, 97.0, 7.0, 8.0, 1.0, 37.0, 13.0, 1.0, 2.0]  episode_count: 713 q_vals: [-6.609, -6.476, -6.49, -7.876, -7.205, -8.956, -6.585, -6.88, -10.28, -9.778]
Step 319 6 visits [38.0, 114.0, 97.0, 7.0, 8.0, 1.0, 38.0, 13.0, 1.0, 2.0]  episode_count: 715 q_vals: [-6.609, -6.476, -6.49, -7.876, -7.205, -8.956, -6.582, -6.88, -10.28, -9.778]
Step 320 6 visits [38.0, 114.0, 97.0, 7.0, 8.0, 1.0, 39.0, 13.0, 1.0, 2.0]  episode_count: 717 q_vals: [-6.609, -6.476, -6.49, -7.876, -7.205, -8.956, -6.58, -6.88, -10.28, -9.778]
{"total_number_of_episodes": 721, "number_of_timesteps": 14537, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.01388888888888889, "biggest_recent_change": 0.3000000000000007},
Step 321 6 visits [38.0, 114.0, 97.0, 7.0, 8.0, 1.0, 40.0, 13.0, 1.0, 2.0]  episode_count: 721 q_vals: [-6.609, -6.476, -6.49, -7.876, -7.205, -8.956, -6.576, -6.88, -10.28, -9.778]
Step 322 6 visits [38.0, 114.0, 97.0, 7.0, 8.0, 1.0, 41.0, 13.0, 1.0, 2.0]  episode_count: 722 q_vals: [-6.609, -6.476, -6.49, -7.876, -7.205, -8.956, -6.608, -6.88, -10.28, -9.778]
Step 323 7 visits [38.0, 114.0, 97.0, 7.0, 8.0, 1.0, 41.0, 14.0, 1.0, 2.0]  episode_count: 724 q_vals: [-6.609, -6.476, -6.49, -7.876, -7.205, -8.956, -6.608, -6.804, -10.28, -9.778]
Step 324 7 visits [38.0, 114.0, 97.0, 7.0, 8.0, 1.0, 41.0, 15.0, 1.0, 2.0]  episode_count: 728 q_vals: [-6.609, -6.476, -6.49, -7.876, -7.205, -8.956, -6.608, -6.81, -10.28, -9.778]
Step 325 7 visits [38.0, 114.0, 97.0, 7.0, 8.0, 1.0, 41.0, 16.0, 1.0, 2.0]  episode_count: 730 q_vals: [-6.609, -6.476, -6.49, -7.876, -7.205, -8.956, -6.608, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 733, "number_of_timesteps": 14744, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.014444444444444413, "biggest_recent_change": 0.3000000000000007},
Step 326 0 visits [39.0, 114.0, 97.0, 7.0, 8.0, 1.0, 41.0, 16.0, 1.0, 2.0]  episode_count: 733 q_vals: [-6.612, -6.476, -6.49, -7.876, -7.205, -8.956, -6.608, -7.333, -10.28, -9.778]
Step 327 0 visits [40.0, 114.0, 97.0, 7.0, 8.0, 1.0, 41.0, 16.0, 1.0, 2.0]  episode_count: 734 q_vals: [-6.614, -6.476, -6.49, -7.876, -7.205, -8.956, -6.608, -7.333, -10.28, -9.778]
Step 328 6 visits [40.0, 114.0, 97.0, 7.0, 8.0, 1.0, 42.0, 16.0, 1.0, 2.0]  episode_count: 736 q_vals: [-6.614, -6.476, -6.49, -7.876, -7.205, -8.956, -6.591, -7.333, -10.28, -9.778]
Step 329 6 visits [40.0, 114.0, 97.0, 7.0, 8.0, 1.0, 43.0, 16.0, 1.0, 2.0]  episode_count: 739 q_vals: [-6.614, -6.476, -6.49, -7.876, -7.205, -8.956, -6.583, -7.333, -10.28, -9.778]
Step 330 6 visits [40.0, 114.0, 97.0, 7.0, 8.0, 1.0, 44.0, 16.0, 1.0, 2.0]  episode_count: 741 q_vals: [-6.614, -6.476, -6.49, -7.876, -7.205, -8.956, -6.593, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 743, "number_of_timesteps": 14960, "per_episode_reward": 16.7, "episode_reward_trend_value": -0.010555555555555547, "biggest_recent_change": 0.3000000000000007},
Step 331 6 visits [40.0, 114.0, 97.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 743 q_vals: [-6.614, -6.476, -6.49, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 332 0 visits [41.0, 114.0, 97.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 746 q_vals: [-6.641, -6.476, -6.49, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 333 2 visits [41.0, 114.0, 98.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 748 q_vals: [-6.641, -6.476, -6.424, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 334 2 visits [41.0, 114.0, 99.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 750 q_vals: [-6.641, -6.476, -6.427, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 335 2 visits [41.0, 114.0, 100.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 751 q_vals: [-6.641, -6.476, -6.428, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 754, "number_of_timesteps": 15143, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.010555555555555587, "biggest_recent_change": 0.3000000000000007},
Step 336 2 visits [41.0, 114.0, 101.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 754 q_vals: [-6.641, -6.476, -6.442, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 337 2 visits [41.0, 114.0, 102.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 755 q_vals: [-6.641, -6.476, -6.456, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 338 2 visits [41.0, 114.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 757 q_vals: [-6.641, -6.476, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 339 1 visits [41.0, 115.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 758 q_vals: [-6.641, -6.488, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 340 1 visits [41.0, 116.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 760 q_vals: [-6.641, -6.495, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 341 0 visits [42.0, 116.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 763 q_vals: [-6.64, -6.495, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 764, "number_of_timesteps": 15397, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.3000000000000007},
Step 342 0 visits [43.0, 116.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 764 q_vals: [-6.669, -6.495, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 343 1 visits [43.0, 117.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 765 q_vals: [-6.669, -6.507, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 344 1 visits [43.0, 118.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 770 q_vals: [-6.669, -6.519, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 345 1 visits [43.0, 119.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 772 q_vals: [-6.669, -6.526, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 346 0 visits [44.0, 119.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 773 q_vals: [-6.697, -6.526, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 775, "number_of_timesteps": 15664, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.3000000000000007},
Step 347 1 visits [44.0, 120.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 775 q_vals: [-6.697, -6.526, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 348 1 visits [44.0, 121.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 778 q_vals: [-6.697, -6.537, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 349 1 visits [44.0, 122.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 780 q_vals: [-6.697, -6.542, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 350 1 visits [44.0, 123.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 784 q_vals: [-6.697, -6.552, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 786, "number_of_timesteps": 15849, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.005000000000000031, "biggest_recent_change": 0.3000000000000007},
Step 351 0 visits [45.0, 123.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 786 q_vals: [-6.707, -6.552, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 352 1 visits [45.0, 124.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 787 q_vals: [-6.707, -6.552, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 353 1 visits [45.0, 125.0, 103.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 790 q_vals: [-6.707, -6.658, -6.58, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 354 2 visits [45.0, 125.0, 104.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 790 q_vals: [-6.707, -6.658, -6.592, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 355 0 visits [46.0, 125.0, 104.0, 7.0, 8.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 791 q_vals: [-6.991, -6.658, -6.592, -7.876, -7.205, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 356 4 visits [46.0, 125.0, 104.0, 7.0, 9.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 795 q_vals: [-6.991, -6.658, -6.592, -7.876, -7.031, -8.956, -6.803, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 800, "number_of_timesteps": 16170, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.14999999999999858},
Step 357 4 visits [46.0, 125.0, 104.0, 7.0, 10.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 800 q_vals: [-6.991, -6.658, -6.592, -7.876, -7.118, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 358 4 visits [46.0, 125.0, 104.0, 7.0, 11.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 800 q_vals: [-6.991, -6.658, -6.592, -7.876, -8.266, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 359 2 visits [46.0, 125.0, 105.0, 7.0, 11.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 803 q_vals: [-6.991, -6.658, -6.602, -7.876, -8.266, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 360 2 visits [46.0, 125.0, 106.0, 7.0, 11.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 807 q_vals: [-6.991, -6.658, -6.539, -7.876, -8.266, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 361 2 visits [46.0, 125.0, 107.0, 7.0, 11.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 809 q_vals: [-6.991, -6.658, -6.663, -7.876, -8.266, -8.956, -6.803, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 812, "number_of_timesteps": 16382, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
Step 362 2 visits [46.0, 125.0, 108.0, 7.0, 11.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 812 q_vals: [-6.991, -6.658, -6.784, -7.876, -8.266, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 363 1 visits [46.0, 126.0, 108.0, 7.0, 11.0, 1.0, 45.0, 16.0, 1.0, 2.0]  episode_count: 816 q_vals: [-6.991, -6.668, -6.784, -7.876, -8.266, -8.956, -6.803, -7.333, -10.28, -9.778]
Step 364 6 visits [46.0, 126.0, 108.0, 7.0, 11.0, 1.0, 46.0, 16.0, 1.0, 2.0]  episode_count: 818 q_vals: [-6.991, -6.668, -6.784, -7.876, -8.266, -8.956, -6.827, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 822, "number_of_timesteps": 16513, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
Step 365 1 visits [46.0, 127.0, 108.0, 7.0, 11.0, 1.0, 46.0, 16.0, 1.0, 2.0]  episode_count: 822 q_vals: [-6.991, -6.615, -6.784, -7.876, -8.266, -8.956, -6.827, -7.333, -10.28, -9.778]
Step 366 1 visits [46.0, 128.0, 108.0, 7.0, 11.0, 1.0, 46.0, 16.0, 1.0, 2.0]  episode_count: 823 q_vals: [-6.991, -6.718, -6.784, -7.876, -8.266, -8.956, -6.827, -7.333, -10.28, -9.778]
Step 367 6 visits [46.0, 128.0, 108.0, 7.0, 11.0, 1.0, 47.0, 16.0, 1.0, 2.0]  episode_count: 825 q_vals: [-6.991, -6.718, -6.784, -7.876, -8.266, -8.956, -6.682, -7.333, -10.28, -9.778]
Step 368 6 visits [46.0, 128.0, 108.0, 7.0, 11.0, 1.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 827 q_vals: [-6.991, -6.718, -6.784, -7.876, -8.266, -8.956, -6.954, -7.333, -10.28, -9.778]
Step 369 1 visits [46.0, 129.0, 108.0, 7.0, 11.0, 1.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 828 q_vals: [-6.991, -6.727, -6.784, -7.876, -8.266, -8.956, -6.954, -7.333, -10.28, -9.778]
Step 370 1 visits [46.0, 130.0, 108.0, 7.0, 11.0, 1.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 831 q_vals: [-6.991, -6.73, -6.784, -7.876, -8.266, -8.956, -6.954, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 834, "number_of_timesteps": 16778, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 371 1 visits [46.0, 131.0, 108.0, 7.0, 11.0, 1.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 834 q_vals: [-6.991, -6.736, -6.784, -7.876, -8.266, -8.956, -6.954, -7.333, -10.28, -9.778]
Step 372 5 visits [46.0, 131.0, 108.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 837 q_vals: [-6.991, -6.736, -6.784, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 373 1 visits [46.0, 132.0, 108.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 838 q_vals: [-6.991, -6.712, -6.784, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 374 1 visits [46.0, 133.0, 108.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 841 q_vals: [-6.991, -6.69, -6.784, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 375 1 visits [46.0, 134.0, 108.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 843 q_vals: [-6.991, -6.699, -6.784, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 844, "number_of_timesteps": 16960, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.10000000000000142},
Step 376 1 visits [46.0, 135.0, 108.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 844 q_vals: [-6.991, -6.708, -6.784, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 377 1 visits [46.0, 136.0, 108.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 848 q_vals: [-6.991, -6.711, -6.784, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 378 1 visits [46.0, 137.0, 108.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 849 q_vals: [-6.991, -6.806, -6.784, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 379 2 visits [46.0, 137.0, 109.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 851 q_vals: [-6.991, -6.806, -6.789, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 380 2 visits [46.0, 137.0, 110.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 853 q_vals: [-6.991, -6.806, -6.727, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 381 2 visits [46.0, 137.0, 111.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 853 q_vals: [-6.991, -6.806, -6.739, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 857, "number_of_timesteps": 17250, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 382 2 visits [46.0, 137.0, 112.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 857 q_vals: [-6.991, -6.806, -6.746, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 383 2 visits [46.0, 137.0, 113.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 859 q_vals: [-6.991, -6.806, -6.686, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 384 2 visits [46.0, 137.0, 114.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 859 q_vals: [-6.991, -6.806, -6.697, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 385 2 visits [46.0, 137.0, 115.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 862 q_vals: [-6.991, -6.806, -6.798, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 386 2 visits [46.0, 137.0, 116.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 866 q_vals: [-6.991, -6.806, -6.808, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 867, "number_of_timesteps": 17472, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 387 2 visits [46.0, 137.0, 117.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 867 q_vals: [-6.991, -6.806, -6.817, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 388 2 visits [46.0, 137.0, 118.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 869 q_vals: [-6.991, -6.806, -6.759, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 389 2 visits [46.0, 137.0, 119.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 872 q_vals: [-6.991, -6.806, -6.769, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 390 2 visits [46.0, 137.0, 120.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 875 q_vals: [-6.991, -6.806, -6.777, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 877, "number_of_timesteps": 17634, "per_episode_reward": 16.65, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
Step 391 2 visits [46.0, 137.0, 121.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 877 q_vals: [-6.991, -6.806, -6.786, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 392 2 visits [46.0, 137.0, 122.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 881 q_vals: [-6.991, -6.806, -6.795, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 393 2 visits [46.0, 137.0, 123.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 883 q_vals: [-6.991, -6.806, -6.74, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 887, "number_of_timesteps": 17851, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.15000000000000213},
Step 394 2 visits [46.0, 137.0, 124.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 887 q_vals: [-6.991, -6.806, -6.845, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 395 1 visits [46.0, 138.0, 124.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 890 q_vals: [-6.991, -6.757, -6.845, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 396 1 visits [46.0, 139.0, 124.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 891 q_vals: [-6.991, -6.764, -6.845, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 397 1 visits [46.0, 140.0, 124.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 894 q_vals: [-6.991, -6.772, -6.845, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 897, "number_of_timesteps": 17997, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.15000000000000213},
Step 398 1 visits [46.0, 141.0, 124.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 897 q_vals: [-6.991, -6.78, -6.845, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 399 1 visits [46.0, 142.0, 124.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 899 q_vals: [-6.991, -6.788, -6.845, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 400 1 visits [46.0, 143.0, 124.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 900 q_vals: [-6.991, -6.773, -6.845, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 401 1 visits [46.0, 144.0, 124.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 904 q_vals: [-6.991, -6.78, -6.845, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 907, "number_of_timesteps": 18189, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000213},
Step 402 1 visits [46.0, 145.0, 124.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 907 q_vals: [-6.991, -6.785, -6.845, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 403 1 visits [46.0, 146.0, 124.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 910 q_vals: [-6.991, -6.789, -6.845, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 404 1 visits [46.0, 147.0, 124.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 911 q_vals: [-6.991, -6.794, -6.845, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
Step 405 1 visits [46.0, 148.0, 124.0, 7.0, 11.0, 2.0, 48.0, 16.0, 1.0, 2.0]  episode_count: 914 q_vals: [-6.991, -6.875, -6.845, -7.876, -8.266, -14.354, -6.954, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 917, "number_of_timesteps": 18352, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000213},
Step 406 6 visits [46.0, 148.0, 124.0, 7.0, 11.0, 2.0, 49.0, 16.0, 1.0, 2.0]  episode_count: 917 q_vals: [-6.991, -6.875, -6.845, -7.876, -8.266, -14.354, -6.812, -7.333, -10.28, -9.778]
Step 407 6 visits [46.0, 148.0, 124.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 919 q_vals: [-6.991, -6.875, -6.845, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
Step 408 2 visits [46.0, 148.0, 125.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 921 q_vals: [-6.991, -6.875, -6.82, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
Step 409 2 visits [46.0, 148.0, 126.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 925 q_vals: [-6.991, -6.875, -6.766, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
Step 410 2 visits [46.0, 148.0, 127.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 926 q_vals: [-6.991, -6.875, -6.775, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 928, "number_of_timesteps": 18557, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000213},
Step 411 2 visits [46.0, 148.0, 128.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 928 q_vals: [-6.991, -6.875, -6.877, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
Step 412 0 visits [47.0, 148.0, 128.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 932 q_vals: [-6.842, -6.875, -6.877, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
Step 413 0 visits [48.0, 148.0, 128.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 935 q_vals: [-6.864, -6.875, -6.877, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
Step 414 0 visits [49.0, 148.0, 128.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 937 q_vals: [-6.885, -6.875, -6.877, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 939, "number_of_timesteps": 18740, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.002222222222222254, "biggest_recent_change": 0.15000000000000213},
Step 415 0 visits [50.0, 148.0, 128.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 939 q_vals: [-7.143, -6.875, -6.877, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
Step 416 2 visits [50.0, 148.0, 129.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 942 q_vals: [-7.143, -6.875, -6.884, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
Step 417 2 visits [50.0, 148.0, 130.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 944 q_vals: [-7.143, -6.875, -6.831, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
Step 418 2 visits [50.0, 148.0, 131.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 947 q_vals: [-7.143, -6.875, -6.839, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 950, "number_of_timesteps": 18948, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000213},
Step 419 2 visits [50.0, 148.0, 132.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 950 q_vals: [-7.143, -6.875, -6.937, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
Step 420 1 visits [50.0, 149.0, 132.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 953 q_vals: [-7.143, -6.882, -6.937, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
Step 421 1 visits [50.0, 150.0, 132.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 955 q_vals: [-7.143, -6.888, -6.937, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
Step 422 1 visits [50.0, 151.0, 132.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 957 q_vals: [-7.143, -6.895, -6.937, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 960, "number_of_timesteps": 19087, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.004444444444444468, "biggest_recent_change": 0.15000000000000213},
Step 423 1 visits [50.0, 152.0, 132.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 960 q_vals: [-7.143, -6.902, -6.937, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
Step 424 1 visits [50.0, 153.0, 132.0, 7.0, 11.0, 2.0, 50.0, 16.0, 1.0, 2.0]  episode_count: 964 q_vals: [-7.143, -6.908, -6.937, -7.876, -8.266, -14.354, -7.054, -7.333, -10.28, -9.778]
Step 425 6 visits [50.0, 153.0, 132.0, 7.0, 11.0, 2.0, 51.0, 16.0, 1.0, 2.0]  episode_count: 965 q_vals: [-7.143, -6.908, -6.937, -7.876, -8.266, -14.354, -7.071, -7.333, -10.28, -9.778]
Step 426 1 visits [50.0, 154.0, 132.0, 7.0, 11.0, 2.0, 51.0, 16.0, 1.0, 2.0]  episode_count: 967 q_vals: [-7.143, -6.915, -6.937, -7.876, -8.266, -14.354, -7.071, -7.333, -10.28, -9.778]
{"total_number_of_episodes": 971, "number_of_timesteps": 19283, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.0038888888888888654, "biggest_recent_change": 0.14999999999999858},
Step 427 1 visits [50.0, 155.0, 132.0, 7.0, 11.0, 2.0, 51.0, 16.0, 1.0, 2.0]  episode_count: 971 q_vals: [-7.143, -6.921, -6.937, -7.876, -8.266, -14.354, -7.071, -7.333, -10.28, -9.778]
Step 428 7 visits [50.0, 155.0, 132.0, 7.0, 11.0, 2.0, 51.0, 17.0, 1.0, 2.0]  episode_count: 973 q_vals: [-7.143, -6.921, -6.937, -7.876, -8.266, -14.354, -7.071, -8.064, -10.28, -9.778]
Step 429 2 visits [50.0, 155.0, 133.0, 7.0, 11.0, 2.0, 51.0, 17.0, 1.0, 2.0]  episode_count: 976 q_vals: [-7.143, -6.921, -6.944, -7.876, -8.266, -14.354, -7.071, -8.064, -10.28, -9.778]
Step 430 1 visits [50.0, 156.0, 133.0, 7.0, 11.0, 2.0, 51.0, 17.0, 1.0, 2.0]  episode_count: 979 q_vals: [-7.143, -7.0, -6.944, -7.876, -8.266, -14.354, -7.071, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 982, "number_of_timesteps": 19478, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
Step 431 6 visits [50.0, 156.0, 133.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 982 q_vals: [-7.143, -7.0, -6.944, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 432 2 visits [50.0, 156.0, 134.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 985 q_vals: [-7.143, -7.0, -7.04, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 433 0 visits [51.0, 156.0, 134.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 987 q_vals: [-7.39, -7.0, -7.04, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 434 1 visits [51.0, 157.0, 134.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 990 q_vals: [-7.39, -7.006, -7.04, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 993, "number_of_timesteps": 19648, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
Step 435 1 visits [51.0, 158.0, 134.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 993 q_vals: [-7.39, -7.012, -7.04, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 436 1 visits [51.0, 159.0, 134.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 998 q_vals: [-7.39, -7.017, -7.04, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 437 1 visits [51.0, 160.0, 134.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1001 q_vals: [-7.39, -7.023, -7.04, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 438 2 visits [51.0, 160.0, 135.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1002 q_vals: [-7.39, -7.023, -7.034, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1009, "number_of_timesteps": 19868, "per_episode_reward": 16.25, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
Step 439 2 visits [51.0, 160.0, 136.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1009 q_vals: [-7.39, -7.023, -7.127, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 440 1 visits [51.0, 161.0, 136.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1011 q_vals: [-7.39, -7.028, -7.127, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 441 1 visits [51.0, 162.0, 136.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1014 q_vals: [-7.39, -7.034, -7.127, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 442 1 visits [51.0, 163.0, 136.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1017 q_vals: [-7.39, -7.039, -7.127, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1020, "number_of_timesteps": 20008, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.14999999999999858},
Step 443 1 visits [51.0, 164.0, 136.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1020 q_vals: [-7.39, -7.044, -7.127, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 444 1 visits [51.0, 165.0, 136.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1024 q_vals: [-7.39, -7.05, -7.127, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 445 1 visits [51.0, 166.0, 136.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1026 q_vals: [-7.39, -7.039, -7.127, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1030, "number_of_timesteps": 20152, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
Step 446 1 visits [51.0, 167.0, 136.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1030 q_vals: [-7.39, -7.044, -7.127, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 447 1 visits [51.0, 168.0, 136.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1034 q_vals: [-7.39, -7.12, -7.127, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 448 2 visits [51.0, 168.0, 137.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1036 q_vals: [-7.39, -7.12, -7.133, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1041, "number_of_timesteps": 20288, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
Step 449 2 visits [51.0, 168.0, 138.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1041 q_vals: [-7.39, -7.12, -7.139, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 450 2 visits [51.0, 168.0, 139.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1042 q_vals: [-7.39, -7.12, -7.144, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 451 1 visits [51.0, 169.0, 139.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1044 q_vals: [-7.39, -7.195, -7.144, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 452 2 visits [51.0, 169.0, 140.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1049 q_vals: [-7.39, -7.195, -7.15, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1051, "number_of_timesteps": 20444, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.10000000000000142},
Step 453 2 visits [51.0, 169.0, 141.0, 7.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1051 q_vals: [-7.39, -7.195, -7.239, -7.876, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 454 3 visits [51.0, 169.0, 141.0, 8.0, 11.0, 2.0, 52.0, 17.0, 1.0, 2.0]  episode_count: 1054 q_vals: [-7.39, -7.195, -7.239, -7.879, -8.266, -14.354, -7.306, -8.064, -10.28, -9.778]
Step 455 6 visits [51.0, 169.0, 141.0, 8.0, 11.0, 2.0, 53.0, 17.0, 1.0, 2.0]  episode_count: 1059 q_vals: [-7.39, -7.195, -7.239, -7.879, -8.266, -14.354, -7.168, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1062, "number_of_timesteps": 20594, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.006666666666666643, "biggest_recent_change": 0.10000000000000142},
Step 456 6 visits [51.0, 169.0, 141.0, 8.0, 11.0, 2.0, 54.0, 17.0, 1.0, 2.0]  episode_count: 1062 q_vals: [-7.39, -7.195, -7.239, -7.879, -8.266, -14.354, -7.182, -8.064, -10.28, -9.778]
Step 457 6 visits [51.0, 169.0, 141.0, 8.0, 11.0, 2.0, 55.0, 17.0, 1.0, 2.0]  episode_count: 1065 q_vals: [-7.39, -7.195, -7.239, -7.879, -8.266, -14.354, -7.051, -8.064, -10.28, -9.778]
Step 458 6 visits [51.0, 169.0, 141.0, 8.0, 11.0, 2.0, 56.0, 17.0, 1.0, 2.0]  episode_count: 1068 q_vals: [-7.39, -7.195, -7.239, -7.879, -8.266, -14.354, -7.278, -8.064, -10.28, -9.778]
Step 459 6 visits [51.0, 169.0, 141.0, 8.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1070 q_vals: [-7.39, -7.195, -7.239, -7.879, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1073, "number_of_timesteps": 20738, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
Step 460 1 visits [51.0, 170.0, 141.0, 8.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1073 q_vals: [-7.39, -7.183, -7.239, -7.879, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 461 1 visits [51.0, 171.0, 141.0, 8.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1079 q_vals: [-7.39, -7.187, -7.239, -7.879, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 462 1 visits [51.0, 172.0, 141.0, 8.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1081 q_vals: [-7.39, -7.176, -7.239, -7.879, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1085, "number_of_timesteps": 20893, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.10000000000000142},
Step 463 1 visits [51.0, 173.0, 141.0, 8.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1085 q_vals: [-7.39, -7.18, -7.239, -7.879, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 464 1 visits [51.0, 174.0, 141.0, 8.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1090 q_vals: [-7.39, -7.184, -7.239, -7.879, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 465 1 visits [51.0, 175.0, 141.0, 8.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1092 q_vals: [-7.39, -7.17, -7.239, -7.879, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1098, "number_of_timesteps": 21040, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.10000000000000142},
Step 466 1 visits [51.0, 176.0, 141.0, 8.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1098 q_vals: [-7.39, -7.129, -7.239, -7.879, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 467 1 visits [51.0, 177.0, 141.0, 8.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1100 q_vals: [-7.39, -7.201, -7.239, -7.879, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 468 3 visits [51.0, 177.0, 141.0, 9.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1104 q_vals: [-7.39, -7.201, -7.239, -7.592, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1109, "number_of_timesteps": 21165, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.10000000000000142},
Step 469 3 visits [51.0, 177.0, 141.0, 10.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1109 q_vals: [-7.39, -7.201, -7.239, -7.623, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 470 3 visits [51.0, 177.0, 141.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1111 q_vals: [-7.39, -7.201, -7.239, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 471 1 visits [51.0, 178.0, 141.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1113 q_vals: [-7.39, -7.204, -7.239, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1120, "number_of_timesteps": 21309, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.006666666666666643, "biggest_recent_change": 0.10000000000000142},
Step 472 1 visits [51.0, 179.0, 141.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1120 q_vals: [-7.39, -7.275, -7.239, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 473 2 visits [51.0, 179.0, 142.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1120 q_vals: [-7.39, -7.275, -7.188, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 474 2 visits [51.0, 179.0, 143.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1125 q_vals: [-7.39, -7.275, -7.177, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 475 2 visits [51.0, 179.0, 144.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1128 q_vals: [-7.39, -7.275, -7.264, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1130, "number_of_timesteps": 21436, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.10000000000000142},
Step 476 0 visits [52.0, 179.0, 144.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1130 q_vals: [-7.628, -7.275, -7.264, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 477 2 visits [52.0, 179.0, 145.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1135 q_vals: [-7.628, -7.275, -7.351, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 478 1 visits [52.0, 180.0, 145.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1138 q_vals: [-7.628, -7.344, -7.351, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1141, "number_of_timesteps": 21583, "per_episode_reward": 15.45, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
Step 479 2 visits [52.0, 180.0, 146.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1141 q_vals: [-7.628, -7.344, -7.34, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 480 2 visits [52.0, 180.0, 147.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1145 q_vals: [-7.628, -7.344, -7.344, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 481 2 visits [52.0, 180.0, 148.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1148 q_vals: [-7.628, -7.344, -7.347, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 482 2 visits [52.0, 180.0, 149.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1150 q_vals: [-7.628, -7.344, -7.351, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1155, "number_of_timesteps": 21756, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
Step 483 2 visits [52.0, 180.0, 150.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1155 q_vals: [-7.628, -7.344, -7.355, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 484 2 visits [52.0, 180.0, 151.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1158 q_vals: [-7.628, -7.344, -7.34, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 485 2 visits [52.0, 180.0, 152.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1163 q_vals: [-7.628, -7.344, -7.343, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1167, "number_of_timesteps": 21898, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
Step 486 2 visits [52.0, 180.0, 153.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1167 q_vals: [-7.628, -7.344, -7.425, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 487 1 visits [52.0, 181.0, 153.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1168 q_vals: [-7.628, -7.33, -7.425, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 488 1 visits [52.0, 182.0, 153.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1173 q_vals: [-7.628, -7.333, -7.425, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1177, "number_of_timesteps": 22022, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
Step 489 1 visits [52.0, 183.0, 153.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1177 q_vals: [-7.628, -7.336, -7.425, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 490 1 visits [52.0, 184.0, 153.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1179 q_vals: [-7.628, -7.339, -7.425, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 491 1 visits [52.0, 185.0, 153.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1184 q_vals: [-7.628, -7.342, -7.425, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1187, "number_of_timesteps": 22156, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
Step 492 1 visits [52.0, 186.0, 153.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1187 q_vals: [-7.628, -7.303, -7.425, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 493 1 visits [52.0, 187.0, 153.0, 11.0, 11.0, 2.0, 57.0, 17.0, 1.0, 2.0]  episode_count: 1191 q_vals: [-7.628, -7.37, -7.425, -8.726, -8.266, -14.354, -7.497, -8.064, -10.28, -9.778]
Step 494 6 visits [52.0, 187.0, 153.0, 11.0, 11.0, 2.0, 58.0, 17.0, 1.0, 2.0]  episode_count: 1195 q_vals: [-7.628, -7.37, -7.425, -8.726, -8.266, -14.354, -7.557, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1199, "number_of_timesteps": 22294, "per_episode_reward": 15.05, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.14999999999999858},
Step 495 1 visits [52.0, 188.0, 153.0, 11.0, 11.0, 2.0, 58.0, 17.0, 1.0, 2.0]  episode_count: 1199 q_vals: [-7.628, -7.435, -7.425, -8.726, -8.266, -14.354, -7.557, -8.064, -10.28, -9.778]
Step 496 2 visits [52.0, 188.0, 154.0, 11.0, 11.0, 2.0, 58.0, 17.0, 1.0, 2.0]  episode_count: 1201 q_vals: [-7.628, -7.435, -7.428, -8.726, -8.266, -14.354, -7.557, -8.064, -10.28, -9.778]
Step 497 2 visits [52.0, 188.0, 155.0, 11.0, 11.0, 2.0, 58.0, 17.0, 1.0, 2.0]  episode_count: 1207 q_vals: [-7.628, -7.435, -7.431, -8.726, -8.266, -14.354, -7.557, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1210, "number_of_timesteps": 22414, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.15000000000000036},
Step 498 6 visits [52.0, 188.0, 155.0, 11.0, 11.0, 2.0, 59.0, 17.0, 1.0, 2.0]  episode_count: 1210 q_vals: [-7.628, -7.435, -7.431, -8.726, -8.266, -14.354, -7.562, -8.064, -10.28, -9.778]
Step 499 2 visits [52.0, 188.0, 156.0, 11.0, 11.0, 2.0, 59.0, 17.0, 1.0, 2.0]  episode_count: 1213 q_vals: [-7.628, -7.435, -7.418, -8.726, -8.266, -14.354, -7.562, -8.064, -10.28, -9.778]
Step 500 2 visits [52.0, 188.0, 157.0, 11.0, 11.0, 2.0, 59.0, 17.0, 1.0, 2.0]  episode_count: 1219 q_vals: [-7.628, -7.435, -7.421, -8.726, -8.266, -14.354, -7.562, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1220, "number_of_timesteps": 22523, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.15000000000000036},
Step 501 2 visits [52.0, 188.0, 158.0, 11.0, 11.0, 2.0, 59.0, 17.0, 1.0, 2.0]  episode_count: 1220 q_vals: [-7.628, -7.435, -7.424, -8.726, -8.266, -14.354, -7.562, -8.064, -10.28, -9.778]
Step 502 2 visits [52.0, 188.0, 159.0, 11.0, 11.0, 2.0, 59.0, 17.0, 1.0, 2.0]  episode_count: 1224 q_vals: [-7.628, -7.435, -7.408, -8.726, -8.266, -14.354, -7.562, -8.064, -10.28, -9.778]
Step 503 2 visits [52.0, 188.0, 160.0, 11.0, 11.0, 2.0, 59.0, 17.0, 1.0, 2.0]  episode_count: 1229 q_vals: [-7.628, -7.435, -7.411, -8.726, -8.266, -14.354, -7.562, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1231, "number_of_timesteps": 22656, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.15000000000000036},
Step 504 2 visits [52.0, 188.0, 161.0, 11.0, 11.0, 2.0, 59.0, 17.0, 1.0, 2.0]  episode_count: 1231 q_vals: [-7.628, -7.435, -7.414, -8.726, -8.266, -14.354, -7.562, -8.064, -10.28, -9.778]
Step 505 2 visits [52.0, 188.0, 162.0, 11.0, 11.0, 2.0, 59.0, 17.0, 1.0, 2.0]  episode_count: 1235 q_vals: [-7.628, -7.435, -7.369, -8.726, -8.266, -14.354, -7.562, -8.064, -10.28, -9.778]
Step 506 2 visits [52.0, 188.0, 163.0, 11.0, 11.0, 2.0, 59.0, 17.0, 1.0, 2.0]  episode_count: 1238 q_vals: [-7.628, -7.435, -7.372, -8.726, -8.266, -14.354, -7.562, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1243, "number_of_timesteps": 22800, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.15000000000000036},
Step 507 2 visits [52.0, 188.0, 164.0, 11.0, 11.0, 2.0, 59.0, 17.0, 1.0, 2.0]  episode_count: 1243 q_vals: [-7.628, -7.435, -7.447, -8.726, -8.266, -14.354, -7.562, -8.064, -10.28, -9.778]
Step 508 6 visits [52.0, 188.0, 164.0, 11.0, 11.0, 2.0, 60.0, 17.0, 1.0, 2.0]  episode_count: 1247 q_vals: [-7.628, -7.435, -7.447, -8.726, -8.266, -14.354, -7.568, -8.064, -10.28, -9.778]
Step 509 6 visits [52.0, 188.0, 164.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1249 q_vals: [-7.628, -7.435, -7.447, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1255, "number_of_timesteps": 22927, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
Step 510 2 visits [52.0, 188.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1255 q_vals: [-7.628, -7.435, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 511 1 visits [52.0, 189.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1259 q_vals: [-7.628, -7.396, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 512 1 visits [52.0, 190.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1260 q_vals: [-7.628, -7.399, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1266, "number_of_timesteps": 23043, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
Step 513 1 visits [52.0, 191.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1266 q_vals: [-7.628, -7.401, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 514 1 visits [52.0, 192.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1269 q_vals: [-7.628, -7.404, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 515 1 visits [52.0, 193.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1274 q_vals: [-7.628, -7.407, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1276, "number_of_timesteps": 23155, "per_episode_reward": 14.75, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.15000000000000036},
Step 516 1 visits [52.0, 194.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1276 q_vals: [-7.628, -7.409, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 517 1 visits [52.0, 195.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1280 q_vals: [-7.628, -7.401, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 518 1 visits [52.0, 196.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1284 q_vals: [-7.628, -7.388, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1286, "number_of_timesteps": 23281, "per_episode_reward": 14.65, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.15000000000000036},
Step 519 1 visits [52.0, 197.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1286 q_vals: [-7.628, -7.35, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 520 1 visits [52.0, 198.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1292 q_vals: [-7.628, -7.353, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 521 1 visits [52.0, 199.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1295 q_vals: [-7.628, -7.356, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1299, "number_of_timesteps": 23434, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
Step 522 1 visits [52.0, 200.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1299 q_vals: [-7.628, -7.343, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 523 1 visits [52.0, 201.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1303 q_vals: [-7.628, -7.346, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 524 1 visits [52.0, 202.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1304 q_vals: [-7.628, -7.349, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1312, "number_of_timesteps": 23593, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
Step 525 1 visits [52.0, 203.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1312 q_vals: [-7.628, -7.351, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 526 1 visits [52.0, 204.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1313 q_vals: [-7.628, -7.354, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 527 1 visits [52.0, 205.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1314 q_vals: [-7.628, -7.357, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 528 1 visits [52.0, 206.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1320 q_vals: [-7.628, -7.359, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1323, "number_of_timesteps": 23736, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
Step 529 1 visits [52.0, 207.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1323 q_vals: [-7.628, -7.419, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 530 1 visits [52.0, 208.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1324 q_vals: [-7.628, -7.421, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 531 1 visits [52.0, 209.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1327 q_vals: [-7.628, -7.424, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1333, "number_of_timesteps": 23885, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
Step 532 1 visits [52.0, 210.0, 165.0, 11.0, 11.0, 2.0, 61.0, 17.0, 1.0, 2.0]  episode_count: 1333 q_vals: [-7.628, -7.426, -7.45, -8.726, -8.266, -14.354, -7.574, -8.064, -10.28, -9.778]
Step 533 6 visits [52.0, 210.0, 165.0, 11.0, 11.0, 2.0, 62.0, 17.0, 1.0, 2.0]  episode_count: 1335 q_vals: [-7.628, -7.426, -7.45, -8.726, -8.266, -14.354, -7.579, -8.064, -10.28, -9.778]
Step 534 1 visits [52.0, 211.0, 165.0, 11.0, 11.0, 2.0, 62.0, 17.0, 1.0, 2.0]  episode_count: 1337 q_vals: [-7.628, -7.484, -7.45, -8.726, -8.266, -14.354, -7.579, -8.064, -10.28, -9.778]
Step 535 2 visits [52.0, 211.0, 166.0, 11.0, 11.0, 2.0, 62.0, 17.0, 1.0, 2.0]  episode_count: 1342 q_vals: [-7.628, -7.484, -7.524, -8.726, -8.266, -14.354, -7.579, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1344, "number_of_timesteps": 24028, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
Step 536 6 visits [52.0, 211.0, 166.0, 11.0, 11.0, 2.0, 63.0, 17.0, 1.0, 2.0]  episode_count: 1344 q_vals: [-7.628, -7.484, -7.524, -8.726, -8.266, -14.354, -7.584, -8.064, -10.28, -9.778]
Step 537 6 visits [52.0, 211.0, 166.0, 11.0, 11.0, 2.0, 64.0, 17.0, 1.0, 2.0]  episode_count: 1347 q_vals: [-7.628, -7.484, -7.524, -8.726, -8.266, -14.354, -7.589, -8.064, -10.28, -9.778]
Step 538 6 visits [52.0, 211.0, 166.0, 11.0, 11.0, 2.0, 65.0, 17.0, 1.0, 2.0]  episode_count: 1351 q_vals: [-7.628, -7.484, -7.524, -8.726, -8.266, -14.354, -7.594, -8.064, -10.28, -9.778]
Step 539 0 visits [53.0, 211.0, 166.0, 11.0, 11.0, 2.0, 65.0, 17.0, 1.0, 2.0]  episode_count: 1353 q_vals: [-7.857, -7.484, -7.524, -8.726, -8.266, -14.354, -7.594, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1356, "number_of_timesteps": 24196, "per_episode_reward": 14.45, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.09999999999999964},
Step 540 6 visits [53.0, 211.0, 166.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1356 q_vals: [-7.857, -7.484, -7.524, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 541 1 visits [53.0, 212.0, 166.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1357 q_vals: [-7.857, -7.486, -7.524, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 542 1 visits [53.0, 213.0, 166.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1362 q_vals: [-7.857, -7.544, -7.524, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 543 2 visits [53.0, 213.0, 167.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1364 q_vals: [-7.857, -7.544, -7.526, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 544 2 visits [53.0, 213.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1364 q_vals: [-7.857, -7.544, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1368, "number_of_timesteps": 24410, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
Step 545 1 visits [53.0, 214.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1368 q_vals: [-7.857, -7.546, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 546 1 visits [53.0, 215.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1372 q_vals: [-7.857, -7.547, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 547 1 visits [53.0, 216.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1373 q_vals: [-7.857, -7.549, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 548 1 visits [53.0, 217.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1376 q_vals: [-7.857, -7.551, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1378, "number_of_timesteps": 24580, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 549 1 visits [53.0, 218.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1378 q_vals: [-7.857, -7.552, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 550 1 visits [53.0, 219.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1379 q_vals: [-7.857, -7.554, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 551 1 visits [53.0, 220.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1384 q_vals: [-7.857, -7.555, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 552 1 visits [53.0, 221.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1385 q_vals: [-7.857, -7.557, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1390, "number_of_timesteps": 24809, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 553 1 visits [53.0, 222.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1390 q_vals: [-7.857, -7.523, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 554 1 visits [53.0, 223.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1391 q_vals: [-7.857, -7.525, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 555 1 visits [53.0, 224.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1393 q_vals: [-7.857, -7.526, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 556 1 visits [53.0, 225.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1396 q_vals: [-7.857, -7.528, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 557 1 visits [53.0, 226.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1397 q_vals: [-7.857, -7.53, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 558 1 visits [53.0, 227.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1399 q_vals: [-7.857, -7.531, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1400, "number_of_timesteps": 24989, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 559 1 visits [53.0, 228.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1400 q_vals: [-7.857, -7.533, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 560 1 visits [53.0, 229.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1402 q_vals: [-7.857, -7.534, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 561 1 visits [53.0, 230.0, 168.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1405 q_vals: [-7.857, -7.588, -7.599, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 562 2 visits [53.0, 230.0, 169.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1406 q_vals: [-7.857, -7.588, -7.554, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 563 2 visits [53.0, 230.0, 170.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1408 q_vals: [-7.857, -7.588, -7.626, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 564 1 visits [53.0, 231.0, 170.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1409 q_vals: [-7.857, -7.555, -7.626, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1410, "number_of_timesteps": 25250, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 565 1 visits [53.0, 232.0, 170.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1410 q_vals: [-7.857, -7.556, -7.626, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 566 1 visits [53.0, 233.0, 170.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1412 q_vals: [-7.857, -7.609, -7.626, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 567 2 visits [53.0, 233.0, 171.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1416 q_vals: [-7.857, -7.609, -7.628, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 568 2 visits [53.0, 233.0, 172.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1418 q_vals: [-7.857, -7.609, -7.583, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1421, "number_of_timesteps": 25523, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 569 2 visits [53.0, 233.0, 173.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1421 q_vals: [-7.857, -7.609, -7.585, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 570 2 visits [53.0, 233.0, 174.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1423 q_vals: [-7.857, -7.609, -7.587, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 571 2 visits [53.0, 233.0, 175.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1425 q_vals: [-7.857, -7.609, -7.589, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 572 2 visits [53.0, 233.0, 176.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1427 q_vals: [-7.857, -7.609, -7.59, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1431, "number_of_timesteps": 25696, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 573 2 visits [53.0, 233.0, 177.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1431 q_vals: [-7.857, -7.609, -7.592, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 574 2 visits [53.0, 233.0, 178.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1433 q_vals: [-7.857, -7.609, -7.594, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 575 2 visits [53.0, 233.0, 179.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1437 q_vals: [-7.857, -7.609, -7.596, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 576 2 visits [53.0, 233.0, 180.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1438 q_vals: [-7.857, -7.609, -7.663, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1442, "number_of_timesteps": 25830, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 577 1 visits [53.0, 234.0, 180.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1442 q_vals: [-7.857, -7.61, -7.663, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 578 1 visits [53.0, 235.0, 180.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1444 q_vals: [-7.857, -7.611, -7.663, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 579 1 visits [53.0, 236.0, 180.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1446 q_vals: [-7.857, -7.579, -7.663, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 580 1 visits [53.0, 237.0, 180.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1451 q_vals: [-7.857, -7.58, -7.663, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1453, "number_of_timesteps": 26066, "per_episode_reward": 14.55, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.09999999999999964},
Step 581 1 visits [53.0, 238.0, 180.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1453 q_vals: [-7.857, -7.581, -7.663, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 582 1 visits [53.0, 239.0, 180.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1456 q_vals: [-7.857, -7.583, -7.663, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 583 1 visits [53.0, 240.0, 180.0, 11.0, 11.0, 2.0, 66.0, 17.0, 1.0, 2.0]  episode_count: 1458 q_vals: [-7.857, -7.634, -7.663, -8.726, -8.266, -14.354, -7.758, -8.064, -10.28, -9.778]
Step 584 6 visits [53.0, 240.0, 180.0, 11.0, 11.0, 2.0, 67.0, 17.0, 1.0, 2.0]  episode_count: 1462 q_vals: [-7.857, -7.634, -7.663, -8.726, -8.266, -14.354, -7.76, -8.064, -10.28, -9.778]
{"total_number_of_episodes": 1465, "number_of_timesteps": 26235, "per_episode_reward": 14.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 585 7 visits [53.0, 240.0, 180.0, 11.0, 11.0, 2.0, 67.0, 18.0, 1.0, 2.0]  episode_count: 1465 q_vals: [-7.857, -7.634, -7.663, -8.726, -8.266, -14.354, -7.76, -8.055, -10.28, -9.778]
Step 586 6 visits [53.0, 240.0, 180.0, 11.0, 11.0, 2.0, 68.0, 18.0, 1.0, 2.0]  episode_count: 1465 q_vals: [-7.857, -7.634, -7.663, -8.726, -8.266, -14.354, -7.646, -8.055, -10.28, -9.778]
Step 587 6 visits [53.0, 240.0, 180.0, 11.0, 11.0, 2.0, 69.0, 18.0, 1.0, 2.0]  episode_count: 1470 q_vals: [-7.857, -7.634, -7.663, -8.726, -8.266, -14.354, -7.65, -8.055, -10.28, -9.778]
Step 588 6 visits [53.0, 240.0, 180.0, 11.0, 11.0, 2.0, 70.0, 18.0, 1.0, 2.0]  episode_count: 1471 q_vals: [-7.857, -7.634, -7.663, -8.726, -8.266, -14.354, -7.823, -8.055, -10.28, -9.778]
Step 589 7 visits [53.0, 240.0, 180.0, 11.0, 11.0, 2.0, 70.0, 19.0, 1.0, 2.0]  episode_count: 1473 q_vals: [-7.857, -7.634, -7.663, -8.726, -8.266, -14.354, -7.823, -8.047, -10.28, -9.778]
{"total_number_of_episodes": 1479, "number_of_timesteps": 26496, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 590 7 visits [53.0, 240.0, 180.0, 11.0, 11.0, 2.0, 70.0, 20.0, 1.0, 2.0]  episode_count: 1479 q_vals: [-7.857, -7.634, -7.663, -8.726, -8.266, -14.354, -7.823, -8.039, -10.28, -9.778]
Step 591 1 visits [53.0, 241.0, 180.0, 11.0, 11.0, 2.0, 70.0, 20.0, 1.0, 2.0]  episode_count: 1479 q_vals: [-7.857, -7.633, -7.663, -8.726, -8.266, -14.354, -7.823, -8.039, -10.28, -9.778]
Step 592 1 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 20.0, 1.0, 2.0]  episode_count: 1483 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -8.039, -10.28, -9.778]
Step 593 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 21.0, 1.0, 2.0]  episode_count: 1487 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.657, -10.28, -9.778]
{"total_number_of_episodes": 1489, "number_of_timesteps": 26642, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 594 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 22.0, 1.0, 2.0]  episode_count: 1489 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.668, -10.28, -9.778]
Step 595 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 23.0, 1.0, 2.0]  episode_count: 1491 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.678, -10.28, -9.778]
Step 596 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 24.0, 1.0, 2.0]  episode_count: 1498 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.687, -10.28, -9.778]
{"total_number_of_episodes": 1499, "number_of_timesteps": 26784, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
Step 597 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 25.0, 1.0, 2.0]  episode_count: 1499 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.696, -10.28, -9.778]
Step 598 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 26.0, 1.0, 2.0]  episode_count: 1501 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.704, -10.28, -9.778]
Step 599 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 27.0, 1.0, 2.0]  episode_count: 1504 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.711, -10.28, -9.778]
Step 600 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 28.0, 1.0, 2.0]  episode_count: 1507 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.436, -10.28, -9.778]
{"total_number_of_episodes": 1511, "number_of_timesteps": 26960, "per_episode_reward": 14.45, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
Step 601 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 29.0, 1.0, 2.0]  episode_count: 1511 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.452, -10.28, -9.778]
Step 602 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 30.0, 1.0, 2.0]  episode_count: 1515 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.467, -10.28, -9.778]
Step 603 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 31.0, 1.0, 2.0]  episode_count: 1518 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.226, -10.28, -9.778]
 604 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 32.0, 1.0, 2.0]  episode_count: 1520 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.359, -10.28, -9.778]
{"total_number_of_episodes": 1524, "number_of_timesteps": 27143, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.15000000000000036},
Step 605 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 33.0, 1.0, 2.0]  episode_count: 1524 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.375, -10.28, -9.778]
Step 606 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 34.0, 1.0, 2.0]  episode_count: 1527 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.391, -10.28, -9.778]
Step 607 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 35.0, 1.0, 2.0]  episode_count: 1533 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.405, -10.28, -9.778]
{"total_number_of_episodes": 1534, "number_of_timesteps": 27270, "per_episode_reward": 14.45, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
Step 608 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 36.0, 1.0, 2.0]  episode_count: 1534 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.419, -10.28, -9.778]
Step 609 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 37.0, 1.0, 2.0]  episode_count: 1540 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.432, -10.28, -9.778]
Step 610 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 38.0, 1.0, 2.0]  episode_count: 1543 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.237, -10.28, -9.778]
{"total_number_of_episodes": 1546, "number_of_timesteps": 27409, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
Step 611 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 39.0, 1.0, 2.0]  episode_count: 1546 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.254, -10.28, -9.778]
Step 612 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 40.0, 1.0, 2.0]  episode_count: 1550 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.269, -10.28, -9.778]
Step 613 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 41.0, 1.0, 2.0]  episode_count: 1554 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.573, -10.28, -9.778]
{"total_number_of_episodes": 1557, "number_of_timesteps": 27545, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
Step 614 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 42.0, 1.0, 2.0]  episode_count: 1557 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.863, -10.28, -9.778]
Step 615 7 visits [53.0, 242.0, 180.0, 11.0, 11.0, 2.0, 70.0, 43.0, 1.0, 2.0]  episode_count: 1559 q_vals: [-7.857, -7.638, -7.663, -8.726, -8.266, -14.354, -7.823, -7.864, -10.28, -9.778]
Step 616 2 visits [53.0, 242.0, 181.0, 11.0, 11.0, 2.0, 70.0, 43.0, 1.0, 2.0]  episode_count: 1561 q_vals: [-7.857, -7.638, -7.665, -8.726, -8.266, -14.354, -7.823, -7.864, -10.28, -9.778]
Step 617 1 visits [53.0, 243.0, 181.0, 11.0, 11.0, 2.0, 70.0, 43.0, 1.0, 2.0]  episode_count: 1566 q_vals: [-7.857, -7.639, -7.665, -8.726, -8.266, -14.354, -7.823, -7.864, -10.28, -9.778]
{"total_number_of_episodes": 1569, "number_of_timesteps": 27714, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
Step 618 1 visits [53.0, 244.0, 181.0, 11.0, 11.0, 2.0, 70.0, 43.0, 1.0, 2.0]  episode_count: 1569 q_vals: [-7.857, -7.631, -7.665, -8.726, -8.266, -14.354, -7.823, -7.864, -10.28, -9.778]
Step 619 1 visits [53.0, 245.0, 181.0, 11.0, 11.0, 2.0, 70.0, 43.0, 1.0, 2.0]  episode_count: 1572 q_vals: [-7.857, -7.632, -7.665, -8.726, -8.266, -14.354, -7.823, -7.864, -10.28, -9.778]
Step 620 1 visits [53.0, 246.0, 181.0, 11.0, 11.0, 2.0, 70.0, 43.0, 1.0, 2.0]  episode_count: 1577 q_vals: [-7.857, -7.601, -7.665, -8.726, -8.266, -14.354, -7.823, -7.864, -10.28, -9.778]
Step 621 1 visits [53.0, 247.0, 181.0, 11.0, 11.0, 2.0, 70.0, 43.0, 1.0, 2.0]  episode_count: 1577 q_vals: [-7.857, -7.65, -7.665, -8.726, -8.266, -14.354, -7.823, -7.864, -10.28, -9.778]
{"total_number_of_episodes": 1582, "number_of_timesteps": 27894, "per_episode_reward": 14.35, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
Step 622 2 visits [53.0, 247.0, 182.0, 11.0, 11.0, 2.0, 70.0, 43.0, 1.0, 2.0]  episode_count: 1582 q_vals: [-7.857, -7.65, -7.666, -8.726, -8.266, -14.354, -7.823, -7.864, -10.28, -9.778]
Step 623 7 visits [53.0, 247.0, 182.0, 11.0, 11.0, 2.0, 70.0, 44.0, 1.0, 2.0]  episode_count: 1586 q_vals: [-7.857, -7.65, -7.666, -8.726, -8.266, -14.354, -7.823, -7.865, -10.28, -9.778]
Step 624 2 visits [53.0, 247.0, 183.0, 11.0, 11.0, 2.0, 70.0, 44.0, 1.0, 2.0]  episode_count: 1588 q_vals: [-7.857, -7.65, -7.667, -8.726, -8.266, -14.354, -7.823, -7.865, -10.28, -9.778]
Step 625 2 visits [53.0, 247.0, 184.0, 11.0, 11.0, 2.0, 70.0, 44.0, 1.0, 2.0]  episode_count: 1591 q_vals: [-7.857, -7.65, -7.625, -8.726, -8.266, -14.354, -7.823, -7.865, -10.28, -9.778]
{"total_number_of_episodes": 1596, "number_of_timesteps": 28093, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
Step 626 2 visits [53.0, 247.0, 185.0, 11.0, 11.0, 2.0, 70.0, 44.0, 1.0, 2.0]  episode_count: 1596 q_vals: [-7.857, -7.65, -7.627, -8.726, -8.266, -14.354, -7.823, -7.865, -10.28, -9.778]
Step 627 2 visits [53.0, 247.0, 186.0, 11.0, 11.0, 2.0, 70.0, 44.0, 1.0, 2.0]  episode_count: 1597 q_vals: [-7.857, -7.65, -7.647, -8.726, -8.266, -14.354, -7.823, -7.865, -10.28, -9.778]
Step 628 2 visits [53.0, 247.0, 187.0, 11.0, 11.0, 2.0, 70.0, 44.0, 1.0, 2.0]  episode_count: 1603 q_vals: [-7.857, -7.65, -7.711, -8.726, -8.266, -14.354, -7.823, -7.865, -10.28, -9.778]
{"total_number_of_episodes": 1606, "number_of_timesteps": 28210, "per_episode_reward": 14.35, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 629 7 visits [53.0, 247.0, 187.0, 11.0, 11.0, 2.0, 70.0, 45.0, 1.0, 2.0]  episode_count: 1606 q_vals: [-7.857, -7.65, -7.711, -8.726, -8.266, -14.354, -7.823, -7.69, -10.28, -9.778]
Step 630 7 visits [53.0, 247.0, 187.0, 11.0, 11.0, 2.0, 70.0, 46.0, 1.0, 2.0]  episode_count: 1609 q_vals: [-7.857, -7.65, -7.711, -8.726, -8.266, -14.354, -7.823, -7.695, -10.28, -9.778]
Step 631 7 visits [53.0, 247.0, 187.0, 11.0, 11.0, 2.0, 70.0, 47.0, 1.0, 2.0]  episode_count: 1613 q_vals: [-7.857, -7.65, -7.711, -8.726, -8.266, -14.354, -7.823, -7.699, -10.28, -9.778]
Step 632 7 visits [53.0, 247.0, 187.0, 11.0, 11.0, 2.0, 70.0, 48.0, 1.0, 2.0]  episode_count: 1615 q_vals: [-7.857, -7.65, -7.711, -8.726, -8.266, -14.354, -7.823, -7.539, -10.28, -9.778]
{"total_number_of_episodes": 1618, "number_of_timesteps": 28363, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.10000000000000142},
Step 633 7 visits [53.0, 247.0, 187.0, 11.0, 11.0, 2.0, 70.0, 49.0, 1.0, 2.0]  episode_count: 1618 q_vals: [-7.857, -7.65, -7.711, -8.726, -8.266, -14.354, -7.823, -7.788, -10.28, -9.778]
Step 634 7 visits [53.0, 247.0, 187.0, 11.0, 11.0, 2.0, 70.0, 50.0, 1.0, 2.0]  episode_count: 1622 q_vals: [-7.857, -7.65, -7.711, -8.726, -8.266, -14.354, -7.823, -7.632, -10.28, -9.778]
Step 635 7 visits [53.0, 247.0, 187.0, 11.0, 11.0, 2.0, 70.0, 51.0, 1.0, 2.0]  episode_count: 1623 q_vals: [-7.857, -7.65, -7.711, -8.726, -8.266, -14.354, -7.823, -7.638, -10.28, -9.778]
Step 636 7 visits [53.0, 247.0, 187.0, 11.0, 11.0, 2.0, 70.0, 52.0, 1.0, 2.0]  episode_count: 1627 q_vals: [-7.857, -7.65, -7.711, -8.726, -8.266, -14.354, -7.823, -7.643, -10.28, -9.778]
{"total_number_of_episodes": 1631, "number_of_timesteps": 28557, "per_episode_reward": 14.35, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
Step 637 7 visits [53.0, 247.0, 187.0, 11.0, 11.0, 2.0, 70.0, 53.0, 1.0, 2.0]  episode_count: 1631 q_vals: [-7.857, -7.65, -7.711, -8.726, -8.266, -14.354, -7.823, -7.869, -10.28, -9.778]
Step 638 1 visits [53.0, 248.0, 187.0, 11.0, 11.0, 2.0, 70.0, 53.0, 1.0, 2.0]  episode_count: 1632 q_vals: [-7.857, -7.651, -7.711, -8.726, -8.266, -14.354, -7.823, -7.869, -10.28, -9.778]
Step 639 1 visits [53.0, 249.0, 187.0, 11.0, 11.0, 2.0, 70.0, 53.0, 1.0, 2.0]  episode_count: 1636 q_vals: [-7.857, -7.652, -7.711, -8.726, -8.266, -14.354, -7.823, -7.869, -10.28, -9.778]
Step 640 1 visits [53.0, 250.0, 187.0, 11.0, 11.0, 2.0, 70.0, 53.0, 1.0, 2.0]  episode_count: 1640 q_vals: [-7.857, -7.701, -7.711, -8.726, -8.266, -14.354, -7.823, -7.869, -10.28, -9.778]
{"total_number_of_episodes": 1642, "number_of_timesteps": 28705, "per_episode_reward": 14.35, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 641 4 visits [53.0, 250.0, 187.0, 11.0, 12.0, 2.0, 70.0, 53.0, 1.0, 2.0]  episode_count: 1642 q_vals: [-7.857, -7.701, -7.711, -8.726, -8.236, -14.354, -7.823, -7.869, -10.28, -9.778]
Step 642 4 visits [53.0, 250.0, 187.0, 11.0, 13.0, 2.0, 70.0, 53.0, 1.0, 2.0]  episode_count: 1645 q_vals: [-7.857, -7.701, -7.711, -8.726, -8.21, -14.354, -7.823, -7.869, -10.28, -9.778]
Step 643 4 visits [53.0, 250.0, 187.0, 11.0, 14.0, 2.0, 70.0, 53.0, 1.0, 2.0]  episode_count: 1649 q_vals: [-7.857, -7.701, -7.711, -8.726, -9.035, -14.354, -7.823, -7.869, -10.28, -9.778]
{"total_number_of_episodes": 1652, "number_of_timesteps": 28864, "per_episode_reward": 14.35, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 644 0 visits [54.0, 250.0, 187.0, 11.0, 14.0, 2.0, 70.0, 53.0, 1.0, 2.0]  episode_count: 1652 q_vals: [-7.857, -7.701, -7.711, -8.726, -9.035, -14.354, -7.823, -7.869, -10.28, -9.778]
Step 645 0 visits [55.0, 250.0, 187.0, 11.0, 14.0, 2.0, 70.0, 53.0, 1.0, 2.0]  episode_count: 1654 q_vals: [-7.858, -7.701, -7.711, -8.726, -9.035, -14.354, -7.823, -7.869, -10.28, -9.778]
Step 646 0 visits [56.0, 250.0, 187.0, 11.0, 14.0, 2.0, 70.0, 53.0, 1.0, 2.0]  episode_count: 1657 q_vals: [-7.859, -7.701, -7.711, -8.726, -9.035, -14.354, -7.823, -7.869, -10.28, -9.778]
Step 647 6 visits [56.0, 250.0, 187.0, 11.0, 14.0, 2.0, 71.0, 53.0, 1.0, 2.0]  episode_count: 1661 q_vals: [-7.859, -7.701, -7.711, -8.726, -9.035, -14.354, -7.713, -7.869, -10.28, -9.778]
{"total_number_of_episodes": 1664, "number_of_timesteps": 29042, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
Step 648 6 visits [56.0, 250.0, 187.0, 11.0, 14.0, 2.0, 72.0, 53.0, 1.0, 2.0]  episode_count: 1664 q_vals: [-7.859, -7.701, -7.711, -8.726, -9.035, -14.354, -7.715, -7.869, -10.28, -9.778]
Step 649 6 visits [56.0, 250.0, 187.0, 11.0, 14.0, 2.0, 73.0, 53.0, 1.0, 2.0]  episode_count: 1664 q_vals: [-7.859, -7.701, -7.711, -8.726, -9.035, -14.354, -7.718, -7.869, -10.28, -9.778]
Step 650 6 visits [56.0, 250.0, 187.0, 11.0, 14.0, 2.0, 74.0, 53.0, 1.0, 2.0]  episode_count: 1669 q_vals: [-7.859, -7.701, -7.711, -8.726, -9.035, -14.354, -7.72, -7.869, -10.28, -9.778]
Step 651 6 visits [56.0, 250.0, 187.0, 11.0, 14.0, 2.0, 75.0, 53.0, 1.0, 2.0]  episode_count: 1670 q_vals: [-7.859, -7.701, -7.711, -8.726, -9.035, -14.354, -7.881, -7.869, -10.28, -9.778]
Step 652 0 visits [57.0, 250.0, 187.0, 11.0, 14.0, 2.0, 75.0, 53.0, 1.0, 2.0]  episode_count: 1671 q_vals: [-7.86, -7.701, -7.711, -8.726, -9.035, -14.354, -7.881, -7.869, -10.28, -9.778]
Step 653 7 visits [57.0, 250.0, 187.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1672 q_vals: [-7.86, -7.701, -7.711, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
{"total_number_of_episodes": 1675, "number_of_timesteps": 29235, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
Step 654 0 visits [58.0, 250.0, 187.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1675 q_vals: [-7.86, -7.701, -7.711, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 655 2 visits [58.0, 250.0, 188.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1677 q_vals: [-7.86, -7.701, -7.67, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 656 2 visits [58.0, 250.0, 189.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1678 q_vals: [-7.86, -7.701, -7.672, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 657 2 visits [58.0, 250.0, 190.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1682 q_vals: [-7.86, -7.701, -7.735, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 658 0 visits [59.0, 250.0, 190.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1683 q_vals: [-8.062, -7.701, -7.735, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
{"total_number_of_episodes": 1685, "number_of_timesteps": 29437, "per_episode_reward": 14.25, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
Step 659 1 visits [59.0, 251.0, 190.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1685 q_vals: [-8.062, -7.67, -7.735, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 660 1 visits [59.0, 252.0, 190.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1688 q_vals: [-8.062, -7.718, -7.735, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 661 2 visits [59.0, 252.0, 191.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1689 q_vals: [-8.062, -7.718, -7.736, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 662 2 visits [59.0, 252.0, 192.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1692 q_vals: [-8.062, -7.718, -7.737, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 663 2 visits [59.0, 252.0, 193.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1694 q_vals: [-8.062, -7.718, -7.697, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 664 2 visits [59.0, 252.0, 194.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1694 q_vals: [-8.062, -7.718, -7.698, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
{"total_number_of_episodes": 1696, "number_of_timesteps": 29734, "per_episode_reward": 14.25, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
Step 665 2 visits [59.0, 252.0, 195.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1696 q_vals: [-8.062, -7.718, -7.658, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 666 2 visits [59.0, 252.0, 196.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1696 q_vals: [-8.062, -7.718, -7.648, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 667 2 visits [59.0, 252.0, 197.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1698 q_vals: [-8.062, -7.718, -7.709, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 668 2 visits [59.0, 252.0, 198.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1700 q_vals: [-8.062, -7.718, -7.71, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 669 2 visits [59.0, 252.0, 199.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1701 q_vals: [-8.062, -7.718, -7.711, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 670 2 visits [59.0, 252.0, 200.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1703 q_vals: [-8.062, -7.718, -7.771, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 671 1 visits [59.0, 253.0, 200.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1705 q_vals: [-8.062, -7.719, -7.771, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 672 1 visits [59.0, 254.0, 200.0, 11.0, 14.0, 2.0, 75.0, 54.0, 1.0, 2.0]  episode_count: 1705 q_vals: [-8.062, -7.766, -7.771, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
{"total_number_of_episodes": 1707, "number_of_timesteps": 30061, "per_episode_reward": 14.35, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
Step 673 6 visits [59.0, 254.0, 200.0, 11.0, 14.0, 2.0, 76.0, 54.0, 1.0, 2.0]  episode_count: 1707 q_vals: [-8.062, -7.766, -7.771, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 674 6 visits [59.0, 254.0, 200.0, 11.0, 14.0, 2.0, 77.0, 54.0, 1.0, 2.0]  episode_count: 1709 q_vals: [-8.062, -7.766, -7.771, -8.726, -9.035, -14.354, -7.881, -8.089, -10.28, -9.778]
Step 675 6 visits [59.0, 254.0, 200.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1711 q_vals: [-8.062, -7.766, -7.771, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 676 2 visits [59.0, 254.0, 201.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1712 q_vals: [-8.062, -7.766, -7.831, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 677 1 visits [59.0, 255.0, 201.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1714 q_vals: [-8.062, -7.813, -7.831, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
{"total_number_of_episodes": 1717, "number_of_timesteps": 30300, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
Step 678 2 visits [59.0, 255.0, 202.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1717 q_vals: [-8.062, -7.813, -7.831, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 679 2 visits [59.0, 255.0, 203.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1717 q_vals: [-8.062, -7.813, -7.886, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 680 1 visits [59.0, 256.0, 203.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1717 q_vals: [-8.062, -7.813, -7.886, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 681 1 visits [59.0, 257.0, 203.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1720 q_vals: [-8.062, -7.814, -7.886, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 682 1 visits [59.0, 258.0, 203.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1723 q_vals: [-8.062, -7.814, -7.886, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 683 1 visits [59.0, 259.0, 203.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1724 q_vals: [-8.062, -7.815, -7.886, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 684 1 visits [59.0, 260.0, 203.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1726 q_vals: [-8.062, -7.815, -7.886, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
{"total_number_of_episodes": 1727, "number_of_timesteps": 30626, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
Step 685 1 visits [59.0, 261.0, 203.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1727 q_vals: [-8.062, -7.792, -7.886, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 686 1 visits [59.0, 262.0, 203.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1730 q_vals: [-8.062, -7.792, -7.886, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 687 1 visits [59.0, 263.0, 203.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1731 q_vals: [-8.062, -7.793, -7.886, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 688 1 visits [59.0, 264.0, 203.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1732 q_vals: [-8.062, -7.793, -7.886, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 689 1 visits [59.0, 265.0, 203.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1735 q_vals: [-8.062, -7.793, -7.886, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 690 1 visits [59.0, 266.0, 203.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1736 q_vals: [-8.062, -7.838, -7.886, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
{"total_number_of_episodes": 1738, "number_of_timesteps": 30943, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
Step 691 1 visits [59.0, 267.0, 203.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1738 q_vals: [-8.062, -7.883, -7.886, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 692 2 visits [59.0, 267.0, 204.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1739 q_vals: [-8.062, -7.883, -7.883, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 693 2 visits [59.0, 267.0, 205.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1741 q_vals: [-8.062, -7.883, -7.845, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 694 2 visits [59.0, 267.0, 206.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1742 q_vals: [-8.062, -7.883, -7.839, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 695 2 visits [59.0, 267.0, 207.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1746 q_vals: [-8.062, -7.883, -7.837, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 696 2 visits [59.0, 267.0, 208.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1747 q_vals: [-8.062, -7.883, -7.882, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
{"total_number_of_episodes": 1749, "number_of_timesteps": 31248, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
Step 697 2 visits [59.0, 267.0, 209.0, 11.0, 14.0, 2.0, 78.0, 54.0, 1.0, 2.0]  episode_count: 1749 q_vals: [-8.062, -7.883, -7.939, -8.726, -9.035, -14.354, -8.033, -8.089, -10.28, -9.778]
Step 698 8 visits [59.0, 267.0, 209.0, 11.0, 14.0, 2.0, 78.0, 54.0, 2.0, 2.0]  episode_count: 1754 q_vals: [-8.062, -7.883, -7.939, -8.726, -9.035, -14.354, -8.033, -8.089, -15.016, -9.778]
Step 699 1 visits [59.0, 268.0, 209.0, 11.0, 14.0, 2.0, 78.0, 54.0, 2.0, 2.0]  episode_count: 1755 q_vals: [-8.062, -7.883, -7.939, -8.726, -9.035, -14.354, -8.033, -8.089, -15.016, -9.778]
Step 700 1 visits [59.0, 269.0, 209.0, 11.0, 14.0, 2.0, 78.0, 54.0, 2.0, 2.0]  episode_count: 1755 q_vals: [-8.062, -7.916, -7.939, -8.726, -9.035, -14.354, -8.033, -8.089, -15.016, -9.778]
Step 701 0 visits [60.0, 269.0, 209.0, 11.0, 14.0, 2.0, 78.0, 54.0, 2.0, 2.0]  episode_count: 1757 q_vals: [-7.928, -7.916, -7.939, -8.726, -9.035, -14.354, -8.033, -8.089, -15.016, -9.778]
Step 702 0 visits [61.0, 269.0, 209.0, 11.0, 14.0, 2.0, 78.0, 54.0, 2.0, 2.0]  episode_count: 1758 q_vals: [-7.927, -7.916, -7.939, -8.726, -9.035, -14.354, -8.033, -8.089, -15.016, -9.778]
{"total_number_of_episodes": 1762, "number_of_timesteps": 31519, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
Step 703 0 visits [62.0, 269.0, 209.0, 11.0, 14.0, 2.0, 78.0, 54.0, 2.0, 2.0]  episode_count: 1762 q_vals: [-8.118, -7.916, -7.939, -8.726, -9.035, -14.354, -8.033, -8.089, -15.016, -9.778]
Step 704 7 visits [62.0, 269.0, 209.0, 11.0, 14.0, 2.0, 78.0, 55.0, 2.0, 2.0]  episode_count: 1764 q_vals: [-8.118, -7.916, -7.939, -8.726, -9.035, -14.354, -8.033, -8.301, -15.016, -9.778]
Step 705 6 visits [62.0, 269.0, 209.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1766 q_vals: [-8.118, -7.916, -7.939, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 706 1 visits [62.0, 270.0, 209.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1768 q_vals: [-8.118, -7.916, -7.939, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 707 1 visits [62.0, 271.0, 209.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1769 q_vals: [-8.118, -7.916, -7.939, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1774, "number_of_timesteps": 31816, "per_episode_reward": 14.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
Step 708 1 visits [62.0, 272.0, 209.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1774 q_vals: [-8.118, -7.96, -7.939, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 709 2 visits [62.0, 272.0, 210.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1775 q_vals: [-8.118, -7.96, -7.927, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 710 2 visits [62.0, 272.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1778 q_vals: [-8.118, -7.96, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 711 0 visits [63.0, 272.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1779 q_vals: [-8.093, -7.96, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 712 0 visits [64.0, 272.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1783 q_vals: [-8.09, -7.96, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1784, "number_of_timesteps": 31980, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 713 0 visits [65.0, 272.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1784 q_vals: [-8.088, -7.96, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 714 0 visits [66.0, 272.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1786 q_vals: [-7.965, -7.96, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 715 0 visits [67.0, 272.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1788 q_vals: [-7.964, -7.96, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 716 0 visits [68.0, 272.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1790 q_vals: [-8.137, -7.96, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1794, "number_of_timesteps": 32220, "per_episode_reward": 14.55, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
Step 717 1 visits [68.0, 273.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1794 q_vals: [-8.137, -7.959, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 718 1 visits [68.0, 274.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1795 q_vals: [-8.137, -7.959, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 719 1 visits [68.0, 275.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1798 q_vals: [-8.137, -7.959, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 720 1 visits [68.0, 276.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1799 q_vals: [-8.137, -7.957, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 721 1 visits [68.0, 277.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1800 q_vals: [-8.137, -7.948, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 722 1 visits [68.0, 278.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1802 q_vals: [-8.137, -7.948, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1804, "number_of_timesteps": 32397, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 723 1 visits [68.0, 279.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1804 q_vals: [-8.137, -7.948, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 724 1 visits [68.0, 280.0, 211.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1808 q_vals: [-8.137, -7.99, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 725 2 visits [68.0, 280.0, 212.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1810 q_vals: [-8.137, -7.99, -7.983, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 726 2 visits [68.0, 280.0, 213.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1810 q_vals: [-8.137, -7.99, -8.038, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 727 0 visits [69.0, 280.0, 213.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1812 q_vals: [-8.214, -7.99, -8.038, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1816, "number_of_timesteps": 32671, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 728 1 visits [69.0, 281.0, 213.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1816 q_vals: [-8.214, -7.99, -8.038, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 729 1 visits [69.0, 282.0, 213.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1816 q_vals: [-8.214, -8.005, -8.038, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 730 1 visits [69.0, 283.0, 213.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1818 q_vals: [-8.214, -8.046, -8.038, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 731 2 visits [69.0, 283.0, 214.0, 11.0, 14.0, 2.0, 79.0, 55.0, 2.0, 2.0]  episode_count: 1822 q_vals: [-8.214, -8.046, -8.093, -8.726, -9.035, -14.354, -8.182, -8.301, -15.016, -9.778]
Step 732 6 visits [69.0, 283.0, 214.0, 11.0, 14.0, 2.0, 80.0, 55.0, 2.0, 2.0]  episode_count: 1822 q_vals: [-8.214, -8.046, -8.093, -8.726, -9.035, -14.354, -8.079, -8.301, -15.016, -9.778]
Step 733 6 visits [69.0, 283.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1825 q_vals: [-8.214, -8.046, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1827, "number_of_timesteps": 32949, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 734 1 visits [69.0, 284.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1827 q_vals: [-8.214, -8.046, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 735 1 visits [69.0, 285.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1828 q_vals: [-8.214, -8.045, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 736 1 visits [69.0, 286.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1832 q_vals: [-8.214, -8.037, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 737 1 visits [69.0, 287.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1836 q_vals: [-8.214, -8.037, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 738 1 visits [69.0, 288.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1836 q_vals: [-8.214, -8.036, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1839, "number_of_timesteps": 33174, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 739 1 visits [69.0, 289.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1839 q_vals: [-8.214, -8.036, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 740 1 visits [69.0, 290.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1839 q_vals: [-8.214, -8.035, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 741 1 visits [69.0, 291.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1840 q_vals: [-8.214, -8.035, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 742 1 visits [69.0, 292.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1843 q_vals: [-8.214, -8.035, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 743 1 visits [69.0, 293.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1845 q_vals: [-8.214, -8.075, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 744 0 visits [70.0, 293.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1847 q_vals: [-8.21, -8.075, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 745 0 visits [71.0, 293.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1848 q_vals: [-8.094, -8.075, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1851, "number_of_timesteps": 33477, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 746 0 visits [72.0, 293.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1851 q_vals: [-8.091, -8.075, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 747 0 visits [73.0, 293.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1853 q_vals: [-7.981, -8.075, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 748 0 visits [74.0, 293.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1854 q_vals: [-7.98, -8.075, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 749 0 visits [75.0, 293.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1856 q_vals: [-8.137, -8.075, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 750 0 visits [76.0, 293.0, 214.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1858 q_vals: [-8.237, -8.075, -8.093, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1863, "number_of_timesteps": 33795, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 751 2 visits [76.0, 293.0, 215.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1863 q_vals: [-8.237, -8.075, -8.055, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 752 2 visits [76.0, 293.0, 216.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1863 q_vals: [-8.237, -8.075, -8.055, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 753 2 visits [76.0, 293.0, 217.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1865 q_vals: [-8.237, -8.075, -8.018, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 754 2 visits [76.0, 293.0, 218.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1870 q_vals: [-8.237, -8.075, -8.017, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 755 2 visits [76.0, 293.0, 219.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1871 q_vals: [-8.237, -8.075, -8.017, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1874, "number_of_timesteps": 33992, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 756 2 visits [76.0, 293.0, 220.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1874 q_vals: [-8.237, -8.075, -8.016, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 757 2 visits [76.0, 293.0, 221.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1877 q_vals: [-8.237, -8.075, -8.069, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 758 2 visits [76.0, 293.0, 222.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1879 q_vals: [-8.237, -8.075, -8.068, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 759 2 visits [76.0, 293.0, 223.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1881 q_vals: [-8.237, -8.075, -8.068, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 760 2 visits [76.0, 293.0, 224.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1883 q_vals: [-8.237, -8.075, -8.067, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1885, "number_of_timesteps": 34195, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 761 2 visits [76.0, 293.0, 225.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1885 q_vals: [-8.237, -8.075, -8.066, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 762 2 visits [76.0, 293.0, 226.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1888 q_vals: [-8.237, -8.075, -8.065, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 763 2 visits [76.0, 293.0, 227.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1888 q_vals: [-8.237, -8.075, -8.065, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 764 2 visits [76.0, 293.0, 228.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1891 q_vals: [-8.237, -8.075, -8.064, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 765 2 visits [76.0, 293.0, 229.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1891 q_vals: [-8.237, -8.075, -8.063, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 766 2 visits [76.0, 293.0, 230.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1892 q_vals: [-8.237, -8.075, -8.063, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1896, "number_of_timesteps": 34475, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
Step 767 2 visits [76.0, 293.0, 231.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1896 q_vals: [-8.237, -8.075, -8.062, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 768 2 visits [76.0, 293.0, 232.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1899 q_vals: [-8.237, -8.075, -8.112, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 769 1 visits [76.0, 294.0, 232.0, 11.0, 14.0, 2.0, 81.0, 55.0, 2.0, 2.0]  episode_count: 1900 q_vals: [-8.237, -8.114, -8.112, -8.726, -9.035, -14.354, -8.224, -8.301, -15.016, -9.778]
Step 770 6 visits [76.0, 294.0, 232.0, 11.0, 14.0, 2.0, 82.0, 55.0, 2.0, 2.0]  episode_count: 1903 q_vals: [-8.237, -8.114, -8.112, -8.726, -9.035, -14.354, -8.217, -8.301, -15.016, -9.778]
Step 771 6 visits [76.0, 294.0, 232.0, 11.0, 14.0, 2.0, 83.0, 55.0, 2.0, 2.0]  episode_count: 1904 q_vals: [-8.237, -8.114, -8.112, -8.726, -9.035, -14.354, -8.213, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1908, "number_of_timesteps": 34742, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 772 6 visits [76.0, 294.0, 232.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1908 q_vals: [-8.237, -8.114, -8.112, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 773 0 visits [77.0, 294.0, 232.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1909 q_vals: [-8.232, -8.114, -8.112, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 774 0 visits [78.0, 294.0, 232.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1910 q_vals: [-8.228, -8.114, -8.112, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 775 0 visits [79.0, 294.0, 232.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1913 q_vals: [-8.124, -8.114, -8.112, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 776 0 visits [80.0, 294.0, 232.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1915 q_vals: [-8.121, -8.114, -8.112, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1918, "number_of_timesteps": 34944, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 777 0 visits [81.0, 294.0, 232.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1918 q_vals: [-8.118, -8.114, -8.112, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 778 0 visits [82.0, 294.0, 232.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1920 q_vals: [-8.116, -8.114, -8.112, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 779 0 visits [83.0, 294.0, 232.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1921 q_vals: [-8.113, -8.114, -8.112, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 780 0 visits [84.0, 294.0, 232.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1921 q_vals: [-8.017, -8.114, -8.112, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 781 0 visits [85.0, 294.0, 232.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1927 q_vals: [-8.015, -8.114, -8.112, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1930, "number_of_timesteps": 35214, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
Step 782 0 visits [86.0, 294.0, 232.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1930 q_vals: [-8.152, -8.114, -8.112, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 783 0 visits [87.0, 294.0, 232.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1931 q_vals: [-8.285, -8.114, -8.112, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 784 2 visits [87.0, 294.0, 233.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1931 q_vals: [-8.285, -8.114, -8.111, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 785 2 visits [87.0, 294.0, 234.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1935 q_vals: [-8.285, -8.114, -8.11, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 786 2 visits [87.0, 294.0, 235.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1937 q_vals: [-8.285, -8.114, -8.11, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1940, "number_of_timesteps": 35431, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
Step 787 2 visits [87.0, 294.0, 236.0, 11.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1940 q_vals: [-8.285, -8.114, -8.159, -8.726, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 788 3 visits [87.0, 294.0, 236.0, 12.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1942 q_vals: [-8.285, -8.114, -8.159, -8.657, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 789 3 visits [87.0, 294.0, 236.0, 13.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1942 q_vals: [-8.285, -8.114, -8.159, -8.599, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 790 3 visits [87.0, 294.0, 236.0, 14.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1945 q_vals: [-8.285, -8.114, -8.159, -8.549, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
{"total_number_of_episodes": 1950, "number_of_timesteps": 35617, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
Step 791 3 visits [87.0, 294.0, 236.0, 15.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1950 q_vals: [-8.285, -8.114, -8.159, -8.506, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 792 3 visits [87.0, 294.0, 236.0, 16.0, 14.0, 2.0, 84.0, 55.0, 2.0, 2.0]  episode_count: 1950 q_vals: [-8.285, -8.114, -8.159, -9.209, -9.035, -14.354, -8.351, -8.301, -15.016, -9.778]
Step 793 9 visits [87.0, 294.0, 236.0, 16.0, 14.0, 2.0, 84.0, 55.0, 2.0, 3.0]  episode_count: 1952 q_vals: [-8.285, -8.114, -8.159, -9.209, -9.035, -14.354, -8.351, -8.301, -15.016, -9.153]
Step 794 9 visits [87.0, 294.0, 236.0, 16.0, 14.0, 2.0, 84.0, 55.0, 2.0, 4.0]  episode_count: 1954 q_vals: [-8.285, -8.114, -8.159, -9.209, -9.035, -14.354, -8.351, -8.301, -15.016, -11.803]
Step 795 7 visits [87.0, 294.0, 236.0, 16.0, 14.0, 2.0, 84.0, 56.0, 2.0, 4.0]  episode_count: 1956 q_vals: [-8.285, -8.114, -8.159, -9.209, -9.035, -14.354, -8.351, -8.294, -15.016, -11.803]
{"total_number_of_episodes": 1960, "number_of_timesteps": 35832, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
Step 796 7 visits [87.0, 294.0, 236.0, 16.0, 14.0, 2.0, 84.0, 57.0, 2.0, 4.0]  episode_count: 1960 q_vals: [-8.285, -8.114, -8.159, -9.209, -9.035, -14.354, -8.351, -8.287, -15.016, -11.803]
Step 797 7 visits [87.0, 294.0, 236.0, 16.0, 14.0, 2.0, 84.0, 58.0, 2.0, 4.0]  episode_count: 1962 q_vals: [-8.285, -8.114, -8.159, -9.209, -9.035, -14.354, -8.351, -8.145, -15.016, -11.803]
Step 798 7 visits [87.0, 294.0, 236.0, 16.0, 14.0, 2.0, 84.0, 59.0, 2.0, 4.0]  episode_count: 1963 q_vals: [-8.285, -8.114, -8.159, -9.209, -9.035, -14.354, -8.351, -8.14, -15.016, -11.803]
Step 799 7 visits [87.0, 294.0, 236.0, 16.0, 14.0, 2.0, 84.0, 60.0, 2.0, 4.0]  episode_count: 1964 q_vals: [-8.285, -8.114, -8.159, -9.209, -9.035, -14.354, -8.351, -8.334, -15.016, -11.803]
Step 800 1 visits [87.0, 295.0, 236.0, 16.0, 14.0, 2.0, 84.0, 60.0, 2.0, 4.0]  episode_count: 1967 q_vals: [-8.285, -8.114, -8.159, -9.209, -9.035, -14.354, -8.351, -8.334, -15.016, -11.803]
Step 801 1 visits [87.0, 296.0, 236.0, 16.0, 14.0, 2.0, 84.0, 60.0, 2.0, 4.0]  episode_count: 1968 q_vals: [-8.285, -8.113, -8.159, -9.209, -9.035, -14.354, -8.351, -8.334, -15.016, -11.803]
{"total_number_of_episodes": 1970, "number_of_timesteps": 36040, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
Step 802 1 visits [87.0, 297.0, 236.0, 16.0, 14.0, 2.0, 84.0, 60.0, 2.0, 4.0]  episode_count: 1970 q_vals: [-8.285, -8.112, -8.159, -9.209, -9.035, -14.354, -8.351, -8.334, -15.016, -11.803]
Step 803 1 visits [87.0, 298.0, 236.0, 16.0, 14.0, 2.0, 84.0, 60.0, 2.0, 4.0]  episode_count: 1971 q_vals: [-8.285, -8.111, -8.159, -9.209, -9.035, -14.354, -8.351, -8.334, -15.016, -11.803]
Step 804 1 visits [87.0, 299.0, 236.0, 16.0, 14.0, 2.0, 84.0, 60.0, 2.0, 4.0]  episode_count: 1974 q_vals: [-8.285, -8.111, -8.159, -9.209, -9.035, -14.354, -8.351, -8.334, -15.016, -11.803]
Step 805 1 visits [87.0, 300.0, 236.0, 16.0, 14.0, 2.0, 84.0, 60.0, 2.0, 4.0]  episode_count: 1975 q_vals: [-8.285, -8.149, -8.159, -9.209, -9.035, -14.354, -8.351, -8.334, -15.016, -11.803]
Step 806 2 visits [87.0, 300.0, 237.0, 16.0, 14.0, 2.0, 84.0, 60.0, 2.0, 4.0]  episode_count: 1977 q_vals: [-8.285, -8.149, -8.158, -9.209, -9.035, -14.354, -8.351, -8.334, -15.016, -11.803]
{"total_number_of_episodes": 1980, "number_of_timesteps": 36296, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
Step 807 2 visits [87.0, 300.0, 238.0, 16.0, 14.0, 2.0, 84.0, 60.0, 2.0, 4.0]  episode_count: 1980 q_vals: [-8.285, -8.149, -8.157, -9.209, -9.035, -14.354, -8.351, -8.334, -15.016, -11.803]
Step 808 2 visits [87.0, 300.0, 239.0, 16.0, 14.0, 2.0, 84.0, 60.0, 2.0, 4.0]  episode_count: 1980 q_vals: [-8.285, -8.149, -8.123, -9.209, -9.035, -14.354, -8.351, -8.334, -15.016, -11.803]
Step 809 2 visits [87.0, 300.0, 240.0, 16.0, 14.0, 2.0, 84.0, 60.0, 2.0, 4.0]  episode_count: 1980 q_vals: [-8.285, -8.149, -8.171, -9.209, -9.035, -14.354, -8.351, -8.334, -15.016, -11.803]
Step 810 7 visits [87.0, 300.0, 240.0, 16.0, 14.0, 2.0, 84.0, 61.0, 2.0, 4.0]  episode_count: 1982 q_vals: [-8.285, -8.149, -8.171, -9.209, -9.035, -14.354, -8.351, -8.197, -15.016, -11.803]
Step 811 7 visits [87.0, 300.0, 240.0, 16.0, 14.0, 2.0, 84.0, 62.0, 2.0, 4.0]  episode_count: 1985 q_vals: [-8.285, -8.149, -8.171, -9.209, -9.035, -14.354, -8.351, -8.193, -15.016, -11.803]
Step 812 7 visits [87.0, 300.0, 240.0, 16.0, 14.0, 2.0, 84.0, 63.0, 2.0, 4.0]  episode_count: 1987 q_vals: [-8.285, -8.149, -8.171, -9.209, -9.035, -14.354, -8.351, -8.376, -15.016, -11.803]
Step 813 1 visits [87.0, 301.0, 240.0, 16.0, 14.0, 2.0, 84.0, 63.0, 2.0, 4.0]  episode_count: 1989 q_vals: [-8.285, -8.149, -8.171, -9.209, -9.035, -14.354, -8.351, -8.376, -15.016, -11.803]
{"total_number_of_episodes": 1990, "number_of_timesteps": 36553, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
Step 814 1 visits [87.0, 302.0, 240.0, 16.0, 14.0, 2.0, 84.0, 63.0, 2.0, 4.0]  episode_count: 1990 q_vals: [-8.285, -8.187, -8.171, -9.209, -9.035, -14.354, -8.351, -8.376, -15.016, -11.803]
Step 815 2 visits [87.0, 302.0, 241.0, 16.0, 14.0, 2.0, 84.0, 63.0, 2.0, 4.0]  episode_count: 1992 q_vals: [-8.285, -8.187, -8.17, -9.209, -9.035, -14.354, -8.351, -8.376, -15.016, -11.803]
Step 816 2 visits [87.0, 302.0, 242.0, 16.0, 14.0, 2.0, 84.0, 63.0, 2.0, 4.0]  episode_count: 1995 q_vals: [-8.285, -8.187, -8.218, -9.209, -9.035, -14.354, -8.351, -8.376, -15.016, -11.803]
Step 817 0 visits [88.0, 302.0, 242.0, 16.0, 14.0, 2.0, 84.0, 63.0, 2.0, 4.0]  episode_count: 1998 q_vals: [-8.415, -8.187, -8.218, -9.209, -9.035, -14.354, -8.351, -8.376, -15.016, -11.803]
{"total_number_of_episodes": 2000, "number_of_timesteps": 36790, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
Step 818 1 visits [88.0, 303.0, 242.0, 16.0, 14.0, 2.0, 84.0, 63.0, 2.0, 4.0]  episode_count: 2000 q_vals: [-8.415, -8.186, -8.218, -9.209, -9.035, -14.354, -8.351, -8.376, -15.016, -11.803]
Step 819 1 visits [88.0, 304.0, 242.0, 16.0, 14.0, 2.0, 84.0, 63.0, 2.0, 4.0]  episode_count: 2003 q_vals: [-8.415, -8.224, -8.218, -9.209, -9.035, -14.354, -8.351, -8.376, -15.016, -11.803]
Step 820 7 visits [88.0, 304.0, 242.0, 16.0, 14.0, 2.0, 84.0, 64.0, 2.0, 4.0]  episode_count: 2006 q_vals: [-8.415, -8.224, -8.218, -9.209, -9.035, -14.354, -8.351, -8.369, -15.016, -11.803]
Step 821 7 visits [88.0, 304.0, 242.0, 16.0, 14.0, 2.0, 84.0, 65.0, 2.0, 4.0]  episode_count: 2008 q_vals: [-8.415, -8.224, -8.218, -9.209, -9.035, -14.354, -8.351, -8.361, -15.016, -11.803]
{"total_number_of_episodes": 2010, "number_of_timesteps": 37004, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
Step 822 7 visits [88.0, 304.0, 242.0, 16.0, 14.0, 2.0, 84.0, 66.0, 2.0, 4.0]  episode_count: 2010 q_vals: [-8.415, -8.224, -8.218, -9.209, -9.035, -14.354, -8.351, -8.354, -15.016, -11.803]
Step 823 7 visits [88.0, 304.0, 242.0, 16.0, 14.0, 2.0, 84.0, 67.0, 2.0, 4.0]  episode_count: 2013 q_vals: [-8.415, -8.224, -8.218, -9.209, -9.035, -14.354, -8.351, -8.525, -15.016, -11.803]
Step 824 2 visits [88.0, 304.0, 243.0, 16.0, 14.0, 2.0, 84.0, 67.0, 2.0, 4.0]  episode_count: 2013 q_vals: [-8.415, -8.224, -8.216, -9.209, -9.035, -14.354, -8.351, -8.525, -15.016, -11.803]
Step 825 2 visits [88.0, 304.0, 244.0, 16.0, 14.0, 2.0, 84.0, 67.0, 2.0, 4.0]  episode_count: 2016 q_vals: [-8.415, -8.224, -8.215, -9.209, -9.035, -14.354, -8.351, -8.525, -15.016, -11.803]
Step 826 2 visits [88.0, 304.0, 245.0, 16.0, 14.0, 2.0, 84.0, 67.0, 2.0, 4.0]  episode_count: 2018 q_vals: [-8.415, -8.224, -8.262, -9.209, -9.035, -14.354, -8.351, -8.525, -15.016, -11.803]
{"total_number_of_episodes": 2020, "number_of_timesteps": 37204, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 827 6 visits [88.0, 304.0, 245.0, 16.0, 14.0, 2.0, 85.0, 67.0, 2.0, 4.0]  episode_count: 2020 q_vals: [-8.415, -8.224, -8.262, -9.209, -9.035, -14.354, -8.252, -8.525, -15.016, -11.803]
Step 828 6 visits [88.0, 304.0, 245.0, 16.0, 14.0, 2.0, 86.0, 67.0, 2.0, 4.0]  episode_count: 2021 q_vals: [-8.415, -8.224, -8.262, -9.209, -9.035, -14.354, -8.386, -8.525, -15.016, -11.803]
Step 829 1 visits [88.0, 305.0, 245.0, 16.0, 14.0, 2.0, 86.0, 67.0, 2.0, 4.0]  episode_count: 2023 q_vals: [-8.415, -8.223, -8.262, -9.209, -9.035, -14.354, -8.386, -8.525, -15.016, -11.803]
Step 830 1 visits [88.0, 306.0, 245.0, 16.0, 14.0, 2.0, 86.0, 67.0, 2.0, 4.0]  episode_count: 2026 q_vals: [-8.415, -8.261, -8.262, -9.209, -9.035, -14.354, -8.386, -8.525, -15.016, -11.803]
Step 831 2 visits [88.0, 306.0, 246.0, 16.0, 14.0, 2.0, 86.0, 67.0, 2.0, 4.0]  episode_count: 2028 q_vals: [-8.415, -8.261, -8.261, -9.209, -9.035, -14.354, -8.386, -8.525, -15.016, -11.803]
Step 832 2 visits [88.0, 306.0, 247.0, 16.0, 14.0, 2.0, 86.0, 67.0, 2.0, 4.0]  episode_count: 2028 q_vals: [-8.415, -8.261, -8.259, -9.209, -9.035, -14.354, -8.386, -8.525, -15.016, -11.803]
{"total_number_of_episodes": 2030, "number_of_timesteps": 37467, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 833 2 visits [88.0, 306.0, 248.0, 16.0, 14.0, 2.0, 86.0, 67.0, 2.0, 4.0]  episode_count: 2030 q_vals: [-8.415, -8.261, -8.258, -9.209, -9.035, -14.354, -8.386, -8.525, -15.016, -11.803]
Step 834 2 visits [88.0, 306.0, 249.0, 16.0, 14.0, 2.0, 86.0, 67.0, 2.0, 4.0]  episode_count: 2034 q_vals: [-8.415, -8.261, -8.257, -9.209, -9.035, -14.354, -8.386, -8.525, -15.016, -11.803]
Step 835 2 visits [88.0, 306.0, 250.0, 16.0, 14.0, 2.0, 86.0, 67.0, 2.0, 4.0]  episode_count: 2035 q_vals: [-8.415, -8.261, -8.255, -9.209, -9.035, -14.354, -8.386, -8.525, -15.016, -11.803]
Step 836 2 visits [88.0, 306.0, 251.0, 16.0, 14.0, 2.0, 86.0, 67.0, 2.0, 4.0]  episode_count: 2037 q_vals: [-8.415, -8.261, -8.222, -9.209, -9.035, -14.354, -8.386, -8.525, -15.016, -11.803]
{"total_number_of_episodes": 2040, "number_of_timesteps": 37693, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 837 2 visits [88.0, 306.0, 252.0, 16.0, 14.0, 2.0, 86.0, 67.0, 2.0, 4.0]  episode_count: 2040 q_vals: [-8.415, -8.261, -8.221, -9.209, -9.035, -14.354, -8.386, -8.525, -15.016, -11.803]
Step 838 2 visits [88.0, 306.0, 253.0, 16.0, 14.0, 2.0, 86.0, 67.0, 2.0, 4.0]  episode_count: 2041 q_vals: [-8.415, -8.261, -8.22, -9.209, -9.035, -14.354, -8.386, -8.525, -15.016, -11.803]
Step 839 2 visits [88.0, 306.0, 254.0, 16.0, 14.0, 2.0, 86.0, 67.0, 2.0, 4.0]  episode_count: 2041 q_vals: [-8.415, -8.261, -8.265, -9.209, -9.035, -14.354, -8.386, -8.525, -15.016, -11.803]
Step 840 2 visits [88.0, 306.0, 255.0, 16.0, 14.0, 2.0, 86.0, 67.0, 2.0, 4.0]  episode_count: 2044 q_vals: [-8.415, -8.261, -8.264, -9.209, -9.035, -14.354, -8.386, -8.525, -15.016, -11.803]
Step 841 2 visits [88.0, 306.0, 256.0, 16.0, 14.0, 2.0, 86.0, 67.0, 2.0, 4.0]  episode_count: 2045 q_vals: [-8.415, -8.261, -8.309, -9.209, -9.035, -14.354, -8.386, -8.525, -15.016, -11.803]
Step 842 6 visits [88.0, 306.0, 256.0, 16.0, 14.0, 2.0, 87.0, 67.0, 2.0, 4.0]  episode_count: 2046 q_vals: [-8.415, -8.261, -8.309, -9.209, -9.035, -14.354, -8.38, -8.525, -15.016, -11.803]
Step 843 6 visits [88.0, 306.0, 256.0, 16.0, 14.0, 2.0, 88.0, 67.0, 2.0, 4.0]  episode_count: 2048 q_vals: [-8.415, -8.261, -8.309, -9.209, -9.035, -14.354, -8.375, -8.525, -15.016, -11.803]
{"total_number_of_episodes": 2050, "number_of_timesteps": 37952, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 844 6 visits [88.0, 306.0, 256.0, 16.0, 14.0, 2.0, 89.0, 67.0, 2.0, 4.0]  episode_count: 2050 q_vals: [-8.415, -8.261, -8.309, -9.209, -9.035, -14.354, -8.281, -8.525, -15.016, -11.803]
Step 845 6 visits [88.0, 306.0, 256.0, 16.0, 14.0, 2.0, 90.0, 67.0, 2.0, 4.0]  episode_count: 2053 q_vals: [-8.415, -8.261, -8.309, -9.209, -9.035, -14.354, -8.408, -8.525, -15.016, -11.803]
Step 846 1 visits [88.0, 307.0, 256.0, 16.0, 14.0, 2.0, 90.0, 67.0, 2.0, 4.0]  episode_count: 2054 q_vals: [-8.415, -8.298, -8.309, -9.209, -9.035, -14.354, -8.408, -8.525, -15.016, -11.803]
Step 847 6 visits [88.0, 307.0, 256.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2055 q_vals: [-8.415, -8.298, -8.309, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 848 0 visits [89.0, 307.0, 256.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2058 q_vals: [-8.41, -8.298, -8.309, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
{"total_number_of_episodes": 2061, "number_of_timesteps": 38230, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 849 0 visits [90.0, 307.0, 256.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2061 q_vals: [-8.404, -8.298, -8.309, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 850 0 visits [91.0, 307.0, 256.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2063 q_vals: [-8.398, -8.298, -8.309, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 851 0 visits [92.0, 307.0, 256.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2065 q_vals: [-8.393, -8.298, -8.309, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 852 0 visits [93.0, 307.0, 256.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2068 q_vals: [-8.388, -8.298, -8.309, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 853 0 visits [94.0, 307.0, 256.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2070 q_vals: [-8.299, -8.298, -8.309, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
{"total_number_of_episodes": 2072, "number_of_timesteps": 38458, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 854 0 visits [95.0, 307.0, 256.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2072 q_vals: [-8.294, -8.298, -8.309, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 855 0 visits [96.0, 307.0, 256.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2074 q_vals: [-8.414, -8.298, -8.309, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 856 2 visits [96.0, 307.0, 257.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2076 q_vals: [-8.414, -8.298, -8.307, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 857 2 visits [96.0, 307.0, 258.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2078 q_vals: [-8.414, -8.298, -8.305, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 858 2 visits [96.0, 307.0, 259.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2081 q_vals: [-8.414, -8.298, -8.301, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
{"total_number_of_episodes": 2084, "number_of_timesteps": 38723, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 859 2 visits [96.0, 307.0, 260.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2084 q_vals: [-8.414, -8.298, -8.269, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 860 2 visits [96.0, 307.0, 261.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2086 q_vals: [-8.414, -8.298, -8.267, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 861 2 visits [96.0, 307.0, 262.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2088 q_vals: [-8.414, -8.298, -8.266, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 862 2 visits [96.0, 307.0, 263.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2090 q_vals: [-8.414, -8.298, -8.31, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 863 0 visits [97.0, 307.0, 263.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2093 q_vals: [-8.408, -8.298, -8.31, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
{"total_number_of_episodes": 2094, "number_of_timesteps": 38912, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 864 0 visits [98.0, 307.0, 263.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2094 q_vals: [-8.524, -8.298, -8.31, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 865 2 visits [98.0, 307.0, 264.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2096 q_vals: [-8.524, -8.298, -8.278, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 866 2 visits [98.0, 307.0, 265.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2099 q_vals: [-8.524, -8.298, -8.277, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 867 2 visits [98.0, 307.0, 266.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2099 q_vals: [-8.524, -8.298, -8.275, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 868 2 visits [98.0, 307.0, 267.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2100 q_vals: [-8.524, -8.298, -8.274, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
{"total_number_of_episodes": 2104, "number_of_timesteps": 39141, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 869 2 visits [98.0, 307.0, 268.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2104 q_vals: [-8.524, -8.298, -8.273, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 870 2 visits [98.0, 307.0, 269.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2107 q_vals: [-8.524, -8.298, -8.315, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 871 1 visits [98.0, 308.0, 269.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2108 q_vals: [-8.524, -8.335, -8.315, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 872 2 visits [98.0, 308.0, 270.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2108 q_vals: [-8.524, -8.335, -8.358, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
[-8.524, -8.334, -8.358, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
{"total_number_of_episodes": 2116, "number_of_timesteps": 39411, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 874 1 visits [98.0, 310.0, 270.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2116 q_vals: [-8.524, -8.333, -8.358, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 875 1 visits [98.0, 311.0, 270.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2116 q_vals: [-8.524, -8.331, -8.358, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 876 1 visits [98.0, 312.0, 270.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2118 q_vals: [-8.524, -8.33, -8.358, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 877 1 visits [98.0, 313.0, 270.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2121 q_vals: [-8.524, -8.366, -8.358, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 878 2 visits [98.0, 313.0, 271.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2122 q_vals: [-8.524, -8.366, -8.356, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 879 2 visits [98.0, 313.0, 272.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2123 q_vals: [-8.524, -8.366, -8.354, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 880 2 visits [98.0, 313.0, 273.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2125 q_vals: [-8.524, -8.366, -8.353, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
{"total_number_of_episodes": 2128, "number_of_timesteps": 39708, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 881 2 visits [98.0, 313.0, 274.0, 16.0, 14.0, 2.0, 91.0, 67.0, 2.0, 4.0]  episode_count: 2128 q_vals: [-8.524, -8.366, -8.394, -9.209, -9.035, -14.354, -8.533, -8.525, -15.016, -11.803]
Step 882 7 visits [98.0, 313.0, 274.0, 16.0, 14.0, 2.0, 91.0, 68.0, 2.0, 4.0]  episode_count: 2131 q_vals: [-8.524, -8.366, -8.394, -9.209, -9.035, -14.354, -8.533, -8.69, -15.016, -11.803]
Step 883 1 visits [98.0, 314.0, 274.0, 16.0, 14.0, 2.0, 91.0, 68.0, 2.0, 4.0]  episode_count: 2132 q_vals: [-8.524, -8.403, -8.394, -9.209, -9.035, -14.354, -8.533, -8.69, -15.016, -11.803]
Step 884 2 visits [98.0, 314.0, 275.0, 16.0, 14.0, 2.0, 91.0, 68.0, 2.0, 4.0]  episode_count: 2134 q_vals: [-8.524, -8.403, -8.392, -9.209, -9.035, -14.354, -8.533, -8.69, -15.016, -11.803]
Step 885 2 visits [98.0, 314.0, 276.0, 16.0, 14.0, 2.0, 91.0, 68.0, 2.0, 4.0]  episode_count: 2136 q_vals: [-8.524, -8.403, -8.391, -9.209, -9.035, -14.354, -8.533, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2138, "number_of_timesteps": 39937, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 886 2 visits [98.0, 314.0, 277.0, 16.0, 14.0, 2.0, 91.0, 68.0, 2.0, 4.0]  episode_count: 2138 q_vals: [-8.524, -8.403, -8.36, -9.209, -9.035, -14.354, -8.533, -8.69, -15.016, -11.803]
Step 887 2 visits [98.0, 314.0, 278.0, 16.0, 14.0, 2.0, 91.0, 68.0, 2.0, 4.0]  episode_count: 2139 q_vals: [-8.524, -8.403, -8.359, -9.209, -9.035, -14.354, -8.533, -8.69, -15.016, -11.803]
Step 888 2 visits [98.0, 314.0, 279.0, 16.0, 14.0, 2.0, 91.0, 68.0, 2.0, 4.0]  episode_count: 2142 q_vals: [-8.524, -8.403, -8.399, -9.209, -9.035, -14.354, -8.533, -8.69, -15.016, -11.803]
Step 889 2 visits [98.0, 314.0, 280.0, 16.0, 14.0, 2.0, 91.0, 68.0, 2.0, 4.0]  episode_count: 2145 q_vals: [-8.524, -8.403, -8.398, -9.209, -9.035, -14.354, -8.533, -8.69, -15.016, -11.803]
Step 890 2 visits [98.0, 314.0, 281.0, 16.0, 14.0, 2.0, 91.0, 68.0, 2.0, 4.0]  episode_count: 2147 q_vals: [-8.524, -8.403, -8.396, -9.209, -9.035, -14.354, -8.533, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2149, "number_of_timesteps": 40188, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 891 2 visits [98.0, 314.0, 282.0, 16.0, 14.0, 2.0, 91.0, 68.0, 2.0, 4.0]  episode_count: 2149 q_vals: [-8.524, -8.403, -8.394, -9.209, -9.035, -14.354, -8.533, -8.69, -15.016, -11.803]
Step 892 2 visits [98.0, 314.0, 283.0, 16.0, 14.0, 2.0, 91.0, 68.0, 2.0, 4.0]  episode_count: 2151 q_vals: [-8.524, -8.403, -8.434, -9.209, -9.035, -14.354, -8.533, -8.69, -15.016, -11.803]
Step 893 1 visits [98.0, 315.0, 283.0, 16.0, 14.0, 2.0, 91.0, 68.0, 2.0, 4.0]  episode_count: 2156 q_vals: [-8.524, -8.401, -8.434, -9.209, -9.035, -14.354, -8.533, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2159, "number_of_timesteps": 40358, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 894 1 visits [98.0, 316.0, 283.0, 16.0, 14.0, 2.0, 91.0, 68.0, 2.0, 4.0]  episode_count: 2159 q_vals: [-8.524, -8.437, -8.434, -9.209, -9.035, -14.354, -8.533, -8.69, -15.016, -11.803]
Step 895 6 visits [98.0, 316.0, 283.0, 16.0, 14.0, 2.0, 92.0, 68.0, 2.0, 4.0]  episode_count: 2162 q_vals: [-8.524, -8.437, -8.434, -9.209, -9.035, -14.354, -8.526, -8.69, -15.016, -11.803]
Step 896 6 visits [98.0, 316.0, 283.0, 16.0, 14.0, 2.0, 93.0, 68.0, 2.0, 4.0]  episode_count: 2164 q_vals: [-8.524, -8.437, -8.434, -9.209, -9.035, -14.354, -8.519, -8.69, -15.016, -11.803]
Step 897 6 visits [98.0, 316.0, 283.0, 16.0, 14.0, 2.0, 94.0, 68.0, 2.0, 4.0]  episode_count: 2167 q_vals: [-8.524, -8.437, -8.434, -9.209, -9.035, -14.354, -8.513, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2170, "number_of_timesteps": 40511, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 898 6 visits [98.0, 316.0, 283.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2170 q_vals: [-8.524, -8.437, -8.434, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 899 0 visits [99.0, 316.0, 283.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2171 q_vals: [-8.518, -8.437, -8.434, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 900 0 visits [100.0, 316.0, 283.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2171 q_vals: [-8.433, -8.437, -8.434, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 901 0 visits [101.0, 316.0, 283.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2175 q_vals: [-8.427, -8.437, -8.434, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 902 0 visits [102.0, 316.0, 283.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2179 q_vals: [-8.422, -8.437, -8.434, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2180, "number_of_timesteps": 40708, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 903 0 visits [103.0, 316.0, 283.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2180 q_vals: [-8.417, -8.437, -8.434, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 904 0 visits [104.0, 316.0, 283.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2181 q_vals: [-8.412, -8.437, -8.434, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 905 0 visits [105.0, 316.0, 283.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2184 q_vals: [-8.52, -8.437, -8.434, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 906 0 visits [106.0, 316.0, 283.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2189 q_vals: [-8.514, -8.437, -8.434, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 907 0 visits [107.0, 316.0, 283.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2189 q_vals: [-8.619, -8.437, -8.434, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2193, "number_of_timesteps": 40973, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 908 2 visits [107.0, 316.0, 284.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2193 q_vals: [-8.619, -8.437, -8.474, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 909 1 visits [107.0, 317.0, 284.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2197 q_vals: [-8.619, -8.435, -8.474, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 910 1 visits [107.0, 318.0, 284.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2198 q_vals: [-8.619, -8.434, -8.474, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 911 1 visits [107.0, 319.0, 284.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2201 q_vals: [-8.619, -8.469, -8.474, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2205, "number_of_timesteps": 41152, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 912 2 visits [107.0, 319.0, 285.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2205 q_vals: [-8.619, -8.469, -8.472, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 913 2 visits [107.0, 319.0, 286.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2206 q_vals: [-8.619, -8.469, -8.47, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 914 2 visits [107.0, 319.0, 287.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2209 q_vals: [-8.619, -8.469, -8.468, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 915 2 visits [107.0, 319.0, 288.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2210 q_vals: [-8.619, -8.469, -8.466, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2216, "number_of_timesteps": 41352, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 916 2 visits [107.0, 319.0, 289.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2216 q_vals: [-8.619, -8.469, -8.464, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 917 2 visits [107.0, 319.0, 290.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2217 q_vals: [-8.619, -8.469, -8.435, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 918 2 visits [107.0, 319.0, 291.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2220 q_vals: [-8.619, -8.469, -8.474, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2226, "number_of_timesteps": 41502, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 919 2 visits [107.0, 319.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2226 q_vals: [-8.619, -8.469, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 920 1 visits [107.0, 320.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2227 q_vals: [-8.619, -8.467, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 921 1 visits [107.0, 321.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2230 q_vals: [-8.619, -8.466, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 922 1 visits [107.0, 322.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2233 q_vals: [-8.619, -8.439, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 923 1 visits [107.0, 323.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2235 q_vals: [-8.619, -8.438, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2239, "number_of_timesteps": 41686, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 924 1 visits [107.0, 324.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2239 q_vals: [-8.619, -8.472, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 925 1 visits [107.0, 325.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2241 q_vals: [-8.619, -8.471, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 926 1 visits [107.0, 326.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2245 q_vals: [-8.619, -8.469, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2249, "number_of_timesteps": 41848, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 927 1 visits [107.0, 327.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2249 q_vals: [-8.619, -8.467, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 928 1 visits [107.0, 328.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2251 q_vals: [-8.619, -8.466, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 929 1 visits [107.0, 329.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2253 q_vals: [-8.619, -8.464, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 930 1 visits [107.0, 330.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2258 q_vals: [-8.619, -8.462, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2262, "number_of_timesteps": 42022, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 931 1 visits [107.0, 331.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2262 q_vals: [-8.619, -8.46, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 932 1 visits [107.0, 332.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2264 q_vals: [-8.619, -8.459, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 933 1 visits [107.0, 333.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2270 q_vals: [-8.619, -8.457, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2273, "number_of_timesteps": 42152, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 934 1 visits [107.0, 334.0, 292.0, 16.0, 14.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2273 q_vals: [-8.619, -8.491, -8.513, -9.209, -9.035, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 935 4 visits [107.0, 334.0, 292.0, 16.0, 15.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2275 q_vals: [-8.619, -8.491, -8.513, -9.209, -8.959, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 936 4 visits [107.0, 334.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2279 q_vals: [-8.619, -8.491, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 937 1 visits [107.0, 335.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2282 q_vals: [-8.619, -8.489, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2285, "number_of_timesteps": 42307, "per_episode_reward": 15.05, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 938 1 visits [107.0, 336.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2285 q_vals: [-8.619, -8.464, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 939 1 visits [107.0, 337.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2290 q_vals: [-8.619, -8.439, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 940 1 visits [107.0, 338.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2294 q_vals: [-8.619, -8.437, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2295, "number_of_timesteps": 42419, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 941 1 visits [107.0, 339.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2295 q_vals: [-8.619, -8.436, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 942 1 visits [107.0, 340.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2300 q_vals: [-8.619, -8.434, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 943 1 visits [107.0, 341.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2300 q_vals: [-8.619, -8.467, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 944 1 visits [107.0, 342.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2300 q_vals: [-8.619, -8.466, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2307, "number_of_timesteps": 42614, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 945 1 visits [107.0, 343.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2307 q_vals: [-8.619, -8.464, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 946 1 visits [107.0, 344.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2309 q_vals: [-8.619, -8.462, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 947 1 visits [107.0, 345.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2312 q_vals: [-8.619, -8.438, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 948 1 visits [107.0, 346.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2315 q_vals: [-8.619, -8.436, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2317, "number_of_timesteps": 42774, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 949 1 visits [107.0, 347.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2317 q_vals: [-8.619, -8.435, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 950 1 visits [107.0, 348.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2319 q_vals: [-8.619, -8.41, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 951 1 visits [107.0, 349.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2323 q_vals: [-8.619, -8.386, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 952 1 visits [107.0, 350.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2325 q_vals: [-8.619, -8.385, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2328, "number_of_timesteps": 42968, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 953 1 visits [107.0, 351.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2328 q_vals: [-8.619, -8.384, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 954 1 visits [107.0, 352.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2332 q_vals: [-8.619, -8.382, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 955 1 visits [107.0, 353.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2333 q_vals: [-8.619, -8.381, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 956 1 visits [107.0, 354.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2334 q_vals: [-8.619, -8.379, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2340, "number_of_timesteps": 43151, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
Step 957 1 visits [107.0, 355.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2340 q_vals: [-8.619, -8.378, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 958 1 visits [107.0, 356.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2342 q_vals: [-8.619, -8.355, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 959 1 visits [107.0, 357.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2345 q_vals: [-8.619, -8.353, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 960 1 visits [107.0, 358.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2346 q_vals: [-8.619, -8.352, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 961 1 visits [107.0, 359.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2348 q_vals: [-8.619, -8.351, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2350, "number_of_timesteps": 43322, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 962 1 visits [107.0, 360.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2350 q_vals: [-8.619, -8.35, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 963 1 visits [107.0, 361.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2352 q_vals: [-8.619, -8.348, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 964 1 visits [107.0, 362.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2353 q_vals: [-8.619, -8.325, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 965 1 visits [107.0, 363.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2354 q_vals: [-8.619, -8.324, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 966 1 visits [107.0, 364.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2358 q_vals: [-8.619, -8.355, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2361, "number_of_timesteps": 43599, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 967 1 visits [107.0, 365.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2361 q_vals: [-8.619, -8.354, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 968 1 visits [107.0, 366.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2364 q_vals: [-8.619, -8.353, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 969 1 visits [107.0, 367.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2369 q_vals: [-8.619, -8.384, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2371, "number_of_timesteps": 43742, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 970 1 visits [107.0, 368.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2371 q_vals: [-8.619, -8.415, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 971 1 visits [107.0, 369.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2373 q_vals: [-8.619, -8.414, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 972 1 visits [107.0, 370.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2377 q_vals: [-8.619, -8.412, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 973 1 visits [107.0, 371.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2377 q_vals: [-8.619, -8.411, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 974 1 visits [107.0, 372.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2379 q_vals: [-8.619, -8.409, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 975 1 visits [107.0, 373.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2380 q_vals: [-8.619, -8.44, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2383, "number_of_timesteps": 43945, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 976 1 visits [107.0, 374.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2383 q_vals: [-8.619, -8.47, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 977 1 visits [107.0, 375.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2386 q_vals: [-8.619, -8.469, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 978 1 visits [107.0, 376.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2387 q_vals: [-8.619, -8.467, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 979 1 visits [107.0, 377.0, 292.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2390 q_vals: [-8.619, -8.497, -8.513, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 980 2 visits [107.0, 377.0, 293.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2390 q_vals: [-8.619, -8.497, -8.511, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2394, "number_of_timesteps": 44168, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 981 2 visits [107.0, 377.0, 294.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2394 q_vals: [-8.619, -8.497, -8.508, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 982 2 visits [107.0, 377.0, 295.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2396 q_vals: [-8.619, -8.497, -8.506, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 983 2 visits [107.0, 377.0, 296.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2398 q_vals: [-8.619, -8.497, -8.544, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 984 1 visits [107.0, 378.0, 296.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2401 q_vals: [-8.619, -8.495, -8.544, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 985 1 visits [107.0, 379.0, 296.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2402 q_vals: [-8.619, -8.494, -8.544, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 986 1 visits [107.0, 380.0, 296.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2402 q_vals: [-8.619, -8.492, -8.544, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2406, "number_of_timesteps": 44466, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 987 1 visits [107.0, 381.0, 296.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2406 q_vals: [-8.619, -8.491, -8.544, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 988 1 visits [107.0, 382.0, 296.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2407 q_vals: [-8.619, -8.489, -8.544, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 989 1 visits [107.0, 383.0, 296.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2411 q_vals: [-8.619, -8.488, -8.544, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 990 1 visits [107.0, 384.0, 296.0, 16.0, 16.0, 2.0, 95.0, 68.0, 2.0, 4.0]  episode_count: 2413 q_vals: [-8.619, -8.517, -8.544, -9.209, -9.634, -14.354, -8.631, -8.69, -15.016, -11.803]
Step 991 6 visits [107.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2414 q_vals: [-8.619, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 992 0 visits [108.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2414 q_vals: [-8.613, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2417, "number_of_timesteps": 44696, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 993 0 visits [109.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2417 q_vals: [-8.606, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 994 0 visits [110.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2419 q_vals: [-8.6, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 995 0 visits [111.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2419 q_vals: [-8.594, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 996 0 visits [112.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2419 q_vals: [-8.587, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 997 0 visits [113.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2425 q_vals: [-8.511, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 998 0 visits [114.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2426 q_vals: [-8.437, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2427, "number_of_timesteps": 44981, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 999 0 visits [115.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2427 q_vals: [-8.432, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 1000 0 visits [116.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2429 q_vals: [-8.428, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 1001 0 visits [117.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2435 q_vals: [-8.524, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 1002 0 visits [118.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2436 q_vals: [-8.519, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2439, "number_of_timesteps": 45239, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1003 0 visits [119.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2439 q_vals: [-8.514, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 1004 0 visits [120.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2440 q_vals: [-8.509, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 1005 0 visits [121.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2443 q_vals: [-8.438, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 1006 0 visits [122.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2446 q_vals: [-8.434, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 1007 0 visits [123.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2448 q_vals: [-8.365, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2450, "number_of_timesteps": 45411, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1008 0 visits [124.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2450 q_vals: [-8.457, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 1009 0 visits [125.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2454 q_vals: [-8.453, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 1010 0 visits [126.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2455 q_vals: [-8.448, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 1011 0 visits [127.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2459 q_vals: [-8.537, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
{"total_number_of_episodes": 2462, "number_of_timesteps": 45641, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 1012 0 visits [128.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2462 q_vals: [-8.533, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 1013 0 visits [129.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 68.0, 2.0, 4.0]  episode_count: 2463 q_vals: [-8.62, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.69, -15.016, -11.803]
Step 1014 7 visits [129.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 69.0, 2.0, 4.0]  episode_count: 2466 q_vals: [-8.62, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.678, -15.016, -11.803]
{"total_number_of_episodes": 2472, "number_of_timesteps": 45797, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 1015 7 visits [129.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 70.0, 2.0, 4.0]  episode_count: 2472 q_vals: [-8.62, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.667, -15.016, -11.803]
Step 1016 7 visits [129.0, 384.0, 296.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2473 q_vals: [-8.62, -8.517, -8.544, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1017 1 visits [129.0, 385.0, 296.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2473 q_vals: [-8.62, -8.514, -8.544, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1018 1 visits [129.0, 386.0, 296.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2478 q_vals: [-8.62, -8.543, -8.544, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1019 0 visits [130.0, 386.0, 296.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2480 q_vals: [-8.705, -8.543, -8.544, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1020 2 visits [130.0, 386.0, 297.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2481 q_vals: [-8.705, -8.543, -8.542, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
{"total_number_of_episodes": 2484, "number_of_timesteps": 45982, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1021 2 visits [130.0, 386.0, 298.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2484 q_vals: [-8.705, -8.543, -8.514, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1022 2 visits [130.0, 386.0, 299.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2486 q_vals: [-8.705, -8.543, -8.512, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1023 2 visits [130.0, 386.0, 300.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2491 q_vals: [-8.705, -8.543, -8.483, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
{"total_number_of_episodes": 2494, "number_of_timesteps": 46174, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1024 2 visits [130.0, 386.0, 301.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2494 q_vals: [-8.705, -8.543, -8.521, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1025 2 visits [130.0, 386.0, 302.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2498 q_vals: [-8.705, -8.543, -8.558, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1026 2 visits [130.0, 386.0, 303.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2502 q_vals: [-8.705, -8.543, -8.556, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
{"total_number_of_episodes": 2505, "number_of_timesteps": 46300, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 1027 2 visits [130.0, 386.0, 304.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2505 q_vals: [-8.705, -8.543, -8.553, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1028 2 visits [130.0, 386.0, 305.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2507 q_vals: [-8.705, -8.543, -8.551, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1029 2 visits [130.0, 386.0, 306.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2513 q_vals: [-8.705, -8.543, -8.588, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
{"total_number_of_episodes": 2515, "number_of_timesteps": 46421, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 1030 1 visits [130.0, 387.0, 306.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2515 q_vals: [-8.705, -8.54, -8.588, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1031 1 visits [130.0, 388.0, 306.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2518 q_vals: [-8.705, -8.538, -8.588, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1032 1 visits [130.0, 389.0, 306.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2521 q_vals: [-8.705, -8.567, -8.588, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
{"total_number_of_episodes": 2526, "number_of_timesteps": 46579, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 1033 1 visits [130.0, 390.0, 306.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2526 q_vals: [-8.705, -8.565, -8.588, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1034 1 visits [130.0, 391.0, 306.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2529 q_vals: [-8.705, -8.564, -8.588, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1035 1 visits [130.0, 392.0, 306.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2533 q_vals: [-8.705, -8.592, -8.588, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
{"total_number_of_episodes": 2536, "number_of_timesteps": 46698, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1036 2 visits [130.0, 392.0, 307.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2536 q_vals: [-8.705, -8.592, -8.616, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1037 1 visits [130.0, 393.0, 307.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2540 q_vals: [-8.705, -8.59, -8.616, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1038 1 visits [130.0, 394.0, 307.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2545 q_vals: [-8.705, -8.589, -8.616, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
{"total_number_of_episodes": 2549, "number_of_timesteps": 46844, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1039 1 visits [130.0, 395.0, 307.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2549 q_vals: [-8.705, -8.617, -8.616, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1040 2 visits [130.0, 395.0, 308.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2553 q_vals: [-8.705, -8.617, -8.614, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1041 2 visits [130.0, 395.0, 309.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2557 q_vals: [-8.705, -8.617, -8.65, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
{"total_number_of_episodes": 2561, "number_of_timesteps": 46970, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1042 0 visits [131.0, 395.0, 309.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2561 q_vals: [-8.699, -8.617, -8.65, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1043 0 visits [132.0, 395.0, 309.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2564 q_vals: [-8.633, -8.617, -8.65, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1044 0 visits [133.0, 395.0, 309.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2566 q_vals: [-8.628, -8.617, -8.65, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
{"total_number_of_episodes": 2573, "number_of_timesteps": 47119, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1045 0 visits [134.0, 395.0, 309.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2573 q_vals: [-8.622, -8.617, -8.65, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1046 0 visits [135.0, 395.0, 309.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2575 q_vals: [-8.558, -8.617, -8.65, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1047 0 visits [136.0, 395.0, 309.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2576 q_vals: [-8.613, -8.617, -8.65, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1048 0 visits [137.0, 395.0, 309.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2582 q_vals: [-8.608, -8.617, -8.65, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
{"total_number_of_episodes": 2584, "number_of_timesteps": 47254, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1049 0 visits [138.0, 395.0, 309.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2584 q_vals: [-8.688, -8.617, -8.65, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1050 0 visits [139.0, 395.0, 309.0, 16.0, 16.0, 2.0, 96.0, 71.0, 2.0, 4.0]  episode_count: 2587 q_vals: [-8.768, -8.617, -8.65, -9.209, -9.634, -14.354, -8.747, -8.823, -15.016, -11.803]
Step 1051 6 visits [139.0, 395.0, 309.0, 16.0, 16.0, 2.0, 97.0, 71.0, 2.0, 4.0]  episode_count: 2592 q_vals: [-8.768, -8.617, -8.65, -9.209, -9.634, -14.354, -8.738, -8.823, -15.016, -11.803]
{"total_number_of_episodes": 2595, "number_of_timesteps": 47393, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1052 6 visits [139.0, 395.0, 309.0, 16.0, 16.0, 2.0, 98.0, 71.0, 2.0, 4.0]  episode_count: 2595 q_vals: [-8.768, -8.617, -8.65, -9.209, -9.634, -14.354, -8.73, -8.823, -15.016, -11.803]
Step 1053 6 visits [139.0, 395.0, 309.0, 16.0, 16.0, 2.0, 99.0, 71.0, 2.0, 4.0]  episode_count: 2597 q_vals: [-8.768, -8.617, -8.65, -9.209, -9.634, -14.354, -8.841, -8.823, -15.016, -11.803]
Step 1054 1 visits [139.0, 396.0, 309.0, 16.0, 16.0, 2.0, 99.0, 71.0, 2.0, 4.0]  episode_count: 2602 q_vals: [-8.768, -8.645, -8.65, -9.209, -9.634, -14.354, -8.841, -8.823, -15.016, -11.803]
{"total_number_of_episodes": 2606, "number_of_timesteps": 47539, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1055 2 visits [139.0, 396.0, 310.0, 16.0, 16.0, 2.0, 99.0, 71.0, 2.0, 4.0]  episode_count: 2606 q_vals: [-8.768, -8.645, -8.686, -9.209, -9.634, -14.354, -8.841, -8.823, -15.016, -11.803]
Step 1056 7 visits [139.0, 396.0, 310.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2607 q_vals: [-8.768, -8.645, -8.686, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1057 1 visits [139.0, 397.0, 310.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2610 q_vals: [-8.768, -8.643, -8.686, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2616, "number_of_timesteps": 47681, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1058 1 visits [139.0, 398.0, 310.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2616 q_vals: [-8.768, -8.621, -8.686, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1059 1 visits [139.0, 399.0, 310.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2616 q_vals: [-8.768, -8.619, -8.686, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1060 1 visits [139.0, 400.0, 310.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2619 q_vals: [-8.768, -8.617, -8.686, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1061 1 visits [139.0, 401.0, 310.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2623 q_vals: [-8.768, -8.645, -8.686, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2627, "number_of_timesteps": 47837, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
Step 1062 1 visits [139.0, 402.0, 310.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2627 q_vals: [-8.768, -8.673, -8.686, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1063 2 visits [139.0, 402.0, 311.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2629 q_vals: [-8.768, -8.673, -8.683, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1064 2 visits [139.0, 402.0, 312.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2629 q_vals: [-8.768, -8.673, -8.719, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1065 1 visits [139.0, 403.0, 312.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2633 q_vals: [-8.768, -8.7, -8.719, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1066 0 visits [140.0, 403.0, 312.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2635 q_vals: [-8.762, -8.7, -8.719, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2638, "number_of_timesteps": 48040, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1067 0 visits [141.0, 403.0, 312.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2638 q_vals: [-8.756, -8.7, -8.719, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1068 0 visits [142.0, 403.0, 312.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2641 q_vals: [-8.75, -8.7, -8.719, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1069 0 visits [143.0, 403.0, 312.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2643 q_vals: [-8.688, -8.7, -8.719, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2648, "number_of_timesteps": 48184, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1070 0 visits [144.0, 403.0, 312.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2648 q_vals: [-8.679, -8.7, -8.719, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1071 0 visits [145.0, 403.0, 312.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2650 q_vals: [-8.755, -8.7, -8.719, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1072 0 visits [146.0, 403.0, 312.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2653 q_vals: [-8.743, -8.7, -8.719, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1073 0 visits [147.0, 403.0, 312.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2657 q_vals: [-8.738, -8.7, -8.719, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2660, "number_of_timesteps": 48361, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1074 0 visits [148.0, 403.0, 312.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2660 q_vals: [-8.732, -8.7, -8.719, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1075 0 visits [149.0, 403.0, 312.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2662 q_vals: [-8.726, -8.7, -8.719, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1076 0 visits [150.0, 403.0, 312.0, 16.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2666 q_vals: [-8.784, -8.7, -8.719, -9.209, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1077 3 visits [150.0, 403.0, 312.0, 17.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2669 q_vals: [-8.784, -8.7, -8.719, -8.667, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2673, "number_of_timesteps": 48536, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1078 3 visits [150.0, 403.0, 312.0, 18.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2673 q_vals: [-8.784, -8.7, -8.719, -8.625, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1079 3 visits [150.0, 403.0, 312.0, 19.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2677 q_vals: [-8.784, -8.7, -8.719, -8.475, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1080 3 visits [150.0, 403.0, 312.0, 20.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2680 q_vals: [-8.784, -8.7, -8.719, -8.446, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2684, "number_of_timesteps": 48671, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1081 3 visits [150.0, 403.0, 312.0, 21.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2684 q_vals: [-8.784, -8.7, -8.719, -8.42, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1082 3 visits [150.0, 403.0, 312.0, 22.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2688 q_vals: [-8.784, -8.7, -8.719, -8.935, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1083 3 visits [150.0, 403.0, 312.0, 23.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2692 q_vals: [-8.784, -8.7, -8.719, -9.405, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1084 0 visits [151.0, 403.0, 312.0, 23.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2693 q_vals: [-8.856, -8.7, -8.719, -9.405, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2699, "number_of_timesteps": 48842, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1085 1 visits [151.0, 404.0, 312.0, 23.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2699 q_vals: [-8.856, -8.694, -8.719, -9.405, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1086 1 visits [151.0, 405.0, 312.0, 23.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2701 q_vals: [-8.856, -8.722, -8.719, -9.405, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1087 2 visits [151.0, 405.0, 313.0, 23.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2705 q_vals: [-8.856, -8.722, -8.716, -9.405, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
Step 1088 2 visits [151.0, 405.0, 314.0, 23.0, 16.0, 2.0, 99.0, 72.0, 2.0, 4.0]  episode_count: 2708 q_vals: [-8.856, -8.722, -8.751, -9.405, -9.634, -14.354, -8.841, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2713, "number_of_timesteps": 49038, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1089 6 visits [151.0, 405.0, 314.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2713 q_vals: [-8.856, -8.722, -8.751, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1090 1 visits [151.0, 406.0, 314.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2714 q_vals: [-8.856, -8.738, -8.751, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1091 2 visits [151.0, 406.0, 315.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2718 q_vals: [-8.856, -8.738, -8.747, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1092 2 visits [151.0, 406.0, 316.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2721 q_vals: [-8.856, -8.738, -8.744, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2723, "number_of_timesteps": 49171, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1093 2 visits [151.0, 406.0, 317.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2723 q_vals: [-8.856, -8.738, -8.735, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1094 2 visits [151.0, 406.0, 318.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2728 q_vals: [-8.856, -8.738, -8.732, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1095 2 visits [151.0, 406.0, 319.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2732 q_vals: [-8.856, -8.738, -8.729, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2736, "number_of_timesteps": 49346, "per_episode_reward": 14.75, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1096 2 visits [151.0, 406.0, 320.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2736 q_vals: [-8.856, -8.738, -8.727, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1097 2 visits [151.0, 406.0, 321.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2739 q_vals: [-8.856, -8.738, -8.724, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1098 2 visits [151.0, 406.0, 322.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2742 q_vals: [-8.856, -8.738, -8.721, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2748, "number_of_timesteps": 49480, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
Step 1099 2 visits [151.0, 406.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2748 q_vals: [-8.856, -8.738, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1100 1 visits [151.0, 407.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2750 q_vals: [-8.856, -8.736, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1101 1 visits [151.0, 408.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2753 q_vals: [-8.856, -8.714, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1102 1 visits [151.0, 409.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2756 q_vals: [-8.856, -8.708, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2760, "number_of_timesteps": 49632, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
Step 1103 1 visits [151.0, 410.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2760 q_vals: [-8.856, -8.698, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1104 1 visits [151.0, 411.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2764 q_vals: [-8.856, -8.696, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1105 1 visits [151.0, 412.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2768 q_vals: [-8.856, -8.694, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2772, "number_of_timesteps": 49784, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
Step 1106 1 visits [151.0, 413.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2772 q_vals: [-8.856, -8.692, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1107 1 visits [151.0, 414.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2773 q_vals: [-8.856, -8.69, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1108 1 visits [151.0, 415.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2779 q_vals: [-8.856, -8.716, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1109 1 visits [151.0, 416.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2781 q_vals: [-8.856, -8.714, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2783, "number_of_timesteps": 49923, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
Step 1110 1 visits [151.0, 417.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2783 q_vals: [-8.856, -8.712, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1111 1 visits [151.0, 418.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2789 q_vals: [-8.856, -8.71, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1112 1 visits [151.0, 419.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2791 q_vals: [-8.856, -8.736, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2795, "number_of_timesteps": 50072, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
Step 1113 1 visits [151.0, 420.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2795 q_vals: [-8.856, -8.715, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1114 1 visits [151.0, 421.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2800 q_vals: [-8.856, -8.71, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1115 1 visits [151.0, 422.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2802 q_vals: [-8.856, -8.708, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2808, "number_of_timesteps": 50218, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
Step 1116 1 visits [151.0, 423.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2808 q_vals: [-8.856, -8.706, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1117 1 visits [151.0, 424.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2811 q_vals: [-8.856, -8.702, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1118 1 visits [151.0, 425.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2814 q_vals: [-8.856, -8.728, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2820, "number_of_timesteps": 50347, "per_episode_reward": 14.45, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.15000000000000036},
Step 1119 1 visits [151.0, 426.0, 323.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2820 q_vals: [-8.856, -8.754, -8.756, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1120 2 visits [151.0, 426.0, 324.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2823 q_vals: [-8.856, -8.754, -8.753, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1121 2 visits [151.0, 426.0, 325.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2826 q_vals: [-8.856, -8.754, -8.746, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2832, "number_of_timesteps": 50489, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
Step 1122 2 visits [151.0, 426.0, 326.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2832 q_vals: [-8.856, -8.754, -8.743, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1123 2 visits [151.0, 426.0, 327.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2834 q_vals: [-8.856, -8.754, -8.738, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1124 2 visits [151.0, 426.0, 328.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2835 q_vals: [-8.856, -8.754, -8.771, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1125 2 visits [151.0, 426.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2841 q_vals: [-8.856, -8.754, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2844, "number_of_timesteps": 50641, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
Step 1126 1 visits [151.0, 427.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2844 q_vals: [-8.856, -8.752, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1127 1 visits [151.0, 428.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2845 q_vals: [-8.856, -8.777, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1128 0 visits [152.0, 428.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2851 q_vals: [-8.842, -8.777, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2854, "number_of_timesteps": 50766, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
Step 1129 0 visits [153.0, 428.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2854 q_vals: [-8.836, -8.777, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1130 0 visits [154.0, 428.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2857 q_vals: [-8.83, -8.777, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1131 0 visits [155.0, 428.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2860 q_vals: [-8.824, -8.777, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1132 0 visits [156.0, 428.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2863 q_vals: [-8.894, -8.777, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2865, "number_of_timesteps": 50904, "per_episode_reward": 14.35, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
Step 1133 1 visits [156.0, 429.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2865 q_vals: [-8.894, -8.775, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1134 1 visits [156.0, 430.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2870 q_vals: [-8.894, -8.769, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1135 1 visits [156.0, 431.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2872 q_vals: [-8.894, -8.767, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2875, "number_of_timesteps": 51035, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.10000000000000142},
Step 1136 1 visits [156.0, 432.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2875 q_vals: [-8.894, -8.765, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1137 1 visits [156.0, 433.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2878 q_vals: [-8.894, -8.757, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1138 1 visits [156.0, 434.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2880 q_vals: [-8.894, -8.755, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2886, "number_of_timesteps": 51202, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.10000000000000142},
Step 1139 1 visits [156.0, 435.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2886 q_vals: [-8.894, -8.753, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1140 1 visits [156.0, 436.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2888 q_vals: [-8.894, -8.751, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1141 1 visits [156.0, 437.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2890 q_vals: [-8.894, -8.749, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1142 1 visits [156.0, 438.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2894 q_vals: [-8.894, -8.773, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2897, "number_of_timesteps": 51367, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.10000000000000142},
Step 1143 1 visits [156.0, 439.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2897 q_vals: [-8.894, -8.771, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1144 1 visits [156.0, 440.0, 329.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2899 q_vals: [-8.894, -8.795, -8.805, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
Step 1145 2 visits [156.0, 440.0, 330.0, 23.0, 16.0, 2.0, 100.0, 72.0, 2.0, 4.0]  episode_count: 2903 q_vals: [-8.894, -8.795, -8.834, -9.405, -9.634, -14.354, -8.95, -8.975, -15.016, -11.803]
{"total_number_of_episodes": 2907, "number_of_timesteps": 51509, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
Step 1146 7 visits [156.0, 440.0, 330.0, 23.0, 16.0, 2.0, 100.0, 73.0, 2.0, 4.0]  episode_count: 2907 q_vals: [-8.894, -8.795, -8.834, -9.405, -9.634, -14.354, -8.95, -8.96, -15.016, -11.803]
Step 1147 7 visits [156.0, 440.0, 330.0, 23.0, 16.0, 2.0, 100.0, 74.0, 2.0, 4.0]  episode_count: 2909 q_vals: [-8.894, -8.795, -8.834, -9.405, -9.634, -14.354, -8.95, -8.946, -15.016, -11.803]
Step 1148 7 visits [156.0, 440.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2912 q_vals: [-8.894, -8.795, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 2917, "number_of_timesteps": 51636, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
Step 1149 1 visits [156.0, 441.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2917 q_vals: [-8.894, -8.785, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
Step 1150 1 visits [156.0, 442.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2918 q_vals: [-8.894, -8.783, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
Step 1151 1 visits [156.0, 443.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2922 q_vals: [-8.894, -8.774, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
Step 1152 1 visits [156.0, 444.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2925 q_vals: [-8.894, -8.771, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 2927, "number_of_timesteps": 51764, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1153 1 visits [156.0, 445.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2927 q_vals: [-8.894, -8.769, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
Step 1154 1 visits [156.0, 446.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2931 q_vals: [-8.894, -8.765, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
Step 1155 1 visits [156.0, 447.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2934 q_vals: [-8.894, -8.763, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 2937, "number_of_timesteps": 51912, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1156 1 visits [156.0, 448.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2937 q_vals: [-8.894, -8.761, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
Step 1157 1 visits [156.0, 449.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2940 q_vals: [-8.894, -8.749, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
Step 1158 1 visits [156.0, 450.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2943 q_vals: [-8.894, -8.773, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 2950, "number_of_timesteps": 52093, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1159 1 visits [156.0, 451.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2950 q_vals: [-8.894, -8.771, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
Step 1160 1 visits [156.0, 452.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2951 q_vals: [-8.894, -8.752, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
Step 1161 1 visits [156.0, 453.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2955 q_vals: [-8.894, -8.776, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 2960, "number_of_timesteps": 52209, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1162 1 visits [156.0, 454.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2960 q_vals: [-8.894, -8.801, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
Step 1163 1 visits [156.0, 455.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2961 q_vals: [-8.894, -8.793, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
Step 1164 1 visits [156.0, 456.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2965 q_vals: [-8.894, -8.791, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
Step 1165 1 visits [156.0, 457.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2968 q_vals: [-8.894, -8.815, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
Step 1166 0 visits [157.0, 457.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2969 q_vals: [-8.878, -8.815, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 2975, "number_of_timesteps": 52409, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1167 0 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 100.0, 75.0, 2.0, 4.0]  episode_count: 2975 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.95, -9.001, -15.016, -11.803]
Step 1168 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 101.0, 75.0, 2.0, 4.0]  episode_count: 2977 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.94, -9.001, -15.016, -11.803]
Step 1169 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 102.0, 75.0, 2.0, 4.0]  episode_count: 2980 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.93, -9.001, -15.016, -11.803]
Step 1170 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 103.0, 75.0, 2.0, 4.0]  episode_count: 2982 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.92, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 2985, "number_of_timesteps": 52553, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1171 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 104.0, 75.0, 2.0, 4.0]  episode_count: 2985 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.852, -9.001, -15.016, -11.803]
Step 1172 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 105.0, 75.0, 2.0, 4.0]  episode_count: 2987 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.843, -9.001, -15.016, -11.803]
Step 1173 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 106.0, 75.0, 2.0, 4.0]  episode_count: 2990 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.808, -9.001, -15.016, -11.803]
Step 1174 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 107.0, 75.0, 2.0, 4.0]  episode_count: 2992 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.74, -9.001, -15.016, -11.803]
Step 1175 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 108.0, 75.0, 2.0, 4.0]  episode_count: 2993 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.732, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 2999, "number_of_timesteps": 52786, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1176 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 109.0, 75.0, 2.0, 4.0]  episode_count: 2999 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.677, -9.001, -15.016, -11.803]
Step 1177 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 110.0, 75.0, 2.0, 4.0]  episode_count: 3003 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.67, -9.001, -15.016, -11.803]
Step 1178 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 111.0, 75.0, 2.0, 4.0]  episode_count: 3006 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.663, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3011, "number_of_timesteps": 52941, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1179 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 112.0, 75.0, 2.0, 4.0]  episode_count: 3011 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.656, -9.001, -15.016, -11.803]
Step 1180 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 113.0, 75.0, 2.0, 4.0]  episode_count: 3015 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.579, -9.001, -15.016, -11.803]
Step 1181 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 114.0, 75.0, 2.0, 4.0]  episode_count: 3018 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.569, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3023, "number_of_timesteps": 53069, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1182 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 115.0, 75.0, 2.0, 4.0]  episode_count: 3023 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.527, -9.001, -15.016, -11.803]
Step 1183 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 116.0, 75.0, 2.0, 4.0]  episode_count: 3024 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.522, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3033, "number_of_timesteps": 53180, "per_episode_reward": 14.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1184 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 117.0, 75.0, 2.0, 4.0]  episode_count: 3033 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.527, -9.001, -15.016, -11.803]
Step 1185 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 118.0, 75.0, 2.0, 4.0]  episode_count: 3034 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.508, -9.001, -15.016, -11.803]
[-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.437, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3044, "number_of_timesteps": 53286, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1187 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 120.0, 75.0, 2.0, 4.0]  episode_count: 3044 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.531, -9.001, -15.016, -11.803]
Step 1188 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 121.0, 75.0, 2.0, 4.0]  episode_count: 3049 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.623, -9.001, -15.016, -11.803]
Step 1189 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 122.0, 75.0, 2.0, 4.0]  episode_count: 3052 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.714, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3056, "number_of_timesteps": 53415, "per_episode_reward": 14.15, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 1190 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 123.0, 75.0, 2.0, 4.0]  episode_count: 3056 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.804, -9.001, -15.016, -11.803]
Step 1191 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 124.0, 75.0, 2.0, 4.0]  episode_count: 3061 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.796, -9.001, -15.016, -11.803]
Step 1192 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 125.0, 75.0, 2.0, 4.0]  episode_count: 3064 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.786, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3069, "number_of_timesteps": 53549, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 1193 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 126.0, 75.0, 2.0, 4.0]  episode_count: 3069 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.779, -9.001, -15.016, -11.803]
Step 1194 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 127.0, 75.0, 2.0, 4.0]  episode_count: 3071 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.772, -9.001, -15.016, -11.803]
Step 1195 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 128.0, 75.0, 2.0, 4.0]  episode_count: 3075 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.704, -9.001, -15.016, -11.803]
Step 1196 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 129.0, 75.0, 2.0, 4.0]  episode_count: 3078 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.79, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3082, "number_of_timesteps": 53714, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 1197 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 130.0, 75.0, 2.0, 4.0]  episode_count: 3082 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.779, -9.001, -15.016, -11.803]
Step 1198 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 131.0, 75.0, 2.0, 4.0]  episode_count: 3085 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.746, -9.001, -15.016, -11.803]
Step 1199 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 132.0, 75.0, 2.0, 4.0]  episode_count: 3088 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.829, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3093, "number_of_timesteps": 53846, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 1200 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 133.0, 75.0, 2.0, 4.0]  episode_count: 3093 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.816, -9.001, -15.016, -11.803]
Step 1201 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 134.0, 75.0, 2.0, 4.0]  episode_count: 3095 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.81, -9.001, -15.016, -11.803]
Step 1202 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 135.0, 75.0, 2.0, 4.0]  episode_count: 3102 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.803, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3103, "number_of_timesteps": 53968, "per_episode_reward": 14.05, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
Step 1203 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 136.0, 75.0, 2.0, 4.0]  episode_count: 3103 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.812, -9.001, -15.016, -11.803]
Step 1204 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 137.0, 75.0, 2.0, 4.0]  episode_count: 3107 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.806, -9.001, -15.016, -11.803]
Step 1205 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 138.0, 75.0, 2.0, 4.0]  episode_count: 3112 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.795, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3115, "number_of_timesteps": 54115, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
Step 1206 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 139.0, 75.0, 2.0, 4.0]  episode_count: 3115 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.874, -9.001, -15.016, -11.803]
Step 1207 6 visits [158.0, 457.0, 330.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3118 q_vals: [-8.947, -8.815, -8.834, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1208 2 visits [158.0, 457.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3123 q_vals: [-8.947, -8.815, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3125, "number_of_timesteps": 54227, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
Step 1209 1 visits [158.0, 458.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3125 q_vals: [-8.947, -8.811, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1210 1 visits [158.0, 459.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3131 q_vals: [-8.947, -8.808, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3135, "number_of_timesteps": 54336, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
Step 1211 1 visits [158.0, 460.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3135 q_vals: [-8.947, -8.797, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1212 1 visits [158.0, 461.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3137 q_vals: [-8.947, -8.795, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
[-8.947, -8.793, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3145, "number_of_timesteps": 54456, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 1214 1 visits [158.0, 463.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3145 q_vals: [-8.947, -8.791, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1215 1 visits [158.0, 464.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3149 q_vals: [-8.947, -8.776, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1216 1 visits [158.0, 465.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3152 q_vals: [-8.947, -8.774, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3157, "number_of_timesteps": 54588, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 1217 1 visits [158.0, 466.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3157 q_vals: [-8.947, -8.759, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1218 1 visits [158.0, 467.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3160 q_vals: [-8.947, -8.757, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1219 1 visits [158.0, 468.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3162 q_vals: [-8.947, -8.755, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3169, "number_of_timesteps": 54731, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1220 1 visits [158.0, 469.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3169 q_vals: [-8.947, -8.746, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1221 1 visits [158.0, 470.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3170 q_vals: [-8.947, -8.733, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1222 1 visits [158.0, 471.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3176 q_vals: [-8.947, -8.731, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3179, "number_of_timesteps": 54843, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1223 1 visits [158.0, 472.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3179 q_vals: [-8.947, -8.729, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1224 1 visits [158.0, 473.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3181 q_vals: [-8.947, -8.711, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1225 1 visits [158.0, 474.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3185 q_vals: [-8.947, -8.709, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3190, "number_of_timesteps": 54981, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1226 1 visits [158.0, 475.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3190 q_vals: [-8.947, -8.691, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1227 1 visits [158.0, 476.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3193 q_vals: [-8.947, -8.689, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1228 1 visits [158.0, 477.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3196 q_vals: [-8.947, -8.688, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3200, "number_of_timesteps": 55096, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1229 1 visits [158.0, 478.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3200 q_vals: [-8.947, -8.686, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1230 1 visits [158.0, 479.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3203 q_vals: [-8.947, -8.709, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1231 1 visits [158.0, 480.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3208 q_vals: [-8.947, -8.703, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3210, "number_of_timesteps": 55215, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1232 1 visits [158.0, 481.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3210 q_vals: [-8.947, -8.702, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1233 1 visits [158.0, 482.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3214 q_vals: [-8.947, -8.695, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1234 1 visits [158.0, 483.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3219 q_vals: [-8.947, -8.677, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3222, "number_of_timesteps": 55354, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1235 1 visits [158.0, 484.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3222 q_vals: [-8.947, -8.676, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1236 1 visits [158.0, 485.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3224 q_vals: [-8.947, -8.674, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1237 1 visits [158.0, 486.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3228 q_vals: [-8.947, -8.67, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1238 1 visits [158.0, 487.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3231 q_vals: [-8.947, -8.669, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3233, "number_of_timesteps": 55498, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1239 1 visits [158.0, 488.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3233 q_vals: [-8.947, -8.666, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1240 1 visits [158.0, 489.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3237 q_vals: [-8.947, -8.665, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
[-8.947, -8.678, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3243, "number_of_timesteps": 55632, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1242 1 visits [158.0, 491.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3243 q_vals: [-8.947, -8.676, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1243 1 visits [158.0, 492.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3245 q_vals: [-8.947, -8.674, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1244 1 visits [158.0, 493.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3250 q_vals: [-8.947, -8.669, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1245 1 visits [158.0, 494.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3251 q_vals: [-8.947, -8.651, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3254, "number_of_timesteps": 55803, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1246 1 visits [158.0, 495.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3254 q_vals: [-8.947, -8.674, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1247 1 visits [158.0, 496.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3257 q_vals: [-8.947, -8.681, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1248 1 visits [158.0, 497.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3260 q_vals: [-8.947, -8.679, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1249 1 visits [158.0, 498.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3261 q_vals: [-8.947, -8.677, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3264, "number_of_timesteps": 55942, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1250 1 visits [158.0, 499.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3264 q_vals: [-8.947, -8.676, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1251 1 visits [158.0, 500.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3266 q_vals: [-8.947, -8.674, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1252 1 visits [158.0, 501.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3268 q_vals: [-8.947, -8.657, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1253 1 visits [158.0, 502.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3270 q_vals: [-8.947, -8.679, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1254 1 visits [158.0, 503.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3273 q_vals: [-8.947, -8.678, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3275, "number_of_timesteps": 56202, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1255 1 visits [158.0, 504.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3275 q_vals: [-8.947, -8.676, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1256 1 visits [158.0, 505.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3276 q_vals: [-8.947, -8.659, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1257 1 visits [158.0, 506.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3279 q_vals: [-8.947, -8.642, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1258 1 visits [158.0, 507.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3282 q_vals: [-8.947, -8.64, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3285, "number_of_timesteps": 56369, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1259 1 visits [158.0, 508.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3285 q_vals: [-8.947, -8.639, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1260 1 visits [158.0, 509.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3288 q_vals: [-8.947, -8.625, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1261 1 visits [158.0, 510.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3289 q_vals: [-8.947, -8.62, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1262 1 visits [158.0, 511.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3292 q_vals: [-8.947, -8.619, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3295, "number_of_timesteps": 56545, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1263 1 visits [158.0, 512.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3295 q_vals: [-8.947, -8.606, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1264 1 visits [158.0, 513.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3298 q_vals: [-8.947, -8.6, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1265 1 visits [158.0, 514.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3300 q_vals: [-8.947, -8.622, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1266 1 visits [158.0, 515.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3301 q_vals: [-8.947, -8.619, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3306, "number_of_timesteps": 56738, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1267 1 visits [158.0, 516.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3306 q_vals: [-8.947, -8.618, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1268 1 visits [158.0, 517.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3307 q_vals: [-8.947, -8.611, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1269 1 visits [158.0, 518.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3309 q_vals: [-8.947, -8.609, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1270 1 visits [158.0, 519.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3312 q_vals: [-8.947, -8.608, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3317, "number_of_timesteps": 56963, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1271 1 visits [158.0, 520.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3317 q_vals: [-8.947, -8.592, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1272 1 visits [158.0, 521.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3319 q_vals: [-8.947, -8.59, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1273 1 visits [158.0, 522.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3321 q_vals: [-8.947, -8.585, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3327, "number_of_timesteps": 57089, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1274 1 visits [158.0, 523.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3327 q_vals: [-8.947, -8.582, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1275 1 visits [158.0, 524.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3329 q_vals: [-8.947, -8.604, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1276 1 visits [158.0, 525.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3329 q_vals: [-8.947, -8.625, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1277 1 visits [158.0, 526.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3336 q_vals: [-8.947, -8.619, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3337, "number_of_timesteps": 57222, "per_episode_reward": 13.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1278 1 visits [158.0, 527.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3337 q_vals: [-8.947, -8.603, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1279 1 visits [158.0, 528.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3339 q_vals: [-8.947, -8.586, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1280 1 visits [158.0, 529.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3344 q_vals: [-8.947, -8.608, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3347, "number_of_timesteps": 57370, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1281 1 visits [158.0, 530.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3347 q_vals: [-8.947, -8.615, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1282 1 visits [158.0, 531.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3349 q_vals: [-8.947, -8.613, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1283 1 visits [158.0, 532.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3353 q_vals: [-8.947, -8.612, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1284 1 visits [158.0, 533.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3355 q_vals: [-8.947, -8.611, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3359, "number_of_timesteps": 57538, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1285 1 visits [158.0, 534.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3359 q_vals: [-8.947, -8.632, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1286 1 visits [158.0, 535.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3361 q_vals: [-8.947, -8.63, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1287 1 visits [158.0, 536.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3363 q_vals: [-8.947, -8.629, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1288 1 visits [158.0, 537.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3364 q_vals: [-8.947, -8.628, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1289 1 visits [158.0, 538.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3367 q_vals: [-8.947, -8.648, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3370, "number_of_timesteps": 57730, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1290 1 visits [158.0, 539.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3370 q_vals: [-8.947, -8.642, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1291 1 visits [158.0, 540.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3374 q_vals: [-8.947, -8.626, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1292 1 visits [158.0, 541.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3377 q_vals: [-8.947, -8.642, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3381, "number_of_timesteps": 57906, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1293 1 visits [158.0, 542.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3381 q_vals: [-8.947, -8.64, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1294 1 visits [158.0, 543.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3382 q_vals: [-8.947, -8.639, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1295 1 visits [158.0, 544.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3386 q_vals: [-8.947, -8.638, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1296 1 visits [158.0, 545.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3388 q_vals: [-8.947, -8.636, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1297 1 visits [158.0, 546.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3389 q_vals: [-8.947, -8.635, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3394, "number_of_timesteps": 58106, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1298 1 visits [158.0, 547.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3394 q_vals: [-8.947, -8.633, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1299 1 visits [158.0, 548.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3396 q_vals: [-8.947, -8.632, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1300 1 visits [158.0, 549.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3397 q_vals: [-8.947, -8.631, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1301 1 visits [158.0, 550.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3401 q_vals: [-8.947, -8.629, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3404, "number_of_timesteps": 58285, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1302 1 visits [158.0, 551.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3404 q_vals: [-8.947, -8.628, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1303 1 visits [158.0, 552.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3406 q_vals: [-8.947, -8.613, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1304 1 visits [158.0, 553.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3409 q_vals: [-8.947, -8.608, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1305 1 visits [158.0, 554.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3412 q_vals: [-8.947, -8.628, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3415, "number_of_timesteps": 58466, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1306 1 visits [158.0, 555.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3415 q_vals: [-8.947, -8.627, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1307 1 visits [158.0, 556.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3417 q_vals: [-8.947, -8.626, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1308 1 visits [158.0, 557.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3419 q_vals: [-8.947, -8.624, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1309 1 visits [158.0, 558.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3420 q_vals: [-8.947, -8.623, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3425, "number_of_timesteps": 58633, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1310 1 visits [158.0, 559.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3425 q_vals: [-8.947, -8.622, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1311 1 visits [158.0, 560.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3427 q_vals: [-8.947, -8.621, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1312 1 visits [158.0, 561.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3428 q_vals: [-8.947, -8.619, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1313 1 visits [158.0, 562.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3430 q_vals: [-8.947, -8.614, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1314 1 visits [158.0, 563.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3433 q_vals: [-8.947, -8.613, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1315 1 visits [158.0, 564.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3434 q_vals: [-8.947, -8.598, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3436, "number_of_timesteps": 58859, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1316 1 visits [158.0, 565.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3436 q_vals: [-8.947, -8.595, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1317 1 visits [158.0, 566.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3438 q_vals: [-8.947, -8.594, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1318 1 visits [158.0, 567.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3439 q_vals: [-8.947, -8.593, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1319 1 visits [158.0, 568.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3442 q_vals: [-8.947, -8.613, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1320 1 visits [158.0, 569.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3445 q_vals: [-8.947, -8.607, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3446, "number_of_timesteps": 59087, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1321 1 visits [158.0, 570.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3446 q_vals: [-8.947, -8.605, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1322 1 visits [158.0, 571.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3447 q_vals: [-8.947, -8.604, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1323 1 visits [158.0, 572.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3451 q_vals: [-8.947, -8.6, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1324 1 visits [158.0, 573.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3453 q_vals: [-8.947, -8.585, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1325 1 visits [158.0, 574.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3454 q_vals: [-8.947, -8.584, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3458, "number_of_timesteps": 59343, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1326 1 visits [158.0, 575.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3458 q_vals: [-8.947, -8.603, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1327 1 visits [158.0, 576.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3458 q_vals: [-8.947, -8.588, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1328 1 visits [158.0, 577.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3462 q_vals: [-8.947, -8.607, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1329 1 visits [158.0, 578.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3466 q_vals: [-8.947, -8.606, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3468, "number_of_timesteps": 59562, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1330 1 visits [158.0, 579.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3468 q_vals: [-8.947, -8.605, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1331 1 visits [158.0, 580.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3468 q_vals: [-8.947, -8.59, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1332 1 visits [158.0, 581.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3471 q_vals: [-8.947, -8.589, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1333 1 visits [158.0, 582.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3472 q_vals: [-8.947, -8.574, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1334 1 visits [158.0, 583.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3475 q_vals: [-8.947, -8.573, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3478, "number_of_timesteps": 59760, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1335 1 visits [158.0, 584.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3478 q_vals: [-8.947, -8.558, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1336 1 visits [158.0, 585.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3481 q_vals: [-8.947, -8.557, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1337 1 visits [158.0, 586.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3483 q_vals: [-8.947, -8.556, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1338 1 visits [158.0, 587.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3484 q_vals: [-8.947, -8.554, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3488, "number_of_timesteps": 59940, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1339 1 visits [158.0, 588.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3488 q_vals: [-8.947, -8.556, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1340 1 visits [158.0, 589.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3490 q_vals: [-8.947, -8.555, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1341 1 visits [158.0, 590.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3492 q_vals: [-8.947, -8.574, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1342 1 visits [158.0, 591.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3495 q_vals: [-8.947, -8.572, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1343 1 visits [158.0, 592.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3496 q_vals: [-8.947, -8.564, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3499, "number_of_timesteps": 60143, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1344 1 visits [158.0, 593.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3499 q_vals: [-8.947, -8.559, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1345 1 visits [158.0, 594.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3501 q_vals: [-8.947, -8.557, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1346 1 visits [158.0, 595.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3505 q_vals: [-8.947, -8.556, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1347 1 visits [158.0, 596.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3508 q_vals: [-8.947, -8.555, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3510, "number_of_timesteps": 60364, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1348 1 visits [158.0, 597.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3510 q_vals: [-8.947, -8.549, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1349 1 visits [158.0, 598.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3511 q_vals: [-8.947, -8.548, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1350 1 visits [158.0, 599.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3515 q_vals: [-8.947, -8.542, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1351 1 visits [158.0, 600.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3519 q_vals: [-8.947, -8.561, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3521, "number_of_timesteps": 60550, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1352 1 visits [158.0, 601.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3521 q_vals: [-8.947, -8.56, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1353 1 visits [158.0, 602.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3526 q_vals: [-8.947, -8.559, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1354 1 visits [158.0, 603.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3528 q_vals: [-8.947, -8.544, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1355 1 visits [158.0, 604.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3530 q_vals: [-8.947, -8.543, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3534, "number_of_timesteps": 60735, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1356 1 visits [158.0, 605.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3534 q_vals: [-8.947, -8.542, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1357 1 visits [158.0, 606.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3534 q_vals: [-8.947, -8.541, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1358 1 visits [158.0, 607.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3538 q_vals: [-8.947, -8.554, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1359 1 visits [158.0, 608.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3539 q_vals: [-8.947, -8.553, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1360 1 visits [158.0, 609.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3542 q_vals: [-8.947, -8.568, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3544, "number_of_timesteps": 60924, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1361 1 visits [158.0, 610.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3544 q_vals: [-8.947, -8.567, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1362 1 visits [158.0, 611.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3548 q_vals: [-8.947, -8.566, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1363 1 visits [158.0, 612.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3550 q_vals: [-8.947, -8.584, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1364 1 visits [158.0, 613.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3553 q_vals: [-8.947, -8.582, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3556, "number_of_timesteps": 61136, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1365 1 visits [158.0, 614.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3556 q_vals: [-8.947, -8.581, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1366 1 visits [158.0, 615.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3559 q_vals: [-8.947, -8.58, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1367 1 visits [158.0, 616.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3561 q_vals: [-8.947, -8.598, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1368 1 visits [158.0, 617.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3563 q_vals: [-8.947, -8.616, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1369 1 visits [158.0, 618.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3565 q_vals: [-8.947, -8.634, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3566, "number_of_timesteps": 61281, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1370 1 visits [158.0, 619.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3566 q_vals: [-8.947, -8.633, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1371 1 visits [158.0, 620.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3569 q_vals: [-8.947, -8.651, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1372 1 visits [158.0, 621.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3571 q_vals: [-8.947, -8.669, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1373 1 visits [158.0, 622.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3573 q_vals: [-8.947, -8.655, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3576, "number_of_timesteps": 61527, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1374 1 visits [158.0, 623.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3576 q_vals: [-8.947, -8.653, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1375 1 visits [158.0, 624.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3577 q_vals: [-8.947, -8.652, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1376 1 visits [158.0, 625.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3581 q_vals: [-8.947, -8.651, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1377 1 visits [158.0, 626.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3583 q_vals: [-8.947, -8.65, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1378 1 visits [158.0, 627.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3584 q_vals: [-8.947, -8.668, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1379 1 visits [158.0, 628.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3585 q_vals: [-8.947, -8.654, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3588, "number_of_timesteps": 61700, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1380 1 visits [158.0, 629.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3588 q_vals: [-8.947, -8.64, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1381 1 visits [158.0, 630.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3591 q_vals: [-8.947, -8.658, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1382 1 visits [158.0, 631.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3592 q_vals: [-8.947, -8.675, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1383 1 visits [158.0, 632.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3596 q_vals: [-8.947, -8.693, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3598, "number_of_timesteps": 61994, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1384 1 visits [158.0, 633.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3598 q_vals: [-8.947, -8.71, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1385 1 visits [158.0, 634.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3600 q_vals: [-8.947, -8.709, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1386 1 visits [158.0, 635.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3602 q_vals: [-8.947, -8.708, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1387 1 visits [158.0, 636.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3603 q_vals: [-8.947, -8.694, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3608, "number_of_timesteps": 62205, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1388 1 visits [158.0, 637.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3608 q_vals: [-8.947, -8.711, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1389 1 visits [158.0, 638.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3609 q_vals: [-8.947, -8.71, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1390 1 visits [158.0, 639.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3612 q_vals: [-8.947, -8.709, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1391 1 visits [158.0, 640.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3617 q_vals: [-8.947, -8.695, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3618, "number_of_timesteps": 62367, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1392 1 visits [158.0, 641.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3618 q_vals: [-8.947, -8.712, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1393 1 visits [158.0, 642.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3619 q_vals: [-8.947, -8.711, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1394 1 visits [158.0, 643.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3621 q_vals: [-8.947, -8.71, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1395 1 visits [158.0, 644.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3625 q_vals: [-8.947, -8.709, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1396 1 visits [158.0, 645.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3626 q_vals: [-8.947, -8.707, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3628, "number_of_timesteps": 62565, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1397 1 visits [158.0, 646.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3628 q_vals: [-8.947, -8.705, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1398 1 visits [158.0, 647.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3631 q_vals: [-8.947, -8.692, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1399 1 visits [158.0, 648.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3634 q_vals: [-8.947, -8.685, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1400 1 visits [158.0, 649.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3635 q_vals: [-8.947, -8.684, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1401 1 visits [158.0, 650.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3636 q_vals: [-8.947, -8.701, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3638, "number_of_timesteps": 62757, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1402 1 visits [158.0, 651.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3638 q_vals: [-8.947, -8.688, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1403 1 visits [158.0, 652.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3640 q_vals: [-8.947, -8.686, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1404 1 visits [158.0, 653.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3643 q_vals: [-8.947, -8.685, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1405 1 visits [158.0, 654.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3646 q_vals: [-8.947, -8.684, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1406 1 visits [158.0, 655.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3646 q_vals: [-8.947, -8.683, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1407 1 visits [158.0, 656.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3647 q_vals: [-8.947, -8.67, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3650, "number_of_timesteps": 63017, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1408 1 visits [158.0, 657.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3650 q_vals: [-8.947, -8.668, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1409 1 visits [158.0, 658.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3652 q_vals: [-8.947, -8.667, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1410 1 visits [158.0, 659.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3654 q_vals: [-8.947, -8.666, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1411 1 visits [158.0, 660.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3656 q_vals: [-8.947, -8.673, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1412 1 visits [158.0, 661.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3657 q_vals: [-8.947, -8.672, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3662, "number_of_timesteps": 63324, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1413 1 visits [158.0, 662.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3662 q_vals: [-8.947, -8.659, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1414 1 visits [158.0, 663.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3663 q_vals: [-8.947, -8.658, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1415 1 visits [158.0, 664.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3664 q_vals: [-8.947, -8.657, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1416 1 visits [158.0, 665.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3667 q_vals: [-8.947, -8.655, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1417 1 visits [158.0, 666.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3670 q_vals: [-8.947, -8.654, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1418 1 visits [158.0, 667.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3671 q_vals: [-8.947, -8.653, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3675, "number_of_timesteps": 63575, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1419 1 visits [158.0, 668.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3675 q_vals: [-8.947, -8.652, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1420 1 visits [158.0, 669.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3677 q_vals: [-8.947, -8.651, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1421 1 visits [158.0, 670.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3679 q_vals: [-8.947, -8.65, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1422 1 visits [158.0, 671.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3683 q_vals: [-8.947, -8.649, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1423 1 visits [158.0, 672.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3684 q_vals: [-8.947, -8.648, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3686, "number_of_timesteps": 63794, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1424 1 visits [158.0, 673.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3686 q_vals: [-8.947, -8.647, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1425 1 visits [158.0, 674.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3687 q_vals: [-8.947, -8.645, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1426 1 visits [158.0, 675.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3692 q_vals: [-8.947, -8.644, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1427 1 visits [158.0, 676.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3694 q_vals: [-8.947, -8.643, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1428 1 visits [158.0, 677.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3695 q_vals: [-8.947, -8.642, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3696, "number_of_timesteps": 63993, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1429 1 visits [158.0, 678.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3696 q_vals: [-8.947, -8.659, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1430 1 visits [158.0, 679.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3697 q_vals: [-8.947, -8.657, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1431 1 visits [158.0, 680.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3700 q_vals: [-8.947, -8.656, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1432 1 visits [158.0, 681.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3704 q_vals: [-8.947, -8.655, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1433 1 visits [158.0, 682.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3704 q_vals: [-8.947, -8.654, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1434 1 visits [158.0, 683.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3705 q_vals: [-8.947, -8.653, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3708, "number_of_timesteps": 64263, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1435 1 visits [158.0, 684.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3708 q_vals: [-8.947, -8.652, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1436 1 visits [158.0, 685.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3709 q_vals: [-8.947, -8.651, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1437 1 visits [158.0, 686.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3712 q_vals: [-8.947, -8.65, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1438 1 visits [158.0, 687.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3714 q_vals: [-8.947, -8.649, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1439 1 visits [158.0, 688.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3716 q_vals: [-8.947, -8.648, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1440 1 visits [158.0, 689.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3717 q_vals: [-8.947, -8.646, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3721, "number_of_timesteps": 64548, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1441 1 visits [158.0, 690.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3721 q_vals: [-8.947, -8.645, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1442 1 visits [158.0, 691.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3723 q_vals: [-8.947, -8.644, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1443 1 visits [158.0, 692.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3727 q_vals: [-8.947, -8.643, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1444 1 visits [158.0, 693.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3729 q_vals: [-8.947, -8.642, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1445 1 visits [158.0, 694.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3730 q_vals: [-8.947, -8.641, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3732, "number_of_timesteps": 64794, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1446 1 visits [158.0, 695.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3732 q_vals: [-8.947, -8.629, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1447 1 visits [158.0, 696.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3735 q_vals: [-8.947, -8.628, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1448 1 visits [158.0, 697.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3736 q_vals: [-8.947, -8.627, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1449 1 visits [158.0, 698.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3737 q_vals: [-8.947, -8.625, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1450 1 visits [158.0, 699.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3739 q_vals: [-8.947, -8.613, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1451 1 visits [158.0, 700.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3739 q_vals: [-8.947, -8.612, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3743, "number_of_timesteps": 65055, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1452 1 visits [158.0, 701.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3743 q_vals: [-8.947, -8.611, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1453 1 visits [158.0, 702.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3745 q_vals: [-8.947, -8.61, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1454 1 visits [158.0, 703.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3746 q_vals: [-8.947, -8.609, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1455 1 visits [158.0, 704.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3750 q_vals: [-8.947, -8.608, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1456 1 visits [158.0, 705.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3752 q_vals: [-8.947, -8.607, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3753, "number_of_timesteps": 65258, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1457 1 visits [158.0, 706.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3753 q_vals: [-8.947, -8.606, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1458 1 visits [158.0, 707.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3756 q_vals: [-8.947, -8.605, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1459 1 visits [158.0, 708.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3759 q_vals: [-8.947, -8.593, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1460 1 visits [158.0, 709.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3761 q_vals: [-8.947, -8.581, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3765, "number_of_timesteps": 65503, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1461 1 visits [158.0, 710.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3765 q_vals: [-8.947, -8.58, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1462 1 visits [158.0, 711.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3767 q_vals: [-8.947, -8.572, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1463 1 visits [158.0, 712.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3768 q_vals: [-8.947, -8.571, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1464 1 visits [158.0, 713.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3773 q_vals: [-8.947, -8.57, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3775, "number_of_timesteps": 65683, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1465 1 visits [158.0, 714.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3775 q_vals: [-8.947, -8.585, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1466 1 visits [158.0, 715.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3778 q_vals: [-8.947, -8.601, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1467 1 visits [158.0, 716.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3782 q_vals: [-8.947, -8.589, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3785, "number_of_timesteps": 65833, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1468 1 visits [158.0, 717.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3785 q_vals: [-8.947, -8.588, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1469 1 visits [158.0, 718.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3787 q_vals: [-8.947, -8.587, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1470 1 visits [158.0, 719.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3789 q_vals: [-8.947, -8.586, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1471 1 visits [158.0, 720.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3791 q_vals: [-8.947, -8.585, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1472 1 visits [158.0, 721.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3794 q_vals: [-8.947, -8.584, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3798, "number_of_timesteps": 66055, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1473 1 visits [158.0, 722.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3798 q_vals: [-8.947, -8.6, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1474 1 visits [158.0, 723.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3799 q_vals: [-8.947, -8.599, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1475 1 visits [158.0, 724.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3802 q_vals: [-8.947, -8.598, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1476 1 visits [158.0, 725.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3803 q_vals: [-8.947, -8.59, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1477 1 visits [158.0, 726.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3806 q_vals: [-8.947, -8.584, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3809, "number_of_timesteps": 66210, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1478 1 visits [158.0, 727.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3809 q_vals: [-8.947, -8.583, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
[-8.947, -8.582, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1480 1 visits [158.0, 729.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3816 q_vals: [-8.947, -8.571, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3819, "number_of_timesteps": 66414, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1481 1 visits [158.0, 730.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3819 q_vals: [-8.947, -8.559, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1482 1 visits [158.0, 731.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3822 q_vals: [-8.947, -8.558, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1483 1 visits [158.0, 732.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3825 q_vals: [-8.947, -8.573, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1484 1 visits [158.0, 733.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3828 q_vals: [-8.947, -8.572, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3829, "number_of_timesteps": 66551, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1485 1 visits [158.0, 734.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3829 q_vals: [-8.947, -8.579, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1486 1 visits [158.0, 735.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3832 q_vals: [-8.947, -8.578, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1487 1 visits [158.0, 736.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3834 q_vals: [-8.947, -8.577, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1488 1 visits [158.0, 737.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3838 q_vals: [-8.947, -8.582, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3840, "number_of_timesteps": 66738, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1489 1 visits [158.0, 738.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3840 q_vals: [-8.947, -8.581, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1490 1 visits [158.0, 739.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3842 q_vals: [-8.947, -8.597, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1491 1 visits [158.0, 740.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3845 q_vals: [-8.947, -8.596, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1492 1 visits [158.0, 741.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3847 q_vals: [-8.947, -8.584, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1493 1 visits [158.0, 742.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3848 q_vals: [-8.947, -8.583, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1494 1 visits [158.0, 743.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3849 q_vals: [-8.947, -8.582, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3855, "number_of_timesteps": 67051, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1495 1 visits [158.0, 744.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3855 q_vals: [-8.947, -8.597, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1496 1 visits [158.0, 745.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3856 q_vals: [-8.947, -8.596, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1497 1 visits [158.0, 746.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3859 q_vals: [-8.947, -8.595, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1498 1 visits [158.0, 747.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3863 q_vals: [-8.947, -8.594, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1499 1 visits [158.0, 748.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3864 q_vals: [-8.947, -8.609, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3867, "number_of_timesteps": 67249, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1500 1 visits [158.0, 749.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3867 q_vals: [-8.947, -8.608, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1501 1 visits [158.0, 750.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3872 q_vals: [-8.947, -8.607, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1502 1 visits [158.0, 751.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3874 q_vals: [-8.947, -8.606, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1503 1 visits [158.0, 752.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3875 q_vals: [-8.947, -8.606, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3879, "number_of_timesteps": 67415, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1504 1 visits [158.0, 753.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3879 q_vals: [-8.947, -8.605, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1505 1 visits [158.0, 754.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3881 q_vals: [-8.947, -8.604, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1506 1 visits [158.0, 755.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3881 q_vals: [-8.947, -8.601, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1507 1 visits [158.0, 756.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3886 q_vals: [-8.947, -8.616, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1508 1 visits [158.0, 757.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3887 q_vals: [-8.947, -8.615, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3889, "number_of_timesteps": 67618, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
 episode_count: 3889 q_vals: [-8.947, -8.614, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1510 1 visits [158.0, 759.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3893 q_vals: [-8.947, -8.613, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1511 1 visits [158.0, 760.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3893 q_vals: [-8.947, -8.612, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1512 1 visits [158.0, 761.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3896 q_vals: [-8.947, -8.611, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3899, "number_of_timesteps": 67767, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1513 1 visits [158.0, 762.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3899 q_vals: [-8.947, -8.626, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1514 1 visits [158.0, 763.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3901 q_vals: [-8.947, -8.625, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1515 1 visits [158.0, 764.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3904 q_vals: [-8.947, -8.624, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1516 1 visits [158.0, 765.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3906 q_vals: [-8.947, -8.623, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1517 1 visits [158.0, 766.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3908 q_vals: [-8.947, -8.622, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3913, "number_of_timesteps": 68075, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1518 1 visits [158.0, 767.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3913 q_vals: [-8.947, -8.618, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1519 1 visits [158.0, 768.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3913 q_vals: [-8.947, -8.617, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1520 1 visits [158.0, 769.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3918 q_vals: [-8.947, -8.616, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1521 1 visits [158.0, 770.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3922 q_vals: [-8.947, -8.615, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3924, "number_of_timesteps": 68236, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1522 1 visits [158.0, 771.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3924 q_vals: [-8.947, -8.614, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1523 1 visits [158.0, 772.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3926 q_vals: [-8.947, -8.629, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1524 1 visits [158.0, 773.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3932 q_vals: [-8.947, -8.628, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3934, "number_of_timesteps": 68373, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1525 1 visits [158.0, 774.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3934 q_vals: [-8.947, -8.638, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1526 1 visits [158.0, 775.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3937 q_vals: [-8.947, -8.637, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1527 1 visits [158.0, 776.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3941 q_vals: [-8.947, -8.652, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1528 1 visits [158.0, 777.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3943 q_vals: [-8.947, -8.651, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3947, "number_of_timesteps": 68549, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1529 1 visits [158.0, 778.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3947 q_vals: [-8.947, -8.64, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1530 1 visits [158.0, 779.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3949 q_vals: [-8.947, -8.639, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1531 1 visits [158.0, 780.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3952 q_vals: [-8.947, -8.638, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1532 1 visits [158.0, 781.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3956 q_vals: [-8.947, -8.637, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3958, "number_of_timesteps": 68712, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1533 1 visits [158.0, 782.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3958 q_vals: [-8.947, -8.636, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1534 1 visits [158.0, 783.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3961 q_vals: [-8.947, -8.635, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1535 1 visits [158.0, 784.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3965 q_vals: [-8.947, -8.634, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1536 1 visits [158.0, 785.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3967 q_vals: [-8.947, -8.648, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3971, "number_of_timesteps": 68894, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1537 1 visits [158.0, 786.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3971 q_vals: [-8.947, -8.648, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1538 1 visits [158.0, 787.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3973 q_vals: [-8.947, -8.647, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
[158.0, 788.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3976 q_vals: [-8.947, -8.646, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1540 1 visits [158.0, 789.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3978 q_vals: [-8.947, -8.645, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1541 1 visits [158.0, 790.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3980 q_vals: [-8.947, -8.641, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3982, "number_of_timesteps": 69072, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1542 1 visits [158.0, 791.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3982 q_vals: [-8.947, -8.64, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1543 1 visits [158.0, 792.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3985 q_vals: [-8.947, -8.639, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1544 1 visits [158.0, 793.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3988 q_vals: [-8.947, -8.638, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1545 1 visits [158.0, 794.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3991 q_vals: [-8.947, -8.637, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 3993, "number_of_timesteps": 69279, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1546 1 visits [158.0, 795.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3993 q_vals: [-8.947, -8.651, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1547 1 visits [158.0, 796.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3994 q_vals: [-8.947, -8.65, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1548 1 visits [158.0, 797.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3996 q_vals: [-8.947, -8.649, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1549 1 visits [158.0, 798.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 3998 q_vals: [-8.947, -8.648, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1550 1 visits [158.0, 799.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4001 q_vals: [-8.947, -8.647, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4003, "number_of_timesteps": 69503, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1551 1 visits [158.0, 800.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4003 q_vals: [-8.947, -8.647, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1552 1 visits [158.0, 801.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4005 q_vals: [-8.947, -8.646, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1553 1 visits [158.0, 802.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4007 q_vals: [-8.947, -8.645, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1554 1 visits [158.0, 803.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4008 q_vals: [-8.947, -8.659, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1555 1 visits [158.0, 804.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4009 q_vals: [-8.947, -8.658, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4013, "number_of_timesteps": 69719, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1556 1 visits [158.0, 805.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4013 q_vals: [-8.947, -8.657, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1557 1 visits [158.0, 806.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4015 q_vals: [-8.947, -8.656, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1558 1 visits [158.0, 807.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4017 q_vals: [-8.947, -8.654, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1559 1 visits [158.0, 808.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4020 q_vals: [-8.947, -8.668, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1560 1 visits [158.0, 809.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4020 q_vals: [-8.947, -8.667, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4023, "number_of_timesteps": 69933, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1561 1 visits [158.0, 810.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4023 q_vals: [-8.947, -8.666, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1562 1 visits [158.0, 811.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4025 q_vals: [-8.947, -8.655, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1563 1 visits [158.0, 812.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4028 q_vals: [-8.947, -8.654, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1564 1 visits [158.0, 813.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4031 q_vals: [-8.947, -8.653, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1565 1 visits [158.0, 814.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4032 q_vals: [-8.947, -8.643, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1566 1 visits [158.0, 815.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4032 q_vals: [-8.947, -8.642, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4037, "number_of_timesteps": 70228, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1567 1 visits [158.0, 816.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4037 q_vals: [-8.947, -8.655, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1568 1 visits [158.0, 817.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4038 q_vals: [-8.947, -8.655, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1569 1 visits [158.0, 818.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4038 q_vals: [-8.947, -8.654, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1570 1 visits [158.0, 819.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4040 q_vals: [-8.947, -8.667, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1571 1 visits [158.0, 820.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4043 q_vals: [-8.947, -8.666, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1572 1 visits [158.0, 821.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4046 q_vals: [-8.947, -8.665, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4047, "number_of_timesteps": 70448, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1573 1 visits [158.0, 822.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4047 q_vals: [-8.947, -8.664, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1574 1 visits [158.0, 823.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4049 q_vals: [-8.947, -8.663, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1575 1 visits [158.0, 824.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4051 q_vals: [-8.947, -8.663, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1576 1 visits [158.0, 825.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4052 q_vals: [-8.947, -8.662, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1577 1 visits [158.0, 826.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4055 q_vals: [-8.947, -8.675, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4057, "number_of_timesteps": 70689, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1578 1 visits [158.0, 827.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4057 q_vals: [-8.947, -8.665, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1579 1 visits [158.0, 828.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4058 q_vals: [-8.947, -8.664, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1580 1 visits [158.0, 829.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4060 q_vals: [-8.947, -8.663, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1581 1 visits [158.0, 830.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4065 q_vals: [-8.947, -8.662, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4067, "number_of_timesteps": 70945, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1582 1 visits [158.0, 831.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4067 q_vals: [-8.947, -8.661, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1583 1 visits [158.0, 832.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4068 q_vals: [-8.947, -8.66, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1584 1 visits [158.0, 833.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4070 q_vals: [-8.947, -8.659, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1585 1 visits [158.0, 834.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4072 q_vals: [-8.947, -8.658, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1586 1 visits [158.0, 835.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4074 q_vals: [-8.947, -8.671, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1587 1 visits [158.0, 836.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4075 q_vals: [-8.947, -8.661, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4077, "number_of_timesteps": 71136, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1588 1 visits [158.0, 837.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4077 q_vals: [-8.947, -8.66, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1589 1 visits [158.0, 838.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4081 q_vals: [-8.947, -8.65, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1590 1 visits [158.0, 839.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4083 q_vals: [-8.947, -8.649, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4087, "number_of_timesteps": 71339, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1591 1 visits [158.0, 840.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4087 q_vals: [-8.947, -8.648, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1592 1 visits [158.0, 841.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4088 q_vals: [-8.947, -8.647, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1593 1 visits [158.0, 842.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4092 q_vals: [-8.947, -8.646, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1594 1 visits [158.0, 843.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4094 q_vals: [-8.947, -8.645, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1595 1 visits [158.0, 844.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4096 q_vals: [-8.947, -8.644, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4101, "number_of_timesteps": 71595, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1596 1 visits [158.0, 845.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4101 q_vals: [-8.947, -8.644, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1597 1 visits [158.0, 846.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4104 q_vals: [-8.947, -8.657, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1598 1 visits [158.0, 847.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4105 q_vals: [-8.947, -8.656, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4111, "number_of_timesteps": 71734, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1599 1 visits [158.0, 848.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4111 q_vals: [-8.947, -8.655, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1600 1 visits [158.0, 849.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4113 q_vals: [-8.947, -8.668, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1601 1 visits [158.0, 850.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4115 q_vals: [-8.947, -8.667, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1602 1 visits [158.0, 851.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4118 q_vals: [-8.947, -8.666, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4122, "number_of_timesteps": 71905, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1603 1 visits [158.0, 852.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4122 q_vals: [-8.947, -8.665, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1604 1 visits [158.0, 853.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4124 q_vals: [-8.947, -8.664, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1605 1 visits [158.0, 854.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4126 q_vals: [-8.947, -8.664, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1606 1 visits [158.0, 855.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4130 q_vals: [-8.947, -8.663, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4132, "number_of_timesteps": 72048, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1607 1 visits [158.0, 856.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4132 q_vals: [-8.947, -8.676, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1608 1 visits [158.0, 857.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4135 q_vals: [-8.947, -8.675, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1609 1 visits [158.0, 858.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4137 q_vals: [-8.947, -8.674, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1610 1 visits [158.0, 859.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4139 q_vals: [-8.947, -8.673, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4145, "number_of_timesteps": 72282, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1611 1 visits [158.0, 860.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4145 q_vals: [-8.947, -8.672, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1612 1 visits [158.0, 861.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4148 q_vals: [-8.947, -8.671, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1613 1 visits [158.0, 862.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4152 q_vals: [-8.947, -8.684, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1614 1 visits [158.0, 863.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4154 q_vals: [-8.947, -8.683, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4157, "number_of_timesteps": 72438, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1615 1 visits [158.0, 864.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4157 q_vals: [-8.947, -8.682, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1616 1 visits [158.0, 865.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4159 q_vals: [-8.947, -8.681, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1617 1 visits [158.0, 866.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4165 q_vals: [-8.947, -8.694, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1618 1 visits [158.0, 867.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4166 q_vals: [-8.947, -8.693, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4171, "number_of_timesteps": 72642, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1619 1 visits [158.0, 868.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4171 q_vals: [-8.947, -8.692, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1620 1 visits [158.0, 869.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4173 q_vals: [-8.947, -8.705, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1621 1 visits [158.0, 870.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4175 q_vals: [-8.947, -8.704, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1622 1 visits [158.0, 871.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4180 q_vals: [-8.947, -8.703, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4181, "number_of_timesteps": 72763, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1623 1 visits [158.0, 872.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4181 q_vals: [-8.947, -8.716, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1624 1 visits [158.0, 873.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4187 q_vals: [-8.947, -8.728, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1625 1 visits [158.0, 874.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4189 q_vals: [-8.947, -8.727, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4193, "number_of_timesteps": 72941, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1626 1 visits [158.0, 875.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4193 q_vals: [-8.947, -8.727, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1627 1 visits [158.0, 876.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4196 q_vals: [-8.947, -8.726, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1628 1 visits [158.0, 877.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4198 q_vals: [-8.947, -8.738, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1629 1 visits [158.0, 878.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4202 q_vals: [-8.947, -8.751, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4207, "number_of_timesteps": 73139, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1630 1 visits [158.0, 879.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4207 q_vals: [-8.947, -8.75, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1631 1 visits [158.0, 880.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4208 q_vals: [-8.947, -8.749, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1632 1 visits [158.0, 881.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4213 q_vals: [-8.947, -8.748, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1633 1 visits [158.0, 882.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4216 q_vals: [-8.947, -8.747, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4220, "number_of_timesteps": 73303, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1634 1 visits [158.0, 883.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4220 q_vals: [-8.947, -8.746, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1635 1 visits [158.0, 884.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4225 q_vals: [-8.947, -8.745, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1636 1 visits [158.0, 885.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4227 q_vals: [-8.947, -8.744, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4233, "number_of_timesteps": 73451, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1637 1 visits [158.0, 886.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4233 q_vals: [-8.947, -8.756, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1638 1 visits [158.0, 887.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4237 q_vals: [-8.947, -8.755, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1639 1 visits [158.0, 888.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4240 q_vals: [-8.947, -8.754, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
{"total_number_of_episodes": 4244, "number_of_timesteps": 73564, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1640 1 visits [158.0, 889.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4244 q_vals: [-8.947, -8.767, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1641 1 visits [158.0, 890.0, 331.0, 23.0, 16.0, 2.0, 140.0, 75.0, 2.0, 4.0]  episode_count: 4246 q_vals: [-8.947, -8.779, -8.858, -9.405, -9.634, -14.354, -8.937, -9.001, -15.016, -11.803]
Step 1642 7 visits [158.0, 890.0, 331.0, 23.0, 16.0, 2.0, 140.0, 76.0, 2.0, 4.0]  episode_count: 4253 q_vals: [-8.947, -8.779, -8.858, -9.405, -9.634, -14.354, -8.937, -8.986, -15.016, -11.803]
{"total_number_of_episodes": 4255, "number_of_timesteps": 73696, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1643 7 visits [158.0, 890.0, 331.0, 23.0, 16.0, 2.0, 140.0, 77.0, 2.0, 4.0]  episode_count: 4255 q_vals: [-8.947, -8.779, -8.858, -9.405, -9.634, -14.354, -8.937, -8.972, -15.016, -11.803]
Step 1644 7 visits [158.0, 890.0, 331.0, 23.0, 16.0, 2.0, 140.0, 78.0, 2.0, 4.0]  episode_count: 4260 q_vals: [-8.947, -8.779, -8.858, -9.405, -9.634, -14.354, -8.937, -8.958, -15.016, -11.803]
Step 1645 7 visits [158.0, 890.0, 331.0, 23.0, 16.0, 2.0, 140.0, 79.0, 2.0, 4.0]  episode_count: 4263 q_vals: [-8.947, -8.779, -8.858, -9.405, -9.634, -14.354, -8.937, -8.945, -15.016, -11.803]
{"total_number_of_episodes": 4268, "number_of_timesteps": 73840, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1646 7 visits [158.0, 890.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4268 q_vals: [-8.947, -8.779, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1647 1 visits [158.0, 891.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4272 q_vals: [-8.947, -8.778, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1648 1 visits [158.0, 892.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4276 q_vals: [-8.947, -8.777, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4279, "number_of_timesteps": 73955, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1649 1 visits [158.0, 893.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4279 q_vals: [-8.947, -8.776, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1650 1 visits [158.0, 894.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4284 q_vals: [-8.947, -8.775, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1651 1 visits [158.0, 895.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4285 q_vals: [-8.947, -8.774, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4289, "number_of_timesteps": 74070, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1652 1 visits [158.0, 896.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4289 q_vals: [-8.947, -8.773, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1653 1 visits [158.0, 897.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4292 q_vals: [-8.947, -8.772, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1654 1 visits [158.0, 898.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4295 q_vals: [-8.947, -8.771, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4299, "number_of_timesteps": 74201, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1655 1 visits [158.0, 899.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4299 q_vals: [-8.947, -8.77, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1656 1 visits [158.0, 900.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4303 q_vals: [-8.947, -8.761, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1657 1 visits [158.0, 901.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4307 q_vals: [-8.947, -8.76, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4311, "number_of_timesteps": 74336, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1658 1 visits [158.0, 902.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4311 q_vals: [-8.947, -8.759, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1659 1 visits [158.0, 903.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4313 q_vals: [-8.947, -8.758, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1660 1 visits [158.0, 904.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4318 q_vals: [-8.947, -8.757, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1661 1 visits [158.0, 905.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4319 q_vals: [-8.947, -8.756, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4324, "number_of_timesteps": 74503, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1662 1 visits [158.0, 906.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4324 q_vals: [-8.947, -8.746, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1663 1 visits [158.0, 907.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4327 q_vals: [-8.947, -8.745, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1664 1 visits [158.0, 908.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4331 q_vals: [-8.947, -8.757, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4335, "number_of_timesteps": 74638, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1665 1 visits [158.0, 909.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4335 q_vals: [-8.947, -8.756, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1666 1 visits [158.0, 910.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4337 q_vals: [-8.947, -8.756, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1667 1 visits [158.0, 911.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4343 q_vals: [-8.947, -8.768, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1668 1 visits [158.0, 912.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4344 q_vals: [-8.947, -8.767, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4349, "number_of_timesteps": 74811, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1669 1 visits [158.0, 913.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4349 q_vals: [-8.947, -8.766, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1670 1 visits [158.0, 914.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4352 q_vals: [-8.947, -8.765, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1671 1 visits [158.0, 915.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4355 q_vals: [-8.947, -8.764, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1672 1 visits [158.0, 916.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4358 q_vals: [-8.947, -8.763, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4362, "number_of_timesteps": 74978, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1673 1 visits [158.0, 917.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4362 q_vals: [-8.947, -8.775, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1674 1 visits [158.0, 918.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4364 q_vals: [-8.947, -8.774, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1675 1 visits [158.0, 919.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4367 q_vals: [-8.947, -8.773, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1676 1 visits [158.0, 920.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4369 q_vals: [-8.947, -8.772, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4374, "number_of_timesteps": 75158, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1677 1 visits [158.0, 921.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4374 q_vals: [-8.947, -8.771, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1678 1 visits [158.0, 922.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4374 q_vals: [-8.947, -8.77, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1679 1 visits [158.0, 923.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4379 q_vals: [-8.947, -8.769, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1680 1 visits [158.0, 924.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4382 q_vals: [-8.947, -8.781, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4385, "number_of_timesteps": 75313, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1681 1 visits [158.0, 925.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4385 q_vals: [-8.947, -8.793, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1682 1 visits [158.0, 926.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4390 q_vals: [-8.947, -8.783, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1683 1 visits [158.0, 927.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4391 q_vals: [-8.947, -8.783, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1684 1 visits [158.0, 928.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4393 q_vals: [-8.947, -8.782, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4397, "number_of_timesteps": 75483, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1685 1 visits [158.0, 929.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4397 q_vals: [-8.947, -8.772, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1686 1 visits [158.0, 930.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4399 q_vals: [-8.947, -8.763, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1687 1 visits [158.0, 931.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4401 q_vals: [-8.947, -8.753, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1688 1 visits [158.0, 932.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4405 q_vals: [-8.947, -8.752, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1689 1 visits [158.0, 933.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4405 q_vals: [-8.947, -8.751, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1690 1 visits [158.0, 934.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4406 q_vals: [-8.947, -8.751, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4409, "number_of_timesteps": 75706, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1691 1 visits [158.0, 935.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4409 q_vals: [-8.947, -8.75, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1692 1 visits [158.0, 936.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4411 q_vals: [-8.947, -8.749, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1693 1 visits [158.0, 937.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4412 q_vals: [-8.947, -8.748, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1694 1 visits [158.0, 938.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4414 q_vals: [-8.947, -8.76, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1695 1 visits [158.0, 939.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4417 q_vals: [-8.947, -8.771, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4419, "number_of_timesteps": 75956, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1696 1 visits [158.0, 940.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4419 q_vals: [-8.947, -8.783, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1697 1 visits [158.0, 941.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4423 q_vals: [-8.947, -8.782, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1698 1 visits [158.0, 942.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4425 q_vals: [-8.947, -8.781, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1699 1 visits [158.0, 943.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4426 q_vals: [-8.947, -8.78, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1700 1 visits [158.0, 944.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4428 q_vals: [-8.947, -8.779, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4431, "number_of_timesteps": 76187, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1701 1 visits [158.0, 945.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4431 q_vals: [-8.947, -8.778, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1702 1 visits [158.0, 946.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4433 q_vals: [-8.947, -8.777, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1703 1 visits [158.0, 947.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4435 q_vals: [-8.947, -8.776, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1704 1 visits [158.0, 948.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4436 q_vals: [-8.947, -8.775, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1705 1 visits [158.0, 949.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4438 q_vals: [-8.947, -8.775, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1706 1 visits [158.0, 950.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4440 q_vals: [-8.947, -8.786, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4441, "number_of_timesteps": 76386, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1707 1 visits [158.0, 951.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4441 q_vals: [-8.947, -8.785, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1708 1 visits [158.0, 952.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4443 q_vals: [-8.947, -8.784, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1709 1 visits [158.0, 953.0, 331.0, 23.0, 16.0, 2.0, 140.0, 80.0, 2.0, 4.0]  episode_count: 4446 q_vals: [-8.947, -8.796, -8.858, -9.405, -9.634, -14.354, -8.937, -9.08, -15.016, -11.803]
Step 1710 6 visits [158.0, 953.0, 331.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4446 q_vals: [-8.947, -8.796, -8.858, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1711 1 visits [158.0, 954.0, 331.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4450 q_vals: [-8.947, -8.795, -8.858, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4453, "number_of_timesteps": 76666, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1712 1 visits [158.0, 955.0, 331.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4453 q_vals: [-8.947, -8.794, -8.858, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1713 1 visits [158.0, 956.0, 331.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4456 q_vals: [-8.947, -8.793, -8.858, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1714 1 visits [158.0, 957.0, 331.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4457 q_vals: [-8.947, -8.792, -8.858, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1715 1 visits [158.0, 958.0, 331.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4457 q_vals: [-8.947, -8.791, -8.858, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4463, "number_of_timesteps": 76918, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1716 1 visits [158.0, 959.0, 331.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4463 q_vals: [-8.947, -8.782, -8.858, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1717 1 visits [158.0, 960.0, 331.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4464 q_vals: [-8.947, -8.781, -8.858, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1718 1 visits [158.0, 961.0, 331.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4466 q_vals: [-8.947, -8.78, -8.858, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1719 1 visits [158.0, 962.0, 331.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4467 q_vals: [-8.947, -8.792, -8.858, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1720 1 visits [158.0, 963.0, 331.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4470 q_vals: [-8.947, -8.803, -8.858, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1721 2 visits [158.0, 963.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4472 q_vals: [-8.947, -8.803, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4473, "number_of_timesteps": 77121, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1722 1 visits [158.0, 964.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4473 q_vals: [-8.947, -8.802, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1723 1 visits [158.0, 965.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4477 q_vals: [-8.947, -8.813, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1724 1 visits [158.0, 966.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4481 q_vals: [-8.947, -8.812, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1725 1 visits [158.0, 967.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4482 q_vals: [-8.947, -8.811, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4485, "number_of_timesteps": 77372, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1726 1 visits [158.0, 968.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4485 q_vals: [-8.947, -8.802, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1727 1 visits [158.0, 969.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4487 q_vals: [-8.947, -8.801, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1728 1 visits [158.0, 970.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4488 q_vals: [-8.947, -8.813, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1729 1 visits [158.0, 971.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4489 q_vals: [-8.947, -8.812, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1730 1 visits [158.0, 972.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4490 q_vals: [-8.947, -8.811, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1731 1 visits [158.0, 973.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4493 q_vals: [-8.947, -8.822, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4495, "number_of_timesteps": 77589, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1732 0 visits [159.0, 973.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4495 q_vals: [-8.891, -8.822, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1733 0 visits [160.0, 973.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4497 q_vals: [-8.885, -8.822, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1734 0 visits [161.0, 973.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4500 q_vals: [-8.879, -8.822, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1735 0 visits [162.0, 973.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4502 q_vals: [-8.873, -8.822, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1736 0 visits [163.0, 973.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4504 q_vals: [-8.867, -8.822, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4507, "number_of_timesteps": 77869, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1737 0 visits [164.0, 973.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4507 q_vals: [-8.933, -8.822, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1738 0 visits [165.0, 973.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4510 q_vals: [-8.999, -8.822, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1739 1 visits [165.0, 974.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4511 q_vals: [-8.999, -8.813, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1740 1 visits [165.0, 975.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4513 q_vals: [-8.999, -8.812, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1741 1 visits [165.0, 976.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4515 q_vals: [-8.999, -8.803, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4517, "number_of_timesteps": 78026, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1742 1 visits [165.0, 977.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4517 q_vals: [-8.999, -8.802, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1743 1 visits [165.0, 978.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4520 q_vals: [-8.999, -8.801, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1744 1 visits [165.0, 979.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4520 q_vals: [-8.999, -8.812, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1745 1 visits [165.0, 980.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4523 q_vals: [-8.999, -8.811, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1746 1 visits [165.0, 981.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4523 q_vals: [-8.999, -8.81, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1747 1 visits [165.0, 982.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4526 q_vals: [-8.999, -8.822, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4530, "number_of_timesteps": 78385, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1748 1 visits [165.0, 983.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4530 q_vals: [-8.999, -8.821, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1749 1 visits [165.0, 984.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4530 q_vals: [-8.999, -8.82, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1750 1 visits [165.0, 985.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4533 q_vals: [-8.999, -8.819, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1751 1 visits [165.0, 986.0, 332.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4534 q_vals: [-8.999, -8.83, -8.891, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1752 2 visits [165.0, 986.0, 333.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4534 q_vals: [-8.999, -8.83, -8.888, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1753 2 visits [165.0, 986.0, 334.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4536 q_vals: [-8.999, -8.83, -8.885, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4541, "number_of_timesteps": 78623, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1754 2 visits [165.0, 986.0, 335.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4541 q_vals: [-8.999, -8.83, -8.917, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1755 1 visits [165.0, 987.0, 335.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4543 q_vals: [-8.999, -8.829, -8.917, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1756 1 visits [165.0, 988.0, 335.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4544 q_vals: [-8.999, -8.828, -8.917, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1757 1 visits [165.0, 989.0, 335.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4548 q_vals: [-8.999, -8.839, -8.917, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1758 1 visits [165.0, 990.0, 335.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4550 q_vals: [-8.999, -8.838, -8.917, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4553, "number_of_timesteps": 78883, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1759 1 visits [165.0, 991.0, 335.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4553 q_vals: [-8.999, -8.849, -8.917, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1760 1 visits [165.0, 992.0, 335.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4556 q_vals: [-8.999, -8.848, -8.917, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1761 1 visits [165.0, 993.0, 335.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4558 q_vals: [-8.999, -8.847, -8.917, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1762 1 visits [165.0, 994.0, 335.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4561 q_vals: [-8.999, -8.846, -8.917, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4564, "number_of_timesteps": 79070, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1763 1 visits [165.0, 995.0, 335.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4564 q_vals: [-8.999, -8.857, -8.917, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1764 2 visits [165.0, 995.0, 336.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4566 q_vals: [-8.999, -8.857, -8.914, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1765 2 visits [165.0, 995.0, 337.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4569 q_vals: [-8.999, -8.857, -8.911, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1766 2 visits [165.0, 995.0, 338.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4570 q_vals: [-8.999, -8.857, -8.943, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4574, "number_of_timesteps": 79231, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1767 1 visits [165.0, 996.0, 338.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4574 q_vals: [-8.999, -8.856, -8.943, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1768 1 visits [165.0, 997.0, 338.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4577 q_vals: [-8.999, -8.852, -8.943, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1769 1 visits [165.0, 998.0, 338.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4580 q_vals: [-8.999, -8.851, -8.943, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
{"total_number_of_episodes": 4585, "number_of_timesteps": 79410, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1770 1 visits [165.0, 999.0, 338.0, 23.0, 16.0, 2.0, 141.0, 80.0, 2.0, 4.0]  episode_count: 4585 q_vals: [-8.999, -8.85, -8.943, -9.405, -9.634, -14.354, -9.014, -9.08, -15.016, -11.803]
Step 1771 1 visits [0.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 4587 q_vals: [0.0, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1772 0 visits [1.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 4589 q_vals: [0.0, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1773 2 visits [1.0, 1000.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 4591 q_vals: [0.0, -inf, -12.64, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1774 3 visits [1.0, 1000.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 4593 q_vals: [0.0, -inf, -12.64, -21.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
{"total_number_of_episodes": 4597, "number_of_timesteps": 79604, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
Step 1775 4 visits [1.0, 1000.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 4597 q_vals: [0.0, -inf, -12.64, -21.875, -6.361, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1776 5 visits [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 4599 q_vals: [0.0, -inf, -12.64, -21.875, -6.361, -8.75, 0.0, 0.0, 0.0, 0.0]
Step 1777 6 visits [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 4602 q_vals: [0.0, -inf, -12.64, -21.875, -6.361, -8.75, -8.75, 0.0, 0.0, 0.0]
[0.0, -inf, -12.64, -21.875, -6.361, -8.75, -8.75, -8.75, 0.0, 0.0]
{"total_number_of_episodes": 4607, "number_of_timesteps": 79773, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
Step 1779 8 visits [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 4607 q_vals: [0.0, -inf, -12.64, -21.875, -6.361, -8.75, -8.75, -8.75, -21.875, 0.0]
Step 1780 9 visits [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 4611 q_vals: [0.0, -inf, -12.64, -21.875, -6.361, -8.75, -8.75, -8.75, -21.875, 0.0]
Step 1781 0 visits [2.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 4611 q_vals: [-0.733, -inf, -12.64, -21.875, -6.361, -8.75, -8.75, -8.75, -21.875, 0.0]
{"total_number_of_episodes": 4617, "number_of_timesteps": 79926, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
Step 1782 9 visits [2.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0]  episode_count: 4617 q_vals: [-0.733, -inf, -12.64, -21.875, -6.361, -8.75, -8.75, -8.75, -21.875, -4.375]
Step 1783 0 visits [3.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0]  episode_count: 4620 q_vals: [-3.406, -inf, -12.64, -21.875, -6.361, -8.75, -8.75, -8.75, -21.875, -4.375]
Step 1784 0 visits [4.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0]  episode_count: 4622 q_vals: [-4.228, -inf, -12.64, -21.875, -6.361, -8.75, -8.75, -8.75, -21.875, -4.375]
Step 1785 9 visits [4.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0]  episode_count: 4624 q_vals: [-4.228, -inf, -12.64, -21.875, -6.361, -8.75, -8.75, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4627, "number_of_timesteps": 80073, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
Step 1786 0 visits [5.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0]  episode_count: 4627 q_vals: [-5.132, -inf, -12.64, -21.875, -6.361, -8.75, -8.75, -8.75, -21.875, -10.208]
Step 1787 0 visits [6.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0]  episode_count: 4630 q_vals: [-5.735, -inf, -12.64, -21.875, -6.361, -8.75, -8.75, -8.75, -21.875, -10.208]
Step 1788 4 visits [6.0, 1000.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0]  episode_count: 4634 q_vals: [-5.735, -inf, -12.64, -21.875, -10.063, -8.75, -8.75, -8.75, -21.875, -10.208]
Step 1789 0 visits [7.0, 1000.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0]  episode_count: 4636 q_vals: [-8.041, -inf, -12.64, -21.875, -10.063, -8.75, -8.75, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4640, "number_of_timesteps": 80278, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
Step 1790 7 visits [7.0, 1000.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0]  episode_count: 4640 q_vals: [-8.041, -inf, -12.64, -21.875, -10.063, -8.75, -8.75, -8.75, -21.875, -10.208]
Step 1791 6 visits [7.0, 1000.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0]  episode_count: 4642 q_vals: [-8.041, -inf, -12.64, -21.875, -10.063, -8.75, -4.375, -8.75, -21.875, -10.208]
Step 1792 6 visits [7.0, 1000.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 3.0]  episode_count: 4643 q_vals: [-8.041, -inf, -12.64, -21.875, -10.063, -8.75, -5.833, -8.75, -21.875, -10.208]
Step 1793 6 visits [7.0, 1000.0, 1.0, 1.0, 2.0, 1.0, 4.0, 2.0, 1.0, 3.0]  episode_count: 4646 q_vals: [-8.041, -inf, -12.64, -21.875, -10.063, -8.75, -6.562, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4651, "number_of_timesteps": 80463, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
Step 1794 6 visits [7.0, 1000.0, 1.0, 1.0, 2.0, 1.0, 5.0, 2.0, 1.0, 3.0]  episode_count: 4651 q_vals: [-8.041, -inf, -12.64, -21.875, -10.063, -8.75, -9.325, -8.75, -21.875, -10.208]
Step 1795 5 visits [7.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 2.0, 1.0, 3.0]  episode_count: 4651 q_vals: [-8.041, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1796 0 visits [8.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 2.0, 1.0, 3.0]  episode_count: 4654 q_vals: [-8.129, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1797 7 visits [8.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 3.0, 1.0, 3.0]  episode_count: 4657 q_vals: [-8.129, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1798 0 visits [9.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 3.0, 1.0, 3.0]  episode_count: 4658 q_vals: [-8.198, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4662, "number_of_timesteps": 80641, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
Step 1799 0 visits [10.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 3.0, 1.0, 3.0]  episode_count: 4662 q_vals: [-8.254, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1800 0 visits [11.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 3.0, 1.0, 3.0]  episode_count: 4665 q_vals: [-8.299, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1801 7 visits [11.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4667 q_vals: [-8.299, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1802 0 visits [12.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4670 q_vals: [-7.607, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4672, "number_of_timesteps": 80819, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
Step 1803 0 visits [13.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4672 q_vals: [-7.695, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1804 0 visits [14.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4676 q_vals: [-7.77, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1805 0 visits [15.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4678 q_vals: [-7.836, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1806 0 visits [16.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4681 q_vals: [-7.346, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4683, "number_of_timesteps": 81005, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
[-7.429, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1808 0 visits [18.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4685 q_vals: [-7.502, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1809 0 visits [19.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4687 q_vals: [-7.568, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1810 0 visits [20.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4689 q_vals: [-7.627, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1811 0 visits [21.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4689 q_vals: [-7.68, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4693, "number_of_timesteps": 81172, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1812 0 visits [22.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4693 q_vals: [-7.729, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1813 0 visits [23.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4696 q_vals: [-7.773, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1814 0 visits [24.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4698 q_vals: [-7.449, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1815 0 visits [25.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4700 q_vals: [-7.501, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4704, "number_of_timesteps": 81423, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1816 0 visits [26.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4704 q_vals: [-8.054, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1817 0 visits [27.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4708 q_vals: [-8.08, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1818 0 visits [28.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4710 q_vals: [-8.104, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1819 0 visits [29.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4713 q_vals: [-8.126, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4719, "number_of_timesteps": 81638, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1820 0 visits [30.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 3.0]  episode_count: 4719 q_vals: [-8.147, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1821 7 visits [30.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 5.0, 1.0, 3.0]  episode_count: 4720 q_vals: [-8.147, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1822 0 visits [31.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 5.0, 1.0, 3.0]  episode_count: 4724 q_vals: [-8.166, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1823 0 visits [32.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 5.0, 1.0, 3.0]  episode_count: 4728 q_vals: [-8.185, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4731, "number_of_timesteps": 81787, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1824 0 visits [33.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 5.0, 1.0, 3.0]  episode_count: 4731 q_vals: [-8.202, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1825 0 visits [34.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 5.0, 1.0, 3.0]  episode_count: 4733 q_vals: [-8.218, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1826 7 visits [34.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 6.0, 1.0, 3.0]  episode_count: 4737 q_vals: [-8.218, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1827 0 visits [35.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 6.0, 1.0, 3.0]  episode_count: 4738 q_vals: [-8.233, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4742, "number_of_timesteps": 81954, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1828 0 visits [36.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 6.0, 1.0, 3.0]  episode_count: 4742 q_vals: [-8.248, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1829 0 visits [37.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 6.0, 1.0, 3.0]  episode_count: 4743 q_vals: [-8.261, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1830 7 visits [37.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4747 q_vals: [-8.261, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4753, "number_of_timesteps": 82126, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1831 0 visits [38.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4753 q_vals: [-8.274, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1832 0 visits [39.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4755 q_vals: [-8.286, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1833 0 visits [40.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4758 q_vals: [-8.298, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1834 0 visits [41.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4762 q_vals: [-8.095, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4763, "number_of_timesteps": 82251, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1835 0 visits [42.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4763 q_vals: [-8.111, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1836 0 visits [43.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4765 q_vals: [-8.126, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1837 0 visits [44.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4770 q_vals: [-7.941, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
[-7.765, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4773, "number_of_timesteps": 82402, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1839 0 visits [46.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4773 q_vals: [-7.786, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1840 0 visits [47.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4778 q_vals: [-7.807, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1841 0 visits [48.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4780 q_vals: [-7.826, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1842 0 visits [49.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4780 q_vals: [-8.113, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4783, "number_of_timesteps": 82561, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1843 0 visits [50.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4783 q_vals: [-8.126, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1844 0 visits [51.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4787 q_vals: [-8.138, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1845 0 visits [52.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4787 q_vals: [-8.15, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1846 0 visits [53.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4791 q_vals: [-8.161, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4797, "number_of_timesteps": 82849, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1847 0 visits [54.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4797 q_vals: [-8.172, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1848 0 visits [55.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4797 q_vals: [-8.182, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1849 0 visits [56.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4801 q_vals: [-8.036, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1850 0 visits [57.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4804 q_vals: [-8.049, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1851 0 visits [58.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4805 q_vals: [-8.061, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4808, "number_of_timesteps": 83010, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1852 0 visits [59.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4808 q_vals: [-8.073, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1853 0 visits [60.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4813 q_vals: [-8.084, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1854 0 visits [61.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4813 q_vals: [-8.095, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4818, "number_of_timesteps": 83175, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1855 0 visits [62.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4818 q_vals: [-8.105, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1856 0 visits [63.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4821 q_vals: [-7.977, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1857 0 visits [64.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4824 q_vals: [-7.852, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1858 0 visits [65.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4827 q_vals: [-7.866, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4829, "number_of_timesteps": 83340, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1859 0 visits [66.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4829 q_vals: [-7.879, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1860 0 visits [67.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4832 q_vals: [-7.887, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1861 0 visits [68.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4837 q_vals: [-7.9, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4840, "number_of_timesteps": 83505, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1862 0 visits [69.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4840 q_vals: [-7.912, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1863 0 visits [70.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4841 q_vals: [-7.924, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1864 0 visits [71.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4844 q_vals: [-7.935, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1865 0 visits [72.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4846 q_vals: [-8.129, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4851, "number_of_timesteps": 83681, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1866 0 visits [73.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4851 q_vals: [-8.018, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1867 0 visits [74.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4852 q_vals: [-8.028, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
[-7.921, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1869 0 visits [76.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4857 q_vals: [-7.816, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1870 0 visits [77.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4859 q_vals: [-7.715, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4861, "number_of_timesteps": 83836, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1871 0 visits [78.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4861 q_vals: [-7.728, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1872 0 visits [79.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4863 q_vals: [-7.741, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1873 0 visits [80.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4863 q_vals: [-7.754, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1874 0 visits [81.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4866 q_vals: [-7.658, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1875 0 visits [82.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4868 q_vals: [-7.671, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1876 0 visits [83.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4868 q_vals: [-7.579, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4871, "number_of_timesteps": 84076, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1877 0 visits [84.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4871 q_vals: [-7.593, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1878 0 visits [85.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4873 q_vals: [-7.503, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1879 0 visits [86.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4876 q_vals: [-7.518, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1880 0 visits [87.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4877 q_vals: [-7.532, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1881 0 visits [88.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4879 q_vals: [-7.546, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4883, "number_of_timesteps": 84338, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1882 0 visits [89.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4883 q_vals: [-7.707, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1883 0 visits [90.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4886 q_vals: [-7.864, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1884 0 visits [91.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4886 q_vals: [-7.778, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1885 0 visits [92.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4891 q_vals: [-7.789, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4894, "number_of_timesteps": 84564, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1886 0 visits [93.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4894 q_vals: [-7.94, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1887 0 visits [94.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4895 q_vals: [-7.949, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1888 0 visits [95.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4895 q_vals: [-7.957, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1889 0 visits [96.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4898 q_vals: [-7.965, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1890 0 visits [97.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4901 q_vals: [-7.973, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1891 0 visits [98.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4903 q_vals: [-7.892, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4905, "number_of_timesteps": 84760, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1892 0 visits [99.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4905 q_vals: [-7.812, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1893 0 visits [100.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4907 q_vals: [-7.822, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1894 0 visits [101.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4909 q_vals: [-7.802, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1895 0 visits [102.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4909 q_vals: [-7.812, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1896 0 visits [103.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4912 q_vals: [-7.819, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4915, "number_of_timesteps": 85005, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1897 0 visits [104.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4915 q_vals: [-7.828, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1898 0 visits [105.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4916 q_vals: [-7.837, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1899 0 visits [106.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4918 q_vals: [-7.763, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1900 0 visits [107.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4919 q_vals: [-7.772, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1901 0 visits [108.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4921 q_vals: [-7.781, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1902 0 visits [109.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4922 q_vals: [-7.71, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1903 0 visits [110.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4924 q_vals: [-7.681, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4925, "number_of_timesteps": 85272, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1904 0 visits [111.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4925 q_vals: [-7.691, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1905 0 visits [112.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4928 q_vals: [-7.7, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1906 0 visits [113.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4929 q_vals: [-7.709, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1907 0 visits [114.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4930 q_vals: [-7.719, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1908 0 visits [115.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4930 q_vals: [-7.728, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1909 0 visits [116.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4930 q_vals: [-7.661, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1910 0 visits [117.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4933 q_vals: [-7.782, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4937, "number_of_timesteps": 85685, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1911 0 visits [118.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4937 q_vals: [-7.716, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1912 0 visits [119.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4938 q_vals: [-7.835, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1913 0 visits [120.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4940 q_vals: [-7.843, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1914 0 visits [121.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4943 q_vals: [-7.778, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1915 0 visits [122.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4944 q_vals: [-7.714, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4947, "number_of_timesteps": 85868, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1916 0 visits [123.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4947 q_vals: [-7.723, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1917 0 visits [124.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4951 q_vals: [-7.661, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1918 0 visits [125.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4953 q_vals: [-7.669, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1919 0 visits [126.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4956 q_vals: [-7.678, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4957, "number_of_timesteps": 86102, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1920 0 visits [127.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4957 q_vals: [-7.686, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1921 0 visits [128.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4958 q_vals: [-7.695, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1922 0 visits [129.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4962 q_vals: [-7.703, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1923 0 visits [130.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4964 q_vals: [-7.711, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1924 0 visits [131.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4965 q_vals: [-7.719, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4967, "number_of_timesteps": 86327, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1925 0 visits [132.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4967 q_vals: [-7.727, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1926 0 visits [133.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4970 q_vals: [-7.669, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1927 0 visits [134.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4972 q_vals: [-7.677, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1928 0 visits [135.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4972 q_vals: [-7.62, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1929 0 visits [136.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4974 q_vals: [-7.628, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4978, "number_of_timesteps": 86559, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1930 0 visits [137.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4978 q_vals: [-7.572, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1931 0 visits [138.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4981 q_vals: [-7.581, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1932 0 visits [139.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4981 q_vals: [-7.589, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1933 0 visits [140.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4984 q_vals: [-7.598, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 4990, "number_of_timesteps": 86793, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 1934 0 visits [141.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4990 q_vals: [-7.544, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1935 0 visits [142.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4990 q_vals: [-7.491, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1936 0 visits [143.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4991 q_vals: [-7.499, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1937 0 visits [144.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4992 q_vals: [-7.508, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1938 0 visits [145.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4994 q_vals: [-7.517, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1939 0 visits [146.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4998 q_vals: [-7.525, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1940 0 visits [147.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 4999 q_vals: [-7.533, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 5002, "number_of_timesteps": 87069, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1941 0 visits [148.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5002 q_vals: [-7.542, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1942 0 visits [149.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5003 q_vals: [-7.518, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1943 0 visits [150.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5004 q_vals: [-7.526, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1944 0 visits [151.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5006 q_vals: [-7.534, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1945 0 visits [152.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5007 q_vals: [-7.542, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1946 0 visits [153.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5010 q_vals: [-7.55, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 5014, "number_of_timesteps": 87334, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1947 0 visits [154.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5014 q_vals: [-7.558, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1948 0 visits [155.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5014 q_vals: [-7.566, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1949 0 visits [156.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5016 q_vals: [-7.573, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1950 0 visits [157.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5019 q_vals: [-7.581, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1951 0 visits [158.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5020 q_vals: [-7.588, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1952 0 visits [159.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5021 q_vals: [-7.596, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1953 0 visits [160.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5021 q_vals: [-7.603, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 5028, "number_of_timesteps": 87666, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1954 0 visits [161.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5028 q_vals: [-7.61, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1955 0 visits [162.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5028 q_vals: [-7.617, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1956 0 visits [163.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5029 q_vals: [-7.624, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1957 0 visits [164.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5030 q_vals: [-7.631, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1958 0 visits [165.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5032 q_vals: [-7.638, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1959 0 visits [166.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5035 q_vals: [-7.644, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1960 0 visits [167.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5037 q_vals: [-7.651, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1961 0 visits [168.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5037 q_vals: [-7.657, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 5041, "number_of_timesteps": 87978, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1962 0 visits [169.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5041 q_vals: [-7.664, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1963 0 visits [170.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5043 q_vals: [-7.67, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1964 0 visits [171.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5047 q_vals: [-7.677, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1965 0 visits [172.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5049 q_vals: [-7.632, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1966 0 visits [173.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5050 q_vals: [-7.714, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 5053, "number_of_timesteps": 88192, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1967 0 visits [174.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5053 q_vals: [-7.796, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1968 0 visits [175.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5057 q_vals: [-7.856, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1969 0 visits [176.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5057 q_vals: [-7.811, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1970 0 visits [177.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5058 q_vals: [-7.816, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1971 0 visits [178.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5061 q_vals: [-7.822, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 5063, "number_of_timesteps": 88443, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1972 0 visits [179.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5063 q_vals: [-7.827, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1973 0 visits [180.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5064 q_vals: [-7.832, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1974 0 visits [181.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5064 q_vals: [-7.837, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1975 0 visits [182.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5065 q_vals: [-7.842, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1976 0 visits [183.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5070 q_vals: [-7.847, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1977 0 visits [184.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5070 q_vals: [-7.852, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 5074, "number_of_timesteps": 88736, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1978 0 visits [185.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5074 q_vals: [-7.857, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1979 0 visits [186.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5077 q_vals: [-7.861, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1980 0 visits [187.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5078 q_vals: [-7.819, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1981 0 visits [188.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5079 q_vals: [-7.824, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1982 0 visits [189.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5081 q_vals: [-7.829, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1983 0 visits [190.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5082 q_vals: [-7.834, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 5086, "number_of_timesteps": 88988, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1984 0 visits [191.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5086 q_vals: [-7.833, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1985 0 visits [192.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5087 q_vals: [-7.792, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1986 0 visits [193.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5088 q_vals: [-7.797, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1987 0 visits [194.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5093 q_vals: [-7.788, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 5096, "number_of_timesteps": 89257, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1988 0 visits [195.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5096 q_vals: [-7.791, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1989 0 visits [196.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5098 q_vals: [-7.795, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1990 0 visits [197.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5100 q_vals: [-7.756, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1991 0 visits [198.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5103 q_vals: [-7.717, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1992 0 visits [199.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5105 q_vals: [-7.788, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 5106, "number_of_timesteps": 89410, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1993 0 visits [200.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5106 q_vals: [-7.858, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1994 0 visits [201.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5106 q_vals: [-7.863, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1995 0 visits [202.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5112 q_vals: [-7.867, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1996 0 visits [203.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5114 q_vals: [-7.828, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1997 0 visits [204.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5114 q_vals: [-7.833, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 5116, "number_of_timesteps": 89643, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1998 0 visits [205.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5116 q_vals: [-7.837, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 1999 0 visits [206.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5117 q_vals: [-7.842, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 2000 0 visits [207.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5118 q_vals: [-7.846, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 2001 0 visits [208.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5119 q_vals: [-7.808, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 2002 0 visits [209.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5121 q_vals: [-7.813, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 2003 0 visits [210.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5123 q_vals: [-7.817, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 2004 0 visits [211.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5125 q_vals: [-7.822, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
{"total_number_of_episodes": 5127, "number_of_timesteps": 89936, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 2005 0 visits [212.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5127 q_vals: [-7.888, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 2006 0 visits [213.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5128 q_vals: [-7.892, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 2007 0 visits [214.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5130 q_vals: [-7.896, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 2008 0 visits [215.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5130 q_vals: [-7.9, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 2009 0 visits [216.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5131 q_vals: [-7.965, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 2010 0 visits [217.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 7.0, 1.0, 3.0]  episode_count: 5135 q_vals: [-8.029, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -8.75, -21.875, -10.208]
Step 2011 7 visits [217.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5135 q_vals: [-8.029, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5138, "number_of_timesteps": 90283, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2012 0 visits [218.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5138 q_vals: [-8.032, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2013 0 visits [219.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5140 q_vals: [-8.036, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2014 0 visits [220.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5141 q_vals: [-7.999, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2015 0 visits [221.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5143 q_vals: [-7.963, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2016 0 visits [222.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5146 q_vals: [-7.927, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2017 0 visits [223.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5146 q_vals: [-7.931, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5149, "number_of_timesteps": 90533, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2018 0 visits [224.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5149 q_vals: [-7.934, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2019 0 visits [225.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5153 q_vals: [-7.899, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2020 0 visits [226.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5154 q_vals: [-7.903, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2021 0 visits [227.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5157 q_vals: [-7.868, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2022 0 visits [228.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5157 q_vals: [-7.929, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5159, "number_of_timesteps": 90779, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2023 0 visits [229.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5159 q_vals: [-7.99, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2024 0 visits [230.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5161 q_vals: [-7.994, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2025 0 visits [231.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5163 q_vals: [-7.997, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2026 0 visits [232.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5164 q_vals: [-8.0, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2027 0 visits [233.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5168 q_vals: [-8.003, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5169, "number_of_timesteps": 90995, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2028 0 visits [234.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5169 q_vals: [-7.969, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2029 0 visits [235.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5172 q_vals: [-7.972, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2030 0 visits [236.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5175 q_vals: [-8.031, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2031 0 visits [237.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5178 q_vals: [-8.034, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5179, "number_of_timesteps": 91232, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2032 0 visits [238.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5179 q_vals: [-8.037, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2033 0 visits [239.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5182 q_vals: [-8.04, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2034 0 visits [240.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5184 q_vals: [-8.043, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2035 0 visits [241.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5187 q_vals: [-8.046, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5190, "number_of_timesteps": 91451, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 2036 0 visits [242.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5190 q_vals: [-8.049, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2037 0 visits [243.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5192 q_vals: [-8.052, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2038 0 visits [244.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5194 q_vals: [-8.109, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2039 0 visits [245.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5197 q_vals: [-8.111, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2040 0 visits [246.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5198 q_vals: [-8.114, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2041 0 visits [247.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5199 q_vals: [-8.117, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5200, "number_of_timesteps": 91624, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 2042 0 visits [248.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5200 q_vals: [-8.119, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2043 0 visits [249.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5203 q_vals: [-8.122, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2044 0 visits [250.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5204 q_vals: [-8.124, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2045 0 visits [251.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5207 q_vals: [-8.092, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2046 0 visits [252.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5209 q_vals: [-8.06, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5213, "number_of_timesteps": 91956, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 2047 0 visits [253.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5213 q_vals: [-8.114, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2048 0 visits [254.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5214 q_vals: [-8.168, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2049 0 visits [255.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5217 q_vals: [-8.171, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2050 0 visits [256.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5222 q_vals: [-8.173, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5224, "number_of_timesteps": 92117, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 2051 0 visits [257.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5224 q_vals: [-8.141, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2052 0 visits [258.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5226 q_vals: [-8.144, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2053 0 visits [259.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5229 q_vals: [-8.146, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2054 0 visits [260.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5232 q_vals: [-8.148, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5235, "number_of_timesteps": 92316, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 2055 0 visits [261.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5235 q_vals: [-8.15, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2056 0 visits [262.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5238 q_vals: [-8.153, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2057 0 visits [263.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5243 q_vals: [-8.155, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5245, "number_of_timesteps": 92439, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 2058 0 visits [264.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5245 q_vals: [-8.157, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2059 0 visits [265.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5248 q_vals: [-8.16, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2060 0 visits [266.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5254 q_vals: [-8.162, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5255, "number_of_timesteps": 92562, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2061 0 visits [267.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5255 q_vals: [-8.164, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2062 0 visits [268.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5257 q_vals: [-8.215, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2063 0 visits [269.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5260 q_vals: [-8.185, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5265, "number_of_timesteps": 92722, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2064 0 visits [270.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5265 q_vals: [-8.187, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2065 0 visits [271.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5266 q_vals: [-8.189, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2066 0 visits [272.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5269 q_vals: [-8.191, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2067 0 visits [273.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5274 q_vals: [-8.193, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5275, "number_of_timesteps": 92865, "per_episode_reward": 12.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2068 0 visits [274.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5275 q_vals: [-8.195, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2069 0 visits [275.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5280 q_vals: [-8.245, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2070 0 visits [276.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5283 q_vals: [-8.246, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5286, "number_of_timesteps": 93017, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2071 0 visits [277.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5286 q_vals: [-8.217, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2072 0 visits [278.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5292 q_vals: [-8.219, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2073 0 visits [279.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5293 q_vals: [-8.221, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5298, "number_of_timesteps": 93155, "per_episode_reward": 12.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2074 0 visits [280.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5298 q_vals: [-8.269, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2075 0 visits [281.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5303 q_vals: [-8.271, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2076 0 visits [282.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5305 q_vals: [-8.273, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5308, "number_of_timesteps": 93282, "per_episode_reward": 12.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2077 0 visits [283.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5308 q_vals: [-8.274, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2078 0 visits [284.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5312 q_vals: [-8.276, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2079 0 visits [285.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5315 q_vals: [-8.278, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5320, "number_of_timesteps": 93440, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 2080 0 visits [286.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5320 q_vals: [-8.279, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2081 0 visits [287.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5324 q_vals: [-8.281, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2082 0 visits [288.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5326 q_vals: [-8.252, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5330, "number_of_timesteps": 93554, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2083 0 visits [289.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5330 q_vals: [-8.254, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2084 0 visits [290.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5334 q_vals: [-8.256, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2085 0 visits [291.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5336 q_vals: [-8.257, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5341, "number_of_timesteps": 93702, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2086 0 visits [292.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5341 q_vals: [-8.259, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2087 0 visits [293.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5343 q_vals: [-8.231, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2088 0 visits [294.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5347 q_vals: [-8.203, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5351, "number_of_timesteps": 93835, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2089 0 visits [295.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5351 q_vals: [-8.205, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2090 0 visits [296.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5354 q_vals: [-8.207, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2091 0 visits [297.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5356 q_vals: [-8.208, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2092 0 visits [298.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5359 q_vals: [-8.181, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5362, "number_of_timesteps": 93981, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2093 0 visits [299.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5362 q_vals: [-8.183, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2094 0 visits [300.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5364 q_vals: [-8.185, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2095 0 visits [301.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5367 q_vals: [-8.187, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2096 0 visits [302.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5369 q_vals: [-8.159, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2097 0 visits [303.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5371 q_vals: [-8.161, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5375, "number_of_timesteps": 94207, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
Step 2098 0 visits [304.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5375 q_vals: [-8.163, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2099 0 visits [305.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5378 q_vals: [-8.165, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2100 0 visits [306.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5380 q_vals: [-8.21, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5385, "number_of_timesteps": 94362, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2101 0 visits [307.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5385 q_vals: [-8.212, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2102 0 visits [308.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5388 q_vals: [-8.214, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2103 0 visits [309.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5389 q_vals: [-8.215, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2104 0 visits [310.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5391 q_vals: [-8.217, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2105 0 visits [311.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5394 q_vals: [-8.219, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5400, "number_of_timesteps": 94599, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
Step 2106 0 visits [312.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5400 q_vals: [-8.22, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2107 0 visits [313.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5401 q_vals: [-8.222, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2108 0 visits [314.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5402 q_vals: [-8.196, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2109 0 visits [315.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5406 q_vals: [-8.198, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2110 0 visits [316.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5407 q_vals: [-8.199, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5410, "number_of_timesteps": 94762, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
Step 2111 0 visits [317.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5410 q_vals: [-8.174, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2112 0 visits [318.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5413 q_vals: [-8.217, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2113 0 visits [319.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5416 q_vals: [-8.259, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2114 0 visits [320.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5418 q_vals: [-8.261, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5420, "number_of_timesteps": 94946, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 2115 0 visits [321.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5420 q_vals: [-8.263, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2116 0 visits [322.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5422 q_vals: [-8.237, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2117 0 visits [323.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5426 q_vals: [-8.238, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2118 0 visits [324.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5428 q_vals: [-8.213, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5430, "number_of_timesteps": 95126, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2119 0 visits [325.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5430 q_vals: [-8.215, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2120 0 visits [326.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5433 q_vals: [-8.216, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2121 0 visits [327.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5435 q_vals: [-8.191, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2122 0 visits [328.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5439 q_vals: [-8.166, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5443, "number_of_timesteps": 95346, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2123 0 visits [329.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5443 q_vals: [-8.168, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2124 0 visits [330.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5446 q_vals: [-8.17, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2125 0 visits [331.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5447 q_vals: [-8.172, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2126 0 visits [332.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5450 q_vals: [-8.173, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5454, "number_of_timesteps": 95503, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2127 0 visits [333.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5454 q_vals: [-8.175, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2128 0 visits [334.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5454 q_vals: [-8.151, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2129 0 visits [335.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5455 q_vals: [-8.126, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2130 0 visits [336.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5457 q_vals: [-8.128, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2131 0 visits [337.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5460 q_vals: [-8.13, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2132 0 visits [338.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5462 q_vals: [-8.132, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2133 0 visits [339.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5462 q_vals: [-8.172, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5466, "number_of_timesteps": 95778, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2134 0 visits [340.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5466 q_vals: [-8.213, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2135 0 visits [341.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5468 q_vals: [-8.214, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2136 0 visits [342.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5470 q_vals: [-8.216, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2137 0 visits [343.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5475 q_vals: [-8.217, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5477, "number_of_timesteps": 96019, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2138 0 visits [344.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5477 q_vals: [-8.219, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
[345.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5479 q_vals: [-8.258, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2140 0 visits [346.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5481 q_vals: [-8.26, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2141 0 visits [347.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5483 q_vals: [-8.261, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2142 0 visits [348.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5485 q_vals: [-8.263, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5488, "number_of_timesteps": 96220, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2143 0 visits [349.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5488 q_vals: [-8.239, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2144 0 visits [350.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5492 q_vals: [-8.24, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2145 0 visits [351.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5494 q_vals: [-8.217, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2146 0 visits [352.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5497 q_vals: [-8.218, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5500, "number_of_timesteps": 96431, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2147 0 visits [353.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5500 q_vals: [-8.22, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2148 0 visits [354.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5503 q_vals: [-8.221, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2149 0 visits [355.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5503 q_vals: [-8.223, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2150 0 visits [356.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5504 q_vals: [-8.224, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5512, "number_of_timesteps": 96647, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2151 0 visits [357.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5512 q_vals: [-8.226, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2152 0 visits [358.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5513 q_vals: [-8.227, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2153 0 visits [359.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5516 q_vals: [-8.229, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5523, "number_of_timesteps": 96777, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2154 0 visits [360.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5523 q_vals: [-8.23, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2155 0 visits [361.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5524 q_vals: [-8.207, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2156 0 visits [362.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5525 q_vals: [-8.185, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2157 0 visits [363.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5530 q_vals: [-8.223, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2158 0 visits [364.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5532 q_vals: [-8.224, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5535, "number_of_timesteps": 96933, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2159 0 visits [365.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5535 q_vals: [-8.225, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2160 0 visits [366.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5537 q_vals: [-8.203, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2161 0 visits [367.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5538 q_vals: [-8.204, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2162 0 visits [368.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5543 q_vals: [-8.206, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2163 0 visits [369.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5543 q_vals: [-8.184, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5545, "number_of_timesteps": 97108, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2164 0 visits [370.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5545 q_vals: [-8.185, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2165 0 visits [371.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5548 q_vals: [-8.187, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2166 0 visits [372.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5550 q_vals: [-8.188, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2167 0 visits [373.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5552 q_vals: [-8.182, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5555, "number_of_timesteps": 97335, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2168 0 visits [374.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5555 q_vals: [-8.219, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
[-8.22, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2170 0 visits [376.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5560 q_vals: [-8.222, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2171 0 visits [377.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5561 q_vals: [-8.223, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2172 0 visits [378.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5561 q_vals: [-8.259, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2173 0 visits [379.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5562 q_vals: [-8.26, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5565, "number_of_timesteps": 97523, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2174 0 visits [380.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5565 q_vals: [-8.296, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2175 0 visits [381.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5567 q_vals: [-8.297, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2176 0 visits [382.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5568 q_vals: [-8.276, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2177 0 visits [383.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5571 q_vals: [-8.277, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2178 0 visits [384.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5573 q_vals: [-8.255, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2179 0 visits [385.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5574 q_vals: [-8.257, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5576, "number_of_timesteps": 97808, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2180 0 visits [386.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5576 q_vals: [-8.258, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2181 0 visits [387.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5580 q_vals: [-8.247, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2182 0 visits [388.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5583 q_vals: [-8.248, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5586, "number_of_timesteps": 98039, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2183 0 visits [389.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5586 q_vals: [-8.25, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2184 0 visits [390.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5588 q_vals: [-8.251, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2185 0 visits [391.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5589 q_vals: [-8.252, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2186 0 visits [392.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5591 q_vals: [-8.287, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2187 0 visits [393.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5591 q_vals: [-8.288, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2188 0 visits [394.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5595 q_vals: [-8.289, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2189 0 visits [395.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5595 q_vals: [-8.291, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5599, "number_of_timesteps": 98341, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2190 0 visits [396.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5599 q_vals: [-8.292, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2191 0 visits [397.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5599 q_vals: [-8.293, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2192 0 visits [398.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5600 q_vals: [-8.294, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2193 0 visits [399.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5603 q_vals: [-8.273, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2194 0 visits [400.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5607 q_vals: [-8.273, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2195 0 visits [401.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5608 q_vals: [-8.252, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5610, "number_of_timesteps": 98576, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 2196 0 visits [402.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5610 q_vals: [-8.254, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2197 0 visits [403.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5613 q_vals: [-8.253, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2198 0 visits [404.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5615 q_vals: [-8.255, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2199 0 visits [405.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5617 q_vals: [-8.256, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5622, "number_of_timesteps": 98804, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2200 0 visits [406.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5622 q_vals: [-8.244, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2201 0 visits [407.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5623 q_vals: [-8.245, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2202 0 visits [408.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5625 q_vals: [-8.246, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2203 0 visits [409.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5630 q_vals: [-8.226, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5633, "number_of_timesteps": 98998, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2204 0 visits [410.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5633 q_vals: [-8.206, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2205 0 visits [411.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5634 q_vals: [-8.207, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2206 0 visits [412.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5636 q_vals: [-8.187, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2207 0 visits [413.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5639 q_vals: [-8.221, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2208 0 visits [414.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5640 q_vals: [-8.201, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5646, "number_of_timesteps": 99227, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
Step 2209 0 visits [415.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5646 q_vals: [-8.202, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2210 0 visits [416.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5647 q_vals: [-8.203, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2211 0 visits [417.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5650 q_vals: [-8.205, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2212 0 visits [418.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5652 q_vals: [-8.185, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2213 0 visits [419.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5654 q_vals: [-8.186, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5658, "number_of_timesteps": 99429, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 2214 0 visits [420.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5658 q_vals: [-8.188, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2215 0 visits [421.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5658 q_vals: [-8.168, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2216 0 visits [422.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5661 q_vals: [-8.201, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2217 0 visits [423.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5662 q_vals: [-8.202, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2218 0 visits [424.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5663 q_vals: [-8.203, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2219 0 visits [425.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5666 q_vals: [-8.205, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5669, "number_of_timesteps": 99680, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2220 0 visits [426.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5669 q_vals: [-8.206, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2221 0 visits [427.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5672 q_vals: [-8.187, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2222 0 visits [428.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5673 q_vals: [-8.188, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2223 0 visits [429.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5676 q_vals: [-8.169, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2224 0 visits [430.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5676 q_vals: [-8.17, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2225 0 visits [431.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5678 q_vals: [-8.151, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2226 0 visits [432.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5678 q_vals: [-8.153, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5679, "number_of_timesteps": 99861, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
Step 2227 0 visits [433.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5679 q_vals: [-8.154, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2228 0 visits [434.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5682 q_vals: [-8.155, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2229 0 visits [435.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5684 q_vals: [-8.157, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2230 0 visits [436.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5686 q_vals: [-8.158, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5690, "number_of_timesteps": 100214, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2231 0 visits [437.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5690 q_vals: [-8.14, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2232 0 visits [438.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5690 q_vals: [-8.121, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2233 0 visits [439.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5692 q_vals: [-8.102, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2234 0 visits [440.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5696 q_vals: [-8.104, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2235 0 visits [441.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5699 q_vals: [-8.086, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5701, "number_of_timesteps": 100410, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2236 0 visits [442.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5701 q_vals: [-8.087, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2237 0 visits [443.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5703 q_vals: [-8.118, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2238 0 visits [444.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5705 q_vals: [-8.12, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2239 0 visits [445.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5707 q_vals: [-8.121, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2240 0 visits [446.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5709 q_vals: [-8.103, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2241 0 visits [447.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5710 q_vals: [-8.085, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5714, "number_of_timesteps": 100676, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 2242 0 visits [448.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5714 q_vals: [-8.083, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2243 0 visits [449.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5715 q_vals: [-8.085, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2244 0 visits [450.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5716 q_vals: [-8.086, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2245 0 visits [451.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5718 q_vals: [-8.068, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2246 0 visits [452.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5720 q_vals: [-8.099, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2247 0 visits [453.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5720 q_vals: [-8.1, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2248 0 visits [454.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5721 q_vals: [-8.131, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2249 0 visits [455.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5722 q_vals: [-8.161, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5724, "number_of_timesteps": 100892, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 2250 0 visits [456.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5724 q_vals: [-8.162, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2251 0 visits [457.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5729 q_vals: [-8.163, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2252 0 visits [458.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5729 q_vals: [-8.165, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2253 0 visits [459.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5729 q_vals: [-8.166, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2254 0 visits [460.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5730 q_vals: [-8.167, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5734, "number_of_timesteps": 101242, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 2255 0 visits [461.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5734 q_vals: [-8.168, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2256 0 visits [462.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5736 q_vals: [-8.198, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2257 0 visits [463.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5740 q_vals: [-8.199, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2258 0 visits [464.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5742 q_vals: [-8.201, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5745, "number_of_timesteps": 101456, "per_episode_reward": 13.05, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.09999999999999964},
Step 2259 0 visits [465.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5745 q_vals: [-8.202, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2260 0 visits [466.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5749 q_vals: [-8.203, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2261 0 visits [467.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5752 q_vals: [-8.204, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5756, "number_of_timesteps": 101629, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2262 0 visits [468.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5756 q_vals: [-8.187, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2263 0 visits [469.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5760 q_vals: [-8.188, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2264 0 visits [470.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5761 q_vals: [-8.189, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5766, "number_of_timesteps": 101747, "per_episode_reward": 13.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 2265 0 visits [471.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5766 q_vals: [-8.19, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2266 0 visits [472.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5769 q_vals: [-8.173, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2267 0 visits [473.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5771 q_vals: [-8.174, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5778, "number_of_timesteps": 101903, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 2268 0 visits [474.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5778 q_vals: [-8.175, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2269 0 visits [475.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5780 q_vals: [-8.158, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2270 0 visits [476.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5784 q_vals: [-8.159, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5789, "number_of_timesteps": 102022, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 2271 0 visits [477.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5789 q_vals: [-8.16, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2272 0 visits [478.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5791 q_vals: [-8.162, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2273 0 visits [479.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5795 q_vals: [-8.163, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5799, "number_of_timesteps": 102134, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 2274 0 visits [480.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5799 q_vals: [-8.164, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2275 0 visits [481.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5802 q_vals: [-8.165, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2276 0 visits [482.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5805 q_vals: [-8.167, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2277 0 visits [483.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5807 q_vals: [-8.195, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5813, "number_of_timesteps": 102322, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 2278 0 visits [484.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5813 q_vals: [-8.223, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2279 0 visits [485.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5814 q_vals: [-8.224, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2280 0 visits [486.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5819 q_vals: [-8.207, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2281 0 visits [487.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5822 q_vals: [-8.209, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5826, "number_of_timesteps": 102472, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 2282 0 visits [488.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5826 q_vals: [-8.21, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2283 0 visits [489.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5829 q_vals: [-8.211, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2284 0 visits [490.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5832 q_vals: [-8.212, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5836, "number_of_timesteps": 102609, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 2285 0 visits [491.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5836 q_vals: [-8.213, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2286 0 visits [492.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5839 q_vals: [-8.214, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2287 0 visits [493.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5842 q_vals: [-8.215, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5846, "number_of_timesteps": 102730, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 2288 0 visits [494.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5846 q_vals: [-8.216, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2289 0 visits [495.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5850 q_vals: [-8.2, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2290 0 visits [496.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5853 q_vals: [-8.201, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5858, "number_of_timesteps": 102868, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 2291 0 visits [497.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5858 q_vals: [-8.228, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2292 0 visits [498.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5861 q_vals: [-8.229, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2293 0 visits [499.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5864 q_vals: [-8.23, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5868, "number_of_timesteps": 102984, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 2294 0 visits [500.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5868 q_vals: [-8.231, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2295 0 visits [501.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5871 q_vals: [-8.215, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2296 0 visits [502.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5875 q_vals: [-8.216, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5879, "number_of_timesteps": 103121, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 2297 0 visits [503.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5879 q_vals: [-8.217, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2298 0 visits [504.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5880 q_vals: [-8.218, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2299 0 visits [505.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5884 q_vals: [-8.219, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5890, "number_of_timesteps": 103271, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 2300 0 visits [506.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5890 q_vals: [-8.203, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2301 0 visits [507.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5892 q_vals: [-8.23, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2302 0 visits [508.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5893 q_vals: [-8.231, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5900, "number_of_timesteps": 103395, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 2303 0 visits [509.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5900 q_vals: [-8.258, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2304 0 visits [510.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5901 q_vals: [-8.259, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2305 0 visits [511.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5903 q_vals: [-8.26, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2306 0 visits [512.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5907 q_vals: [-8.243, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5912, "number_of_timesteps": 103562, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 2307 0 visits [513.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5912 q_vals: [-8.244, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2308 0 visits [514.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5914 q_vals: [-8.245, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2309 0 visits [515.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5919 q_vals: [-8.246, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5922, "number_of_timesteps": 103677, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 2310 0 visits [516.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5922 q_vals: [-8.247, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2311 0 visits [517.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5924 q_vals: [-8.248, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2312 0 visits [518.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5928 q_vals: [-8.232, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2313 0 visits [519.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5931 q_vals: [-8.233, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5933, "number_of_timesteps": 103829, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2314 0 visits [520.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5933 q_vals: [-8.26, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2315 0 visits [521.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5936 q_vals: [-8.261, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2316 0 visits [522.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5942 q_vals: [-8.245, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5944, "number_of_timesteps": 103977, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2317 0 visits [523.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5944 q_vals: [-8.246, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2318 0 visits [524.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5948 q_vals: [-8.23, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2319 0 visits [525.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5950 q_vals: [-8.231, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5954, "number_of_timesteps": 104100, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 2320 0 visits [526.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5954 q_vals: [-8.232, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2321 0 visits [527.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5960 q_vals: [-8.216, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2322 0 visits [528.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5961 q_vals: [-8.242, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5965, "number_of_timesteps": 104235, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2323 0 visits [529.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5965 q_vals: [-8.227, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2324 0 visits [530.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5969 q_vals: [-8.228, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2325 0 visits [531.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5973 q_vals: [-8.229, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5979, "number_of_timesteps": 104398, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 2326 0 visits [532.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5979 q_vals: [-8.213, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2327 0 visits [533.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5982 q_vals: [-8.214, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2328 0 visits [534.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5986 q_vals: [-8.215, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 5989, "number_of_timesteps": 104499, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 2329 0 visits [535.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5989 q_vals: [-8.2, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2330 0 visits [536.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5995 q_vals: [-8.201, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2331 0 visits [537.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 5995 q_vals: [-8.186, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6000, "number_of_timesteps": 104621, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 2332 0 visits [538.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6000 q_vals: [-8.187, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2333 0 visits [539.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6003 q_vals: [-8.188, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2334 0 visits [540.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6005 q_vals: [-8.189, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2335 0 visits [541.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6009 q_vals: [-8.19, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6013, "number_of_timesteps": 104796, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 2336 0 visits [542.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6013 q_vals: [-8.191, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2337 0 visits [543.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6017 q_vals: [-8.176, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2338 0 visits [544.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6019 q_vals: [-8.177, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2339 0 visits [545.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6022 q_vals: [-8.162, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6026, "number_of_timesteps": 104963, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 2340 0 visits [546.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6026 q_vals: [-8.163, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2341 0 visits [547.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6029 q_vals: [-8.164, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2342 0 visits [548.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6030 q_vals: [-8.165, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2343 0 visits [549.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6034 q_vals: [-8.166, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6037, "number_of_timesteps": 105106, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2344 0 visits [550.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6037 q_vals: [-8.167, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2345 0 visits [551.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6040 q_vals: [-8.152, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2346 0 visits [552.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6043 q_vals: [-8.138, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6047, "number_of_timesteps": 105271, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2347 0 visits [553.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6047 q_vals: [-8.139, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2348 0 visits [554.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6048 q_vals: [-8.14, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2349 0 visits [555.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6054 q_vals: [-8.141, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2350 0 visits [556.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6055 q_vals: [-8.142, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6061, "number_of_timesteps": 105470, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2351 0 visits [557.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6061 q_vals: [-8.143, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2352 0 visits [558.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6064 q_vals: [-8.128, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2353 0 visits [559.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6066 q_vals: [-8.13, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2354 0 visits [560.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6069 q_vals: [-8.131, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6071, "number_of_timesteps": 105592, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2355 0 visits [561.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6071 q_vals: [-8.116, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2356 0 visits [562.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6073 q_vals: [-8.117, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2357 0 visits [563.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6075 q_vals: [-8.118, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2358 0 visits [564.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6076 q_vals: [-8.104, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2359 0 visits [565.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6077 q_vals: [-8.105, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6082, "number_of_timesteps": 105833, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2360 0 visits [566.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6082 q_vals: [-8.106, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2361 0 visits [567.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6085 q_vals: [-8.107, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2362 0 visits [568.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6088 q_vals: [-8.109, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6092, "number_of_timesteps": 105986, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2363 0 visits [569.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6092 q_vals: [-8.11, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2364 0 visits [570.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6096 q_vals: [-8.111, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2365 0 visits [571.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6097 q_vals: [-8.112, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2366 0 visits [572.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6099 q_vals: [-8.136, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2367 0 visits [573.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6101 q_vals: [-8.122, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6103, "number_of_timesteps": 106148, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2368 0 visits [574.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6103 q_vals: [-8.123, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2369 0 visits [575.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6105 q_vals: [-8.124, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2370 0 visits [576.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6110 q_vals: [-8.11, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6113, "number_of_timesteps": 106353, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2371 0 visits [577.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6113 q_vals: [-8.111, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2372 0 visits [578.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6118 q_vals: [-8.112, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2373 0 visits [579.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6121 q_vals: [-8.136, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6125, "number_of_timesteps": 106488, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2374 0 visits [580.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6125 q_vals: [-8.122, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2375 0 visits [581.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6129 q_vals: [-8.146, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2376 0 visits [582.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6130 q_vals: [-8.169, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6135, "number_of_timesteps": 106619, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2377 0 visits [583.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6135 q_vals: [-8.155, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2378 0 visits [584.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6137 q_vals: [-8.141, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2379 0 visits [585.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6140 q_vals: [-8.142, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2380 0 visits [586.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6143 q_vals: [-8.143, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6146, "number_of_timesteps": 106774, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2381 0 visits [587.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6146 q_vals: [-8.144, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2382 0 visits [588.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6147 q_vals: [-8.145, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2383 0 visits [589.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6151 q_vals: [-8.131, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2384 0 visits [590.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6153 q_vals: [-8.132, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6157, "number_of_timesteps": 106938, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2385 0 visits [591.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6157 q_vals: [-8.119, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2386 0 visits [592.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6157 q_vals: [-8.12, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2387 0 visits [593.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6164 q_vals: [-8.121, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2388 0 visits [594.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6164 q_vals: [-8.122, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6167, "number_of_timesteps": 107119, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2389 0 visits [595.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6167 q_vals: [-8.123, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2390 0 visits [596.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6170 q_vals: [-8.124, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2391 0 visits [597.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6173 q_vals: [-8.125, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2392 0 visits [598.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6175 q_vals: [-8.126, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6177, "number_of_timesteps": 107281, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2393 0 visits [599.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6177 q_vals: [-8.149, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2394 0 visits [600.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6182 q_vals: [-8.15, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2395 0 visits [601.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6183 q_vals: [-8.137, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2396 0 visits [602.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6186 q_vals: [-8.138, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6189, "number_of_timesteps": 107491, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2397 0 visits [603.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6189 q_vals: [-8.139, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2398 0 visits [604.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6192 q_vals: [-8.14, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2399 0 visits [605.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6196 q_vals: [-8.126, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6199, "number_of_timesteps": 107646, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2400 0 visits [606.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6199 q_vals: [-8.127, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2401 0 visits [607.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6202 q_vals: [-8.128, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2402 0 visits [608.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6205 q_vals: [-8.129, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
[-8.13, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6211, "number_of_timesteps": 107802, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2404 0 visits [610.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6211 q_vals: [-8.153, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2405 0 visits [611.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6215 q_vals: [-8.139, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2406 0 visits [612.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6216 q_vals: [-8.126, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2407 0 visits [613.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6217 q_vals: [-8.127, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2408 0 visits [614.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6220 q_vals: [-8.114, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6223, "number_of_timesteps": 108007, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2409 0 visits [615.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6223 q_vals: [-8.115, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2410 0 visits [616.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6226 q_vals: [-8.116, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2411 0 visits [617.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6227 q_vals: [-8.117, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2412 0 visits [618.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6229 q_vals: [-8.118, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2413 0 visits [619.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6232 q_vals: [-8.119, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6233, "number_of_timesteps": 108198, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2414 0 visits [620.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6233 q_vals: [-8.12, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2415 0 visits [621.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6235 q_vals: [-8.107, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2416 0 visits [622.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6240 q_vals: [-8.108, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2417 0 visits [623.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6241 q_vals: [-8.109, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6243, "number_of_timesteps": 108411, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2418 0 visits [624.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6243 q_vals: [-8.11, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2419 0 visits [625.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6245 q_vals: [-8.111, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2420 0 visits [626.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6249 q_vals: [-8.112, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2421 0 visits [627.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6251 q_vals: [-8.099, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6254, "number_of_timesteps": 108617, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2422 0 visits [628.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6254 q_vals: [-8.086, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2423 0 visits [629.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6257 q_vals: [-8.087, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2424 0 visits [630.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6258 q_vals: [-8.088, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2425 0 visits [631.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6259 q_vals: [-8.089, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6264, "number_of_timesteps": 108792, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2426 0 visits [632.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6264 q_vals: [-8.077, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2427 0 visits [633.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6266 q_vals: [-8.078, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2428 0 visits [634.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6268 q_vals: [-8.065, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2429 0 visits [635.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6273 q_vals: [-8.066, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6275, "number_of_timesteps": 108981, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2430 0 visits [636.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6275 q_vals: [-8.067, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2431 0 visits [637.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6276 q_vals: [-8.068, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2432 0 visits [638.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6278 q_vals: [-8.069, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2433 0 visits [639.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6281 q_vals: [-8.07, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
[640.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6283 q_vals: [-8.071, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6285, "number_of_timesteps": 109150, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2435 0 visits [641.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6285 q_vals: [-8.059, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2436 0 visits [642.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6287 q_vals: [-8.06, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2437 0 visits [643.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6288 q_vals: [-8.061, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2438 0 visits [644.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6291 q_vals: [-8.062, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2439 0 visits [645.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6292 q_vals: [-8.049, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2440 0 visits [646.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6293 q_vals: [-8.051, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6295, "number_of_timesteps": 109380, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2441 0 visits [647.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6295 q_vals: [-8.052, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2442 0 visits [648.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6296 q_vals: [-8.053, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2443 0 visits [649.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6297 q_vals: [-8.054, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2444 0 visits [650.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6300 q_vals: [-8.055, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2445 0 visits [651.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6301 q_vals: [-8.056, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2446 0 visits [652.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6304 q_vals: [-8.057, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6305, "number_of_timesteps": 109718, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2447 0 visits [653.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6305 q_vals: [-8.045, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2448 0 visits [654.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6308 q_vals: [-8.046, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2449 0 visits [655.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6310 q_vals: [-8.047, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2450 0 visits [656.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6312 q_vals: [-8.048, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2451 0 visits [657.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6313 q_vals: [-8.049, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2452 0 visits [658.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6314 q_vals: [-8.05, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6317, "number_of_timesteps": 109983, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2453 0 visits [659.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6317 q_vals: [-8.051, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2454 0 visits [660.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6319 q_vals: [-8.051, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2455 0 visits [661.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6321 q_vals: [-8.052, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2456 0 visits [662.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6324 q_vals: [-8.053, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6328, "number_of_timesteps": 110192, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2457 0 visits [663.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6328 q_vals: [-8.054, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2458 0 visits [664.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6328 q_vals: [-8.055, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2459 0 visits [665.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6330 q_vals: [-8.043, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2460 0 visits [666.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6335 q_vals: [-8.044, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2461 0 visits [667.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6336 q_vals: [-8.034, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6338, "number_of_timesteps": 110405, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2462 0 visits [668.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6338 q_vals: [-8.035, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2463 0 visits [669.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6341 q_vals: [-8.036, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2464 0 visits [670.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6344 q_vals: [-8.037, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6348, "number_of_timesteps": 110576, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 2465 0 visits [671.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6348 q_vals: [-8.058, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2466 0 visits [672.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6351 q_vals: [-8.059, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2467 0 visits [673.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6352 q_vals: [-8.06, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2468 0 visits [674.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6355 q_vals: [-8.081, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2469 0 visits [675.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6357 q_vals: [-8.097, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6359, "number_of_timesteps": 110783, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 2470 0 visits [676.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6359 q_vals: [-8.095, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2471 0 visits [677.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6362 q_vals: [-8.115, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2472 0 visits [678.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6364 q_vals: [-8.116, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2473 0 visits [679.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6366 q_vals: [-8.117, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6369, "number_of_timesteps": 110973, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 2474 0 visits [680.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6369 q_vals: [-8.137, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2475 0 visits [681.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6372 q_vals: [-8.138, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2476 0 visits [682.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6372 q_vals: [-8.139, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2477 0 visits [683.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6374 q_vals: [-8.14, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2478 0 visits [684.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6377 q_vals: [-8.141, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6379, "number_of_timesteps": 111157, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 2479 0 visits [685.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6379 q_vals: [-8.142, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2480 0 visits [686.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6381 q_vals: [-8.143, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2481 0 visits [687.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6382 q_vals: [-8.144, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2482 0 visits [688.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6384 q_vals: [-8.132, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2483 0 visits [689.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6388 q_vals: [-8.133, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6390, "number_of_timesteps": 111417, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 2484 0 visits [690.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6390 q_vals: [-8.127, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2485 0 visits [691.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6392 q_vals: [-8.116, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2486 0 visits [692.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6395 q_vals: [-8.117, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2487 0 visits [693.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6396 q_vals: [-8.118, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2488 0 visits [694.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6398 q_vals: [-8.118, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6400, "number_of_timesteps": 111642, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 2489 0 visits [695.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6400 q_vals: [-8.119, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2490 0 visits [696.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6404 q_vals: [-8.139, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2491 0 visits [697.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6404 q_vals: [-8.14, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2492 0 visits [698.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6407 q_vals: [-8.128, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6410, "number_of_timesteps": 111836, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 2493 0 visits [699.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6410 q_vals: [-8.129, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2494 0 visits [700.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6410 q_vals: [-8.118, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2495 0 visits [701.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6411 q_vals: [-8.118, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2496 0 visits [702.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6413 q_vals: [-8.119, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2497 0 visits [703.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6414 q_vals: [-8.12, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2498 0 visits [704.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6417 q_vals: [-8.121, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2499 0 visits [705.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6419 q_vals: [-8.122, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6421, "number_of_timesteps": 112108, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 2500 0 visits [706.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6421 q_vals: [-8.123, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2501 0 visits [707.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6424 q_vals: [-8.124, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2502 0 visits [708.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6426 q_vals: [-8.112, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2503 0 visits [709.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6427 q_vals: [-8.113, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2504 0 visits [710.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6428 q_vals: [-8.114, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6432, "number_of_timesteps": 112341, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.10000000000000142},
Step 2505 0 visits [711.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6432 q_vals: [-8.102, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2506 0 visits [712.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6432 q_vals: [-8.1, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2507 0 visits [713.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6434 q_vals: [-8.101, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2508 0 visits [714.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6438 q_vals: [-8.102, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2509 0 visits [715.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6440 q_vals: [-8.091, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2510 0 visits [716.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6441 q_vals: [-8.092, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6444, "number_of_timesteps": 112652, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 2511 0 visits [717.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6444 q_vals: [-8.093, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2512 0 visits [718.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6446 q_vals: [-8.094, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2513 0 visits [719.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6448 q_vals: [-8.094, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2514 0 visits [720.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6450 q_vals: [-8.095, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2515 0 visits [721.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6452 q_vals: [-8.096, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6454, "number_of_timesteps": 112852, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 2516 0 visits [722.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6454 q_vals: [-8.097, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2517 0 visits [723.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6458 q_vals: [-8.098, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2518 0 visits [724.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6460 q_vals: [-8.117, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2519 0 visits [725.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6462 q_vals: [-8.106, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6466, "number_of_timesteps": 113080, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 2520 0 visits [726.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6466 q_vals: [-8.107, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2521 0 visits [727.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6467 q_vals: [-8.108, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2522 0 visits [728.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6470 q_vals: [-8.109, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2523 0 visits [729.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6473 q_vals: [-8.097, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6476, "number_of_timesteps": 113275, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2524 0 visits [730.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6476 q_vals: [-8.086, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2525 0 visits [731.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6480 q_vals: [-8.087, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2526 0 visits [732.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6482 q_vals: [-8.081, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2527 0 visits [733.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6485 q_vals: [-8.082, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6488, "number_of_timesteps": 113439, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2528 0 visits [734.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6488 q_vals: [-8.083, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2529 0 visits [735.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6489 q_vals: [-8.102, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2530 0 visits [736.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6492 q_vals: [-8.103, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2531 0 visits [737.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6494 q_vals: [-8.104, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2532 0 visits [738.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6496 q_vals: [-8.105, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6499, "number_of_timesteps": 113655, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2533 0 visits [739.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6499 q_vals: [-8.106, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2534 0 visits [740.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6499 q_vals: [-8.106, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2535 0 visits [741.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6501 q_vals: [-8.107, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2536 0 visits [742.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6505 q_vals: [-8.108, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2537 0 visits [743.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6508 q_vals: [-8.097, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6510, "number_of_timesteps": 113899, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2538 0 visits [744.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6510 q_vals: [-8.098, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2539 0 visits [745.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6514 q_vals: [-8.099, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2540 0 visits [746.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6516 q_vals: [-8.1, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6520, "number_of_timesteps": 114052, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2541 0 visits [747.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6520 q_vals: [-8.101, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2542 0 visits [748.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6522 q_vals: [-8.102, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2543 0 visits [749.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6524 q_vals: [-8.102, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2544 0 visits [750.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6529 q_vals: [-8.092, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2545 0 visits [751.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6529 q_vals: [-8.093, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6530, "number_of_timesteps": 114198, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2546 0 visits [752.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6530 q_vals: [-8.093, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2547 0 visits [753.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6535 q_vals: [-8.094, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2548 0 visits [754.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6536 q_vals: [-8.095, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2549 0 visits [755.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6538 q_vals: [-8.113, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2550 0 visits [756.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6539 q_vals: [-8.132, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6541, "number_of_timesteps": 114408, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2551 0 visits [757.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6541 q_vals: [-8.15, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2552 0 visits [758.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6543 q_vals: [-8.151, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2553 0 visits [759.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6548 q_vals: [-8.151, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2554 0 visits [760.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6548 q_vals: [-8.152, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2555 0 visits [761.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6550 q_vals: [-8.153, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6555, "number_of_timesteps": 114697, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2556 0 visits [762.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6555 q_vals: [-8.154, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2557 0 visits [763.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6556 q_vals: [-8.154, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2558 0 visits [764.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6558 q_vals: [-8.147, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2559 0 visits [765.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6560 q_vals: [-8.165, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6566, "number_of_timesteps": 114915, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2560 0 visits [766.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6566 q_vals: [-8.165, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2561 0 visits [767.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6566 q_vals: [-8.155, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2562 0 visits [768.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6568 q_vals: [-8.156, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2563 0 visits [769.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6570 q_vals: [-8.156, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2564 0 visits [770.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6572 q_vals: [-8.174, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2565 0 visits [771.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6574 q_vals: [-8.192, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6576, "number_of_timesteps": 115122, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2566 0 visits [772.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6576 q_vals: [-8.193, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2567 0 visits [773.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6579 q_vals: [-8.193, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2568 0 visits [774.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6580 q_vals: [-8.194, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2569 0 visits [775.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6583 q_vals: [-8.212, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6587, "number_of_timesteps": 115348, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2570 0 visits [776.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6587 q_vals: [-8.212, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2571 0 visits [777.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6588 q_vals: [-8.213, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2572 0 visits [778.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6593 q_vals: [-8.214, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2573 0 visits [779.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6595 q_vals: [-8.215, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6598, "number_of_timesteps": 115542, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2574 0 visits [780.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6598 q_vals: [-8.215, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2575 0 visits [781.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6600 q_vals: [-8.216, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2576 0 visits [782.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6604 q_vals: [-8.205, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2577 0 visits [783.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6607 q_vals: [-8.206, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6614, "number_of_timesteps": 115772, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2578 0 visits [784.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6614 q_vals: [-8.196, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2579 0 visits [785.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6614 q_vals: [-8.196, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2580 0 visits [786.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6616 q_vals: [-8.186, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2581 0 visits [787.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6622 q_vals: [-8.187, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6624, "number_of_timesteps": 115910, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2582 0 visits [788.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6624 q_vals: [-8.176, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2583 0 visits [789.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6625 q_vals: [-8.177, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2584 0 visits [790.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6626 q_vals: [-8.167, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2585 0 visits [791.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6628 q_vals: [-8.156, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2586 0 visits [792.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6633 q_vals: [-8.157, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6634, "number_of_timesteps": 116092, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2587 0 visits [793.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6634 q_vals: [-8.174, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2588 0 visits [794.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6636 q_vals: [-8.164, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2589 0 visits [795.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6636 q_vals: [-8.154, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2590 0 visits [796.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6639 q_vals: [-8.144, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2591 0 visits [797.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6643 q_vals: [-8.133, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6644, "number_of_timesteps": 116294, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2592 0 visits [798.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6644 q_vals: [-8.134, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2593 0 visits [799.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6646 q_vals: [-8.135, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2594 0 visits [800.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6650 q_vals: [-8.136, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2595 0 visits [801.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6651 q_vals: [-8.125, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6654, "number_of_timesteps": 116460, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2596 0 visits [802.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6654 q_vals: [-8.126, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2597 0 visits [803.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6656 q_vals: [-8.127, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2598 0 visits [804.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6660 q_vals: [-8.128, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6664, "number_of_timesteps": 116698, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2599 0 visits [805.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6664 q_vals: [-8.129, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2600 0 visits [806.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6665 q_vals: [-8.119, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2601 0 visits [807.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6669 q_vals: [-8.108, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2602 0 visits [808.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6672 q_vals: [-8.109, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2603 0 visits [809.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6672 q_vals: [-8.11, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6675, "number_of_timesteps": 116865, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2604 0 visits [810.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6675 q_vals: [-8.111, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2605 0 visits [811.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6679 q_vals: [-8.101, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2606 0 visits [812.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6679 q_vals: [-8.102, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2607 0 visits [813.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6683 q_vals: [-8.102, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6685, "number_of_timesteps": 117046, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2608 0 visits [814.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6685 q_vals: [-8.119, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2609 0 visits [815.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6687 q_vals: [-8.136, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2610 0 visits [816.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6691 q_vals: [-8.137, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2611 0 visits [817.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6693 q_vals: [-8.138, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6695, "number_of_timesteps": 117219, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2612 0 visits [818.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6695 q_vals: [-8.128, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2613 0 visits [819.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6698 q_vals: [-8.129, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2614 0 visits [820.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6699 q_vals: [-8.129, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2615 0 visits [821.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6702 q_vals: [-8.13, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6706, "number_of_timesteps": 117439, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2616 0 visits [822.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6706 q_vals: [-8.131, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2617 0 visits [823.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6709 q_vals: [-8.132, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2618 0 visits [824.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6709 q_vals: [-8.132, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2619 0 visits [825.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6711 q_vals: [-8.133, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2620 0 visits [826.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6715 q_vals: [-8.134, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6716, "number_of_timesteps": 117629, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2621 0 visits [827.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6716 q_vals: [-8.127, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2622 0 visits [828.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6718 q_vals: [-8.127, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2623 0 visits [829.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6719 q_vals: [-8.128, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2624 0 visits [830.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6722 q_vals: [-8.129, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2625 0 visits [831.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6725 q_vals: [-8.145, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6728, "number_of_timesteps": 117901, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2626 0 visits [832.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6728 q_vals: [-8.136, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2627 0 visits [833.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6730 q_vals: [-8.136, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2628 0 visits [834.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6732 q_vals: [-8.137, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2629 0 visits [835.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6735 q_vals: [-8.154, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2630 0 visits [836.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6737 q_vals: [-8.154, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6739, "number_of_timesteps": 118076, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2631 0 visits [837.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6739 q_vals: [-8.155, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2632 0 visits [838.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6740 q_vals: [-8.171, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2633 0 visits [839.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6744 q_vals: [-8.161, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2634 0 visits [840.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6745 q_vals: [-8.162, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2635 0 visits [841.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6747 q_vals: [-8.163, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6749, "number_of_timesteps": 118285, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2636 0 visits [842.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6749 q_vals: [-8.163, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2637 0 visits [843.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6752 q_vals: [-8.164, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2638 0 visits [844.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6753 q_vals: [-8.165, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2639 0 visits [845.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6754 q_vals: [-8.166, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2640 0 visits [846.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6757 q_vals: [-8.166, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2641 0 visits [847.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6758 q_vals: [-8.157, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6759, "number_of_timesteps": 118542, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2642 0 visits [848.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6759 q_vals: [-8.157, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2643 0 visits [849.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6763 q_vals: [-8.158, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2644 0 visits [850.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6764 q_vals: [-8.148, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2645 0 visits [851.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6766 q_vals: [-8.149, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2646 0 visits [852.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6768 q_vals: [-8.15, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6769, "number_of_timesteps": 118768, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2647 0 visits [853.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6769 q_vals: [-8.15, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2648 0 visits [854.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6770 q_vals: [-8.141, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2649 0 visits [855.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6771 q_vals: [-8.142, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2650 0 visits [856.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6772 q_vals: [-8.158, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2651 0 visits [857.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6775 q_vals: [-8.158, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2652 0 visits [858.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6777 q_vals: [-8.149, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2653 0 visits [859.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6778 q_vals: [-8.15, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6779, "number_of_timesteps": 119079, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2654 0 visits [860.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6779 q_vals: [-8.15, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2655 0 visits [861.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6781 q_vals: [-8.151, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2656 0 visits [862.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6786 q_vals: [-8.152, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2657 0 visits [863.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6788 q_vals: [-8.152, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6792, "number_of_timesteps": 119386, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2658 0 visits [864.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6792 q_vals: [-8.152, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2659 0 visits [865.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6794 q_vals: [-8.152, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2660 0 visits [866.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6797 q_vals: [-8.153, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2661 0 visits [867.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6800 q_vals: [-8.152, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2662 0 visits [868.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6800 q_vals: [-8.143, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6802, "number_of_timesteps": 119550, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2663 0 visits [869.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6802 q_vals: [-8.143, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2664 0 visits [870.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6805 q_vals: [-8.134, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2665 0 visits [871.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6809 q_vals: [-8.135, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2666 0 visits [872.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6811 q_vals: [-8.135, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6814, "number_of_timesteps": 119775, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2667 0 visits [873.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6814 q_vals: [-8.136, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2668 0 visits [874.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6815 q_vals: [-8.136, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2669 0 visits [875.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6818 q_vals: [-8.133, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2670 0 visits [876.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6820 q_vals: [-8.133, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6824, "number_of_timesteps": 119963, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2671 0 visits [877.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6824 q_vals: [-8.134, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2672 0 visits [878.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6827 q_vals: [-8.135, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2673 0 visits [879.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6828 q_vals: [-8.125, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2674 0 visits [880.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6830 q_vals: [-8.121, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2675 0 visits [881.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6832 q_vals: [-8.122, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6835, "number_of_timesteps": 120173, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2676 0 visits [882.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6835 q_vals: [-8.123, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2677 0 visits [883.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6837 q_vals: [-8.12, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2678 0 visits [884.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6840 q_vals: [-8.122, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2679 0 visits [885.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6843 q_vals: [-8.113, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6845, "number_of_timesteps": 120369, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2680 0 visits [886.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6845 q_vals: [-8.114, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2681 0 visits [887.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6848 q_vals: [-8.115, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2682 0 visits [888.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6851 q_vals: [-8.115, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2683 0 visits [889.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6852 q_vals: [-8.116, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6855, "number_of_timesteps": 120498, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2684 0 visits [890.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6855 q_vals: [-8.117, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2685 0 visits [891.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6858 q_vals: [-8.117, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2686 0 visits [892.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6861 q_vals: [-8.118, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2687 0 visits [893.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6864 q_vals: [-8.119, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6867, "number_of_timesteps": 120747, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2688 0 visits [894.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6867 q_vals: [-8.11, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2689 0 visits [895.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6870 q_vals: [-8.108, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2690 0 visits [896.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6874 q_vals: [-8.109, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2691 0 visits [897.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6876 q_vals: [-8.11, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6878, "number_of_timesteps": 120911, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2692 0 visits [898.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6878 q_vals: [-8.103, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2693 0 visits [899.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6879 q_vals: [-8.104, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2694 0 visits [900.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6883 q_vals: [-8.104, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2695 0 visits [901.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6885 q_vals: [-8.105, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6888, "number_of_timesteps": 121100, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2696 0 visits [902.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6888 q_vals: [-8.113, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2697 0 visits [903.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6892 q_vals: [-8.104, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2698 0 visits [904.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6893 q_vals: [-8.105, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2699 0 visits [905.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6895 q_vals: [-8.105, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2700 0 visits [906.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6897 q_vals: [-8.106, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6898, "number_of_timesteps": 121279, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2701 0 visits [907.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6898 q_vals: [-8.107, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2702 0 visits [908.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6899 q_vals: [-8.108, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2703 0 visits [909.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6902 q_vals: [-8.108, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2704 0 visits [910.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6905 q_vals: [-8.109, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2705 0 visits [911.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6907 q_vals: [-8.109, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2706 0 visits [912.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6907 q_vals: [-8.101, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6909, "number_of_timesteps": 121509, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2707 0 visits [913.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6909 q_vals: [-8.101, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2708 0 visits [914.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6913 q_vals: [-8.092, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2709 0 visits [915.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6915 q_vals: [-8.093, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2710 0 visits [916.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6917 q_vals: [-8.094, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2711 0 visits [917.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6918 q_vals: [-8.095, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6922, "number_of_timesteps": 121801, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2712 0 visits [918.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6922 q_vals: [-8.086, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2713 0 visits [919.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6926 q_vals: [-8.086, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2714 0 visits [920.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6927 q_vals: [-8.087, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2715 0 visits [921.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6928 q_vals: [-8.102, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2716 0 visits [922.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6930 q_vals: [-8.103, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6933, "number_of_timesteps": 122026, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2717 0 visits [923.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6933 q_vals: [-8.1, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2718 0 visits [924.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6933 q_vals: [-8.1, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2719 0 visits [925.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6934 q_vals: [-8.101, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2720 0 visits [926.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6939 q_vals: [-8.102, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2721 0 visits [927.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6940 q_vals: [-8.093, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2722 0 visits [928.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6940 q_vals: [-8.094, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2723 0 visits [929.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6942 q_vals: [-8.108, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6944, "number_of_timesteps": 122320, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2724 0 visits [930.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6944 q_vals: [-8.109, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2725 0 visits [931.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6945 q_vals: [-8.11, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2726 0 visits [932.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6947 q_vals: [-8.124, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2727 0 visits [933.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6950 q_vals: [-8.125, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2728 0 visits [934.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6952 q_vals: [-8.126, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6955, "number_of_timesteps": 122579, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2729 0 visits [935.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6955 q_vals: [-8.126, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2730 0 visits [936.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6957 q_vals: [-8.127, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2731 0 visits [937.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6958 q_vals: [-8.128, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2732 0 visits [938.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6962 q_vals: [-8.128, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6965, "number_of_timesteps": 122780, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2733 0 visits [939.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6965 q_vals: [-8.143, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2734 0 visits [940.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6966 q_vals: [-8.144, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2735 0 visits [941.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6970 q_vals: [-8.135, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2736 0 visits [942.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6971 q_vals: [-8.136, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
[-8.136, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6979, "number_of_timesteps": 123037, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2738 0 visits [944.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6979 q_vals: [-8.137, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2739 0 visits [945.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6981 q_vals: [-8.128, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2740 0 visits [946.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6986 q_vals: [-8.129, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 6989, "number_of_timesteps": 123173, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2741 0 visits [947.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6989 q_vals: [-8.13, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2742 0 visits [948.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6992 q_vals: [-8.13, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2743 0 visits [949.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6994 q_vals: [-8.131, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2744 0 visits [950.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 6998 q_vals: [-8.132, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 7000, "number_of_timesteps": 123319, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2745 0 visits [951.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7000 q_vals: [-8.132, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2746 0 visits [952.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7004 q_vals: [-8.124, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2747 0 visits [953.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7007 q_vals: [-8.124, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 7012, "number_of_timesteps": 123497, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2748 0 visits [954.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7012 q_vals: [-8.125, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2749 0 visits [955.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7014 q_vals: [-8.126, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2750 0 visits [956.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7017 q_vals: [-8.126, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2751 0 visits [957.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7019 q_vals: [-8.127, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 7023, "number_of_timesteps": 123645, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2752 0 visits [958.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7023 q_vals: [-8.128, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2753 0 visits [959.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7025 q_vals: [-8.128, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2754 0 visits [960.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7027 q_vals: [-8.12, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2755 0 visits [961.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7032 q_vals: [-8.12, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 7034, "number_of_timesteps": 123833, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2756 0 visits [962.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7034 q_vals: [-8.112, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2757 0 visits [963.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7037 q_vals: [-8.113, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2758 0 visits [964.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7040 q_vals: [-8.113, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2759 0 visits [965.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7042 q_vals: [-8.114, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 7046, "number_of_timesteps": 124011, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2760 0 visits [966.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7046 q_vals: [-8.115, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2761 0 visits [967.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7051 q_vals: [-8.115, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2762 0 visits [968.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7052 q_vals: [-8.116, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2763 0 visits [969.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7055 q_vals: [-8.128, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 7059, "number_of_timesteps": 124187, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2764 0 visits [970.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7059 q_vals: [-8.143, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2765 0 visits [971.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7061 q_vals: [-8.157, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2766 0 visits [972.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7061 q_vals: [-8.157, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
 [973.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7064 q_vals: [-8.158, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2768 0 visits [974.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7068 q_vals: [-8.158, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 7071, "number_of_timesteps": 124409, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2769 0 visits [975.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7071 q_vals: [-8.159, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2770 0 visits [976.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7074 q_vals: [-8.159, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2771 0 visits [977.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7077 q_vals: [-8.16, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2772 0 visits [978.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7080 q_vals: [-8.161, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 7082, "number_of_timesteps": 124566, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2773 0 visits [979.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7082 q_vals: [-8.175, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2774 0 visits [980.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7086 q_vals: [-8.175, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2775 0 visits [981.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7089 q_vals: [-8.175, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2776 0 visits [982.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7091 q_vals: [-8.176, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 7095, "number_of_timesteps": 124769, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2777 0 visits [983.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7095 q_vals: [-8.176, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2778 0 visits [984.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7096 q_vals: [-8.177, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2779 0 visits [985.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7099 q_vals: [-8.178, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2780 0 visits [986.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7103 q_vals: [-8.191, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 7106, "number_of_timesteps": 124957, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2781 0 visits [987.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7106 q_vals: [-8.192, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2782 0 visits [988.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7108 q_vals: [-8.193, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2783 0 visits [989.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7110 q_vals: [-8.184, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2784 0 visits [990.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7112 q_vals: [-8.176, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2785 0 visits [991.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7115 q_vals: [-8.177, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 7118, "number_of_timesteps": 125154, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2786 0 visits [992.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7118 q_vals: [-8.177, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2787 0 visits [993.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7119 q_vals: [-8.169, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2788 0 visits [994.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7119 q_vals: [-8.17, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2789 0 visits [995.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7123 q_vals: [-8.17, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2790 0 visits [996.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7125 q_vals: [-8.17, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2791 0 visits [997.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7127 q_vals: [-8.162, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
{"total_number_of_episodes": 7133, "number_of_timesteps": 125466, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2792 0 visits [998.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7133 q_vals: [-8.154, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2793 0 visits [999.0, 1000.0, 1.0, 1.0, 2.0, 2.0, 5.0, 8.0, 1.0, 3.0]  episode_count: 7134 q_vals: [-8.146, -inf, -12.64, -21.875, -10.063, -15.312, -9.325, -10.391, -21.875, -10.208]
Step 2794 0 visits [1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 7137 q_vals: [-inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2795 2 visits [1000.0, 1000.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 7142 q_vals: [-inf, -inf, -9.516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
{"total_number_of_episodes": 7144, "number_of_timesteps": 125616, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.4499999999999993},
Step 2796 3 visits [1000.0, 1000.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 7144 q_vals: [-inf, -inf, -9.516, -9.796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
[-inf, -inf, -9.516, -9.796, -9.796, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2798 5 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 7150 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, 0.0, 0.0, 0.0, 0.0, 0.0]
{"total_number_of_episodes": 7154, "number_of_timesteps": 125763, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.4499999999999993},
Step 2799 6 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 7154 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2800 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 7155 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2801 8 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 7159 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, 0.0, 0.0, 0.0, -9.796, 0.0]
Step 2802 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 7163 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, 0.0, 0.0, 0.0, -9.796, 0.0]
{"total_number_of_episodes": 7165, "number_of_timesteps": 125927, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.4499999999999993},
Step 2803 5 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 7165 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, 0.0, 0.0, -9.796, 0.0]
Step 2804 6 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 7167 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -4.898, 0.0, -9.796, 0.0]
Step 2805 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0]  episode_count: 7170 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -4.898, -4.898, -9.796, 0.0]
Step 2806 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0]  episode_count: 7171 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -4.898, -4.898, -9.796, 0.0]
Step 2807 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0]  episode_count: 7174 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -4.898, -4.898, -9.796, -3.182]
{"total_number_of_episodes": 7179, "number_of_timesteps": 126156, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.4499999999999993},
Step 2808 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 4.0]  episode_count: 7179 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -4.898, -4.898, -9.796, -4.836]
Step 2809 6 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 1.0, 4.0]  episode_count: 7182 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -6.531, -4.898, -9.796, -4.836]
Step 2810 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 4.0]  episode_count: 7184 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -6.531, -6.531, -9.796, -4.836]
Step 2811 5 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 1.0, 4.0]  episode_count: 7186 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -3.265, -6.531, -6.531, -9.796, -4.836]
{"total_number_of_episodes": 7189, "number_of_timesteps": 126307, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.4499999999999993},
Step 2812 5 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 4.0]  episode_count: 7189 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -6.531, -6.531, -9.796, -4.836]
Step 2813 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 5.0]  episode_count: 7189 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -6.531, -6.531, -9.796, -3.869]
Step 2814 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 6.0]  episode_count: 7193 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -6.531, -6.531, -9.796, -3.224]
Step 2815 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 7.0]  episode_count: 7198 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -6.531, -6.531, -9.796, -2.763]
{"total_number_of_episodes": 7199, "number_of_timesteps": 126488, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.4499999999999993},
Step 2816 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 8.0]  episode_count: 7199 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -6.531, -6.531, -9.796, -3.642]
Step 2817 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 9.0]  episode_count: 7201 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -6.531, -6.531, -9.796, -3.238]
Step 2818 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 10.0]  episode_count: 7204 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -6.531, -6.531, -9.796, -3.894]
{"total_number_of_episodes": 7209, "number_of_timesteps": 126644, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.4499999999999993},
Step 2819 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 11.0]  episode_count: 7209 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -6.531, -6.531, -9.796, -3.54]
Step 2820 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 12.0]  episode_count: 7209 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -6.531, -6.531, -9.796, -4.061]
Step 2821 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 13.0]  episode_count: 7213 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -4.898, -6.531, -6.531, -9.796, -4.502]
Step 2822 5 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 5.0, 3.0, 3.0, 1.0, 13.0]  episode_count: 7215 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -5.878, -6.531, -6.531, -9.796, -4.502]
{"total_number_of_episodes": 7219, "number_of_timesteps": 126792, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.4499999999999993},
Step 2823 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 5.0, 3.0, 3.0, 1.0, 14.0]  episode_count: 7219 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -5.878, -6.531, -6.531, -9.796, -4.852]
Step 2824 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 5.0, 3.0, 3.0, 1.0, 15.0]  episode_count: 7220 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -5.878, -6.531, -6.531, -9.796, -5.182]
Step 2825 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 5.0, 3.0, 3.0, 1.0, 16.0]  episode_count: 7226 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -5.878, -6.531, -6.531, -9.796, -5.463]
{"total_number_of_episodes": 7230, "number_of_timesteps": 126976, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.016111111111111104, "biggest_recent_change": 1.4499999999999993},
Step 2826 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 5.0, 3.0, 3.0, 1.0, 17.0]  episode_count: 7230 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -5.878, -6.531, -6.531, -9.796, -5.695]
Step 2827 5 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 3.0, 3.0, 1.0, 17.0]  episode_count: 7232 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -6.531, -6.531, -9.796, -5.695]
Step 2828 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 3.0, 3.0, 1.0, 18.0]  episode_count: 7234 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -6.531, -6.531, -9.796, -5.379]
Step 2829 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 3.0, 3.0, 1.0, 19.0]  episode_count: 7236 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -6.531, -6.531, -9.796, -6.385]
Step 2830 6 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 3.0, 1.0, 19.0]  episode_count: 7239 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -6.531, -9.796, -6.385]
{"total_number_of_episodes": 7245, "number_of_timesteps": 127182, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2831 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 4.0, 1.0, 19.0]  episode_count: 7245 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -4.898, -9.796, -6.385]
Step 2832 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 5.0, 1.0, 19.0]  episode_count: 7247 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -3.918, -9.796, -6.385]
Step 2833 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 6.0, 1.0, 19.0]  episode_count: 7249 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -3.265, -9.796, -6.385]
Step 2834 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 7.0, 1.0, 19.0]  episode_count: 7252 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -4.166, -9.796, -6.385]
{"total_number_of_episodes": 7257, "number_of_timesteps": 127363, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2835 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 8.0, 1.0, 19.0]  episode_count: 7257 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -3.645, -9.796, -6.385]
Step 2836 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 9.0, 1.0, 19.0]  episode_count: 7259 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -3.24, -9.796, -6.385]
Step 2837 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 10.0, 1.0, 19.0]  episode_count: 7262 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -3.896, -9.796, -6.385]
Step 2838 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 11.0, 1.0, 19.0]  episode_count: 7263 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -4.432, -9.796, -6.385]
Step 2839 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 12.0, 1.0, 19.0]  episode_count: 7265 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -4.879, -9.796, -6.385]
{"total_number_of_episodes": 7268, "number_of_timesteps": 127521, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2840 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 13.0, 1.0, 19.0]  episode_count: 7268 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -5.257, -9.796, -6.385]
Step 2841 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 14.0, 1.0, 19.0]  episode_count: 7271 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -5.568, -9.796, -6.385]
Step 2842 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 15.0, 1.0, 19.0]  episode_count: 7275 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -5.849, -9.796, -6.385]
{"total_number_of_episodes": 7278, "number_of_timesteps": 127721, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2843 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 16.0, 1.0, 19.0]  episode_count: 7278 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -6.096, -9.796, -6.385]
Step 2844 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 17.0, 1.0, 19.0]  episode_count: 7283 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -5.737, -9.796, -6.385]
Step 2845 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 18.0, 1.0, 19.0]  episode_count: 7286 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -5.929, -9.796, -6.385]
Step 2846 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 19.0, 1.0, 19.0]  episode_count: 7286 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -5.617, -9.796, -6.385]
{"total_number_of_episodes": 7291, "number_of_timesteps": 127886, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2847 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 20.0, 1.0, 19.0]  episode_count: 7291 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -5.336, -9.796, -6.385]
Step 2848 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 21.0, 1.0, 19.0]  episode_count: 7294 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -5.534, -9.796, -6.385]
Step 2849 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 22.0, 1.0, 19.0]  episode_count: 7296 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -5.727, -9.796, -6.385]
{"total_number_of_episodes": 7301, "number_of_timesteps": 128023, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 2850 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 23.0, 1.0, 19.0]  episode_count: 7301 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -5.904, -9.796, -6.385]
Step 2851 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 24.0, 1.0, 19.0]  episode_count: 7304 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -6.066, -9.796, -6.385]
Step 2852 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 6.0, 4.0, 25.0, 1.0, 19.0]  episode_count: 7307 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.531, -11.02, -6.216, -9.796, -6.385]
Step 2853 5 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 7.0, 4.0, 25.0, 1.0, 19.0]  episode_count: 7309 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.997, -11.02, -6.216, -9.796, -6.385]
{"total_number_of_episodes": 7313, "number_of_timesteps": 128171, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 2854 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 7.0, 4.0, 26.0, 1.0, 19.0]  episode_count: 7313 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.997, -11.02, -5.977, -9.796, -6.385]
Step 2855 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 7.0, 4.0, 27.0, 1.0, 19.0]  episode_count: 7316 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.997, -11.02, -6.118, -9.796, -6.385]
Step 2856 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 7.0, 4.0, 28.0, 1.0, 19.0]  episode_count: 7318 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.997, -11.02, -6.249, -9.796, -6.385]
Step 2857 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 7.0, 4.0, 29.0, 1.0, 19.0]  episode_count: 7321 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.997, -11.02, -6.034, -9.796, -6.385]
{"total_number_of_episodes": 7323, "number_of_timesteps": 128338, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 2858 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 7.0, 4.0, 30.0, 1.0, 19.0]  episode_count: 7323 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.997, -11.02, -5.833, -9.796, -6.385]
Step 2859 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 7.0, 4.0, 31.0, 1.0, 19.0]  episode_count: 7328 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.997, -11.02, -5.961, -9.796, -6.385]
Step 2860 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 7.0, 4.0, 32.0, 1.0, 19.0]  episode_count: 7332 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.997, -11.02, -6.54, -9.796, -6.385]
Step 2861 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 7.0, 4.0, 32.0, 1.0, 20.0]  episode_count: 7332 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.997, -11.02, -6.54, -9.796, -6.555]
{"total_number_of_episodes": 7337, "number_of_timesteps": 128532, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 2862 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 7.0, 4.0, 32.0, 1.0, 21.0]  episode_count: 7337 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.997, -11.02, -6.54, -9.796, -6.694]
Step 2863 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 7.0, 4.0, 33.0, 1.0, 21.0]  episode_count: 7340 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.997, -11.02, -6.341, -9.796, -6.694]
Step 2864 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 7.0, 4.0, 34.0, 1.0, 21.0]  episode_count: 7342 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.997, -11.02, -6.443, -9.796, -6.694]
{"total_number_of_episodes": 7347, "number_of_timesteps": 128675, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2865 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 7.0, 4.0, 35.0, 1.0, 21.0]  episode_count: 7347 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.997, -11.02, -6.539, -9.796, -6.694]
Step 2866 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 7.0, 4.0, 36.0, 1.0, 21.0]  episode_count: 7351 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -6.997, -11.02, -6.629, -9.796, -6.694]
Step 2867 5 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 8.0, 4.0, 36.0, 1.0, 21.0]  episode_count: 7351 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.323, -11.02, -6.629, -9.796, -6.694]
Step 2868 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 8.0, 4.0, 36.0, 1.0, 22.0]  episode_count: 7356 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.323, -11.02, -6.629, -9.796, -6.389]
{"total_number_of_episodes": 7358, "number_of_timesteps": 128816, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 2869 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 8.0, 4.0, 36.0, 1.0, 23.0]  episode_count: 7358 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.323, -11.02, -6.629, -9.796, -6.538]
Step 2870 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 8.0, 4.0, 36.0, 1.0, 24.0]  episode_count: 7360 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.323, -11.02, -6.629, -9.796, -6.652]
Step 2871 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 8.0, 4.0, 36.0, 1.0, 25.0]  episode_count: 7365 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.323, -11.02, -6.629, -9.796, -7.365]
{"total_number_of_episodes": 7368, "number_of_timesteps": 128981, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2872 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 8.0, 4.0, 37.0, 1.0, 25.0]  episode_count: 7368 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.323, -11.02, -7.091, -9.796, -7.365]
Step 2873 5 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 37.0, 1.0, 25.0]  episode_count: 7370 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -7.091, -9.796, -7.365]
Step 2874 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 38.0, 1.0, 25.0]  episode_count: 7374 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -7.162, -9.796, -7.365]
Step 2875 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 39.0, 1.0, 25.0]  episode_count: 7376 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -7.22, -9.796, -7.365]
{"total_number_of_episodes": 7380, "number_of_timesteps": 129138, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 2876 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 40.0, 1.0, 25.0]  episode_count: 7380 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -7.04, -9.796, -7.365]
Step 2877 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 41.0, 1.0, 25.0]  episode_count: 7382 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.868, -9.796, -7.365]
Step 2878 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 42.0, 1.0, 25.0]  episode_count: 7385 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.938, -9.796, -7.365]
Step 2879 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 43.0, 1.0, 25.0]  episode_count: 7387 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.776, -9.796, -7.365]
{"total_number_of_episodes": 7392, "number_of_timesteps": 129328, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2880 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 44.0, 1.0, 25.0]  episode_count: 7392 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.622, -9.796, -7.365]
Step 2881 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 45.0, 1.0, 25.0]  episode_count: 7395 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.986, -9.796, -7.365]
Step 2882 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 46.0, 1.0, 25.0]  episode_count: 7397 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -7.047, -9.796, -7.365]
Step 2883 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 47.0, 1.0, 25.0]  episode_count: 7400 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -7.106, -9.796, -7.365]
{"total_number_of_episodes": 7403, "number_of_timesteps": 129498, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2884 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 48.0, 1.0, 25.0]  episode_count: 7403 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.958, -9.796, -7.365]
Step 2885 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 49.0, 1.0, 25.0]  episode_count: 7405 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -7.015, -9.796, -7.365]
Step 2886 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 50.0, 1.0, 25.0]  episode_count: 7410 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.875, -9.796, -7.365]
Step 2887 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 51.0, 1.0, 25.0]  episode_count: 7411 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.74, -9.796, -7.365]
{"total_number_of_episodes": 7413, "number_of_timesteps": 129647, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2888 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 52.0, 1.0, 25.0]  episode_count: 7413 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.799, -9.796, -7.365]
Step 2889 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 53.0, 1.0, 25.0]  episode_count: 7418 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.856, -9.796, -7.365]
Step 2890 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 54.0, 1.0, 25.0]  episode_count: 7419 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.729, -9.796, -7.365]
{"total_number_of_episodes": 7425, "number_of_timesteps": 129842, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2891 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 55.0, 1.0, 25.0]  episode_count: 7425 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.606, -9.796, -7.365]
Step 2892 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 56.0, 1.0, 25.0]  episode_count: 7429 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.663, -9.796, -7.365]
Step 2893 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 57.0, 1.0, 25.0]  episode_count: 7430 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.718, -9.796, -7.365]
Step 2894 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 58.0, 1.0, 25.0]  episode_count: 7434 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.771, -9.796, -7.365]
{"total_number_of_episodes": 7438, "number_of_timesteps": 130010, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2895 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 59.0, 1.0, 25.0]  episode_count: 7438 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.657, -9.796, -7.365]
Step 2896 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 60.0, 1.0, 25.0]  episode_count: 7438 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.546, -9.796, -7.365]
Step 2897 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 61.0, 1.0, 25.0]  episode_count: 7443 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.438, -9.796, -7.365]
Step 2898 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 62.0, 1.0, 25.0]  episode_count: 7445 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.492, -9.796, -7.365]
Step 2899 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 63.0, 1.0, 25.0]  episode_count: 7447 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.545, -9.796, -7.365]
{"total_number_of_episodes": 7449, "number_of_timesteps": 130174, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2900 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 64.0, 1.0, 25.0]  episode_count: 7449 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.443, -9.796, -7.365]
Step 2901 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 65.0, 1.0, 25.0]  episode_count: 7450 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.494, -9.796, -7.365]
Step 2902 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 66.0, 1.0, 25.0]  episode_count: 7455 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.544, -9.796, -7.365]
Step 2903 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 67.0, 1.0, 25.0]  episode_count: 7457 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.447, -9.796, -7.365]
{"total_number_of_episodes": 7460, "number_of_timesteps": 130355, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2904 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 68.0, 1.0, 25.0]  episode_count: 7460 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.495, -9.796, -7.365]
Step 2905 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 69.0, 1.0, 25.0]  episode_count: 7463 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.756, -9.796, -7.365]
Step 2906 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 70.0, 1.0, 25.0]  episode_count: 7464 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.659, -9.796, -7.365]
Step 2907 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 71.0, 1.0, 25.0]  episode_count: 7467 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.703, -9.796, -7.365]
Step 2908 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 72.0, 1.0, 25.0]  episode_count: 7468 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.746, -9.796, -7.365]
{"total_number_of_episodes": 7472, "number_of_timesteps": 130608, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2909 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 73.0, 1.0, 25.0]  episode_count: 7472 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.78, -9.796, -7.365]
Step 2910 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 74.0, 1.0, 25.0]  episode_count: 7475 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.809, -9.796, -7.365]
Step 2911 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 75.0, 1.0, 25.0]  episode_count: 7478 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.718, -9.796, -7.365]
Step 2912 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 76.0, 1.0, 25.0]  episode_count: 7481 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.935, -9.796, -7.365]
{"total_number_of_episodes": 7482, "number_of_timesteps": 130784, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2913 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 77.0, 1.0, 25.0]  episode_count: 7482 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.967, -9.796, -7.365]
Step 2914 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 78.0, 1.0, 25.0]  episode_count: 7484 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.877, -9.796, -7.365]
Step 2915 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 79.0, 1.0, 25.0]  episode_count: 7485 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.79, -9.796, -7.365]
Step 2916 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 80.0, 1.0, 25.0]  episode_count: 7491 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.828, -9.796, -7.365]
{"total_number_of_episodes": 7494, "number_of_timesteps": 131014, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2917 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 81.0, 1.0, 25.0]  episode_count: 7494 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.743, -9.796, -7.365]
Step 2918 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 82.0, 1.0, 25.0]  episode_count: 7496 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.96, -9.796, -7.365]
Step 2919 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 83.0, 1.0, 25.0]  episode_count: 7500 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.994, -9.796, -7.365]
Step 2920 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 84.0, 1.0, 25.0]  episode_count: 7501 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -7.027, -9.796, -7.365]
Step 2921 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 85.0, 1.0, 25.0]  episode_count: 7503 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -7.06, -9.796, -7.365]
{"total_number_of_episodes": 7508, "number_of_timesteps": 131225, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2922 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 86.0, 1.0, 25.0]  episode_count: 7508 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -7.085, -9.796, -7.365]
Step 2923 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 87.0, 1.0, 25.0]  episode_count: 7510 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -7.003, -9.796, -7.365]
Step 2924 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 88.0, 1.0, 25.0]  episode_count: 7516 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -7.035, -9.796, -7.365]
{"total_number_of_episodes": 7518, "number_of_timesteps": 131371, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2925 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 89.0, 1.0, 25.0]  episode_count: 7518 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -7.066, -9.796, -7.365]
Step 2926 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 90.0, 1.0, 25.0]  episode_count: 7519 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -6.988, -9.796, -7.365]
Step 2927 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 9.0, 4.0, 91.0, 1.0, 25.0]  episode_count: 7524 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -7.597, -11.02, -7.18, -9.796, -7.365]
Step 2928 5 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 91.0, 1.0, 25.0]  episode_count: 7527 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.18, -9.796, -7.365]
{"total_number_of_episodes": 7530, "number_of_timesteps": 131522, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2929 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 91.0, 1.0, 26.0]  episode_count: 7530 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.18, -9.796, -7.426]
Step 2930 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 92.0, 1.0, 26.0]  episode_count: 7533 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.102, -9.796, -7.426]
Step 2931 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 93.0, 1.0, 26.0]  episode_count: 7538 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.119, -9.796, -7.426]
{"total_number_of_episodes": 7541, "number_of_timesteps": 131688, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2932 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 94.0, 1.0, 26.0]  episode_count: 7541 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.147, -9.796, -7.426]
Step 2933 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 95.0, 1.0, 26.0]  episode_count: 7544 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.072, -9.796, -7.426]
Step 2934 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 96.0, 1.0, 26.0]  episode_count: 7549 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.094, -9.796, -7.426]
{"total_number_of_episodes": 7552, "number_of_timesteps": 131814, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2935 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 97.0, 1.0, 26.0]  episode_count: 7552 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.122, -9.796, -7.426]
Step 2936 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 98.0, 1.0, 26.0]  episode_count: 7556 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.049, -9.796, -7.426]
Step 2937 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 99.0, 1.0, 26.0]  episode_count: 7560 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.077, -9.796, -7.426]
{"total_number_of_episodes": 7563, "number_of_timesteps": 131936, "per_episode_reward": 11.45, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2938 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 100.0, 1.0, 26.0]  episode_count: 7563 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.104, -9.796, -7.426]
Step 2939 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 101.0, 1.0, 26.0]  episode_count: 7566 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.034, -9.796, -7.426]
Step 2940 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 102.0, 1.0, 26.0]  episode_count: 7571 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.965, -9.796, -7.426]
{"total_number_of_episodes": 7573, "number_of_timesteps": 132061, "per_episode_reward": 11.45, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2941 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 103.0, 1.0, 26.0]  episode_count: 7573 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.897, -9.796, -7.426]
Step 2942 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 104.0, 1.0, 26.0]  episode_count: 7578 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.925, -9.796, -7.426]
Step 2943 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 105.0, 1.0, 26.0]  episode_count: 7581 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.859, -9.796, -7.426]
{"total_number_of_episodes": 7584, "number_of_timesteps": 132196, "per_episode_reward": 11.45, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2944 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 106.0, 1.0, 26.0]  episode_count: 7584 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.887, -9.796, -7.426]
Step 2945 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 107.0, 1.0, 26.0]  episode_count: 7588 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.822, -9.796, -7.426]
Step 2946 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 108.0, 1.0, 26.0]  episode_count: 7592 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.85, -9.796, -7.426]
{"total_number_of_episodes": 7596, "number_of_timesteps": 132335, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2947 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 109.0, 1.0, 26.0]  episode_count: 7596 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.787, -9.796, -7.426]
Step 2948 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 110.0, 1.0, 26.0]  episode_count: 7597 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.725, -9.796, -7.426]
Step 2949 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 111.0, 1.0, 26.0]  episode_count: 7603 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.752, -9.796, -7.426]
{"total_number_of_episodes": 7606, "number_of_timesteps": 132465, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2950 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 112.0, 1.0, 26.0]  episode_count: 7606 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.779, -9.796, -7.426]
Step 2951 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 113.0, 1.0, 26.0]  episode_count: 7610 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.806, -9.796, -7.426]
Step 2952 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 114.0, 1.0, 26.0]  episode_count: 7613 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.831, -9.796, -7.426]
{"total_number_of_episodes": 7616, "number_of_timesteps": 132575, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2953 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 115.0, 1.0, 26.0]  episode_count: 7616 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.772, -9.796, -7.426]
Step 2954 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 116.0, 1.0, 26.0]  episode_count: 7621 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.798, -9.796, -7.426]
Step 2955 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 117.0, 1.0, 26.0]  episode_count: 7622 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.949, -9.796, -7.426]
{"total_number_of_episodes": 7626, "number_of_timesteps": 132704, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2956 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 118.0, 1.0, 26.0]  episode_count: 7626 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.89, -9.796, -7.426]
Step 2957 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 119.0, 1.0, 26.0]  episode_count: 7631 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.908, -9.796, -7.426]
Step 2958 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 120.0, 1.0, 26.0]  episode_count: 7633 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.85, -9.796, -7.426]
{"total_number_of_episodes": 7636, "number_of_timesteps": 132840, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2959 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 121.0, 1.0, 26.0]  episode_count: 7636 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.794, -9.796, -7.426]
Step 2960 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 122.0, 1.0, 26.0]  episode_count: 7641 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.738, -9.796, -7.426]
Step 2961 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 123.0, 1.0, 26.0]  episode_count: 7643 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.763, -9.796, -7.426]
{"total_number_of_episodes": 7647, "number_of_timesteps": 132982, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2962 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 124.0, 1.0, 26.0]  episode_count: 7647 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.906, -9.796, -7.426]
Step 2963 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 125.0, 1.0, 26.0]  episode_count: 7652 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.922, -9.796, -7.426]
Step 2964 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 126.0, 1.0, 26.0]  episode_count: 7655 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.062, -9.796, -7.426]
{"total_number_of_episodes": 7657, "number_of_timesteps": 133101, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 2965 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 127.0, 1.0, 26.0]  episode_count: 7657 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.006, -9.796, -7.426]
Step 2966 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 128.0, 1.0, 26.0]  episode_count: 7662 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.028, -9.796, -7.426]
Step 2967 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 129.0, 1.0, 26.0]  episode_count: 7665 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.05, -9.796, -7.426]
{"total_number_of_episodes": 7668, "number_of_timesteps": 133230, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 2968 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 130.0, 1.0, 26.0]  episode_count: 7668 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.071, -9.796, -7.426]
Step 2969 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 131.0, 1.0, 26.0]  episode_count: 7672 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.091, -9.796, -7.426]
Step 2970 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 132.0, 1.0, 26.0]  episode_count: 7674 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.112, -9.796, -7.426]
{"total_number_of_episodes": 7678, "number_of_timesteps": 133350, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 2971 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 133.0, 1.0, 26.0]  episode_count: 7678 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.058, -9.796, -7.426]
Step 2972 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 134.0, 1.0, 26.0]  episode_count: 7682 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.079, -9.796, -7.426]
Step 2973 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 135.0, 1.0, 26.0]  episode_count: 7683 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.094, -9.796, -7.426]
Step 2974 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 136.0, 1.0, 26.0]  episode_count: 7686 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.042, -9.796, -7.426]
Step 2975 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 137.0, 1.0, 26.0]  episode_count: 7687 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.055, -9.796, -7.426]
{"total_number_of_episodes": 7688, "number_of_timesteps": 133485, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2976 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 138.0, 1.0, 26.0]  episode_count: 7688 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.033, -9.796, -7.426]
Step 2977 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 139.0, 1.0, 26.0]  episode_count: 7693 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.053, -9.796, -7.426]
Step 2978 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 140.0, 1.0, 26.0]  episode_count: 7695 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.176, -9.796, -7.426]
Step 2979 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 140.0, 1.0, 27.0]  episode_count: 7696 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.176, -9.796, -7.514]
{"total_number_of_episodes": 7700, "number_of_timesteps": 133739, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2980 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 141.0, 1.0, 27.0]  episode_count: 7700 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.193, -9.796, -7.514]
Step 2981 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 142.0, 1.0, 27.0]  episode_count: 7702 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.211, -9.796, -7.514]
Step 2982 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 143.0, 1.0, 27.0]  episode_count: 7703 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.16, -9.796, -7.514]
Step 2983 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 144.0, 1.0, 27.0]  episode_count: 7706 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.179, -9.796, -7.514]
Step 2984 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 145.0, 1.0, 27.0]  episode_count: 7708 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.197, -9.796, -7.514]
Step 2985 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 146.0, 1.0, 27.0]  episode_count: 7709 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.215, -9.796, -7.514]
Step 2986 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 147.0, 1.0, 27.0]  episode_count: 7709 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.166, -9.796, -7.514]
{"total_number_of_episodes": 7713, "number_of_timesteps": 133996, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2987 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 148.0, 1.0, 27.0]  episode_count: 7713 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.169, -9.796, -7.514]
Step 2988 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 149.0, 1.0, 27.0]  episode_count: 7714 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.185, -9.796, -7.514]
Step 2989 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 150.0, 1.0, 27.0]  episode_count: 7715 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.203, -9.796, -7.514]
Step 2990 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 151.0, 1.0, 27.0]  episode_count: 7720 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.219, -9.796, -7.514]
Step 2991 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 152.0, 1.0, 27.0]  episode_count: 7722 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.171, -9.796, -7.514]
{"total_number_of_episodes": 7723, "number_of_timesteps": 134253, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2992 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 153.0, 1.0, 27.0]  episode_count: 7723 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.188, -9.796, -7.514]
Step 2993 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 154.0, 1.0, 27.0]  episode_count: 7726 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.141, -9.796, -7.514]
Step 2994 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 155.0, 1.0, 27.0]  episode_count: 7727 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.159, -9.796, -7.514]
Step 2995 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 156.0, 1.0, 27.0]  episode_count: 7731 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.113, -9.796, -7.514]
{"total_number_of_episodes": 7734, "number_of_timesteps": 134467, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2996 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 157.0, 1.0, 27.0]  episode_count: 7734 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.13, -9.796, -7.514]
Step 2997 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 158.0, 1.0, 27.0]  episode_count: 7735 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.147, -9.796, -7.514]
Step 2998 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 159.0, 1.0, 27.0]  episode_count: 7738 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.102, -9.796, -7.514]
Step 2999 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 160.0, 1.0, 27.0]  episode_count: 7741 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.115, -9.796, -7.514]
Step 3000 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 161.0, 1.0, 27.0]  episode_count: 7742 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.071, -9.796, -7.514]
{"total_number_of_episodes": 7745, "number_of_timesteps": 134670, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3001 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 162.0, 1.0, 27.0]  episode_count: 7745 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.088, -9.796, -7.514]
Step 3002 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 163.0, 1.0, 27.0]  episode_count: 7747 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.044, -9.796, -7.514]
Step 3003 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 164.0, 1.0, 27.0]  episode_count: 7748 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.061, -9.796, -7.514]
Step 3004 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 165.0, 1.0, 27.0]  episode_count: 7752 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.077, -9.796, -7.514]
Step 3005 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 166.0, 1.0, 27.0]  episode_count: 7754 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.035, -9.796, -7.514]
{"total_number_of_episodes": 7755, "number_of_timesteps": 134857, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3006 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 167.0, 1.0, 27.0]  episode_count: 7755 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.993, -9.796, -7.514]
Step 3007 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 168.0, 1.0, 27.0]  episode_count: 7758 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.951, -9.796, -7.514]
Step 3008 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 169.0, 1.0, 27.0]  episode_count: 7759 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.968, -9.796, -7.514]
Step 3009 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 170.0, 1.0, 27.0]  episode_count: 7762 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.927, -9.796, -7.514]
{"total_number_of_episodes": 7766, "number_of_timesteps": 135121, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3010 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 171.0, 1.0, 27.0]  episode_count: 7766 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.944, -9.796, -7.514]
Step 3011 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 172.0, 1.0, 27.0]  episode_count: 7767 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.96, -9.796, -7.514]
Step 3012 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 173.0, 1.0, 27.0]  episode_count: 7767 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.977, -9.796, -7.514]
Step 3013 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 174.0, 1.0, 27.0]  episode_count: 7769 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.993, -9.796, -7.514]
Step 3014 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 175.0, 1.0, 27.0]  episode_count: 7772 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.008, -9.796, -7.514]
Step 3015 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 176.0, 1.0, 27.0]  episode_count: 7773 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.968, -9.796, -7.514]
Step 3016 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 177.0, 1.0, 27.0]  episode_count: 7775 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.984, -9.796, -7.514]
{"total_number_of_episodes": 7778, "number_of_timesteps": 135369, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3017 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 178.0, 1.0, 27.0]  episode_count: 7778 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.0, -9.796, -7.514]
Step 3018 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 179.0, 1.0, 27.0]  episode_count: 7780 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.016, -9.796, -7.514]
Step 3019 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 180.0, 1.0, 27.0]  episode_count: 7781 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.031, -9.796, -7.514]
Step 3020 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 181.0, 1.0, 27.0]  episode_count: 7783 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.047, -9.796, -7.514]
Step 3021 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 182.0, 1.0, 27.0]  episode_count: 7784 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.062, -9.796, -7.514]
Step 3022 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 183.0, 1.0, 27.0]  episode_count: 7786 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.023, -9.796, -7.514]
Step 3023 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 184.0, 1.0, 27.0]  episode_count: 7787 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.038, -9.796, -7.514]
{"total_number_of_episodes": 7793, "number_of_timesteps": 135765, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3024 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 185.0, 1.0, 27.0]  episode_count: 7793 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.049, -9.796, -7.514]
Step 3025 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 186.0, 1.0, 27.0]  episode_count: 7795 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.063, -9.796, -7.514]
Step 3026 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 187.0, 1.0, 27.0]  episode_count: 7796 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.078, -9.796, -7.514]
Step 3027 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 188.0, 1.0, 27.0]  episode_count: 7801 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.04, -9.796, -7.514]
{"total_number_of_episodes": 7803, "number_of_timesteps": 135916, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3028 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 189.0, 1.0, 27.0]  episode_count: 7803 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.055, -9.796, -7.514]
Step 3029 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 190.0, 1.0, 27.0]  episode_count: 7803 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.064, -9.796, -7.514]
Step 3030 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 191.0, 1.0, 27.0]  episode_count: 7807 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.028, -9.796, -7.514]
Step 3031 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 192.0, 1.0, 27.0]  episode_count: 7812 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.991, -9.796, -7.514]
{"total_number_of_episodes": 7813, "number_of_timesteps": 136102, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3032 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 193.0, 1.0, 27.0]  episode_count: 7813 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.005, -9.796, -7.514]
Step 3033 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 194.0, 1.0, 27.0]  episode_count: 7816 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.014, -9.796, -7.514]
Step 3034 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 195.0, 1.0, 27.0]  episode_count: 7819 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.021, -9.796, -7.514]
{"total_number_of_episodes": 7823, "number_of_timesteps": 136230, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3035 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 196.0, 1.0, 27.0]  episode_count: 7823 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.035, -9.796, -7.514]
Step 3036 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 197.0, 1.0, 27.0]  episode_count: 7825 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.049, -9.796, -7.514]
Step 3037 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 198.0, 1.0, 27.0]  episode_count: 7827 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.063, -9.796, -7.514]
Step 3038 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 199.0, 1.0, 27.0]  episode_count: 7832 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.077, -9.796, -7.514]
{"total_number_of_episodes": 7835, "number_of_timesteps": 136405, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3039 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 200.0, 1.0, 27.0]  episode_count: 7835 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.087, -9.796, -7.514]
Step 3040 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 201.0, 1.0, 27.0]  episode_count: 7836 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.052, -9.796, -7.514]
Step 3041 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 202.0, 1.0, 27.0]  episode_count: 7841 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.017, -9.796, -7.514]
{"total_number_of_episodes": 7846, "number_of_timesteps": 136570, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3042 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 203.0, 1.0, 27.0]  episode_count: 7846 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.028, -9.796, -7.514]
Step 3043 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 204.0, 1.0, 27.0]  episode_count: 7849 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.113, -9.796, -7.514]
Step 3044 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 205.0, 1.0, 27.0]  episode_count: 7855 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.079, -9.796, -7.514]
{"total_number_of_episodes": 7858, "number_of_timesteps": 136697, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3045 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 206.0, 1.0, 27.0]  episode_count: 7858 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.088, -9.796, -7.514]
Step 3046 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 207.0, 1.0, 27.0]  episode_count: 7862 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.054, -9.796, -7.514]
Step 3047 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 208.0, 1.0, 27.0]  episode_count: 7867 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.067, -9.796, -7.514]
{"total_number_of_episodes": 7871, "number_of_timesteps": 136837, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3048 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 209.0, 1.0, 27.0]  episode_count: 7871 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.033, -9.796, -7.514]
Step 3049 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 210.0, 1.0, 27.0]  episode_count: 7873 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.044, -9.796, -7.514]
Step 3050 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 211.0, 1.0, 27.0]  episode_count: 7879 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.053, -9.796, -7.514]
{"total_number_of_episodes": 7883, "number_of_timesteps": 136970, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3051 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 212.0, 1.0, 27.0]  episode_count: 7883 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.02, -9.796, -7.514]
Step 3052 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 213.0, 1.0, 27.0]  episode_count: 7887 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.987, -9.796, -7.514]
Step 3053 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 214.0, 1.0, 27.0]  episode_count: 7888 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.954, -9.796, -7.514]
{"total_number_of_episodes": 7896, "number_of_timesteps": 137119, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3054 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 215.0, 1.0, 27.0]  episode_count: 7896 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.963, -9.796, -7.514]
Step 3055 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 216.0, 1.0, 27.0]  episode_count: 7898 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.032, -9.796, -7.514]
Step 3056 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 217.0, 1.0, 27.0]  episode_count: 7904 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.108, -9.796, -7.514]
{"total_number_of_episodes": 7907, "number_of_timesteps": 137225, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3057 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 218.0, 1.0, 27.0]  episode_count: 7907 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.117, -9.796, -7.514]
Step 3058 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 219.0, 1.0, 27.0]  episode_count: 7911 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.186, -9.796, -7.514]
Step 3059 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 220.0, 1.0, 27.0]  episode_count: 7915 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.196, -9.796, -7.514]
{"total_number_of_episodes": 7920, "number_of_timesteps": 137365, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3060 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 221.0, 1.0, 27.0]  episode_count: 7920 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.163, -9.796, -7.514]
Step 3061 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 222.0, 1.0, 27.0]  episode_count: 7924 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.168, -9.796, -7.514]
Step 3062 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 223.0, 1.0, 27.0]  episode_count: 7927 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.18, -9.796, -7.514]
{"total_number_of_episodes": 7933, "number_of_timesteps": 137496, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3063 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 224.0, 1.0, 27.0]  episode_count: 7933 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.187, -9.796, -7.514]
Step 3064 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 225.0, 1.0, 27.0]  episode_count: 7935 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.155, -9.796, -7.514]
Step 3065 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 27.0]  episode_count: 7937 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -7.514]
{"total_number_of_episodes": 7943, "number_of_timesteps": 137610, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3066 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 28.0]  episode_count: 7943 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -7.245]
Step 3067 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 29.0]  episode_count: 7945 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -7.333]
Step 3068 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 30.0]  episode_count: 7950 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -7.382]
{"total_number_of_episodes": 7954, "number_of_timesteps": 137735, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3069 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 31.0]  episode_count: 7954 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -7.423]
Step 3070 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 32.0]  episode_count: 7956 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -7.191]
Step 3071 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 33.0]  episode_count: 7963 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -6.973]
{"total_number_of_episodes": 7965, "number_of_timesteps": 137862, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3072 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 34.0]  episode_count: 7965 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -7.056]
Step 3073 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 35.0]  episode_count: 7970 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -6.855]
Step 3074 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 36.0]  episode_count: 7974 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -6.937]
{"total_number_of_episodes": 7977, "number_of_timesteps": 137988, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3075 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 37.0]  episode_count: 7977 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -6.988]
Step 3076 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 38.0]  episode_count: 7983 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -7.047]
Step 3077 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 39.0]  episode_count: 7985 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -7.064]
{"total_number_of_episodes": 7989, "number_of_timesteps": 138120, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3078 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 40.0]  episode_count: 7989 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -7.132]
Step 3079 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 226.0, 1.0, 41.0]  episode_count: 7994 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.232, -9.796, -7.504]
Step 3080 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 227.0, 1.0, 41.0]  episode_count: 7996 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.243, -9.796, -7.504]
{"total_number_of_episodes": 8001, "number_of_timesteps": 138253, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3081 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 228.0, 1.0, 41.0]  episode_count: 8001 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.249, -9.796, -7.504]
Step 3082 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 229.0, 1.0, 41.0]  episode_count: 8005 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.217, -9.796, -7.504]
Step 3083 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 230.0, 1.0, 41.0]  episode_count: 8008 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.224, -9.796, -7.504]
{"total_number_of_episodes": 8013, "number_of_timesteps": 138389, "per_episode_reward": 11.35, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3084 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 231.0, 1.0, 41.0]  episode_count: 8013 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.289, -9.796, -7.504]
Step 3085 9 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 231.0, 1.0, 42.0]  episode_count: 8018 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.289, -9.796, -7.81]
Step 3086 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 232.0, 1.0, 42.0]  episode_count: 8019 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.258, -9.796, -7.81]
{"total_number_of_episodes": 8027, "number_of_timesteps": 138534, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3087 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 233.0, 1.0, 42.0]  episode_count: 8027 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.267, -9.796, -7.81]
Step 3088 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 234.0, 1.0, 42.0]  episode_count: 8028 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.273, -9.796, -7.81]
Step 3089 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 235.0, 1.0, 42.0]  episode_count: 8031 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.28, -9.796, -7.81]
Step 3090 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 236.0, 1.0, 42.0]  episode_count: 8036 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.249, -9.796, -7.81]
{"total_number_of_episodes": 8039, "number_of_timesteps": 138678, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3091 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 237.0, 1.0, 42.0]  episode_count: 8039 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.219, -9.796, -7.81]
Step 3092 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 238.0, 1.0, 42.0]  episode_count: 8041 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.229, -9.796, -7.81]
q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.24, -9.796, -7.81]
{"total_number_of_episodes": 8049, "number_of_timesteps": 138808, "per_episode_reward": 11.35, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3094 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 240.0, 1.0, 42.0]  episode_count: 8049 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.251, -9.796, -7.81]
Step 3095 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 241.0, 1.0, 42.0]  episode_count: 8054 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.221, -9.796, -7.81]
Step 3096 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 242.0, 1.0, 42.0]  episode_count: 8058 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.227, -9.796, -7.81]
{"total_number_of_episodes": 8060, "number_of_timesteps": 138928, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3097 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 243.0, 1.0, 42.0]  episode_count: 8060 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.234, -9.796, -7.81]
Step 3098 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 244.0, 1.0, 42.0]  episode_count: 8065 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.204, -9.796, -7.81]
{"total_number_of_episodes": 8070, "number_of_timesteps": 139048, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3099 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 245.0, 1.0, 42.0]  episode_count: 8070 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.212, -9.796, -7.81]
Step 3100 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 246.0, 1.0, 42.0]  episode_count: 8071 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.182, -9.796, -7.81]
Step 3101 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 247.0, 1.0, 42.0]  episode_count: 8078 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.188, -9.796, -7.81]
Step 3102 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 248.0, 1.0, 42.0]  episode_count: 8079 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.196, -9.796, -7.81]
{"total_number_of_episodes": 8082, "number_of_timesteps": 139188, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3103 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 249.0, 1.0, 42.0]  episode_count: 8082 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.167, -9.796, -7.81]
Step 3104 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 250.0, 1.0, 42.0]  episode_count: 8086 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.139, -9.796, -7.81]
Step 3105 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 251.0, 1.0, 42.0]  episode_count: 8088 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.11, -9.796, -7.81]
{"total_number_of_episodes": 8092, "number_of_timesteps": 139321, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3106 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 252.0, 1.0, 42.0]  episode_count: 8092 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.121, -9.796, -7.81]
Step 3107 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 253.0, 1.0, 42.0]  episode_count: 8098 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.132, -9.796, -7.81]
Step 3108 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 254.0, 1.0, 42.0]  episode_count: 8101 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.138, -9.796, -7.81]
{"total_number_of_episodes": 8104, "number_of_timesteps": 139464, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3109 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 255.0, 1.0, 42.0]  episode_count: 8104 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.11, -9.796, -7.81]
Step 3110 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 256.0, 1.0, 42.0]  episode_count: 8110 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.082, -9.796, -7.81]
Step 3111 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 257.0, 1.0, 42.0]  episode_count: 8112 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.055, -9.796, -7.81]
{"total_number_of_episodes": 8117, "number_of_timesteps": 139612, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3112 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 258.0, 1.0, 42.0]  episode_count: 8117 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.027, -9.796, -7.81]
Step 3113 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 259.0, 1.0, 42.0]  episode_count: 8121 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.036, -9.796, -7.81]
Step 3114 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 260.0, 1.0, 42.0]  episode_count: 8125 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.042, -9.796, -7.81]
{"total_number_of_episodes": 8129, "number_of_timesteps": 139750, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3115 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 261.0, 1.0, 42.0]  episode_count: 8129 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.048, -9.796, -7.81]
Step 3116 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 262.0, 1.0, 42.0]  episode_count: 8130 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.052, -9.796, -7.81]
Step 3117 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 263.0, 1.0, 42.0]  episode_count: 8135 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.025, -9.796, -7.81]
Step 3118 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 264.0, 1.0, 42.0]  episode_count: 8138 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.999, -9.796, -7.81]
{"total_number_of_episodes": 8140, "number_of_timesteps": 139892, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3119 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 265.0, 1.0, 42.0]  episode_count: 8140 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.009, -9.796, -7.81]
Step 3120 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 266.0, 1.0, 42.0]  episode_count: 8145 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.02, -9.796, -7.81]
Step 3121 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 267.0, 1.0, 42.0]  episode_count: 8148 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.027, -9.796, -7.81]
{"total_number_of_episodes": 8151, "number_of_timesteps": 140043, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3122 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 268.0, 1.0, 42.0]  episode_count: 8151 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.001, -9.796, -7.81]
Step 3123 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 269.0, 1.0, 42.0]  episode_count: 8154 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.011, -9.796, -7.81]
Step 3124 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 270.0, 1.0, 42.0]  episode_count: 8159 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.021, -9.796, -7.81]
Step 3125 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 271.0, 1.0, 42.0]  episode_count: 8159 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.995, -9.796, -7.81]
{"total_number_of_episodes": 8163, "number_of_timesteps": 140193, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3126 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 272.0, 1.0, 42.0]  episode_count: 8163 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.969, -9.796, -7.81]
Step 3127 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 273.0, 1.0, 42.0]  episode_count: 8167 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.944, -9.796, -7.81]
Step 3128 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 274.0, 1.0, 42.0]  episode_count: 8169 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.918, -9.796, -7.81]
{"total_number_of_episodes": 8174, "number_of_timesteps": 140351, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3129 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 275.0, 1.0, 42.0]  episode_count: 8174 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.925, -9.796, -7.81]
Step 3130 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 276.0, 1.0, 42.0]  episode_count: 8175 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.935, -9.796, -7.81]
Step 3131 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 277.0, 1.0, 42.0]  episode_count: 8178 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.91, -9.796, -7.81]
Step 3132 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 278.0, 1.0, 42.0]  episode_count: 8179 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.921, -9.796, -7.81]
{"total_number_of_episodes": 8185, "number_of_timesteps": 140509, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3133 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 279.0, 1.0, 42.0]  episode_count: 8185 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.926, -9.796, -7.81]
Step 3134 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 280.0, 1.0, 42.0]  episode_count: 8188 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.935, -9.796, -7.81]
Step 3135 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 281.0, 1.0, 42.0]  episode_count: 8191 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.945, -9.796, -7.81]
Step 3136 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 282.0, 1.0, 42.0]  episode_count: 8192 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.956, -9.796, -7.81]
Step 3137 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 283.0, 1.0, 42.0]  episode_count: 8194 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.017, -9.796, -7.81]
{"total_number_of_episodes": 8196, "number_of_timesteps": 140675, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3138 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 284.0, 1.0, 42.0]  episode_count: 8196 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.027, -9.796, -7.81]
Step 3139 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 285.0, 1.0, 42.0]  episode_count: 8198 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.003, -9.796, -7.81]
Step 3140 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 286.0, 1.0, 42.0]  episode_count: 8200 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.012, -9.796, -7.81]
Step 3141 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 287.0, 1.0, 42.0]  episode_count: 8203 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.988, -9.796, -7.81]
Step 3142 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 288.0, 1.0, 42.0]  episode_count: 8204 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.049, -9.796, -7.81]
Step 3143 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 289.0, 1.0, 42.0]  episode_count: 8205 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.024, -9.796, -7.81]
{"total_number_of_episodes": 8209, "number_of_timesteps": 140926, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3144 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 290.0, 1.0, 42.0]  episode_count: 8209 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.029, -9.796, -7.81]
Step 3145 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 291.0, 1.0, 42.0]  episode_count: 8210 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.038, -9.796, -7.81]
Step 3146 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 292.0, 1.0, 42.0]  episode_count: 8210 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.014, -9.796, -7.81]
Step 3147 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 293.0, 1.0, 42.0]  episode_count: 8213 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.02, -9.796, -7.81]
Step 3148 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 294.0, 1.0, 42.0]  episode_count: 8215 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.996, -9.796, -7.81]
Step 3149 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 295.0, 1.0, 42.0]  episode_count: 8217 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.006, -9.796, -7.81]
{"total_number_of_episodes": 8221, "number_of_timesteps": 141248, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3150 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 296.0, 1.0, 42.0]  episode_count: 8221 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.012, -9.796, -7.81]
Step 3151 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 297.0, 1.0, 42.0]  episode_count: 8222 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.011, -9.796, -7.81]
Step 3152 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 298.0, 1.0, 42.0]  episode_count: 8223 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.02, -9.796, -7.81]
Step 3153 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 299.0, 1.0, 42.0]  episode_count: 8226 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.996, -9.796, -7.81]
Step 3154 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 300.0, 1.0, 42.0]  episode_count: 8230 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.005, -9.796, -7.81]
{"total_number_of_episodes": 8231, "number_of_timesteps": 141477, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3155 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 301.0, 1.0, 42.0]  episode_count: 8231 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.982, -9.796, -7.81]
Step 3156 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 302.0, 1.0, 42.0]  episode_count: 8235 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.991, -9.796, -7.81]
Step 3157 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 303.0, 1.0, 42.0]  episode_count: 8237 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.997, -9.796, -7.81]
{"total_number_of_episodes": 8241, "number_of_timesteps": 141664, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3158 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 304.0, 1.0, 42.0]  episode_count: 8241 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.006, -9.796, -7.81]
Step 3159 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 305.0, 1.0, 42.0]  episode_count: 8243 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.983, -9.796, -7.81]
Step 3160 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 306.0, 1.0, 42.0]  episode_count: 8245 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.96, -9.796, -7.81]
Step 3161 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 307.0, 1.0, 42.0]  episode_count: 8249 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.941, -9.796, -7.81]
{"total_number_of_episodes": 8252, "number_of_timesteps": 141838, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3162 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 308.0, 1.0, 42.0]  episode_count: 8252 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.95, -9.796, -7.81]
Step 3163 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 309.0, 1.0, 42.0]  episode_count: 8254 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.956, -9.796, -7.81]
Step 3164 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 310.0, 1.0, 42.0]  episode_count: 8258 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.933, -9.796, -7.81]
Step 3165 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 311.0, 1.0, 42.0]  episode_count: 8260 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.943, -9.796, -7.81]
{"total_number_of_episodes": 8262, "number_of_timesteps": 141989, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3166 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 312.0, 1.0, 42.0]  episode_count: 8262 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.952, -9.796, -7.81]
Step 3167 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 313.0, 1.0, 42.0]  episode_count: 8264 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.961, -9.796, -7.81]
Step 3168 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 314.0, 1.0, 42.0]  episode_count: 8265 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.939, -9.796, -7.81]
Step 3169 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 315.0, 1.0, 42.0]  episode_count: 8268 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.948, -9.796, -7.81]
Step 3170 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 316.0, 1.0, 42.0]  episode_count: 8269 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.926, -9.796, -7.81]
{"total_number_of_episodes": 8272, "number_of_timesteps": 142161, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3171 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 317.0, 1.0, 42.0]  episode_count: 8272 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.935, -9.796, -7.81]
Step 3172 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 318.0, 1.0, 42.0]  episode_count: 8273 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.913, -9.796, -7.81]
Step 3173 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 319.0, 1.0, 42.0]  episode_count: 8275 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.919, -9.796, -7.81]
Step 3174 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 320.0, 1.0, 42.0]  episode_count: 8279 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.928, -9.796, -7.81]
Step 3175 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 321.0, 1.0, 42.0]  episode_count: 8280 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.934, -9.796, -7.81]
{"total_number_of_episodes": 8282, "number_of_timesteps": 142416, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3176 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 322.0, 1.0, 42.0]  episode_count: 8282 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.943, -9.796, -7.81]
Step 3177 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 323.0, 1.0, 42.0]  episode_count: 8284 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.921, -9.796, -7.81]
Step 3178 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 324.0, 1.0, 42.0]  episode_count: 8286 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.927, -9.796, -7.81]
Step 3179 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 325.0, 1.0, 42.0]  episode_count: 8287 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.913, -9.796, -7.81]
Step 3180 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 326.0, 1.0, 42.0]  episode_count: 8289 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.892, -9.796, -7.81]
{"total_number_of_episodes": 8294, "number_of_timesteps": 142661, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3181 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 327.0, 1.0, 42.0]  episode_count: 8294 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.9, -9.796, -7.81]
Step 3182 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 328.0, 1.0, 42.0]  episode_count: 8294 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.909, -9.796, -7.81]
Step 3183 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 329.0, 1.0, 42.0]  episode_count: 8295 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.918, -9.796, -7.81]
Step 3184 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 330.0, 1.0, 42.0]  episode_count: 8298 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.923, -9.796, -7.81]
Step 3185 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 331.0, 1.0, 42.0]  episode_count: 8299 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -6.976, -9.796, -7.81]
Step 3186 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 332.0, 1.0, 42.0]  episode_count: 8302 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.029, -9.796, -7.81]
{"total_number_of_episodes": 8305, "number_of_timesteps": 142903, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3187 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 333.0, 1.0, 42.0]  episode_count: 8305 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.073, -9.796, -7.81]
Step 3188 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 334.0, 1.0, 42.0]  episode_count: 8306 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.081, -9.796, -7.81]
Step 3189 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 335.0, 1.0, 42.0]  episode_count: 8309 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.089, -9.796, -7.81]
Step 3190 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 336.0, 1.0, 42.0]  episode_count: 8313 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.136, -9.796, -7.81]
Step 3191 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 337.0, 1.0, 42.0]  episode_count: 8313 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.115, -9.796, -7.81]
{"total_number_of_episodes": 8320, "number_of_timesteps": 143229, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3192 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 338.0, 1.0, 42.0]  episode_count: 8320 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.119, -9.796, -7.81]
Step 3193 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 339.0, 1.0, 42.0]  episode_count: 8321 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.098, -9.796, -7.81]
Step 3194 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 340.0, 1.0, 42.0]  episode_count: 8322 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.149, -9.796, -7.81]
Step 3195 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 341.0, 1.0, 42.0]  episode_count: 8329 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.199, -9.796, -7.81]
{"total_number_of_episodes": 8330, "number_of_timesteps": 143374, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3196 7 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8330 q_vals: [-inf, -inf, -9.516, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3197 2 visits [1000.0, 1000.0, 2.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8332 q_vals: [-inf, -inf, -4.758, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3198 2 visits [1000.0, 1000.0, 3.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8336 q_vals: [-inf, -inf, -5.864, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3199 2 visits [1000.0, 1000.0, 4.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8338 q_vals: [-inf, -inf, -6.847, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8342, "number_of_timesteps": 143550, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3200 2 visits [1000.0, 1000.0, 5.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8342 q_vals: [-inf, -inf, -7.172, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3201 2 visits [1000.0, 1000.0, 6.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8344 q_vals: [-inf, -inf, -7.347, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3202 2 visits [1000.0, 1000.0, 7.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8348 q_vals: [-inf, -inf, -7.349, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3203 2 visits [1000.0, 1000.0, 8.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8350 q_vals: [-inf, -inf, -6.43, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8354, "number_of_timesteps": 143726, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3204 2 visits [1000.0, 1000.0, 9.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8354 q_vals: [-inf, -inf, -5.716, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3205 2 visits [1000.0, 1000.0, 10.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8357 q_vals: [-inf, -inf, -5.144, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3206 2 visits [1000.0, 1000.0, 11.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8360 q_vals: [-inf, -inf, -5.429, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3207 2 visits [1000.0, 1000.0, 12.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8362 q_vals: [-inf, -inf, -5.655, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8365, "number_of_timesteps": 143878, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3208 2 visits [1000.0, 1000.0, 13.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8365 q_vals: [-inf, -inf, -5.22, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3209 2 visits [1000.0, 1000.0, 14.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8367 q_vals: [-inf, -inf, -5.547, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3210 2 visits [1000.0, 1000.0, 15.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8372 q_vals: [-inf, -inf, -5.749, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8375, "number_of_timesteps": 144034, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3211 2 visits [1000.0, 1000.0, 16.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8375 q_vals: [-inf, -inf, -5.389, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3212 2 visits [1000.0, 1000.0, 17.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8379 q_vals: [-inf, -inf, -5.072, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3213 2 visits [1000.0, 1000.0, 18.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8382 q_vals: [-inf, -inf, -5.25, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8385, "number_of_timesteps": 144152, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3214 2 visits [1000.0, 1000.0, 19.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8385 q_vals: [-inf, -inf, -5.436, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3215 2 visits [1000.0, 1000.0, 20.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8389 q_vals: [-inf, -inf, -5.654, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3216 2 visits [1000.0, 1000.0, 21.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8390 q_vals: [-inf, -inf, -5.851, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3217 2 visits [1000.0, 1000.0, 22.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8394 q_vals: [-inf, -inf, -6.03, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8398, "number_of_timesteps": 144342, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3218 2 visits [1000.0, 1000.0, 23.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8398 q_vals: [-inf, -inf, -6.155, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3219 2 visits [1000.0, 1000.0, 24.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8401 q_vals: [-inf, -inf, -6.259, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3220 2 visits [1000.0, 1000.0, 25.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8404 q_vals: [-inf, -inf, -6.372, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8409, "number_of_timesteps": 144474, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3221 2 visits [1000.0, 1000.0, 26.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8409 q_vals: [-inf, -inf, -6.44, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3222 2 visits [1000.0, 1000.0, 27.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8411 q_vals: [-inf, -inf, -6.202, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3223 2 visits [1000.0, 1000.0, 28.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8417 q_vals: [-inf, -inf, -6.33, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8419, "number_of_timesteps": 144589, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3224 2 visits [1000.0, 1000.0, 29.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8419 q_vals: [-inf, -inf, -6.333, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3225 2 visits [1000.0, 1000.0, 30.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8421 q_vals: [-inf, -inf, -6.121, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3226 2 visits [1000.0, 1000.0, 31.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8425 q_vals: [-inf, -inf, -6.21, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3227 2 visits [1000.0, 1000.0, 32.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8427 q_vals: [-inf, -inf, -6.274, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8431, "number_of_timesteps": 144764, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3228 2 visits [1000.0, 1000.0, 33.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8431 q_vals: [-inf, -inf, -6.336, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3229 2 visits [1000.0, 1000.0, 34.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8435 q_vals: [-inf, -inf, -6.149, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3230 2 visits [1000.0, 1000.0, 35.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8435 q_vals: [-inf, -inf, -6.245, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3231 2 visits [1000.0, 1000.0, 36.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8438 q_vals: [-inf, -inf, -6.343, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8444, "number_of_timesteps": 144959, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3232 2 visits [1000.0, 1000.0, 37.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8444 q_vals: [-inf, -inf, -6.172, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3233 2 visits [1000.0, 1000.0, 38.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8445 q_vals: [-inf, -inf, -6.236, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3234 2 visits [1000.0, 1000.0, 39.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8447 q_vals: [-inf, -inf, -6.294, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3235 2 visits [1000.0, 1000.0, 40.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8448 q_vals: [-inf, -inf, -6.137, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3236 2 visits [1000.0, 1000.0, 41.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8453 q_vals: [-inf, -inf, -6.212, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8454, "number_of_timesteps": 145109, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3237 2 visits [1000.0, 1000.0, 42.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8454 q_vals: [-inf, -inf, -6.297, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3238 2 visits [1000.0, 1000.0, 43.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8456 q_vals: [-inf, -inf, -6.379, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3239 2 visits [1000.0, 1000.0, 44.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8458 q_vals: [-inf, -inf, -6.234, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8464, "number_of_timesteps": 145289, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3240 2 visits [1000.0, 1000.0, 45.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8464 q_vals: [-inf, -inf, -6.095, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3241 2 visits [1000.0, 1000.0, 46.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8465 q_vals: [-inf, -inf, -6.126, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3242 2 visits [1000.0, 1000.0, 47.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8467 q_vals: [-inf, -inf, -5.996, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3243 2 visits [1000.0, 1000.0, 48.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8471 q_vals: [-inf, -inf, -6.068, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3244 2 visits [1000.0, 1000.0, 49.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8472 q_vals: [-inf, -inf, -6.144, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8474, "number_of_timesteps": 145458, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3245 2 visits [1000.0, 1000.0, 50.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8474 q_vals: [-inf, -inf, -6.217, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3246 2 visits [1000.0, 1000.0, 51.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8477 q_vals: [-inf, -inf, -6.095, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3247 2 visits [1000.0, 1000.0, 52.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8477 q_vals: [-inf, -inf, -6.167, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3248 2 visits [1000.0, 1000.0, 53.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8480 q_vals: [-inf, -inf, -6.203, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3249 2 visits [1000.0, 1000.0, 54.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8483 q_vals: [-inf, -inf, -6.088, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3250 2 visits [1000.0, 1000.0, 55.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8483 q_vals: [-inf, -inf, -6.155, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8488, "number_of_timesteps": 145790, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3251 2 visits [1000.0, 1000.0, 56.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8488 q_vals: [-inf, -inf, -6.045, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3252 2 visits [1000.0, 1000.0, 57.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8491 q_vals: [-inf, -inf, -6.085, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3253 2 visits [1000.0, 1000.0, 58.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8492 q_vals: [-inf, -inf, -5.98, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3254 2 visits [1000.0, 1000.0, 59.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8494 q_vals: [-inf, -inf, -5.879, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3255 2 visits [1000.0, 1000.0, 60.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8496 q_vals: [-inf, -inf, -5.781, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3256 2 visits [1000.0, 1000.0, 61.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8496 q_vals: [-inf, -inf, -5.686, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8499, "number_of_timesteps": 145985, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3257 2 visits [1000.0, 1000.0, 62.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8499 q_vals: [-inf, -inf, -5.705, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3258 2 visits [1000.0, 1000.0, 63.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8500 q_vals: [-inf, -inf, -5.77, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3259 2 visits [1000.0, 1000.0, 64.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8504 q_vals: [-inf, -inf, -5.68, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3260 2 visits [1000.0, 1000.0, 65.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8504 q_vals: [-inf, -inf, -5.743, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3261 2 visits [1000.0, 1000.0, 66.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8506 q_vals: [-inf, -inf, -5.656, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8510, "number_of_timesteps": 146270, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3262 2 visits [1000.0, 1000.0, 67.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8510 q_vals: [-inf, -inf, -5.718, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3263 2 visits [1000.0, 1000.0, 68.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8512 q_vals: [-inf, -inf, -5.752, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3264 2 visits [1000.0, 1000.0, 69.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8512 q_vals: [-inf, -inf, -5.793, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3265 2 visits [1000.0, 1000.0, 70.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8515 q_vals: [-inf, -inf, -5.839, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3266 2 visits [1000.0, 1000.0, 71.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8515 q_vals: [-inf, -inf, -5.764, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3267 2 visits [1000.0, 1000.0, 72.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8517 q_vals: [-inf, -inf, -5.795, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8522, "number_of_timesteps": 146551, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3268 2 visits [1000.0, 1000.0, 73.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8522 q_vals: [-inf, -inf, -5.84, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3269 2 visits [1000.0, 1000.0, 74.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8523 q_vals: [-inf, -inf, -5.761, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3270 2 visits [1000.0, 1000.0, 75.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8523 q_vals: [-inf, -inf, -5.685, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3271 2 visits [1000.0, 1000.0, 76.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8524 q_vals: [-inf, -inf, -5.61, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3272 2 visits [1000.0, 1000.0, 77.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8527 q_vals: [-inf, -inf, -5.537, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3273 2 visits [1000.0, 1000.0, 78.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8527 q_vals: [-inf, -inf, -5.592, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3274 2 visits [1000.0, 1000.0, 79.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8530 q_vals: [-inf, -inf, -5.645, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8535, "number_of_timesteps": 146857, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3275 2 visits [1000.0, 1000.0, 80.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8535 q_vals: [-inf, -inf, -5.697, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3276 2 visits [1000.0, 1000.0, 81.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8537 q_vals: [-inf, -inf, -5.747, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3277 2 visits [1000.0, 1000.0, 82.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8538 q_vals: [-inf, -inf, -5.677, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3278 2 visits [1000.0, 1000.0, 83.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8541 q_vals: [-inf, -inf, -5.699, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3279 2 visits [1000.0, 1000.0, 84.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8543 q_vals: [-inf, -inf, -5.72, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8546, "number_of_timesteps": 147092, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3280 2 visits [1000.0, 1000.0, 85.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8546 q_vals: [-inf, -inf, -5.75, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3281 2 visits [1000.0, 1000.0, 86.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8550 q_vals: [-inf, -inf, -5.776, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3282 2 visits [1000.0, 1000.0, 87.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8551 q_vals: [-inf, -inf, -5.822, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3283 2 visits [1000.0, 1000.0, 88.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8551 q_vals: [-inf, -inf, -5.867, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3284 2 visits [1000.0, 1000.0, 89.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8554 q_vals: [-inf, -inf, -5.912, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8557, "number_of_timesteps": 147323, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3285 2 visits [1000.0, 1000.0, 90.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8557 q_vals: [-inf, -inf, -5.935, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3286 2 visits [1000.0, 1000.0, 91.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8559 q_vals: [-inf, -inf, -5.96, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3287 2 visits [1000.0, 1000.0, 92.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8560 q_vals: [-inf, -inf, -6.002, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3288 2 visits [1000.0, 1000.0, 93.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8563 q_vals: [-inf, -inf, -6.041, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3289 2 visits [1000.0, 1000.0, 94.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8563 q_vals: [-inf, -inf, -5.977, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3290 2 visits [1000.0, 1000.0, 95.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8565 q_vals: [-inf, -inf, -5.933, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3291 2 visits [1000.0, 1000.0, 96.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8566 q_vals: [-inf, -inf, -5.968, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8568, "number_of_timesteps": 147573, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3292 2 visits [1000.0, 1000.0, 97.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8568 q_vals: [-inf, -inf, -5.907, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3293 2 visits [1000.0, 1000.0, 98.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8572 q_vals: [-inf, -inf, -5.945, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3294 2 visits [1000.0, 1000.0, 99.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8574 q_vals: [-inf, -inf, -5.983, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3295 2 visits [1000.0, 1000.0, 100.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8576 q_vals: [-inf, -inf, -6.003, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3296 2 visits [1000.0, 1000.0, 101.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8576 q_vals: [-inf, -inf, -5.943, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3297 2 visits [1000.0, 1000.0, 102.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8577 q_vals: [-inf, -inf, -5.929, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8578, "number_of_timesteps": 147847, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3298 2 visits [1000.0, 1000.0, 103.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8578 q_vals: [-inf, -inf, -5.966, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3299 2 visits [1000.0, 1000.0, 104.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8583 q_vals: [-inf, -inf, -5.98, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3300 2 visits [1000.0, 1000.0, 105.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8585 q_vals: [-inf, -inf, -6.012, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8588, "number_of_timesteps": 148092, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3301 2 visits [1000.0, 1000.0, 106.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8588 q_vals: [-inf, -inf, -5.955, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3302 2 visits [1000.0, 1000.0, 107.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8591 q_vals: [-inf, -inf, -5.988, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3303 2 visits [1000.0, 1000.0, 108.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8591 q_vals: [-inf, -inf, -6.013, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3304 2 visits [1000.0, 1000.0, 109.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8596 q_vals: [-inf, -inf, -5.958, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3305 2 visits [1000.0, 1000.0, 110.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8597 q_vals: [-inf, -inf, -5.993, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3306 2 visits [1000.0, 1000.0, 111.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8597 q_vals: [-inf, -inf, -6.027, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8603, "number_of_timesteps": 148347, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3307 2 visits [1000.0, 1000.0, 112.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8603 q_vals: [-inf, -inf, -5.973, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3308 2 visits [1000.0, 1000.0, 113.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8605 q_vals: [-inf, -inf, -5.92, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3309 2 visits [1000.0, 1000.0, 114.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8606 q_vals: [-inf, -inf, -5.954, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3310 2 visits [1000.0, 1000.0, 115.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8609 q_vals: [-inf, -inf, -5.988, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3311 2 visits [1000.0, 1000.0, 116.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8611 q_vals: [-inf, -inf, -6.001, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8615, "number_of_timesteps": 148595, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3312 2 visits [1000.0, 1000.0, 117.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8615 q_vals: [-inf, -inf, -5.949, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3313 2 visits [1000.0, 1000.0, 118.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8616 q_vals: [-inf, -inf, -5.965, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3314 2 visits [1000.0, 1000.0, 119.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8617 q_vals: [-inf, -inf, -5.938, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3315 2 visits [1000.0, 1000.0, 120.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8619 q_vals: [-inf, -inf, -5.888, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3316 2 visits [1000.0, 1000.0, 121.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8623 q_vals: [-inf, -inf, -5.84, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8625, "number_of_timesteps": 148797, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3317 2 visits [1000.0, 1000.0, 122.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8625 q_vals: [-inf, -inf, -5.847, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3318 2 visits [1000.0, 1000.0, 123.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8627 q_vals: [-inf, -inf, -5.88, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3319 2 visits [1000.0, 1000.0, 124.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8630 q_vals: [-inf, -inf, -5.907, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3320 2 visits [1000.0, 1000.0, 125.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8632 q_vals: [-inf, -inf, -5.859, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3321 2 visits [1000.0, 1000.0, 126.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8632 q_vals: [-inf, -inf, -5.891, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8639, "number_of_timesteps": 149055, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3322 2 visits [1000.0, 1000.0, 127.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8639 q_vals: [-inf, -inf, -5.903, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3323 2 visits [1000.0, 1000.0, 128.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8640 q_vals: [-inf, -inf, -5.916, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3324 2 visits [1000.0, 1000.0, 129.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8642 q_vals: [-inf, -inf, -5.931, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3325 2 visits [1000.0, 1000.0, 130.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8643 q_vals: [-inf, -inf, -5.944, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3326 2 visits [1000.0, 1000.0, 131.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8644 q_vals: [-inf, -inf, -5.97, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3327 2 visits [1000.0, 1000.0, 132.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8644 q_vals: [-inf, -inf, -5.98, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8649, "number_of_timesteps": 149269, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3328 2 visits [1000.0, 1000.0, 133.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8649 q_vals: [-inf, -inf, -5.935, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3329 2 visits [1000.0, 1000.0, 134.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8653 q_vals: [-inf, -inf, -5.891, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3330 2 visits [1000.0, 1000.0, 135.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8653 q_vals: [-inf, -inf, -5.92, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3331 2 visits [1000.0, 1000.0, 136.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8656 q_vals: [-inf, -inf, -5.949, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8660, "number_of_timesteps": 149490, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3332 2 visits [1000.0, 1000.0, 137.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8660 q_vals: [-inf, -inf, -5.949, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3333 2 visits [1000.0, 1000.0, 138.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8663 q_vals: [-inf, -inf, -5.906, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3334 2 visits [1000.0, 1000.0, 139.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8664 q_vals: [-inf, -inf, -5.925, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3335 2 visits [1000.0, 1000.0, 140.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8666 q_vals: [-inf, -inf, -5.953, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3336 2 visits [1000.0, 1000.0, 141.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8668 q_vals: [-inf, -inf, -5.911, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
[-inf, -inf, -5.938, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3338 2 visits [1000.0, 1000.0, 143.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8668 q_vals: [-inf, -inf, -5.965, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8672, "number_of_timesteps": 149737, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3339 2 visits [1000.0, 1000.0, 144.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8672 q_vals: [-inf, -inf, -5.992, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3340 2 visits [1000.0, 1000.0, 145.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8676 q_vals: [-inf, -inf, -6.003, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3341 2 visits [1000.0, 1000.0, 146.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8677 q_vals: [-inf, -inf, -6.012, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3342 2 visits [1000.0, 1000.0, 147.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8677 q_vals: [-inf, -inf, -6.038, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3343 2 visits [1000.0, 1000.0, 148.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8678 q_vals: [-inf, -inf, -6.063, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8684, "number_of_timesteps": 150027, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3344 2 visits [1000.0, 1000.0, 149.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8684 q_vals: [-inf, -inf, -6.076, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3345 2 visits [1000.0, 1000.0, 150.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8686 q_vals: [-inf, -inf, -6.1, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3346 2 visits [1000.0, 1000.0, 151.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8687 q_vals: [-inf, -inf, -6.124, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3347 2 visits [1000.0, 1000.0, 152.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8689 q_vals: [-inf, -inf, -6.148, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3348 2 visits [1000.0, 1000.0, 153.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8689 q_vals: [-inf, -inf, -6.172, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3349 2 visits [1000.0, 1000.0, 154.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8693 q_vals: [-inf, -inf, -6.193, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8696, "number_of_timesteps": 150297, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3350 2 visits [1000.0, 1000.0, 155.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8696 q_vals: [-inf, -inf, -6.216, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3351 2 visits [1000.0, 1000.0, 156.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8698 q_vals: [-inf, -inf, -6.239, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3352 2 visits [1000.0, 1000.0, 157.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8701 q_vals: [-inf, -inf, -6.262, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3353 2 visits [1000.0, 1000.0, 158.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8704 q_vals: [-inf, -inf, -6.284, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3354 2 visits [1000.0, 1000.0, 159.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8705 q_vals: [-inf, -inf, -6.306, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8708, "number_of_timesteps": 150512, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3355 2 visits [1000.0, 1000.0, 160.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8708 q_vals: [-inf, -inf, -6.328, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3356 2 visits [1000.0, 1000.0, 161.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8710 q_vals: [-inf, -inf, -6.311, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3357 2 visits [1000.0, 1000.0, 162.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8713 q_vals: [-inf, -inf, -6.272, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3358 2 visits [1000.0, 1000.0, 163.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8714 q_vals: [-inf, -inf, -6.294, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3359 2 visits [1000.0, 1000.0, 164.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8717 q_vals: [-inf, -inf, -6.255, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8721, "number_of_timesteps": 150776, "per_episode_reward": 11.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3360 2 visits [1000.0, 1000.0, 165.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8721 q_vals: [-inf, -inf, -6.244, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3361 2 visits [1000.0, 1000.0, 166.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8722 q_vals: [-inf, -inf, -6.233, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3362 2 visits [1000.0, 1000.0, 167.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8723 q_vals: [-inf, -inf, -6.242, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3363 2 visits [1000.0, 1000.0, 168.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8726 q_vals: [-inf, -inf, -6.205, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3364 2 visits [1000.0, 1000.0, 169.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8729 q_vals: [-inf, -inf, -6.169, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3365 2 visits [1000.0, 1000.0, 170.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8729 q_vals: [-inf, -inf, -6.152, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8732, "number_of_timesteps": 150983, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3366 2 visits [1000.0, 1000.0, 171.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8732 q_vals: [-inf, -inf, -6.173, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3367 2 visits [1000.0, 1000.0, 172.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8735 q_vals: [-inf, -inf, -6.194, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
[-inf, -inf, -6.186, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3369 2 visits [1000.0, 1000.0, 174.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8740 q_vals: [-inf, -inf, -6.207, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8742, "number_of_timesteps": 151204, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3370 2 visits [1000.0, 1000.0, 175.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8742 q_vals: [-inf, -inf, -6.228, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3371 2 visits [1000.0, 1000.0, 176.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8744 q_vals: [-inf, -inf, -6.192, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3372 2 visits [1000.0, 1000.0, 177.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8745 q_vals: [-inf, -inf, -6.198, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3373 2 visits [1000.0, 1000.0, 178.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8745 q_vals: [-inf, -inf, -6.218, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3374 2 visits [1000.0, 1000.0, 179.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8749 q_vals: [-inf, -inf, -6.222, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8752, "number_of_timesteps": 151409, "per_episode_reward": 11.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3375 2 visits [1000.0, 1000.0, 180.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8752 q_vals: [-inf, -inf, -6.229, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3376 2 visits [1000.0, 1000.0, 181.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8753 q_vals: [-inf, -inf, -6.248, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3377 2 visits [1000.0, 1000.0, 182.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8755 q_vals: [-inf, -inf, -6.214, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3378 2 visits [1000.0, 1000.0, 183.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8756 q_vals: [-inf, -inf, -6.18, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3379 2 visits [1000.0, 1000.0, 184.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8759 q_vals: [-inf, -inf, -6.166, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3380 2 visits [1000.0, 1000.0, 185.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8761 q_vals: [-inf, -inf, -6.133, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8762, "number_of_timesteps": 151662, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3381 2 visits [1000.0, 1000.0, 186.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8762 q_vals: [-inf, -inf, -6.153, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3382 2 visits [1000.0, 1000.0, 187.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8763 q_vals: [-inf, -inf, -6.12, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3383 2 visits [1000.0, 1000.0, 188.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8766 q_vals: [-inf, -inf, -6.087, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3384 2 visits [1000.0, 1000.0, 189.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8768 q_vals: [-inf, -inf, -6.055, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3385 2 visits [1000.0, 1000.0, 190.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8769 q_vals: [-inf, -inf, -6.075, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3386 2 visits [1000.0, 1000.0, 191.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8771 q_vals: [-inf, -inf, -6.043, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8773, "number_of_timesteps": 151909, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3387 2 visits [1000.0, 1000.0, 192.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8773 q_vals: [-inf, -inf, -6.049, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3388 2 visits [1000.0, 1000.0, 193.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8775 q_vals: [-inf, -inf, -6.069, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3389 2 visits [1000.0, 1000.0, 194.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8777 q_vals: [-inf, -inf, -6.037, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3390 2 visits [1000.0, 1000.0, 195.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8779 q_vals: [-inf, -inf, -6.007, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3391 2 visits [1000.0, 1000.0, 196.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8781 q_vals: [-inf, -inf, -5.976, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3392 2 visits [1000.0, 1000.0, 197.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8782 q_vals: [-inf, -inf, -5.987, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8784, "number_of_timesteps": 152175, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3393 2 visits [1000.0, 1000.0, 198.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8784 q_vals: [-inf, -inf, -6.0, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3394 2 visits [1000.0, 1000.0, 199.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8787 q_vals: [-inf, -inf, -6.008, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3395 2 visits [1000.0, 1000.0, 200.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8789 q_vals: [-inf, -inf, -6.023, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3396 2 visits [1000.0, 1000.0, 201.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8789 q_vals: [-inf, -inf, -6.042, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3397 2 visits [1000.0, 1000.0, 202.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8791 q_vals: [-inf, -inf, -6.055, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3398 2 visits [1000.0, 1000.0, 203.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8793 q_vals: [-inf, -inf, -6.025, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8794, "number_of_timesteps": 152444, "per_episode_reward": 11.35, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 3399 2 visits [1000.0, 1000.0, 204.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8794 q_vals: [-inf, -inf, -6.038, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3400 2 visits [1000.0, 1000.0, 205.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8796 q_vals: [-inf, -inf, -6.056, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3401 2 visits [1000.0, 1000.0, 206.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8796 q_vals: [-inf, -inf, -6.074, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3402 2 visits [1000.0, 1000.0, 207.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8799 q_vals: [-inf, -inf, -6.08, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3403 2 visits [1000.0, 1000.0, 208.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8800 q_vals: [-inf, -inf, -6.05, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3404 2 visits [1000.0, 1000.0, 209.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8801 q_vals: [-inf, -inf, -6.068, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3405 2 visits [1000.0, 1000.0, 210.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8803 q_vals: [-inf, -inf, -6.086, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8804, "number_of_timesteps": 152797, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3406 2 visits [1000.0, 1000.0, 211.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8804 q_vals: [-inf, -inf, -6.057, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3407 2 visits [1000.0, 1000.0, 212.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8804 q_vals: [-inf, -inf, -6.063, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3408 2 visits [1000.0, 1000.0, 213.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8808 q_vals: [-inf, -inf, -6.08, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3409 2 visits [1000.0, 1000.0, 214.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8810 q_vals: [-inf, -inf, -6.098, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3410 2 visits [1000.0, 1000.0, 215.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8812 q_vals: [-inf, -inf, -6.11, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3411 2 visits [1000.0, 1000.0, 216.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8813 q_vals: [-inf, -inf, -6.082, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8816, "number_of_timesteps": 153132, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 3412 2 visits [1000.0, 1000.0, 217.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8816 q_vals: [-inf, -inf, -6.087, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3413 2 visits [1000.0, 1000.0, 218.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8818 q_vals: [-inf, -inf, -6.102, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3414 2 visits [1000.0, 1000.0, 219.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8820 q_vals: [-inf, -inf, -6.119, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3415 2 visits [1000.0, 1000.0, 220.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8820 q_vals: [-inf, -inf, -6.091, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3416 2 visits [1000.0, 1000.0, 221.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8823 q_vals: [-inf, -inf, -6.108, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3417 2 visits [1000.0, 1000.0, 222.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8824 q_vals: [-inf, -inf, -6.105, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8827, "number_of_timesteps": 153402, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 3418 2 visits [1000.0, 1000.0, 223.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8827 q_vals: [-inf, -inf, -6.078, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3419 2 visits [1000.0, 1000.0, 224.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8828 q_vals: [-inf, -inf, -6.084, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3420 2 visits [1000.0, 1000.0, 225.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8830 q_vals: [-inf, -inf, -6.057, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3421 2 visits [1000.0, 1000.0, 226.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8831 q_vals: [-inf, -inf, -6.073, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3422 2 visits [1000.0, 1000.0, 227.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8836 q_vals: [-inf, -inf, -6.046, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8837, "number_of_timesteps": 153666, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 3423 2 visits [1000.0, 1000.0, 228.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8837 q_vals: [-inf, -inf, -6.055, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3424 2 visits [1000.0, 1000.0, 229.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8838 q_vals: [-inf, -inf, -6.064, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3425 2 visits [1000.0, 1000.0, 230.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8841 q_vals: [-inf, -inf, -6.037, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3426 2 visits [1000.0, 1000.0, 231.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8842 q_vals: [-inf, -inf, -6.043, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3427 2 visits [1000.0, 1000.0, 232.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8844 q_vals: [-inf, -inf, -6.052, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3428 2 visits [1000.0, 1000.0, 233.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8846 q_vals: [-inf, -inf, -6.026, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8849, "number_of_timesteps": 153899, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
[1000.0, 1000.0, 234.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8849 q_vals: [-inf, -inf, -6.032, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3430 2 visits [1000.0, 1000.0, 235.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8850 q_vals: [-inf, -inf, -6.006, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3431 2 visits [1000.0, 1000.0, 236.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8851 q_vals: [-inf, -inf, -5.981, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3432 2 visits [1000.0, 1000.0, 237.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8854 q_vals: [-inf, -inf, -5.956, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3433 2 visits [1000.0, 1000.0, 238.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8855 q_vals: [-inf, -inf, -5.931, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3434 2 visits [1000.0, 1000.0, 239.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8857 q_vals: [-inf, -inf, -5.906, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8861, "number_of_timesteps": 154191, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3435 2 visits [1000.0, 1000.0, 240.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8861 q_vals: [-inf, -inf, -5.91, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3436 2 visits [1000.0, 1000.0, 241.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8863 q_vals: [-inf, -inf, -5.926, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3437 2 visits [1000.0, 1000.0, 242.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8864 q_vals: [-inf, -inf, -5.933, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3438 2 visits [1000.0, 1000.0, 243.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8866 q_vals: [-inf, -inf, -5.909, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3439 2 visits [1000.0, 1000.0, 244.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8868 q_vals: [-inf, -inf, -5.912, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3440 2 visits [1000.0, 1000.0, 245.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8870 q_vals: [-inf, -inf, -5.928, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8871, "number_of_timesteps": 154440, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3441 2 visits [1000.0, 1000.0, 246.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8871 q_vals: [-inf, -inf, -5.944, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3442 2 visits [1000.0, 1000.0, 247.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8875 q_vals: [-inf, -inf, -5.934, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3443 2 visits [1000.0, 1000.0, 248.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8875 q_vals: [-inf, -inf, -5.91, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3444 2 visits [1000.0, 1000.0, 249.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8875 q_vals: [-inf, -inf, -5.926, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3445 2 visits [1000.0, 1000.0, 250.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8878 q_vals: [-inf, -inf, -5.929, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8882, "number_of_timesteps": 154711, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3446 2 visits [1000.0, 1000.0, 251.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8882 q_vals: [-inf, -inf, -5.934, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3447 2 visits [1000.0, 1000.0, 252.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8885 q_vals: [-inf, -inf, -5.95, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3448 2 visits [1000.0, 1000.0, 253.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8885 q_vals: [-inf, -inf, -5.965, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3449 2 visits [1000.0, 1000.0, 254.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8885 q_vals: [-inf, -inf, -5.98, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3450 2 visits [1000.0, 1000.0, 255.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8891 q_vals: [-inf, -inf, -5.971, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8892, "number_of_timesteps": 154924, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3451 2 visits [1000.0, 1000.0, 256.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8892 q_vals: [-inf, -inf, -5.948, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3452 2 visits [1000.0, 1000.0, 257.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8892 q_vals: [-inf, -inf, -5.963, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3453 2 visits [1000.0, 1000.0, 258.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8894 q_vals: [-inf, -inf, -5.94, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3454 2 visits [1000.0, 1000.0, 259.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8896 q_vals: [-inf, -inf, -5.955, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3455 2 visits [1000.0, 1000.0, 260.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8899 q_vals: [-inf, -inf, -5.96, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3456 2 visits [1000.0, 1000.0, 261.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8901 q_vals: [-inf, -inf, -5.937, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8902, "number_of_timesteps": 155176, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3457 2 visits [1000.0, 1000.0, 262.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8902 q_vals: [-inf, -inf, -5.951, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3458 2 visits [1000.0, 1000.0, 263.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8902 q_vals: [-inf, -inf, -5.929, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3459 2 visits [1000.0, 1000.0, 264.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8904 q_vals: [-inf, -inf, -5.934, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3460 2 visits [1000.0, 1000.0, 265.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8907 q_vals: [-inf, -inf, -5.912, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3461 2 visits [1000.0, 1000.0, 266.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8911 q_vals: [-inf, -inf, -5.914, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8913, "number_of_timesteps": 155475, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3462 2 visits [1000.0, 1000.0, 267.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8913 q_vals: [-inf, -inf, -5.892, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3463 2 visits [1000.0, 1000.0, 268.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8915 q_vals: [-inf, -inf, -5.907, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3464 2 visits [1000.0, 1000.0, 269.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8917 q_vals: [-inf, -inf, -5.914, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3465 2 visits [1000.0, 1000.0, 270.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8919 q_vals: [-inf, -inf, -5.912, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3466 2 visits [1000.0, 1000.0, 271.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8919 q_vals: [-inf, -inf, -5.89, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3467 2 visits [1000.0, 1000.0, 272.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8920 q_vals: [-inf, -inf, -5.904, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8925, "number_of_timesteps": 155696, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3468 2 visits [1000.0, 1000.0, 273.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8925 q_vals: [-inf, -inf, -5.919, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3469 2 visits [1000.0, 1000.0, 274.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8927 q_vals: [-inf, -inf, -5.916, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3470 2 visits [1000.0, 1000.0, 275.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8929 q_vals: [-inf, -inf, -5.894, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3471 2 visits [1000.0, 1000.0, 276.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8931 q_vals: [-inf, -inf, -5.901, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3472 2 visits [1000.0, 1000.0, 277.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8934 q_vals: [-inf, -inf, -5.879, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8935, "number_of_timesteps": 155904, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3473 2 visits [1000.0, 1000.0, 278.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8935 q_vals: [-inf, -inf, -5.858, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3474 2 visits [1000.0, 1000.0, 279.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8937 q_vals: [-inf, -inf, -5.869, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3475 2 visits [1000.0, 1000.0, 280.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8939 q_vals: [-inf, -inf, -5.883, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3476 2 visits [1000.0, 1000.0, 281.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8941 q_vals: [-inf, -inf, -5.897, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3477 2 visits [1000.0, 1000.0, 282.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8943 q_vals: [-inf, -inf, -5.902, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8946, "number_of_timesteps": 156151, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3478 2 visits [1000.0, 1000.0, 283.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8946 q_vals: [-inf, -inf, -5.915, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3479 2 visits [1000.0, 1000.0, 284.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8948 q_vals: [-inf, -inf, -5.895, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3480 2 visits [1000.0, 1000.0, 285.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8951 q_vals: [-inf, -inf, -5.908, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3481 2 visits [1000.0, 1000.0, 286.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8951 q_vals: [-inf, -inf, -5.912, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8956, "number_of_timesteps": 156370, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3482 2 visits [1000.0, 1000.0, 287.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8956 q_vals: [-inf, -inf, -5.917, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3483 2 visits [1000.0, 1000.0, 288.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8958 q_vals: [-inf, -inf, -5.93, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3484 2 visits [1000.0, 1000.0, 289.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8959 q_vals: [-inf, -inf, -5.91, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3485 2 visits [1000.0, 1000.0, 290.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8963 q_vals: [-inf, -inf, -5.923, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8966, "number_of_timesteps": 156569, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3486 2 visits [1000.0, 1000.0, 291.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8966 q_vals: [-inf, -inf, -5.912, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3487 2 visits [1000.0, 1000.0, 292.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8967 q_vals: [-inf, -inf, -5.892, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3488 2 visits [1000.0, 1000.0, 293.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8968 q_vals: [-inf, -inf, -5.905, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3489 2 visits [1000.0, 1000.0, 294.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8970 q_vals: [-inf, -inf, -5.885, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3490 2 visits [1000.0, 1000.0, 295.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8973 q_vals: [-inf, -inf, -5.879, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3491 2 visits [1000.0, 1000.0, 296.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8975 q_vals: [-inf, -inf, -5.884, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8976, "number_of_timesteps": 156758, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3492 2 visits [1000.0, 1000.0, 297.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8976 q_vals: [-inf, -inf, -5.881, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3493 2 visits [1000.0, 1000.0, 298.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8978 q_vals: [-inf, -inf, -5.861, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3494 2 visits [1000.0, 1000.0, 299.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8979 q_vals: [-inf, -inf, -5.842, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3495 2 visits [1000.0, 1000.0, 300.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8984 q_vals: [-inf, -inf, -5.855, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3496 2 visits [1000.0, 1000.0, 301.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8985 q_vals: [-inf, -inf, -5.835, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8988, "number_of_timesteps": 157036, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3497 2 visits [1000.0, 1000.0, 302.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8988 q_vals: [-inf, -inf, -5.839, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3498 2 visits [1000.0, 1000.0, 303.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8990 q_vals: [-inf, -inf, -5.846, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3499 2 visits [1000.0, 1000.0, 304.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8994 q_vals: [-inf, -inf, -5.827, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3500 2 visits [1000.0, 1000.0, 305.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8996 q_vals: [-inf, -inf, -5.84, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3501 2 visits [1000.0, 1000.0, 306.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8997 q_vals: [-inf, -inf, -5.833, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 8999, "number_of_timesteps": 157209, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3502 2 visits [1000.0, 1000.0, 307.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8999 q_vals: [-inf, -inf, -5.846, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3503 2 visits [1000.0, 1000.0, 308.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 8999 q_vals: [-inf, -inf, -5.859, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3504 2 visits [1000.0, 1000.0, 309.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9002 q_vals: [-inf, -inf, -5.864, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3505 2 visits [1000.0, 1000.0, 310.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9005 q_vals: [-inf, -inf, -5.868, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3506 2 visits [1000.0, 1000.0, 311.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9005 q_vals: [-inf, -inf, -5.881, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3507 2 visits [1000.0, 1000.0, 312.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9007 q_vals: [-inf, -inf, -5.893, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9010, "number_of_timesteps": 157487, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3508 2 visits [1000.0, 1000.0, 313.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9010 q_vals: [-inf, -inf, -5.906, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3509 2 visits [1000.0, 1000.0, 314.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9010 q_vals: [-inf, -inf, -5.887, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3510 2 visits [1000.0, 1000.0, 315.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9012 q_vals: [-inf, -inf, -5.889, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3511 2 visits [1000.0, 1000.0, 316.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9017 q_vals: [-inf, -inf, -5.871, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3512 2 visits [1000.0, 1000.0, 317.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9019 q_vals: [-inf, -inf, -5.875, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9022, "number_of_timesteps": 157798, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3513 2 visits [1000.0, 1000.0, 318.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9022 q_vals: [-inf, -inf, -5.879, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3514 2 visits [1000.0, 1000.0, 319.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9024 q_vals: [-inf, -inf, -5.886, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3515 2 visits [1000.0, 1000.0, 320.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9025 q_vals: [-inf, -inf, -5.898, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3516 2 visits [1000.0, 1000.0, 321.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9028 q_vals: [-inf, -inf, -5.886, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9032, "number_of_timesteps": 157978, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 3517 2 visits [1000.0, 1000.0, 322.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9032 q_vals: [-inf, -inf, -5.895, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3518 2 visits [1000.0, 1000.0, 323.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9034 q_vals: [-inf, -inf, -5.907, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3519 2 visits [1000.0, 1000.0, 324.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9035 q_vals: [-inf, -inf, -5.909, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3520 2 visits [1000.0, 1000.0, 325.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9035 q_vals: [-inf, -inf, -5.917, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3521 2 visits [1000.0, 1000.0, 326.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9038 q_vals: [-inf, -inf, -5.926, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3522 2 visits [1000.0, 1000.0, 327.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9040 q_vals: [-inf, -inf, -5.927, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3523 2 visits [1000.0, 1000.0, 328.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9041 q_vals: [-inf, -inf, -5.939, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9043, "number_of_timesteps": 158199, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 3524 2 visits [1000.0, 1000.0, 329.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9043 q_vals: [-inf, -inf, -5.921, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3525 2 visits [1000.0, 1000.0, 330.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9044 q_vals: [-inf, -inf, -5.932, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3526 2 visits [1000.0, 1000.0, 331.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9046 q_vals: [-inf, -inf, -5.932, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3527 2 visits [1000.0, 1000.0, 332.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9049 q_vals: [-inf, -inf, -5.915, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3528 2 visits [1000.0, 1000.0, 333.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9051 q_vals: [-inf, -inf, -5.918, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9056, "number_of_timesteps": 158544, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3529 2 visits [1000.0, 1000.0, 334.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9056 q_vals: [-inf, -inf, -5.92, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3530 2 visits [1000.0, 1000.0, 335.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9057 q_vals: [-inf, -inf, -5.903, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3531 2 visits [1000.0, 1000.0, 336.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9058 q_vals: [-inf, -inf, -5.906, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3532 2 visits [1000.0, 1000.0, 337.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9060 q_vals: [-inf, -inf, -5.888, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3533 2 visits [1000.0, 1000.0, 338.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9060 q_vals: [-inf, -inf, -5.891, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3534 2 visits [1000.0, 1000.0, 339.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9063 q_vals: [-inf, -inf, -5.886, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3535 2 visits [1000.0, 1000.0, 340.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9064 q_vals: [-inf, -inf, -5.889, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3536 2 visits [1000.0, 1000.0, 341.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9065 q_vals: [-inf, -inf, -5.901, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9070, "number_of_timesteps": 158850, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3537 2 visits [1000.0, 1000.0, 342.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9070 q_vals: [-inf, -inf, -5.902, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3538 2 visits [1000.0, 1000.0, 343.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9070 q_vals: [-inf, -inf, -5.885, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3539 2 visits [1000.0, 1000.0, 344.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9070 q_vals: [-inf, -inf, -5.868, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3540 2 visits [1000.0, 1000.0, 345.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9074 q_vals: [-inf, -inf, -5.865, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3541 2 visits [1000.0, 1000.0, 346.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9076 q_vals: [-inf, -inf, -5.867, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3542 2 visits [1000.0, 1000.0, 347.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9077 q_vals: [-inf, -inf, -5.877, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3543 2 visits [1000.0, 1000.0, 348.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9077 q_vals: [-inf, -inf, -5.86, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9084, "number_of_timesteps": 159225, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3544 2 visits [1000.0, 1000.0, 349.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9084 q_vals: [-inf, -inf, -5.843, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3545 2 visits [1000.0, 1000.0, 350.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9086 q_vals: [-inf, -inf, -5.854, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3546 2 visits [1000.0, 1000.0, 351.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9087 q_vals: [-inf, -inf, -5.862, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3547 2 visits [1000.0, 1000.0, 352.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9091 q_vals: [-inf, -inf, -5.871, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3548 2 visits [1000.0, 1000.0, 353.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9093 q_vals: [-inf, -inf, -5.882, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9094, "number_of_timesteps": 159388, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3549 2 visits [1000.0, 1000.0, 354.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9094 q_vals: [-inf, -inf, -5.892, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3550 2 visits [1000.0, 1000.0, 355.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9096 q_vals: [-inf, -inf, -5.875, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3551 2 visits [1000.0, 1000.0, 356.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9097 q_vals: [-inf, -inf, -5.859, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3552 2 visits [1000.0, 1000.0, 357.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9099 q_vals: [-inf, -inf, -5.842, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3553 2 visits [1000.0, 1000.0, 358.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9099 q_vals: [-inf, -inf, -5.852, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3554 2 visits [1000.0, 1000.0, 359.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9101 q_vals: [-inf, -inf, -5.836, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9104, "number_of_timesteps": 159630, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3555 2 visits [1000.0, 1000.0, 360.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9104 q_vals: [-inf, -inf, -5.847, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3556 2 visits [1000.0, 1000.0, 361.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9107 q_vals: [-inf, -inf, -5.853, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3557 2 visits [1000.0, 1000.0, 362.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9107 q_vals: [-inf, -inf, -5.837, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3558 2 visits [1000.0, 1000.0, 363.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9110 q_vals: [-inf, -inf, -5.838, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3559 2 visits [1000.0, 1000.0, 364.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9113 q_vals: [-inf, -inf, -5.848, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3560 2 visits [1000.0, 1000.0, 365.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9113 q_vals: [-inf, -inf, -5.846, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9117, "number_of_timesteps": 159952, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3561 2 visits [1000.0, 1000.0, 366.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9117 q_vals: [-inf, -inf, -5.856, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3562 2 visits [1000.0, 1000.0, 367.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9119 q_vals: [-inf, -inf, -5.84, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3563 2 visits [1000.0, 1000.0, 368.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9121 q_vals: [-inf, -inf, -5.845, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3564 2 visits [1000.0, 1000.0, 369.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9125 q_vals: [-inf, -inf, -5.855, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9127, "number_of_timesteps": 160150, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3565 2 visits [1000.0, 1000.0, 370.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9127 q_vals: [-inf, -inf, -5.84, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3566 2 visits [1000.0, 1000.0, 371.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9130 q_vals: [-inf, -inf, -5.845, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3567 2 visits [1000.0, 1000.0, 372.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9131 q_vals: [-inf, -inf, -5.837, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3568 2 visits [1000.0, 1000.0, 373.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9132 q_vals: [-inf, -inf, -5.839, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3569 2 visits [1000.0, 1000.0, 374.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9135 q_vals: [-inf, -inf, -5.846, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9138, "number_of_timesteps": 160373, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3570 2 visits [1000.0, 1000.0, 375.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9138 q_vals: [-inf, -inf, -5.848, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3571 2 visits [1000.0, 1000.0, 376.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9138 q_vals: [-inf, -inf, -5.858, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3572 2 visits [1000.0, 1000.0, 377.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9142 q_vals: [-inf, -inf, -5.866, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3573 2 visits [1000.0, 1000.0, 378.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9142 q_vals: [-inf, -inf, -5.872, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3574 2 visits [1000.0, 1000.0, 379.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9145 q_vals: [-inf, -inf, -5.883, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3575 2 visits [1000.0, 1000.0, 380.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9147 q_vals: [-inf, -inf, -5.893, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9149, "number_of_timesteps": 160600, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3576 2 visits [1000.0, 1000.0, 381.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9149 q_vals: [-inf, -inf, -5.903, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3577 2 visits [1000.0, 1000.0, 382.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9152 q_vals: [-inf, -inf, -5.904, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3578 2 visits [1000.0, 1000.0, 383.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9156 q_vals: [-inf, -inf, -5.911, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3579 2 visits [1000.0, 1000.0, 384.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9157 q_vals: [-inf, -inf, -5.896, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3580 2 visits [1000.0, 1000.0, 385.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9157 q_vals: [-inf, -inf, -5.881, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3581 2 visits [1000.0, 1000.0, 386.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9157 q_vals: [-inf, -inf, -5.891, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9160, "number_of_timesteps": 160811, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3582 2 visits [1000.0, 1000.0, 387.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9160 q_vals: [-inf, -inf, -5.881, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3583 2 visits [1000.0, 1000.0, 388.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9162 q_vals: [-inf, -inf, -5.866, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3584 2 visits [1000.0, 1000.0, 389.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9163 q_vals: [-inf, -inf, -5.868, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3585 2 visits [1000.0, 1000.0, 390.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9165 q_vals: [-inf, -inf, -5.853, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3586 2 visits [1000.0, 1000.0, 391.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9167 q_vals: [-inf, -inf, -5.838, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3587 2 visits [1000.0, 1000.0, 392.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9168 q_vals: [-inf, -inf, -5.848, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9170, "number_of_timesteps": 161047, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3588 2 visits [1000.0, 1000.0, 393.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9170 q_vals: [-inf, -inf, -5.844, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3589 2 visits [1000.0, 1000.0, 394.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9171 q_vals: [-inf, -inf, -5.83, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3590 2 visits [1000.0, 1000.0, 395.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9172 q_vals: [-inf, -inf, -5.826, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3591 2 visits [1000.0, 1000.0, 396.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9175 q_vals: [-inf, -inf, -5.828, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3592 2 visits [1000.0, 1000.0, 397.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9178 q_vals: [-inf, -inf, -5.816, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3593 2 visits [1000.0, 1000.0, 398.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9179 q_vals: [-inf, -inf, -5.826, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9181, "number_of_timesteps": 161312, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3594 2 visits [1000.0, 1000.0, 399.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9181 q_vals: [-inf, -inf, -5.836, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3595 2 visits [1000.0, 1000.0, 400.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9184 q_vals: [-inf, -inf, -5.846, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3596 2 visits [1000.0, 1000.0, 401.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9184 q_vals: [-inf, -inf, -5.856, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3597 2 visits [1000.0, 1000.0, 402.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9186 q_vals: [-inf, -inf, -5.85, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3598 2 visits [1000.0, 1000.0, 403.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9186 q_vals: [-inf, -inf, -5.85, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3599 2 visits [1000.0, 1000.0, 404.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9189 q_vals: [-inf, -inf, -5.851, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9192, "number_of_timesteps": 161744, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3600 2 visits [1000.0, 1000.0, 405.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9192 q_vals: [-inf, -inf, -5.851, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3601 2 visits [1000.0, 1000.0, 406.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9194 q_vals: [-inf, -inf, -5.837, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3602 2 visits [1000.0, 1000.0, 407.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9196 q_vals: [-inf, -inf, -5.847, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3603 2 visits [1000.0, 1000.0, 408.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9199 q_vals: [-inf, -inf, -5.832, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3604 2 visits [1000.0, 1000.0, 409.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9201 q_vals: [-inf, -inf, -5.821, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9203, "number_of_timesteps": 161981, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3605 2 visits [1000.0, 1000.0, 410.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9203 q_vals: [-inf, -inf, -5.831, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3606 2 visits [1000.0, 1000.0, 411.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9206 q_vals: [-inf, -inf, -5.817, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3607 2 visits [1000.0, 1000.0, 412.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9209 q_vals: [-inf, -inf, -5.818, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3608 2 visits [1000.0, 1000.0, 413.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9209 q_vals: [-inf, -inf, -5.823, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3609 2 visits [1000.0, 1000.0, 414.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9210 q_vals: [-inf, -inf, -5.829, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3610 2 visits [1000.0, 1000.0, 415.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9212 q_vals: [-inf, -inf, -5.838, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9215, "number_of_timesteps": 162243, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3611 2 visits [1000.0, 1000.0, 416.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9215 q_vals: [-inf, -inf, -5.824, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3612 2 visits [1000.0, 1000.0, 417.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9216 q_vals: [-inf, -inf, -5.825, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3613 2 visits [1000.0, 1000.0, 418.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9219 q_vals: [-inf, -inf, -5.811, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3614 2 visits [1000.0, 1000.0, 419.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9220 q_vals: [-inf, -inf, -5.797, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3615 2 visits [1000.0, 1000.0, 420.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9222 q_vals: [-inf, -inf, -5.79, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3616 2 visits [1000.0, 1000.0, 421.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9224 q_vals: [-inf, -inf, -5.792, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9227, "number_of_timesteps": 162500, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3617 2 visits [1000.0, 1000.0, 422.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9227 q_vals: [-inf, -inf, -5.778, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3618 2 visits [1000.0, 1000.0, 423.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9228 q_vals: [-inf, -inf, -5.788, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3619 2 visits [1000.0, 1000.0, 424.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9230 q_vals: [-inf, -inf, -5.781, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3620 2 visits [1000.0, 1000.0, 425.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9232 q_vals: [-inf, -inf, -5.768, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3621 2 visits [1000.0, 1000.0, 426.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9234 q_vals: [-inf, -inf, -5.777, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3622 2 visits [1000.0, 1000.0, 427.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9235 q_vals: [-inf, -inf, -5.775, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9239, "number_of_timesteps": 162784, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3623 2 visits [1000.0, 1000.0, 428.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9239 q_vals: [-inf, -inf, -5.785, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3624 2 visits [1000.0, 1000.0, 429.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9239 q_vals: [-inf, -inf, -5.784, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3625 2 visits [1000.0, 1000.0, 430.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9242 q_vals: [-inf, -inf, -5.785, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3626 2 visits [1000.0, 1000.0, 431.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9244 q_vals: [-inf, -inf, -5.784, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3627 2 visits [1000.0, 1000.0, 432.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9246 q_vals: [-inf, -inf, -5.793, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3628 2 visits [1000.0, 1000.0, 433.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9246 q_vals: [-inf, -inf, -5.803, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9249, "number_of_timesteps": 163056, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3629 2 visits [1000.0, 1000.0, 434.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9249 q_vals: [-inf, -inf, -5.812, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3630 2 visits [1000.0, 1000.0, 435.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9253 q_vals: [-inf, -inf, -5.798, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3631 2 visits [1000.0, 1000.0, 436.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9254 q_vals: [-inf, -inf, -5.785, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3632 2 visits [1000.0, 1000.0, 437.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9257 q_vals: [-inf, -inf, -5.785, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3633 2 visits [1000.0, 1000.0, 438.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9258 q_vals: [-inf, -inf, -5.784, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9261, "number_of_timesteps": 163309, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3634 2 visits [1000.0, 1000.0, 439.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9261 q_vals: [-inf, -inf, -5.771, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3635 2 visits [1000.0, 1000.0, 440.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9261 q_vals: [-inf, -inf, -5.772, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3636 2 visits [1000.0, 1000.0, 441.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9265 q_vals: [-inf, -inf, -5.775, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3637 2 visits [1000.0, 1000.0, 442.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9268 q_vals: [-inf, -inf, -5.762, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3638 2 visits [1000.0, 1000.0, 443.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9268 q_vals: [-inf, -inf, -5.771, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3639 2 visits [1000.0, 1000.0, 444.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9268 q_vals: [-inf, -inf, -5.766, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9271, "number_of_timesteps": 163535, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3640 2 visits [1000.0, 1000.0, 445.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9271 q_vals: [-inf, -inf, -5.753, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3641 2 visits [1000.0, 1000.0, 446.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9274 q_vals: [-inf, -inf, -5.753, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3642 2 visits [1000.0, 1000.0, 447.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9275 q_vals: [-inf, -inf, -5.74, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3643 2 visits [1000.0, 1000.0, 448.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9278 q_vals: [-inf, -inf, -5.727, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3644 2 visits [1000.0, 1000.0, 449.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9278 q_vals: [-inf, -inf, -5.737, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9281, "number_of_timesteps": 163787, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3645 2 visits [1000.0, 1000.0, 450.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9281 q_vals: [-inf, -inf, -5.74, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3646 2 visits [1000.0, 1000.0, 451.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9282 q_vals: [-inf, -inf, -5.729, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3647 2 visits [1000.0, 1000.0, 452.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9283 q_vals: [-inf, -inf, -5.738, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3648 2 visits [1000.0, 1000.0, 453.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9288 q_vals: [-inf, -inf, -5.726, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9291, "number_of_timesteps": 164038, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3649 2 visits [1000.0, 1000.0, 454.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9291 q_vals: [-inf, -inf, -5.735, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3650 2 visits [1000.0, 1000.0, 455.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9293 q_vals: [-inf, -inf, -5.735, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3651 2 visits [1000.0, 1000.0, 456.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9295 q_vals: [-inf, -inf, -5.733, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3652 2 visits [1000.0, 1000.0, 457.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9299 q_vals: [-inf, -inf, -5.742, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3653 2 visits [1000.0, 1000.0, 458.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9300 q_vals: [-inf, -inf, -5.729, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9304, "number_of_timesteps": 164259, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3654 2 visits [1000.0, 1000.0, 459.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9304 q_vals: [-inf, -inf, -5.716, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3655 2 visits [1000.0, 1000.0, 460.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9304 q_vals: [-inf, -inf, -5.725, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3656 2 visits [1000.0, 1000.0, 461.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9307 q_vals: [-inf, -inf, -5.722, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3657 2 visits [1000.0, 1000.0, 462.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9310 q_vals: [-inf, -inf, -5.731, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3658 2 visits [1000.0, 1000.0, 463.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9312 q_vals: [-inf, -inf, -5.731, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9314, "number_of_timesteps": 164441, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3659 2 visits [1000.0, 1000.0, 464.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9314 q_vals: [-inf, -inf, -5.731, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3660 2 visits [1000.0, 1000.0, 465.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9316 q_vals: [-inf, -inf, -5.734, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3661 2 visits [1000.0, 1000.0, 466.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9317 q_vals: [-inf, -inf, -5.738, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3662 2 visits [1000.0, 1000.0, 467.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9319 q_vals: [-inf, -inf, -5.725, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3663 2 visits [1000.0, 1000.0, 468.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9322 q_vals: [-inf, -inf, -5.722, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3664 2 visits [1000.0, 1000.0, 469.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9322 q_vals: [-inf, -inf, -5.728, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9324, "number_of_timesteps": 164671, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3665 2 visits [1000.0, 1000.0, 470.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9324 q_vals: [-inf, -inf, -5.715, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3666 2 visits [1000.0, 1000.0, 471.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9325 q_vals: [-inf, -inf, -5.718, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3667 2 visits [1000.0, 1000.0, 472.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9329 q_vals: [-inf, -inf, -5.721, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3668 2 visits [1000.0, 1000.0, 473.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9330 q_vals: [-inf, -inf, -5.709, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3669 2 visits [1000.0, 1000.0, 474.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9330 q_vals: [-inf, -inf, -5.713, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9334, "number_of_timesteps": 164909, "per_episode_reward": 11.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 3670 2 visits [1000.0, 1000.0, 475.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9334 q_vals: [-inf, -inf, -5.722, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3671 2 visits [1000.0, 1000.0, 476.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9338 q_vals: [-inf, -inf, -5.71, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3672 2 visits [1000.0, 1000.0, 477.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9338 q_vals: [-inf, -inf, -5.698, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3673 2 visits [1000.0, 1000.0, 478.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9341 q_vals: [-inf, -inf, -5.693, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3674 2 visits [1000.0, 1000.0, 479.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9343 q_vals: [-inf, -inf, -5.682, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]

{"total_number_of_episodes": 9345, "number_of_timesteps": 165192, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3675 2 visits [1000.0, 1000.0, 480.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9345 q_vals: [-inf, -inf, -5.69, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3676 2 visits [1000.0, 1000.0, 481.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9348 q_vals: [-inf, -inf, -5.678, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3677 2 visits [1000.0, 1000.0, 482.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9350 q_vals: [-inf, -inf, -5.666, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3678 2 visits [1000.0, 1000.0, 483.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9351 q_vals: [-inf, -inf, -5.655, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3679 2 visits [1000.0, 1000.0, 484.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9352 q_vals: [-inf, -inf, -5.659, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9356, "number_of_timesteps": 165423, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3680 2 visits [1000.0, 1000.0, 485.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9356 q_vals: [-inf, -inf, -5.647, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3681 2 visits [1000.0, 1000.0, 486.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9358 q_vals: [-inf, -inf, -5.648, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3682 2 visits [1000.0, 1000.0, 487.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9358 q_vals: [-inf, -inf, -5.636, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3683 2 visits [1000.0, 1000.0, 488.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9359 q_vals: [-inf, -inf, -5.638, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3684 2 visits [1000.0, 1000.0, 489.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9361 q_vals: [-inf, -inf, -5.627, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3685 2 visits [1000.0, 1000.0, 490.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9361 q_vals: [-inf, -inf, -5.615, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3686 2 visits [1000.0, 1000.0, 491.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9365 q_vals: [-inf, -inf, -5.613, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9367, "number_of_timesteps": 165737, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3687 2 visits [1000.0, 1000.0, 492.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9367 q_vals: [-inf, -inf, -5.616, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3688 2 visits [1000.0, 1000.0, 493.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9368 q_vals: [-inf, -inf, -5.625, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3689 2 visits [1000.0, 1000.0, 494.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9371 q_vals: [-inf, -inf, -5.625, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3690 2 visits [1000.0, 1000.0, 495.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9372 q_vals: [-inf, -inf, -5.626, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3691 2 visits [1000.0, 1000.0, 496.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9374 q_vals: [-inf, -inf, -5.63, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3692 2 visits [1000.0, 1000.0, 497.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9376 q_vals: [-inf, -inf, -5.618, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3693 2 visits [1000.0, 1000.0, 498.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9376 q_vals: [-inf, -inf, -5.619, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9378, "number_of_timesteps": 165970, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3694 2 visits [1000.0, 1000.0, 499.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9378 q_vals: [-inf, -inf, -5.627, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3695 2 visits [1000.0, 1000.0, 500.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9382 q_vals: [-inf, -inf, -5.635, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3696 2 visits [1000.0, 1000.0, 501.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9383 q_vals: [-inf, -inf, -5.624, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3697 2 visits [1000.0, 1000.0, 502.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9384 q_vals: [-inf, -inf, -5.613, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3698 2 visits [1000.0, 1000.0, 503.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9387 q_vals: [-inf, -inf, -5.601, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9389, "number_of_timesteps": 166300, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3699 2 visits [1000.0, 1000.0, 504.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9389 q_vals: [-inf, -inf, -5.59, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3700 2 visits [1000.0, 1000.0, 505.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9391 q_vals: [-inf, -inf, -5.579, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3701 2 visits [1000.0, 1000.0, 506.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9393 q_vals: [-inf, -inf, -5.588, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3702 2 visits [1000.0, 1000.0, 507.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9394 q_vals: [-inf, -inf, -5.596, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3703 2 visits [1000.0, 1000.0, 508.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9395 q_vals: [-inf, -inf, -5.585, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3704 2 visits [1000.0, 1000.0, 509.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9398 q_vals: [-inf, -inf, -5.585, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9401, "number_of_timesteps": 166556, "per_episode_reward": 11.75, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 3705 2 visits [1000.0, 1000.0, 510.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9401 q_vals: [-inf, -inf, -5.585, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3706 2 visits [1000.0, 1000.0, 511.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9403 q_vals: [-inf, -inf, -5.578, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3707 2 visits [1000.0, 1000.0, 512.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9404 q_vals: [-inf, -inf, -5.578, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3708 2 visits [1000.0, 1000.0, 513.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9406 q_vals: [-inf, -inf, -5.578, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3709 2 visits [1000.0, 1000.0, 514.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9409 q_vals: [-inf, -inf, -5.578, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3710 2 visits [1000.0, 1000.0, 515.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9410 q_vals: [-inf, -inf, -5.586, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9412, "number_of_timesteps": 166832, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 3711 2 visits [1000.0, 1000.0, 516.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9412 q_vals: [-inf, -inf, -5.585, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3712 2 visits [1000.0, 1000.0, 517.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9415 q_vals: [-inf, -inf, -5.592, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3713 2 visits [1000.0, 1000.0, 518.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9415 q_vals: [-inf, -inf, -5.581, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3714 2 visits [1000.0, 1000.0, 519.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9418 q_vals: [-inf, -inf, -5.583, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3715 2 visits [1000.0, 1000.0, 520.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9420 q_vals: [-inf, -inf, -5.573, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9422, "number_of_timesteps": 167035, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 3716 2 visits [1000.0, 1000.0, 521.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9422 q_vals: [-inf, -inf, -5.581, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3717 2 visits [1000.0, 1000.0, 522.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9423 q_vals: [-inf, -inf, -5.57, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3718 2 visits [1000.0, 1000.0, 523.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9426 q_vals: [-inf, -inf, -5.559, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3719 2 visits [1000.0, 1000.0, 524.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9429 q_vals: [-inf, -inf, -5.549, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3720 2 visits [1000.0, 1000.0, 525.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9430 q_vals: [-inf, -inf, -5.551, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9432, "number_of_timesteps": 167326, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 3721 2 visits [1000.0, 1000.0, 526.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9432 q_vals: [-inf, -inf, -5.541, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3722 2 visits [1000.0, 1000.0, 527.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9434 q_vals: [-inf, -inf, -5.539, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3723 2 visits [1000.0, 1000.0, 528.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9435 q_vals: [-inf, -inf, -5.547, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3724 2 visits [1000.0, 1000.0, 529.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9439 q_vals: [-inf, -inf, -5.536, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9442, "number_of_timesteps": 167528, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3725 2 visits [1000.0, 1000.0, 530.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9442 q_vals: [-inf, -inf, -5.544, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3726 2 visits [1000.0, 1000.0, 531.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9444 q_vals: [-inf, -inf, -5.552, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3727 2 visits [1000.0, 1000.0, 532.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9445 q_vals: [-inf, -inf, -5.542, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3728 2 visits [1000.0, 1000.0, 533.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9445 q_vals: [-inf, -inf, -5.55, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3729 2 visits [1000.0, 1000.0, 534.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9450 q_vals: [-inf, -inf, -5.541, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9452, "number_of_timesteps": 167743, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3730 2 visits [1000.0, 1000.0, 535.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9452 q_vals: [-inf, -inf, -5.549, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3731 2 visits [1000.0, 1000.0, 536.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9452 q_vals: [-inf, -inf, -5.539, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3732 2 visits [1000.0, 1000.0, 537.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9456 q_vals: [-inf, -inf, -5.539, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3733 2 visits [1000.0, 1000.0, 538.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9456 q_vals: [-inf, -inf, -5.529, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3734 2 visits [1000.0, 1000.0, 539.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9459 q_vals: [-inf, -inf, -5.528, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9462, "number_of_timesteps": 167992, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3735 2 visits [1000.0, 1000.0, 540.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9462 q_vals: [-inf, -inf, -5.524, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3736 2 visits [1000.0, 1000.0, 541.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9462 q_vals: [-inf, -inf, -5.53, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3737 2 visits [1000.0, 1000.0, 542.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9462 q_vals: [-inf, -inf, -5.533, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3738 2 visits [1000.0, 1000.0, 543.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9463 q_vals: [-inf, -inf, -5.532, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3739 2 visits [1000.0, 1000.0, 544.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9466 q_vals: [-inf, -inf, -5.522, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3740 2 visits [1000.0, 1000.0, 545.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9467 q_vals: [-inf, -inf, -5.53, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3741 2 visits [1000.0, 1000.0, 546.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9469 q_vals: [-inf, -inf, -5.529, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3742 2 visits [1000.0, 1000.0, 547.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9470 q_vals: [-inf, -inf, -5.537, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9474, "number_of_timesteps": 168313, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3743 2 visits [1000.0, 1000.0, 548.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9474 q_vals: [-inf, -inf, -5.545, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3744 2 visits [1000.0, 1000.0, 549.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9476 q_vals: [-inf, -inf, -5.552, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3745 2 visits [1000.0, 1000.0, 550.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9478 q_vals: [-inf, -inf, -5.56, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3746 2 visits [1000.0, 1000.0, 551.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9482 q_vals: [-inf, -inf, -5.568, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3747 2 visits [1000.0, 1000.0, 552.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9482 q_vals: [-inf, -inf, -5.558, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3748 2 visits [1000.0, 1000.0, 553.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9483 q_vals: [-inf, -inf, -5.548, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9488, "number_of_timesteps": 168566, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3749 2 visits [1000.0, 1000.0, 554.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9488 q_vals: [-inf, -inf, -5.548, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3750 2 visits [1000.0, 1000.0, 555.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9489 q_vals: [-inf, -inf, -5.556, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3751 2 visits [1000.0, 1000.0, 556.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9489 q_vals: [-inf, -inf, -5.556, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3752 2 visits [1000.0, 1000.0, 557.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9493 q_vals: [-inf, -inf, -5.556, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3753 2 visits [1000.0, 1000.0, 558.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9495 q_vals: [-inf, -inf, -5.546, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3754 2 visits [1000.0, 1000.0, 559.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9497 q_vals: [-inf, -inf, -5.536, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9498, "number_of_timesteps": 168860, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3755 2 visits [1000.0, 1000.0, 560.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9498 q_vals: [-inf, -inf, -5.543, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3756 2 visits [1000.0, 1000.0, 561.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9500 q_vals: [-inf, -inf, -5.545, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3757 2 visits [1000.0, 1000.0, 562.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9501 q_vals: [-inf, -inf, -5.535, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3758 2 visits [1000.0, 1000.0, 563.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9502 q_vals: [-inf, -inf, -5.528, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3759 2 visits [1000.0, 1000.0, 564.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9506 q_vals: [-inf, -inf, -5.518, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9509, "number_of_timesteps": 169130, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3760 2 visits [1000.0, 1000.0, 565.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9509 q_vals: [-inf, -inf, -5.508, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3761 2 visits [1000.0, 1000.0, 566.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9510 q_vals: [-inf, -inf, -5.498, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3762 2 visits [1000.0, 1000.0, 567.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9511 q_vals: [-inf, -inf, -5.5, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3763 2 visits [1000.0, 1000.0, 568.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9514 q_vals: [-inf, -inf, -5.5, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3764 2 visits [1000.0, 1000.0, 569.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9514 q_vals: [-inf, -inf, -5.508, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3765 2 visits [1000.0, 1000.0, 570.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9515 q_vals: [-inf, -inf, -5.508, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3766 2 visits [1000.0, 1000.0, 571.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9515 q_vals: [-inf, -inf, -5.515, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3767 2 visits [1000.0, 1000.0, 572.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9518 q_vals: [-inf, -inf, -5.506, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9519, "number_of_timesteps": 169402, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3768 2 visits [1000.0, 1000.0, 573.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9519 q_vals: [-inf, -inf, -5.513, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3769 2 visits [1000.0, 1000.0, 574.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9523 q_vals: [-inf, -inf, -5.521, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3770 2 visits [1000.0, 1000.0, 575.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9524 q_vals: [-inf, -inf, -5.528, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3771 2 visits [1000.0, 1000.0, 576.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9526 q_vals: [-inf, -inf, -5.518, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3772 2 visits [1000.0, 1000.0, 577.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9526 q_vals: [-inf, -inf, -5.526, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3773 2 visits [1000.0, 1000.0, 578.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9528 q_vals: [-inf, -inf, -5.526, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3774 2 visits [1000.0, 1000.0, 579.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9528 q_vals: [-inf, -inf, -5.533, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9532, "number_of_timesteps": 169788, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3775 2 visits [1000.0, 1000.0, 580.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9532 q_vals: [-inf, -inf, -5.535, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3776 2 visits [1000.0, 1000.0, 581.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9534 q_vals: [-inf, -inf, -5.525, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3777 2 visits [1000.0, 1000.0, 582.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9535 q_vals: [-inf, -inf, -5.533, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3778 2 visits [1000.0, 1000.0, 583.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9536 q_vals: [-inf, -inf, -5.523, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3779 2 visits [1000.0, 1000.0, 584.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9538 q_vals: [-inf, -inf, -5.53, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3780 2 visits [1000.0, 1000.0, 585.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9539 q_vals: [-inf, -inf, -5.53, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3781 2 visits [1000.0, 1000.0, 586.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9540 q_vals: [-inf, -inf, -5.52, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9543, "number_of_timesteps": 170077, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3782 2 visits [1000.0, 1000.0, 587.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9543 q_vals: [-inf, -inf, -5.52, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3783 2 visits [1000.0, 1000.0, 588.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9545 q_vals: [-inf, -inf, -5.527, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3784 2 visits [1000.0, 1000.0, 589.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9546 q_vals: [-inf, -inf, -5.534, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3785 2 visits [1000.0, 1000.0, 590.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9547 q_vals: [-inf, -inf, -5.542, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3786 2 visits [1000.0, 1000.0, 591.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9551 q_vals: [-inf, -inf, -5.542, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9553, "number_of_timesteps": 170313, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3787 2 visits [1000.0, 1000.0, 592.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9553 q_vals: [-inf, -inf, -5.543, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3788 2 visits [1000.0, 1000.0, 593.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9553 q_vals: [-inf, -inf, -5.533, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3789 2 visits [1000.0, 1000.0, 594.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9553 q_vals: [-inf, -inf, -5.537, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3790 2 visits [1000.0, 1000.0, 595.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9558 q_vals: [-inf, -inf, -5.538, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3791 2 visits [1000.0, 1000.0, 596.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9560 q_vals: [-inf, -inf, -5.529, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3792 2 visits [1000.0, 1000.0, 597.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9560 q_vals: [-inf, -inf, -5.536, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3793 2 visits [1000.0, 1000.0, 598.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9562 q_vals: [-inf, -inf, -5.543, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9563, "number_of_timesteps": 170576, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3794 2 visits [1000.0, 1000.0, 599.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9563 q_vals: [-inf, -inf, -5.55, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3795 2 visits [1000.0, 1000.0, 600.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9565 q_vals: [-inf, -inf, -5.544, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3796 2 visits [1000.0, 1000.0, 601.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9569 q_vals: [-inf, -inf, -5.547, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3797 2 visits [1000.0, 1000.0, 602.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9570 q_vals: [-inf, -inf, -5.549, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9573, "number_of_timesteps": 170886, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3798 2 visits [1000.0, 1000.0, 603.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9573 q_vals: [-inf, -inf, -5.542, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3799 2 visits [1000.0, 1000.0, 604.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9576 q_vals: [-inf, -inf, -5.549, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3800 2 visits [1000.0, 1000.0, 605.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9578 q_vals: [-inf, -inf, -5.544, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3801 2 visits [1000.0, 1000.0, 606.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9579 q_vals: [-inf, -inf, -5.551, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3802 2 visits [1000.0, 1000.0, 607.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9580 q_vals: [-inf, -inf, -5.55, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9584, "number_of_timesteps": 171106, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3803 2 visits [1000.0, 1000.0, 608.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9584 q_vals: [-inf, -inf, -5.55, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3804 2 visits [1000.0, 1000.0, 609.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9586 q_vals: [-inf, -inf, -5.546, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3805 2 visits [1000.0, 1000.0, 610.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9587 q_vals: [-inf, -inf, -5.547, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3806 2 visits [1000.0, 1000.0, 611.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9588 q_vals: [-inf, -inf, -5.554, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3807 2 visits [1000.0, 1000.0, 612.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9589 q_vals: [-inf, -inf, -5.545, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3808 2 visits [1000.0, 1000.0, 613.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9591 q_vals: [-inf, -inf, -5.547, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3809 2 visits [1000.0, 1000.0, 614.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9591 q_vals: [-inf, -inf, -5.538, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3810 2 visits [1000.0, 1000.0, 615.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9592 q_vals: [-inf, -inf, -5.537, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9595, "number_of_timesteps": 171388, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3811 2 visits [1000.0, 1000.0, 616.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9595 q_vals: [-inf, -inf, -5.533, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3812 2 visits [1000.0, 1000.0, 617.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9597 q_vals: [-inf, -inf, -5.54, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3813 2 visits [1000.0, 1000.0, 618.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9598 q_vals: [-inf, -inf, -5.531, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3814 2 visits [1000.0, 1000.0, 619.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9598 q_vals: [-inf, -inf, -5.529, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3815 2 visits [1000.0, 1000.0, 620.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9600 q_vals: [-inf, -inf, -5.52, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3816 2 visits [1000.0, 1000.0, 621.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9601 q_vals: [-inf, -inf, -5.521, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3817 2 visits [1000.0, 1000.0, 622.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9604 q_vals: [-inf, -inf, -5.518, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3818 2 visits [1000.0, 1000.0, 623.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9604 q_vals: [-inf, -inf, -5.509, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9605, "number_of_timesteps": 171736, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3819 2 visits [1000.0, 1000.0, 624.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9605 q_vals: [-inf, -inf, -5.512, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3820 2 visits [1000.0, 1000.0, 625.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9609 q_vals: [-inf, -inf, -5.503, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3821 2 visits [1000.0, 1000.0, 626.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9612 q_vals: [-inf, -inf, -5.502, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3822 2 visits [1000.0, 1000.0, 627.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9613 q_vals: [-inf, -inf, -5.508, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3823 2 visits [1000.0, 1000.0, 628.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9614 q_vals: [-inf, -inf, -5.509, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9618, "number_of_timesteps": 172105, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3824 2 visits [1000.0, 1000.0, 629.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9618 q_vals: [-inf, -inf, -5.508, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3825 2 visits [1000.0, 1000.0, 630.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9619 q_vals: [-inf, -inf, -5.509, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3826 2 visits [1000.0, 1000.0, 631.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9623 q_vals: [-inf, -inf, -5.508, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3827 2 visits [1000.0, 1000.0, 632.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9624 q_vals: [-inf, -inf, -5.499, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3828 2 visits [1000.0, 1000.0, 633.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9627 q_vals: [-inf, -inf, -5.506, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3829 2 visits [1000.0, 1000.0, 634.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9627 q_vals: [-inf, -inf, -5.503, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9628, "number_of_timesteps": 172323, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3830 2 visits [1000.0, 1000.0, 635.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9628 q_vals: [-inf, -inf, -5.494, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3831 2 visits [1000.0, 1000.0, 636.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9629 q_vals: [-inf, -inf, -5.497, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3832 2 visits [1000.0, 1000.0, 637.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9631 q_vals: [-inf, -inf, -5.503, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3833 2 visits [1000.0, 1000.0, 638.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9634 q_vals: [-inf, -inf, -5.51, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3834 2 visits [1000.0, 1000.0, 639.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9637 q_vals: [-inf, -inf, -5.507, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9639, "number_of_timesteps": 172623, "per_episode_reward": 11.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3835 2 visits [1000.0, 1000.0, 640.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9639 q_vals: [-inf, -inf, -5.498, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3836 2 visits [1000.0, 1000.0, 641.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9639 q_vals: [-inf, -inf, -5.501, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3837 2 visits [1000.0, 1000.0, 642.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9642 q_vals: [-inf, -inf, -5.508, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3838 2 visits [1000.0, 1000.0, 643.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9643 q_vals: [-inf, -inf, -5.509, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3839 2 visits [1000.0, 1000.0, 644.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9645 q_vals: [-inf, -inf, -5.506, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3840 2 visits [1000.0, 1000.0, 645.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9647 q_vals: [-inf, -inf, -5.51, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3841 2 visits [1000.0, 1000.0, 646.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9648 q_vals: [-inf, -inf, -5.516, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9651, "number_of_timesteps": 172928, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3842 2 visits [1000.0, 1000.0, 647.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9651 q_vals: [-inf, -inf, -5.516, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3843 2 visits [1000.0, 1000.0, 648.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9652 q_vals: [-inf, -inf, -5.522, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3844 2 visits [1000.0, 1000.0, 649.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9653 q_vals: [-inf, -inf, -5.529, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3845 2 visits [1000.0, 1000.0, 650.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9654 q_vals: [-inf, -inf, -5.529, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3846 2 visits [1000.0, 1000.0, 651.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9658 q_vals: [-inf, -inf, -5.522, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3847 2 visits [1000.0, 1000.0, 652.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9658 q_vals: [-inf, -inf, -5.521, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9661, "number_of_timesteps": 173190, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3848 2 visits [1000.0, 1000.0, 653.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9661 q_vals: [-inf, -inf, -5.52, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3849 2 visits [1000.0, 1000.0, 654.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9663 q_vals: [-inf, -inf, -5.517, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3850 2 visits [1000.0, 1000.0, 655.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9666 q_vals: [-inf, -inf, -5.523, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3851 2 visits [1000.0, 1000.0, 656.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9667 q_vals: [-inf, -inf, -5.515, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3852 2 visits [1000.0, 1000.0, 657.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9668 q_vals: [-inf, -inf, -5.507, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9671, "number_of_timesteps": 173384, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3853 2 visits [1000.0, 1000.0, 658.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9671 q_vals: [-inf, -inf, -5.498, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3854 2 visits [1000.0, 1000.0, 659.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9671 q_vals: [-inf, -inf, -5.49, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3855 2 visits [1000.0, 1000.0, 660.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9675 q_vals: [-inf, -inf, -5.489, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3856 2 visits [1000.0, 1000.0, 661.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9677 q_vals: [-inf, -inf, -5.484, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3857 2 visits [1000.0, 1000.0, 662.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9678 q_vals: [-inf, -inf, -5.485, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3858 2 visits [1000.0, 1000.0, 663.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9680 q_vals: [-inf, -inf, -5.487, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9682, "number_of_timesteps": 173704, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3859 2 visits [1000.0, 1000.0, 664.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9682 q_vals: [-inf, -inf, -5.484, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3860 2 visits [1000.0, 1000.0, 665.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9683 q_vals: [-inf, -inf, -5.484, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3861 2 visits [1000.0, 1000.0, 666.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9686 q_vals: [-inf, -inf, -5.476, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3862 2 visits [1000.0, 1000.0, 667.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9690 q_vals: [-inf, -inf, -5.468, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9692, "number_of_timesteps": 173950, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3863 2 visits [1000.0, 1000.0, 668.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9692 q_vals: [-inf, -inf, -5.46, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3864 2 visits [1000.0, 1000.0, 669.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9692 q_vals: [-inf, -inf, -5.452, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3865 2 visits [1000.0, 1000.0, 670.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9695 q_vals: [-inf, -inf, -5.446, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3866 2 visits [1000.0, 1000.0, 671.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9696 q_vals: [-inf, -inf, -5.438, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3867 2 visits [1000.0, 1000.0, 672.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9700 q_vals: [-inf, -inf, -5.437, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3868 2 visits [1000.0, 1000.0, 673.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9701 q_vals: [-inf, -inf, -5.429, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9702, "number_of_timesteps": 174178, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3869 2 visits [1000.0, 1000.0, 674.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9702 q_vals: [-inf, -inf, -5.432, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3870 2 visits [1000.0, 1000.0, 675.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9704 q_vals: [-inf, -inf, -5.439, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3871 2 visits [1000.0, 1000.0, 676.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9708 q_vals: [-inf, -inf, -5.431, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3872 2 visits [1000.0, 1000.0, 677.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9709 q_vals: [-inf, -inf, -5.437, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3873 2 visits [1000.0, 1000.0, 678.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9711 q_vals: [-inf, -inf, -5.431, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9715, "number_of_timesteps": 174428, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3874 2 visits [1000.0, 1000.0, 679.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9715 q_vals: [-inf, -inf, -5.438, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3875 2 visits [1000.0, 1000.0, 680.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9719 q_vals: [-inf, -inf, -5.43, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3876 2 visits [1000.0, 1000.0, 681.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9721 q_vals: [-inf, -inf, -5.436, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3877 2 visits [1000.0, 1000.0, 682.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9722 q_vals: [-inf, -inf, -5.428, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3878 2 visits [1000.0, 1000.0, 683.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9724 q_vals: [-inf, -inf, -5.42, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9725, "number_of_timesteps": 174616, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3879 2 visits [1000.0, 1000.0, 684.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9725 q_vals: [-inf, -inf, -5.423, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3880 2 visits [1000.0, 1000.0, 685.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9726 q_vals: [-inf, -inf, -5.415, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3881 2 visits [1000.0, 1000.0, 686.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9728 q_vals: [-inf, -inf, -5.413, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3882 2 visits [1000.0, 1000.0, 687.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9729 q_vals: [-inf, -inf, -5.42, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3883 2 visits [1000.0, 1000.0, 688.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9732 q_vals: [-inf, -inf, -5.412, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9735, "number_of_timesteps": 174867, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3884 2 visits [1000.0, 1000.0, 689.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9735 q_vals: [-inf, -inf, -5.404, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3885 2 visits [1000.0, 1000.0, 690.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9737 q_vals: [-inf, -inf, -5.396, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3886 2 visits [1000.0, 1000.0, 691.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9738 q_vals: [-inf, -inf, -5.388, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3887 2 visits [1000.0, 1000.0, 692.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9739 q_vals: [-inf, -inf, -5.381, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3888 2 visits [1000.0, 1000.0, 693.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9741 q_vals: [-inf, -inf, -5.38, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3889 2 visits [1000.0, 1000.0, 694.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9743 q_vals: [-inf, -inf, -5.372, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3890 2 visits [1000.0, 1000.0, 695.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9744 q_vals: [-inf, -inf, -5.371, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9746, "number_of_timesteps": 175123, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3891 2 visits [1000.0, 1000.0, 696.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9746 q_vals: [-inf, -inf, -5.378, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3892 2 visits [1000.0, 1000.0, 697.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9750 q_vals: [-inf, -inf, -5.37, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3893 2 visits [1000.0, 1000.0, 698.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9752 q_vals: [-inf, -inf, -5.371, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3894 2 visits [1000.0, 1000.0, 699.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9753 q_vals: [-inf, -inf, -5.377, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9756, "number_of_timesteps": 175377, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3895 2 visits [1000.0, 1000.0, 700.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9756 q_vals: [-inf, -inf, -5.383, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3896 2 visits [1000.0, 1000.0, 701.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9757 q_vals: [-inf, -inf, -5.383, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3897 2 visits [1000.0, 1000.0, 702.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9758 q_vals: [-inf, -inf, -5.382, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3898 2 visits [1000.0, 1000.0, 703.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9762 q_vals: [-inf, -inf, -5.38, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3899 2 visits [1000.0, 1000.0, 704.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9762 q_vals: [-inf, -inf, -5.383, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3900 2 visits [1000.0, 1000.0, 705.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9764 q_vals: [-inf, -inf, -5.388, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9767, "number_of_timesteps": 175648, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3901 2 visits [1000.0, 1000.0, 706.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9767 q_vals: [-inf, -inf, -5.387, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3902 2 visits [1000.0, 1000.0, 707.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9767 q_vals: [-inf, -inf, -5.389, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3903 2 visits [1000.0, 1000.0, 708.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9769 q_vals: [-inf, -inf, -5.381, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3904 2 visits [1000.0, 1000.0, 709.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9772 q_vals: [-inf, -inf, -5.387, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3905 2 visits [1000.0, 1000.0, 710.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9772 q_vals: [-inf, -inf, -5.388, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3906 2 visits [1000.0, 1000.0, 711.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9773 q_vals: [-inf, -inf, -5.391, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9777, "number_of_timesteps": 175826, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3907 2 visits [1000.0, 1000.0, 712.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9777 q_vals: [-inf, -inf, -5.39, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3908 2 visits [1000.0, 1000.0, 713.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9779 q_vals: [-inf, -inf, -5.383, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3909 2 visits [1000.0, 1000.0, 714.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9780 q_vals: [-inf, -inf, -5.381, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3910 2 visits [1000.0, 1000.0, 715.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9781 q_vals: [-inf, -inf, -5.379, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3911 2 visits [1000.0, 1000.0, 716.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9782 q_vals: [-inf, -inf, -5.378, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3912 2 visits [1000.0, 1000.0, 717.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9784 q_vals: [-inf, -inf, -5.377, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3913 2 visits [1000.0, 1000.0, 718.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9785 q_vals: [-inf, -inf, -5.383, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9787, "number_of_timesteps": 176201, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3914 2 visits [1000.0, 1000.0, 719.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9787 q_vals: [-inf, -inf, -5.377, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3915 2 visits [1000.0, 1000.0, 720.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9789 q_vals: [-inf, -inf, -5.371, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3916 2 visits [1000.0, 1000.0, 721.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9790 q_vals: [-inf, -inf, -5.377, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3917 2 visits [1000.0, 1000.0, 722.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9794 q_vals: [-inf, -inf, -5.376, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9797, "number_of_timesteps": 176482, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3918 2 visits [1000.0, 1000.0, 723.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9797 q_vals: [-inf, -inf, -5.377, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3919 2 visits [1000.0, 1000.0, 724.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9800 q_vals: [-inf, -inf, -5.369, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3920 2 visits [1000.0, 1000.0, 725.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9801 q_vals: [-inf, -inf, -5.37, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3921 2 visits [1000.0, 1000.0, 726.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9802 q_vals: [-inf, -inf, -5.368, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3922 2 visits [1000.0, 1000.0, 727.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9805 q_vals: [-inf, -inf, -5.36, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3923 2 visits [1000.0, 1000.0, 728.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9805 q_vals: [-inf, -inf, -5.358, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9807, "number_of_timesteps": 176684, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3924 2 visits [1000.0, 1000.0, 729.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9807 q_vals: [-inf, -inf, -5.351, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3925 2 visits [1000.0, 1000.0, 730.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9808 q_vals: [-inf, -inf, -5.35, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3926 2 visits [1000.0, 1000.0, 731.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9810 q_vals: [-inf, -inf, -5.343, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3927 2 visits [1000.0, 1000.0, 732.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9811 q_vals: [-inf, -inf, -5.344, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3928 2 visits [1000.0, 1000.0, 733.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9812 q_vals: [-inf, -inf, -5.337, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3929 2 visits [1000.0, 1000.0, 734.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9816 q_vals: [-inf, -inf, -5.33, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9818, "number_of_timesteps": 176972, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3930 2 visits [1000.0, 1000.0, 735.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9818 q_vals: [-inf, -inf, -5.336, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3931 2 visits [1000.0, 1000.0, 736.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9819 q_vals: [-inf, -inf, -5.342, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3932 2 visits [1000.0, 1000.0, 737.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9821 q_vals: [-inf, -inf, -5.341, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3933 2 visits [1000.0, 1000.0, 738.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9823 q_vals: [-inf, -inf, -5.338, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3934 2 visits [1000.0, 1000.0, 739.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9825 q_vals: [-inf, -inf, -5.341, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3935 2 visits [1000.0, 1000.0, 740.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9825 q_vals: [-inf, -inf, -5.341, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3936 2 visits [1000.0, 1000.0, 741.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9825 q_vals: [-inf, -inf, -5.339, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3937 2 visits [1000.0, 1000.0, 742.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9826 q_vals: [-inf, -inf, -5.338, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9828, "number_of_timesteps": 177255, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3938 2 visits [1000.0, 1000.0, 743.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9828 q_vals: [-inf, -inf, -5.33, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3939 2 visits [1000.0, 1000.0, 744.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9833 q_vals: [-inf, -inf, -5.336, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3940 2 visits [1000.0, 1000.0, 745.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9834 q_vals: [-inf, -inf, -5.329, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3941 2 visits [1000.0, 1000.0, 746.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9834 q_vals: [-inf, -inf, -5.328, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3942 2 visits [1000.0, 1000.0, 747.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9835 q_vals: [-inf, -inf, -5.328, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3943 2 visits [1000.0, 1000.0, 748.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9835 q_vals: [-inf, -inf, -5.328, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9839, "number_of_timesteps": 177629, "per_episode_reward": 11.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3944 2 visits [1000.0, 1000.0, 749.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9839 q_vals: [-inf, -inf, -5.325, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3945 2 visits [1000.0, 1000.0, 750.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9841 q_vals: [-inf, -inf, -5.331, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3946 2 visits [1000.0, 1000.0, 751.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9841 q_vals: [-inf, -inf, -5.328, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3947 2 visits [1000.0, 1000.0, 752.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9842 q_vals: [-inf, -inf, -5.321, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3948 2 visits [1000.0, 1000.0, 753.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9843 q_vals: [-inf, -inf, -5.327, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3949 2 visits [1000.0, 1000.0, 754.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9846 q_vals: [-inf, -inf, -5.326, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3950 2 visits [1000.0, 1000.0, 755.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9848 q_vals: [-inf, -inf, -5.332, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9849, "number_of_timesteps": 177910, "per_episode_reward": 11.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3951 2 visits [1000.0, 1000.0, 756.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9849 q_vals: [-inf, -inf, -5.331, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3952 2 visits [1000.0, 1000.0, 757.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9852 q_vals: [-inf, -inf, -5.33, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3953 2 visits [1000.0, 1000.0, 758.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9853 q_vals: [-inf, -inf, -5.329, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3954 2 visits [1000.0, 1000.0, 759.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9854 q_vals: [-inf, -inf, -5.322, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
[-inf, -inf, -5.321, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3956 2 visits [1000.0, 1000.0, 761.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9856 q_vals: [-inf, -inf, -5.327, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3957 2 visits [1000.0, 1000.0, 762.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9857 q_vals: [-inf, -inf, -5.333, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9860, "number_of_timesteps": 178249, "per_episode_reward": 11.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3958 2 visits [1000.0, 1000.0, 763.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9860 q_vals: [-inf, -inf, -5.326, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3959 2 visits [1000.0, 1000.0, 764.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9861 q_vals: [-inf, -inf, -5.319, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3960 2 visits [1000.0, 1000.0, 765.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9863 q_vals: [-inf, -inf, -5.325, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3961 2 visits [1000.0, 1000.0, 766.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9865 q_vals: [-inf, -inf, -5.318, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3962 2 visits [1000.0, 1000.0, 767.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9866 q_vals: [-inf, -inf, -5.313, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3963 2 visits [1000.0, 1000.0, 768.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9866 q_vals: [-inf, -inf, -5.319, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3964 2 visits [1000.0, 1000.0, 769.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9867 q_vals: [-inf, -inf, -5.32, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9871, "number_of_timesteps": 178548, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3965 2 visits [1000.0, 1000.0, 770.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9871 q_vals: [-inf, -inf, -5.319, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3966 2 visits [1000.0, 1000.0, 771.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9874 q_vals: [-inf, -inf, -5.313, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3967 2 visits [1000.0, 1000.0, 772.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9874 q_vals: [-inf, -inf, -5.316, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3968 2 visits [1000.0, 1000.0, 773.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9876 q_vals: [-inf, -inf, -5.315, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3969 2 visits [1000.0, 1000.0, 774.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9878 q_vals: [-inf, -inf, -5.317, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3970 2 visits [1000.0, 1000.0, 775.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9879 q_vals: [-inf, -inf, -5.315, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9881, "number_of_timesteps": 178838, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3971 2 visits [1000.0, 1000.0, 776.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9881 q_vals: [-inf, -inf, -5.314, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3972 2 visits [1000.0, 1000.0, 777.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9881 q_vals: [-inf, -inf, -5.313, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3973 2 visits [1000.0, 1000.0, 778.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9883 q_vals: [-inf, -inf, -5.306, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3974 2 visits [1000.0, 1000.0, 779.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9883 q_vals: [-inf, -inf, -5.299, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3975 2 visits [1000.0, 1000.0, 780.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9884 q_vals: [-inf, -inf, -5.292, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3976 2 visits [1000.0, 1000.0, 781.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9885 q_vals: [-inf, -inf, -5.293, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3977 2 visits [1000.0, 1000.0, 782.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9887 q_vals: [-inf, -inf, -5.287, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3978 2 visits [1000.0, 1000.0, 783.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9887 q_vals: [-inf, -inf, -5.287, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3979 2 visits [1000.0, 1000.0, 784.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9890 q_vals: [-inf, -inf, -5.286, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9892, "number_of_timesteps": 179306, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3980 2 visits [1000.0, 1000.0, 785.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9892 q_vals: [-inf, -inf, -5.292, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3981 2 visits [1000.0, 1000.0, 786.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9895 q_vals: [-inf, -inf, -5.298, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3982 2 visits [1000.0, 1000.0, 787.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9895 q_vals: [-inf, -inf, -5.303, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3983 2 visits [1000.0, 1000.0, 788.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9898 q_vals: [-inf, -inf, -5.297, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3984 2 visits [1000.0, 1000.0, 789.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9898 q_vals: [-inf, -inf, -5.29, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9902, "number_of_timesteps": 179598, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3985 2 visits [1000.0, 1000.0, 790.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9902 q_vals: [-inf, -inf, -5.289, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3986 2 visits [1000.0, 1000.0, 791.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9902 q_vals: [-inf, -inf, -5.283, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]

Step 3987 2 visits [1000.0, 1000.0, 792.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9903 q_vals: [-inf, -inf, -5.287, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3988 2 visits [1000.0, 1000.0, 793.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9906 q_vals: [-inf, -inf, -5.282, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3989 2 visits [1000.0, 1000.0, 794.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9907 q_vals: [-inf, -inf, -5.284, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3990 2 visits [1000.0, 1000.0, 795.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9909 q_vals: [-inf, -inf, -5.29, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3991 2 visits [1000.0, 1000.0, 796.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9911 q_vals: [-inf, -inf, -5.283, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9912, "number_of_timesteps": 179862, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3992 2 visits [1000.0, 1000.0, 797.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9912 q_vals: [-inf, -inf, -5.28, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3993 2 visits [1000.0, 1000.0, 798.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9914 q_vals: [-inf, -inf, -5.279, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3994 2 visits [1000.0, 1000.0, 799.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9917 q_vals: [-inf, -inf, -5.279, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3995 2 visits [1000.0, 1000.0, 800.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9917 q_vals: [-inf, -inf, -5.272, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3996 2 visits [1000.0, 1000.0, 801.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9919 q_vals: [-inf, -inf, -5.271, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3997 2 visits [1000.0, 1000.0, 802.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9919 q_vals: [-inf, -inf, -5.277, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 3998 2 visits [1000.0, 1000.0, 803.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9921 q_vals: [-inf, -inf, -5.274, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9924, "number_of_timesteps": 180210, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3999 2 visits [1000.0, 1000.0, 804.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9924 q_vals: [-inf, -inf, -5.273, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4000 2 visits [1000.0, 1000.0, 805.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9927 q_vals: [-inf, -inf, -5.279, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4001 2 visits [1000.0, 1000.0, 806.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9927 q_vals: [-inf, -inf, -5.272, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4002 2 visits [1000.0, 1000.0, 807.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9929 q_vals: [-inf, -inf, -5.265, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4003 2 visits [1000.0, 1000.0, 808.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9932 q_vals: [-inf, -inf, -5.259, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4004 2 visits [1000.0, 1000.0, 809.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9933 q_vals: [-inf, -inf, -5.252, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4005 2 visits [1000.0, 1000.0, 810.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9933 q_vals: [-inf, -inf, -5.258, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9935, "number_of_timesteps": 180445, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4006 2 visits [1000.0, 1000.0, 811.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9935 q_vals: [-inf, -inf, -5.253, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4007 2 visits [1000.0, 1000.0, 812.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9938 q_vals: [-inf, -inf, -5.246, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4008 2 visits [1000.0, 1000.0, 813.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9938 q_vals: [-inf, -inf, -5.251, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4009 2 visits [1000.0, 1000.0, 814.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9939 q_vals: [-inf, -inf, -5.244, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4010 2 visits [1000.0, 1000.0, 815.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9942 q_vals: [-inf, -inf, -5.245, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4011 2 visits [1000.0, 1000.0, 816.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9942 q_vals: [-inf, -inf, -5.245, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4012 2 visits [1000.0, 1000.0, 817.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9944 q_vals: [-inf, -inf, -5.251, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9946, "number_of_timesteps": 180739, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4013 2 visits [1000.0, 1000.0, 818.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9946 q_vals: [-inf, -inf, -5.249, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4014 2 visits [1000.0, 1000.0, 819.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9949 q_vals: [-inf, -inf, -5.247, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4015 2 visits [1000.0, 1000.0, 820.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9949 q_vals: [-inf, -inf, -5.247, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4016 2 visits [1000.0, 1000.0, 821.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9951 q_vals: [-inf, -inf, -5.241, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4017 2 visits [1000.0, 1000.0, 822.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9951 q_vals: [-inf, -inf, -5.243, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4018 2 visits [1000.0, 1000.0, 823.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9953 q_vals: [-inf, -inf, -5.236, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4019 2 visits [1000.0, 1000.0, 824.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9954 q_vals: [-inf, -inf, -5.236, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9956, "number_of_timesteps": 181135, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4020 2 visits [1000.0, 1000.0, 825.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9956 q_vals: [-inf, -inf, -5.234, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4021 2 visits [1000.0, 1000.0, 826.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9958 q_vals: [-inf, -inf, -5.24, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4022 2 visits [1000.0, 1000.0, 827.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9960 q_vals: [-inf, -inf, -5.239, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4023 2 visits [1000.0, 1000.0, 828.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9962 q_vals: [-inf, -inf, -5.233, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4024 2 visits [1000.0, 1000.0, 829.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9963 q_vals: [-inf, -inf, -5.232, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4025 2 visits [1000.0, 1000.0, 830.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9964 q_vals: [-inf, -inf, -5.229, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9966, "number_of_timesteps": 181446, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4026 2 visits [1000.0, 1000.0, 831.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9966 q_vals: [-inf, -inf, -5.234, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4027 2 visits [1000.0, 1000.0, 832.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9967 q_vals: [-inf, -inf, -5.228, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4028 2 visits [1000.0, 1000.0, 833.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9970 q_vals: [-inf, -inf, -5.228, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4029 2 visits [1000.0, 1000.0, 834.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9971 q_vals: [-inf, -inf, -5.233, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4030 2 visits [1000.0, 1000.0, 835.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9974 q_vals: [-inf, -inf, -5.239, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4031 2 visits [1000.0, 1000.0, 836.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9975 q_vals: [-inf, -inf, -5.232, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9977, "number_of_timesteps": 181757, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4032 2 visits [1000.0, 1000.0, 837.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9977 q_vals: [-inf, -inf, -5.231, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4033 2 visits [1000.0, 1000.0, 838.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9981 q_vals: [-inf, -inf, -5.224, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4034 2 visits [1000.0, 1000.0, 839.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9981 q_vals: [-inf, -inf, -5.224, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4035 2 visits [1000.0, 1000.0, 840.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9982 q_vals: [-inf, -inf, -5.218, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4036 2 visits [1000.0, 1000.0, 841.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9983 q_vals: [-inf, -inf, -5.211, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4037 2 visits [1000.0, 1000.0, 842.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9985 q_vals: [-inf, -inf, -5.21, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9987, "number_of_timesteps": 182019, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4038 2 visits [1000.0, 1000.0, 843.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9987 q_vals: [-inf, -inf, -5.209, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4039 2 visits [1000.0, 1000.0, 844.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9987 q_vals: [-inf, -inf, -5.205, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4040 2 visits [1000.0, 1000.0, 845.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9987 q_vals: [-inf, -inf, -5.205, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4041 2 visits [1000.0, 1000.0, 846.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9991 q_vals: [-inf, -inf, -5.202, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4042 2 visits [1000.0, 1000.0, 847.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9993 q_vals: [-inf, -inf, -5.202, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4043 2 visits [1000.0, 1000.0, 848.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9993 q_vals: [-inf, -inf, -5.196, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4044 2 visits [1000.0, 1000.0, 849.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9994 q_vals: [-inf, -inf, -5.192, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4045 2 visits [1000.0, 1000.0, 850.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9995 q_vals: [-inf, -inf, -5.197, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 9998, "number_of_timesteps": 182360, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4046 2 visits [1000.0, 1000.0, 851.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9998 q_vals: [-inf, -inf, -5.203, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4047 2 visits [1000.0, 1000.0, 852.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9999 q_vals: [-inf, -inf, -5.201, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4048 2 visits [1000.0, 1000.0, 853.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 9999 q_vals: [-inf, -inf, -5.195, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4049 2 visits [1000.0, 1000.0, 854.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10003 q_vals: [-inf, -inf, -5.195, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
[-inf, -inf, -5.189, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4051 2 visits [1000.0, 1000.0, 856.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10006 q_vals: [-inf, -inf, -5.183, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10008, "number_of_timesteps": 182676, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4052 2 visits [1000.0, 1000.0, 857.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10008 q_vals: [-inf, -inf, -5.189, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4053 2 visits [1000.0, 1000.0, 858.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10010 q_vals: [-inf, -inf, -5.183, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4054 2 visits [1000.0, 1000.0, 859.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10010 q_vals: [-inf, -inf, -5.188, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4055 2 visits [1000.0, 1000.0, 860.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10011 q_vals: [-inf, -inf, -5.191, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4056 2 visits [1000.0, 1000.0, 861.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10012 q_vals: [-inf, -inf, -5.191, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4057 2 visits [1000.0, 1000.0, 862.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10015 q_vals: [-inf, -inf, -5.19, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4058 2 visits [1000.0, 1000.0, 863.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10017 q_vals: [-inf, -inf, -5.195, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10020, "number_of_timesteps": 183044, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4059 2 visits [1000.0, 1000.0, 864.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10020 q_vals: [-inf, -inf, -5.191, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4060 2 visits [1000.0, 1000.0, 865.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10021 q_vals: [-inf, -inf, -5.189, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4061 2 visits [1000.0, 1000.0, 866.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10024 q_vals: [-inf, -inf, -5.183, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4062 2 visits [1000.0, 1000.0, 867.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10024 q_vals: [-inf, -inf, -5.177, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4063 2 visits [1000.0, 1000.0, 868.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10025 q_vals: [-inf, -inf, -5.174, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4064 2 visits [1000.0, 1000.0, 869.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10027 q_vals: [-inf, -inf, -5.172, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10032, "number_of_timesteps": 183286, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4065 2 visits [1000.0, 1000.0, 870.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10032 q_vals: [-inf, -inf, -5.166, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4066 2 visits [1000.0, 1000.0, 871.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10033 q_vals: [-inf, -inf, -5.172, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4067 2 visits [1000.0, 1000.0, 872.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10033 q_vals: [-inf, -inf, -5.17, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4068 2 visits [1000.0, 1000.0, 873.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10033 q_vals: [-inf, -inf, -5.169, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4069 2 visits [1000.0, 1000.0, 874.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10035 q_vals: [-inf, -inf, -5.163, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4070 2 visits [1000.0, 1000.0, 875.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10037 q_vals: [-inf, -inf, -5.163, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4071 2 visits [1000.0, 1000.0, 876.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10039 q_vals: [-inf, -inf, -5.166, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4072 2 visits [1000.0, 1000.0, 877.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10041 q_vals: [-inf, -inf, -5.16, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10043, "number_of_timesteps": 183644, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4073 2 visits [1000.0, 1000.0, 878.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10043 q_vals: [-inf, -inf, -5.159, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4074 2 visits [1000.0, 1000.0, 879.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10044 q_vals: [-inf, -inf, -5.153, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4075 2 visits [1000.0, 1000.0, 880.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10046 q_vals: [-inf, -inf, -5.158, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4076 2 visits [1000.0, 1000.0, 881.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10046 q_vals: [-inf, -inf, -5.155, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4077 2 visits [1000.0, 1000.0, 882.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10048 q_vals: [-inf, -inf, -5.154, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4078 2 visits [1000.0, 1000.0, 883.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10049 q_vals: [-inf, -inf, -5.148, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4079 2 visits [1000.0, 1000.0, 884.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10052 q_vals: [-inf, -inf, -5.142, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10054, "number_of_timesteps": 183994, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4080 2 visits [1000.0, 1000.0, 885.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10054 q_vals: [-inf, -inf, -5.137, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4081 2 visits [1000.0, 1000.0, 886.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10055 q_vals: [-inf, -inf, -5.131, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4082 2 visits [1000.0, 1000.0, 887.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10059 q_vals: [-inf, -inf, -5.13, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4083 2 visits [1000.0, 1000.0, 888.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10060 q_vals: [-inf, -inf, -5.135, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4084 2 visits [1000.0, 1000.0, 889.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10061 q_vals: [-inf, -inf, -5.139, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4085 2 visits [1000.0, 1000.0, 890.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10062 q_vals: [-inf, -inf, -5.144, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4086 2 visits [1000.0, 1000.0, 891.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10063 q_vals: [-inf, -inf, -5.138, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10065, "number_of_timesteps": 184220, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4087 2 visits [1000.0, 1000.0, 892.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10065 q_vals: [-inf, -inf, -5.137, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4088 2 visits [1000.0, 1000.0, 893.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10067 q_vals: [-inf, -inf, -5.136, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4089 2 visits [1000.0, 1000.0, 894.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10067 q_vals: [-inf, -inf, -5.136, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4090 2 visits [1000.0, 1000.0, 895.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10068 q_vals: [-inf, -inf, -5.141, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4091 2 visits [1000.0, 1000.0, 896.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10069 q_vals: [-inf, -inf, -5.14, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4092 2 visits [1000.0, 1000.0, 897.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10072 q_vals: [-inf, -inf, -5.134, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10075, "number_of_timesteps": 184622, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4093 2 visits [1000.0, 1000.0, 898.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10075 q_vals: [-inf, -inf, -5.128, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4094 2 visits [1000.0, 1000.0, 899.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10076 q_vals: [-inf, -inf, -5.127, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4095 2 visits [1000.0, 1000.0, 900.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10077 q_vals: [-inf, -inf, -5.126, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4096 2 visits [1000.0, 1000.0, 901.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10079 q_vals: [-inf, -inf, -5.125, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4097 2 visits [1000.0, 1000.0, 902.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10082 q_vals: [-inf, -inf, -5.123, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4098 2 visits [1000.0, 1000.0, 903.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10083 q_vals: [-inf, -inf, -5.128, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4099 2 visits [1000.0, 1000.0, 904.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10084 q_vals: [-inf, -inf, -5.127, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10086, "number_of_timesteps": 184863, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4100 2 visits [1000.0, 1000.0, 905.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10086 q_vals: [-inf, -inf, -5.125, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4101 2 visits [1000.0, 1000.0, 906.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10089 q_vals: [-inf, -inf, -5.125, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4102 2 visits [1000.0, 1000.0, 907.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10092 q_vals: [-inf, -inf, -5.123, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4103 2 visits [1000.0, 1000.0, 908.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10093 q_vals: [-inf, -inf, -5.117, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4104 2 visits [1000.0, 1000.0, 909.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10094 q_vals: [-inf, -inf, -5.12, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10096, "number_of_timesteps": 185086, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4105 2 visits [1000.0, 1000.0, 910.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10096 q_vals: [-inf, -inf, -5.114, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4106 2 visits [1000.0, 1000.0, 911.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10097 q_vals: [-inf, -inf, -5.109, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4107 2 visits [1000.0, 1000.0, 912.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10099 q_vals: [-inf, -inf, -5.103, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4108 2 visits [1000.0, 1000.0, 913.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10099 q_vals: [-inf, -inf, -5.098, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4109 2 visits [1000.0, 1000.0, 914.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10100 q_vals: [-inf, -inf, -5.096, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4110 2 visits [1000.0, 1000.0, 915.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10102 q_vals: [-inf, -inf, -5.093, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4111 2 visits [1000.0, 1000.0, 916.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10104 q_vals: [-inf, -inf, -5.098, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10107, "number_of_timesteps": 185457, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4112 2 visits [1000.0, 1000.0, 917.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10107 q_vals: [-inf, -inf, -5.098, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4113 2 visits [1000.0, 1000.0, 918.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10108 q_vals: [-inf, -inf, -5.093, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4114 2 visits [1000.0, 1000.0, 919.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10110 q_vals: [-inf, -inf, -5.092, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4115 2 visits [1000.0, 1000.0, 920.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10112 q_vals: [-inf, -inf, -5.087, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4116 2 visits [1000.0, 1000.0, 921.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10114 q_vals: [-inf, -inf, -5.085, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4117 2 visits [1000.0, 1000.0, 922.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10115 q_vals: [-inf, -inf, -5.083, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10117, "number_of_timesteps": 185771, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4118 2 visits [1000.0, 1000.0, 923.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10117 q_vals: [-inf, -inf, -5.082, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4119 2 visits [1000.0, 1000.0, 924.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10119 q_vals: [-inf, -inf, -5.087, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4120 2 visits [1000.0, 1000.0, 925.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10120 q_vals: [-inf, -inf, -5.082, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4121 2 visits [1000.0, 1000.0, 926.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10123 q_vals: [-inf, -inf, -5.076, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4122 2 visits [1000.0, 1000.0, 927.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10124 q_vals: [-inf, -inf, -5.072, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10127, "number_of_timesteps": 186006, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4123 2 visits [1000.0, 1000.0, 928.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10127 q_vals: [-inf, -inf, -5.067, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4124 2 visits [1000.0, 1000.0, 929.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10129 q_vals: [-inf, -inf, -5.062, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4125 2 visits [1000.0, 1000.0, 930.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10130 q_vals: [-inf, -inf, -5.064, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4126 2 visits [1000.0, 1000.0, 931.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10131 q_vals: [-inf, -inf, -5.065, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4127 2 visits [1000.0, 1000.0, 932.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10133 q_vals: [-inf, -inf, -5.063, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4128 2 visits [1000.0, 1000.0, 933.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10134 q_vals: [-inf, -inf, -5.063, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4129 2 visits [1000.0, 1000.0, 934.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10136 q_vals: [-inf, -inf, -5.062, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10139, "number_of_timesteps": 186361, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4130 2 visits [1000.0, 1000.0, 935.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10139 q_vals: [-inf, -inf, -5.057, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4131 2 visits [1000.0, 1000.0, 936.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10140 q_vals: [-inf, -inf, -5.055, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4132 2 visits [1000.0, 1000.0, 937.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10140 q_vals: [-inf, -inf, -5.06, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4133 2 visits [1000.0, 1000.0, 938.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10144 q_vals: [-inf, -inf, -5.058, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4134 2 visits [1000.0, 1000.0, 939.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10145 q_vals: [-inf, -inf, -5.063, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4135 2 visits [1000.0, 1000.0, 940.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10147 q_vals: [-inf, -inf, -5.058, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4136 2 visits [1000.0, 1000.0, 941.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10148 q_vals: [-inf, -inf, -5.052, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10151, "number_of_timesteps": 186656, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4137 2 visits [1000.0, 1000.0, 942.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10151 q_vals: [-inf, -inf, -5.047, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4138 2 visits [1000.0, 1000.0, 943.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10153 q_vals: [-inf, -inf, -5.047, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4139 2 visits [1000.0, 1000.0, 944.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10154 q_vals: [-inf, -inf, -5.046, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4140 2 visits [1000.0, 1000.0, 945.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10154 q_vals: [-inf, -inf, -5.045, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4141 2 visits [1000.0, 1000.0, 946.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10156 q_vals: [-inf, -inf, -5.04, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4142 2 visits [1000.0, 1000.0, 947.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10157 q_vals: [-inf, -inf, -5.036, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4143 2 visits [1000.0, 1000.0, 948.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10158 q_vals: [-inf, -inf, -5.036, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4144 2 visits [1000.0, 1000.0, 949.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10160 q_vals: [-inf, -inf, -5.03, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10161, "number_of_timesteps": 186964, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4145 2 visits [1000.0, 1000.0, 950.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10161 q_vals: [-inf, -inf, -5.028, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4146 2 visits [1000.0, 1000.0, 951.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10161 q_vals: [-inf, -inf, -5.027, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4147 2 visits [1000.0, 1000.0, 952.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10162 q_vals: [-inf, -inf, -5.025, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4148 2 visits [1000.0, 1000.0, 953.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10165 q_vals: [-inf, -inf, -5.019, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4149 2 visits [1000.0, 1000.0, 954.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10167 q_vals: [-inf, -inf, -5.018, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4150 2 visits [1000.0, 1000.0, 955.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10169 q_vals: [-inf, -inf, -5.023, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4151 2 visits [1000.0, 1000.0, 956.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10170 q_vals: [-inf, -inf, -5.022, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10173, "number_of_timesteps": 187338, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4152 2 visits [1000.0, 1000.0, 957.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10173 q_vals: [-inf, -inf, -5.027, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4153 2 visits [1000.0, 1000.0, 958.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10175 q_vals: [-inf, -inf, -5.021, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4154 2 visits [1000.0, 1000.0, 959.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10177 q_vals: [-inf, -inf, -5.021, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4155 2 visits [1000.0, 1000.0, 960.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10178 q_vals: [-inf, -inf, -5.025, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4156 2 visits [1000.0, 1000.0, 961.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10182 q_vals: [-inf, -inf, -5.026, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10183, "number_of_timesteps": 187606, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4157 2 visits [1000.0, 1000.0, 962.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10183 q_vals: [-inf, -inf, -5.031, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4158 2 visits [1000.0, 1000.0, 963.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10185 q_vals: [-inf, -inf, -5.033, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4159 2 visits [1000.0, 1000.0, 964.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10186 q_vals: [-inf, -inf, -5.028, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4160 2 visits [1000.0, 1000.0, 965.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10188 q_vals: [-inf, -inf, -5.025, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4161 2 visits [1000.0, 1000.0, 966.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10189 q_vals: [-inf, -inf, -5.02, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4162 2 visits [1000.0, 1000.0, 967.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10192 q_vals: [-inf, -inf, -5.015, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10195, "number_of_timesteps": 187927, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4163 2 visits [1000.0, 1000.0, 968.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10195 q_vals: [-inf, -inf, -5.009, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4164 2 visits [1000.0, 1000.0, 969.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10196 q_vals: [-inf, -inf, -5.004, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4165 2 visits [1000.0, 1000.0, 970.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10197 q_vals: [-inf, -inf, -5.005, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4166 2 visits [1000.0, 1000.0, 971.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10200 q_vals: [-inf, -inf, -5.0, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4167 2 visits [1000.0, 1000.0, 972.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10201 q_vals: [-inf, -inf, -4.995, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4168 2 visits [1000.0, 1000.0, 973.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10202 q_vals: [-inf, -inf, -4.989, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10205, "number_of_timesteps": 188132, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4169 2 visits [1000.0, 1000.0, 974.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10205 q_vals: [-inf, -inf, -4.989, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4170 2 visits [1000.0, 1000.0, 975.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10206 q_vals: [-inf, -inf, -4.985, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4171 2 visits [1000.0, 1000.0, 976.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10207 q_vals: [-inf, -inf, -4.984, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4172 2 visits [1000.0, 1000.0, 977.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10207 q_vals: [-inf, -inf, -4.979, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4173 2 visits [1000.0, 1000.0, 978.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10209 q_vals: [-inf, -inf, -4.974, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4174 2 visits [1000.0, 1000.0, 979.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10212 q_vals: [-inf, -inf, -4.973, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4175 2 visits [1000.0, 1000.0, 980.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10213 q_vals: [-inf, -inf, -4.972, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4176 2 visits [1000.0, 1000.0, 981.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10213 q_vals: [-inf, -inf, -4.972, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4177 2 visits [1000.0, 1000.0, 982.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10214 q_vals: [-inf, -inf, -4.967, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10217, "number_of_timesteps": 188536, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4178 2 visits [1000.0, 1000.0, 983.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10217 q_vals: [-inf, -inf, -4.966, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4179 2 visits [1000.0, 1000.0, 984.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10220 q_vals: [-inf, -inf, -4.967, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4180 2 visits [1000.0, 1000.0, 985.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10220 q_vals: [-inf, -inf, -4.962, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4181 2 visits [1000.0, 1000.0, 986.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10221 q_vals: [-inf, -inf, -4.962, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4182 2 visits [1000.0, 1000.0, 987.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10224 q_vals: [-inf, -inf, -4.966, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4183 2 visits [1000.0, 1000.0, 988.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10225 q_vals: [-inf, -inf, -4.961, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10227, "number_of_timesteps": 188832, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4184 2 visits [1000.0, 1000.0, 989.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10227 q_vals: [-inf, -inf, -4.966, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4185 2 visits [1000.0, 1000.0, 990.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10227 q_vals: [-inf, -inf, -4.964, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4186 2 visits [1000.0, 1000.0, 991.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10228 q_vals: [-inf, -inf, -4.962, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4187 2 visits [1000.0, 1000.0, 992.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10229 q_vals: [-inf, -inf, -4.959, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4188 2 visits [1000.0, 1000.0, 993.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10230 q_vals: [-inf, -inf, -4.957, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4189 2 visits [1000.0, 1000.0, 994.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10231 q_vals: [-inf, -inf, -4.956, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4190 2 visits [1000.0, 1000.0, 995.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10234 q_vals: [-inf, -inf, -4.951, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4191 2 visits [1000.0, 1000.0, 996.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10234 q_vals: [-inf, -inf, -4.95, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
{"total_number_of_episodes": 10237, "number_of_timesteps": 189194, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4192 2 visits [1000.0, 1000.0, 997.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10237 q_vals: [-inf, -inf, -4.95, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4193 2 visits [1000.0, 1000.0, 998.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10238 q_vals: [-inf, -inf, -4.945, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4194 2 visits [1000.0, 1000.0, 999.0, 1.0, 1.0, 10.0, 4.0, 342.0, 1.0, 42.0]  episode_count: 10239 q_vals: [-inf, -inf, -4.94, -9.796, -9.796, -9.287, -11.02, -7.205, -9.796, -7.81]
Step 4195 2 visits [1000.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 10242 q_vals: [-inf, -inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
{"total_number_of_episodes": 10247, "number_of_timesteps": 189471, "per_episode_reward": 10.5, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 10258, "number_of_timesteps": 189824, "per_episode_reward": 10.5, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 10268, "number_of_timesteps": 190048, "per_episode_reward": 10.5, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 10278, "number_of_timesteps": 190272, "per_episode_reward": 10.5, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 10289, "number_of_timesteps": 190585, "per_episode_reward": 10.5, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 10300, "number_of_timesteps": 190948, "per_episode_reward": 10.5, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 10310, "number_of_timesteps": 191269, "per_episode_reward": 10.5, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 10323, "number_of_timesteps": 191797, "per_episode_reward": 10.5, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 10333, "number_of_timesteps": 192159, "per_episode_reward": 10.5, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 10343, "number_of_timesteps": 192567, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10353, "number_of_timesteps": 192890, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10363, "number_of_timesteps": 193157, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10374, "number_of_timesteps": 193588, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10385, "number_of_timesteps": 194008, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10395, "number_of_timesteps": 194319, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10405, "number_of_timesteps": 194596, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10415, "number_of_timesteps": 194937, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10426, "number_of_timesteps": 195269, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10440, "number_of_timesteps": 195744, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10451, "number_of_timesteps": 196098, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10461, "number_of_timesteps": 196365, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10471, "number_of_timesteps": 196673, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10481, "number_of_timesteps": 196957, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10491, "number_of_timesteps": 197326, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10503, "number_of_timesteps": 197772, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10513, "number_of_timesteps": 198047, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10525, "number_of_timesteps": 198277, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10536, "number_of_timesteps": 198654, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10546, "number_of_timesteps": 198961, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10560, "number_of_timesteps": 199346, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10570, "number_of_timesteps": 199665, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10581, "number_of_timesteps": 199942, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10591, "number_of_timesteps": 200247, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10602, "number_of_timesteps": 200663, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10613, "number_of_timesteps": 201015, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10624, "number_of_timesteps": 201391, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10634, "number_of_timesteps": 201824, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10644, "number_of_timesteps": 202391, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10654, "number_of_timesteps": 202772, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10667, "number_of_timesteps": 203314, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10679, "number_of_timesteps": 203739, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10690, "number_of_timesteps": 204137, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10700, "number_of_timesteps": 204485, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10711, "number_of_timesteps": 204910, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10721, "number_of_timesteps": 205216, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10731, "number_of_timesteps": 205545, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10742, "number_of_timesteps": 206190, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10752, "number_of_timesteps": 206593, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10763, "number_of_timesteps": 207050, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10775, "number_of_timesteps": 207527, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10785, "number_of_timesteps": 207809, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10795, "number_of_timesteps": 208147, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10805, "number_of_timesteps": 208636, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10817, "number_of_timesteps": 209018, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10827, "number_of_timesteps": 209474, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10837, "number_of_timesteps": 209904, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10847, "number_of_timesteps": 210197, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10858, "number_of_timesteps": 210651, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10868, "number_of_timesteps": 211125, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10880, "number_of_timesteps": 211734, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10890, "number_of_timesteps": 212107, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10900, "number_of_timesteps": 212517, "per_episode_reward": 10.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10910, "number_of_timesteps": 212914, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10920, "number_of_timesteps": 213442, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10931, "number_of_timesteps": 213999, "per_episode_reward": 10.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10943, "number_of_timesteps": 214764, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10953, "number_of_timesteps": 215098, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 10963, "number_of_timesteps": 215587, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 10973, "number_of_timesteps": 216440, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 10983, "number_of_timesteps": 217013, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 10994, "number_of_timesteps": 217427, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 11005, "number_of_timesteps": 218037, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 11015, "number_of_timesteps": 218726, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 11025, "number_of_timesteps": 219164, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 11035, "number_of_timesteps": 219665, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 11045, "number_of_timesteps": 220372, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11056, "number_of_timesteps": 221016, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11066, "number_of_timesteps": 221775, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11076, "number_of_timesteps": 222292, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11088, "number_of_timesteps": 223078, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11099, "number_of_timesteps": 223682, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11110, "number_of_timesteps": 224327, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11120, "number_of_timesteps": 224963, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11132, "number_of_timesteps": 225725, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11142, "number_of_timesteps": 226527, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11153, "number_of_timesteps": 227133, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11164, "number_of_timesteps": 227822, "per_episode_reward": 10.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 11174, "number_of_timesteps": 228523, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11185, "number_of_timesteps": 229316, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11195, "number_of_timesteps": 230604, "per_episode_reward": 10.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11205, "number_of_timesteps": 231729, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11216, "number_of_timesteps": 233090, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11226, "number_of_timesteps": 233921, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11237, "number_of_timesteps": 235410, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11247, "number_of_timesteps": 236318, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11257, "number_of_timesteps": 237011, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11267, "number_of_timesteps": 238253, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11277, "number_of_timesteps": 239399, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11288, "number_of_timesteps": 240674, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11298, "number_of_timesteps": 241996, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11309, "number_of_timesteps": 242951, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11319, "number_of_timesteps": 243660, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11329, "number_of_timesteps": 244300, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11339, "number_of_timesteps": 245703, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11350, "number_of_timesteps": 247048, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11360, "number_of_timesteps": 248238, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11370, "number_of_timesteps": 250113, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11380, "number_of_timesteps": 252063, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11390, "number_of_timesteps": 253664, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11400, "number_of_timesteps": 255117, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11410, "number_of_timesteps": 256032, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11420, "number_of_timesteps": 257129, "per_episode_reward": 11.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11430, "number_of_timesteps": 258176, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11440, "number_of_timesteps": 259468, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11450, "number_of_timesteps": 260769, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11460, "number_of_timesteps": 261644, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11470, "number_of_timesteps": 263024, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11480, "number_of_timesteps": 265026, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},

{"total_number_of_episodes": 11490, "number_of_timesteps": 267355, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11500, "number_of_timesteps": 269603, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11510, "number_of_timesteps": 272471, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 11520, "number_of_timesteps": 275710, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11530, "number_of_timesteps": 278817, "per_episode_reward": 11.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11540, "number_of_timesteps": 281924, "per_episode_reward": 11.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11550, "number_of_timesteps": 284995, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11560, "number_of_timesteps": 287171, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11570, "number_of_timesteps": 288808, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11581, "number_of_timesteps": 290697, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11591, "number_of_timesteps": 292473, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11601, "number_of_timesteps": 294760, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11611, "number_of_timesteps": 296042, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11622, "number_of_timesteps": 297499, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 11632, "number_of_timesteps": 298570, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 11642, "number_of_timesteps": 299823, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11652, "number_of_timesteps": 300608, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11663, "number_of_timesteps": 301607, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11673, "number_of_timesteps": 302432, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11684, "number_of_timesteps": 303388, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11694, "number_of_timesteps": 303930, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11704, "number_of_timesteps": 304831, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11714, "number_of_timesteps": 305696, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11725, "number_of_timesteps": 306171, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11735, "number_of_timesteps": 306894, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11745, "number_of_timesteps": 307921, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11755, "number_of_timesteps": 309180, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11766, "number_of_timesteps": 311412, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11776, "number_of_timesteps": 312211, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11786, "number_of_timesteps": 312789, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11796, "number_of_timesteps": 313622, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11806, "number_of_timesteps": 313984, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11818, "number_of_timesteps": 314351, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11828, "number_of_timesteps": 314603, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11838, "number_of_timesteps": 314819, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11848, "number_of_timesteps": 315169, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11859, "number_of_timesteps": 316608, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11869, "number_of_timesteps": 318821, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11879, "number_of_timesteps": 320621, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11889, "number_of_timesteps": 322089, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11902, "number_of_timesteps": 323267, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11912, "number_of_timesteps": 323627, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11923, "number_of_timesteps": 324056, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11933, "number_of_timesteps": 324538, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11943, "number_of_timesteps": 325856, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11953, "number_of_timesteps": 328292, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11963, "number_of_timesteps": 331322, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11973, "number_of_timesteps": 333811, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11983, "number_of_timesteps": 335911, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11993, "number_of_timesteps": 339763, "per_episode_reward": 11.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12003, "number_of_timesteps": 342529, "per_episode_reward": 11.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12013, "number_of_timesteps": 346168, "per_episode_reward": 11.35, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12023, "number_of_timesteps": 350651, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12033, "number_of_timesteps": 355362, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12043, "number_of_timesteps": 359979, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12053, "number_of_timesteps": 364747, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12063, "number_of_timesteps": 367941, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12073, "number_of_timesteps": 372934, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12084, "number_of_timesteps": 377543, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12094, "number_of_timesteps": 380990, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12104, "number_of_timesteps": 385024, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12114, "number_of_timesteps": 389127, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12124, "number_of_timesteps": 393481, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12134, "number_of_timesteps": 398040, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12144, "number_of_timesteps": 402608, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12154, "number_of_timesteps": 407187, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12164, "number_of_timesteps": 412083, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12174, "number_of_timesteps": 416471, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12184, "number_of_timesteps": 421262, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12194, "number_of_timesteps": 425505, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12204, "number_of_timesteps": 430174, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12214, "number_of_timesteps": 434797, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12224, "number_of_timesteps": 438930, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12234, "number_of_timesteps": 443804, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12244, "number_of_timesteps": 448346, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12254, "number_of_timesteps": 453346, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12264, "number_of_timesteps": 458131, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12275, "number_of_timesteps": 463330, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12285, "number_of_timesteps": 467581, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12295, "number_of_timesteps": 471883, "per_episode_reward": 11.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12305, "number_of_timesteps": 476407, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12315, "number_of_timesteps": 481181, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12325, "number_of_timesteps": 485954, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12335, "number_of_timesteps": 490373, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12345, "number_of_timesteps": 495373, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12355, "number_of_timesteps": 499912, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12365, "number_of_timesteps": 504688, "per_episode_reward": 11.75, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12375, "number_of_timesteps": 509618, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12385, "number_of_timesteps": 514341, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12395, "number_of_timesteps": 518758, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12405, "number_of_timesteps": 523725, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12416, "number_of_timesteps": 528358, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12426, "number_of_timesteps": 533358, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12436, "number_of_timesteps": 537871, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12446, "number_of_timesteps": 542473, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12456, "number_of_timesteps": 546576, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12466, "number_of_timesteps": 551337, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12476, "number_of_timesteps": 555637, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12486, "number_of_timesteps": 560567, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12496, "number_of_timesteps": 565370, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12506, "number_of_timesteps": 568976, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12516, "number_of_timesteps": 573832, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12526, "number_of_timesteps": 578704, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12536, "number_of_timesteps": 583535, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12546, "number_of_timesteps": 587207, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12556, "number_of_timesteps": 592022, "per_episode_reward": 11.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 12566, "number_of_timesteps": 597022, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12576, "number_of_timesteps": 602022, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12586, "number_of_timesteps": 606894, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12596, "number_of_timesteps": 611411, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12606, "number_of_timesteps": 616411, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12616, "number_of_timesteps": 621290, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12626, "number_of_timesteps": 626290, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12636, "number_of_timesteps": 631029, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12646, "number_of_timesteps": 635824, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12656, "number_of_timesteps": 640576, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12666, "number_of_timesteps": 645287, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12676, "number_of_timesteps": 649785, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12686, "number_of_timesteps": 654613, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12696, "number_of_timesteps": 659310, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12706, "number_of_timesteps": 663860, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12716, "number_of_timesteps": 668552, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12726, "number_of_timesteps": 673339, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12736, "number_of_timesteps": 677823, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12746, "number_of_timesteps": 682778, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12756, "number_of_timesteps": 687558, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12766, "number_of_timesteps": 692558, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12776, "number_of_timesteps": 696774, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12786, "number_of_timesteps": 701774, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12796, "number_of_timesteps": 706426, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12806, "number_of_timesteps": 711263, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12816, "number_of_timesteps": 715629, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12826, "number_of_timesteps": 720629, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12836, "number_of_timesteps": 725277, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12846, "number_of_timesteps": 730024, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12856, "number_of_timesteps": 734711, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12866, "number_of_timesteps": 739711, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12876, "number_of_timesteps": 744095, "per_episode_reward": 11.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 12886, "number_of_timesteps": 749044, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12896, "number_of_timesteps": 753822, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12906, "number_of_timesteps": 758822, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12916, "number_of_timesteps": 763301, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12926, "number_of_timesteps": 768301, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12936, "number_of_timesteps": 773301, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12946, "number_of_timesteps": 778093, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12956, "number_of_timesteps": 783093, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12966, "number_of_timesteps": 787747, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12976, "number_of_timesteps": 792747, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12986, "number_of_timesteps": 797499, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12996, "number_of_timesteps": 802176, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 13006, "number_of_timesteps": 806727, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13016, "number_of_timesteps": 811727, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13026, "number_of_timesteps": 816727, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13036, "number_of_timesteps": 821485, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13046, "number_of_timesteps": 826485, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13056, "number_of_timesteps": 831485, "per_episode_reward": 12.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13066, "number_of_timesteps": 836485, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13076, "number_of_timesteps": 841164, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13086, "number_of_timesteps": 846164, "per_episode_reward": 12.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13096, "number_of_timesteps": 851164, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13106, "number_of_timesteps": 855736, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13116, "number_of_timesteps": 859999, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13126, "number_of_timesteps": 864999, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13136, "number_of_timesteps": 869967, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13146, "number_of_timesteps": 874503, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13156, "number_of_timesteps": 878759, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13166, "number_of_timesteps": 883026, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13176, "number_of_timesteps": 888026, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 13186, "number_of_timesteps": 892737, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13196, "number_of_timesteps": 897389, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13206, "number_of_timesteps": 902350, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13216, "number_of_timesteps": 907231, "per_episode_reward": 12.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13226, "number_of_timesteps": 911842, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13236, "number_of_timesteps": 916539, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13246, "number_of_timesteps": 921539, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13256, "number_of_timesteps": 926539, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13266, "number_of_timesteps": 931539, "per_episode_reward": 12.35, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13276, "number_of_timesteps": 936356, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13286, "number_of_timesteps": 941168, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13296, "number_of_timesteps": 946168, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13306, "number_of_timesteps": 951168, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13316, "number_of_timesteps": 956168, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13326, "number_of_timesteps": 961168, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13336, "number_of_timesteps": 966168, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13346, "number_of_timesteps": 971168, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13356, "number_of_timesteps": 976168, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13366, "number_of_timesteps": 980894, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13376, "number_of_timesteps": 985852, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13386, "number_of_timesteps": 990852, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13396, "number_of_timesteps": 995409, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13406, "number_of_timesteps": 1000409, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 13416, "number_of_timesteps": 1005409, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 13426, "number_of_timesteps": 1010152, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 13436, "number_of_timesteps": 1015152, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 13446, "number_of_timesteps": 1020152, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 13456, "number_of_timesteps": 1025152, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 13466, "number_of_timesteps": 1030152, "per_episode_reward": 12.55, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 13476, "number_of_timesteps": 1035152, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 13486, "number_of_timesteps": 1040152, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 13496, "number_of_timesteps": 1045152, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13506, "number_of_timesteps": 1050152, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13516, "number_of_timesteps": 1054864, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13526, "number_of_timesteps": 1059260, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13536, "number_of_timesteps": 1064260, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13546, "number_of_timesteps": 1068901, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13556, "number_of_timesteps": 1073567, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 13566, "number_of_timesteps": 1078567, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13576, "number_of_timesteps": 1083397, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13586, "number_of_timesteps": 1088013, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13597, "number_of_timesteps": 1093293, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13607, "number_of_timesteps": 1098293, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13617, "number_of_timesteps": 1103293, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13627, "number_of_timesteps": 1108293, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13637, "number_of_timesteps": 1113293, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13648, "number_of_timesteps": 1118411, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13658, "number_of_timesteps": 1123363, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13668, "number_of_timesteps": 1128363, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13678, "number_of_timesteps": 1133047, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13688, "number_of_timesteps": 1137858, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13698, "number_of_timesteps": 1142858, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13708, "number_of_timesteps": 1147858, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13718, "number_of_timesteps": 1152858, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13728, "number_of_timesteps": 1157704, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13738, "number_of_timesteps": 1162371, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13748, "number_of_timesteps": 1166859, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13758, "number_of_timesteps": 1171755, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13768, "number_of_timesteps": 1176528, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13779, "number_of_timesteps": 1181853, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13789, "number_of_timesteps": 1186853, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13800, "number_of_timesteps": 1192249, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13810, "number_of_timesteps": 1197249, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13820, "number_of_timesteps": 1202249, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13830, "number_of_timesteps": 1207249, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13840, "number_of_timesteps": 1211913, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13850, "number_of_timesteps": 1216913, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13860, "number_of_timesteps": 1221913, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13870, "number_of_timesteps": 1226913, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13880, "number_of_timesteps": 1231913, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13890, "number_of_timesteps": 1236913, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13900, "number_of_timesteps": 1241913, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13910, "number_of_timesteps": 1246913, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13920, "number_of_timesteps": 1251656, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13930, "number_of_timesteps": 1256223, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13940, "number_of_timesteps": 1261223, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13950, "number_of_timesteps": 1266022, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13960, "number_of_timesteps": 1270892, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13970, "number_of_timesteps": 1275642, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 13980, "number_of_timesteps": 1280642, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 13990, "number_of_timesteps": 1285642, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14000, "number_of_timesteps": 1290528, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14010, "number_of_timesteps": 1295528, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14020, "number_of_timesteps": 1300528, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14030, "number_of_timesteps": 1305528, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14040, "number_of_timesteps": 1310528, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14050, "number_of_timesteps": 1315528, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14060, "number_of_timesteps": 1320528, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14070, "number_of_timesteps": 1325528, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14080, "number_of_timesteps": 1330352, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14090, "number_of_timesteps": 1335352, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14100, "number_of_timesteps": 1340352, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14110, "number_of_timesteps": 1345352, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14120, "number_of_timesteps": 1350352, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14130, "number_of_timesteps": 1355352, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14140, "number_of_timesteps": 1360352, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14150, "number_of_timesteps": 1365352, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 14160, "number_of_timesteps": 1370352, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14170, "number_of_timesteps": 1375352, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14180, "number_of_timesteps": 1380352, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14190, "number_of_timesteps": 1385352, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14200, "number_of_timesteps": 1390352, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14210, "number_of_timesteps": 1395352, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14220, "number_of_timesteps": 1400352, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14230, "number_of_timesteps": 1404728, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14240, "number_of_timesteps": 1409349, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14250, "number_of_timesteps": 1414171, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14260, "number_of_timesteps": 1419171, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 14270, "number_of_timesteps": 1423851, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14280, "number_of_timesteps": 1428851, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14290, "number_of_timesteps": 1433851, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14300, "number_of_timesteps": 1438807, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14310, "number_of_timesteps": 1443807, "per_episode_reward": 13.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14320, "number_of_timesteps": 1448807, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14330, "number_of_timesteps": 1453807, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14340, "number_of_timesteps": 1458807, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14350, "number_of_timesteps": 1463807, "per_episode_reward": 13.25, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14360, "number_of_timesteps": 1468807, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14370, "number_of_timesteps": 1473807, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14380, "number_of_timesteps": 1478563, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14390, "number_of_timesteps": 1483563, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14400, "number_of_timesteps": 1487856, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14410, "number_of_timesteps": 1492758, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14420, "number_of_timesteps": 1497561, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14430, "number_of_timesteps": 1502561, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14440, "number_of_timesteps": 1507466, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14450, "number_of_timesteps": 1512399, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14460, "number_of_timesteps": 1517399, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14470, "number_of_timesteps": 1522399, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14480, "number_of_timesteps": 1527399, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14490, "number_of_timesteps": 1532116, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14500, "number_of_timesteps": 1536519, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14510, "number_of_timesteps": 1541447, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14520, "number_of_timesteps": 1546447, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14530, "number_of_timesteps": 1551447, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14540, "number_of_timesteps": 1556447, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14550, "number_of_timesteps": 1561447, "per_episode_reward": 13.35, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 14560, "number_of_timesteps": 1566447, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14570, "number_of_timesteps": 1571447, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14580, "number_of_timesteps": 1576447, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14590, "number_of_timesteps": 1581447, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14600, "number_of_timesteps": 1586447, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14610, "number_of_timesteps": 1591353, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14620, "number_of_timesteps": 1595931, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14630, "number_of_timesteps": 1600931, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14640, "number_of_timesteps": 1605931, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14650, "number_of_timesteps": 1610931, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14660, "number_of_timesteps": 1615931, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14670, "number_of_timesteps": 1620916, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14680, "number_of_timesteps": 1625916, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14690, "number_of_timesteps": 1630555, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14700, "number_of_timesteps": 1635451, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14710, "number_of_timesteps": 1640451, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14720, "number_of_timesteps": 1645451, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14730, "number_of_timesteps": 1650451, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14740, "number_of_timesteps": 1655202, "per_episode_reward": 13.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 14750, "number_of_timesteps": 1660202, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14760, "number_of_timesteps": 1665202, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14770, "number_of_timesteps": 1670202, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14780, "number_of_timesteps": 1675202, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14790, "number_of_timesteps": 1679689, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14800, "number_of_timesteps": 1684689, "per_episode_reward": 13.55, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14810, "number_of_timesteps": 1689526, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14820, "number_of_timesteps": 1694526, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14830, "number_of_timesteps": 1699526, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14840, "number_of_timesteps": 1704526, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14850, "number_of_timesteps": 1709526, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14860, "number_of_timesteps": 1714526, "per_episode_reward": 13.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14870, "number_of_timesteps": 1719526, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14880, "number_of_timesteps": 1724526, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14890, "number_of_timesteps": 1729526, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14900, "number_of_timesteps": 1734289, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14910, "number_of_timesteps": 1739289, "per_episode_reward": 13.75, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14920, "number_of_timesteps": 1744289, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14930, "number_of_timesteps": 1749289, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14940, "number_of_timesteps": 1754289, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14950, "number_of_timesteps": 1758921, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14960, "number_of_timesteps": 1763921, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14970, "number_of_timesteps": 1768921, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14980, "number_of_timesteps": 1773921, "per_episode_reward": 13.85, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14990, "number_of_timesteps": 1778921, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15000, "number_of_timesteps": 1783921, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15010, "number_of_timesteps": 1788921, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15020, "number_of_timesteps": 1793921, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15030, "number_of_timesteps": 1798921, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15040, "number_of_timesteps": 1803921, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15050, "number_of_timesteps": 1808798, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15060, "number_of_timesteps": 1813459, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15070, "number_of_timesteps": 1818459, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15080, "number_of_timesteps": 1823459, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15090, "number_of_timesteps": 1828459, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15100, "number_of_timesteps": 1833313, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15110, "number_of_timesteps": 1837898, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15120, "number_of_timesteps": 1842898, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15130, "number_of_timesteps": 1847586, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15140, "number_of_timesteps": 1852586, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15150, "number_of_timesteps": 1857393, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15160, "number_of_timesteps": 1862019, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15170, "number_of_timesteps": 1867019, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15180, "number_of_timesteps": 1872019, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15190, "number_of_timesteps": 1876462, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15200, "number_of_timesteps": 1881462, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15210, "number_of_timesteps": 1886067, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15220, "number_of_timesteps": 1891067, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15230, "number_of_timesteps": 1896067, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15240, "number_of_timesteps": 1901067, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15250, "number_of_timesteps": 1906067, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15260, "number_of_timesteps": 1910999, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15270, "number_of_timesteps": 1915769, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15280, "number_of_timesteps": 1920702, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15290, "number_of_timesteps": 1925702, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15300, "number_of_timesteps": 1930702, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15310, "number_of_timesteps": 1935180, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15320, "number_of_timesteps": 1940180, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15330, "number_of_timesteps": 1945180, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15340, "number_of_timesteps": 1949815, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 15350, "number_of_timesteps": 1954797, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15360, "number_of_timesteps": 1959629, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15370, "number_of_timesteps": 1964629, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15380, "number_of_timesteps": 1969629, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15390, "number_of_timesteps": 1974629, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15400, "number_of_timesteps": 1979629, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15410, "number_of_timesteps": 1984629, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15420, "number_of_timesteps": 1989629, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15430, "number_of_timesteps": 1993883, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15440, "number_of_timesteps": 1998883, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15450, "number_of_timesteps": 2003883, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15460, "number_of_timesteps": 2008883, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15470, "number_of_timesteps": 2013883, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15480, "number_of_timesteps": 2018883, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15490, "number_of_timesteps": 2023883, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15500, "number_of_timesteps": 2028883, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15510, "number_of_timesteps": 2033883, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15520, "number_of_timesteps": 2038883, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15530, "number_of_timesteps": 2043601, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15540, "number_of_timesteps": 2048344, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15550, "number_of_timesteps": 2053344, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15560, "number_of_timesteps": 2058344, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15570, "number_of_timesteps": 2063344, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15580, "number_of_timesteps": 2068344, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15590, "number_of_timesteps": 2073344, "per_episode_reward": 14.25, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15600, "number_of_timesteps": 2078258, "per_episode_reward": 14.35, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15610, "number_of_timesteps": 2082887, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15620, "number_of_timesteps": 2087887, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15630, "number_of_timesteps": 2092887, "per_episode_reward": 14.4, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15640, "number_of_timesteps": 2097887, "per_episode_reward": 14.45, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15650, "number_of_timesteps": 2102887, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15660, "number_of_timesteps": 2107887, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15670, "number_of_timesteps": 2112887, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15680, "number_of_timesteps": 2117655, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 15690, "number_of_timesteps": 2122655, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15700, "number_of_timesteps": 2127655, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15710, "number_of_timesteps": 2132579, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15720, "number_of_timesteps": 2137579, "per_episode_reward": 14.55, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15730, "number_of_timesteps": 2142579, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15740, "number_of_timesteps": 2147579, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15750, "number_of_timesteps": 2152579, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15760, "number_of_timesteps": 2157579, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15770, "number_of_timesteps": 2162402, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15780, "number_of_timesteps": 2167402, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15790, "number_of_timesteps": 2172402, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15800, "number_of_timesteps": 2177402, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15810, "number_of_timesteps": 2182402, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 15820, "number_of_timesteps": 2187402, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15830, "number_of_timesteps": 2192402, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15840, "number_of_timesteps": 2197402, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15850, "number_of_timesteps": 2202314, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15860, "number_of_timesteps": 2207280, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15870, "number_of_timesteps": 2212052, "per_episode_reward": 14.75, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15880, "number_of_timesteps": 2217052, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15890, "number_of_timesteps": 2222052, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15900, "number_of_timesteps": 2227052, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15910, "number_of_timesteps": 2232052, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15920, "number_of_timesteps": 2237052, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15930, "number_of_timesteps": 2242052, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15940, "number_of_timesteps": 2247052, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15950, "number_of_timesteps": 2252052, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15960, "number_of_timesteps": 2257052, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},

{"total_number_of_episodes": 15970, "number_of_timesteps": 2262052, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15980, "number_of_timesteps": 2267052, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15990, "number_of_timesteps": 2272052, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16000, "number_of_timesteps": 2277052, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16010, "number_of_timesteps": 2282052, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16020, "number_of_timesteps": 2286632, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16030, "number_of_timesteps": 2291632, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16040, "number_of_timesteps": 2296481, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16050, "number_of_timesteps": 2301481, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16060, "number_of_timesteps": 2306481, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16070, "number_of_timesteps": 2311481, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16080, "number_of_timesteps": 2316481, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16090, "number_of_timesteps": 2321481, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16100, "number_of_timesteps": 2326481, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16110, "number_of_timesteps": 2331069, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16120, "number_of_timesteps": 2336069, "per_episode_reward": 14.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 16130, "number_of_timesteps": 2341069, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16140, "number_of_timesteps": 2346069, "per_episode_reward": 14.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16150, "number_of_timesteps": 2351069, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16160, "number_of_timesteps": 2356069, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16170, "number_of_timesteps": 2360956, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16180, "number_of_timesteps": 2365956, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16190, "number_of_timesteps": 2370956, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16200, "number_of_timesteps": 2375956, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16210, "number_of_timesteps": 2380956, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16220, "number_of_timesteps": 2385849, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16230, "number_of_timesteps": 2390849, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16240, "number_of_timesteps": 2395849, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16250, "number_of_timesteps": 2400849, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16260, "number_of_timesteps": 2405849, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16270, "number_of_timesteps": 2410849, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16280, "number_of_timesteps": 2415849, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16290, "number_of_timesteps": 2420849, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16300, "number_of_timesteps": 2425699, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16310, "number_of_timesteps": 2430699, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16320, "number_of_timesteps": 2435699, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16330, "number_of_timesteps": 2440699, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16340, "number_of_timesteps": 2445699, "per_episode_reward": 15.35, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16350, "number_of_timesteps": 2450699, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16360, "number_of_timesteps": 2455699, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16370, "number_of_timesteps": 2460699, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16380, "number_of_timesteps": 2465699, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16390, "number_of_timesteps": 2470645, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16400, "number_of_timesteps": 2475557, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16410, "number_of_timesteps": 2480557, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16420, "number_of_timesteps": 2485557, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16430, "number_of_timesteps": 2490557, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16440, "number_of_timesteps": 2495557, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16450, "number_of_timesteps": 2500408, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16460, "number_of_timesteps": 2505408, "per_episode_reward": 15.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 16470, "number_of_timesteps": 2510408, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16480, "number_of_timesteps": 2515408, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16490, "number_of_timesteps": 2520408, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16501, "number_of_timesteps": 2525464, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16511, "number_of_timesteps": 2530464, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16521, "number_of_timesteps": 2535464, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16531, "number_of_timesteps": 2540464, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16541, "number_of_timesteps": 2545422, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16551, "number_of_timesteps": 2550422, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16561, "number_of_timesteps": 2555422, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16571, "number_of_timesteps": 2560422, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 16581, "number_of_timesteps": 2565422, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16591, "number_of_timesteps": 2570422, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16601, "number_of_timesteps": 2575422, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16611, "number_of_timesteps": 2580422, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16621, "number_of_timesteps": 2585422, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16631, "number_of_timesteps": 2590422, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16641, "number_of_timesteps": 2595422, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16651, "number_of_timesteps": 2600422, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16661, "number_of_timesteps": 2605422, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16671, "number_of_timesteps": 2610422, "per_episode_reward": 15.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16681, "number_of_timesteps": 2615287, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16691, "number_of_timesteps": 2620287, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16701, "number_of_timesteps": 2625287, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16711, "number_of_timesteps": 2630287, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16721, "number_of_timesteps": 2635287, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16731, "number_of_timesteps": 2640287, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16741, "number_of_timesteps": 2645287, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16751, "number_of_timesteps": 2650287, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16761, "number_of_timesteps": 2655287, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16771, "number_of_timesteps": 2660287, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 16781, "number_of_timesteps": 2665287, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 16791, "number_of_timesteps": 2670287, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 16801, "number_of_timesteps": 2675287, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 16811, "number_of_timesteps": 2680273, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 16821, "number_of_timesteps": 2685273, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 16831, "number_of_timesteps": 2690144, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 16841, "number_of_timesteps": 2694877, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 16851, "number_of_timesteps": 2699877, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 16861, "number_of_timesteps": 2704877, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 16871, "number_of_timesteps": 2709877, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16881, "number_of_timesteps": 2714877, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16891, "number_of_timesteps": 2719633, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16901, "number_of_timesteps": 2724025, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16911, "number_of_timesteps": 2729025, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16921, "number_of_timesteps": 2734025, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16931, "number_of_timesteps": 2739025, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16941, "number_of_timesteps": 2744025, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16951, "number_of_timesteps": 2749025, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16961, "number_of_timesteps": 2754025, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16971, "number_of_timesteps": 2759025, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16981, "number_of_timesteps": 2764025, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 16991, "number_of_timesteps": 2769025, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17001, "number_of_timesteps": 2774025, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17011, "number_of_timesteps": 2779025, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17021, "number_of_timesteps": 2783909, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17031, "number_of_timesteps": 2788909, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17041, "number_of_timesteps": 2793559, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17051, "number_of_timesteps": 2798312, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17061, "number_of_timesteps": 2803044, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17071, "number_of_timesteps": 2808044, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17081, "number_of_timesteps": 2812683, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17091, "number_of_timesteps": 2817683, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17101, "number_of_timesteps": 2822683, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17111, "number_of_timesteps": 2827683, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17121, "number_of_timesteps": 2832683, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17131, "number_of_timesteps": 2837359, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17141, "number_of_timesteps": 2842359, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17151, "number_of_timesteps": 2847359, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17161, "number_of_timesteps": 2852359, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17171, "number_of_timesteps": 2857359, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17181, "number_of_timesteps": 2862359, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17191, "number_of_timesteps": 2867359, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17201, "number_of_timesteps": 2872359, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17211, "number_of_timesteps": 2877359, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17221, "number_of_timesteps": 2881835, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17231, "number_of_timesteps": 2886835, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17241, "number_of_timesteps": 2891835, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17251, "number_of_timesteps": 2896835, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17261, "number_of_timesteps": 2901835, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17271, "number_of_timesteps": 2906682, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17281, "number_of_timesteps": 2911682, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17291, "number_of_timesteps": 2916682, "per_episode_reward": 16.65, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 17301, "number_of_timesteps": 2921682, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17311, "number_of_timesteps": 2926293, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17321, "number_of_timesteps": 2931293, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17331, "number_of_timesteps": 2936293, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17341, "number_of_timesteps": 2941293, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17351, "number_of_timesteps": 2946293, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17361, "number_of_timesteps": 2951293, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17371, "number_of_timesteps": 2956293, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17381, "number_of_timesteps": 2961293, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17391, "number_of_timesteps": 2966293, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},

{"total_number_of_episodes": 17401, "number_of_timesteps": 2971293, "per_episode_reward": 16.85, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17411, "number_of_timesteps": 2976293, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17421, "number_of_timesteps": 2981293, "per_episode_reward": 16.95, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17431, "number_of_timesteps": 2986293, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17441, "number_of_timesteps": 2991293, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17451, "number_of_timesteps": 2996058, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17461, "number_of_timesteps": 3000759, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17471, "number_of_timesteps": 3005444, "per_episode_reward": 17.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17481, "number_of_timesteps": 3010444, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17491, "number_of_timesteps": 3015444, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17501, "number_of_timesteps": 3020261, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17511, "number_of_timesteps": 3025261, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17521, "number_of_timesteps": 3030261, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17531, "number_of_timesteps": 3035261, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17541, "number_of_timesteps": 3039890, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17551, "number_of_timesteps": 3044690, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17561, "number_of_timesteps": 3049690, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17571, "number_of_timesteps": 3054690, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17581, "number_of_timesteps": 3059610, "per_episode_reward": 17.15, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 17591, "number_of_timesteps": 3064610, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17601, "number_of_timesteps": 3069610, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17611, "number_of_timesteps": 3074610, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17621, "number_of_timesteps": 3079610, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17631, "number_of_timesteps": 3084610, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17641, "number_of_timesteps": 3089610, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17651, "number_of_timesteps": 3094610, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17661, "number_of_timesteps": 3099610, "per_episode_reward": 17.35, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17671, "number_of_timesteps": 3104610, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17681, "number_of_timesteps": 3109610, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17691, "number_of_timesteps": 3114610, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17701, "number_of_timesteps": 3119610, "per_episode_reward": 17.45, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17711, "number_of_timesteps": 3124610, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17721, "number_of_timesteps": 3129610, "per_episode_reward": 17.55, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17731, "number_of_timesteps": 3134610, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17741, "number_of_timesteps": 3139610, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17751, "number_of_timesteps": 3144610, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17761, "number_of_timesteps": 3149610, "per_episode_reward": 17.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17771, "number_of_timesteps": 3154610, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17781, "number_of_timesteps": 3159610, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17791, "number_of_timesteps": 3164610, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17801, "number_of_timesteps": 3169610, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17811, "number_of_timesteps": 3174610, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17821, "number_of_timesteps": 3179610, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},

{"total_number_of_episodes": 17831, "number_of_timesteps": 3184192, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17841, "number_of_timesteps": 3189192, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17851, "number_of_timesteps": 3194192, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17861, "number_of_timesteps": 3198829, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17871, "number_of_timesteps": 3203829, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17881, "number_of_timesteps": 3208695, "per_episode_reward": 17.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17891, "number_of_timesteps": 3213695, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17901, "number_of_timesteps": 3218695, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17911, "number_of_timesteps": 3223695, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17921, "number_of_timesteps": 3228695, "per_episode_reward": 17.85, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17931, "number_of_timesteps": 3233695, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17941, "number_of_timesteps": 3238695, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17951, "number_of_timesteps": 3243695, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17961, "number_of_timesteps": 3248695, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17971, "number_of_timesteps": 3253695, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17981, "number_of_timesteps": 3258695, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 17991, "number_of_timesteps": 3263695, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18001, "number_of_timesteps": 3268695, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18011, "number_of_timesteps": 3273695, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 18021, "number_of_timesteps": 3278695, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18031, "number_of_timesteps": 3283695, "per_episode_reward": 18.15, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 18041, "number_of_timesteps": 3288695, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 18051, "number_of_timesteps": 3293695, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 18061, "number_of_timesteps": 3298695, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 18071, "number_of_timesteps": 3303695, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 18081, "number_of_timesteps": 3308695, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 18091, "number_of_timesteps": 3313695, "per_episode_reward": 18.35, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.14999999999999858},

{"total_number_of_episodes": 18101, "number_of_timesteps": 3318695, "per_episode_reward": 18.45, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 18111, "number_of_timesteps": 3323695, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 18121, "number_of_timesteps": 3328695, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18131, "number_of_timesteps": 3333695, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18141, "number_of_timesteps": 3338695, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18151, "number_of_timesteps": 3343695, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18161, "number_of_timesteps": 3348695, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18171, "number_of_timesteps": 3353695, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18181, "number_of_timesteps": 3358695, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18191, "number_of_timesteps": 3363695, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18201, "number_of_timesteps": 3368695, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18211, "number_of_timesteps": 3373695, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18221, "number_of_timesteps": 3378695, "per_episode_reward": 18.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},

{"total_number_of_episodes": 18231, "number_of_timesteps": 3383695, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18241, "number_of_timesteps": 3388695, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18251, "number_of_timesteps": 3393695, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18261, "number_of_timesteps": 3398695, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18271, "number_of_timesteps": 3403695, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18281, "number_of_timesteps": 3408695, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18291, "number_of_timesteps": 3413695, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18301, "number_of_timesteps": 3418695, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18311, "number_of_timesteps": 3423695, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18321, "number_of_timesteps": 3428695, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18331, "number_of_timesteps": 3433695, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18341, "number_of_timesteps": 3438695, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18351, "number_of_timesteps": 3443695, "per_episode_reward": 18.75, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18361, "number_of_timesteps": 3448695, "per_episode_reward": 18.85, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18371, "number_of_timesteps": 3453695, "per_episode_reward": 18.9, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18381, "number_of_timesteps": 3458695, "per_episode_reward": 18.95, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18391, "number_of_timesteps": 3463695, "per_episode_reward": 19.05, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18401, "number_of_timesteps": 3468695, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18411, "number_of_timesteps": 3473695, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18421, "number_of_timesteps": 3478695, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18431, "number_of_timesteps": 3483695, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18441, "number_of_timesteps": 3488695, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18451, "number_of_timesteps": 3493695, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18461, "number_of_timesteps": 3498695, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18471, "number_of_timesteps": 3503695, "per_episode_reward": 19.2, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 18481, "number_of_timesteps": 3508695, "per_episode_reward": 19.25, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18491, "number_of_timesteps": 3513695, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18501, "number_of_timesteps": 3518695, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18511, "number_of_timesteps": 3523695, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18521, "number_of_timesteps": 3528695, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18531, "number_of_timesteps": 3533571, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18541, "number_of_timesteps": 3538571, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18551, "number_of_timesteps": 3543571, "per_episode_reward": 19.35, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18561, "number_of_timesteps": 3548571, "per_episode_reward": 19.45, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18571, "number_of_timesteps": 3553571, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18581, "number_of_timesteps": 3558571, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18591, "number_of_timesteps": 3563571, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18601, "number_of_timesteps": 3568571, "per_episode_reward": 19.55, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18611, "number_of_timesteps": 3573571, "per_episode_reward": 19.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18621, "number_of_timesteps": 3578449, "per_episode_reward": 19.65, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18631, "number_of_timesteps": 3583449, "per_episode_reward": 19.7, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18641, "number_of_timesteps": 3588449, "per_episode_reward": 19.75, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18651, "number_of_timesteps": 3593449, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18661, "number_of_timesteps": 3598433, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18671, "number_of_timesteps": 3603203, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18681, "number_of_timesteps": 3608203, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18691, "number_of_timesteps": 3613203, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18701, "number_of_timesteps": 3618203, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18711, "number_of_timesteps": 3623203, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18721, "number_of_timesteps": 3628203, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18731, "number_of_timesteps": 3633203, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18741, "number_of_timesteps": 3638203, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18751, "number_of_timesteps": 3643203, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18761, "number_of_timesteps": 3647889, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18771, "number_of_timesteps": 3652889, "per_episode_reward": 19.85, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18781, "number_of_timesteps": 3657889, "per_episode_reward": 19.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18791, "number_of_timesteps": 3662889, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18801, "number_of_timesteps": 3667889, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18811, "number_of_timesteps": 3672889, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18821, "number_of_timesteps": 3677889, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18831, "number_of_timesteps": 3682889, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18841, "number_of_timesteps": 3687889, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18851, "number_of_timesteps": 3692889, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 18861, "number_of_timesteps": 3697889, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},

{"total_number_of_episodes": 18871, "number_of_timesteps": 3702889, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18881, "number_of_timesteps": 3707889, "per_episode_reward": 20.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18891, "number_of_timesteps": 3712889, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18901, "number_of_timesteps": 3717889, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18911, "number_of_timesteps": 3722889, "per_episode_reward": 20.15, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18921, "number_of_timesteps": 3727889, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18931, "number_of_timesteps": 3732889, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18941, "number_of_timesteps": 3737889, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18951, "number_of_timesteps": 3742889, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18961, "number_of_timesteps": 3747283, "per_episode_reward": 20.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},

{"total_number_of_episodes": 18971, "number_of_timesteps": 3752283, "per_episode_reward": 20.3, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18981, "number_of_timesteps": 3757283, "per_episode_reward": 20.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 18991, "number_of_timesteps": 3762283, "per_episode_reward": 20.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19001, "number_of_timesteps": 3767283, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19011, "number_of_timesteps": 3772283, "per_episode_reward": 20.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19021, "number_of_timesteps": 3777283, "per_episode_reward": 20.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19031, "number_of_timesteps": 3782283, "per_episode_reward": 20.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19041, "number_of_timesteps": 3787283, "per_episode_reward": 20.55, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19051, "number_of_timesteps": 3792283, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19061, "number_of_timesteps": 3797283, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19071, "number_of_timesteps": 3802283, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19081, "number_of_timesteps": 3807283, "per_episode_reward": 20.65, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19091, "number_of_timesteps": 3812283, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19101, "number_of_timesteps": 3817283, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19111, "number_of_timesteps": 3822283, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19121, "number_of_timesteps": 3827283, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19131, "number_of_timesteps": 3832283, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19141, "number_of_timesteps": 3837283, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19151, "number_of_timesteps": 3842283, "per_episode_reward": 20.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19161, "number_of_timesteps": 3846798, "per_episode_reward": 20.9, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19171, "number_of_timesteps": 3851798, "per_episode_reward": 20.95, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19181, "number_of_timesteps": 3856798, "per_episode_reward": 21.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19191, "number_of_timesteps": 3861798, "per_episode_reward": 21.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19201, "number_of_timesteps": 3866798, "per_episode_reward": 21.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19211, "number_of_timesteps": 3871798, "per_episode_reward": 21.05, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19221, "number_of_timesteps": 3876798, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19231, "number_of_timesteps": 3881798, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19241, "number_of_timesteps": 3886798, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19251, "number_of_timesteps": 3891798, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19261, "number_of_timesteps": 3896798, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19271, "number_of_timesteps": 3901798, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19281, "number_of_timesteps": 3906798, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19291, "number_of_timesteps": 3911798, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19301, "number_of_timesteps": 3916798, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19311, "number_of_timesteps": 3921798, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19321, "number_of_timesteps": 3926798, "per_episode_reward": 21.35, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19331, "number_of_timesteps": 3931798, "per_episode_reward": 21.4, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19341, "number_of_timesteps": 3936798, "per_episode_reward": 21.4, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19351, "number_of_timesteps": 3941798, "per_episode_reward": 21.45, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19361, "number_of_timesteps": 3946798, "per_episode_reward": 21.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19371, "number_of_timesteps": 3951798, "per_episode_reward": 21.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19381, "number_of_timesteps": 3956798, "per_episode_reward": 21.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19391, "number_of_timesteps": 3961798, "per_episode_reward": 21.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19401, "number_of_timesteps": 3966798, "per_episode_reward": 21.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19411, "number_of_timesteps": 3971798, "per_episode_reward": 21.55, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19421, "number_of_timesteps": 3976798, "per_episode_reward": 21.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19431, "number_of_timesteps": 3981798, "per_episode_reward": 21.7, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19441, "number_of_timesteps": 3986798, "per_episode_reward": 21.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19451, "number_of_timesteps": 3991798, "per_episode_reward": 21.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19461, "number_of_timesteps": 3996798, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19471, "number_of_timesteps": 4001798, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19481, "number_of_timesteps": 4006798, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19491, "number_of_timesteps": 4011798, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19501, "number_of_timesteps": 4016798, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19511, "number_of_timesteps": 4021798, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19521, "number_of_timesteps": 4026798, "per_episode_reward": 21.85, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19531, "number_of_timesteps": 4031798, "per_episode_reward": 21.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19541, "number_of_timesteps": 4036798, "per_episode_reward": 21.9, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19551, "number_of_timesteps": 4041798, "per_episode_reward": 21.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19561, "number_of_timesteps": 4046798, "per_episode_reward": 22.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19571, "number_of_timesteps": 4051798, "per_episode_reward": 22.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19581, "number_of_timesteps": 4056798, "per_episode_reward": 22.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19591, "number_of_timesteps": 4061798, "per_episode_reward": 22.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19601, "number_of_timesteps": 4066798, "per_episode_reward": 22.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19611, "number_of_timesteps": 4071798, "per_episode_reward": 22.15, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19621, "number_of_timesteps": 4076798, "per_episode_reward": 22.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19631, "number_of_timesteps": 4081798, "per_episode_reward": 22.25, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19641, "number_of_timesteps": 4086798, "per_episode_reward": 22.45, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 19651, "number_of_timesteps": 4091798, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 19661, "number_of_timesteps": 4096798, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 19671, "number_of_timesteps": 4101798, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 19681, "number_of_timesteps": 4106798, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 19691, "number_of_timesteps": 4111798, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 19701, "number_of_timesteps": 4116798, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 19711, "number_of_timesteps": 4121798, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 19721, "number_of_timesteps": 4126798, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 19731, "number_of_timesteps": 4131798, "per_episode_reward": 22.55, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19741, "number_of_timesteps": 4136646, "per_episode_reward": 22.65, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19751, "number_of_timesteps": 4141646, "per_episode_reward": 22.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19761, "number_of_timesteps": 4146646, "per_episode_reward": 22.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19771, "number_of_timesteps": 4151646, "per_episode_reward": 22.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19781, "number_of_timesteps": 4156646, "per_episode_reward": 22.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 19791, "number_of_timesteps": 4161646, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19801, "number_of_timesteps": 4166646, "per_episode_reward": 22.9, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19811, "number_of_timesteps": 4171646, "per_episode_reward": 22.9, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19821, "number_of_timesteps": 4176646, "per_episode_reward": 22.95, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19831, "number_of_timesteps": 4181646, "per_episode_reward": 23.05, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19841, "number_of_timesteps": 4186646, "per_episode_reward": 23.1, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19851, "number_of_timesteps": 4191646, "per_episode_reward": 23.1, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19861, "number_of_timesteps": 4196646, "per_episode_reward": 23.1, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19871, "number_of_timesteps": 4201646, "per_episode_reward": 23.15, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19881, "number_of_timesteps": 4206646, "per_episode_reward": 23.2, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19891, "number_of_timesteps": 4211646, "per_episode_reward": 23.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19901, "number_of_timesteps": 4216646, "per_episode_reward": 23.3, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19911, "number_of_timesteps": 4221646, "per_episode_reward": 23.3, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19921, "number_of_timesteps": 4226646, "per_episode_reward": 23.3, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19931, "number_of_timesteps": 4231646, "per_episode_reward": 23.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19941, "number_of_timesteps": 4236646, "per_episode_reward": 23.35, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19951, "number_of_timesteps": 4241646, "per_episode_reward": 23.45, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19961, "number_of_timesteps": 4246646, "per_episode_reward": 23.55, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19971, "number_of_timesteps": 4251646, "per_episode_reward": 23.6, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19981, "number_of_timesteps": 4256646, "per_episode_reward": 23.6, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 19991, "number_of_timesteps": 4261646, "per_episode_reward": 23.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20001, "number_of_timesteps": 4266646, "per_episode_reward": 23.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20011, "number_of_timesteps": 4271646, "per_episode_reward": 23.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20021, "number_of_timesteps": 4276646, "per_episode_reward": 23.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20031, "number_of_timesteps": 4281646, "per_episode_reward": 23.75, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.14999999999999858},

{"total_number_of_episodes": 20041, "number_of_timesteps": 4286646, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20051, "number_of_timesteps": 4291646, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20061, "number_of_timesteps": 4296646, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20071, "number_of_timesteps": 4301646, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20081, "number_of_timesteps": 4306646, "per_episode_reward": 23.9, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20091, "number_of_timesteps": 4311646, "per_episode_reward": 24.0, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20101, "number_of_timesteps": 4316646, "per_episode_reward": 24.0, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20111, "number_of_timesteps": 4321646, "per_episode_reward": 24.1, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20121, "number_of_timesteps": 4326646, "per_episode_reward": 24.2, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20131, "number_of_timesteps": 4331646, "per_episode_reward": 24.25, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20141, "number_of_timesteps": 4336646, "per_episode_reward": 24.35, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20151, "number_of_timesteps": 4341646, "per_episode_reward": 24.4, "episode_reward_trend_value": 0.006666666666666643, "biggest_recent_change": 0.10000000000000142},

{"total_number_of_episodes": 20161, "number_of_timesteps": 4346646, "per_episode_reward": 24.45, "episode_reward_trend_value": 0.007222222222222206, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20171, "number_of_timesteps": 4351646, "per_episode_reward": 24.55, "episode_reward_trend_value": 0.007222222222222246, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20181, "number_of_timesteps": 4356646, "per_episode_reward": 24.6, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20191, "number_of_timesteps": 4361646, "per_episode_reward": 24.6, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20201, "number_of_timesteps": 4366646, "per_episode_reward": 24.65, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.10000000000000142},

{"total_number_of_episodes": 20211, "number_of_timesteps": 4371646, "per_episode_reward": 24.7, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20221, "number_of_timesteps": 4376646, "per_episode_reward": 24.7, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20231, "number_of_timesteps": 4381646, "per_episode_reward": 24.7, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20241, "number_of_timesteps": 4386646, "per_episode_reward": 24.7, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20251, "number_of_timesteps": 4391646, "per_episode_reward": 24.75, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20261, "number_of_timesteps": 4396646, "per_episode_reward": 24.85, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20271, "number_of_timesteps": 4401646, "per_episode_reward": 24.9, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20281, "number_of_timesteps": 4406646, "per_episode_reward": 24.95, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20291, "number_of_timesteps": 4411646, "per_episode_reward": 25.0, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20301, "number_of_timesteps": 4416646, "per_episode_reward": 25.05, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20311, "number_of_timesteps": 4421646, "per_episode_reward": 25.15, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20321, "number_of_timesteps": 4426646, "per_episode_reward": 25.25, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20331, "number_of_timesteps": 4431646, "per_episode_reward": 25.35, "episode_reward_trend_value": 0.007222222222222246, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20341, "number_of_timesteps": 4436646, "per_episode_reward": 25.4, "episode_reward_trend_value": 0.007222222222222206, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20351, "number_of_timesteps": 4441646, "per_episode_reward": 25.4, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20361, "number_of_timesteps": 4446646, "per_episode_reward": 25.4, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20371, "number_of_timesteps": 4451646, "per_episode_reward": 25.4, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20381, "number_of_timesteps": 4456646, "per_episode_reward": 25.4, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20391, "number_of_timesteps": 4461646, "per_episode_reward": 25.5, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20401, "number_of_timesteps": 4466646, "per_episode_reward": 25.6, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20411, "number_of_timesteps": 4471646, "per_episode_reward": 25.6, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20421, "number_of_timesteps": 4476646, "per_episode_reward": 25.75, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20431, "number_of_timesteps": 4481646, "per_episode_reward": 25.85, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20441, "number_of_timesteps": 4486646, "per_episode_reward": 25.9, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20451, "number_of_timesteps": 4491646, "per_episode_reward": 25.9, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20461, "number_of_timesteps": 4496646, "per_episode_reward": 25.9, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20471, "number_of_timesteps": 4501646, "per_episode_reward": 25.9, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20481, "number_of_timesteps": 4506646, "per_episode_reward": 25.9, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20491, "number_of_timesteps": 4511646, "per_episode_reward": 25.9, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20501, "number_of_timesteps": 4516646, "per_episode_reward": 25.9, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20511, "number_of_timesteps": 4521646, "per_episode_reward": 25.9, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20521, "number_of_timesteps": 4526646, "per_episode_reward": 26.0, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20531, "number_of_timesteps": 4531646, "per_episode_reward": 26.15, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20541, "number_of_timesteps": 4536646, "per_episode_reward": 26.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20551, "number_of_timesteps": 4541646, "per_episode_reward": 26.4, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1999999999999993},

{"total_number_of_episodes": 20561, "number_of_timesteps": 4546646, "per_episode_reward": 26.4, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 20571, "number_of_timesteps": 4551646, "per_episode_reward": 26.45, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 20581, "number_of_timesteps": 4556646, "per_episode_reward": 26.5, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 20591, "number_of_timesteps": 4561646, "per_episode_reward": 26.5, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 20601, "number_of_timesteps": 4566646, "per_episode_reward": 26.5, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 20611, "number_of_timesteps": 4571646, "per_episode_reward": 26.6, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 20621, "number_of_timesteps": 4576646, "per_episode_reward": 26.75, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 20631, "number_of_timesteps": 4581646, "per_episode_reward": 26.8, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 20641, "number_of_timesteps": 4586646, "per_episode_reward": 26.85, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20651, "number_of_timesteps": 4591646, "per_episode_reward": 26.9, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},

{"total_number_of_episodes": 20661, "number_of_timesteps": 4596646, "per_episode_reward": 26.9, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20671, "number_of_timesteps": 4601646, "per_episode_reward": 26.9, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20681, "number_of_timesteps": 4606646, "per_episode_reward": 27.0, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20691, "number_of_timesteps": 4611646, "per_episode_reward": 27.05, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20701, "number_of_timesteps": 4616646, "per_episode_reward": 27.1, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20711, "number_of_timesteps": 4621646, "per_episode_reward": 27.1, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20721, "number_of_timesteps": 4626646, "per_episode_reward": 27.15, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20731, "number_of_timesteps": 4631646, "per_episode_reward": 27.25, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20741, "number_of_timesteps": 4636646, "per_episode_reward": 27.3, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20751, "number_of_timesteps": 4641646, "per_episode_reward": 27.35, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20761, "number_of_timesteps": 4646646, "per_episode_reward": 27.4, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20771, "number_of_timesteps": 4651646, "per_episode_reward": 27.4, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20781, "number_of_timesteps": 4656646, "per_episode_reward": 27.45, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20791, "number_of_timesteps": 4661646, "per_episode_reward": 27.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20801, "number_of_timesteps": 4666646, "per_episode_reward": 27.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20811, "number_of_timesteps": 4671646, "per_episode_reward": 27.6, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20821, "number_of_timesteps": 4676646, "per_episode_reward": 27.65, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20831, "number_of_timesteps": 4681646, "per_episode_reward": 27.75, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 20841, "number_of_timesteps": 4686646, "per_episode_reward": 27.9, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 20851, "number_of_timesteps": 4691646, "per_episode_reward": 28.05, "episode_reward_trend_value": 0.007222222222222246, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 20861, "number_of_timesteps": 4696160, "per_episode_reward": 28.1, "episode_reward_trend_value": 0.00777777777777781, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 20871, "number_of_timesteps": 4701160, "per_episode_reward": 28.1, "episode_reward_trend_value": 0.007222222222222246, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 20881, "number_of_timesteps": 4706160, "per_episode_reward": 28.1, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 20891, "number_of_timesteps": 4711160, "per_episode_reward": 28.1, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 20901, "number_of_timesteps": 4716160, "per_episode_reward": 28.1, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 20911, "number_of_timesteps": 4721160, "per_episode_reward": 28.1, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 20921, "number_of_timesteps": 4726160, "per_episode_reward": 28.15, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 20931, "number_of_timesteps": 4731160, "per_episode_reward": 28.3, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 20941, "number_of_timesteps": 4736160, "per_episode_reward": 28.5, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.1999999999999993},

{"total_number_of_episodes": 20951, "number_of_timesteps": 4741160, "per_episode_reward": 28.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.1999999999999993},

{"total_number_of_episodes": 20961, "number_of_timesteps": 4746160, "per_episode_reward": 28.6, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 20971, "number_of_timesteps": 4751160, "per_episode_reward": 28.7, "episode_reward_trend_value": 0.006666666666666643, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 20981, "number_of_timesteps": 4756160, "per_episode_reward": 28.75, "episode_reward_trend_value": 0.007222222222222206, "biggest_recent_change": 0.1999999999999993},
exited at update_barrier.wait(): 8, error = 
None
exited at update_barrier.wait(): 5, error = 
None
exited at update_barrier.wait(): 7, error = 
None
{"total_number_of_episodes": 20991, "number_of_timesteps": 4761160, "per_episode_reward": 28.8, "episode_reward_trend_value": 0.00777777777777777, "biggest_recent_change": 0.1999999999999993},
exited at update_barrier.wait(): 2, error = 
None
exited at update_barrier.wait(): 6, error = 
None
exited at all_updated_barrier.wait(): 1, error = 
None
exited at all_updated_barrier.wait(): 3, error = 
None
exited at all_updated_barrier.wait(): 9, error = 
None
exited at update_barrier.wait(): 0, error = 
None
[done calling async_.run_async()]
final_eval: {'number_of_steps': 125000, 'number_of_episodes': None, 'mean': 498.12, 'median': 500.0, 'stdev': 29.725410005582763}
logs/comparisons/cartpole__atk=sign__def=ucb.log fitness_value = 24.200000000000003
