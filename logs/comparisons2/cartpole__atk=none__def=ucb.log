config = {
    "evaluation": {
        "enabled": True, 
        "number_of_episodes_before_eval": 130, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": 125000, 
            "number_of_episodes": None, 
        }, 
    }, 
    "verbose": True, 
    "number_of_processes": 7, 
    "number_of_malicious_processes": 0, 
    "expected_number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": {
        0: 0.1, 
        1: 0.08, 
        2: 0.063, 
        3: 0.05, 
        4: 0.04, 
        5: 0.032, 
        6: 0.025, 
        7: 0.02, 
        8: 0.016, 
        9: 0.012, 
        10: 0.01, 
        11: 0.008, 
        12: 0.0063, 
        13: 0.005, 
        14: 0.004, 
        15: 0.0032, 
        16: 0.0025, 
        17: 0.002, 
        18: 0.0016, 
        19: 0.0012, 
        20: 0.001, 
        21: 0.0008, 
        22: 0.00063, 
        23: 0.0005, 
        24: 0.0004, 
        25: 0.00032, 
        26: 0.00025, 
        27: 0.0002, 
        28: 0.00016, 
        29: 0.00012, 
        30: 1e-05, 
        31: 8e-06, 
        32: 6.3e-06, 
        33: 5e-06, 
        34: 4e-06, 
        35: 3.2e-06, 
        36: 2.5e-06, 
        37: 2e-06, 
        38: 1.6e-06, 
        39: 1.2e-06, 
    }, 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": {0: 0, }, 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0, 
        "min_number_of_episodes": 30, 
        "thresholds": {}, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": {0: 0, 1: 1, 2: 2, }, }, 
            "sequential_options": {
                "t_max": {0: 3, 1: 5, 2: 10, 3: 20, 4: 30, 5: 50, }, 
                "hidden_size": {0: 16, 1: 32, 2: 64, 3: 128, }, 
                "learning_rate": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
                "beta": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
                "beta": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 21000, }, 
    "env_config": {
        "env_name": "CartPole-v1", 
        "learning_rate": 0.001, 
        "beta": 2e-05, 
        "t_max": 5, 
        "activation": 1, 
        "hidden_size": 64, 
        "permaban_threshold": 1000, 
        "variance_scaling_factor": 1, 
    }, 
}
args = {
    "processes": 7, 
    "env": "CartPole-v1", 
    "seed": 721986755, 
    "outdir": "results", 
    "t_max": 5, 
    "beta": 2e-05, 
    "profile": False, 
    "steps": 21000, 
    "max_frames": (108000, ), 
    "lr": 0.001, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 1000, 
    "malicious": 0, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 64, 
    "activation": 1, 
}
[starting train_a3c()]
[starting train_agent_async()]
[about to call async_.run_async()]
[starting run_func()]
[starting train_loop()]
Step 0 0 visits [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1 0 visits [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2 1 visits [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 3 2 visits [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 1 q_vals: [0.0, 0.0, -6.04, 0.0, 0.0, 0.0, 0.0]
Step 4 3 visits [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 4 q_vals: [0.0, 0.0, -6.04, -4.102, 0.0, 0.0, 0.0]
Step 5 4 visits [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 6 q_vals: [0.0, 0.0, -6.04, -4.102, -4.612, 0.0, 0.0]
Step 6 5 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 8 q_vals: [0.0, 0.0, -6.04, -4.102, -4.612, -4.523, 0.0]
Step 7 6 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 8 q_vals: [0.0, 0.0, -6.04, -4.102, -4.612, -4.523, -4.919]
Step 8 0 visits [2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 8 q_vals: [-3.426, 0.0, -6.04, -4.102, -4.612, -4.523, -4.919]
Step 9 1 visits [2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 11 q_vals: [-3.426, -2.236, -6.04, -4.102, -4.612, -4.523, -4.919]
Step 10 1 visits [2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 12 q_vals: [-3.426, -2.821, -6.04, -4.102, -4.612, -4.523, -4.919]
Step 11 1 visits [2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 13 q_vals: [-3.426, -3.335, -6.04, -4.102, -4.612, -4.523, -4.919]
Step 12 0 visits [3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 13 q_vals: [-3.694, -3.335, -6.04, -4.102, -4.612, -4.523, -4.919]
Step 13 3 visits [3.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 15 q_vals: [-3.694, -3.335, -6.04, -4.103, -4.612, -4.523, -4.919]
Step 14 1 visits [3.0, 5.0, 1.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 17 q_vals: [-3.694, -3.52, -6.04, -4.103, -4.612, -4.523, -4.919]
Step 15 0 visits [4.0, 5.0, 1.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 19 q_vals: [-4.157, -3.52, -6.04, -4.103, -4.612, -4.523, -4.919]
Step 16 1 visits [4.0, 6.0, 1.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 20 q_vals: [-4.157, -3.845, -6.04, -4.103, -4.612, -4.523, -4.919]
Step 17 5 visits [4.0, 6.0, 1.0, 2.0, 1.0, 2.0, 1.0]  episode_count: 22 q_vals: [-4.157, -3.845, -6.04, -4.103, -4.612, -5.38, -4.919]
Step 18 3 visits [4.0, 6.0, 1.0, 3.0, 1.0, 2.0, 1.0]  episode_count: 23 q_vals: [-4.157, -3.845, -6.04, -4.525, -4.612, -5.38, -4.919]
Step 19 4 visits [4.0, 6.0, 1.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 24 q_vals: [-4.157, -3.845, -6.04, -4.525, -5.283, -5.38, -4.919]
Step 20 1 visits [4.0, 7.0, 1.0, 3.0, 2.0, 2.0, 1.0]  episode_count: 26 q_vals: [-4.157, -4.38, -6.04, -4.525, -5.283, -5.38, -4.919]
Step 21 6 visits [4.0, 7.0, 1.0, 3.0, 2.0, 2.0, 2.0]  episode_count: 27 q_vals: [-4.157, -4.38, -6.04, -4.525, -5.283, -5.38, -5.098]
Step 22 0 visits [5.0, 7.0, 1.0, 3.0, 2.0, 2.0, 2.0]  episode_count: 30 q_vals: [-4.49, -4.38, -6.04, -4.525, -5.283, -5.38, -5.098]
{"total_number_of_episodes": 31, "number_of_timesteps": 675, "per_episode_reward": 21.93, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Step 23 3 visits [5.0, 7.0, 1.0, 4.0, 2.0, 2.0, 2.0]  episode_count: 31 q_vals: [-4.49, -4.38, -6.04, -4.828, -5.283, -5.38, -5.098]
Step 24 0 visits [6.0, 7.0, 1.0, 4.0, 2.0, 2.0, 2.0]  episode_count: 33 q_vals: [-4.738, -4.38, -6.04, -4.828, -5.283, -5.38, -5.098]
Step 25 1 visits [6.0, 8.0, 1.0, 4.0, 2.0, 2.0, 2.0]  episode_count: 33 q_vals: [-4.738, -3.833, -6.04, -4.828, -5.283, -5.38, -5.098]
Step 26 1 visits [6.0, 9.0, 1.0, 4.0, 2.0, 2.0, 2.0]  episode_count: 34 q_vals: [-4.738, -4.463, -6.04, -4.828, -5.283, -5.38, -5.098]
Step 27 6 visits [6.0, 9.0, 1.0, 4.0, 2.0, 2.0, 3.0]  episode_count: 35 q_vals: [-4.738, -4.463, -6.04, -4.828, -5.283, -5.38, -5.556]
Step 28 1 visits [6.0, 10.0, 1.0, 4.0, 2.0, 2.0, 3.0]  episode_count: 37 q_vals: [-4.738, -4.65, -6.04, -4.828, -5.283, -5.38, -5.556]
Step 29 3 visits [6.0, 10.0, 1.0, 5.0, 2.0, 2.0, 3.0]  episode_count: 39 q_vals: [-4.738, -4.65, -6.04, -5.274, -5.283, -5.38, -5.556]
Step 30 4 visits [6.0, 10.0, 1.0, 5.0, 3.0, 2.0, 3.0]  episode_count: 40 q_vals: [-4.738, -4.65, -6.04, -5.274, -3.522, -5.38, -5.556]
Step 31 4 visits [6.0, 10.0, 1.0, 5.0, 4.0, 2.0, 3.0]  episode_count: 40 q_vals: [-4.738, -4.65, -6.04, -5.274, -4.686, -5.38, -5.556]
{"total_number_of_episodes": 41, "number_of_timesteps": 898, "per_episode_reward": 22.93, "episode_reward_trend_value": 0.1, "biggest_recent_change": NaN},
Step 32 4 visits [6.0, 10.0, 1.0, 5.0, 5.0, 2.0, 3.0]  episode_count: 41 q_vals: [-4.738, -4.65, -6.04, -5.274, -5.147, -5.38, -5.556]
Step 33 0 visits [7.0, 10.0, 1.0, 5.0, 5.0, 2.0, 3.0]  episode_count: 42 q_vals: [-5.319, -4.65, -6.04, -5.274, -5.147, -5.38, -5.556]
Step 34 5 visits [7.0, 10.0, 1.0, 5.0, 5.0, 3.0, 3.0]  episode_count: 45 q_vals: [-5.319, -4.65, -6.04, -5.274, -5.147, -6.515, -5.556]
Step 35 1 visits [7.0, 11.0, 1.0, 5.0, 5.0, 3.0, 3.0]  episode_count: 46 q_vals: [-5.319, -5.158, -6.04, -5.274, -5.147, -6.515, -5.556]
Step 36 2 visits [7.0, 11.0, 2.0, 5.0, 5.0, 3.0, 3.0]  episode_count: 47 q_vals: [-5.319, -5.158, -6.554, -5.274, -5.147, -6.515, -5.556]
Step 37 4 visits [7.0, 11.0, 2.0, 5.0, 6.0, 3.0, 3.0]  episode_count: 48 q_vals: [-5.319, -5.158, -6.554, -5.274, -5.596, -6.515, -5.556]
Step 38 3 visits [7.0, 11.0, 2.0, 6.0, 6.0, 3.0, 3.0]  episode_count: 50 q_vals: [-5.319, -5.158, -6.554, -4.395, -5.596, -6.515, -5.556]
{"total_number_of_episodes": 51, "number_of_timesteps": 1108, "per_episode_reward": 22.79, "episode_reward_trend_value": 0.042857142857142885, "biggest_recent_change": NaN},
Step 39 3 visits [7.0, 11.0, 2.0, 7.0, 6.0, 3.0, 3.0]  episode_count: 51 q_vals: [-5.319, -5.158, -6.554, -5.103, -5.596, -6.515, -5.556]
Step 40 3 visits [7.0, 11.0, 2.0, 8.0, 6.0, 3.0, 3.0]  episode_count: 51 q_vals: [-5.319, -5.158, -6.554, -5.586, -5.596, -6.515, -5.556]
Step 41 6 visits [7.0, 11.0, 2.0, 8.0, 6.0, 3.0, 4.0]  episode_count: 53 q_vals: [-5.319, -5.158, -6.554, -5.586, -5.596, -6.515, -6.575]
Step 42 1 visits [7.0, 12.0, 2.0, 8.0, 6.0, 3.0, 4.0]  episode_count: 54 q_vals: [-5.319, -5.463, -6.554, -5.586, -5.596, -6.515, -6.575]
Step 43 0 visits [8.0, 12.0, 2.0, 8.0, 6.0, 3.0, 4.0]  episode_count: 57 q_vals: [-4.654, -5.463, -6.554, -5.586, -5.596, -6.515, -6.575]
Step 44 0 visits [9.0, 12.0, 2.0, 8.0, 6.0, 3.0, 4.0]  episode_count: 57 q_vals: [-5.168, -5.463, -6.554, -5.586, -5.596, -6.515, -6.575]
Step 45 0 visits [10.0, 12.0, 2.0, 8.0, 6.0, 3.0, 4.0]  episode_count: 59 q_vals: [-5.604, -5.463, -6.554, -5.586, -5.596, -6.515, -6.575]
{"total_number_of_episodes": 61, "number_of_timesteps": 1395, "per_episode_reward": 23.57, "episode_reward_trend_value": 0.054761904761904866, "biggest_recent_change": NaN},
Step 46 4 visits [10.0, 12.0, 2.0, 8.0, 7.0, 3.0, 4.0]  episode_count: 61 q_vals: [-5.604, -5.463, -6.554, -5.586, -6.351, -6.515, -6.575]
Step 47 3 visits [10.0, 12.0, 2.0, 9.0, 7.0, 3.0, 4.0]  episode_count: 62 q_vals: [-5.604, -5.463, -6.554, -6.2, -6.351, -6.515, -6.575]
Step 48 1 visits [10.0, 13.0, 2.0, 9.0, 7.0, 3.0, 4.0]  episode_count: 62 q_vals: [-5.604, -5.897, -6.554, -6.2, -6.351, -6.515, -6.575]
Step 49 0 visits [11.0, 13.0, 2.0, 9.0, 7.0, 3.0, 4.0]  episode_count: 65 q_vals: [-6.104, -5.897, -6.554, -6.2, -6.351, -6.515, -6.575]
Step 50 2 visits [11.0, 13.0, 3.0, 9.0, 7.0, 3.0, 4.0]  episode_count: 65 q_vals: [-6.104, -5.897, -4.369, -6.2, -6.351, -6.515, -6.575]
Step 51 2 visits [11.0, 13.0, 4.0, 9.0, 7.0, 3.0, 4.0]  episode_count: 68 q_vals: [-6.104, -5.897, -5.859, -6.2, -6.351, -6.515, -6.575]
Step 52 2 visits [11.0, 13.0, 5.0, 9.0, 7.0, 3.0, 4.0]  episode_count: 69 q_vals: [-6.104, -5.897, -6.91, -6.2, -6.351, -6.515, -6.575]
Step 53 1 visits [11.0, 14.0, 5.0, 9.0, 7.0, 3.0, 4.0]  episode_count: 70 q_vals: [-6.104, -6.27, -6.91, -6.2, -6.351, -6.515, -6.575]
{"total_number_of_episodes": 71, "number_of_timesteps": 1651, "per_episode_reward": 23.86, "episode_reward_trend_value": 0.048214285714285765, "biggest_recent_change": NaN},
Step 54 5 visits [11.0, 14.0, 5.0, 9.0, 7.0, 4.0, 4.0]  episode_count: 71 q_vals: [-6.104, -6.27, -6.91, -6.2, -6.351, -7.664, -6.575]
Step 55 0 visits [12.0, 14.0, 5.0, 9.0, 7.0, 4.0, 4.0]  episode_count: 73 q_vals: [-6.522, -6.27, -6.91, -6.2, -6.351, -7.664, -6.575]
Step 56 3 visits [12.0, 14.0, 5.0, 10.0, 7.0, 4.0, 4.0]  episode_count: 74 q_vals: [-6.522, -6.27, -6.91, -6.691, -6.351, -7.664, -6.575]
Step 57 6 visits [12.0, 14.0, 5.0, 10.0, 7.0, 4.0, 5.0]  episode_count: 77 q_vals: [-6.522, -6.27, -6.91, -6.691, -6.351, -7.664, -7.482]
Step 58 4 visits [12.0, 14.0, 5.0, 10.0, 8.0, 4.0, 5.0]  episode_count: 79 q_vals: [-6.522, -6.27, -6.91, -6.691, -5.557, -7.664, -7.482]
Step 59 4 visits [12.0, 14.0, 5.0, 10.0, 9.0, 4.0, 5.0]  episode_count: 80 q_vals: [-6.522, -6.27, -6.91, -6.691, -6.174, -7.664, -7.482]
{"total_number_of_episodes": 81, "number_of_timesteps": 1846, "per_episode_reward": 22.71, "episode_reward_trend_value": 0.015714285714285764, "biggest_recent_change": NaN},
Step 60 4 visits [12.0, 14.0, 5.0, 10.0, 10.0, 4.0, 5.0]  episode_count: 81 q_vals: [-6.522, -6.27, -6.91, -6.691, -6.668, -7.664, -7.482]
Step 61 1 visits [12.0, 15.0, 5.0, 10.0, 10.0, 4.0, 5.0]  episode_count: 84 q_vals: [-6.522, -6.592, -6.91, -6.691, -6.668, -7.664, -7.482]
Step 62 0 visits [13.0, 15.0, 5.0, 10.0, 10.0, 4.0, 5.0]  episode_count: 85 q_vals: [-6.494, -6.592, -6.91, -6.691, -6.668, -7.664, -7.482]
Step 63 0 visits [14.0, 15.0, 5.0, 10.0, 10.0, 4.0, 5.0]  episode_count: 87 q_vals: [-6.823, -6.592, -6.91, -6.691, -6.668, -7.664, -7.482]
Step 64 2 visits [14.0, 15.0, 6.0, 10.0, 10.0, 4.0, 5.0]  episode_count: 87 q_vals: [-6.823, -6.592, -7.61, -6.691, -6.668, -7.664, -7.482]
Step 65 4 visits [14.0, 15.0, 6.0, 10.0, 11.0, 4.0, 5.0]  episode_count: 90 q_vals: [-6.823, -6.592, -7.61, -6.691, -7.072, -7.664, -7.482]
{"total_number_of_episodes": 92, "number_of_timesteps": 2043, "per_episode_reward": 20.79, "episode_reward_trend_value": -0.01904761904761904, "biggest_recent_change": NaN},
Step 66 3 visits [14.0, 15.0, 6.0, 11.0, 11.0, 4.0, 5.0]  episode_count: 92 q_vals: [-6.823, -6.592, -7.61, -7.093, -7.072, -7.664, -7.482]
Step 67 1 visits [14.0, 16.0, 6.0, 11.0, 11.0, 4.0, 5.0]  episode_count: 95 q_vals: [-6.823, -6.18, -7.61, -7.093, -7.072, -7.664, -7.482]
Step 68 1 visits [14.0, 17.0, 6.0, 11.0, 11.0, 4.0, 5.0]  episode_count: 97 q_vals: [-6.823, -6.47, -7.61, -7.093, -7.072, -7.664, -7.482]
Step 69 1 visits [14.0, 18.0, 6.0, 11.0, 11.0, 4.0, 5.0]  episode_count: 97 q_vals: [-6.823, -6.728, -7.61, -7.093, -7.072, -7.664, -7.482]
Step 70 1 visits [14.0, 19.0, 6.0, 11.0, 11.0, 4.0, 5.0]  episode_count: 99 q_vals: [-6.823, -6.959, -7.61, -7.093, -7.072, -7.664, -7.482]
Step 71 0 visits [15.0, 19.0, 6.0, 11.0, 11.0, 4.0, 5.0]  episode_count: 100 q_vals: [-7.109, -6.959, -7.61, -7.093, -7.072, -7.664, -7.482]
Step 72 4 visits [15.0, 19.0, 6.0, 11.0, 12.0, 4.0, 5.0]  episode_count: 100 q_vals: [-7.109, -6.959, -7.61, -7.093, -7.409, -7.664, -7.482]
{"total_number_of_episodes": 102, "number_of_timesteps": 2236, "per_episode_reward": 20.0, "episode_reward_trend_value": -0.027551020408163245, "biggest_recent_change": NaN},
Step 73 3 visits [15.0, 19.0, 6.0, 12.0, 12.0, 4.0, 5.0]  episode_count: 102 q_vals: [-7.109, -6.959, -7.61, -7.428, -7.409, -7.664, -7.482]
Step 74 1 visits [15.0, 20.0, 6.0, 12.0, 12.0, 4.0, 5.0]  episode_count: 102 q_vals: [-7.109, -7.166, -7.61, -7.428, -7.409, -7.664, -7.482]
Step 75 6 visits [15.0, 20.0, 6.0, 12.0, 12.0, 4.0, 6.0]  episode_count: 103 q_vals: [-7.109, -7.166, -7.61, -7.428, -7.409, -7.664, -8.087]
Step 76 0 visits [16.0, 20.0, 6.0, 12.0, 12.0, 4.0, 6.0]  episode_count: 106 q_vals: [-7.359, -7.166, -7.61, -7.428, -7.409, -7.664, -8.087]
Step 77 5 visits [16.0, 20.0, 6.0, 12.0, 12.0, 5.0, 6.0]  episode_count: 107 q_vals: [-7.359, -7.166, -7.61, -7.428, -7.409, -8.353, -8.087]
Step 78 1 visits [16.0, 21.0, 6.0, 12.0, 12.0, 5.0, 6.0]  episode_count: 109 q_vals: [-7.359, -6.825, -7.61, -7.428, -7.409, -8.353, -8.087]
Step 79 1 visits [16.0, 22.0, 6.0, 12.0, 12.0, 5.0, 6.0]  episode_count: 109 q_vals: [-7.359, -7.02, -7.61, -7.428, -7.409, -8.353, -8.087]
Step 80 1 visits [16.0, 23.0, 6.0, 12.0, 12.0, 5.0, 6.0]  episode_count: 110 q_vals: [-7.359, -7.198, -7.61, -7.428, -7.409, -8.353, -8.087]
{"total_number_of_episodes": 112, "number_of_timesteps": 2510, "per_episode_reward": 21.14, "episode_reward_trend_value": -0.009821428571428559, "biggest_recent_change": NaN},
Step 81 2 visits [16.0, 23.0, 7.0, 12.0, 12.0, 5.0, 6.0]  episode_count: 112 q_vals: [-7.359, -7.198, -8.11, -7.428, -7.409, -8.353, -8.087]
Step 82 1 visits [16.0, 24.0, 7.0, 12.0, 12.0, 5.0, 6.0]  episode_count: 115 q_vals: [-7.359, -7.361, -8.11, -7.428, -7.409, -8.353, -8.087]
Step 83 4 visits [16.0, 24.0, 7.0, 12.0, 13.0, 5.0, 6.0]  episode_count: 117 q_vals: [-7.359, -7.361, -8.11, -7.428, -7.693, -8.353, -8.087]
Step 84 3 visits [16.0, 24.0, 7.0, 13.0, 13.0, 5.0, 6.0]  episode_count: 117 q_vals: [-7.359, -7.361, -8.11, -7.711, -7.693, -8.353, -8.087]
Step 85 0 visits [17.0, 24.0, 7.0, 13.0, 13.0, 5.0, 6.0]  episode_count: 118 q_vals: [-7.58, -7.361, -8.11, -7.711, -7.693, -8.353, -8.087]
Step 86 1 visits [17.0, 25.0, 7.0, 13.0, 13.0, 5.0, 6.0]  episode_count: 121 q_vals: [-7.58, -7.511, -8.11, -7.711, -7.693, -8.353, -8.087]
{"total_number_of_episodes": 122, "number_of_timesteps": 2719, "per_episode_reward": 21.07, "episode_reward_trend_value": -0.00952380952380949, "biggest_recent_change": 1.9285714285714306},
Step 87 0 visits [18.0, 25.0, 7.0, 13.0, 13.0, 5.0, 6.0]  episode_count: 122 q_vals: [-7.776, -7.511, -8.11, -7.711, -7.693, -8.353, -8.087]
Step 88 1 visits [18.0, 26.0, 7.0, 13.0, 13.0, 5.0, 6.0]  episode_count: 123 q_vals: [-7.776, -7.649, -8.11, -7.711, -7.693, -8.353, -8.087]
Step 89 4 visits [18.0, 26.0, 7.0, 13.0, 14.0, 5.0, 6.0]  episode_count: 125 q_vals: [-7.776, -7.649, -8.11, -7.711, -7.938, -8.353, -8.087]
Step 90 3 visits [18.0, 26.0, 7.0, 14.0, 14.0, 5.0, 6.0]  episode_count: 125 q_vals: [-7.776, -7.649, -8.11, -7.954, -7.938, -8.353, -8.087]
Step 91 6 visits [18.0, 26.0, 7.0, 14.0, 14.0, 5.0, 7.0]  episode_count: 125 q_vals: [-7.776, -7.649, -8.11, -7.954, -7.938, -8.353, -6.932]
Step 92 6 visits [18.0, 26.0, 7.0, 14.0, 14.0, 5.0, 8.0]  episode_count: 128 q_vals: [-7.776, -7.649, -8.11, -7.954, -7.938, -8.353, -7.454]
Step 93 6 visits [18.0, 26.0, 7.0, 14.0, 14.0, 5.0, 9.0]  episode_count: 130 q_vals: [-7.776, -7.649, -8.11, -7.954, -7.938, -8.353, -7.86]
Step 94 6 visits [18.0, 26.0, 7.0, 14.0, 14.0, 5.0, 10.0]  episode_count: 130 q_vals: [-7.776, -7.649, -8.11, -7.954, -7.938, -8.353, -7.074]
Step 95 6 visits [18.0, 26.0, 7.0, 14.0, 14.0, 5.0, 11.0]  episode_count: 131 q_vals: [-7.776, -7.649, -8.11, -7.954, -7.938, -8.353, -7.441]
{"total_number_of_episodes": 132, "number_of_timesteps": 2933, "per_episode_reward": 20.86, "episode_reward_trend_value": -0.023015873015872993, "biggest_recent_change": 1.9285714285714306},
Step 96 6 visits [18.0, 26.0, 7.0, 14.0, 14.0, 5.0, 12.0]  episode_count: 132 q_vals: [-7.776, -7.649, -8.11, -7.954, -7.938, -8.353, -7.747]
Step 97 6 visits [18.0, 26.0, 7.0, 14.0, 14.0, 5.0, 13.0]  episode_count: 133 q_vals: [-7.776, -7.649, -8.11, -7.954, -7.938, -8.353, -8.006]
Step 98 1 visits [18.0, 27.0, 7.0, 14.0, 14.0, 5.0, 13.0]  episode_count: 134 q_vals: [-7.776, -7.366, -8.11, -7.954, -7.938, -8.353, -8.006]
Step 99 1 visits [18.0, 28.0, 7.0, 14.0, 14.0, 5.0, 13.0]  episode_count: 134 q_vals: [-7.776, -7.5, -8.11, -7.954, -7.938, -8.353, -8.006]
Step 100 1 visits [18.0, 29.0, 7.0, 14.0, 14.0, 5.0, 13.0]  episode_count: 137 q_vals: [-7.776, -7.624, -8.11, -7.954, -7.938, -8.353, -8.006]
Step 101 1 visits [18.0, 30.0, 7.0, 14.0, 14.0, 5.0, 13.0]  episode_count: 138 q_vals: [-7.776, -7.741, -8.11, -7.954, -7.938, -8.353, -8.006]
Step 102 0 visits [19.0, 30.0, 7.0, 14.0, 14.0, 5.0, 13.0]  episode_count: 140 q_vals: [-7.952, -7.741, -8.11, -7.954, -7.938, -8.353, -8.006]
Step 103 2 visits [19.0, 30.0, 8.0, 14.0, 14.0, 5.0, 13.0]  episode_count: 141 q_vals: [-7.952, -7.741, -8.485, -7.954, -7.938, -8.353, -8.006]
{"total_number_of_episodes": 142, "number_of_timesteps": 3239, "per_episode_reward": 19.93, "episode_reward_trend_value": -0.03174603174603175, "biggest_recent_change": 1.9285714285714306},
Step 104 1 visits [19.0, 31.0, 8.0, 14.0, 14.0, 5.0, 13.0]  episode_count: 142 q_vals: [-7.952, -7.849, -8.485, -7.954, -7.938, -8.353, -8.006]
Step 105 4 visits [19.0, 31.0, 8.0, 14.0, 15.0, 5.0, 13.0]  episode_count: 144 q_vals: [-7.952, -7.849, -8.485, -7.954, -7.408, -8.353, -8.006]
Step 106 4 visits [19.0, 31.0, 8.0, 14.0, 16.0, 5.0, 13.0]  episode_count: 144 q_vals: [-7.952, -7.849, -8.485, -7.954, -7.64, -8.353, -8.006]
Step 107 4 visits [19.0, 31.0, 8.0, 14.0, 17.0, 5.0, 13.0]  episode_count: 146 q_vals: [-7.952, -7.849, -8.485, -7.954, -7.844, -8.353, -8.006]
Step 108 4 visits [19.0, 31.0, 8.0, 14.0, 18.0, 5.0, 13.0]  episode_count: 149 q_vals: [-7.952, -7.849, -8.485, -7.954, -8.026, -8.353, -8.006]
Step 109 3 visits [19.0, 31.0, 8.0, 15.0, 18.0, 5.0, 13.0]  episode_count: 149 q_vals: [-7.952, -7.849, -8.485, -8.164, -8.026, -8.353, -8.006]
Step 110 5 visits [19.0, 31.0, 8.0, 15.0, 18.0, 6.0, 13.0]  episode_count: 149 q_vals: [-7.952, -7.849, -8.485, -8.164, -8.026, -8.813, -8.006]
{"total_number_of_episodes": 152, "number_of_timesteps": 3444, "per_episode_reward": 19.64, "episode_reward_trend_value": -0.043650793650793676, "biggest_recent_change": 1.9285714285714306},
Step 111 6 visits [19.0, 31.0, 8.0, 15.0, 18.0, 6.0, 14.0]  episode_count: 152 q_vals: [-7.952, -7.849, -8.485, -8.164, -8.026, -8.813, -8.228]
Step 112 0 visits [20.0, 31.0, 8.0, 15.0, 18.0, 6.0, 14.0]  episode_count: 155 q_vals: [-8.11, -7.849, -8.485, -8.164, -8.026, -8.813, -8.228]
Step 113 1 visits [20.0, 32.0, 8.0, 15.0, 18.0, 6.0, 14.0]  episode_count: 155 q_vals: [-8.11, -7.951, -8.485, -8.164, -8.026, -8.813, -8.228]
Step 114 4 visits [20.0, 32.0, 8.0, 15.0, 19.0, 6.0, 14.0]  episode_count: 156 q_vals: [-8.11, -7.951, -8.485, -8.164, -8.188, -8.813, -8.228]
Step 115 1 visits [20.0, 33.0, 8.0, 15.0, 19.0, 6.0, 14.0]  episode_count: 158 q_vals: [-8.11, -8.047, -8.485, -8.164, -8.188, -8.813, -8.228]
Step 116 3 visits [20.0, 33.0, 8.0, 16.0, 19.0, 6.0, 14.0]  episode_count: 160 q_vals: [-8.11, -8.047, -8.485, -8.349, -8.188, -8.813, -8.228]
Step 117 0 visits [21.0, 33.0, 8.0, 16.0, 19.0, 6.0, 14.0]  episode_count: 160 q_vals: [-8.253, -8.047, -8.485, -8.349, -8.188, -8.813, -8.228]
{"total_number_of_episodes": 163, "number_of_timesteps": 3637, "per_episode_reward": 19.5, "episode_reward_trend_value": -0.04841269841269842, "biggest_recent_change": 1.9285714285714306},
Step 118 6 visits [21.0, 33.0, 8.0, 16.0, 19.0, 6.0, 15.0]  episode_count: 163 q_vals: [-8.253, -8.047, -8.485, -8.349, -8.188, -8.813, -8.42]
Step 119 1 visits [21.0, 34.0, 8.0, 16.0, 19.0, 6.0, 15.0]  episode_count: 164 q_vals: [-8.253, -8.137, -8.485, -8.349, -8.188, -8.813, -8.42]
Step 120 4 visits [21.0, 34.0, 8.0, 16.0, 20.0, 6.0, 15.0]  episode_count: 166 q_vals: [-8.253, -8.137, -8.485, -8.349, -8.334, -8.813, -8.42]
Step 121 2 visits [21.0, 34.0, 9.0, 16.0, 20.0, 6.0, 15.0]  episode_count: 167 q_vals: [-8.253, -8.137, -8.777, -8.349, -8.334, -8.813, -8.42]
Step 122 1 visits [21.0, 35.0, 9.0, 16.0, 20.0, 6.0, 15.0]  episode_count: 170 q_vals: [-8.253, -8.222, -8.777, -8.349, -8.334, -8.813, -8.42]
Step 123 0 visits [22.0, 35.0, 9.0, 16.0, 20.0, 6.0, 15.0]  episode_count: 170 q_vals: [-8.383, -8.222, -8.777, -8.349, -8.334, -8.813, -8.42]
Step 124 3 visits [22.0, 35.0, 9.0, 17.0, 20.0, 6.0, 15.0]  episode_count: 171 q_vals: [-8.383, -8.222, -8.777, -8.511, -8.334, -8.813, -8.42]
Step 125 4 visits [22.0, 35.0, 9.0, 17.0, 21.0, 6.0, 15.0]  episode_count: 172 q_vals: [-8.383, -8.222, -8.777, -8.511, -8.466, -8.813, -8.42]
{"total_number_of_episodes": 173, "number_of_timesteps": 3911, "per_episode_reward": 19.57, "episode_reward_trend_value": -0.034920634920634915, "biggest_recent_change": 1.9285714285714306},
Step 126 1 visits [22.0, 36.0, 9.0, 17.0, 21.0, 6.0, 15.0]  episode_count: 173 q_vals: [-8.383, -8.302, -8.777, -8.511, -8.466, -8.813, -8.42]
Step 127 6 visits [22.0, 36.0, 9.0, 17.0, 21.0, 6.0, 16.0]  episode_count: 175 q_vals: [-8.383, -8.302, -8.777, -8.511, -8.466, -8.813, -8.588]
Step 128 0 visits [23.0, 36.0, 9.0, 17.0, 21.0, 6.0, 16.0]  episode_count: 177 q_vals: [-8.501, -8.302, -8.777, -8.511, -8.466, -8.813, -8.588]
Step 129 5 visits [23.0, 36.0, 9.0, 17.0, 21.0, 7.0, 16.0]  episode_count: 177 q_vals: [-8.501, -8.302, -8.777, -8.511, -8.466, -9.141, -8.588]
Step 130 1 visits [23.0, 37.0, 9.0, 17.0, 21.0, 7.0, 16.0]  episode_count: 178 q_vals: [-8.501, -8.378, -8.777, -8.511, -8.466, -9.141, -8.588]
{"total_number_of_episodes": 183, "number_of_timesteps": 4173, "per_episode_reward": 19.93, "episode_reward_trend_value": -0.009523809523809528, "biggest_recent_change": 1.1428571428571423},
Step 131 3 visits [23.0, 37.0, 9.0, 18.0, 21.0, 7.0, 16.0]  episode_count: 183 q_vals: [-8.501, -8.378, -8.777, -8.656, -8.466, -9.141, -8.588]
Step 132 4 visits [23.0, 37.0, 9.0, 18.0, 22.0, 7.0, 16.0]  episode_count: 183 q_vals: [-8.501, -8.378, -8.777, -8.656, -8.587, -9.141, -8.588]
Step 133 1 visits [23.0, 38.0, 9.0, 18.0, 22.0, 7.0, 16.0]  episode_count: 184 q_vals: [-8.501, -8.45, -8.777, -8.656, -8.587, -9.141, -8.588]
Step 134 6 visits [23.0, 38.0, 9.0, 18.0, 22.0, 7.0, 17.0]  episode_count: 188 q_vals: [-8.501, -8.45, -8.777, -8.656, -8.587, -9.141, -8.737]
Step 135 2 visits [23.0, 38.0, 10.0, 18.0, 22.0, 7.0, 17.0]  episode_count: 189 q_vals: [-8.501, -8.45, -9.01, -8.656, -8.587, -9.141, -8.737]
Step 136 0 visits [24.0, 38.0, 10.0, 18.0, 22.0, 7.0, 17.0]  episode_count: 192 q_vals: [-8.61, -8.45, -9.01, -8.656, -8.587, -9.141, -8.737]
{"total_number_of_episodes": 194, "number_of_timesteps": 4336, "per_episode_reward": 19.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 1.1428571428571423},
Step 137 1 visits [24.0, 39.0, 10.0, 18.0, 22.0, 7.0, 17.0]  episode_count: 194 q_vals: [-8.61, -8.518, -9.01, -8.656, -8.587, -9.141, -8.737]
Step 138 4 visits [24.0, 39.0, 10.0, 18.0, 23.0, 7.0, 17.0]  episode_count: 195 q_vals: [-8.61, -8.518, -9.01, -8.656, -8.696, -9.141, -8.737]
Step 139 3 visits [24.0, 39.0, 10.0, 19.0, 23.0, 7.0, 17.0]  episode_count: 199 q_vals: [-8.61, -8.518, -9.01, -8.785, -8.696, -9.141, -8.737]
Step 140 0 visits [25.0, 39.0, 10.0, 19.0, 23.0, 7.0, 17.0]  episode_count: 200 q_vals: [-8.266, -8.518, -9.01, -8.785, -8.696, -9.141, -8.737]
Step 141 0 visits [26.0, 39.0, 10.0, 19.0, 23.0, 7.0, 17.0]  episode_count: 202 q_vals: [-8.375, -8.518, -9.01, -8.785, -8.696, -9.141, -8.737]
{"total_number_of_episodes": 204, "number_of_timesteps": 4479, "per_episode_reward": 19.0, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 0.9285714285714306},
Step 142 0 visits [27.0, 39.0, 10.0, 19.0, 23.0, 7.0, 17.0]  episode_count: 204 q_vals: [-8.476, -8.518, -9.01, -8.785, -8.696, -9.141, -8.737]
Step 143 0 visits [28.0, 39.0, 10.0, 19.0, 23.0, 7.0, 17.0]  episode_count: 207 q_vals: [-8.57, -8.518, -9.01, -8.785, -8.696, -9.141, -8.737]
Step 144 0 visits [29.0, 39.0, 10.0, 19.0, 23.0, 7.0, 17.0]  episode_count: 208 q_vals: [-8.658, -8.518, -9.01, -8.785, -8.696, -9.141, -8.737]
Step 145 1 visits [29.0, 40.0, 10.0, 19.0, 23.0, 7.0, 17.0]  episode_count: 209 q_vals: [-8.658, -8.583, -9.01, -8.785, -8.696, -9.141, -8.737]
{"total_number_of_episodes": 214, "number_of_timesteps": 4631, "per_episode_reward": 18.57, "episode_reward_trend_value": -0.02777777777777778, "biggest_recent_change": 0.9285714285714306},
Step 146 6 visits [29.0, 40.0, 10.0, 19.0, 23.0, 7.0, 18.0]  episode_count: 214 q_vals: [-8.658, -8.583, -9.01, -8.785, -8.696, -9.141, -8.251]
Step 147 6 visits [29.0, 40.0, 10.0, 19.0, 23.0, 7.0, 19.0]  episode_count: 215 q_vals: [-8.658, -8.583, -9.01, -8.785, -8.696, -9.141, -8.402]
Step 148 6 visits [29.0, 40.0, 10.0, 19.0, 23.0, 7.0, 20.0]  episode_count: 217 q_vals: [-8.658, -8.583, -9.01, -8.785, -8.696, -9.141, -8.537]
Step 149 6 visits [29.0, 40.0, 10.0, 19.0, 23.0, 7.0, 21.0]  episode_count: 222 q_vals: [-8.658, -8.583, -9.01, -8.785, -8.696, -9.141, -8.131]
Step 150 6 visits [29.0, 40.0, 10.0, 19.0, 23.0, 7.0, 22.0]  episode_count: 222 q_vals: [-8.658, -8.583, -9.01, -8.785, -8.696, -9.141, -8.266]
{"total_number_of_episodes": 225, "number_of_timesteps": 4761, "per_episode_reward": 18.29, "episode_reward_trend_value": -0.028571428571428588, "biggest_recent_change": 0.9285714285714306},
Step 151 6 visits [29.0, 40.0, 10.0, 19.0, 23.0, 7.0, 23.0]  episode_count: 225 q_vals: [-8.658, -8.583, -9.01, -8.785, -8.696, -9.141, -8.39]
Step 152 6 visits [29.0, 40.0, 10.0, 19.0, 23.0, 7.0, 24.0]  episode_count: 229 q_vals: [-8.658, -8.583, -9.01, -8.785, -8.696, -9.141, -8.503]
Step 153 6 visits [29.0, 40.0, 10.0, 19.0, 23.0, 7.0, 25.0]  episode_count: 229 q_vals: [-8.658, -8.583, -9.01, -8.785, -8.696, -9.141, -8.608]
Step 154 6 visits [29.0, 40.0, 10.0, 19.0, 23.0, 7.0, 26.0]  episode_count: 230 q_vals: [-8.658, -8.583, -9.01, -8.785, -8.696, -9.141, -8.704]
{"total_number_of_episodes": 235, "number_of_timesteps": 4898, "per_episode_reward": 17.93, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 0.5},
Step 155 4 visits [29.0, 40.0, 10.0, 19.0, 24.0, 7.0, 26.0]  episode_count: 235 q_vals: [-8.658, -8.583, -9.01, -8.785, -8.797, -9.141, -8.704]
Step 156 1 visits [29.0, 41.0, 10.0, 19.0, 24.0, 7.0, 26.0]  episode_count: 235 q_vals: [-8.658, -8.645, -9.01, -8.785, -8.797, -9.141, -8.704]
Step 157 0 visits [30.0, 41.0, 10.0, 19.0, 24.0, 7.0, 26.0]  episode_count: 236 q_vals: [-8.369, -8.645, -9.01, -8.785, -8.797, -9.141, -8.704]
Step 158 0 visits [31.0, 41.0, 10.0, 19.0, 24.0, 7.0, 26.0]  episode_count: 239 q_vals: [-8.458, -8.645, -9.01, -8.785, -8.797, -9.141, -8.704]
Step 159 0 visits [32.0, 41.0, 10.0, 19.0, 24.0, 7.0, 26.0]  episode_count: 240 q_vals: [-8.541, -8.645, -9.01, -8.785, -8.797, -9.141, -8.704]
Step 160 0 visits [33.0, 41.0, 10.0, 19.0, 24.0, 7.0, 26.0]  episode_count: 241 q_vals: [-8.619, -8.645, -9.01, -8.785, -8.797, -9.141, -8.704]
Step 161 0 visits [34.0, 41.0, 10.0, 19.0, 24.0, 7.0, 26.0]  episode_count: 244 q_vals: [-8.692, -8.645, -9.01, -8.785, -8.797, -9.141, -8.704]
{"total_number_of_episodes": 247, "number_of_timesteps": 5118, "per_episode_reward": 17.86, "episode_reward_trend_value": -0.01984126984126983, "biggest_recent_change": 0.5},
Step 162 6 visits [34.0, 41.0, 10.0, 19.0, 24.0, 7.0, 27.0]  episode_count: 247 q_vals: [-8.692, -8.645, -9.01, -8.785, -8.797, -9.141, -8.793]
Step 163 3 visits [34.0, 41.0, 10.0, 20.0, 24.0, 7.0, 27.0]  episode_count: 247 q_vals: [-8.692, -8.645, -9.01, -8.901, -8.797, -9.141, -8.793]
Step 164 5 visits [34.0, 41.0, 10.0, 20.0, 24.0, 8.0, 27.0]  episode_count: 250 q_vals: [-8.692, -8.645, -9.01, -8.901, -8.797, -9.387, -8.793]
Step 165 1 visits [34.0, 42.0, 10.0, 20.0, 24.0, 8.0, 27.0]  episode_count: 252 q_vals: [-8.692, -8.439, -9.01, -8.901, -8.797, -9.387, -8.793]
Step 166 1 visits [34.0, 43.0, 10.0, 20.0, 24.0, 8.0, 27.0]  episode_count: 253 q_vals: [-8.692, -8.501, -9.01, -8.901, -8.797, -9.387, -8.793]
Step 167 1 visits [34.0, 44.0, 10.0, 20.0, 24.0, 8.0, 27.0]  episode_count: 254 q_vals: [-8.692, -8.308, -9.01, -8.901, -8.797, -9.387, -8.793]
Step 168 1 visits [34.0, 45.0, 10.0, 20.0, 24.0, 8.0, 27.0]  episode_count: 255 q_vals: [-8.692, -8.37, -9.01, -8.901, -8.797, -9.387, -8.793]
{"total_number_of_episodes": 258, "number_of_timesteps": 5302, "per_episode_reward": 17.79, "episode_reward_trend_value": -0.019047619047619056, "biggest_recent_change": 0.5},
Step 169 1 visits [34.0, 46.0, 10.0, 20.0, 24.0, 8.0, 27.0]  episode_count: 258 q_vals: [-8.692, -8.43, -9.01, -8.901, -8.797, -9.387, -8.793]
Step 170 1 visits [34.0, 47.0, 10.0, 20.0, 24.0, 8.0, 27.0]  episode_count: 258 q_vals: [-8.692, -8.487, -9.01, -8.901, -8.797, -9.387, -8.793]
Step 171 1 visits [34.0, 48.0, 10.0, 20.0, 24.0, 8.0, 27.0]  episode_count: 260 q_vals: [-8.692, -8.542, -9.01, -8.901, -8.797, -9.387, -8.793]
Step 172 1 visits [34.0, 49.0, 10.0, 20.0, 24.0, 8.0, 27.0]  episode_count: 260 q_vals: [-8.692, -8.594, -9.01, -8.901, -8.797, -9.387, -8.793]
Step 173 1 visits [34.0, 50.0, 10.0, 20.0, 24.0, 8.0, 27.0]  episode_count: 260 q_vals: [-8.692, -8.644, -9.01, -8.901, -8.797, -9.387, -8.793]
Step 174 2 visits [34.0, 50.0, 11.0, 20.0, 24.0, 8.0, 27.0]  episode_count: 262 q_vals: [-8.692, -8.644, -9.201, -8.901, -8.797, -9.387, -8.793]
Step 175 0 visits [35.0, 50.0, 11.0, 20.0, 24.0, 8.0, 27.0]  episode_count: 263 q_vals: [-8.761, -8.644, -9.201, -8.901, -8.797, -9.387, -8.793]
Step 176 1 visits [35.0, 51.0, 11.0, 20.0, 24.0, 8.0, 27.0]  episode_count: 264 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.797, -9.387, -8.793]
Step 177 4 visits [35.0, 51.0, 11.0, 20.0, 25.0, 8.0, 27.0]  episode_count: 264 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.445, -9.387, -8.793]
Step 178 4 visits [35.0, 51.0, 11.0, 20.0, 26.0, 8.0, 27.0]  episode_count: 265 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.12, -9.387, -8.793]
Step 179 4 visits [35.0, 51.0, 11.0, 20.0, 27.0, 8.0, 27.0]  episode_count: 266 q_vals: [-8.761, -8.693, -9.201, -8.901, -7.819, -9.387, -8.793]
{"total_number_of_episodes": 268, "number_of_timesteps": 5602, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.017460317460317475, "biggest_recent_change": 0.5},
Step 180 4 visits [35.0, 51.0, 11.0, 20.0, 28.0, 8.0, 27.0]  episode_count: 268 q_vals: [-8.761, -8.693, -9.201, -8.901, -7.937, -9.387, -8.793]
Step 181 4 visits [35.0, 51.0, 11.0, 20.0, 29.0, 8.0, 27.0]  episode_count: 269 q_vals: [-8.761, -8.693, -9.201, -8.901, -7.663, -9.387, -8.793]
Step 182 4 visits [35.0, 51.0, 11.0, 20.0, 30.0, 8.0, 27.0]  episode_count: 270 q_vals: [-8.761, -8.693, -9.201, -8.901, -7.778, -9.387, -8.793]
Step 183 4 visits [35.0, 51.0, 11.0, 20.0, 31.0, 8.0, 27.0]  episode_count: 271 q_vals: [-8.761, -8.693, -9.201, -8.901, -7.886, -9.387, -8.793]
Step 184 4 visits [35.0, 51.0, 11.0, 20.0, 32.0, 8.0, 27.0]  episode_count: 274 q_vals: [-8.761, -8.693, -9.201, -8.901, -7.987, -9.387, -8.793]
Step 185 4 visits [35.0, 51.0, 11.0, 20.0, 33.0, 8.0, 27.0]  episode_count: 275 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.081, -9.387, -8.793]
Step 186 4 visits [35.0, 51.0, 11.0, 20.0, 34.0, 8.0, 27.0]  episode_count: 276 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.17, -9.387, -8.793]
Step 187 4 visits [35.0, 51.0, 11.0, 20.0, 35.0, 8.0, 27.0]  episode_count: 277 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.254, -9.387, -8.793]
{"total_number_of_episodes": 279, "number_of_timesteps": 5906, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.02142857142857141, "biggest_recent_change": 0.5},
Step 188 4 visits [35.0, 51.0, 11.0, 20.0, 36.0, 8.0, 27.0]  episode_count: 279 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.334, -9.387, -8.793]
Step 189 4 visits [35.0, 51.0, 11.0, 20.0, 37.0, 8.0, 27.0]  episode_count: 279 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.409, -9.387, -8.793]
Step 190 4 visits [35.0, 51.0, 11.0, 20.0, 38.0, 8.0, 27.0]  episode_count: 282 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.48, -9.387, -8.793]
Step 191 4 visits [35.0, 51.0, 11.0, 20.0, 39.0, 8.0, 27.0]  episode_count: 285 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.547, -9.387, -8.793]
Step 192 4 visits [35.0, 51.0, 11.0, 20.0, 40.0, 8.0, 27.0]  episode_count: 286 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.334, -9.387, -8.793]
Step 193 4 visits [35.0, 51.0, 11.0, 20.0, 41.0, 8.0, 27.0]  episode_count: 287 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.401, -9.387, -8.793]
{"total_number_of_episodes": 289, "number_of_timesteps": 6097, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.5},
Step 194 4 visits [35.0, 51.0, 11.0, 20.0, 42.0, 8.0, 27.0]  episode_count: 289 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.466, -9.387, -8.793]
Step 195 4 visits [35.0, 51.0, 11.0, 20.0, 43.0, 8.0, 27.0]  episode_count: 290 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.527, -9.387, -8.793]
Step 196 4 visits [35.0, 51.0, 11.0, 20.0, 44.0, 8.0, 27.0]  episode_count: 292 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.586, -9.387, -8.793]
Step 197 4 visits [35.0, 51.0, 11.0, 20.0, 45.0, 8.0, 27.0]  episode_count: 294 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.642, -9.387, -8.793]
Step 198 4 visits [35.0, 51.0, 11.0, 20.0, 46.0, 8.0, 27.0]  episode_count: 295 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.696, -9.387, -8.793]
Step 199 6 visits [35.0, 51.0, 11.0, 20.0, 46.0, 8.0, 28.0]  episode_count: 297 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.696, -9.387, -8.876]
{"total_number_of_episodes": 300, "number_of_timesteps": 6310, "per_episode_reward": 18.07, "episode_reward_trend_value": -0.0103174603174603, "biggest_recent_change": 0.42857142857142705},
Step 200 4 visits [35.0, 51.0, 11.0, 20.0, 47.0, 8.0, 28.0]  episode_count: 300 q_vals: [-8.761, -8.693, -9.201, -8.901, -8.747, -9.387, -8.876]
Step 201 1 visits [35.0, 52.0, 11.0, 20.0, 47.0, 8.0, 28.0]  episode_count: 301 q_vals: [-8.761, -8.739, -9.201, -8.901, -8.747, -9.387, -8.876]
Step 202 0 visits [36.0, 52.0, 11.0, 20.0, 47.0, 8.0, 28.0]  episode_count: 303 q_vals: [-8.826, -8.739, -9.201, -8.901, -8.747, -9.387, -8.876]
Step 203 3 visits [36.0, 52.0, 11.0, 21.0, 47.0, 8.0, 28.0]  episode_count: 305 q_vals: [-8.826, -8.739, -9.201, -9.006, -8.747, -9.387, -8.876]
Step 204 4 visits [36.0, 52.0, 11.0, 21.0, 48.0, 8.0, 28.0]  episode_count: 306 q_vals: [-8.826, -8.739, -9.201, -9.006, -8.565, -9.387, -8.876]
Step 205 4 visits [36.0, 52.0, 11.0, 21.0, 49.0, 8.0, 28.0]  episode_count: 308 q_vals: [-8.826, -8.739, -9.201, -9.006, -8.617, -9.387, -8.876]
{"total_number_of_episodes": 311, "number_of_timesteps": 6486, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.006349206349206366, "biggest_recent_change": 0.35714285714285765},
Step 206 4 visits [36.0, 52.0, 11.0, 21.0, 50.0, 8.0, 28.0]  episode_count: 311 q_vals: [-8.826, -8.739, -9.201, -9.006, -8.667, -9.387, -8.876]
Step 207 4 visits [36.0, 52.0, 11.0, 21.0, 51.0, 8.0, 28.0]  episode_count: 312 q_vals: [-8.826, -8.739, -9.201, -9.006, -8.715, -9.387, -8.876]
Step 208 4 visits [36.0, 52.0, 11.0, 21.0, 52.0, 8.0, 28.0]  episode_count: 315 q_vals: [-8.826, -8.739, -9.201, -9.006, -8.761, -9.387, -8.876]
Step 209 1 visits [36.0, 53.0, 11.0, 21.0, 52.0, 8.0, 28.0]  episode_count: 317 q_vals: [-8.826, -8.784, -9.201, -9.006, -8.761, -9.387, -8.876]
Step 210 6 visits [36.0, 53.0, 11.0, 21.0, 52.0, 8.0, 29.0]  episode_count: 318 q_vals: [-8.826, -8.784, -9.201, -9.006, -8.761, -9.387, -8.953]
Step 211 4 visits [36.0, 53.0, 11.0, 21.0, 53.0, 8.0, 29.0]  episode_count: 319 q_vals: [-8.826, -8.784, -9.201, -9.006, -8.805, -9.387, -8.953]
{"total_number_of_episodes": 322, "number_of_timesteps": 6674, "per_episode_reward": 17.86, "episode_reward_trend_value": -0.004761904761904745, "biggest_recent_change": 0.35714285714285765},
Step 212 0 visits [37.0, 53.0, 11.0, 21.0, 53.0, 8.0, 29.0]  episode_count: 322 q_vals: [-8.588, -8.784, -9.201, -9.006, -8.805, -9.387, -8.953]
Step 213 0 visits [38.0, 53.0, 11.0, 21.0, 53.0, 8.0, 29.0]  episode_count: 323 q_vals: [-8.654, -8.784, -9.201, -9.006, -8.805, -9.387, -8.953]
Step 214 0 visits [39.0, 53.0, 11.0, 21.0, 53.0, 8.0, 29.0]  episode_count: 326 q_vals: [-8.717, -8.784, -9.201, -9.006, -8.805, -9.387, -8.953]
Step 215 0 visits [40.0, 53.0, 11.0, 21.0, 53.0, 8.0, 29.0]  episode_count: 328 q_vals: [-8.777, -8.784, -9.201, -9.006, -8.805, -9.387, -8.953]
Step 216 0 visits [41.0, 53.0, 11.0, 21.0, 53.0, 8.0, 29.0]  episode_count: 330 q_vals: [-8.834, -8.784, -9.201, -9.006, -8.805, -9.387, -8.953]
Step 217 1 visits [41.0, 54.0, 11.0, 21.0, 53.0, 8.0, 29.0]  episode_count: 330 q_vals: [-8.834, -8.827, -9.201, -9.006, -8.805, -9.387, -8.953]
{"total_number_of_episodes": 335, "number_of_timesteps": 6878, "per_episode_reward": 17.79, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 218 0 visits [42.0, 54.0, 11.0, 21.0, 53.0, 8.0, 29.0]  episode_count: 335 q_vals: [-8.888, -8.827, -9.201, -9.006, -8.805, -9.387, -8.953]
Step 219 4 visits [42.0, 54.0, 11.0, 21.0, 54.0, 8.0, 29.0]  episode_count: 335 q_vals: [-8.888, -8.827, -9.201, -9.006, -8.642, -9.387, -8.953]
Step 220 4 visits [42.0, 54.0, 11.0, 21.0, 55.0, 8.0, 29.0]  episode_count: 335 q_vals: [-8.888, -8.827, -9.201, -9.006, -8.687, -9.387, -8.953]
Step 221 4 visits [42.0, 54.0, 11.0, 21.0, 56.0, 8.0, 29.0]  episode_count: 337 q_vals: [-8.888, -8.827, -9.201, -9.006, -8.73, -9.387, -8.953]
Step 222 4 visits [42.0, 54.0, 11.0, 21.0, 57.0, 8.0, 29.0]  episode_count: 338 q_vals: [-8.888, -8.827, -9.201, -9.006, -8.772, -9.387, -8.953]
Step 223 4 visits [42.0, 54.0, 11.0, 21.0, 58.0, 8.0, 29.0]  episode_count: 340 q_vals: [-8.888, -8.827, -9.201, -9.006, -8.813, -9.387, -8.953]
Step 224 3 visits [42.0, 54.0, 11.0, 22.0, 58.0, 8.0, 29.0]  episode_count: 341 q_vals: [-8.888, -8.827, -9.201, -9.102, -8.813, -9.387, -8.953]
{"total_number_of_episodes": 345, "number_of_timesteps": 7102, "per_episode_reward": 17.71, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 225 2 visits [42.0, 54.0, 12.0, 22.0, 58.0, 8.0, 29.0]  episode_count: 345 q_vals: [-8.888, -8.827, -9.36, -9.102, -8.813, -9.387, -8.953]
Step 226 4 visits [42.0, 54.0, 12.0, 22.0, 59.0, 8.0, 29.0]  episode_count: 346 q_vals: [-8.888, -8.827, -9.36, -9.102, -8.851, -9.387, -8.953]
Step 227 1 visits [42.0, 55.0, 12.0, 22.0, 59.0, 8.0, 29.0]  episode_count: 347 q_vals: [-8.888, -8.869, -9.36, -9.102, -8.851, -9.387, -8.953]
Step 228 6 visits [42.0, 55.0, 12.0, 22.0, 59.0, 8.0, 30.0]  episode_count: 349 q_vals: [-8.888, -8.869, -9.36, -9.102, -8.851, -9.387, -8.654]
Step 229 6 visits [42.0, 55.0, 12.0, 22.0, 59.0, 8.0, 31.0]  episode_count: 352 q_vals: [-8.888, -8.869, -9.36, -9.102, -8.851, -9.387, -8.734]
Step 230 6 visits [42.0, 55.0, 12.0, 22.0, 59.0, 8.0, 32.0]  episode_count: 353 q_vals: [-8.888, -8.869, -9.36, -9.102, -8.851, -9.387, -8.808]
Step 231 6 visits [42.0, 55.0, 12.0, 22.0, 59.0, 8.0, 33.0]  episode_count: 354 q_vals: [-8.888, -8.869, -9.36, -9.102, -8.851, -9.387, -8.878]
{"total_number_of_episodes": 356, "number_of_timesteps": 7271, "per_episode_reward": 17.79, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.2142857142857153},
Step 232 6 visits [42.0, 55.0, 12.0, 22.0, 59.0, 8.0, 34.0]  episode_count: 356 q_vals: [-8.888, -8.869, -9.36, -9.102, -8.851, -9.387, -8.943]
Step 233 0 visits [43.0, 55.0, 12.0, 22.0, 59.0, 8.0, 34.0]  episode_count: 357 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.851, -9.387, -8.943]
Step 234 6 visits [43.0, 55.0, 12.0, 22.0, 59.0, 8.0, 35.0]  episode_count: 358 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.851, -9.387, -8.688]
Step 235 6 visits [43.0, 55.0, 12.0, 22.0, 59.0, 8.0, 36.0]  episode_count: 359 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.851, -9.387, -8.755]
Step 236 6 visits [43.0, 55.0, 12.0, 22.0, 59.0, 8.0, 37.0]  episode_count: 360 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.851, -9.387, -8.819]
Step 237 6 visits [43.0, 55.0, 12.0, 22.0, 59.0, 8.0, 38.0]  episode_count: 361 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.851, -9.387, -8.879]
Step 238 6 visits [43.0, 55.0, 12.0, 22.0, 59.0, 8.0, 39.0]  episode_count: 365 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.851, -9.387, -8.652]
Step 239 6 visits [43.0, 55.0, 12.0, 22.0, 59.0, 8.0, 40.0]  episode_count: 365 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.851, -9.387, -8.713]
{"total_number_of_episodes": 366, "number_of_timesteps": 7505, "per_episode_reward": 17.79, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.14285714285714235},
Step 240 6 visits [43.0, 55.0, 12.0, 22.0, 59.0, 8.0, 41.0]  episode_count: 366 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.851, -9.387, -8.772]
Step 241 6 visits [43.0, 55.0, 12.0, 22.0, 59.0, 8.0, 42.0]  episode_count: 369 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.851, -9.387, -8.827]
Step 242 6 visits [43.0, 55.0, 12.0, 22.0, 59.0, 8.0, 43.0]  episode_count: 370 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.851, -9.387, -8.88]
Step 243 6 visits [43.0, 55.0, 12.0, 22.0, 59.0, 8.0, 44.0]  episode_count: 370 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.851, -9.387, -8.931]
Step 244 4 visits [43.0, 55.0, 12.0, 22.0, 60.0, 8.0, 44.0]  episode_count: 372 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.704, -9.387, -8.931]
Step 245 4 visits [43.0, 55.0, 12.0, 22.0, 61.0, 8.0, 44.0]  episode_count: 374 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.743, -9.387, -8.931]
Step 246 4 visits [43.0, 55.0, 12.0, 22.0, 62.0, 8.0, 44.0]  episode_count: 375 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.782, -9.387, -8.931]
{"total_number_of_episodes": 376, "number_of_timesteps": 7731, "per_episode_reward": 17.79, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.14285714285714235},
Step 247 4 visits [43.0, 55.0, 12.0, 22.0, 63.0, 8.0, 44.0]  episode_count: 376 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.819, -9.387, -8.931]
Step 248 4 visits [43.0, 55.0, 12.0, 22.0, 64.0, 8.0, 44.0]  episode_count: 378 q_vals: [-8.94, -8.869, -9.36, -9.102, -8.854, -9.387, -8.931]
Step 249 1 visits [43.0, 56.0, 12.0, 22.0, 64.0, 8.0, 44.0]  episode_count: 381 q_vals: [-8.94, -8.909, -9.36, -9.102, -8.854, -9.387, -8.931]
Step 250 5 visits [43.0, 56.0, 12.0, 22.0, 64.0, 9.0, 44.0]  episode_count: 381 q_vals: [-8.94, -8.909, -9.36, -9.102, -8.854, -9.579, -8.931]
Step 251 4 visits [43.0, 56.0, 12.0, 22.0, 65.0, 9.0, 44.0]  episode_count: 382 q_vals: [-8.94, -8.909, -9.36, -9.102, -8.718, -9.579, -8.931]
Step 252 4 visits [43.0, 56.0, 12.0, 22.0, 66.0, 9.0, 44.0]  episode_count: 384 q_vals: [-8.94, -8.909, -9.36, -9.102, -8.754, -9.579, -8.931]
Step 253 4 visits [43.0, 56.0, 12.0, 22.0, 67.0, 9.0, 44.0]  episode_count: 385 q_vals: [-8.94, -8.909, -9.36, -9.102, -8.79, -9.579, -8.931]
{"total_number_of_episodes": 387, "number_of_timesteps": 7924, "per_episode_reward": 17.71, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 254 4 visits [43.0, 56.0, 12.0, 22.0, 68.0, 9.0, 44.0]  episode_count: 387 q_vals: [-8.94, -8.909, -9.36, -9.102, -8.66, -9.579, -8.931]
Step 255 4 visits [43.0, 56.0, 12.0, 22.0, 69.0, 9.0, 44.0]  episode_count: 390 q_vals: [-8.94, -8.909, -9.36, -9.102, -8.696, -9.579, -8.931]
Step 256 4 visits [43.0, 56.0, 12.0, 22.0, 70.0, 9.0, 44.0]  episode_count: 390 q_vals: [-8.94, -8.909, -9.36, -9.102, -8.73, -9.579, -8.931]
Step 257 4 visits [43.0, 56.0, 12.0, 22.0, 71.0, 9.0, 44.0]  episode_count: 392 q_vals: [-8.94, -8.909, -9.36, -9.102, -8.764, -9.579, -8.931]
Step 258 4 visits [43.0, 56.0, 12.0, 22.0, 72.0, 9.0, 44.0]  episode_count: 394 q_vals: [-8.94, -8.909, -9.36, -9.102, -8.797, -9.579, -8.931]
Step 259 4 visits [43.0, 56.0, 12.0, 22.0, 73.0, 9.0, 44.0]  episode_count: 396 q_vals: [-8.94, -8.909, -9.36, -9.102, -8.828, -9.579, -8.931]
{"total_number_of_episodes": 398, "number_of_timesteps": 8173, "per_episode_reward": 17.57, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.14285714285714235},
Step 260 4 visits [43.0, 56.0, 12.0, 22.0, 74.0, 9.0, 44.0]  episode_count: 398 q_vals: [-8.94, -8.909, -9.36, -9.102, -8.859, -9.579, -8.931]
Step 261 6 visits [43.0, 56.0, 12.0, 22.0, 74.0, 9.0, 45.0]  episode_count: 398 q_vals: [-8.94, -8.909, -9.36, -9.102, -8.859, -9.579, -8.979]
Step 262 0 visits [44.0, 56.0, 12.0, 22.0, 74.0, 9.0, 45.0]  episode_count: 402 q_vals: [-8.989, -8.909, -9.36, -9.102, -8.859, -9.579, -8.979]
Step 263 4 visits [44.0, 56.0, 12.0, 22.0, 75.0, 9.0, 45.0]  episode_count: 405 q_vals: [-8.989, -8.909, -9.36, -9.102, -8.889, -9.579, -8.979]
Step 264 1 visits [44.0, 57.0, 12.0, 22.0, 75.0, 9.0, 45.0]  episode_count: 406 q_vals: [-8.989, -8.947, -9.36, -9.102, -8.889, -9.579, -8.979]
Step 265 3 visits [44.0, 57.0, 12.0, 23.0, 75.0, 9.0, 45.0]  episode_count: 407 q_vals: [-8.989, -8.947, -9.36, -9.189, -8.889, -9.579, -8.979]
Step 266 4 visits [44.0, 57.0, 12.0, 23.0, 76.0, 9.0, 45.0]  episode_count: 407 q_vals: [-8.989, -8.947, -9.36, -9.189, -8.918, -9.579, -8.979]
{"total_number_of_episodes": 409, "number_of_timesteps": 8374, "per_episode_reward": 17.57, "episode_reward_trend_value": -0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
Step 267 6 visits [44.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 409 q_vals: [-8.989, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 268 0 visits [starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[45.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 410 q_vals: [-8.789, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 269 0 visits [46.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 410 q_vals: [-8.84, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 270 0 visits [47.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 410 q_vals: [-8.652, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 271 0 visits [48.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 412 q_vals: [-8.703, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 272 0 visits [49.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 413 q_vals: [-8.752, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 273 0 visits [50.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 414 q_vals: [-8.799, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 274 0 visits [51.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 415 q_vals: [-8.627, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 275 0 visits [52.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 417 q_vals: [-8.675, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
{"total_number_of_episodes": 419, "number_of_timesteps": 8705, "per_episode_reward": 17.57, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 276 0 visits [53.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 419 q_vals: [-8.721, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 277 0 visits [54.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 421 q_vals: [-8.559, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 278 0 visits [55.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 423 q_vals: [-8.606, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 279 0 visits [56.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 424 q_vals: [-8.65, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 280 0 visits [57.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 425 q_vals: [-8.693, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 281 0 visits [58.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 426 q_vals: [-8.544, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
{"total_number_of_episodes": 429, "number_of_timesteps": 8886, "per_episode_reward": 17.5, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 282 0 visits [59.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 429 q_vals: [-8.587, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 283 0 visits [60.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 431 q_vals: [-8.629, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 284 0 visits [61.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 431 q_vals: [-8.67, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 285 0 visits [62.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 434 q_vals: [-8.709, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 286 0 visits [63.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 435 q_vals: [-8.747, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 287 0 visits [64.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 436 q_vals: [-8.784, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 288 0 visits [65.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 438 q_vals: [-8.82, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 289 0 visits [66.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 438 q_vals: [-8.855, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
{"total_number_of_episodes": 440, "number_of_timesteps": 9124, "per_episode_reward": 17.64, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.14285714285714235},
Step 290 0 visits [67.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 440 q_vals: [-8.888, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 291 0 visits [68.0, 57.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 442 q_vals: [-8.921, -8.947, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 292 1 visits [68.0, 58.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 443 q_vals: [-8.921, -8.985, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 293 0 visits [69.0, 58.0, 12.0, 23.0, 76.0, 9.0, 46.0]  episode_count: 445 q_vals: [-8.953, -8.985, -9.36, -9.189, -8.918, -9.579, -9.026]
Step 294 4 visits [69.0, 58.0, 12.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 445 q_vals: [-8.953, -8.985, -9.36, -9.189, -8.947, -9.579, -9.026]
Step 295 0 visits [70.0, 58.0, 12.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 445 q_vals: [-8.984, -8.985, -9.36, -9.189, -8.947, -9.579, -9.026]
Step 296 1 visits [70.0, 59.0, 12.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 449 q_vals: [-8.984, -8.832, -9.36, -9.189, -8.947, -9.579, -9.026]
{"total_number_of_episodes": 450, "number_of_timesteps": 9368, "per_episode_reward": 17.79, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 297 1 visits [70.0, 60.0, 12.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 450 q_vals: [-8.984, -8.87, -9.36, -9.189, -8.947, -9.579, -9.026]
Step 298 1 visits [70.0, 61.0, 12.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 450 q_vals: [-8.984, -8.907, -9.36, -9.189, -8.947, -9.579, -9.026]
Step 299 1 visits [70.0, 62.0, 12.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 452 q_vals: [-8.984, -8.943, -9.36, -9.189, -8.947, -9.579, -9.026]
Step 300 1 visits [70.0, 63.0, 12.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 455 q_vals: [-8.984, -8.977, -9.36, -9.189, -8.947, -9.579, -9.026]
Step 301 2 visits [70.0, 63.0, 13.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 455 q_vals: [-8.984, -8.977, -8.64, -9.189, -8.947, -9.579, -9.026]
Step 302 2 visits [70.0, 63.0, 14.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 457 q_vals: [-8.984, -8.977, -8.817, -9.189, -8.947, -9.579, -9.026]
{"total_number_of_episodes": 460, "number_of_timesteps": 9569, "per_episode_reward": 17.64, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 303 2 visits [70.0, 63.0, 15.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 460 q_vals: [-8.984, -8.977, -8.97, -9.189, -8.947, -9.579, -9.026]
Step 304 2 visits [70.0, 63.0, 16.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 461 q_vals: [-8.984, -8.977, -9.104, -9.189, -8.947, -9.579, -9.026]
Step 305 2 visits [70.0, 63.0, 17.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 461 q_vals: [-8.984, -8.977, -9.222, -9.189, -8.947, -9.579, -9.026]
Step 306 2 visits [70.0, 63.0, 18.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 463 q_vals: [-8.984, -8.977, -8.709, -9.189, -8.947, -9.579, -9.026]
Step 307 2 visits [70.0, 63.0, 19.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 464 q_vals: [-8.984, -8.977, -8.836, -9.189, -8.947, -9.579, -9.026]
Step 308 2 visits [70.0, 63.0, 20.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 465 q_vals: [-8.984, -8.977, -8.95, -9.189, -8.947, -9.579, -9.026]
Step 309 2 visits [70.0, 63.0, 21.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 466 q_vals: [-8.984, -8.977, -9.053, -9.189, -8.947, -9.579, -9.026]
Step 310 2 visits [70.0, 63.0, 22.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 468 q_vals: [-8.984, -8.977, -9.146, -9.189, -8.947, -9.579, -9.026]
{"total_number_of_episodes": 470, "number_of_timesteps": 9801, "per_episode_reward": 17.64, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 311 2 visits [70.0, 63.0, 23.0, 23.0, 77.0, 9.0, 46.0]  episode_count: 470 q_vals: [-8.984, -8.977, -9.232, -9.189, -8.947, -9.579, -9.026]
Step 312 6 visits [70.0, 63.0, 23.0, 23.0, 77.0, 9.0, 47.0]  episode_count: 471 q_vals: [-8.984, -8.977, -9.232, -9.189, -8.947, -9.579, -9.07]
Step 313 4 visits [70.0, 63.0, 23.0, 23.0, 78.0, 9.0, 47.0]  episode_count: 474 q_vals: [-8.984, -8.977, -9.232, -9.189, -8.975, -9.579, -9.07]
Step 314 1 visits [70.0, 64.0, 23.0, 23.0, 78.0, 9.0, 47.0]  episode_count: 474 q_vals: [-8.984, -9.01, -9.232, -9.189, -8.975, -9.579, -9.07]
Step 315 3 visits [70.0, 64.0, 23.0, 24.0, 78.0, 9.0, 47.0]  episode_count: 476 q_vals: [-8.984, -9.01, -9.232, -9.269, -8.975, -9.579, -9.07]
Step 316 0 visits [71.0, 64.0, 23.0, 24.0, 78.0, 9.0, 47.0]  episode_count: 478 q_vals: [-9.014, -9.01, -9.232, -9.269, -8.975, -9.579, -9.07]
{"total_number_of_episodes": 480, "number_of_timesteps": 10018, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 317 4 visits [71.0, 64.0, 23.0, 24.0, 79.0, 9.0, 47.0]  episode_count: 480 q_vals: [-9.014, -9.01, -9.232, -9.269, -9.002, -9.579, -9.07]
Step 318 1 visits [71.0, 65.0, 23.0, 24.0, 79.0, 9.0, 47.0]  episode_count: 480 q_vals: [-9.014, -9.043, -9.232, -9.269, -9.002, -9.579, -9.07]
Step 319 6 visits [71.0, 65.0, 23.0, 24.0, 79.0, 9.0, 48.0]  episode_count: 483 q_vals: [-9.014, -9.043, -9.232, -9.269, -9.002, -9.579, -9.113]
Step 320 0 visits [72.0, 65.0, 23.0, 24.0, 79.0, 9.0, 48.0]  episode_count: 484 q_vals: [-9.043, -9.043, -9.232, -9.269, -9.002, -9.579, -9.113]
Step 321 2 visits [72.0, 65.0, 24.0, 24.0, 79.0, 9.0, 48.0]  episode_count: 485 q_vals: [-9.043, -9.043, -8.847, -9.269, -9.002, -9.579, -9.113]
Step 322 2 visits [72.0, 65.0, 25.0, 24.0, 79.0, 9.0, 48.0]  episode_count: 485 q_vals: [-9.043, -9.043, -8.937, -9.269, -9.002, -9.579, -9.113]
{"total_number_of_episodes": 490, "number_of_timesteps": 10215, "per_episode_reward": 17.79, "episode_reward_trend_value": 0.0023809523809523525, "biggest_recent_change": 0.14285714285714235},
Step 323 2 visits [72.0, 65.0, 26.0, 24.0, 79.0, 9.0, 48.0]  episode_count: 490 q_vals: [-9.043, -9.043, -9.021, -9.269, -9.002, -9.579, -9.113]
Step 324 2 visits [72.0, 65.0, 27.0, 24.0, 79.0, 9.0, 48.0]  episode_count: 491 q_vals: [-9.043, -9.043, -9.098, -9.269, -9.002, -9.579, -9.113]
Step 325 2 visits [72.0, 65.0, 28.0, 24.0, 79.0, 9.0, 48.0]  episode_count: 492 q_vals: [-9.043, -9.043, -9.17, -9.269, -9.002, -9.579, -9.113]
Step 326 2 visits [72.0, 65.0, 29.0, 24.0, 79.0, 9.0, 48.0]  episode_count: 493 q_vals: [-9.043, -9.043, -9.237, -9.269, -9.002, -9.579, -9.113]
Step 327 4 visits [72.0, 65.0, 29.0, 24.0, 80.0, 9.0, 48.0]  episode_count: 495 q_vals: [-9.043, -9.043, -9.237, -9.269, -9.028, -9.579, -9.113]
Step 328 1 visits [72.0, 66.0, 29.0, 24.0, 80.0, 9.0, 48.0]  episode_count: 496 q_vals: [-9.043, -9.074, -9.237, -9.269, -9.028, -9.579, -9.113]
Step 329 4 visits [72.0, 66.0, 29.0, 24.0, 81.0, 9.0, 48.0]  episode_count: 499 q_vals: [-9.043, -9.074, -9.237, -9.269, -9.054, -9.579, -9.113]
{"total_number_of_episodes": 500, "number_of_timesteps": 10416, "per_episode_reward": 17.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 330 0 visits [73.0, 66.0, 29.0, 24.0, 81.0, 9.0, 48.0]  episode_count: 500 q_vals: [-9.071, -9.074, -9.237, -9.269, -9.054, -9.579, -9.113]
Step 331 6 visits [73.0, 66.0, 29.0, 24.0, 81.0, 9.0, 49.0]  episode_count: 501 q_vals: [-9.071, -9.074, -9.237, -9.269, -9.054, -9.579, -9.153]
Step 332 5 visits [73.0, 66.0, 29.0, 24.0, 81.0, 10.0, 49.0]  episode_count: 503 q_vals: [-9.071, -9.074, -9.237, -9.269, -9.054, -9.732, -9.153]
Step 333 1 visits [73.0, 67.0, 29.0, 24.0, 81.0, 10.0, 49.0]  episode_count: 504 q_vals: [-9.071, -9.104, -9.237, -9.269, -9.054, -9.732, -9.153]
Step 334 3 visits [73.0, 67.0, 29.0, 25.0, 81.0, 10.0, 49.0]  episode_count: 506 q_vals: [-9.071, -9.104, -9.237, -8.899, -9.054, -9.732, -9.153]
Step 335 3 visits [73.0, 67.0, 29.0, 26.0, 81.0, 10.0, 49.0]  episode_count: 507 q_vals: [-9.071, -9.104, -9.237, -8.984, -9.054, -9.732, -9.153]
Step 336 3 visits [73.0, 67.0, 29.0, 27.0, 81.0, 10.0, 49.0]  episode_count: 509 q_vals: [-9.071, -9.104, -9.237, -9.063, -9.054, -9.732, -9.153]
{"total_number_of_episodes": 510, "number_of_timesteps": 10645, "per_episode_reward": 17.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 337 3 visits [73.0, 67.0, 29.0, 28.0, 81.0, 10.0, 49.0]  episode_count: 510 q_vals: [-9.071, -9.104, -9.237, -9.136, -9.054, -9.732, -9.153]
Step 338 3 visits [73.0, 67.0, 29.0, 29.0, 81.0, 10.0, 49.0]  episode_count: 510 q_vals: [-9.071, -9.104, -9.237, -8.821, -9.054, -9.732, -9.153]
Step 339 3 visits [73.0, 67.0, 29.0, 30.0, 81.0, 10.0, 49.0]  episode_count: 511 q_vals: [-9.071, -9.104, -9.237, -8.897, -9.054, -9.732, -9.153]
Step 340 3 visits [73.0, 67.0, 29.0, 31.0, 81.0, 10.0, 49.0]  episode_count: 514 q_vals: [-9.071, -9.104, -9.237, -8.968, -9.054, -9.732, -9.153]
Step 341 3 visits [73.0, 67.0, 29.0, 32.0, 81.0, 10.0, 49.0]  episode_count: 515 q_vals: [-9.071, -9.104, -9.237, -9.035, -9.054, -9.732, -9.153]
Step 342 3 visits [73.0, 67.0, 29.0, 33.0, 81.0, 10.0, 49.0]  episode_count: 515 q_vals: [-9.071, -9.104, -9.237, -8.762, -9.054, -9.732, -9.153]
Step 343 3 visits [73.0, 67.0, 29.0, 34.0, 81.0, 10.0, 49.0]  episode_count: 516 q_vals: [-9.071, -9.104, -9.237, -8.831, -9.054, -9.732, -9.153]
Step 344 3 visits [73.0, 67.0, 29.0, 35.0, 81.0, 10.0, 49.0]  episode_count: 518 q_vals: [-9.071, -9.104, -9.237, -8.578, -9.054, -9.732, -9.153]
Step 345 3 visits [73.0, 67.0, 29.0, 36.0, 81.0, 10.0, 49.0]  episode_count: 518 q_vals: [-9.071, -9.104, -9.237, -8.649, -9.054, -9.732, -9.153]
Step 346 3 visits [73.0, 67.0, 29.0, 37.0, 81.0, 10.0, 49.0]  episode_count: 519 q_vals: [-9.071, -9.104, -9.237, -8.715, -9.054, -9.732, -9.153]
{"total_number_of_episodes": 520, "number_of_timesteps": 10912, "per_episode_reward": 17.93, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
Step 347 3 visits [73.0, 67.0, 29.0, 38.0, 81.0, 10.0, 49.0]  episode_count: 520 q_vals: [-9.071, -9.104, -9.237, -8.778, -9.054, -9.732, -9.153]
Step 348 3 visits [73.0, 67.0, 29.0, 39.0, 81.0, 10.0, 49.0]  episode_count: 520 q_vals: [-9.071, -9.104, -9.237, -8.838, -9.054, -9.732, -9.153]
Step 349 3 visits [73.0, 67.0, 29.0, 40.0, 81.0, 10.0, 49.0]  episode_count: 521 q_vals: [-9.071, -9.104, -9.237, -8.895, -9.054, -9.732, -9.153]
Step 350 3 visits [73.0, 67.0, 29.0, 41.0, 81.0, 10.0, 49.0]  episode_count: 523 q_vals: [-9.071, -9.104, -9.237, -8.949, -9.054, -9.732, -9.153]
Step 351 3 visits [73.0, 67.0, 29.0, 42.0, 81.0, 10.0, 49.0]  episode_count: 525 q_vals: [-9.071, -9.104, -9.237, -9.001, -9.054, -9.732, -9.153]
Step 352 3 visits [73.0, 67.0, 29.0, 43.0, 81.0, 10.0, 49.0]  episode_count: 526 q_vals: [-9.071, -9.104, -9.237, -9.05, -9.054, -9.732, -9.153]
Step 353 3 visits [73.0, 67.0, 29.0, 44.0, 81.0, 10.0, 49.0]  episode_count: 526 q_vals: [-9.071, -9.104, -9.237, -9.096, -9.054, -9.732, -9.153]
Step 354 3 visits [73.0, 67.0, 29.0, 45.0, 81.0, 10.0, 49.0]  episode_count: 529 q_vals: [-9.071, -9.104, -9.237, -9.141, -9.054, -9.732, -9.153]
{"total_number_of_episodes": 531, "number_of_timesteps": 11222, "per_episode_reward": 17.93, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 355 3 visits [73.0, 67.0, 29.0, 46.0, 81.0, 10.0, 49.0]  episode_count: 531 q_vals: [-9.071, -9.104, -9.237, -9.184, -9.054, -9.732, -9.153]
Step 356 4 visits [73.0, 67.0, 29.0, 46.0, 82.0, 10.0, 49.0]  episode_count: 532 q_vals: [-9.071, -9.104, -9.237, -9.184, -9.079, -9.732, -9.153]
Step 357 2 visits [73.0, 67.0, 30.0, 46.0, 82.0, 10.0, 49.0]  episode_count: 534 q_vals: [-9.071, -9.104, -9.3, -9.184, -9.079, -9.732, -9.153]
Step 358 0 visits [74.0, 67.0, 30.0, 46.0, 82.0, 10.0, 49.0]  episode_count: 534 q_vals: [-9.099, -9.104, -9.3, -9.184, -9.079, -9.732, -9.153]
Step 359 6 visits [74.0, 67.0, 30.0, 46.0, 82.0, 10.0, 50.0]  episode_count: 536 q_vals: [-9.099, -9.104, -9.3, -9.184, -9.079, -9.732, -9.193]
Step 360 1 visits [74.0, 68.0, 30.0, 46.0, 82.0, 10.0, 50.0]  episode_count: 537 q_vals: [-9.099, -9.134, -9.3, -9.184, -9.079, -9.732, -9.193]
Step 361 4 visits [74.0, 68.0, 30.0, 46.0, 83.0, 10.0, 50.0]  episode_count: 540 q_vals: [-9.099, -9.134, -9.3, -9.184, -9.103, -9.732, -9.193]
{"total_number_of_episodes": 542, "number_of_timesteps": 11460, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.14285714285714235},
Step 362 0 visits [75.0, 68.0, 30.0, 46.0, 83.0, 10.0, 50.0]  episode_count: 542 q_vals: [-9.126, -9.134, -9.3, -9.184, -9.103, -9.732, -9.193]
Step 363 3 visits [75.0, 68.0, 30.0, 47.0, 83.0, 10.0, 50.0]  episode_count: 542 q_vals: [-9.126, -9.134, -9.3, -9.225, -9.103, -9.732, -9.193]
Step 364 4 visits [75.0, 68.0, 30.0, 47.0, 84.0, 10.0, 50.0]  episode_count: 544 q_vals: [-9.126, -9.134, -9.3, -9.225, -8.995, -9.732, -9.193]
Step 365 4 visits [75.0, 68.0, 30.0, 47.0, 85.0, 10.0, 50.0]  episode_count: 546 q_vals: [-9.126, -9.134, -9.3, -9.225, -9.02, -9.732, -9.193]
Step 366 4 visits [75.0, 68.0, 30.0, 47.0, 86.0, 10.0, 50.0]  episode_count: 547 q_vals: [-9.126, -9.134, -9.3, -9.225, -9.044, -9.732, -9.193]
Step 367 4 visits [75.0, 68.0, 30.0, 47.0, 87.0, 10.0, 50.0]  episode_count: 548 q_vals: [-9.126, -9.134, -9.3, -9.225, -9.068, -9.732, -9.193]
Step 368 4 visits [75.0, 68.0, 30.0, 47.0, 88.0, 10.0, 50.0]  episode_count: 550 q_vals: [-9.126, -9.134, -9.3, -9.225, -9.091, -9.732, -9.193]
{"total_number_of_episodes": 552, "number_of_timesteps": 11682, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.07142857142857295},
Step 369 4 visits [75.0, 68.0, 30.0, 47.0, 89.0, 10.0, 50.0]  episode_count: 552 q_vals: [-9.126, -9.134, -9.3, -9.225, -9.114, -9.732, -9.193]
Step 370 1 visits [75.0, 69.0, 30.0, 47.0, 89.0, 10.0, 50.0]  episode_count: 554 q_vals: [-9.126, -9.163, -9.3, -9.225, -9.114, -9.732, -9.193]
Step 371 0 visits [76.0, 69.0, 30.0, 47.0, 89.0, 10.0, 50.0]  episode_count: 555 q_vals: [-9.152, -9.163, -9.3, -9.225, -9.114, -9.732, -9.193]
Step 372 6 visits [76.0, 69.0, 30.0, 47.0, 89.0, 10.0, 51.0]  episode_count: 556 q_vals: [-9.152, -9.163, -9.3, -9.225, -9.114, -9.732, -9.23]
Step 373 2 visits [76.0, 69.0, 31.0, 47.0, 89.0, 10.0, 51.0]  episode_count: 558 q_vals: [-9.152, -9.163, -9.358, -9.225, -9.114, -9.732, -9.23]
Step 374 4 visits [76.0, 69.0, 31.0, 47.0, 90.0, 10.0, 51.0]  episode_count: 559 q_vals: [-9.152, -9.163, -9.358, -9.225, -9.136, -9.732, -9.23]
Step 375 1 visits [76.0, 70.0, 31.0, 47.0, 90.0, 10.0, 51.0]  episode_count: 559 q_vals: [-9.152, -9.19, -9.358, -9.225, -9.136, -9.732, -9.23]
Step 376 3 visits [76.0, 70.0, 31.0, 48.0, 90.0, 10.0, 51.0]  episode_count: 561 q_vals: [-9.152, -9.19, -9.358, -9.264, -9.136, -9.732, -9.23]
Step 377 0 visits [77.0, 70.0, 31.0, 48.0, 90.0, 10.0, 51.0]  episode_count: 561 q_vals: [-9.033, -9.19, -9.358, -9.264, -9.136, -9.732, -9.23]
{"total_number_of_episodes": 564, "number_of_timesteps": 11965, "per_episode_reward": 18.07, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.07142857142857295},
Step 378 0 visits [78.0, 70.0, 31.0, 48.0, 90.0, 10.0, 51.0]  episode_count: 564 q_vals: [-9.059, -9.19, -9.358, -9.264, -9.136, -9.732, -9.23]
Step 379 0 visits [79.0, 70.0, 31.0, 48.0, 90.0, 10.0, 51.0]  episode_count: 566 q_vals: [-8.945, -9.19, -9.358, -9.264, -9.136, -9.732, -9.23]
Step 380 0 visits [80.0, 70.0, 31.0, 48.0, 90.0, 10.0, 51.0]  episode_count: 566 q_vals: [-8.972, -9.19, -9.358, -9.264, -9.136, -9.732, -9.23]
Step 381 0 visits [81.0, 70.0, 31.0, 48.0, 90.0, 10.0, 51.0]  episode_count: 568 q_vals: [-8.992, -9.19, -9.358, -9.264, -9.136, -9.732, -9.23]
Step 382 0 visits [82.0, 70.0, 31.0, 48.0, 90.0, 10.0, 51.0]  episode_count: 570 q_vals: [-9.018, -9.19, -9.358, -9.264, -9.136, -9.732, -9.23]
Step 383 0 visits [83.0, 70.0, 31.0, 48.0, 90.0, 10.0, 51.0]  episode_count: 571 q_vals: [-9.043, -9.19, -9.358, -9.264, -9.136, -9.732, -9.23]
Step 384 0 visits [84.0, 70.0, 31.0, 48.0, 90.0, 10.0, 51.0]  episode_count: 572 q_vals: [-9.067, -9.19, -9.358, -9.264, -9.136, -9.732, -9.23]
{"total_number_of_episodes": 575, "number_of_timesteps": 12165, "per_episode_reward": 17.93, "episode_reward_trend_value": 0.0023809523809523525, "biggest_recent_change": 0.1428571428571459},
Step 385 0 visits [85.0, 70.0, 31.0, 48.0, 90.0, 10.0, 51.0]  episode_count: 575 q_vals: [-9.092, -9.19, -9.358, -9.264, -9.136, -9.732, -9.23]
Step 386 0 visits [86.0, 70.0, 31.0, 48.0, 90.0, 10.0, 51.0]  episode_count: 576 q_vals: [-9.115, -9.19, -9.358, -9.264, -9.136, -9.732, -9.23]
Step 387 0 visits [87.0, 70.0, 31.0, 48.0, 90.0, 10.0, 51.0]  episode_count: 578 q_vals: [-9.138, -9.19, -9.358, -9.264, -9.136, -9.732, -9.23]
Step 388 0 visits [88.0, 70.0, 31.0, 48.0, 90.0, 10.0, 51.0]  episode_count: 581 q_vals: [-9.16, -9.19, -9.358, -9.264, -9.136, -9.732, -9.23]
Step 389 4 visits [88.0, 70.0, 31.0, 48.0, 91.0, 10.0, 51.0]  episode_count: 582 q_vals: [-9.16, -9.19, -9.358, -9.264, -9.036, -9.732, -9.23]
{"total_number_of_episodes": 585, "number_of_timesteps": 12385, "per_episode_reward": 17.93, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.1428571428571459},
Step 390 4 visits [88.0, 70.0, 31.0, 48.0, 92.0, 10.0, 51.0]  episode_count: 585 q_vals: [-9.16, -9.19, -9.358, -9.264, -9.058, -9.732, -9.23]
Step 391 4 visits [88.0, 70.0, 31.0, 48.0, 93.0, 10.0, 51.0]  episode_count: 586 q_vals: [-9.16, -9.19, -9.358, -9.264, -9.08, -9.732, -9.23]
Step 392 4 visits [88.0, 70.0, 31.0, 48.0, 94.0, 10.0, 51.0]  episode_count: 589 q_vals: [-9.16, -9.19, -9.358, -9.264, -9.102, -9.732, -9.23]
Step 393 4 visits [88.0, 70.0, 31.0, 48.0, 95.0, 10.0, 51.0]  episode_count: 590 q_vals: [-9.16, -9.19, -9.358, -9.264, -9.123, -9.732, -9.23]
Step 394 4 visits [88.0, 70.0, 31.0, 48.0, 96.0, 10.0, 51.0]  episode_count: 591 q_vals: [-9.16, -9.19, -9.358, -9.264, -9.144, -9.732, -9.23]
Step 395 6 visits [88.0, 70.0, 31.0, 48.0, 96.0, 10.0, 52.0]  episode_count: 593 q_vals: [-9.16, -9.19, -9.358, -9.264, -9.144, -9.732, -9.266]
{"total_number_of_episodes": 595, "number_of_timesteps": 12550, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.1428571428571459},
Step 396 4 visits [88.0, 70.0, 31.0, 48.0, 97.0, 10.0, 52.0]  episode_count: 595 q_vals: [-9.16, -9.19, -9.358, -9.264, -9.164, -9.732, -9.266]
Step 397 1 visits [88.0, 71.0, 31.0, 48.0, 97.0, 10.0, 52.0]  episode_count: 598 q_vals: [-9.16, -9.217, -9.358, -9.264, -9.164, -9.732, -9.266]
Step 398 0 visits [89.0, 71.0, 31.0, 48.0, 97.0, 10.0, 52.0]  episode_count: 598 q_vals: [-9.182, -9.217, -9.358, -9.264, -9.164, -9.732, -9.266]
Step 399 3 visits [89.0, 71.0, 31.0, 49.0, 97.0, 10.0, 52.0]  episode_count: 602 q_vals: [-9.182, -9.217, -9.358, -9.302, -9.164, -9.732, -9.266]
Step 400 4 visits [89.0, 71.0, 31.0, 49.0, 98.0, 10.0, 52.0]  episode_count: 603 q_vals: [-9.182, -9.217, -9.358, -9.302, -9.184, -9.732, -9.266]
{"total_number_of_episodes": 605, "number_of_timesteps": 12723, "per_episode_reward": 17.93, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.1428571428571459},
Step 401 2 visits [89.0, 71.0, 32.0, 49.0, 98.0, 10.0, 52.0]  episode_count: 605 q_vals: [-9.182, -9.217, -9.413, -9.302, -9.184, -9.732, -9.266]
Step 402 0 visits [90.0, 71.0, 32.0, 49.0, 98.0, 10.0, 52.0]  episode_count: 605 q_vals: [-9.204, -9.217, -9.413, -9.302, -9.184, -9.732, -9.266]
Step 403 1 visits [90.0, 72.0, 32.0, 49.0, 98.0, 10.0, 52.0]  episode_count: 608 q_vals: [-9.204, -9.244, -9.413, -9.302, -9.184, -9.732, -9.266]
Step 404 6 visits [90.0, 72.0, 32.0, 49.0, 98.0, 10.0, 53.0]  episode_count: 609 q_vals: [-9.204, -9.244, -9.413, -9.302, -9.184, -9.732, -9.301]
Step 405 4 visits [90.0, 72.0, 32.0, 49.0, 99.0, 10.0, 53.0]  episode_count: 609 q_vals: [-9.204, -9.244, -9.413, -9.302, -9.091, -9.732, -9.301]
Step 406 4 visits [90.0, 72.0, 32.0, 49.0, 100.0, 10.0, 53.0]  episode_count: 611 q_vals: [-9.204, -9.244, -9.413, -9.302, -9.111, -9.732, -9.301]
Step 407 4 visits [90.0, 72.0, 32.0, 49.0, 101.0, 10.0, 53.0]  episode_count: 613 q_vals: [-9.204, -9.244, -9.413, -9.302, -9.131, -9.732, -9.301]
Step 408 4 visits [90.0, 72.0, 32.0, 49.0, 102.0, 10.0, 53.0]  episode_count: 613 q_vals: [-9.204, -9.244, -9.413, -9.302, -9.15, -9.732, -9.301]
{"total_number_of_episodes": 616, "number_of_timesteps": 12943, "per_episode_reward": 17.86, "episode_reward_trend_value": -0.0007936507936507711, "biggest_recent_change": 0.1428571428571459},
Step 409 4 visits [90.0, 72.0, 32.0, 49.0, 103.0, 10.0, 53.0]  episode_count: 616 q_vals: [-9.204, -9.244, -9.413, -9.302, -9.062, -9.732, -9.301]
Step 410 4 visits [90.0, 72.0, 32.0, 49.0, 104.0, 10.0, 53.0]  episode_count: 617 q_vals: [-9.204, -9.244, -9.413, -9.302, -9.081, -9.732, -9.301]
Step 411 4 visits [90.0, 72.0, 32.0, 49.0, 105.0, 10.0, 53.0]  episode_count: 617 q_vals: [-9.204, -9.244, -9.413, -9.302, -9.101, -9.732, -9.301]
Step 412 4 visits [90.0, 72.0, 32.0, 49.0, 106.0, 10.0, 53.0]  episode_count: 618 q_vals: [-9.204, -9.244, -9.413, -9.302, -9.12, -9.732, -9.301]
Step 413 4 visits [90.0, 72.0, 32.0, 49.0, 107.0, 10.0, 53.0]  episode_count: 620 q_vals: [-9.204, -9.244, -9.413, -9.302, -9.138, -9.732, -9.301]
Step 414 4 visits [90.0, 72.0, 32.0, 49.0, 108.0, 10.0, 53.0]  episode_count: 622 q_vals: [-9.204, -9.244, -9.413, -9.302, -9.157, -9.732, -9.301]
Step 415 4 visits [90.0, 72.0, 32.0, 49.0, 109.0, 10.0, 53.0]  episode_count: 624 q_vals: [-9.204, -9.244, -9.413, -9.302, -9.174, -9.732, -9.301]
Step 416 4 visits [90.0, 72.0, 32.0, 49.0, 110.0, 10.0, 53.0]  episode_count: 625 q_vals: [-9.204, -9.244, -9.413, -9.302, -9.192, -9.732, -9.301]
{"total_number_of_episodes": 626, "number_of_timesteps": 13213, "per_episode_reward": 17.93, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1428571428571459},
Step 417 0 visits [91.0, 72.0, 32.0, 49.0, 110.0, 10.0, 53.0]  episode_count: 626 q_vals: [-9.103, -9.244, -9.413, -9.302, -9.192, -9.732, -9.301]
Step 418 0 visits [92.0, 72.0, 32.0, 49.0, 110.0, 10.0, 53.0]  episode_count: 628 q_vals: [-9.124, -9.244, -9.413, -9.302, -9.192, -9.732, -9.301]
Step 419 0 visits [93.0, 72.0, 32.0, 49.0, 110.0, 10.0, 53.0]  episode_count: 628 q_vals: [-9.146, -9.244, -9.413, -9.302, -9.192, -9.732, -9.301]
Step 420 0 visits [94.0, 72.0, 32.0, 49.0, 110.0, 10.0, 53.0]  episode_count: 630 q_vals: [-9.048, -9.244, -9.413, -9.302, -9.192, -9.732, -9.301]
Step 421 0 visits [95.0, 72.0, 32.0, 49.0, 110.0, 10.0, 53.0]  episode_count: 633 q_vals: [-9.07, -9.244, -9.413, -9.302, -9.192, -9.732, -9.301]
Step 422 0 visits [96.0, 72.0, 32.0, 49.0, 110.0, 10.0, 53.0]  episode_count: 633 q_vals: [-9.091, -9.244, -9.413, -9.302, -9.192, -9.732, -9.301]
Step 423 0 visits [97.0, 72.0, 32.0, 49.0, 110.0, 10.0, 53.0]  episode_count: 633 q_vals: [-9.112, -9.244, -9.413, -9.302, -9.192, -9.732, -9.301]
Step 424 0 visits [98.0, 72.0, 32.0, 49.0, 110.0, 10.0, 53.0]  episode_count: 634 q_vals: [-9.133, -9.244, -9.413, -9.302, -9.192, -9.732, -9.301]
Step 425 0 visits [99.0, 72.0, 32.0, 49.0, 110.0, 10.0, 53.0]  episode_count: 634 q_vals: [-9.153, -9.244, -9.413, -9.302, -9.192, -9.732, -9.301]
{"total_number_of_episodes": 637, "number_of_timesteps": 13483, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1428571428571459},
Step 426 0 visits [100.0, 72.0, 32.0, 49.0, 110.0, 10.0, 53.0]  episode_count: 637 q_vals: [-9.172, -9.244, -9.413, -9.302, -9.192, -9.732, -9.301]
Step 427 0 visits [101.0, 72.0, 32.0, 49.0, 110.0, 10.0, 53.0]  episode_count: 640 q_vals: [-9.191, -9.244, -9.413, -9.302, -9.192, -9.732, -9.301]
Step 428 0 visits [102.0, 72.0, 32.0, 49.0, 110.0, 10.0, 53.0]  episode_count: 642 q_vals: [-9.21, -9.244, -9.413, -9.302, -9.192, -9.732, -9.301]
Step 429 3 visits [102.0, 72.0, 32.0, 50.0, 110.0, 10.0, 53.0]  episode_count: 643 q_vals: [-9.21, -9.244, -9.413, -9.338, -9.192, -9.732, -9.301]
Step 430 1 visits [102.0, 73.0, 32.0, 50.0, 110.0, 10.0, 53.0]  episode_count: 644 q_vals: [-9.21, -9.269, -9.413, -9.338, -9.192, -9.732, -9.301]
{"total_number_of_episodes": 647, "number_of_timesteps": 13682, "per_episode_reward": 17.79, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.2142857142857153},
Step 431 5 visits [102.0, 73.0, 32.0, 50.0, 110.0, 11.0, 53.0]  episode_count: 647 q_vals: [-9.21, -9.269, -9.413, -9.338, -9.192, -9.858, -9.301]
Step 432 4 visits [102.0, 73.0, 32.0, 50.0, 111.0, 11.0, 53.0]  episode_count: 649 q_vals: [-9.21, -9.269, -9.413, -9.338, -9.209, -9.858, -9.301]
Step 433 6 visits [102.0, 73.0, 32.0, 50.0, 111.0, 11.0, 54.0]  episode_count: 649 q_vals: [-9.21, -9.269, -9.413, -9.338, -9.209, -9.858, -9.335]
Step 434 0 visits [103.0, 73.0, 32.0, 50.0, 111.0, 11.0, 54.0]  episode_count: 652 q_vals: [-9.229, -9.269, -9.413, -9.338, -9.209, -9.858, -9.335]
Step 435 4 visits [103.0, 73.0, 32.0, 50.0, 112.0, 11.0, 54.0]  episode_count: 655 q_vals: [-9.229, -9.269, -9.413, -9.338, -9.226, -9.858, -9.335]
Step 436 2 visits [103.0, 73.0, 33.0, 50.0, 112.0, 11.0, 54.0]  episode_count: 655 q_vals: [-9.229, -9.269, -9.128, -9.338, -9.226, -9.858, -9.335]
{"total_number_of_episodes": 658, "number_of_timesteps": 13877, "per_episode_reward": 17.79, "episode_reward_trend_value": -0.003174603174603203, "biggest_recent_change": 0.2142857142857153},
Step 437 2 visits [103.0, 73.0, 34.0, 50.0, 112.0, 11.0, 54.0]  episode_count: 658 q_vals: [-9.229, -9.269, -9.186, -9.338, -9.226, -9.858, -9.335]
Step 438 2 visits [103.0, 73.0, 35.0, 50.0, 112.0, 11.0, 54.0]  episode_count: 660 q_vals: [-9.229, -9.269, -9.241, -9.338, -9.226, -9.858, -9.335]
Step 439 2 visits [103.0, 73.0, 36.0, 50.0, 112.0, 11.0, 54.0]  episode_count: 661 q_vals: [-9.229, -9.269, -9.293, -9.338, -9.226, -9.858, -9.335]
Step 440 2 visits [103.0, 73.0, 37.0, 50.0, 112.0, 11.0, 54.0]  episode_count: 664 q_vals: [-9.229, -9.269, -9.342, -9.338, -9.226, -9.858, -9.335]
Step 441 2 visits [103.0, 73.0, 38.0, 50.0, 112.0, 11.0, 54.0]  episode_count: 665 q_vals: [-9.229, -9.269, -9.389, -9.338, -9.226, -9.858, -9.335]
Step 442 1 visits [103.0, 74.0, 38.0, 50.0, 112.0, 11.0, 54.0]  episode_count: 667 q_vals: [-9.229, -9.294, -9.389, -9.338, -9.226, -9.858, -9.335]
{"total_number_of_episodes": 668, "number_of_timesteps": 14029, "per_episode_reward": 17.71, "episode_reward_trend_value": -0.0023809523809523525, "biggest_recent_change": 0.2142857142857153},
Step 443 0 visits [104.0, 74.0, 38.0, 50.0, 112.0, 11.0, 54.0]  episode_count: 668 q_vals: [-9.247, -9.294, -9.389, -9.338, -9.226, -9.858, -9.335]
Step 444 2 visits [104.0, 74.0, 39.0, 50.0, 112.0, 11.0, 54.0]  episode_count: 670 q_vals: [-9.247, -9.294, -9.433, -9.338, -9.226, -9.858, -9.335]
Step 445 3 visits [104.0, 74.0, 39.0, 51.0, 112.0, 11.0, 54.0]  episode_count: 673 q_vals: [-9.247, -9.294, -9.433, -9.373, -9.226, -9.858, -9.335]
Step 446 4 visits [104.0, 74.0, 39.0, 51.0, 113.0, 11.0, 54.0]  episode_count: 674 q_vals: [-9.247, -9.294, -9.433, -9.373, -9.243, -9.858, -9.335]
Step 447 6 visits [104.0, 74.0, 39.0, 51.0, 113.0, 11.0, 55.0]  episode_count: 676 q_vals: [-9.247, -9.294, -9.433, -9.373, -9.243, -9.858, -9.367]
Step 448 0 visits [105.0, 74.0, 39.0, 51.0, 113.0, 11.0, 55.0]  episode_count: 676 q_vals: [-9.265, -9.294, -9.433, -9.373, -9.243, -9.858, -9.367]
Step 449 1 visits [105.0, 75.0, 39.0, 51.0, 113.0, 11.0, 55.0]  episode_count: 677 q_vals: [-9.265, -9.318, -9.433, -9.373, -9.243, -9.858, -9.367]
{"total_number_of_episodes": 678, "number_of_timesteps": 14237, "per_episode_reward": 17.79, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 450 4 visits [105.0, 75.0, 39.0, 51.0, 114.0, 11.0, 55.0]  episode_count: 678 q_vals: [-9.265, -9.318, -9.433, -9.373, -9.162, -9.858, -9.367]
Step 451 4 visits [105.0, 75.0, 39.0, 51.0, 115.0, 11.0, 55.0]  episode_count: 679 q_vals: [-9.265, -9.318, -9.433, -9.373, -9.179, -9.858, -9.367]
Step 452 4 visits [105.0, 75.0, 39.0, 51.0, 116.0, 11.0, 55.0]  episode_count: 682 q_vals: [-9.265, -9.318, -9.433, -9.373, -9.196, -9.858, -9.367]
Step 453 4 visits [105.0, 75.0, 39.0, 51.0, 117.0, 11.0, 55.0]  episode_count: 685 q_vals: [-9.265, -9.318, -9.433, -9.373, -9.212, -9.858, -9.367]
Step 454 4 visits [105.0, 75.0, 39.0, 51.0, 118.0, 11.0, 55.0]  episode_count: 685 q_vals: [-9.265, -9.318, -9.433, -9.373, -9.228, -9.858, -9.367]
Step 455 4 visits [105.0, 75.0, 39.0, 51.0, 119.0, 11.0, 55.0]  episode_count: 687 q_vals: [-9.265, -9.318, -9.433, -9.373, -9.244, -9.858, -9.367]
{"total_number_of_episodes": 691, "number_of_timesteps": 14493, "per_episode_reward": 17.79, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.2142857142857153},
Step 456 4 visits [105.0, 75.0, 39.0, 51.0, 120.0, 11.0, 55.0]  episode_count: 691 q_vals: [-9.265, -9.318, -9.433, -9.373, -9.259, -9.858, -9.367]
Step 457 0 visits [106.0, 75.0, 39.0, 51.0, 120.0, 11.0, 55.0]  episode_count: 691 q_vals: [-9.282, -9.318, -9.433, -9.373, -9.259, -9.858, -9.367]
Step 458 3 visits [106.0, 75.0, 39.0, 52.0, 120.0, 11.0, 55.0]  episode_count: 693 q_vals: [-9.282, -9.318, -9.433, -9.406, -9.259, -9.858, -9.367]
Step 459 1 visits [106.0, 76.0, 39.0, 52.0, 120.0, 11.0, 55.0]  episode_count: 694 q_vals: [-9.282, -9.342, -9.433, -9.406, -9.259, -9.858, -9.367]
Step 460 6 visits [106.0, 76.0, 39.0, 52.0, 120.0, 11.0, 56.0]  episode_count: 695 q_vals: [-9.282, -9.342, -9.433, -9.406, -9.259, -9.858, -9.398]
Step 461 4 visits [106.0, 76.0, 39.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 696 q_vals: [-9.282, -9.342, -9.433, -9.406, -9.275, -9.858, -9.398]
Step 462 2 visits [106.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 698 q_vals: [-9.282, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
{"total_number_of_episodes": 701, "number_of_timesteps": 14679, "per_episode_reward": 17.79, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 463 0 visits [107.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 701 q_vals: [-9.195, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 464 0 visits [108.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 702 q_vals: [-9.213, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 465 0 visits [109.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 703 q_vals: [-9.23, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 466 0 visits [110.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 704 q_vals: [-9.247, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 467 0 visits [111.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 707 q_vals: [-9.264, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 468 0 visits [112.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 709 q_vals: [-9.182, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 469 0 visits [113.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 709 q_vals: [-9.199, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
{"total_number_of_episodes": 711, "number_of_timesteps": 14918, "per_episode_reward": 17.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.2142857142857153},
Step 470 0 visits [114.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 711 q_vals: [-9.215, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 471 0 visits [115.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 712 q_vals: [-9.232, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 472 0 visits [116.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 714 q_vals: [-9.248, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 473 0 visits [117.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 715 q_vals: [-9.169, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 474 0 visits [118.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 717 q_vals: [-9.185, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 475 0 visits [119.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 719 q_vals: [-9.202, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
{"total_number_of_episodes": 721, "number_of_timesteps": 15130, "per_episode_reward": 17.86, "episode_reward_trend_value": -0.0007936507936507711, "biggest_recent_change": 0.2142857142857153},
Step 476 0 visits [120.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 721 q_vals: [-9.125, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 477 0 visits [121.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 721 q_vals: [-9.141, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 478 0 visits [122.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 721 q_vals: [-9.158, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 479 0 visits [123.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 722 q_vals: [-9.173, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 480 0 visits [124.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 723 q_vals: [-9.189, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 481 0 visits [125.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 724 q_vals: [-9.204, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 482 0 visits [126.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 726 q_vals: [-9.22, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 483 0 visits [127.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 726 q_vals: [-9.234, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 484 0 visits [128.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 728 q_vals: [-9.249, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 485 0 visits [129.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 729 q_vals: [-9.177, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
{"total_number_of_episodes": 731, "number_of_timesteps": 15405, "per_episode_reward": 17.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 486 0 visits [130.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 731 q_vals: [-9.192, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 487 0 visits [131.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 731 q_vals: [-9.207, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 488 0 visits [132.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 734 q_vals: [-9.221, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 489 0 visits [133.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 735 q_vals: [-9.236, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 490 0 visits [134.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 735 q_vals: [-9.25, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 491 0 visits [135.0, 76.0, 40.0, 52.0, 121.0, 11.0, 56.0]  episode_count: 736 q_vals: [-9.263, -9.342, -9.475, -9.406, -9.275, -9.858, -9.398]
Step 492 4 visits [135.0, 76.0, 40.0, 52.0, 122.0, 11.0, 56.0]  episode_count: 738 q_vals: [-9.263, -9.342, -9.475, -9.406, -9.29, -9.858, -9.398]
{"total_number_of_episodes": 741, "number_of_timesteps": 15686, "per_episode_reward": 17.86, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 493 0 visits [136.0, 76.0, 40.0, 52.0, 122.0, 11.0, 56.0]  episode_count: 741 q_vals: [-9.277, -9.342, -9.475, -9.406, -9.29, -9.858, -9.398]
Step 494 1 visits [136.0, 77.0, 40.0, 52.0, 122.0, 11.0, 56.0]  episode_count: 741 q_vals: [-9.277, -9.365, -9.475, -9.406, -9.29, -9.858, -9.398]
Step 495 3 visits [136.0, 77.0, 40.0, 53.0, 122.0, 11.0, 56.0]  episode_count: 742 q_vals: [-9.277, -9.365, -9.475, -9.439, -9.29, -9.858, -9.398]
Step 496 0 visits [137.0, 77.0, 40.0, 53.0, 122.0, 11.0, 56.0]  episode_count: 743 q_vals: [-9.29, -9.365, -9.475, -9.439, -9.29, -9.858, -9.398]
Step 497 4 visits [137.0, 77.0, 40.0, 53.0, 123.0, 11.0, 56.0]  episode_count: 746 q_vals: [-9.29, -9.365, -9.475, -9.439, -9.305, -9.858, -9.398]
Step 498 6 visits [137.0, 77.0, 40.0, 53.0, 123.0, 11.0, 57.0]  episode_count: 746 q_vals: [-9.29, -9.365, -9.475, -9.439, -9.305, -9.858, -9.428]
Step 499 0 visits [138.0, 77.0, 40.0, 53.0, 123.0, 11.0, 57.0]  episode_count: 748 q_vals: [-9.304, -9.365, -9.475, -9.439, -9.305, -9.858, -9.428]
Step 500 4 visits [138.0, 77.0, 40.0, 53.0, 124.0, 11.0, 57.0]  episode_count: 750 q_vals: [-9.304, -9.365, -9.475, -9.439, -9.319, -9.858, -9.428]
Step 501 2 visits [138.0, 77.0, 41.0, 53.0, 124.0, 11.0, 57.0]  episode_count: 750 q_vals: [-9.304, -9.365, -9.515, -9.439, -9.319, -9.858, -9.428]
{"total_number_of_episodes": 754, "number_of_timesteps": 15975, "per_episode_reward": 17.86, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 502 1 visits [138.0, 78.0, 41.0, 53.0, 124.0, 11.0, 57.0]  episode_count: 754 q_vals: [-9.304, -9.387, -9.515, -9.439, -9.319, -9.858, -9.428]
Step 503 0 visits [139.0, 78.0, 41.0, 53.0, 124.0, 11.0, 57.0]  episode_count: 755 q_vals: [-9.237, -9.387, -9.515, -9.439, -9.319, -9.858, -9.428]
Step 504 0 visits [140.0, 78.0, 41.0, 53.0, 124.0, 11.0, 57.0]  episode_count: 756 q_vals: [-9.25, -9.387, -9.515, -9.439, -9.319, -9.858, -9.428]
Step 505 0 visits [141.0, 78.0, 41.0, 53.0, 124.0, 11.0, 57.0]  episode_count: 757 q_vals: [-9.263, -9.387, -9.515, -9.439, -9.319, -9.858, -9.428]
Step 506 0 visits [142.0, 78.0, 41.0, 53.0, 124.0, 11.0, 57.0]  episode_count: 759 q_vals: [-9.276, -9.387, -9.515, -9.439, -9.319, -9.858, -9.428]
Step 507 0 visits [143.0, 78.0, 41.0, 53.0, 124.0, 11.0, 57.0]  episode_count: 761 q_vals: [-9.289, -9.387, -9.515, -9.439, -9.319, -9.858, -9.428]
Step 508 0 visits [144.0, 78.0, 41.0, 53.0, 124.0, 11.0, 57.0]  episode_count: 761 q_vals: [-9.302, -9.387, -9.515, -9.439, -9.319, -9.858, -9.428]
Step 509 0 visits [145.0, 78.0, 41.0, 53.0, 124.0, 11.0, 57.0]  episode_count: 762 q_vals: [-9.314, -9.387, -9.515, -9.439, -9.319, -9.858, -9.428]
{"total_number_of_episodes": 766, "number_of_timesteps": 16199, "per_episode_reward": 17.86, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
Step 510 4 visits [145.0, 78.0, 41.0, 53.0, 125.0, 11.0, 57.0]  episode_count: 766 q_vals: [-9.314, -9.387, -9.515, -9.439, -9.333, -9.858, -9.428]
Step 511 3 visits [145.0, 78.0, 41.0, 54.0, 125.0, 11.0, 57.0]  episode_count: 767 q_vals: [-9.314, -9.387, -9.515, -9.47, -9.333, -9.858, -9.428]
Step 512 6 visits [145.0, 78.0, 41.0, 54.0, 125.0, 11.0, 58.0]  episode_count: 769 q_vals: [-9.314, -9.387, -9.515, -9.47, -9.333, -9.858, -9.457]
Step 513 5 visits [145.0, 78.0, 41.0, 54.0, 125.0, 12.0, 58.0]  episode_count: 770 q_vals: [-9.314, -9.387, -9.515, -9.47, -9.333, -9.962, -9.457]
Step 514 1 visits [145.0, 79.0, 41.0, 54.0, 125.0, 12.0, 58.0]  episode_count: 771 q_vals: [-9.314, -9.409, -9.515, -9.47, -9.333, -9.962, -9.457]
Step 515 0 visits [146.0, 79.0, 41.0, 54.0, 125.0, 12.0, 58.0]  episode_count: 774 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.333, -9.962, -9.457]
Step 516 4 visits [146.0, 79.0, 41.0, 54.0, 126.0, 12.0, 58.0]  episode_count: 775 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.259, -9.962, -9.457]
{"total_number_of_episodes": 776, "number_of_timesteps": 16410, "per_episode_reward": 17.86, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 517 4 visits [146.0, 79.0, 41.0, 54.0, 127.0, 12.0, 58.0]  episode_count: 776 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.186, -9.962, -9.457]
Step 518 4 visits [146.0, 79.0, 41.0, 54.0, 128.0, 12.0, 58.0]  episode_count: 779 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.2, -9.962, -9.457]
Step 519 4 visits [146.0, 79.0, 41.0, 54.0, 129.0, 12.0, 58.0]  episode_count: 779 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.215, -9.962, -9.457]
Step 520 4 visits [146.0, 79.0, 41.0, 54.0, 130.0, 12.0, 58.0]  episode_count: 782 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.23, -9.962, -9.457]
{"total_number_of_episodes": 786, "number_of_timesteps": 16603, "per_episode_reward": 17.93, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
Step 521 4 visits [146.0, 79.0, 41.0, 54.0, 131.0, 12.0, 58.0]  episode_count: 786 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.244, -9.962, -9.457]
Step 522 4 visits [146.0, 79.0, 41.0, 54.0, 132.0, 12.0, 58.0]  episode_count: 786 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.258, -9.962, -9.457]
Step 523 4 visits [146.0, 79.0, 41.0, 54.0, 133.0, 12.0, 58.0]  episode_count: 791 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.272, -9.962, -9.457]
Step 524 4 visits [146.0, 79.0, 41.0, 54.0, 134.0, 12.0, 58.0]  episode_count: 793 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.286, -9.962, -9.457]
Step 525 4 visits [146.0, 79.0, 41.0, 54.0, 135.0, 12.0, 58.0]  episode_count: 793 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.299, -9.962, -9.457]
{"total_number_of_episodes": 796, "number_of_timesteps": 16723, "per_episode_reward": 17.57, "episode_reward_trend_value": -0.0023809523809523525, "biggest_recent_change": 0.3571428571428541},
Step 526 4 visits [146.0, 79.0, 41.0, 54.0, 136.0, 12.0, 58.0]  episode_count: 796 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.231, -9.962, -9.457]
Step 527 4 visits [146.0, 79.0, 41.0, 54.0, 137.0, 12.0, 58.0]  episode_count: 797 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.245, -9.962, -9.457]
Step 528 4 visits [146.0, 79.0, 41.0, 54.0, 138.0, 12.0, 58.0]  episode_count: 799 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.258, -9.962, -9.457]
Step 529 4 visits [146.0, 79.0, 41.0, 54.0, 139.0, 12.0, 58.0]  episode_count: 800 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.271, -9.962, -9.457]
Step 530 4 visits [146.0, 79.0, 41.0, 54.0, 140.0, 12.0, 58.0]  episode_count: 803 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.284, -9.962, -9.457]
[-9.326, -9.409, -9.515, -9.47, -9.297, -9.962, -9.457]
{"total_number_of_episodes": 806, "number_of_timesteps": 16909, "per_episode_reward": 17.5, "episode_reward_trend_value": -0.003968253968253973, "biggest_recent_change": 0.3571428571428541},
Step 532 4 visits [146.0, 79.0, 41.0, 54.0, 142.0, 12.0, 58.0]  episode_count: 806 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.308, -9.962, -9.457]
Step 533 4 visits [146.0, 79.0, 41.0, 54.0, 143.0, 12.0, 58.0]  episode_count: 807 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.321, -9.962, -9.457]
Step 534 4 visits [146.0, 79.0, 41.0, 54.0, 144.0, 12.0, 58.0]  episode_count: 810 q_vals: [-9.326, -9.409, -9.515, -9.47, -9.334, -9.962, -9.457]
Step 535 0 visits [147.0, 79.0, 41.0, 54.0, 144.0, 12.0, 58.0]  episode_count: 811 q_vals: [-9.339, -9.409, -9.515, -9.47, -9.334, -9.962, -9.457]
Step 536 2 visits [147.0, 79.0, 42.0, 54.0, 144.0, 12.0, 58.0]  episode_count: 812 q_vals: [-9.339, -9.409, -9.548, -9.47, -9.334, -9.962, -9.457]
Step 537 4 visits [147.0, 79.0, 42.0, 54.0, 145.0, 12.0, 58.0]  episode_count: 814 q_vals: [-9.339, -9.409, -9.548, -9.47, -9.346, -9.962, -9.457]
{"total_number_of_episodes": 816, "number_of_timesteps": 17101, "per_episode_reward": 17.57, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.3571428571428541},
Step 538 1 visits [147.0, 80.0, 42.0, 54.0, 145.0, 12.0, 58.0]  episode_count: 816 q_vals: [-9.339, -9.43, -9.548, -9.47, -9.346, -9.962, -9.457]
Step 539 6 visits [147.0, 80.0, 42.0, 54.0, 145.0, 12.0, 59.0]  episode_count: 817 q_vals: [-9.339, -9.43, -9.548, -9.47, -9.346, -9.962, -9.485]
Step 540 3 visits [147.0, 80.0, 42.0, 55.0, 145.0, 12.0, 59.0]  episode_count: 821 q_vals: [-9.339, -9.43, -9.548, -9.297, -9.346, -9.962, -9.485]
Step 541 3 visits [147.0, 80.0, 42.0, 56.0, 145.0, 12.0, 59.0]  episode_count: 822 q_vals: [-9.339, -9.43, -9.548, -9.33, -9.346, -9.962, -9.485]
Step 542 3 visits [147.0, 80.0, 42.0, 57.0, 145.0, 12.0, 59.0]  episode_count: 824 q_vals: [-9.339, -9.43, -9.548, -9.361, -9.346, -9.962, -9.485]
{"total_number_of_episodes": 826, "number_of_timesteps": 17267, "per_episode_reward": 17.5, "episode_reward_trend_value": -0.003968253968253973, "biggest_recent_change": 0.3571428571428541},
Step 543 3 visits [147.0, 80.0, 42.0, 58.0, 145.0, 12.0, 59.0]  episode_count: 826 q_vals: [-9.339, -9.43, -9.548, -9.391, -9.346, -9.962, -9.485]
Step 544 3 visits [147.0, 80.0, 42.0, 59.0, 145.0, 12.0, 59.0]  episode_count: 826 q_vals: [-9.339, -9.43, -9.548, -9.416, -9.346, -9.962, -9.485]
Step 545 3 visits [147.0, 80.0, 42.0, 60.0, 145.0, 12.0, 59.0]  episode_count: 827 q_vals: [-9.339, -9.43, -9.548, -9.445, -9.346, -9.962, -9.485]
Step 546 3 visits [147.0, 80.0, 42.0, 61.0, 145.0, 12.0, 59.0]  episode_count: 829 q_vals: [-9.339, -9.43, -9.548, -9.472, -9.346, -9.962, -9.485]
Step 547 0 visits [148.0, 80.0, 42.0, 61.0, 145.0, 12.0, 59.0]  episode_count: 831 q_vals: [-9.35, -9.43, -9.548, -9.472, -9.346, -9.962, -9.485]
Step 548 4 visits [148.0, 80.0, 42.0, 61.0, 146.0, 12.0, 59.0]  episode_count: 832 q_vals: [-9.35, -9.43, -9.548, -9.472, -9.358, -9.962, -9.485]
Step 549 0 visits [149.0, 80.0, 42.0, 61.0, 146.0, 12.0, 59.0]  episode_count: 832 q_vals: [-9.362, -9.43, -9.548, -9.472, -9.358, -9.962, -9.485]
Step 550 1 visits [149.0, 81.0, 42.0, 61.0, 146.0, 12.0, 59.0]  episode_count: 833 q_vals: [-9.362, -9.451, -9.548, -9.472, -9.358, -9.962, -9.485]
{"total_number_of_episodes": 837, "number_of_timesteps": 17507, "per_episode_reward": 17.43, "episode_reward_trend_value": -0.004761904761904785, "biggest_recent_change": 0.3571428571428541},
Step 551 4 visits [149.0, 81.0, 42.0, 61.0, 147.0, 12.0, 59.0]  episode_count: 837 q_vals: [-9.362, -9.451, -9.548, -9.472, -9.37, -9.962, -9.485]
Step 552 3 visits [149.0, 81.0, 42.0, 62.0, 147.0, 12.0, 59.0]  episode_count: 838 q_vals: [-9.362, -9.451, -9.548, -9.498, -9.37, -9.962, -9.485]
Step 553 0 visits [150.0, 81.0, 42.0, 62.0, 147.0, 12.0, 59.0]  episode_count: 838 q_vals: [-9.373, -9.451, -9.548, -9.498, -9.37, -9.962, -9.485]
Step 554 6 visits [150.0, 81.0, 42.0, 62.0, 147.0, 12.0, 60.0]  episode_count: 842 q_vals: [-9.373, -9.451, -9.548, -9.498, -9.37, -9.962, -9.512]
Step 555 2 visits [150.0, 81.0, 43.0, 62.0, 147.0, 12.0, 60.0]  episode_count: 845 q_vals: [-9.373, -9.451, -9.574, -9.498, -9.37, -9.962, -9.512]
Step 556 4 visits [150.0, 81.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 846 q_vals: [-9.373, -9.451, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 557 0 visits [151.0, 81.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 846 q_vals: [-9.385, -9.451, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 847, "number_of_timesteps": 17711, "per_episode_reward": 17.43, "episode_reward_trend_value": -0.004761904761904785, "biggest_recent_change": 0.3571428571428541},
Step 558 1 visits [151.0, 82.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 847 q_vals: [-9.385, -9.336, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 559 1 visits [151.0, 83.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 850 q_vals: [-9.385, -9.357, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 560 1 visits [151.0, 84.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 853 q_vals: [-9.385, -9.378, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 561 1 visits [151.0, 85.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 853 q_vals: [-9.385, -9.399, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 562 1 visits [151.0, 86.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 854 q_vals: [-9.385, -9.419, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 857, "number_of_timesteps": 17896, "per_episode_reward": 17.36, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.3571428571428541},
Step 563 1 visits [151.0, 87.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 857 q_vals: [-9.385, -9.438, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 564 1 visits [151.0, 88.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 858 q_vals: [-9.385, -9.331, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 565 1 visits [151.0, 89.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 858 q_vals: [-9.385, -9.349, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 566 1 visits [151.0, 90.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 859 q_vals: [-9.385, -9.368, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 567 1 visits [151.0, 91.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 861 q_vals: [-9.385, -9.265, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 568 1 visits [151.0, 92.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 862 q_vals: [-9.385, -9.285, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 569 1 visits [151.0, 93.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 863 q_vals: [-9.385, -9.299, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 570 1 visits [151.0, 94.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 865 q_vals: [-9.385, -9.314, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 867, "number_of_timesteps": 18148, "per_episode_reward": 17.57, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.3571428571428541},
Step 571 1 visits [151.0, 95.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 867 q_vals: [-9.385, -9.216, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 572 1 visits [151.0, 96.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 867 q_vals: [-9.385, -9.236, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 573 1 visits [151.0, 97.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 870 q_vals: [-9.385, -9.249, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 574 1 visits [151.0, 98.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 872 q_vals: [-9.385, -9.268, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 575 1 visits [151.0, 99.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 873 q_vals: [-9.385, -9.174, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 576 1 visits [151.0, 100.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 874 q_vals: [-9.385, -9.193, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 577 1 visits [151.0, 101.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 874 q_vals: [-9.385, -9.102, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 578 1 visits [151.0, 102.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 876 q_vals: [-9.385, -9.122, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 878, "number_of_timesteps": 18400, "per_episode_reward": 17.64, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.3571428571428541},
Step 579 1 visits [151.0, 103.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 878 q_vals: [-9.385, -9.033, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 580 1 visits [151.0, 104.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 878 q_vals: [-9.385, -8.947, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 581 1 visits [151.0, 105.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 882 q_vals: [-9.385, -8.967, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 582 1 visits [151.0, 106.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 883 q_vals: [-9.385, -8.883, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 583 1 visits [151.0, 107.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 883 q_vals: [-9.385, -8.903, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 888, "number_of_timesteps": 18586, "per_episode_reward": 17.79, "episode_reward_trend_value": 0.0023809523809523525, "biggest_recent_change": 0.2142857142857153},
Step 584 1 visits [151.0, 108.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 888 q_vals: [-9.385, -8.924, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 585 1 visits [151.0, 109.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 889 q_vals: [-9.385, -8.944, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 586 1 visits [151.0, 110.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 889 q_vals: [-9.385, -8.964, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 587 1 visits [151.0, 111.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 891 q_vals: [-9.385, -8.983, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 588 1 visits [151.0, 112.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 894 q_vals: [-9.385, -9.002, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 589 1 visits [151.0, 113.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 894 q_vals: [-9.385, -9.021, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 898, "number_of_timesteps": 18787, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.2142857142857153},
Step 590 1 visits [151.0, 114.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 898 q_vals: [-9.385, -9.039, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 591 1 visits [151.0, 115.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 898 q_vals: [-9.385, -9.047, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 592 1 visits [151.0, 116.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 900 q_vals: [-9.385, -9.065, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 593 1 visits [151.0, 117.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 902 q_vals: [-9.385, -9.076, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 594 1 visits [151.0, 118.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 904 q_vals: [-9.385, -9.088, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 595 1 visits [151.0, 119.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 905 q_vals: [-9.385, -9.105, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 596 1 visits [151.0, 120.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 907 q_vals: [-9.385, -9.122, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 910, "number_of_timesteps": 19003, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 597 1 visits [151.0, 121.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 910 q_vals: [-9.385, -9.138, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 598 1 visits [151.0, 122.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 910 q_vals: [-9.385, -9.152, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 599 1 visits [151.0, 123.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 911 q_vals: [-9.385, -9.168, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 600 1 visits [151.0, 124.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 914 q_vals: [-9.385, -9.184, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 601 1 visits [151.0, 125.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 917 q_vals: [-9.385, -9.193, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 602 1 visits [151.0, 126.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 919 q_vals: [-9.385, -9.208, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 922, "number_of_timesteps": 19198, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.2142857142857153},
Step 603 1 visits [151.0, 127.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 922 q_vals: [-9.385, -9.223, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 604 1 visits [151.0, 128.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 924 q_vals: [-9.385, -9.236, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 605 1 visits [151.0, 129.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 926 q_vals: [-9.385, -9.25, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 606 1 visits [151.0, 130.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 927 q_vals: [-9.385, -9.179, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 607 1 visits [151.0, 131.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 930 q_vals: [-9.385, -9.194, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 932, "number_of_timesteps": 19326, "per_episode_reward": 17.64, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.2142857142857153},
Step 608 1 visits [151.0, 132.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 932 q_vals: [-9.385, -9.208, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 609 1 visits [151.0, 133.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 933 q_vals: [-9.385, -9.139, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 610 1 visits [151.0, 134.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 934 q_vals: [-9.385, -9.154, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 611 1 visits [151.0, 135.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 937 q_vals: [-9.385, -9.168, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 612 1 visits [151.0, 136.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 938 q_vals: [-9.385, -9.182, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 613 1 visits [151.0, 137.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 939 q_vals: [-9.385, -9.197, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 943, "number_of_timesteps": 19543, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.2142857142857153},
Step 614 1 visits [151.0, 138.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 943 q_vals: [-9.385, -9.13, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 615 1 visits [151.0, 139.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 943 q_vals: [-9.385, -9.14, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 616 1 visits [151.0, 140.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 943 q_vals: [-9.385, -9.154, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 617 1 visits [151.0, 141.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 945 q_vals: [-9.385, -9.168, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 618 1 visits [151.0, 142.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 945 q_vals: [-9.385, -9.182, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 619 1 visits [151.0, 143.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 946 q_vals: [-9.385, -9.195, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 620 1 visits [151.0, 144.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 948 q_vals: [-9.385, -9.208, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 621 1 visits [151.0, 145.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 948 q_vals: [-9.385, -9.221, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 622 1 visits [151.0, 146.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 949 q_vals: [-9.385, -9.158, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 623 1 visits [151.0, 147.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 950 q_vals: [-9.385, -9.167, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 953, "number_of_timesteps": 19829, "per_episode_reward": 17.64, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.2142857142857153},
Step 624 1 visits [151.0, 148.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 953 q_vals: [-9.385, -9.18, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 625 1 visits [151.0, 149.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 954 q_vals: [-9.385, -9.184, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 626 1 visits [151.0, 150.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 954 q_vals: [-9.385, -9.197, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 627 1 visits [151.0, 151.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 956 q_vals: [-9.385, -9.21, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 628 1 visits [151.0, 152.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 960 q_vals: [-9.385, -9.22, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 629 1 visits [151.0, 153.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 960 q_vals: [-9.385, -9.233, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 963, "number_of_timesteps": 20026, "per_episode_reward": 17.5, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.14285714285714235},
Step 630 1 visits [151.0, 154.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 963 q_vals: [-9.385, -9.173, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 631 1 visits [151.0, 155.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 965 q_vals: [-9.385, -9.185, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 632 1 visits [151.0, 156.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 966 q_vals: [-9.385, -9.197, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 633 1 visits [151.0, 157.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 969 q_vals: [-9.385, -9.21, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 634 1 visits [151.0, 158.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 970 q_vals: [-9.385, -9.222, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 635 1 visits [151.0, 159.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 972 q_vals: [-9.385, -9.234, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 974, "number_of_timesteps": 20225, "per_episode_reward": 17.57, "episode_reward_trend_value": -0.0007936507936507711, "biggest_recent_change": 0.14285714285714235},
Step 636 1 visits [151.0, 160.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 974 q_vals: [-9.385, -9.245, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 637 1 visits [151.0, 161.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 976 q_vals: [-9.385, -9.254, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 638 1 visits [151.0, 162.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 978 q_vals: [-9.385, -9.266, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 639 1 visits [151.0, 163.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 978 q_vals: [-9.385, -9.277, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 640 1 visits [151.0, 164.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 978 q_vals: [-9.385, -9.288, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 641 1 visits [151.0, 165.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 980 q_vals: [-9.385, -9.232, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 642 1 visits [151.0, 166.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 981 q_vals: [-9.385, -9.176, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 643 1 visits [151.0, 167.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 981 q_vals: [-9.385, -9.188, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 984, "number_of_timesteps": 20414, "per_episode_reward": 17.57, "episode_reward_trend_value": -0.0023809523809523525, "biggest_recent_change": 0.14285714285714235},
Step 644 1 visits [151.0, 168.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 984 q_vals: [-9.385, -9.133, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 645 1 visits [151.0, 169.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 985 q_vals: [-9.385, -9.079, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 646 1 visits [151.0, 170.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 985 q_vals: [-9.385, -9.026, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 647 1 visits [151.0, 171.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 988 q_vals: [-9.385, -9.031, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 648 1 visits [151.0, 172.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 990 q_vals: [-9.385, -9.043, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 649 1 visits [151.0, 173.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 990 q_vals: [-9.385, -8.991, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 650 1 visits [151.0, 174.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 990 q_vals: [-9.385, -9.003, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 651 1 visits [151.0, 175.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 992 q_vals: [-9.385, -9.009, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 996, "number_of_timesteps": 20753, "per_episode_reward": 17.5, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.14285714285714235},
Step 652 1 visits [151.0, 176.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 996 q_vals: [-9.385, -9.021, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 653 1 visits [151.0, 177.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 996 q_vals: [-9.385, -9.025, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 654 1 visits [151.0, 178.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 997 q_vals: [-9.385, -9.037, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 655 1 visits [151.0, 179.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 998 q_vals: [-9.385, -9.048, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 656 1 visits [151.0, 180.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1000 q_vals: [-9.385, -9.06, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 657 1 visits [151.0, 181.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1001 q_vals: [-9.385, -9.065, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 658 1 visits [151.0, 182.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1001 q_vals: [-9.385, -9.069, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 659 1 visits [151.0, 183.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1005 q_vals: [-9.385, -9.081, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 660 1 visits [151.0, 184.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1005 q_vals: [-9.385, -9.092, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1006, "number_of_timesteps": 20985, "per_episode_reward": 17.29, "episode_reward_trend_value": -0.004761904761904785, "biggest_recent_change": 0.2142857142857153},
Step 661 1 visits [151.0, 185.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1006 q_vals: [-9.385, -9.096, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 662 1 visits [151.0, 186.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1009 q_vals: [-9.385, -9.107, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 663 1 visits [151.0, 187.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1009 q_vals: [-9.385, -9.117, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 664 1 visits [151.0, 188.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1009 q_vals: [-9.385, -9.128, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 665 1 visits [151.0, 189.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1011 q_vals: [-9.385, -9.134, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 666 1 visits [151.0, 190.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1012 q_vals: [-9.385, -9.144, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 667 1 visits [151.0, 191.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1013 q_vals: [-9.385, -9.154, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 668 1 visits [151.0, 192.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1014 q_vals: [-9.385, -9.165, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1016, "number_of_timesteps": 21221, "per_episode_reward": 17.36, "episode_reward_trend_value": -0.003968253968253973, "biggest_recent_change": 0.2142857142857153},
Step 669 1 visits [151.0, 193.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1016 q_vals: [-9.385, -9.174, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 670 1 visits [151.0, 194.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1017 q_vals: [-9.385, -9.184, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 671 1 visits [151.0, 195.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1018 q_vals: [-9.385, -9.194, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 672 1 visits [151.0, 196.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1019 q_vals: [-9.385, -9.204, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 673 1 visits [151.0, 197.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1022 q_vals: [-9.385, -9.207, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 674 1 visits [151.0, 198.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1024 q_vals: [-9.385, -9.216, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 675 1 visits [151.0, 199.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1025 q_vals: [-9.385, -9.226, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1028, "number_of_timesteps": 21540, "per_episode_reward": 17.36, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.2142857142857153},
Step 676 1 visits [151.0, 200.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1028 q_vals: [-9.385, -9.235, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 677 1 visits [151.0, 201.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1029 q_vals: [-9.385, -9.238, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 678 1 visits [151.0, 202.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1032 q_vals: [-9.385, -9.192, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 679 1 visits [151.0, 203.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1034 q_vals: [-9.385, -9.147, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 680 1 visits [151.0, 204.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1036 q_vals: [-9.385, -9.157, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 681 1 visits [151.0, 205.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1036 q_vals: [-9.385, -9.166, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1040, "number_of_timesteps": 21735, "per_episode_reward": 17.36, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 682 1 visits [151.0, 206.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1040 q_vals: [-9.385, -9.176, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 683 1 visits [151.0, 207.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1041 q_vals: [-9.385, -9.183, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 684 1 visits [151.0, 208.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1041 q_vals: [-9.385, -9.186, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 685 1 visits [151.0, 209.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1043 q_vals: [-9.385, -9.142, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 686 1 visits [151.0, 210.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1046 q_vals: [-9.385, -9.152, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 687 1 visits [151.0, 211.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1046 q_vals: [-9.385, -9.161, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1050, "number_of_timesteps": 21914, "per_episode_reward": 17.43, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.2142857142857153},
Step 688 1 visits [151.0, 212.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1050 q_vals: [-9.385, -9.17, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 689 1 visits [151.0, 213.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1051 q_vals: [-9.385, -9.174, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 690 1 visits [151.0, 214.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1051 q_vals: [-9.385, -9.183, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 691 1 visits [151.0, 215.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1056 q_vals: [-9.385, -9.192, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 692 1 visits [151.0, 216.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1057 q_vals: [-9.385, -9.194, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 693 1 visits [151.0, 217.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1059 q_vals: [-9.385, -9.203, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1060, "number_of_timesteps": 22082, "per_episode_reward": 17.36, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 694 1 visits [151.0, 218.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1060 q_vals: [-9.385, -9.211, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 695 1 visits [151.0, 219.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1063 q_vals: [-9.385, -9.169, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 696 1 visits [151.0, 220.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1064 q_vals: [-9.385, -9.171, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 697 1 visits [151.0, 221.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1067 q_vals: [-9.385, -9.174, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1070, "number_of_timesteps": 22241, "per_episode_reward": 17.29, "episode_reward_trend_value": -0.003174603174603203, "biggest_recent_change": 0.2142857142857153},
Step 698 1 visits [151.0, 222.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1070 q_vals: [-9.385, -9.133, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 699 1 visits [151.0, 223.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1070 q_vals: [-9.385, -9.142, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 700 1 visits [151.0, 224.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1073 q_vals: [-9.385, -9.151, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 701 1 visits [151.0, 225.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1075 q_vals: [-9.385, -9.159, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 702 1 visits [151.0, 226.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1078 q_vals: [-9.385, -9.165, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 703 1 visits [151.0, 227.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1078 q_vals: [-9.385, -9.168, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1083, "number_of_timesteps": 22426, "per_episode_reward": 17.29, "episode_reward_trend_value": -0.003174603174603203, "biggest_recent_change": 0.2142857142857153},
Step 704 1 visits [151.0, 228.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1083 q_vals: [-9.385, -9.172, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 705 1 visits [151.0, 229.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1084 q_vals: [-9.385, -9.176, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 706 1 visits [151.0, 230.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1086 q_vals: [-9.385, -9.185, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 707 1 visits [151.0, 231.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1090 q_vals: [-9.385, -9.192, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 708 1 visits [151.0, 232.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1091 q_vals: [-9.385, -9.2, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 709 1 visits [151.0, 233.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1092 q_vals: [-9.385, -9.208, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1096, "number_of_timesteps": 22594, "per_episode_reward": 17.21, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.2142857142857153},
Step 710 1 visits [151.0, 234.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1096 q_vals: [-9.385, -9.209, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 711 1 visits [151.0, 235.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1099 q_vals: [-9.385, -9.215, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 712 1 visits [151.0, 236.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1100 q_vals: [-9.385, -9.175, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 713 1 visits [151.0, 237.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1105 q_vals: [-9.385, -9.182, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1107, "number_of_timesteps": 22731, "per_episode_reward": 17.14, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
Step 714 1 visits [151.0, 238.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1107 q_vals: [-9.385, -9.143, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 715 1 visits [151.0, 239.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1108 q_vals: [-9.385, -9.151, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 716 1 visits [151.0, 240.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1113 q_vals: [-9.385, -9.158, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 717 1 visits [151.0, 241.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1114 q_vals: [-9.385, -9.159, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 718 1 visits [151.0, 242.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1115 q_vals: [-9.385, -9.163, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1120, "number_of_timesteps": 22881, "per_episode_reward": 16.93, "episode_reward_trend_value": -0.004761904761904785, "biggest_recent_change": 0.2142857142857153},
Step 719 1 visits [151.0, 243.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1120 q_vals: [-9.385, -9.169, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 720 1 visits [151.0, 244.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1122 q_vals: [-9.385, -9.174, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 721 1 visits [151.0, 245.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1123 q_vals: [-9.385, -9.179, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 722 1 visits [151.0, 246.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1128 q_vals: [-9.385, -9.184, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1130, "number_of_timesteps": 22990, "per_episode_reward": 16.71, "episode_reward_trend_value": -0.0071428571428571366, "biggest_recent_change": 0.2142857142857153},
Step 723 1 visits [151.0, 247.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1130 q_vals: [-9.385, -9.185, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 724 1 visits [151.0, 248.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1131 q_vals: [-9.385, -9.148, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 725 1 visits [151.0, 249.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1137 q_vals: [-9.385, -9.112, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 726 1 visits [151.0, 250.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1137 q_vals: [-9.385, -9.12, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1140, "number_of_timesteps": 23099, "per_episode_reward": 16.57, "episode_reward_trend_value": -0.008730158730158718, "biggest_recent_change": 0.2142857142857153},
Step 727 1 visits [151.0, 251.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1140 q_vals: [-9.385, -9.128, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 728 1 visits [151.0, 252.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1142 q_vals: [-9.385, -9.135, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 729 1 visits [151.0, 253.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1144 q_vals: [-9.385, -9.099, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 730 1 visits [151.0, 254.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1145 q_vals: [-9.385, -9.105, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 731 1 visits [151.0, 255.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1148 q_vals: [-9.385, -9.113, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1150, "number_of_timesteps": 23252, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.0103174603174603, "biggest_recent_change": 0.2142857142857153},
Step 732 1 visits [151.0, 256.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1150 q_vals: [-9.385, -9.12, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 733 1 visits [151.0, 257.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1152 q_vals: [-9.385, -9.128, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 734 1 visits [151.0, 258.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1155 q_vals: [-9.385, -9.136, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 735 1 visits [151.0, 259.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1157 q_vals: [-9.385, -9.143, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 736 1 visits [151.0, 260.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1159 q_vals: [-9.385, -9.151, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1162, "number_of_timesteps": 23410, "per_episode_reward": 16.57, "episode_reward_trend_value": -0.008730158730158718, "biggest_recent_change": 0.2142857142857153},
Step 737 1 visits [151.0, 261.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1162 q_vals: [-9.385, -9.158, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 738 1 visits [151.0, 262.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1162 q_vals: [-9.385, -9.159, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 739 1 visits [151.0, 263.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1164 q_vals: [-9.385, -9.167, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 740 1 visits [151.0, 264.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1167 q_vals: [-9.385, -9.174, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 741 1 visits [151.0, 265.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1167 q_vals: [-9.385, -9.175, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 742 1 visits [151.0, 266.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1168 q_vals: [-9.385, -9.18, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 743 1 visits [151.0, 267.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1171 q_vals: [-9.385, -9.183, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 744 1 visits [151.0, 268.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1171 q_vals: [-9.385, -9.19, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1173, "number_of_timesteps": 23634, "per_episode_reward": 16.57, "episode_reward_trend_value": -0.007936507936507908, "biggest_recent_change": 0.2142857142857153},
Step 745 1 visits [151.0, 269.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1173 q_vals: [-9.385, -9.193, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 746 1 visits [151.0, 270.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1176 q_vals: [-9.385, -9.159, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 747 1 visits [151.0, 271.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1177 q_vals: [-9.385, -9.166, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 748 1 visits [151.0, 272.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1178 q_vals: [-9.385, -9.173, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 749 1 visits [151.0, 273.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1180 q_vals: [-9.385, -9.139, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 750 1 visits [151.0, 274.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1182 q_vals: [-9.385, -9.147, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1184, "number_of_timesteps": 23842, "per_episode_reward": 16.57, "episode_reward_trend_value": -0.007936507936507908, "biggest_recent_change": 0.2142857142857153},
Step 751 1 visits [151.0, 275.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1184 q_vals: [-9.385, -9.113, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 752 1 visits [151.0, 276.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1186 q_vals: [-9.385, -9.121, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 753 1 visits [151.0, 277.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1186 q_vals: [-9.385, -9.125, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 754 1 visits [151.0, 278.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1188 q_vals: [-9.385, -9.093, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 755 1 visits [151.0, 279.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1188 q_vals: [-9.385, -9.1, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 756 1 visits [151.0, 280.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1189 q_vals: [-9.385, -9.067, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 757 1 visits [151.0, 281.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1190 q_vals: [-9.385, -9.075, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1194, "number_of_timesteps": 24078, "per_episode_reward": 16.57, "episode_reward_trend_value": -0.0071428571428571366, "biggest_recent_change": 0.2142857142857153},
Step 758 1 visits [151.0, 282.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1194 q_vals: [-9.385, -9.082, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 759 1 visits [151.0, 283.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1196 q_vals: [-9.385, -9.087, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 760 1 visits [151.0, 284.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1196 q_vals: [-9.385, -9.094, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 761 1 visits [151.0, 285.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1200 q_vals: [-9.385, -9.095, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 762 1 visits [151.0, 286.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1201 q_vals: [-9.385, -9.096, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 763 1 visits [151.0, 287.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1203 q_vals: [-9.385, -9.099, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1205, "number_of_timesteps": 24260, "per_episode_reward": 16.57, "episode_reward_trend_value": -0.006349206349206327, "biggest_recent_change": 0.2142857142857153},
Step 764 1 visits [151.0, 288.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1205 q_vals: [-9.385, -9.068, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 765 1 visits [151.0, 289.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1206 q_vals: [-9.385, -9.069, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 766 1 visits [151.0, 290.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1207 q_vals: [-9.385, -9.076, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 767 1 visits [151.0, 291.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1207 q_vals: [-9.385, -9.044, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 768 1 visits [151.0, 292.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1208 q_vals: [-9.385, -9.048, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 769 1 visits [151.0, 293.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1211 q_vals: [-9.385, -9.055, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 770 1 visits [151.0, 294.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1213 q_vals: [-9.385, -9.062, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1216, "number_of_timesteps": 24478, "per_episode_reward": 16.64, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.21428571428571175},
Step 771 1 visits [151.0, 295.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1216 q_vals: [-9.385, -9.064, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 772 1 visits [151.0, 296.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1216 q_vals: [-9.385, -9.065, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 773 1 visits [151.0, 297.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1218 q_vals: [-9.385, -9.065, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 774 1 visits [151.0, 298.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1218 q_vals: [-9.385, -9.035, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 775 1 visits [151.0, 299.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1220 q_vals: [-9.385, -9.037, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 776 1 visits [151.0, 300.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1222 q_vals: [-9.385, -9.007, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 777 1 visits [151.0, 301.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1225 q_vals: [-9.385, -9.014, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1227, "number_of_timesteps": 24723, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 778 1 visits [151.0, 302.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1227 q_vals: [-9.385, -9.016, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 779 1 visits [151.0, 303.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1227 q_vals: [-9.385, -8.986, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 780 1 visits [151.0, 304.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1230 q_vals: [-9.385, -8.98, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 781 1 visits [151.0, 305.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1232 q_vals: [-9.385, -8.98, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 782 1 visits [151.0, 306.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1233 q_vals: [-9.385, -8.982, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 783 1 visits [151.0, 307.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1235 q_vals: [-9.385, -8.985, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1237, "number_of_timesteps": 24897, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
Step 784 1 visits [151.0, 308.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1237 q_vals: [-9.385, -8.956, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 785 1 visits [151.0, 309.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1238 q_vals: [-9.385, -8.956, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 786 1 visits [151.0, 310.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1239 q_vals: [-9.385, -8.963, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 787 1 visits [151.0, 311.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1240 q_vals: [-9.385, -8.934, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 788 1 visits [151.0, 312.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1243 q_vals: [-9.385, -8.936, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 789 1 visits [151.0, 313.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1244 q_vals: [-9.385, -8.942, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 790 1 visits [151.0, 314.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1244 q_vals: [-9.385, -8.913, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 791 1 visits [151.0, 315.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1245 q_vals: [-9.385, -8.92, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 792 1 visits [151.0, 316.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1246 q_vals: [-9.385, -8.892, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1250, "number_of_timesteps": 25172, "per_episode_reward": 16.79, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857295},
Step 793 1 visits [151.0, 317.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1250 q_vals: [-9.385, -8.899, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 794 1 visits [151.0, 318.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1251 q_vals: [-9.385, -8.902, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 795 1 visits [151.0, 319.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1252 q_vals: [-9.385, -8.902, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 796 1 visits [151.0, 320.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1256 q_vals: [-9.385, -8.903, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 797 1 visits [151.0, 321.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1258 q_vals: [-9.385, -8.905, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1260, "number_of_timesteps": 25345, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
Step 798 1 visits [151.0, 322.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1260 q_vals: [-9.385, -8.909, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 799 1 visits [151.0, 323.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1263 q_vals: [-9.385, -8.915, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 800 1 visits [151.0, 324.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1265 q_vals: [-9.385, -8.916, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 801 1 visits [151.0, 325.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1267 q_vals: [-9.385, -8.917, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 802 1 visits [151.0, 326.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1269 q_vals: [-9.385, -8.919, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1271, "number_of_timesteps": 25489, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 803 1 visits [151.0, 327.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1271 q_vals: [-9.385, -8.925, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 804 1 visits [151.0, 328.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1273 q_vals: [-9.385, -8.929, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 805 1 visits [151.0, 329.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1276 q_vals: [-9.385, -8.934, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 806 1 visits [151.0, 330.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1277 q_vals: [-9.385, -8.94, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 807 1 visits [151.0, 331.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1279 q_vals: [-9.385, -8.94, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 808 1 visits [151.0, 332.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1280 q_vals: [-9.385, -8.942, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1283, "number_of_timesteps": 25659, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 809 1 visits [151.0, 333.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1283 q_vals: [-9.385, -8.948, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 810 1 visits [151.0, 334.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1284 q_vals: [-9.385, -8.954, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 811 1 visits [151.0, 335.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1287 q_vals: [-9.385, -8.955, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 812 1 visits [151.0, 336.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1290 q_vals: [-9.385, -8.956, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 813 1 visits [151.0, 337.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1291 q_vals: [-9.385, -8.929, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1294, "number_of_timesteps": 25832, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 814 1 visits [151.0, 338.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1294 q_vals: [-9.385, -8.903, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 815 1 visits [151.0, 339.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1298 q_vals: [-9.385, -8.906, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 816 1 visits [151.0, 340.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1298 q_vals: [-9.385, -8.912, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 817 1 visits [151.0, 341.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1301 q_vals: [-9.385, -8.913, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1305, "number_of_timesteps": 25974, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.14285714285714235},
Step 818 1 visits [151.0, 342.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1305 q_vals: [-9.385, -8.887, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 819 1 visits [151.0, 343.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1306 q_vals: [-9.385, -8.892, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 820 1 visits [151.0, 344.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1306 q_vals: [-9.385, -8.892, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 821 1 visits [151.0, 345.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1310 q_vals: [-9.385, -8.897, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 822 1 visits [151.0, 346.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1313 q_vals: [-9.385, -8.901, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 823 1 visits [151.0, 347.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1314 q_vals: [-9.385, -8.907, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1317, "number_of_timesteps": 26131, "per_episode_reward": 16.43, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.14285714285714235},
Step 824 1 visits [151.0, 348.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1317 q_vals: [-9.385, -8.912, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 825 1 visits [151.0, 349.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1320 q_vals: [-9.385, -8.915, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 826 1 visits [151.0, 350.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1322 q_vals: [-9.385, -8.916, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 827 1 visits [151.0, 351.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1324 q_vals: [-9.385, -8.919, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1329, "number_of_timesteps": 26281, "per_episode_reward": 16.43, "episode_reward_trend_value": -0.003174603174603203, "biggest_recent_change": 0.14285714285714235},
Step 828 1 visits [151.0, 352.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1329 q_vals: [-9.385, -8.923, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 829 1 visits [151.0, 353.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1331 q_vals: [-9.385, -8.897, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 830 1 visits [151.0, 354.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1333 q_vals: [-9.385, -8.904, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 831 1 visits [151.0, 355.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1336 q_vals: [-9.385, -8.904, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 832 1 visits [151.0, 356.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1338 q_vals: [-9.385, -8.879, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1340, "number_of_timesteps": 26401, "per_episode_reward": 16.21, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.21428571428571175},
Step 833 1 visits [151.0, 357.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1340 q_vals: [-9.385, -8.885, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 834 1 visits [151.0, 358.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1343 q_vals: [-9.385, -8.889, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 835 1 visits [151.0, 359.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1344 q_vals: [-9.385, -8.889, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 836 1 visits [151.0, 360.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1347 q_vals: [-9.385, -8.892, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 837 1 visits [151.0, 361.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1347 q_vals: [-9.385, -8.894, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1350, "number_of_timesteps": 26527, "per_episode_reward": 16.21, "episode_reward_trend_value": -0.006349206349206327, "biggest_recent_change": 0.21428571428571175},
Step 838 1 visits [151.0, 362.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1350 q_vals: [-9.385, -8.87, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 839 1 visits [151.0, 363.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1352 q_vals: [-9.385, -8.871, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 840 1 visits [151.0, 364.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1354 q_vals: [-9.385, -8.871, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 841 1 visits [151.0, 365.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1356 q_vals: [-9.385, -8.877, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 842 1 visits [151.0, 366.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1356 q_vals: [-9.385, -8.883, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 843 1 visits [151.0, 367.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1357 q_vals: [-9.385, -8.889, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 844 1 visits [151.0, 368.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1359 q_vals: [-9.385, -8.893, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1361, "number_of_timesteps": 26760, "per_episode_reward": 16.29, "episode_reward_trend_value": -0.004761904761904785, "biggest_recent_change": 0.21428571428571175},
Step 845 1 visits [151.0, 369.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1361 q_vals: [-9.385, -8.898, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 846 1 visits [151.0, 370.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1361 q_vals: [-9.385, -8.899, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 847 1 visits [151.0, 371.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1362 q_vals: [-9.385, -8.875, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 848 1 visits [151.0, 372.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1364 q_vals: [-9.385, -8.876, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 849 1 visits [151.0, 373.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1365 q_vals: [-9.385, -8.877, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 850 1 visits [151.0, 374.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1367 q_vals: [-9.385, -8.878, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 851 1 visits [151.0, 375.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1370 q_vals: [-9.385, -8.878, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 852 1 visits [151.0, 376.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1370 q_vals: [-9.385, -8.884, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1371, "number_of_timesteps": 26995, "per_episode_reward": 16.29, "episode_reward_trend_value": -0.003174603174603203, "biggest_recent_change": 0.21428571428571175},
Step 853 1 visits [151.0, 377.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1371 q_vals: [-9.385, -8.885, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 854 1 visits [151.0, 378.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1372 q_vals: [-9.385, -8.882, -9.574, -9.498, -9.38, -9.962, -9.512]
[151.0, 379.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1372 q_vals: [-9.385, -8.882, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 856 1 visits [151.0, 380.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1374 q_vals: [-9.385, -8.858, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 857 1 visits [151.0, 381.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1377 q_vals: [-9.385, -8.857, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 858 1 visits [151.0, 382.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1378 q_vals: [-9.385, -8.863, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 859 1 visits [151.0, 383.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1378 q_vals: [-9.385, -8.869, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 860 1 visits [151.0, 384.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1379 q_vals: [-9.385, -8.869, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1381, "number_of_timesteps": 27232, "per_episode_reward": 16.36, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.21428571428571175},
Step 861 1 visits [151.0, 385.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1381 q_vals: [-9.385, -8.869, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 862 1 visits [151.0, 386.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1381 q_vals: [-9.385, -8.87, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 863 1 visits [151.0, 387.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1384 q_vals: [-9.385, -8.871, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 864 1 visits [151.0, 388.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1385 q_vals: [-9.385, -8.848, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 865 1 visits [151.0, 389.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1388 q_vals: [-9.385, -8.854, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 866 1 visits [151.0, 390.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1389 q_vals: [-9.385, -8.858, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 867 1 visits [151.0, 391.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1389 q_vals: [-9.385, -8.864, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 868 1 visits [151.0, 392.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1389 q_vals: [-9.385, -8.87, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1392, "number_of_timesteps": 27515, "per_episode_reward": 16.36, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.21428571428571175},
Step 869 1 visits [151.0, 393.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1392 q_vals: [-9.385, -8.87, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 870 1 visits [151.0, 394.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1394 q_vals: [-9.385, -8.848, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 871 1 visits [151.0, 395.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1395 q_vals: [-9.385, -8.847, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 872 1 visits [151.0, 396.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1397 q_vals: [-9.385, -8.853, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 873 1 visits [151.0, 397.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1399 q_vals: [-9.385, -8.857, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 874 1 visits [151.0, 398.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1400 q_vals: [-9.385, -8.834, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1402, "number_of_timesteps": 27724, "per_episode_reward": 16.36, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.21428571428571175},
Step 875 1 visits [151.0, 399.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1402 q_vals: [-9.385, -8.837, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 876 1 visits [151.0, 400.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1405 q_vals: [-9.385, -8.837, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 877 1 visits [151.0, 401.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1405 q_vals: [-9.385, -8.839, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 878 1 visits [151.0, 402.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1407 q_vals: [-9.385, -8.838, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 879 1 visits [151.0, 403.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1409 q_vals: [-9.385, -8.84, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 880 1 visits [151.0, 404.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1411 q_vals: [-9.385, -8.842, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1412, "number_of_timesteps": 27901, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.21428571428571175},
Step 881 1 visits [151.0, 405.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1412 q_vals: [-9.385, -8.842, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 882 1 visits [151.0, 406.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1413 q_vals: [-9.385, -8.848, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 883 1 visits [151.0, 407.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1415 q_vals: [-9.385, -8.853, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 884 1 visits [151.0, 408.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1416 q_vals: [-9.385, -8.857, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 885 1 visits [151.0, 409.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1419 q_vals: [-9.385, -8.856, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 886 1 visits [151.0, 410.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1420 q_vals: [-9.385, -8.861, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 887 1 visits [151.0, 411.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1421 q_vals: [-9.385, -8.861, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1422, "number_of_timesteps": 28123, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.21428571428571175},
Step 888 1 visits [151.0, 412.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1422 q_vals: [-9.385, -8.86, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 889 1 visits [151.0, 413.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1426 q_vals: [-9.385, -8.859, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 890 1 visits [151.0, 414.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1427 q_vals: [-9.385, -8.865, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 891 1 visits [151.0, 415.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1428 q_vals: [-9.385, -8.843, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 892 1 visits [151.0, 416.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1431 q_vals: [-9.385, -8.845, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 893 1 visits [151.0, 417.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1431 q_vals: [-9.385, -8.85, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 894 1 visits [151.0, 418.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1431 q_vals: [-9.385, -8.851, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1433, "number_of_timesteps": 28321, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857295},
Step 895 1 visits [151.0, 419.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1433 q_vals: [-9.385, -8.85, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 896 1 visits [151.0, 420.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1435 q_vals: [-9.385, -8.851, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 897 1 visits [151.0, 421.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1436 q_vals: [-9.385, -8.85, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 898 1 visits [151.0, 422.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1437 q_vals: [-9.385, -8.855, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 899 1 visits [151.0, 423.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1437 q_vals: [-9.385, -8.86, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 900 1 visits [151.0, 424.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1440 q_vals: [-9.385, -8.859, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 901 1 visits [151.0, 425.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1442 q_vals: [-9.385, -8.859, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1443, "number_of_timesteps": 28556, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.07142857142857295},
Step 902 1 visits [151.0, 426.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1443 q_vals: [-9.385, -8.838, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 903 1 visits [151.0, 427.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1445 q_vals: [-9.385, -8.838, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 904 1 visits [151.0, 428.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1447 q_vals: [-9.385, -8.844, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 905 1 visits [151.0, 429.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1448 q_vals: [-9.385, -8.843, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 906 1 visits [151.0, 430.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1450 q_vals: [-9.385, -8.848, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 907 1 visits [151.0, 431.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1450 q_vals: [-9.385, -8.846, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 908 1 visits [151.0, 432.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1450 q_vals: [-9.385, -8.846, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 909 1 visits [151.0, 433.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1452 q_vals: [-9.385, -8.848, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 910 1 visits [151.0, 434.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1452 q_vals: [-9.385, -8.853, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1453, "number_of_timesteps": 28775, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
Step 911 1 visits [151.0, 435.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1453 q_vals: [-9.385, -8.858, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 912 1 visits [151.0, 436.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1459 q_vals: [-9.385, -8.857, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 913 1 visits [151.0, 437.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1459 q_vals: [-9.385, -8.856, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 914 1 visits [151.0, 438.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1459 q_vals: [-9.385, -8.836, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 915 1 visits [151.0, 439.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1459 q_vals: [-9.385, -8.831, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1464, "number_of_timesteps": 29040, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.07142857142857295},
Step 916 1 visits [151.0, 440.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1464 q_vals: [-9.385, -8.836, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 917 1 visits [151.0, 441.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1464 q_vals: [-9.385, -8.834, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 918 1 visits [151.0, 442.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1465 q_vals: [-9.385, -8.84, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 919 1 visits [151.0, 443.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1467 q_vals: [-9.385, -8.82, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 920 1 visits [151.0, 444.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1468 q_vals: [-9.385, -8.825, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 921 1 visits [151.0, 445.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1470 q_vals: [-9.385, -8.825, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 922 1 visits [151.0, 446.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1471 q_vals: [-9.385, -8.805, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1474, "number_of_timesteps": 29227, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.1428571428571459},
Step 923 1 visits [151.0, 447.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1474 q_vals: [-9.385, -8.808, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 924 1 visits [151.0, 448.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1476 q_vals: [-9.385, -8.788, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 925 1 visits [151.0, 449.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1478 q_vals: [-9.385, -8.793, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 926 1 visits [151.0, 450.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1479 q_vals: [-9.385, -8.773, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 927 1 visits [151.0, 451.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1481 q_vals: [-9.385, -8.772, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1484, "number_of_timesteps": 29404, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.1428571428571459},
Step 928 1 visits [151.0, 452.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1484 q_vals: [-9.385, -8.774, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 929 1 visits [151.0, 453.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1484 q_vals: [-9.385, -8.78, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 930 1 visits [151.0, 454.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1487 q_vals: [-9.385, -8.785, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 931 1 visits [151.0, 455.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1490 q_vals: [-9.385, -8.784, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 932 1 visits [151.0, 456.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1491 q_vals: [-9.385, -8.788, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1494, "number_of_timesteps": 29583, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.1428571428571459},
Step 933 1 visits [151.0, 457.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1494 q_vals: [-9.385, -8.787, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 934 1 visits [151.0, 458.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1496 q_vals: [-9.385, -8.787, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 935 1 visits [151.0, 459.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1498 q_vals: [-9.385, -8.792, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 936 1 visits [151.0, 460.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1500 q_vals: [-9.385, -8.797, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 937 1 visits [151.0, 461.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1502 q_vals: [-9.385, -8.802, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 938 1 visits [151.0, 462.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1503 q_vals: [-9.385, -8.807, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1505, "number_of_timesteps": 29740, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1428571428571459},
Step 939 1 visits [151.0, 463.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1505 q_vals: [-9.385, -8.812, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 940 1 visits [151.0, 464.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1506 q_vals: [-9.385, -8.813, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 941 1 visits [151.0, 465.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1508 q_vals: [-9.385, -8.812, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 942 1 visits [151.0, 466.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1508 q_vals: [-9.385, -8.815, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 943 1 visits [151.0, 467.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1511 q_vals: [-9.385, -8.82, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 944 1 visits [151.0, 468.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1512 q_vals: [-9.385, -8.801, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 945 1 visits [151.0, 469.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1514 q_vals: [-9.385, -8.782, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1516, "number_of_timesteps": 29961, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1428571428571459},
Step 946 1 visits [151.0, 470.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1516 q_vals: [-9.385, -8.787, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 947 1 visits [151.0, 471.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1518 q_vals: [-9.385, -8.792, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 948 1 visits [151.0, 472.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1518 q_vals: [-9.385, -8.773, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 949 1 visits [151.0, 473.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1522 q_vals: [-9.385, -8.772, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 950 1 visits [151.0, 474.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1523 q_vals: [-9.385, -8.772, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 951 1 visits [151.0, 475.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1525 q_vals: [-9.385, -8.776, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1528, "number_of_timesteps": 30185, "per_episode_reward": 16.43, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.1428571428571459},
Step 952 1 visits [151.0, 476.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1528 q_vals: [-9.385, -8.775, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 953 1 visits [151.0, 477.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1529 q_vals: [-9.385, -8.773, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 954 1 visits [151.0, 478.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1531 q_vals: [-9.385, -8.774, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 955 1 visits [151.0, 479.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1533 q_vals: [-9.385, -8.773, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 956 1 visits [151.0, 480.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1533 q_vals: [-9.385, -8.773, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 957 1 visits [151.0, 481.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1535 q_vals: [-9.385, -8.772, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1538, "number_of_timesteps": 30365, "per_episode_reward": 16.43, "episode_reward_trend_value": -0.0015873015873016211, "biggest_recent_change": 0.1428571428571459},
Step 958 1 visits [151.0, 482.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1538 q_vals: [-9.385, -8.77, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 959 1 visits [151.0, 483.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1539 q_vals: [-9.385, -8.752, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 960 1 visits [151.0, 484.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1542 q_vals: [-9.385, -8.755, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 961 1 visits [151.0, 485.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1543 q_vals: [-9.385, -8.753, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 962 1 visits [151.0, 486.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1543 q_vals: [-9.385, -8.758, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 963 1 visits [151.0, 487.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1544 q_vals: [-9.385, -8.763, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 964 1 visits [151.0, 488.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1547 q_vals: [-9.385, -8.762, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1549, "number_of_timesteps": 30570, "per_episode_reward": 16.43, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.1428571428571459},
Step 965 1 visits [151.0, 489.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1549 q_vals: [-9.385, -8.76, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 966 1 visits [151.0, 490.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1550 q_vals: [-9.385, -8.759, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 967 1 visits [151.0, 491.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1552 q_vals: [-9.385, -8.76, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 968 1 visits [151.0, 492.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1555 q_vals: [-9.385, -8.742, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 969 1 visits [151.0, 493.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1557 q_vals: [-9.385, -8.733, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 970 1 visits [151.0, 494.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1558 q_vals: [-9.385, -8.732, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1559, "number_of_timesteps": 30746, "per_episode_reward": 16.43, "episode_reward_trend_value": -0.0015873015873016211, "biggest_recent_change": 0.1428571428571459},
Step 971 1 visits [151.0, 495.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1559 q_vals: [-9.385, -8.731, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 972 1 visits [151.0, 496.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1561 q_vals: [-9.385, -8.733, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 973 1 visits [151.0, 497.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1562 q_vals: [-9.385, -8.738, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 974 1 visits [151.0, 498.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1565 q_vals: [-9.385, -8.736, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 975 1 visits [151.0, 499.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1567 q_vals: [-9.385, -8.734, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 976 1 visits [151.0, 500.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1568 q_vals: [-9.385, -8.733, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1570, "number_of_timesteps": 30958, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 977 1 visits [151.0, 501.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1570 q_vals: [-9.385, -8.733, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 978 1 visits [151.0, 502.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1572 q_vals: [-9.385, -8.73, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 979 1 visits [151.0, 503.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1574 q_vals: [-9.385, -8.729, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 980 1 visits [151.0, 504.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1574 q_vals: [-9.385, -8.732, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 981 1 visits [151.0, 505.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1578 q_vals: [-9.385, -8.733, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 982 1 visits [151.0, 506.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1579 q_vals: [-9.385, -8.733, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1581, "number_of_timesteps": 31151, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 983 1 visits [151.0, 507.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1581 q_vals: [-9.385, -8.731, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 984 1 visits [151.0, 508.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1583 q_vals: [-9.385, -8.729, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 985 1 visits [151.0, 509.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1585 q_vals: [-9.385, -8.734, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 986 1 visits [151.0, 510.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1588 q_vals: [-9.385, -8.739, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 987 1 visits [151.0, 511.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1589 q_vals: [-9.385, -8.739, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1591, "number_of_timesteps": 31295, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 988 1 visits [151.0, 512.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1591 q_vals: [-9.385, -8.744, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 989 1 visits [151.0, 513.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1593 q_vals: [-9.385, -8.745, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 990 1 visits [151.0, 514.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1595 q_vals: [-9.385, -8.746, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 991 1 visits [151.0, 515.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1597 q_vals: [-9.385, -8.745, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 992 1 visits [151.0, 516.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1598 q_vals: [-9.385, -8.744, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 993 1 visits [151.0, 517.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1600 q_vals: [-9.385, -8.742, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1601, "number_of_timesteps": 31431, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 994 1 visits [151.0, 518.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1601 q_vals: [-9.385, -8.74, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 995 1 visits [151.0, 519.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1601 q_vals: [-9.385, -8.741, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 996 1 visits [151.0, 520.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1604 q_vals: [-9.385, -8.743, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 997 1 visits [151.0, 521.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1607 q_vals: [-9.385, -8.741, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 998 1 visits [151.0, 522.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1607 q_vals: [-9.385, -8.74, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 999 1 visits [151.0, 523.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1609 q_vals: [-9.385, -8.745, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1612, "number_of_timesteps": 31667, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1000 1 visits [151.0, 524.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1612 q_vals: [-9.385, -8.747, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1001 1 visits [151.0, 525.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1612 q_vals: [-9.385, -8.75, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1002 1 visits [151.0, 526.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1615 q_vals: [-9.385, -8.748, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1003 1 visits [151.0, 527.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1616 q_vals: [-9.385, -8.746, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1004 1 visits [151.0, 528.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1619 q_vals: [-9.385, -8.748, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1622, "number_of_timesteps": 31846, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1005 1 visits [151.0, 529.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1622 q_vals: [-9.385, -8.753, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1006 1 visits [151.0, 530.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1625 q_vals: [-9.385, -8.751, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1007 1 visits [151.0, 531.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1625 q_vals: [-9.385, -8.755, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1008 1 visits [151.0, 532.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1629 q_vals: [-9.385, -8.753, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1632, "number_of_timesteps": 31972, "per_episode_reward": 16.36, "episode_reward_trend_value": -0.0007936507936507711, "biggest_recent_change": 0.0714285714285694},
Step 1009 1 visits [151.0, 533.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1632 q_vals: [-9.385, -8.737, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1010 1 visits [151.0, 534.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1632 q_vals: [-9.385, -8.721, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1011 1 visits [151.0, 535.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1635 q_vals: [-9.385, -8.721, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1012 1 visits [151.0, 536.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1637 q_vals: [-9.385, -8.722, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1013 1 visits [151.0, 537.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1640 q_vals: [-9.385, -8.72, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1644, "number_of_timesteps": 32137, "per_episode_reward": 16.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
Step 1014 1 visits [151.0, 538.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1644 q_vals: [-9.385, -8.724, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1015 1 visits [151.0, 539.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1645 q_vals: [-9.385, -8.722, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1016 1 visits [151.0, 540.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1647 q_vals: [-9.385, -8.726, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1017 1 visits [151.0, 541.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1649 q_vals: [-9.385, -8.725, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1018 1 visits [151.0, 542.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1651 q_vals: [-9.385, -8.723, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1655, "number_of_timesteps": 32281, "per_episode_reward": 16.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
Step 1019 1 visits [151.0, 543.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1655 q_vals: [-9.385, -8.721, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1020 1 visits [151.0, 544.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1657 q_vals: [-9.385, -8.722, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1021 1 visits [151.0, 545.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1660 q_vals: [-9.385, -8.72, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1022 1 visits [151.0, 546.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1662 q_vals: [-9.385, -8.724, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1023 1 visits [151.0, 547.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1664 q_vals: [-9.385, -8.708, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1666, "number_of_timesteps": 32408, "per_episode_reward": 16.21, "episode_reward_trend_value": -0.0023809523809523525, "biggest_recent_change": 0.07142857142857295},
Step 1024 1 visits [151.0, 548.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1666 q_vals: [-9.385, -8.706, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1025 1 visits [151.0, 549.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1667 q_vals: [-9.385, -8.705, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1026 1 visits [151.0, 550.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1670 q_vals: [-9.385, -8.689, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1027 1 visits [151.0, 551.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1673 q_vals: [-9.385, -8.691, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1028 1 visits [151.0, 552.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1674 q_vals: [-9.385, -8.695, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1678, "number_of_timesteps": 32574, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.07142857142857295},
Step 1029 1 visits [151.0, 553.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1678 q_vals: [-9.385, -8.693, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1030 1 visits [151.0, 554.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1679 q_vals: [-9.385, -8.691, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1031 1 visits [151.0, 555.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1681 q_vals: [-9.385, -8.693, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1032 1 visits [151.0, 556.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1685 q_vals: [-9.385, -8.694, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1033 1 visits [151.0, 557.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1686 q_vals: [-9.385, -8.693, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1034 1 visits [151.0, 558.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1687 q_vals: [-9.385, -8.695, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1691, "number_of_timesteps": 32749, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
Step 1035 1 visits [151.0, 559.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1691 q_vals: [-9.385, -8.694, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1036 1 visits [151.0, 560.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1693 q_vals: [-9.385, -8.692, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1037 1 visits [151.0, 561.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1694 q_vals: [-9.385, -8.692, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1038 1 visits [151.0, 562.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1698 q_vals: [-9.385, -8.69, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1039 1 visits [151.0, 563.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1700 q_vals: [-9.385, -8.689, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1702, "number_of_timesteps": 32886, "per_episode_reward": 15.93, "episode_reward_trend_value": -0.005555555555555536, "biggest_recent_change": 0.14285714285714235},
Step 1040 1 visits [151.0, 564.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1702 q_vals: [-9.385, -8.689, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1041 1 visits [151.0, 565.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1705 q_vals: [-9.385, -8.686, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1042 1 visits [151.0, 566.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1708 q_vals: [-9.385, -8.684, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1043 1 visits [151.0, 567.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1709 q_vals: [-9.385, -8.669, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1713, "number_of_timesteps": 33020, "per_episode_reward": 15.86, "episode_reward_trend_value": -0.006349206349206327, "biggest_recent_change": 0.14285714285714235},
Step 1044 1 visits [151.0, 568.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1713 q_vals: [-9.385, -8.673, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1045 1 visits [151.0, 569.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1715 q_vals: [-9.385, -8.671, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1046 1 visits [151.0, 570.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1716 q_vals: [-9.385, -8.656, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1047 1 visits [151.0, 571.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1718 q_vals: [-9.385, -8.66, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1048 1 visits [151.0, 572.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1722 q_vals: [-9.385, -8.661, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1723, "number_of_timesteps": 33160, "per_episode_reward": 15.86, "episode_reward_trend_value": -0.006349206349206327, "biggest_recent_change": 0.14285714285714235},
Step 1049 1 visits [151.0, 573.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1723 q_vals: [-9.385, -8.66, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1050 1 visits [151.0, 574.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1726 q_vals: [-9.385, -8.659, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1051 1 visits [151.0, 575.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1728 q_vals: [-9.385, -8.657, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1052 1 visits [151.0, 576.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1728 q_vals: [-9.385, -8.656, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1053 1 visits [151.0, 577.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1731 q_vals: [-9.385, -8.654, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1734, "number_of_timesteps": 33319, "per_episode_reward": 15.86, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.14285714285714235},
Step 1054 1 visits [151.0, 578.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1734 q_vals: [-9.385, -8.656, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1055 1 visits [151.0, 579.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1734 q_vals: [-9.385, -8.66, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1056 1 visits [151.0, 580.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1739 q_vals: [-9.385, -8.658, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1057 1 visits [151.0, 581.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1739 q_vals: [-9.385, -8.656, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1058 1 visits [151.0, 582.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1741 q_vals: [-9.385, -8.66, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1744, "number_of_timesteps": 33466, "per_episode_reward": 15.79, "episode_reward_trend_value": -0.005555555555555536, "biggest_recent_change": 0.14285714285714235},
Step 1059 1 visits [151.0, 583.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1744 q_vals: [-9.385, -8.645, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1060 1 visits [151.0, 584.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1744 q_vals: [-9.385, -8.647, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1061 1 visits [151.0, 585.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1745 q_vals: [-9.385, -8.651, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1062 1 visits [151.0, 586.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1749 q_vals: [-9.385, -8.637, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1063 1 visits [151.0, 587.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1752 q_vals: [-9.385, -8.637, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1064 1 visits [151.0, 588.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1753 q_vals: [-9.385, -8.635, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1758, "number_of_timesteps": 33674, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.006349206349206346, "biggest_recent_change": 0.14285714285714235},
Step 1065 1 visits [151.0, 589.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1758 q_vals: [-9.385, -8.621, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1066 1 visits [151.0, 590.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1759 q_vals: [-9.385, -8.625, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1067 1 visits [151.0, 591.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1762 q_vals: [-9.385, -8.624, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1068 1 visits [151.0, 592.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1764 q_vals: [-9.385, -8.628, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1069 1 visits [151.0, 593.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1766 q_vals: [-9.385, -8.633, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1769, "number_of_timesteps": 33814, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.005555555555555576, "biggest_recent_change": 0.14285714285714235},
Step 1070 1 visits [151.0, 594.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1769 q_vals: [-9.385, -8.631, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1071 1 visits [151.0, 595.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1771 q_vals: [-9.385, -8.631, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1072 1 visits [151.0, 596.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1774 q_vals: [-9.385, -8.63, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1073 1 visits [151.0, 597.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1774 q_vals: [-9.385, -8.631, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1074 1 visits [151.0, 598.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1777 q_vals: [-9.385, -8.628, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1075 1 visits [151.0, 599.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1778 q_vals: [-9.385, -8.626, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1781, "number_of_timesteps": 33984, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.004761904761904764, "biggest_recent_change": 0.14285714285714235},
Step 1076 1 visits [151.0, 600.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1781 q_vals: [-9.385, -8.624, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1077 1 visits [151.0, 601.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1783 q_vals: [-9.385, -8.623, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1078 1 visits [151.0, 602.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1785 q_vals: [-9.385, -8.622, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1079 1 visits [151.0, 603.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1786 q_vals: [-9.385, -8.621, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1080 1 visits [151.0, 604.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1789 q_vals: [-9.385, -8.619, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1792, "number_of_timesteps": 34147, "per_episode_reward": 15.79, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.07142857142857295},
Step 1081 1 visits [151.0, 605.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1792 q_vals: [-9.385, -8.619, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1082 1 visits [151.0, 606.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1792 q_vals: [-9.385, -8.617, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1083 1 visits [151.0, 607.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1794 q_vals: [-9.385, -8.621, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1084 1 visits [151.0, 608.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1799 q_vals: [-9.385, -8.625, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1085 1 visits [151.0, 609.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1800 q_vals: [-9.385, -8.61, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1086 1 visits [151.0, 610.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1801 q_vals: [-9.385, -8.611, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1804, "number_of_timesteps": 34323, "per_episode_reward": 15.86, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857295},
Step 1087 1 visits [151.0, 611.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1804 q_vals: [-9.385, -8.613, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1088 1 visits [151.0, 612.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1805 q_vals: [-9.385, -8.599, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1089 1 visits [151.0, 613.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1808 q_vals: [-9.385, -8.597, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1090 1 visits [151.0, 614.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1810 q_vals: [-9.385, -8.601, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1091 1 visits [151.0, 615.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1810 q_vals: [-9.385, -8.598, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1092 1 visits [151.0, 616.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1813 q_vals: [-9.385, -8.597, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1814, "number_of_timesteps": 34461, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
Step 1093 1 visits [151.0, 617.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1814 q_vals: [-9.385, -8.601, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1094 1 visits [151.0, 618.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1814 q_vals: [-9.385, -8.587, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1095 1 visits [151.0, 619.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1817 q_vals: [-9.385, -8.591, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1096 1 visits [151.0, 620.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1819 q_vals: [-9.385, -8.591, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1097 1 visits [151.0, 621.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1819 q_vals: [-9.385, -8.592, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1098 1 visits [151.0, 622.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1822 q_vals: [-9.385, -8.578, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1099 1 visits [151.0, 623.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1822 q_vals: [-9.385, -8.579, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1824, "number_of_timesteps": 34693, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
Step 1100 1 visits [151.0, 624.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1824 q_vals: [-9.385, -8.577, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1101 1 visits [151.0, 625.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1826 q_vals: [-9.385, -8.577, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1102 1 visits [151.0, 626.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1826 q_vals: [-9.385, -8.581, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1103 1 visits [151.0, 627.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1828 q_vals: [-9.385, -8.579, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1104 1 visits [151.0, 628.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1830 q_vals: [-9.385, -8.577, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1105 1 visits [151.0, 629.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1832 q_vals: [-9.385, -8.575, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1106 1 visits [151.0, 630.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1833 q_vals: [-9.385, -8.573, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1835, "number_of_timesteps": 34915, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
 q_vals: [-9.385, -8.57, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1108 1 visits [151.0, 632.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1838 q_vals: [-9.385, -8.57, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1109 1 visits [151.0, 633.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1838 q_vals: [-9.385, -8.568, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1110 1 visits [151.0, 634.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1839 q_vals: [-9.385, -8.569, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1111 1 visits [151.0, 635.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1842 q_vals: [-9.385, -8.573, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1112 1 visits [151.0, 636.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1844 q_vals: [-9.385, -8.57, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1845, "number_of_timesteps": 35112, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
Step 1113 1 visits [151.0, 637.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1845 q_vals: [-9.385, -8.571, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1114 1 visits [151.0, 638.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1847 q_vals: [-9.385, -8.571, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1115 1 visits [151.0, 639.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1850 q_vals: [-9.385, -8.568, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1116 1 visits [151.0, 640.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1852 q_vals: [-9.385, -8.566, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1117 1 visits [151.0, 641.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1854 q_vals: [-9.385, -8.57, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1857, "number_of_timesteps": 35291, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
Step 1118 1 visits [151.0, 642.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1857 q_vals: [-9.385, -8.57, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1119 1 visits [151.0, 643.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1858 q_vals: [-9.385, -8.569, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1120 1 visits [151.0, 644.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1860 q_vals: [-9.385, -8.568, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1121 1 visits [151.0, 645.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1863 q_vals: [-9.385, -8.554, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1122 1 visits [151.0, 646.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1864 q_vals: [-9.385, -8.541, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1123 1 visits [151.0, 647.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1866 q_vals: [-9.385, -8.54, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1870, "number_of_timesteps": 35471, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
Step 1124 1 visits [151.0, 648.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1870 q_vals: [-9.385, -8.54, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1125 1 visits [151.0, 649.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1871 q_vals: [-9.385, -8.539, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1126 1 visits [151.0, 650.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1872 q_vals: [-9.385, -8.539, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1127 1 visits [151.0, 651.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1877 q_vals: [-9.385, -8.537, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1128 1 visits [151.0, 652.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1877 q_vals: [-9.385, -8.535, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1129 1 visits [151.0, 653.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1878 q_vals: [-9.385, -8.534, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1130 1 visits [151.0, 654.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1879 q_vals: [-9.385, -8.52, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1880, "number_of_timesteps": 35629, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
Step 1131 1 visits [151.0, 655.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1880 q_vals: [-9.385, -8.519, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1132 1 visits [151.0, 656.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1881 q_vals: [-9.385, -8.521, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1133 1 visits [151.0, 657.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1884 q_vals: [-9.385, -8.519, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1134 1 visits [151.0, 658.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1884 q_vals: [-9.385, -8.52, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1135 1 visits [151.0, 659.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1886 q_vals: [-9.385, -8.522, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1136 1 visits [151.0, 660.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1887 q_vals: [-9.385, -8.521, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1137 1 visits [151.0, 661.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1889 q_vals: [-9.385, -8.525, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1138 1 visits [151.0, 662.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1889 q_vals: [-9.385, -8.529, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1892, "number_of_timesteps": 35917, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
Step 1139 1 visits [151.0, 663.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1892 q_vals: [-9.385, -8.526, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1140 1 visits [151.0, 664.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1894 q_vals: [-9.385, -8.522, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1141 1 visits [151.0, 665.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1895 q_vals: [-9.385, -8.526, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1142 1 visits [151.0, 666.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1895 q_vals: [-9.385, -8.53, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1143 1 visits [151.0, 667.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1896 q_vals: [-9.385, -8.528, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1144 1 visits [151.0, 668.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1897 q_vals: [-9.385, -8.527, -9.574, -9.498, -9.38, -9.962, -9.512]
visits [151.0, 669.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1897 q_vals: [-9.385, -8.531, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1146 1 visits [151.0, 670.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1899 q_vals: [-9.385, -8.528, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1147 1 visits [151.0, 671.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1901 q_vals: [-9.385, -8.529, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1903, "number_of_timesteps": 36203, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 1148 1 visits [151.0, 672.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1903 q_vals: [-9.385, -8.527, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1149 1 visits [151.0, 673.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1905 q_vals: [-9.385, -8.526, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1150 1 visits [151.0, 674.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1906 q_vals: [-9.385, -8.523, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1151 1 visits [151.0, 675.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1909 q_vals: [-9.385, -8.521, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1152 1 visits [151.0, 676.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1911 q_vals: [-9.385, -8.518, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1153 1 visits [151.0, 677.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1911 q_vals: [-9.385, -8.519, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1915, "number_of_timesteps": 36414, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 1154 1 visits [151.0, 678.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1915 q_vals: [-9.385, -8.521, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1155 1 visits [151.0, 679.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1918 q_vals: [-9.385, -8.523, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1156 1 visits [151.0, 680.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1918 q_vals: [-9.385, -8.52, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1157 1 visits [151.0, 681.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1921 q_vals: [-9.385, -8.518, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1158 1 visits [151.0, 682.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1922 q_vals: [-9.385, -8.515, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1925, "number_of_timesteps": 36568, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 1159 1 visits [151.0, 683.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1925 q_vals: [-9.385, -8.516, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1160 1 visits [151.0, 684.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1926 q_vals: [-9.385, -8.518, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1161 1 visits [151.0, 685.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1928 q_vals: [-9.385, -8.516, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1162 1 visits [151.0, 686.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1930 q_vals: [-9.385, -8.518, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1163 1 visits [151.0, 687.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1931 q_vals: [-9.385, -8.514, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1935, "number_of_timesteps": 36709, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 1164 1 visits [151.0, 688.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1935 q_vals: [-9.385, -8.502, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1165 1 visits [151.0, 689.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1938 q_vals: [-9.385, -8.5, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1166 1 visits [151.0, 690.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1940 q_vals: [-9.385, -8.498, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1167 1 visits [151.0, 691.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1942 q_vals: [-9.385, -8.496, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1168 1 visits [151.0, 692.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1944 q_vals: [-9.385, -8.495, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1946, "number_of_timesteps": 36867, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1169 1 visits [151.0, 693.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1946 q_vals: [-9.385, -8.493, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1170 1 visits [151.0, 694.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1949 q_vals: [-9.385, -8.491, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1171 1 visits [151.0, 695.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1951 q_vals: [-9.385, -8.488, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1172 1 visits [151.0, 696.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1954 q_vals: [-9.385, -8.476, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1173 1 visits [151.0, 697.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1955 q_vals: [-9.385, -8.464, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1959, "number_of_timesteps": 37044, "per_episode_reward": 15.64, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1174 1 visits [151.0, 698.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1959 q_vals: [-9.385, -8.452, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1175 1 visits [151.0, 699.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1960 q_vals: [-9.385, -8.453, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1176 1 visits [151.0, 700.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1962 q_vals: [-9.385, -8.457, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1177 1 visits [151.0, 701.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1966 q_vals: [-9.385, -8.455, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1178 1 visits [151.0, 702.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1967 q_vals: [-9.385, -8.459, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1970, "number_of_timesteps": 37192, "per_episode_reward": 15.43, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.21428571428571352},
Step 1179 1 visits [151.0, 703.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1970 q_vals: [-9.385, -8.46, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1180 1 visits [151.0, 704.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1972 q_vals: [-9.385, -8.46, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1181 1 visits [151.0, 705.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1975 q_vals: [-9.385, -8.457, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1182 1 visits [151.0, 706.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1975 q_vals: [-9.385, -8.458, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1981, "number_of_timesteps": 37336, "per_episode_reward": 15.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.21428571428571352},
Step 1183 1 visits [151.0, 707.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1981 q_vals: [-9.385, -8.446, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1184 1 visits [151.0, 708.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1982 q_vals: [-9.385, -8.434, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1185 1 visits [151.0, 709.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1984 q_vals: [-9.385, -8.432, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1186 1 visits [151.0, 710.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1986 q_vals: [-9.385, -8.429, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1187 1 visits [151.0, 711.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1990 q_vals: [-9.385, -8.417, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1188 1 visits [151.0, 712.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1990 q_vals: [-9.385, -8.409, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 1993, "number_of_timesteps": 37496, "per_episode_reward": 15.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.21428571428571352},
Step 1189 1 visits [151.0, 713.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1993 q_vals: [-9.385, -8.413, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1190 1 visits [151.0, 714.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1994 q_vals: [-9.385, -8.41, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1191 1 visits [151.0, 715.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1995 q_vals: [-9.385, -8.406, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1192 1 visits [151.0, 716.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 1998 q_vals: [-9.385, -8.406, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1193 1 visits [151.0, 717.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2000 q_vals: [-9.385, -8.406, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2003, "number_of_timesteps": 37668, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.21428571428571352},
Step 1194 1 visits [151.0, 718.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2003 q_vals: [-9.385, -8.404, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1195 1 visits [151.0, 719.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2004 q_vals: [-9.385, -8.402, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1196 1 visits [151.0, 720.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2006 q_vals: [-9.385, -8.401, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1197 1 visits [151.0, 721.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2008 q_vals: [-9.385, -8.399, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1198 1 visits [151.0, 722.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2009 q_vals: [-9.385, -8.397, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1199 1 visits [151.0, 723.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2011 q_vals: [-9.385, -8.395, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1200 1 visits [151.0, 724.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2012 q_vals: [-9.385, -8.396, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2013, "number_of_timesteps": 37836, "per_episode_reward": 15.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.21428571428571352},
Step 1201 1 visits [151.0, 725.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2013 q_vals: [-9.385, -8.384, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1202 1 visits [151.0, 726.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2015 q_vals: [-9.385, -8.382, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1203 1 visits [151.0, 727.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2017 q_vals: [-9.385, -8.386, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1204 1 visits [151.0, 728.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2020 q_vals: [-9.385, -8.384, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1205 1 visits [151.0, 729.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2021 q_vals: [-9.385, -8.382, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1206 1 visits [151.0, 730.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2022 q_vals: [-9.385, -8.38, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2024, "number_of_timesteps": 38037, "per_episode_reward": 15.43, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.21428571428571352},
Step 1207 1 visits [151.0, 731.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2024 q_vals: [-9.385, -8.379, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1208 1 visits [151.0, 732.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2026 q_vals: [-9.385, -8.381, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1209 1 visits [151.0, 733.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2028 q_vals: [-9.385, -8.377, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1210 1 visits [151.0, 734.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2029 q_vals: [-9.385, -8.38, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1211 1 visits [151.0, 735.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2032 q_vals: [-9.385, -8.378, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1212 1 visits [151.0, 736.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2033 q_vals: [-9.385, -8.375, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2034, "number_of_timesteps": 38219, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.21428571428571352},
Step 1213 1 visits [151.0, 737.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2034 q_vals: [-9.385, -8.379, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1214 1 visits [151.0, 738.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2038 q_vals: [-9.385, -8.377, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1215 1 visits [151.0, 739.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2039 q_vals: [-9.385, -8.374, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1216 1 visits [151.0, 740.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2039 q_vals: [-9.385, -8.376, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1217 1 visits [151.0, 741.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2042 q_vals: [-9.385, -8.373, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2044, "number_of_timesteps": 38389, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.21428571428571352},
Step 1218 1 visits [151.0, 742.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2044 q_vals: [-9.385, -8.377, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1219 1 visits [151.0, 743.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2047 q_vals: [-9.385, -8.375, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1220 1 visits [151.0, 744.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2048 q_vals: [-9.385, -8.373, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1221 1 visits [151.0, 745.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2050 q_vals: [-9.385, -8.371, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1222 1 visits [151.0, 746.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2053 q_vals: [-9.385, -8.371, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2054, "number_of_timesteps": 38536, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.21428571428571352},
Step 1223 1 visits [151.0, 747.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2054 q_vals: [-9.385, -8.368, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1224 1 visits [151.0, 748.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2055 q_vals: [-9.385, -8.357, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1225 1 visits [151.0, 749.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2060 q_vals: [-9.385, -8.355, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1226 1 visits [151.0, 750.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2061 q_vals: [-9.385, -8.355, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1227 1 visits [151.0, 751.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2062 q_vals: [-9.385, -8.344, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2064, "number_of_timesteps": 38695, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.21428571428571352},
Step 1228 1 visits [151.0, 752.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2064 q_vals: [-9.385, -8.341, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1229 1 visits [151.0, 753.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2066 q_vals: [-9.385, -8.339, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1230 1 visits [151.0, 754.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2067 q_vals: [-9.385, -8.337, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1231 1 visits [151.0, 755.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2069 q_vals: [-9.385, -8.326, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1232 1 visits [151.0, 756.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2072 q_vals: [-9.385, -8.323, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1233 1 visits [151.0, 757.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2073 q_vals: [-9.385, -8.322, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1234 1 visits [151.0, 758.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2073 q_vals: [-9.385, -8.321, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2075, "number_of_timesteps": 38903, "per_episode_reward": 15.64, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.21428571428571352},
Step 1235 1 visits [151.0, 759.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2075 q_vals: [-9.385, -8.318, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1236 1 visits [151.0, 760.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2076 q_vals: [-9.385, -8.32, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1237 1 visits [151.0, 761.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2078 q_vals: [-9.385, -8.322, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1238 1 visits [151.0, 762.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2081 q_vals: [-9.385, -8.321, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1239 1 visits [151.0, 763.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2082 q_vals: [-9.385, -8.317, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2085, "number_of_timesteps": 39101, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.21428571428571352},
Step 1240 1 visits [151.0, 764.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2085 q_vals: [-9.385, -8.315, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1241 1 visits [151.0, 765.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2086 q_vals: [-9.385, -8.315, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1242 1 visits [151.0, 766.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2086 q_vals: [-9.385, -8.305, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1243 1 visits [151.0, 767.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2087 q_vals: [-9.385, -8.302, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1244 1 visits [151.0, 768.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2089 q_vals: [-9.385, -8.3, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1245 1 visits [151.0, 769.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2091 q_vals: [-9.385, -8.297, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1246 1 visits [151.0, 770.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2093 q_vals: [-9.385, -8.295, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2096, "number_of_timesteps": 39335, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.21428571428571352},
Step 1247 1 visits [151.0, 771.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2096 q_vals: [-9.385, -8.292, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1248 1 visits [151.0, 772.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2097 q_vals: [-9.385, -8.293, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1249 1 visits [151.0, 773.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2099 q_vals: [-9.385, -8.296, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1250 1 visits [151.0, 774.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2100 q_vals: [-9.385, -8.294, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1251 1 visits [151.0, 775.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2102 q_vals: [-9.385, -8.291, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1252 1 visits [151.0, 776.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2104 q_vals: [-9.385, -8.289, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2106, "number_of_timesteps": 39505, "per_episode_reward": 15.64, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.21428571428571352},
Step 1253 1 visits [151.0, 777.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2106 q_vals: [-9.385, -8.287, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1254 1 visits [151.0, 778.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2106 q_vals: [-9.385, -8.286, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1255 1 visits [151.0, 779.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2107 q_vals: [-9.385, -8.28, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1256 1 visits [151.0, 780.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2108 q_vals: [-9.385, -8.277, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1257 1 visits [151.0, 781.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2109 q_vals: [-9.385, -8.281, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1258 1 visits [151.0, 782.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2111 q_vals: [-9.385, -8.27, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1259 1 visits [151.0, 783.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2114 q_vals: [-9.385, -8.268, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2116, "number_of_timesteps": 39727, "per_episode_reward": 15.64, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.21428571428571352},
Step 1260 1 visits [151.0, 784.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2116 q_vals: [-9.385, -8.265, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1261 1 visits [151.0, 785.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2117 q_vals: [-9.385, -8.265, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1262 1 visits [151.0, 786.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2119 q_vals: [-9.385, -8.262, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1263 1 visits [151.0, 787.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2122 q_vals: [-9.385, -8.26, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1264 1 visits [151.0, 788.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2123 q_vals: [-9.385, -8.264, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1265 1 visits [151.0, 789.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2125 q_vals: [-9.385, -8.261, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2127, "number_of_timesteps": 39928, "per_episode_reward": 15.43, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.21428571428571352},
Step 1266 1 visits [151.0, 790.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2127 q_vals: [-9.385, -8.258, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1267 1 visits [151.0, 791.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2129 q_vals: [-9.385, -8.248, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1268 1 visits [151.0, 792.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2131 q_vals: [-9.385, -8.238, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1269 1 visits [151.0, 793.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2134 q_vals: [-9.385, -8.231, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1270 1 visits [151.0, 794.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2135 q_vals: [-9.385, -8.228, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2137, "number_of_timesteps": 40081, "per_episode_reward": 15.36, "episode_reward_trend_value": -0.003968253968253954, "biggest_recent_change": 0.21428571428571352},
Step 1271 1 visits [151.0, 795.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2137 q_vals: [-9.385, -8.227, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1272 1 visits [151.0, 796.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2141 q_vals: [-9.385, -8.226, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1273 1 visits [151.0, 797.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2142 q_vals: [-9.385, -8.23, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1274 1 visits [151.0, 798.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2146 q_vals: [-9.385, -8.228, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2148, "number_of_timesteps": 40233, "per_episode_reward": 15.29, "episode_reward_trend_value": -0.004761904761904745, "biggest_recent_change": 0.21428571428571352},
Step 1275 1 visits [151.0, 799.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2148 q_vals: [-9.385, -8.218, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1276 1 visits [151.0, 800.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2148 q_vals: [-9.385, -8.219, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1277 1 visits [151.0, 801.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2149 q_vals: [-9.385, -8.209, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1278 1 visits [151.0, 802.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2152 q_vals: [-9.385, -8.206, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1279 1 visits [151.0, 803.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2152 q_vals: [-9.385, -8.196, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1280 1 visits [151.0, 804.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2153 q_vals: [-9.385, -8.194, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1281 1 visits [151.0, 805.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2155 q_vals: [-9.385, -8.192, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1282 1 visits [151.0, 806.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2156 q_vals: [-9.385, -8.181, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1283 1 visits [151.0, 807.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2157 q_vals: [-9.385, -8.179, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2160, "number_of_timesteps": 40472, "per_episode_reward": 15.43, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.21428571428571352},
Step 1284 1 visits [151.0, 808.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2160 q_vals: [-9.385, -8.177, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1285 1 visits [151.0, 809.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2161 q_vals: [-9.385, -8.175, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1286 1 visits [151.0, 810.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2163 q_vals: [-9.385, -8.173, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1287 1 visits [151.0, 811.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2164 q_vals: [-9.385, -8.171, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1288 1 visits [151.0, 812.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2166 q_vals: [-9.385, -8.168, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1289 1 visits [151.0, 813.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2168 q_vals: [-9.385, -8.165, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1290 1 visits [151.0, 814.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2168 q_vals: [-9.385, -8.166, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2171, "number_of_timesteps": 40709, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.21428571428571352},
Step 1291 1 visits [151.0, 815.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2171 q_vals: [-9.385, -8.164, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1292 1 visits [151.0, 816.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2174 q_vals: [-9.385, -8.154, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1293 1 visits [151.0, 817.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2175 q_vals: [-9.385, -8.151, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1294 1 visits [151.0, 818.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2177 q_vals: [-9.385, -8.141, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1295 1 visits [151.0, 819.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2179 q_vals: [-9.385, -8.131, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2181, "number_of_timesteps": 40874, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.21428571428571352},
Step 1296 1 visits [151.0, 820.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2181 q_vals: [-9.385, -8.134, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1297 1 visits [151.0, 821.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2182 q_vals: [-9.385, -8.132, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1298 1 visits [151.0, 822.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2185 q_vals: [-9.385, -8.13, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1299 1 visits [151.0, 823.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2186 q_vals: [-9.385, -8.129, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1300 1 visits [151.0, 824.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2190 q_vals: [-9.385, -8.127, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2191, "number_of_timesteps": 41033, "per_episode_reward": 15.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.21428571428571352},
Step 1301 1 visits [151.0, 825.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2191 q_vals: [-9.385, -8.125, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1302 1 visits [151.0, 826.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2192 q_vals: [-9.385, -8.129, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1303 1 visits [151.0, 827.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2196 q_vals: [-9.385, -8.128, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1304 1 visits [151.0, 828.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2197 q_vals: [-9.385, -8.127, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1305 1 visits [151.0, 829.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2198 q_vals: [-9.385, -8.13, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2203, "number_of_timesteps": 41213, "per_episode_reward": 15.43, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.21428571428571352},
Step 1306 1 visits [151.0, 830.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2203 q_vals: [-9.385, -8.128, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1307 1 visits [151.0, 831.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2204 q_vals: [-9.385, -8.125, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1308 1 visits [151.0, 832.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2205 q_vals: [-9.385, -8.123, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1309 1 visits [151.0, 833.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2206 q_vals: [-9.385, -8.12, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1310 1 visits [151.0, 834.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2209 q_vals: [-9.385, -8.118, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1311 1 visits [151.0, 835.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2211 q_vals: [-9.385, -8.109, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1312 1 visits [151.0, 836.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2212 q_vals: [-9.385, -8.108, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2213, "number_of_timesteps": 41365, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.21428571428571352},
Step 1313 1 visits [151.0, 837.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2213 q_vals: [-9.385, -8.109, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1314 1 visits [151.0, 838.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2215 q_vals: [-9.385, -8.107, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1315 1 visits [151.0, 839.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2215 q_vals: [-9.385, -8.097, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1316 1 visits [151.0, 840.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2217 q_vals: [-9.385, -8.097, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1317 1 visits [151.0, 841.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2218 q_vals: [-9.385, -8.094, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1318 1 visits [151.0, 842.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2219 q_vals: [-9.385, -8.092, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1319 1 visits [151.0, 843.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2221 q_vals: [-9.385, -8.086, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2223, "number_of_timesteps": 41552, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1320 1 visits [151.0, 844.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2223 q_vals: [-9.385, -8.083, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1321 1 visits [151.0, 845.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2224 q_vals: [-9.385, -8.081, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1322 1 visits [151.0, 846.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2226 q_vals: [-9.385, -8.079, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1323 1 visits [151.0, 847.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2227 q_vals: [-9.385, -8.076, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1324 1 visits [151.0, 848.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2229 q_vals: [-9.385, -8.077, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1325 1 visits [151.0, 849.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2230 q_vals: [-9.385, -8.078, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1326 1 visits [151.0, 850.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2231 q_vals: [-9.385, -8.077, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2233, "number_of_timesteps": 41800, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1327 1 visits [151.0, 851.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2233 q_vals: [-9.385, -8.075, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1328 1 visits [151.0, 852.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2235 q_vals: [-9.385, -8.073, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1329 1 visits [151.0, 853.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2237 q_vals: [-9.385, -8.073, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1330 1 visits [151.0, 854.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2237 q_vals: [-9.385, -8.071, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1331 1 visits [151.0, 855.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2238 q_vals: [-9.385, -8.061, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1332 1 visits [151.0, 856.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2240 q_vals: [-9.385, -8.064, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2244, "number_of_timesteps": 42057, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 1333 1 visits [151.0, 857.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2244 q_vals: [-9.385, -8.055, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1334 1 visits [151.0, 858.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2244 q_vals: [-9.385, -8.053, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1335 1 visits [151.0, 859.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2247 q_vals: [-9.385, -8.052, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1336 1 visits [151.0, 860.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2248 q_vals: [-9.385, -8.055, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1337 1 visits [151.0, 861.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2251 q_vals: [-9.385, -8.046, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1338 1 visits [151.0, 862.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2252 q_vals: [-9.385, -8.049, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2254, "number_of_timesteps": 42229, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1339 1 visits [151.0, 863.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2254 q_vals: [-9.385, -8.047, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1340 1 visits [151.0, 864.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2255 q_vals: [-9.385, -8.044, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1341 1 visits [151.0, 865.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2255 q_vals: [-9.385, -8.042, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1342 1 visits [151.0, 866.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2256 q_vals: [-9.385, -8.041, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1343 1 visits [151.0, 867.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2258 q_vals: [-9.385, -8.044, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1344 1 visits [151.0, 868.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2259 q_vals: [-9.385, -8.042, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1345 1 visits [151.0, 869.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2260 q_vals: [-9.385, -8.039, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1346 1 visits [151.0, 870.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2263 q_vals: [-9.385, -8.037, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2265, "number_of_timesteps": 42466, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1347 1 visits [151.0, 871.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2265 q_vals: [-9.385, -8.036, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1348 1 visits [151.0, 872.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2266 q_vals: [-9.385, -8.033, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1349 1 visits [151.0, 873.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2268 q_vals: [-9.385, -8.034, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1350 1 visits [151.0, 874.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2270 q_vals: [-9.385, -8.037, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1351 1 visits [151.0, 875.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2274 q_vals: [-9.385, -8.041, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2275, "number_of_timesteps": 42655, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1352 1 visits [151.0, 876.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2275 q_vals: [-9.385, -8.04, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1353 1 visits [151.0, 877.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2278 q_vals: [-9.385, -8.037, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1354 1 visits [151.0, 878.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2279 q_vals: [-9.385, -8.028, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1355 1 visits [151.0, 879.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2281 q_vals: [-9.385, -8.019, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1356 1 visits [151.0, 880.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2283 q_vals: [-9.385, -8.018, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2285, "number_of_timesteps": 42799, "per_episode_reward": 15.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1357 1 visits [151.0, 881.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2285 q_vals: [-9.385, -8.009, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1358 1 visits [151.0, 882.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2286 q_vals: [-9.385, -8.007, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1359 1 visits [151.0, 883.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2287 q_vals: [-9.385, -8.011, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1360 1 visits [151.0, 884.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2289 q_vals: [-9.385, -8.009, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1361 1 visits [151.0, 885.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2291 q_vals: [-9.385, -8.008, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1362 1 visits [151.0, 886.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2291 q_vals: [-9.385, -8.006, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1363 1 visits [151.0, 887.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2293 q_vals: [-9.385, -8.006, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1364 1 visits [151.0, 888.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2294 q_vals: [-9.385, -7.997, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2297, "number_of_timesteps": 43049, "per_episode_reward": 15.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1365 1 visits [151.0, 889.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2297 q_vals: [-9.385, -8.001, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1366 1 visits [151.0, 890.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2299 q_vals: [-9.385, -7.992, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1367 1 visits [151.0, 891.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2299 q_vals: [-9.385, -7.992, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1368 1 visits [151.0, 892.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2302 q_vals: [-9.385, -7.99, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1369 1 visits [151.0, 893.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2302 q_vals: [-9.385, -7.987, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1370 1 visits [151.0, 894.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2303 q_vals: [-9.385, -7.991, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1371 1 visits [151.0, 895.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2305 q_vals: [-9.385, -7.982, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2307, "number_of_timesteps": 43231, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1372 1 visits [151.0, 896.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2307 q_vals: [-9.385, -7.979, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1373 1 visits [151.0, 897.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2307 q_vals: [-9.385, -7.976, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1374 1 visits [151.0, 898.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2308 q_vals: [-9.385, -7.976, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1375 1 visits [151.0, 899.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2310 q_vals: [-9.385, -7.967, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1376 1 visits [151.0, 900.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2310 q_vals: [-9.385, -7.971, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1377 1 visits [151.0, 901.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2312 q_vals: [-9.385, -7.969, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1378 1 visits [151.0, 902.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2315 q_vals: [-9.385, -7.966, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1379 1 visits [151.0, 903.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2316 q_vals: [-9.385, -7.964, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2317, "number_of_timesteps": 43510, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1380 1 visits [151.0, 904.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2317 q_vals: [-9.385, -7.968, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1381 1 visits [151.0, 905.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2322 q_vals: [-9.385, -7.967, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1382 1 visits [151.0, 906.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2322 q_vals: [-9.385, -7.963, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1383 1 visits [151.0, 907.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2324 q_vals: [-9.385, -7.962, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1384 1 visits [151.0, 908.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2326 q_vals: [-9.385, -7.96, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2327, "number_of_timesteps": 43663, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1385 1 visits [151.0, 909.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2327 q_vals: [-9.385, -7.959, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1386 1 visits [151.0, 910.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2328 q_vals: [-9.385, -7.95, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1387 1 visits [151.0, 911.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2331 q_vals: [-9.385, -7.948, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1388 1 visits [151.0, 912.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2333 q_vals: [-9.385, -7.951, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1389 1 visits [151.0, 913.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2335 q_vals: [-9.385, -7.949, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2338, "number_of_timesteps": 43843, "per_episode_reward": 15.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1390 1 visits [151.0, 914.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2338 q_vals: [-9.385, -7.947, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1391 1 visits [151.0, 915.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2339 q_vals: [-9.385, -7.938, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1392 1 visits [151.0, 916.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2341 q_vals: [-9.385, -7.935, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1393 1 visits [151.0, 917.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2342 q_vals: [-9.385, -7.935, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1394 1 visits [151.0, 918.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2344 q_vals: [-9.385, -7.935, -9.574, -9.498, -9.38, -9.962, -9.512]
[151.0, 919.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2347 q_vals: [-9.385, -7.933, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2348, "number_of_timesteps": 44031, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1396 1 visits [151.0, 920.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2348 q_vals: [-9.385, -7.93, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1397 1 visits [151.0, 921.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2351 q_vals: [-9.385, -7.928, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1398 1 visits [151.0, 922.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2351 q_vals: [-9.385, -7.925, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1399 1 visits [151.0, 923.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2353 q_vals: [-9.385, -7.923, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1400 1 visits [151.0, 924.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2353 q_vals: [-9.385, -7.923, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1401 1 visits [151.0, 925.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2356 q_vals: [-9.385, -7.922, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1402 1 visits [151.0, 926.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2357 q_vals: [-9.385, -7.913, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2358, "number_of_timesteps": 44214, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1403 1 visits [151.0, 927.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2358 q_vals: [-9.385, -7.905, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1404 1 visits [151.0, 928.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2358 q_vals: [-9.385, -7.902, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1405 1 visits [151.0, 929.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2360 q_vals: [-9.385, -7.902, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1406 1 visits [151.0, 930.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2360 q_vals: [-9.385, -7.899, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1407 1 visits [151.0, 931.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2360 q_vals: [-9.385, -7.903, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1408 1 visits [151.0, 932.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2364 q_vals: [-9.385, -7.894, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1409 1 visits [151.0, 933.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2365 q_vals: [-9.385, -7.898, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1410 1 visits [151.0, 934.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2366 q_vals: [-9.385, -7.897, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1411 1 visits [151.0, 935.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2367 q_vals: [-9.385, -7.895, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2368, "number_of_timesteps": 44507, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1412 1 visits [151.0, 936.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2368 q_vals: [-9.385, -7.886, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1413 1 visits [151.0, 937.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2372 q_vals: [-9.385, -7.878, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1414 1 visits [151.0, 938.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2373 q_vals: [-9.385, -7.876, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1415 1 visits [151.0, 939.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2376 q_vals: [-9.385, -7.875, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1416 1 visits [151.0, 940.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2377 q_vals: [-9.385, -7.873, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2378, "number_of_timesteps": 44679, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1417 1 visits [151.0, 941.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2378 q_vals: [-9.385, -7.87, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1418 1 visits [151.0, 942.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2380 q_vals: [-9.385, -7.867, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1419 1 visits [151.0, 943.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2380 q_vals: [-9.385, -7.865, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1420 1 visits [151.0, 944.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2383 q_vals: [-9.385, -7.86, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1421 1 visits [151.0, 945.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2385 q_vals: [-9.385, -7.857, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1422 1 visits [151.0, 946.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2386 q_vals: [-9.385, -7.854, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1423 1 visits [151.0, 947.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2387 q_vals: [-9.385, -7.858, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2390, "number_of_timesteps": 44939, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1424 1 visits [151.0, 948.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2390 q_vals: [-9.385, -7.857, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1425 1 visits [151.0, 949.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2392 q_vals: [-9.385, -7.854, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1426 1 visits [151.0, 950.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2392 q_vals: [-9.385, -7.846, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1427 1 visits [151.0, 951.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2394 q_vals: [-9.385, -7.843, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1428 1 visits [151.0, 952.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2395 q_vals: [-9.385, -7.835, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1429 1 visits [151.0, 953.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2395 q_vals: [-9.385, -7.832, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1430 1 visits [151.0, 954.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2397 q_vals: [-9.385, -7.824, -9.574, -9.498, -9.38, -9.962, -9.512]
q_vals: [-9.385, -7.821, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2401, "number_of_timesteps": 45180, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
Step 1432 1 visits [151.0, 956.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2401 q_vals: [-9.385, -7.819, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1433 1 visits [151.0, 957.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2401 q_vals: [-9.385, -7.813, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1434 1 visits [151.0, 958.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2403 q_vals: [-9.385, -7.811, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1435 1 visits [151.0, 959.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2404 q_vals: [-9.385, -7.808, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1436 1 visits [151.0, 960.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2406 q_vals: [-9.385, -7.807, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1437 1 visits [151.0, 961.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2407 q_vals: [-9.385, -7.805, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1438 1 visits [151.0, 962.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2410 q_vals: [-9.385, -7.803, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2413, "number_of_timesteps": 45421, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1439 1 visits [151.0, 963.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2413 q_vals: [-9.385, -7.807, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1440 1 visits [151.0, 964.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2413 q_vals: [-9.385, -7.81, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1441 1 visits [151.0, 965.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2417 q_vals: [-9.385, -7.807, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1442 1 visits [151.0, 966.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2418 q_vals: [-9.385, -7.799, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1443 1 visits [151.0, 967.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2419 q_vals: [-9.385, -7.796, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1444 1 visits [151.0, 968.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2422 q_vals: [-9.385, -7.793, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2423, "number_of_timesteps": 45590, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1445 1 visits [151.0, 969.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2423 q_vals: [-9.385, -7.791, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1446 1 visits [151.0, 970.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2425 q_vals: [-9.385, -7.788, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1447 1 visits [151.0, 971.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2427 q_vals: [-9.385, -7.786, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1448 1 visits [151.0, 972.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2430 q_vals: [-9.385, -7.778, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1449 1 visits [151.0, 973.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2430 q_vals: [-9.385, -7.777, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1450 1 visits [151.0, 974.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2432 q_vals: [-9.385, -7.774, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2433, "number_of_timesteps": 45760, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 1451 1 visits [151.0, 975.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2433 q_vals: [-9.385, -7.771, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1452 1 visits [151.0, 976.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2434 q_vals: [-9.385, -7.77, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1453 1 visits [151.0, 977.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2436 q_vals: [-9.385, -7.774, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1454 1 visits [151.0, 978.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2437 q_vals: [-9.385, -7.772, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1455 1 visits [151.0, 979.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2439 q_vals: [-9.385, -7.775, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1456 1 visits [151.0, 980.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2439 q_vals: [-9.385, -7.778, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1457 1 visits [151.0, 981.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2439 q_vals: [-9.385, -7.782, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1458 1 visits [151.0, 982.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2442 q_vals: [-9.385, -7.779, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2443, "number_of_timesteps": 46004, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
Step 1459 1 visits [151.0, 983.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2443 q_vals: [-9.385, -7.776, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1460 1 visits [151.0, 984.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2445 q_vals: [-9.385, -7.78, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1461 1 visits [151.0, 985.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2447 q_vals: [-9.385, -7.778, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1462 1 visits [151.0, 986.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2447 q_vals: [-9.385, -7.775, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1463 1 visits [151.0, 987.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2449 q_vals: [-9.385, -7.773, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1464 1 visits [151.0, 988.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2450 q_vals: [-9.385, -7.77, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1465 1 visits [151.0, 989.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2452 q_vals: [-9.385, -7.773, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2455, "number_of_timesteps": 46271, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1466 1 visits [151.0, 990.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2455 q_vals: [-9.385, -7.773, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1467 1 visits [151.0, 991.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2455 q_vals: [-9.385, -7.771, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1468 1 visits [151.0, 992.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2458 q_vals: [-9.385, -7.763, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1469 1 visits [151.0, 993.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2459 q_vals: [-9.385, -7.761, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1470 1 visits [151.0, 994.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2461 q_vals: [-9.385, -7.76, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1471 1 visits [151.0, 995.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2464 q_vals: [-9.385, -7.763, -9.574, -9.498, -9.38, -9.962, -9.512]
{"total_number_of_episodes": 2467, "number_of_timesteps": 46475, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1472 1 visits [151.0, 996.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2467 q_vals: [-9.385, -7.761, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1473 1 visits [151.0, 997.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2468 q_vals: [-9.385, -7.765, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1474 1 visits [151.0, 998.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2470 q_vals: [-9.385, -7.762, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1475 1 visits [151.0, 999.0, 43.0, 62.0, 148.0, 12.0, 60.0]  episode_count: 2472 q_vals: [-9.385, -7.754, -9.574, -9.498, -9.38, -9.962, -9.512]
Step 1476 1 visits [0.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 2475 q_vals: [0.0, -inf, 0.0, 0.0, 0.0, 0.0, 0.0]
{"total_number_of_episodes": 2477, "number_of_timesteps": 46621, "per_episode_reward": 13.43, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.2857142857142847},
Step 1477 0 visits [1.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 2477 q_vals: [-6.914, -inf, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1478 2 visits [1.0, 1000.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 2479 q_vals: [-6.914, -inf, -8.182, 0.0, 0.0, 0.0, 0.0]
Step 1479 3 visits [1.0, 1000.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 2481 q_vals: [-6.914, -inf, -8.182, 0.0, 0.0, 0.0, 0.0]
Step 1480 4 visits [1.0, 1000.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 2482 q_vals: [-6.914, -inf, -8.182, 0.0, 0.0, 0.0, 0.0]
Step 1481 5 visits [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 2484 q_vals: [-6.914, -inf, -8.182, 0.0, 0.0, -9.303, 0.0]
Step 1482 6 visits [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 2485 q_vals: [-6.914, -inf, -8.182, 0.0, 0.0, -9.303, -7.919]
Step 1483 3 visits [1.0, 1000.0, 1.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 2486 q_vals: [-6.914, -inf, -8.182, 0.0, 0.0, -9.303, -7.919]
{"total_number_of_episodes": 2488, "number_of_timesteps": 46804, "per_episode_reward": 13.43, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.2857142857142847},
Step 1484 4 visits [1.0, 1000.0, 1.0, 2.0, 2.0, 1.0, 1.0]  episode_count: 2488 q_vals: [-6.914, -inf, -8.182, 0.0, 0.0, -9.303, -7.919]
Step 1485 3 visits [1.0, 1000.0, 1.0, 3.0, 2.0, 1.0, 1.0]  episode_count: 2491 q_vals: [-6.914, -inf, -8.182, -2.333, 0.0, -9.303, -7.919]
Step 1486 4 visits [1.0, 1000.0, 1.0, 3.0, 3.0, 1.0, 1.0]  episode_count: 2493 q_vals: [-6.914, -inf, -8.182, -2.333, -2.263, -9.303, -7.919]
Step 1487 4 visits [1.0, 1000.0, 1.0, 3.0, 4.0, 1.0, 1.0]  episode_count: 2494 q_vals: [-6.914, -inf, -8.182, -2.333, -3.086, -9.303, -7.919]
Step 1488 3 visits [1.0, 1000.0, 1.0, 4.0, 4.0, 1.0, 1.0]  episode_count: 2497 q_vals: [-6.914, -inf, -8.182, -3.116, -3.086, -9.303, -7.919]
{"total_number_of_episodes": 2498, "number_of_timesteps": 46981, "per_episode_reward": 13.43, "episode_reward_trend_value": -0.025396825396825383, "biggest_recent_change": 2.2857142857142847},
Step 1489 4 visits [1.0, 1000.0, 1.0, 4.0, 5.0, 1.0, 1.0]  episode_count: 2498 q_vals: [-6.914, -inf, -8.182, -3.116, -3.775, -9.303, -7.919]
Step 1490 3 visits [1.0, 1000.0, 1.0, 5.0, 5.0, 1.0, 1.0]  episode_count: 2501 q_vals: [-6.914, -inf, -8.182, -4.077, -3.775, -9.303, -7.919]
Step 1491 4 visits [1.0, 1000.0, 1.0, 5.0, 6.0, 1.0, 1.0]  episode_count: 2502 q_vals: [-6.914, -inf, -8.182, -4.077, -4.213, -9.303, -7.919]
Step 1492 3 visits [1.0, 1000.0, 1.0, 6.0, 6.0, 1.0, 1.0]  episode_count: 2504 q_vals: [-6.914, -inf, -8.182, -3.398, -4.213, -9.303, -7.919]
Step 1493 3 visits [1.0, 1000.0, 1.0, 7.0, 6.0, 1.0, 1.0]  episode_count: 2507 q_vals: [-6.914, -inf, -8.182, -3.721, -4.213, -9.303, -7.919]
{"total_number_of_episodes": 2509, "number_of_timesteps": 47142, "per_episode_reward": 13.36, "episode_reward_trend_value": -0.026190476190476174, "biggest_recent_change": 2.2857142857142847},
Step 1494 3 visits [1.0, 1000.0, 1.0, 8.0, 6.0, 1.0, 1.0]  episode_count: 2509 q_vals: [-6.914, -inf, -8.182, -4.067, -4.213, -9.303, -7.919]
Step 1495 3 visits [1.0, 1000.0, 1.0, 9.0, 6.0, 1.0, 1.0]  episode_count: 2512 q_vals: [-6.914, -inf, -8.182, -4.38, -4.213, -9.303, -7.919]
Step 1496 4 visits [1.0, 1000.0, 1.0, 9.0, 7.0, 1.0, 1.0]  episode_count: 2515 q_vals: [-6.914, -inf, -8.182, -4.38, -4.42, -9.303, -7.919]
Step 1497 4 visits [1.0, 1000.0, 1.0, 9.0, 8.0, 1.0, 1.0]  episode_count: 2517 q_vals: [-6.914, -inf, -8.182, -4.38, -3.867, -9.303, -7.919]
{"total_number_of_episodes": 2519, "number_of_timesteps": 47276, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.026984126984126965, "biggest_recent_change": 2.2857142857142847},
Step 1498 4 visits [1.0, 1000.0, 1.0, 9.0, 9.0, 1.0, 1.0]  episode_count: 2519 q_vals: [-6.914, -inf, -8.182, -4.38, -4.07, -9.303, -7.919]
Step 1499 4 visits [1.0, 1000.0, 1.0, 9.0, 10.0, 1.0, 1.0]  episode_count: 2520 q_vals: [-6.914, -inf, -8.182, -4.38, -4.242, -9.303, -7.919]
Step 1500 4 visits [1.0, 1000.0, 1.0, 9.0, 11.0, 1.0, 1.0]  episode_count: 2521 q_vals: [-6.914, -inf, -8.182, -4.38, -5.02, -9.303, -7.919]
Step 1501 3 visits [1.0, 1000.0, 1.0, 10.0, 11.0, 1.0, 1.0]  episode_count: 2526 q_vals: [-6.914, -inf, -8.182, -4.514, -5.02, -9.303, -7.919]
Step 1502 3 visits [1.0, 1000.0, 1.0, 11.0, 11.0, 1.0, 1.0]  episode_count: 2528 q_vals: [-6.914, -inf, -8.182, -4.598, -5.02, -9.303, -7.919]
{"total_number_of_episodes": 2529, "number_of_timesteps": 47420, "per_episode_reward": 13.36, "episode_reward_trend_value": -0.026190476190476174, "biggest_recent_change": 2.2857142857142847},
Step 1503 3 visits [1.0, 1000.0, 1.0, 12.0, 11.0, 1.0, 1.0]  episode_count: 2529 q_vals: [-6.914, -inf, -8.182, -4.905, -5.02, -9.303, -7.919]
Step 1504 3 visits [1.0, 1000.0, 1.0, 13.0, 11.0, 1.0, 1.0]  episode_count: 2530 q_vals: [-6.914, -inf, -8.182, -5.512, -5.02, -9.303, -7.919]
Step 1505 4 visits [1.0, 1000.0, 1.0, 13.0, 12.0, 1.0, 1.0]  episode_count: 2533 q_vals: [-6.914, -inf, -8.182, -5.512, -4.602, -9.303, -7.919]
Step 1506 4 visits [1.0, 1000.0, 1.0, 13.0, 13.0, 1.0, 1.0]  episode_count: 2535 q_vals: [-6.914, -inf, -8.182, -5.512, -4.674, -9.303, -7.919]
Step 1507 4 visits [1.0, 1000.0, 1.0, 13.0, 14.0, 1.0, 1.0]  episode_count: 2538 q_vals: [-6.914, -inf, -8.182, -5.512, -4.34, -9.303, -7.919]
Step 1508 4 visits [1.0, 1000.0, 1.0, 13.0, 15.0, 1.0, 1.0]  episode_count: 2538 q_vals: [-6.914, -inf, -8.182, -5.512, -4.051, -9.303, -7.919]
{"total_number_of_episodes": 2541, "number_of_timesteps": 47610, "per_episode_reward": 13.43, "episode_reward_trend_value": -0.025396825396825383, "biggest_recent_change": 2.2857142857142847},
Step 1509 4 visits [1.0, 1000.0, 1.0, 13.0, 16.0, 1.0, 1.0]  episode_count: 2541 q_vals: [-6.914, -inf, -8.182, -5.512, -4.598, -9.303, -7.919]
Step 1510 4 visits [1.0, 1000.0, 1.0, 13.0, 17.0, 1.0, 1.0]  episode_count: 2544 q_vals: [-6.914, -inf, -8.182, -5.512, -4.327, -9.303, -7.919]
Step 1511 4 visits [1.0, 1000.0, 1.0, 13.0, 18.0, 1.0, 1.0]  episode_count: 2544 q_vals: [-6.914, -inf, -8.182, -5.512, -4.087, -9.303, -7.919]
Step 1512 4 visits [1.0, 1000.0, 1.0, 13.0, 19.0, 1.0, 1.0]  episode_count: 2546 q_vals: [-6.914, -inf, -8.182, -5.512, -4.192, -9.303, -7.919]
Step 1513 4 visits [1.0, 1000.0, 1.0, 13.0, 20.0, 1.0, 1.0]  episode_count: 2546 q_vals: [-6.914, -inf, -8.182, -5.512, -3.983, -9.303, -7.919]
Step 1514 4 visits [1.0, 1000.0, 1.0, 13.0, 21.0, 1.0, 1.0]  episode_count: 2548 q_vals: [-6.914, -inf, -8.182, -5.512, -3.793, -9.303, -7.919]
Step 1515 4 visits [1.0, 1000.0, 1.0, 13.0, 22.0, 1.0, 1.0]  episode_count: 2549 q_vals: [-6.914, -inf, -8.182, -5.512, -3.621, -9.303, -7.919]
Step 1516 4 visits [1.0, 1000.0, 1.0, 13.0, 23.0, 1.0, 1.0]  episode_count: 2550 q_vals: [-6.914, -inf, -8.182, -5.512, -3.774, -9.303, -7.919]
{"total_number_of_episodes": 2551, "number_of_timesteps": 47805, "per_episode_reward": 13.36, "episode_reward_trend_value": -0.026190476190476174, "biggest_recent_change": 2.2857142857142847},
Step 1517 4 visits [1.0, 1000.0, 1.0, 13.0, 24.0, 1.0, 1.0]  episode_count: 2551 q_vals: [-6.914, -inf, -8.182, -5.512, -3.841, -9.303, -7.919]
Step 1518 4 visits [1.0, 1000.0, 1.0, 13.0, 25.0, 1.0, 1.0]  episode_count: 2553 q_vals: [-6.914, -inf, -8.182, -5.512, -3.961, -9.303, -7.919]
Step 1519 4 visits [1.0, 1000.0, 1.0, 13.0, 26.0, 1.0, 1.0]  episode_count: 2555 q_vals: [-6.914, -inf, -8.182, -5.512, -4.3, -9.303, -7.919]
Step 1520 4 visits [1.0, 1000.0, 1.0, 13.0, 27.0, 1.0, 1.0]  episode_count: 2557 q_vals: [-6.914, -inf, -8.182, -5.512, -4.264, -9.303, -7.919]
Step 1521 4 visits [1.0, 1000.0, 1.0, 13.0, 28.0, 1.0, 1.0]  episode_count: 2558 q_vals: [-6.914, -inf, -8.182, -5.512, -4.112, -9.303, -7.919]
Step 1522 4 visits [1.0, 1000.0, 1.0, 13.0, 29.0, 1.0, 1.0]  episode_count: 2559 q_vals: [-6.914, -inf, -8.182, -5.512, -4.411, -9.303, -7.919]
{"total_number_of_episodes": 2562, "number_of_timesteps": 48042, "per_episode_reward": 13.36, "episode_reward_trend_value": -0.026190476190476174, "biggest_recent_change": 2.2857142857142847},
Step 1523 4 visits [1.0, 1000.0, 1.0, 13.0, 30.0, 1.0, 1.0]  episode_count: 2562 q_vals: [-6.914, -inf, -8.182, -5.512, -4.691, -9.303, -7.919]
Step 1524 4 visits [1.0, 1000.0, 1.0, 13.0, 31.0, 1.0, 1.0]  episode_count: 2562 q_vals: [-6.914, -inf, -8.182, -5.512, -4.953, -9.303, -7.919]
Step 1525 4 visits [1.0, 1000.0, 1.0, 13.0, 32.0, 1.0, 1.0]  episode_count: 2564 q_vals: [-6.914, -inf, -8.182, -5.512, -4.978, -9.303, -7.919]
Step 1526 4 visits [1.0, 1000.0, 1.0, 13.0, 33.0, 1.0, 1.0]  episode_count: 2568 q_vals: [-6.914, -inf, -8.182, -5.512, -5.058, -9.303, -7.919]
Step 1527 4 visits [1.0, 1000.0, 1.0, 13.0, 34.0, 1.0, 1.0]  episode_count: 2568 q_vals: [-6.914, -inf, -8.182, -5.512, -5.068, -9.303, -7.919]
Step 1528 4 visits [1.0, 1000.0, 1.0, 13.0, 35.0, 1.0, 1.0]  episode_count: 2569 q_vals: [-6.914, -inf, -8.182, -5.512, -5.094, -9.303, -7.919]
Step 1529 4 visits [1.0, 1000.0, 1.0, 13.0, 36.0, 1.0, 1.0]  episode_count: 2570 q_vals: [-6.914, -inf, -8.182, -5.512, -4.952, -9.303, -7.919]
{"total_number_of_episodes": 2572, "number_of_timesteps": 48232, "per_episode_reward": 13.36, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1530 4 visits [1.0, 1000.0, 1.0, 13.0, 37.0, 1.0, 1.0]  episode_count: 2572 q_vals: [-6.914, -inf, -8.182, -5.512, -4.964, -9.303, -7.919]
Step 1531 4 visits [1.0, 1000.0, 1.0, 13.0, 38.0, 1.0, 1.0]  episode_count: 2574 q_vals: [-6.914, -inf, -8.182, -5.512, -5.052, -9.303, -7.919]
Step 1532 4 visits [1.0, 1000.0, 1.0, 13.0, 39.0, 1.0, 1.0]  episode_count: 2574 q_vals: [-6.914, -inf, -8.182, -5.512, -4.922, -9.303, -7.919]
Step 1533 4 visits [1.0, 1000.0, 1.0, 13.0, 40.0, 1.0, 1.0]  episode_count: 2575 q_vals: [-6.914, -inf, -8.182, -5.512, -4.799, -9.303, -7.919]
Step 1534 4 visits [1.0, 1000.0, 1.0, 13.0, 41.0, 1.0, 1.0]  episode_count: 2579 q_vals: [-6.914, -inf, -8.182, -5.512, -4.682, -9.303, -7.919]
Step 1535 4 visits [1.0, 1000.0, 1.0, 13.0, 42.0, 1.0, 1.0]  episode_count: 2580 q_vals: [-6.914, -inf, -8.182, -5.512, -4.697, -9.303, -7.919]
Step 1536 4 visits [1.0, 1000.0, 1.0, 13.0, 43.0, 1.0, 1.0]  episode_count: 2581 q_vals: [-6.914, -inf, -8.182, -5.512, -4.588, -9.303, -7.919]
{"total_number_of_episodes": 2584, "number_of_timesteps": 48492, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1537 4 visits [1.0, 1000.0, 1.0, 13.0, 44.0, 1.0, 1.0]  episode_count: 2584 q_vals: [-6.914, -inf, -8.182, -5.512, -4.611, -9.303, -7.919]
Step 1538 4 visits [1.0, 1000.0, 1.0, 13.0, 45.0, 1.0, 1.0]  episode_count: 2586 q_vals: [-6.914, -inf, -8.182, -5.512, -4.653, -9.303, -7.919]
Step 1539 4 visits [1.0, 1000.0, 1.0, 13.0, 46.0, 1.0, 1.0]  episode_count: 2587 q_vals: [-6.914, -inf, -8.182, -5.512, -4.552, -9.303, -7.919]
Step 1540 4 visits [1.0, 1000.0, 1.0, 13.0, 47.0, 1.0, 1.0]  episode_count: 2591 q_vals: [-6.914, -inf, -8.182, -5.512, -4.455, -9.303, -7.919]
Step 1541 4 visits [1.0, 1000.0, 1.0, 13.0, 48.0, 1.0, 1.0]  episode_count: 2591 q_vals: [-6.914, -inf, -8.182, -5.512, -4.49, -9.303, -7.919]
Step 1542 4 visits [1.0, 1000.0, 1.0, 13.0, 49.0, 1.0, 1.0]  episode_count: 2591 q_vals: [-6.914, -inf, -8.182, -5.512, -4.399, -9.303, -7.919]
{"total_number_of_episodes": 2594, "number_of_timesteps": 48637, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1543 4 visits [1.0, 1000.0, 1.0, 13.0, 50.0, 1.0, 1.0]  episode_count: 2594 q_vals: [-6.914, -inf, -8.182, -5.512, -4.441, -9.303, -7.919]
Step 1544 4 visits [1.0, 1000.0, 1.0, 13.0, 51.0, 1.0, 1.0]  episode_count: 2595 q_vals: [-6.914, -inf, -8.182, -5.512, -4.354, -9.303, -7.919]
Step 1545 4 visits [1.0, 1000.0, 1.0, 13.0, 52.0, 1.0, 1.0]  episode_count: 2597 q_vals: [-6.914, -inf, -8.182, -5.512, -4.377, -9.303, -7.919]
Step 1546 4 visits [1.0, 1000.0, 1.0, 13.0, 53.0, 1.0, 1.0]  episode_count: 2600 q_vals: [-6.914, -inf, -8.182, -5.512, -4.294, -9.303, -7.919]
Step 1547 4 visits [1.0, 1000.0, 1.0, 13.0, 54.0, 1.0, 1.0]  episode_count: 2603 q_vals: [-6.914, -inf, -8.182, -5.512, -4.215, -9.303, -7.919]
Step 1548 4 visits [1.0, 1000.0, 1.0, 13.0, 55.0, 1.0, 1.0]  episode_count: 2603 q_vals: [-6.914, -inf, -8.182, -5.512, -4.138, -9.303, -7.919]
{"total_number_of_episodes": 2607, "number_of_timesteps": 48878, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1549 4 visits [1.0, 1000.0, 1.0, 13.0, 56.0, 1.0, 1.0]  episode_count: 2607 q_vals: [-6.914, -inf, -8.182, -5.512, -4.158, -9.303, -7.919]
Step 1550 4 visits [1.0, 1000.0, 1.0, 13.0, 57.0, 1.0, 1.0]  episode_count: 2609 q_vals: [-6.914, -inf, -8.182, -5.512, -4.203, -9.303, -7.919]
Step 1551 4 visits [1.0, 1000.0, 1.0, 13.0, 58.0, 1.0, 1.0]  episode_count: 2611 q_vals: [-6.914, -inf, -8.182, -5.512, -4.13, -9.303, -7.919]
Step 1552 4 visits [1.0, 1000.0, 1.0, 13.0, 59.0, 1.0, 1.0]  episode_count: 2614 q_vals: [-6.914, -inf, -8.182, -5.512, -4.175, -9.303, -7.919]
Step 1553 4 visits [1.0, 1000.0, 1.0, 13.0, 60.0, 1.0, 1.0]  episode_count: 2615 q_vals: [-6.914, -inf, -8.182, -5.512, -4.319, -9.303, -7.919]
{"total_number_of_episodes": 2618, "number_of_timesteps": 49020, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1554 4 visits [1.0, 1000.0, 1.0, 13.0, 61.0, 1.0, 1.0]  episode_count: 2618 q_vals: [-6.914, -inf, -8.182, -5.512, -4.248, -9.303, -7.919]
Step 1555 4 visits [1.0, 1000.0, 1.0, 13.0, 62.0, 1.0, 1.0]  episode_count: 2621 q_vals: [-6.914, -inf, -8.182, -5.512, -4.265, -9.303, -7.919]
Step 1556 4 visits [1.0, 1000.0, 1.0, 13.0, 63.0, 1.0, 1.0]  episode_count: 2622 q_vals: [-6.914, -inf, -8.182, -5.512, -4.197, -9.303, -7.919]
Step 1557 4 visits [1.0, 1000.0, 1.0, 13.0, 64.0, 1.0, 1.0]  episode_count: 2624 q_vals: [-6.914, -inf, -8.182, -5.512, -4.132, -9.303, -7.919]
{"total_number_of_episodes": 2628, "number_of_timesteps": 49166, "per_episode_reward": 13.21, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714235},
Step 1558 4 visits [1.0, 1000.0, 1.0, 13.0, 65.0, 1.0, 1.0]  episode_count: 2628 q_vals: [-6.914, -inf, -8.182, -5.512, -4.151, -9.303, -7.919]
Step 1559 4 visits [1.0, 1000.0, 1.0, 13.0, 66.0, 1.0, 1.0]  episode_count: 2629 q_vals: [-6.914, -inf, -8.182, -5.512, -4.169, -9.303, -7.919]
Step 1560 4 visits [1.0, 1000.0, 1.0, 13.0, 67.0, 1.0, 1.0]  episode_count: 2630 q_vals: [-6.914, -inf, -8.182, -5.512, -4.298, -9.303, -7.919]
Step 1561 4 visits [1.0, 1000.0, 1.0, 13.0, 68.0, 1.0, 1.0]  episode_count: 2632 q_vals: [-6.914, -inf, -8.182, -5.512, -4.235, -9.303, -7.919]
Step 1562 4 visits [1.0, 1000.0, 1.0, 13.0, 69.0, 1.0, 1.0]  episode_count: 2633 q_vals: [-6.914, -inf, -8.182, -5.512, -4.359, -9.303, -7.919]
Step 1563 4 visits [1.0, 1000.0, 1.0, 13.0, 70.0, 1.0, 1.0]  episode_count: 2634 q_vals: [-6.914, -inf, -8.182, -5.512, -4.297, -9.303, -7.919]
{"total_number_of_episodes": 2639, "number_of_timesteps": 49346, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
Step 1564 4 visits [1.0, 1000.0, 1.0, 13.0, 71.0, 1.0, 1.0]  episode_count: 2639 q_vals: [-6.914, -inf, -8.182, -5.512, -4.328, -9.303, -7.919]
Step 1565 4 visits [1.0, 1000.0, 1.0, 13.0, 72.0, 1.0, 1.0]  episode_count: 2639 q_vals: [-6.914, -inf, -8.182, -5.512, -4.268, -9.303, -7.919]
Step 1566 4 visits [1.0, 1000.0, 1.0, 13.0, 73.0, 1.0, 1.0]  episode_count: 2641 q_vals: [-6.914, -inf, -8.182, -5.512, -4.385, -9.303, -7.919]
Step 1567 4 visits [1.0, 1000.0, 1.0, 13.0, 74.0, 1.0, 1.0]  episode_count: 2644 q_vals: [-6.914, -inf, -8.182, -5.512, -4.377, -9.303, -7.919]
Step 1568 4 visits [1.0, 1000.0, 1.0, 13.0, 75.0, 1.0, 1.0]  episode_count: 2645 q_vals: [-6.914, -inf, -8.182, -5.512, -4.319, -9.303, -7.919]
Step 1569 4 visits [1.0, 1000.0, 1.0, 13.0, 76.0, 1.0, 1.0]  episode_count: 2646 q_vals: [-6.914, -inf, -8.182, -5.512, -4.322, -9.303, -7.919]
{"total_number_of_episodes": 2649, "number_of_timesteps": 49503, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
Step 1570 4 visits [1.0, 1000.0, 1.0, 13.0, 77.0, 1.0, 1.0]  episode_count: 2649 q_vals: [-6.914, -inf, -8.182, -5.512, -4.346, -9.303, -7.919]
Step 1571 4 visits [1.0, 1000.0, 1.0, 13.0, 78.0, 1.0, 1.0]  episode_count: 2650 q_vals: [-6.914, -inf, -8.182, -5.512, -4.454, -9.303, -7.919]
Step 1572 4 visits [1.0, 1000.0, 1.0, 13.0, 79.0, 1.0, 1.0]  episode_count: 2651 q_vals: [-6.914, -inf, -8.182, -5.512, -4.398, -9.303, -7.919]
Step 1573 4 visits [1.0, 1000.0, 1.0, 13.0, 80.0, 1.0, 1.0]  episode_count: 2652 q_vals: [-6.914, -inf, -8.182, -5.512, -4.503, -9.303, -7.919]
Step 1574 4 visits [1.0, 1000.0, 1.0, 13.0, 81.0, 1.0, 1.0]  episode_count: 2655 q_vals: [-6.914, -inf, -8.182, -5.512, -4.507, -9.303, -7.919]
Step 1575 4 visits [1.0, 1000.0, 1.0, 13.0, 82.0, 1.0, 1.0]  episode_count: 2657 q_vals: [-6.914, -inf, -8.182, -5.512, -4.608, -9.303, -7.919]
Step 1576 4 visits [1.0, 1000.0, 1.0, 13.0, 83.0, 1.0, 1.0]  episode_count: 2658 q_vals: [-6.914, -inf, -8.182, -5.512, -4.614, -9.303, -7.919]
{"total_number_of_episodes": 2660, "number_of_timesteps": 49721, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
Step 1577 4 visits [1.0, 1000.0, 1.0, 13.0, 84.0, 1.0, 1.0]  episode_count: 2660 q_vals: [-6.914, -inf, -8.182, -5.512, -4.625, -9.303, -7.919]
Step 1578 4 visits [1.0, 1000.0, 1.0, 13.0, 85.0, 1.0, 1.0]  episode_count: 2662 q_vals: [-6.914, -inf, -8.182, -5.512, -4.571, -9.303, -7.919]
Step 1579 4 visits [1.0, 1000.0, 1.0, 13.0, 86.0, 1.0, 1.0]  episode_count: 2664 q_vals: [-6.914, -inf, -8.182, -5.512, -4.584, -9.303, -7.919]
Step 1580 4 visits [1.0, 1000.0, 1.0, 13.0, 87.0, 1.0, 1.0]  episode_count: 2664 q_vals: [-6.914, -inf, -8.182, -5.512, -4.593, -9.303, -7.919]
Step 1581 4 visits [1.0, 1000.0, 1.0, 13.0, 88.0, 1.0, 1.0]  episode_count: 2665 q_vals: [-6.914, -inf, -8.182, -5.512, -4.541, -9.303, -7.919]
Step 1582 4 visits [1.0, 1000.0, 1.0, 13.0, 89.0, 1.0, 1.0]  episode_count: 2669 q_vals: [-6.914, -inf, -8.182, -5.512, -4.572, -9.303, -7.919]
Step 1583 4 visits [1.0, 1000.0, 1.0, 13.0, 90.0, 1.0, 1.0]  episode_count: 2669 q_vals: [-6.914, -inf, -8.182, -5.512, -4.521, -9.303, -7.919]
{"total_number_of_episodes": 2670, "number_of_timesteps": 49924, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.14285714285714235},
Step 1584 4 visits [1.0, 1000.0, 1.0, 13.0, 91.0, 1.0, 1.0]  episode_count: 2670 q_vals: [-6.914, -inf, -8.182, -5.512, -4.54, -9.303, -7.919]
Step 1585 4 visits [1.0, 1000.0, 1.0, 13.0, 92.0, 1.0, 1.0]  episode_count: 2673 q_vals: [-6.914, -inf, -8.182, -5.512, -4.491, -9.303, -7.919]
Step 1586 4 visits [1.0, 1000.0, 1.0, 13.0, 93.0, 1.0, 1.0]  episode_count: 2674 q_vals: [-6.914, -inf, -8.182, -5.512, -4.497, -9.303, -7.919]
Step 1587 4 visits [1.0, 1000.0, 1.0, 13.0, 94.0, 1.0, 1.0]  episode_count: 2678 q_vals: [-6.914, -inf, -8.182, -5.512, -4.524, -9.303, -7.919]
Step 1588 4 visits [1.0, 1000.0, 1.0, 13.0, 95.0, 1.0, 1.0]  episode_count: 2679 q_vals: [-6.914, -inf, -8.182, -5.512, -4.611, -9.303, -7.919]
{"total_number_of_episodes": 2683, "number_of_timesteps": 50124, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004761904761904764, "biggest_recent_change": 0.14285714285714235},
Step 1589 4 visits [1.0, 1000.0, 1.0, 13.0, 96.0, 1.0, 1.0]  episode_count: 2683 q_vals: [-6.914, -inf, -8.182, -5.512, -4.563, -9.303, -7.919]
Step 1590 4 visits [1.0, 1000.0, 1.0, 13.0, 97.0, 1.0, 1.0]  episode_count: 2684 q_vals: [-6.914, -inf, -8.182, -5.512, -4.584, -9.303, -7.919]
Step 1591 4 visits [1.0, 1000.0, 1.0, 13.0, 98.0, 1.0, 1.0]  episode_count: 2687 q_vals: [-6.914, -inf, -8.182, -5.512, -4.605, -9.303, -7.919]
Step 1592 4 visits [1.0, 1000.0, 1.0, 13.0, 99.0, 1.0, 1.0]  episode_count: 2689 q_vals: [-6.914, -inf, -8.182, -5.512, -4.623, -9.303, -7.919]
Step 1593 4 visits [1.0, 1000.0, 1.0, 13.0, 100.0, 1.0, 1.0]  episode_count: 2689 q_vals: [-6.914, -inf, -8.182, -5.512, -4.635, -9.303, -7.919]
{"total_number_of_episodes": 2693, "number_of_timesteps": 50265, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004761904761904764, "biggest_recent_change": 0.14285714285714235},
Step 1594 4 visits [1.0, 1000.0, 1.0, 13.0, 101.0, 1.0, 1.0]  episode_count: 2693 q_vals: [-6.914, -inf, -8.182, -5.512, -4.647, -9.303, -7.919]
Step 1595 4 visits [1.0, 1000.0, 1.0, 13.0, 102.0, 1.0, 1.0]  episode_count: 2693 q_vals: [-6.914, -inf, -8.182, -5.512, -4.665, -9.303, -7.919]
Step 1596 4 visits [1.0, 1000.0, 1.0, 13.0, 103.0, 1.0, 1.0]  episode_count: 2696 q_vals: [-6.914, -inf, -8.182, -5.512, -4.62, -9.303, -7.919]
Step 1597 4 visits [1.0, 1000.0, 1.0, 13.0, 104.0, 1.0, 1.0]  episode_count: 2698 q_vals: [-6.914, -inf, -8.182, -5.512, -4.625, -9.303, -7.919]
Step 1598 4 visits [1.0, 1000.0, 1.0, 13.0, 105.0, 1.0, 1.0]  episode_count: 2700 q_vals: [-6.914, -inf, -8.182, -5.512, -4.65, -9.303, -7.919]
Step 1599 4 visits [1.0, 1000.0, 1.0, 13.0, 106.0, 1.0, 1.0]  episode_count: 2702 q_vals: [-6.914, -inf, -8.182, -5.512, -4.606, -9.303, -7.919]
{"total_number_of_episodes": 2703, "number_of_timesteps": 50432, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.14285714285714235},
Step 1600 4 visits [1.0, 1000.0, 1.0, 13.0, 107.0, 1.0, 1.0]  episode_count: 2703 q_vals: [-6.914, -inf, -8.182, -5.512, -4.61, -9.303, -7.919]
Step 1601 4 visits [1.0, 1000.0, 1.0, 13.0, 108.0, 1.0, 1.0]  episode_count: 2705 q_vals: [-6.914, -inf, -8.182, -5.512, -4.685, -9.303, -7.919]
Step 1602 4 visits [1.0, 1000.0, 1.0, 13.0, 109.0, 1.0, 1.0]  episode_count: 2708 q_vals: [-6.914, -inf, -8.182, -5.512, -4.692, -9.303, -7.919]
Step 1603 4 visits [1.0, 1000.0, 1.0, 13.0, 110.0, 1.0, 1.0]  episode_count: 2708 q_vals: [-6.914, -inf, -8.182, -5.512, -4.65, -9.303, -7.919]
Step 1604 4 visits [1.0, 1000.0, 1.0, 13.0, 111.0, 1.0, 1.0]  episode_count: 2710 q_vals: [-6.914, -inf, -8.182, -5.512, -4.666, -9.303, -7.919]
Step 1605 4 visits [1.0, 1000.0, 1.0, 13.0, 112.0, 1.0, 1.0]  episode_count: 2712 q_vals: [-6.914, -inf, -8.182, -5.512, -4.672, -9.303, -7.919]
{"total_number_of_episodes": 2714, "number_of_timesteps": 50621, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.14285714285714235},
Step 1606 4 visits [1.0, 1000.0, 1.0, 13.0, 113.0, 1.0, 1.0]  episode_count: 2714 q_vals: [-6.914, -inf, -8.182, -5.512, -4.678, -9.303, -7.919]
Step 1607 4 visits [1.0, 1000.0, 1.0, 13.0, 114.0, 1.0, 1.0]  episode_count: 2716 q_vals: [-6.914, -inf, -8.182, -5.512, -4.637, -9.303, -7.919]
Step 1608 4 visits [1.0, 1000.0, 1.0, 13.0, 115.0, 1.0, 1.0]  episode_count: 2718 q_vals: [-6.914, -inf, -8.182, -5.512, -4.597, -9.303, -7.919]
Step 1609 4 visits [1.0, 1000.0, 1.0, 13.0, 116.0, 1.0, 1.0]  episode_count: 2723 q_vals: [-6.914, -inf, -8.182, -5.512, -4.612, -9.303, -7.919]
{"total_number_of_episodes": 2724, "number_of_timesteps": 50766, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
Step 1610 4 visits [1.0, 1000.0, 1.0, 13.0, 117.0, 1.0, 1.0]  episode_count: 2724 q_vals: [-6.914, -inf, -8.182, -5.512, -4.614, -9.303, -7.919]
Step 1611 4 visits [1.0, 1000.0, 1.0, 13.0, 118.0, 1.0, 1.0]  episode_count: 2725 q_vals: [-6.914, -inf, -8.182, -5.512, -4.575, -9.303, -7.919]
Step 1612 4 visits [1.0, 1000.0, 1.0, 13.0, 119.0, 1.0, 1.0]  episode_count: 2727 q_vals: [-6.914, -inf, -8.182, -5.512, -4.591, -9.303, -7.919]
Step 1613 4 visits [1.0, 1000.0, 1.0, 13.0, 120.0, 1.0, 1.0]  episode_count: 2730 q_vals: [-6.914, -inf, -8.182, -5.512, -4.553, -9.303, -7.919]
Step 1614 4 visits [1.0, 1000.0, 1.0, 13.0, 121.0, 1.0, 1.0]  episode_count: 2733 q_vals: [-6.914, -inf, -8.182, -5.512, -4.556, -9.303, -7.919]
{"total_number_of_episodes": 2735, "number_of_timesteps": 50925, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1615 4 visits [1.0, 1000.0, 1.0, 13.0, 122.0, 1.0, 1.0]  episode_count: 2735 q_vals: [-6.914, -inf, -8.182, -5.512, -4.559, -9.303, -7.919]
Step 1616 4 visits [1.0, 1000.0, 1.0, 13.0, 123.0, 1.0, 1.0]  episode_count: 2736 q_vals: [-6.914, -inf, -8.182, -5.512, -4.522, -9.303, -7.919]
Step 1617 4 visits [1.0, 1000.0, 1.0, 13.0, 124.0, 1.0, 1.0]  episode_count: 2739 q_vals: [-6.914, -inf, -8.182, -5.512, -4.485, -9.303, -7.919]
Step 1618 4 visits [1.0, 1000.0, 1.0, 13.0, 125.0, 1.0, 1.0]  episode_count: 2739 q_vals: [-6.914, -inf, -8.182, -5.512, -4.552, -9.303, -7.919]
Step 1619 4 visits [1.0, 1000.0, 1.0, 13.0, 126.0, 1.0, 1.0]  episode_count: 2740 q_vals: [-6.914, -inf, -8.182, -5.512, -4.564, -9.303, -7.919]
Step 1620 4 visits [1.0, 1000.0, 1.0, 13.0, 127.0, 1.0, 1.0]  episode_count: 2741 q_vals: [-6.914, -inf, -8.182, -5.512, -4.528, -9.303, -7.919]
Step 1621 4 visits [1.0, 1000.0, 1.0, 13.0, 128.0, 1.0, 1.0]  episode_count: 2742 q_vals: [-6.914, -inf, -8.182, -5.512, -4.536, -9.303, -7.919]
{"total_number_of_episodes": 2746, "number_of_timesteps": 51134, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1622 4 visits [1.0, 1000.0, 1.0, 13.0, 129.0, 1.0, 1.0]  episode_count: 2746 q_vals: [-6.914, -inf, -8.182, -5.512, -4.543, -9.303, -7.919]
Step 1623 4 visits [1.0, 1000.0, 1.0, 13.0, 130.0, 1.0, 1.0]  episode_count: 2747 q_vals: [-6.914, -inf, -8.182, -5.512, -4.558, -9.303, -7.919]
Step 1624 4 visits [1.0, 1000.0, 1.0, 13.0, 131.0, 1.0, 1.0]  episode_count: 2751 q_vals: [-6.914, -inf, -8.182, -5.512, -4.56, -9.303, -7.919]
Step 1625 4 visits [1.0, 1000.0, 1.0, 13.0, 132.0, 1.0, 1.0]  episode_count: 2753 q_vals: [-6.914, -inf, -8.182, -5.512, -4.568, -9.303, -7.919]
Step 1626 4 visits [1.0, 1000.0, 1.0, 13.0, 133.0, 1.0, 1.0]  episode_count: 2753 q_vals: [-6.914, -inf, -8.182, -5.512, -4.571, -9.303, -7.919]
{"total_number_of_episodes": 2756, "number_of_timesteps": 51278, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1627 4 visits [1.0, 1000.0, 1.0, 13.0, 134.0, 1.0, 1.0]  episode_count: 2756 q_vals: [-6.914, -inf, -8.182, -5.512, -4.578, -9.303, -7.919]
Step 1628 4 visits [1.0, 1000.0, 1.0, 13.0, 135.0, 1.0, 1.0]  episode_count: 2757 q_vals: [-6.914, -inf, -8.182, -5.512, -4.639, -9.303, -7.919]
Step 1629 4 visits [1.0, 1000.0, 1.0, 13.0, 136.0, 1.0, 1.0]  episode_count: 2759 q_vals: [-6.914, -inf, -8.182, -5.512, -4.64, -9.303, -7.919]
Step 1630 4 visits [1.0, 1000.0, 1.0, 13.0, 137.0, 1.0, 1.0]  episode_count: 2763 q_vals: [-6.914, -inf, -8.182, -5.512, -4.642, -9.303, -7.919]
Step 1631 4 visits [1.0, 1000.0, 1.0, 13.0, 138.0, 1.0, 1.0]  episode_count: 2764 q_vals: [-6.914, -inf, -8.182, -5.512, -4.655, -9.303, -7.919]
{"total_number_of_episodes": 2766, "number_of_timesteps": 51435, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1632 4 visits [1.0, 1000.0, 1.0, 13.0, 139.0, 1.0, 1.0]  episode_count: 2766 q_vals: [-6.914, -inf, -8.182, -5.512, -4.621, -9.303, -7.919]
Step 1633 4 visits [1.0, 1000.0, 1.0, 13.0, 140.0, 1.0, 1.0]  episode_count: 2770 q_vals: [-6.914, -inf, -8.182, -5.512, -4.68, -9.303, -7.919]
Step 1634 4 visits [1.0, 1000.0, 1.0, 13.0, 141.0, 1.0, 1.0]  episode_count: 2773 q_vals: [-6.914, -inf, -8.182, -5.512, -4.686, -9.303, -7.919]
Step 1635 4 visits [1.0, 1000.0, 1.0, 13.0, 142.0, 1.0, 1.0]  episode_count: 2773 q_vals: [-6.914, -inf, -8.182, -5.512, -4.653, -9.303, -7.919]
{"total_number_of_episodes": 2777, "number_of_timesteps": 51575, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1636 4 visits [1.0, 1000.0, 1.0, 13.0, 143.0, 1.0, 1.0]  episode_count: 2777 q_vals: [-6.914, -inf, -8.182, -5.512, -4.664, -9.303, -7.919]
Step 1637 4 visits [1.0, 1000.0, 1.0, 13.0, 144.0, 1.0, 1.0]  episode_count: 2779 q_vals: [-6.914, -inf, -8.182, -5.512, -4.632, -9.303, -7.919]
Step 1638 4 visits [1.0, 1000.0, 1.0, 13.0, 145.0, 1.0, 1.0]  episode_count: 2782 q_vals: [-6.914, -inf, -8.182, -5.512, -4.634, -9.303, -7.919]
Step 1639 4 visits [1.0, 1000.0, 1.0, 13.0, 146.0, 1.0, 1.0]  episode_count: 2783 q_vals: [-6.914, -inf, -8.182, -5.512, -4.639, -9.303, -7.919]
Step 1640 4 visits [1.0, 1000.0, 1.0, 13.0, 147.0, 1.0, 1.0]  episode_count: 2786 q_vals: [-6.914, -inf, -8.182, -5.512, -4.642, -9.303, -7.919]
{"total_number_of_episodes": 2787, "number_of_timesteps": 51707, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1641 4 visits [1.0, 1000.0, 1.0, 13.0, 148.0, 1.0, 1.0]  episode_count: 2787 q_vals: [-6.914, -inf, -8.182, -5.512, -4.61, -9.303, -7.919]
Step 1642 4 visits [1.0, 1000.0, 1.0, 13.0, 149.0, 1.0, 1.0]  episode_count: 2788 q_vals: [-6.914, -inf, -8.182, -5.512, -4.613, -9.303, -7.919]
Step 1643 4 visits [1.0, 1000.0, 1.0, 13.0, 150.0, 1.0, 1.0]  episode_count: 2790 q_vals: [-6.914, -inf, -8.182, -5.512, -4.62, -9.303, -7.919]
Step 1644 4 visits [1.0, 1000.0, 1.0, 13.0, 151.0, 1.0, 1.0]  episode_count: 2792 q_vals: [-6.914, -inf, -8.182, -5.512, -4.674, -9.303, -7.919]
Step 1645 4 visits [1.0, 1000.0, 1.0, 13.0, 152.0, 1.0, 1.0]  episode_count: 2792 q_vals: [-6.914, -inf, -8.182, -5.512, -4.693, -9.303, -7.919]
Step 1646 4 visits [1.0, 1000.0, 1.0, 13.0, 153.0, 1.0, 1.0]  episode_count: 2794 q_vals: [-6.914, -inf, -8.182, -5.512, -4.697, -9.303, -7.919]
Step 1647 4 visits [1.0, 1000.0, 1.0, 13.0, 154.0, 1.0, 1.0]  episode_count: 2796 q_vals: [-6.914, -inf, -8.182, -5.512, -4.703, -9.303, -7.919]
{"total_number_of_episodes": 2798, "number_of_timesteps": 51927, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1648 4 visits [1.0, 1000.0, 1.0, 13.0, 155.0, 1.0, 1.0]  episode_count: 2798 q_vals: [-6.914, -inf, -8.182, -5.512, -4.707, -9.303, -7.919]
Step 1649 4 visits [1.0, 1000.0, 1.0, 13.0, 156.0, 1.0, 1.0]  episode_count: 2798 q_vals: [-6.914, -inf, -8.182, -5.512, -4.676, -9.303, -7.919]
Step 1650 4 visits [1.0, 1000.0, 1.0, 13.0, 157.0, 1.0, 1.0]  episode_count: 2798 q_vals: [-6.914, -inf, -8.182, -5.512, -4.685, -9.303, -7.919]
Step 1651 4 visits [1.0, 1000.0, 1.0, 13.0, 158.0, 1.0, 1.0]  episode_count: 2802 q_vals: [-6.914, -inf, -8.182, -5.512, -4.656, -9.303, -7.919]
Step 1652 4 visits [1.0, 1000.0, 1.0, 13.0, 159.0, 1.0, 1.0]  episode_count: 2803 q_vals: [-6.914, -inf, -8.182, -5.512, -4.656, -9.303, -7.919]
Step 1653 4 visits [1.0, 1000.0, 1.0, 13.0, 160.0, 1.0, 1.0]  episode_count: 2803 q_vals: [-6.914, -inf, -8.182, -5.512, -4.657, -9.303, -7.919]
Step 1654 4 visits [1.0, 1000.0, 1.0, 13.0, 161.0, 1.0, 1.0]  episode_count: 2807 q_vals: [-6.914, -inf, -8.182, -5.512, -4.666, -9.303, -7.919]
{"total_number_of_episodes": 2810, "number_of_timesteps": 52183, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1655 4 visits [1.0, 1000.0, 1.0, 13.0, 162.0, 1.0, 1.0]  episode_count: 2810 q_vals: [-6.914, -inf, -8.182, -5.512, -4.667, -9.303, -7.919]
Step 1656 4 visits [1.0, 1000.0, 1.0, 13.0, 163.0, 1.0, 1.0]  episode_count: 2810 q_vals: [-6.914, -inf, -8.182, -5.512, -4.668, -9.303, -7.919]
Step 1657 4 visits [1.0, 1000.0, 1.0, 13.0, 164.0, 1.0, 1.0]  episode_count: 2812 q_vals: [-6.914, -inf, -8.182, -5.512, -4.666, -9.303, -7.919]
Step 1658 4 visits [1.0, 1000.0, 1.0, 13.0, 165.0, 1.0, 1.0]  episode_count: 2815 q_vals: [-6.914, -inf, -8.182, -5.512, -4.638, -9.303, -7.919]
Step 1659 4 visits [1.0, 1000.0, 1.0, 13.0, 166.0, 1.0, 1.0]  episode_count: 2815 q_vals: [-6.914, -inf, -8.182, -5.512, -4.639, -9.303, -7.919]
Step 1660 4 visits [1.0, 1000.0, 1.0, 13.0, 167.0, 1.0, 1.0]  episode_count: 2818 q_vals: [-6.914, -inf, -8.182, -5.512, -4.611, -9.303, -7.919]
{"total_number_of_episodes": 2821, "number_of_timesteps": 52339, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1661 4 visits [1.0, 1000.0, 1.0, 13.0, 168.0, 1.0, 1.0]  episode_count: 2821 q_vals: [-6.914, -inf, -8.182, -5.512, -4.618, -9.303, -7.919]
Step 1662 4 visits [1.0, 1000.0, 1.0, 13.0, 169.0, 1.0, 1.0]  episode_count: 2822 q_vals: [-6.914, -inf, -8.182, -5.512, -4.591, -9.303, -7.919]
Step 1663 4 visits [1.0, 1000.0, 1.0, 13.0, 170.0, 1.0, 1.0]  episode_count: 2825 q_vals: [-6.914, -inf, -8.182, -5.512, -4.598, -9.303, -7.919]
Step 1664 4 visits [1.0, 1000.0, 1.0, 13.0, 171.0, 1.0, 1.0]  episode_count: 2825 q_vals: [-6.914, -inf, -8.182, -5.512, -4.624, -9.303, -7.919]
Step 1665 4 visits [1.0, 1000.0, 1.0, 13.0, 172.0, 1.0, 1.0]  episode_count: 2827 q_vals: [-6.914, -inf, -8.182, -5.512, -4.631, -9.303, -7.919]
Step 1666 4 visits [1.0, 1000.0, 1.0, 13.0, 173.0, 1.0, 1.0]  episode_count: 2827 q_vals: [-6.914, -inf, -8.182, -5.512, -4.604, -9.303, -7.919]
Step 1667 4 visits [1.0, 1000.0, 1.0, 13.0, 174.0, 1.0, 1.0]  episode_count: 2830 q_vals: [-6.914, -inf, -8.182, -5.512, -4.61, -9.303, -7.919]
{"total_number_of_episodes": 2832, "number_of_timesteps": 52530, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1668 4 visits [1.0, 1000.0, 1.0, 13.0, 175.0, 1.0, 1.0]  episode_count: 2832 q_vals: [-6.914, -inf, -8.182, -5.512, -4.584, -9.303, -7.919]
Step 1669 4 visits [1.0, 1000.0, 1.0, 13.0, 176.0, 1.0, 1.0]  episode_count: 2834 q_vals: [-6.914, -inf, -8.182, -5.512, -4.589, -9.303, -7.919]
Step 1670 4 visits [1.0, 1000.0, 1.0, 13.0, 177.0, 1.0, 1.0]  episode_count: 2834 q_vals: [-6.914, -inf, -8.182, -5.512, -4.592, -9.303, -7.919]
Step 1671 4 visits [1.0, 1000.0, 1.0, 13.0, 178.0, 1.0, 1.0]  episode_count: 2835 q_vals: [-6.914, -inf, -8.182, -5.512, -4.567, -9.303, -7.919]
Step 1672 4 visits [1.0, 1000.0, 1.0, 13.0, 179.0, 1.0, 1.0]  episode_count: 2836 q_vals: [-6.914, -inf, -8.182, -5.512, -4.579, -9.303, -7.919]
Step 1673 4 visits [1.0, 1000.0, 1.0, 13.0, 180.0, 1.0, 1.0]  episode_count: 2837 q_vals: [-6.914, -inf, -8.182, -5.512, -4.582, -9.303, -7.919]
Step 1674 4 visits [1.0, 1000.0, 1.0, 13.0, 181.0, 1.0, 1.0]  episode_count: 2839 q_vals: [-6.914, -inf, -8.182, -5.512, -4.557, -9.303, -7.919]
Step 1675 4 visits [1.0, 1000.0, 1.0, 13.0, 182.0, 1.0, 1.0]  episode_count: 2841 q_vals: [-6.914, -inf, -8.182, -5.512, -4.562, -9.303, -7.919]
{"total_number_of_episodes": 2842, "number_of_timesteps": 52789, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1676 4 visits [1.0, 1000.0, 1.0, 13.0, 183.0, 1.0, 1.0]  episode_count: 2842 q_vals: [-6.914, -inf, -8.182, -5.512, -4.565, -9.303, -7.919]
Step 1677 4 visits [1.0, 1000.0, 1.0, 13.0, 184.0, 1.0, 1.0]  episode_count: 2843 q_vals: [-6.914, -inf, -8.182, -5.512, -4.577, -9.303, -7.919]
Step 1678 4 visits [1.0, 1000.0, 1.0, 13.0, 185.0, 1.0, 1.0]  episode_count: 2846 q_vals: [-6.914, -inf, -8.182, -5.512, -4.583, -9.303, -7.919]
Step 1679 4 visits [1.0, 1000.0, 1.0, 13.0, 186.0, 1.0, 1.0]  episode_count: 2848 q_vals: [-6.914, -inf, -8.182, -5.512, -4.559, -9.303, -7.919]
Step 1680 4 visits [1.0, 1000.0, 1.0, 13.0, 187.0, 1.0, 1.0]  episode_count: 2850 q_vals: [-6.914, -inf, -8.182, -5.512, -4.558, -9.303, -7.919]
Step 1681 4 visits [1.0, 1000.0, 1.0, 13.0, 188.0, 1.0, 1.0]  episode_count: 2850 q_vals: [-6.914, -inf, -8.182, -5.512, -4.56, -9.303, -7.919]
Step 1682 4 visits [1.0, 1000.0, 1.0, 13.0, 189.0, 1.0, 1.0]  episode_count: 2850 q_vals: [-6.914, -inf, -8.182, -5.512, -4.561, -9.303, -7.919]
{"total_number_of_episodes": 2854, "number_of_timesteps": 53045, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1683 4 visits [1.0, 1000.0, 1.0, 13.0, 190.0, 1.0, 1.0]  episode_count: 2854 q_vals: [-6.914, -inf, -8.182, -5.512, -4.537, -9.303, -7.919]
Step 1684 4 visits [1.0, 1000.0, 1.0, 13.0, 191.0, 1.0, 1.0]  episode_count: 2856 q_vals: [-6.914, -inf, -8.182, -5.512, -4.538, -9.303, -7.919]
Step 1685 4 visits [1.0, 1000.0, 1.0, 13.0, 192.0, 1.0, 1.0]  episode_count: 2858 q_vals: [-6.914, -inf, -8.182, -5.512, -4.514, -9.303, -7.919]
Step 1686 4 visits [1.0, 1000.0, 1.0, 13.0, 193.0, 1.0, 1.0]  episode_count: 2859 q_vals: [-6.914, -inf, -8.182, -5.512, -4.515, -9.303, -7.919]
[-6.914, -inf, -8.182, -5.512, -4.516, -9.303, -7.919]
Step 1688 4 visits [1.0, 1000.0, 1.0, 13.0, 195.0, 1.0, 1.0]  episode_count: 2863 q_vals: [-6.914, -inf, -8.182, -5.512, -4.527, -9.303, -7.919]
{"total_number_of_episodes": 2865, "number_of_timesteps": 53254, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1689 4 visits [1.0, 1000.0, 1.0, 13.0, 196.0, 1.0, 1.0]  episode_count: 2865 q_vals: [-6.914, -inf, -8.182, -5.512, -4.504, -9.303, -7.919]
Step 1690 4 visits [1.0, 1000.0, 1.0, 13.0, 197.0, 1.0, 1.0]  episode_count: 2868 q_vals: [-6.914, -inf, -8.182, -5.512, -4.504, -9.303, -7.919]
Step 1691 4 visits [1.0, 1000.0, 1.0, 13.0, 198.0, 1.0, 1.0]  episode_count: 2870 q_vals: [-6.914, -inf, -8.182, -5.512, -4.505, -9.303, -7.919]
Step 1692 4 visits [1.0, 1000.0, 1.0, 13.0, 199.0, 1.0, 1.0]  episode_count: 2871 q_vals: [-6.914, -inf, -8.182, -5.512, -4.507, -9.303, -7.919]
Step 1693 4 visits [1.0, 1000.0, 1.0, 13.0, 200.0, 1.0, 1.0]  episode_count: 2872 q_vals: [-6.914, -inf, -8.182, -5.512, -4.518, -9.303, -7.919]
Step 1694 4 visits [1.0, 1000.0, 1.0, 13.0, 201.0, 1.0, 1.0]  episode_count: 2872 q_vals: [-6.914, -inf, -8.182, -5.512, -4.529, -9.303, -7.919]
Step 1695 4 visits [1.0, 1000.0, 1.0, 13.0, 202.0, 1.0, 1.0]  episode_count: 2874 q_vals: [-6.914, -inf, -8.182, -5.512, -4.57, -9.303, -7.919]
{"total_number_of_episodes": 2877, "number_of_timesteps": 53481, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1696 4 visits [1.0, 1000.0, 1.0, 13.0, 203.0, 1.0, 1.0]  episode_count: 2877 q_vals: [-6.914, -inf, -8.182, -5.512, -4.575, -9.303, -7.919]
Step 1697 4 visits [1.0, 1000.0, 1.0, 13.0, 204.0, 1.0, 1.0]  episode_count: 2878 q_vals: [-6.914, -inf, -8.182, -5.512, -4.579, -9.303, -7.919]
Step 1698 4 visits [1.0, 1000.0, 1.0, 13.0, 205.0, 1.0, 1.0]  episode_count: 2878 q_vals: [-6.914, -inf, -8.182, -5.512, -4.584, -9.303, -7.919]
Step 1699 4 visits [1.0, 1000.0, 1.0, 13.0, 206.0, 1.0, 1.0]  episode_count: 2880 q_vals: [-6.914, -inf, -8.182, -5.512, -4.584, -9.303, -7.919]
Step 1700 4 visits [1.0, 1000.0, 1.0, 13.0, 207.0, 1.0, 1.0]  episode_count: 2882 q_vals: [-6.914, -inf, -8.182, -5.512, -4.595, -9.303, -7.919]
Step 1701 4 visits [1.0, 1000.0, 1.0, 13.0, 208.0, 1.0, 1.0]  episode_count: 2884 q_vals: [-6.914, -inf, -8.182, -5.512, -4.572, -9.303, -7.919]
Step 1702 4 visits [1.0, 1000.0, 1.0, 13.0, 209.0, 1.0, 1.0]  episode_count: 2884 q_vals: [-6.914, -inf, -8.182, -5.512, -4.574, -9.303, -7.919]
Step 1703 4 visits [1.0, 1000.0, 1.0, 13.0, 210.0, 1.0, 1.0]  episode_count: 2885 q_vals: [-6.914, -inf, -8.182, -5.512, -4.552, -9.303, -7.919]
{"total_number_of_episodes": 2887, "number_of_timesteps": 53678, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1704 4 visits [1.0, 1000.0, 1.0, 13.0, 211.0, 1.0, 1.0]  episode_count: 2887 q_vals: [-6.914, -inf, -8.182, -5.512, -4.592, -9.303, -7.919]
Step 1705 4 visits [1.0, 1000.0, 1.0, 13.0, 212.0, 1.0, 1.0]  episode_count: 2889 q_vals: [-6.914, -inf, -8.182, -5.512, -4.57, -9.303, -7.919]
Step 1706 4 visits [1.0, 1000.0, 1.0, 13.0, 213.0, 1.0, 1.0]  episode_count: 2889 q_vals: [-6.914, -inf, -8.182, -5.512, -4.569, -9.303, -7.919]
Step 1707 4 visits [1.0, 1000.0, 1.0, 13.0, 214.0, 1.0, 1.0]  episode_count: 2889 q_vals: [-6.914, -inf, -8.182, -5.512, -4.568, -9.303, -7.919]
Step 1708 4 visits [1.0, 1000.0, 1.0, 13.0, 215.0, 1.0, 1.0]  episode_count: 2892 q_vals: [-6.914, -inf, -8.182, -5.512, -4.55, -9.303, -7.919]
Step 1709 4 visits [1.0, 1000.0, 1.0, 13.0, 216.0, 1.0, 1.0]  episode_count: 2892 q_vals: [-6.914, -inf, -8.182, -5.512, -4.562, -9.303, -7.919]
Step 1710 4 visits [1.0, 1000.0, 1.0, 13.0, 217.0, 1.0, 1.0]  episode_count: 2893 q_vals: [-6.914, -inf, -8.182, -5.512, -4.561, -9.303, -7.919]
{"total_number_of_episodes": 2897, "number_of_timesteps": 53958, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1711 4 visits [1.0, 1000.0, 1.0, 13.0, 218.0, 1.0, 1.0]  episode_count: 2897 q_vals: [-6.914, -inf, -8.182, -5.512, -4.552, -9.303, -7.919]
Step 1712 4 visits [1.0, 1000.0, 1.0, 13.0, 219.0, 1.0, 1.0]  episode_count: 2899 q_vals: [-6.914, -inf, -8.182, -5.512, -4.531, -9.303, -7.919]
Step 1713 4 visits [1.0, 1000.0, 1.0, 13.0, 220.0, 1.0, 1.0]  episode_count: 2900 q_vals: [-6.914, -inf, -8.182, -5.512, -4.531, -9.303, -7.919]
Step 1714 4 visits [1.0, 1000.0, 1.0, 13.0, 221.0, 1.0, 1.0]  episode_count: 2902 q_vals: [-6.914, -inf, -8.182, -5.512, -4.534, -9.303, -7.919]
Step 1715 4 visits [1.0, 1000.0, 1.0, 13.0, 222.0, 1.0, 1.0]  episode_count: 2903 q_vals: [-6.914, -inf, -8.182, -5.512, -4.572, -9.303, -7.919]
Step 1716 4 visits [1.0, 1000.0, 1.0, 13.0, 223.0, 1.0, 1.0]  episode_count: 2906 q_vals: [-6.914, -inf, -8.182, -5.512, -4.575, -9.303, -7.919]
{"total_number_of_episodes": 2908, "number_of_timesteps": 54143, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1717 4 visits [1.0, 1000.0, 1.0, 13.0, 224.0, 1.0, 1.0]  episode_count: 2908 q_vals: [-6.914, -inf, -8.182, -5.512, -4.578, -9.303, -7.919]
Step 1718 4 visits [1.0, 1000.0, 1.0, 13.0, 225.0, 1.0, 1.0]  episode_count: 2911 q_vals: [-6.914, -inf, -8.182, -5.512, -4.578, -9.303, -7.919]
Step 1719 4 visits [1.0, 1000.0, 1.0, 13.0, 226.0, 1.0, 1.0]  episode_count: 2914 q_vals: [-6.914, -inf, -8.182, -5.512, -4.581, -9.303, -7.919]
Step 1720 4 visits [1.0, 1000.0, 1.0, 13.0, 227.0, 1.0, 1.0]  episode_count: 2914 q_vals: [-6.914, -inf, -8.182, -5.512, -4.561, -9.303, -7.919]
{"total_number_of_episodes": 2918, "number_of_timesteps": 54288, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1721 4 visits [1.0, 1000.0, 1.0, 13.0, 228.0, 1.0, 1.0]  episode_count: 2918 q_vals: [-6.914, -inf, -8.182, -5.512, -4.56, -9.303, -7.919]
Step 1722 4 visits [1.0, 1000.0, 1.0, 13.0, 229.0, 1.0, 1.0]  episode_count: 2921 q_vals: [-6.914, -inf, -8.182, -5.512, -4.564, -9.303, -7.919]
Step 1723 4 visits [1.0, 1000.0, 1.0, 13.0, 230.0, 1.0, 1.0]  episode_count: 2922 q_vals: [-6.914, -inf, -8.182, -5.512, -4.563, -9.303, -7.919]
Step 1724 4 visits [1.0, 1000.0, 1.0, 13.0, 231.0, 1.0, 1.0]  episode_count: 2925 q_vals: [-6.914, -inf, -8.182, -5.512, -4.565, -9.303, -7.919]
{"total_number_of_episodes": 2928, "number_of_timesteps": 54419, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
[-6.914, -inf, -8.182, -5.512, -4.546, -9.303, -7.919]
Step 1726 4 visits [1.0, 1000.0, 1.0, 13.0, 233.0, 1.0, 1.0]  episode_count: 2928 q_vals: [-6.914, -inf, -8.182, -5.512, -4.526, -9.303, -7.919]
Step 1727 4 visits [1.0, 1000.0, 1.0, 13.0, 234.0, 1.0, 1.0]  episode_count: 2933 q_vals: [-6.914, -inf, -8.182, -5.512, -4.526, -9.303, -7.919]
Step 1728 4 visits [1.0, 1000.0, 1.0, 13.0, 235.0, 1.0, 1.0]  episode_count: 2934 q_vals: [-6.914, -inf, -8.182, -5.512, -4.507, -9.303, -7.919]
Step 1729 4 visits [1.0, 1000.0, 1.0, 13.0, 236.0, 1.0, 1.0]  episode_count: 2936 q_vals: [-6.914, -inf, -8.182, -5.512, -4.542, -9.303, -7.919]
{"total_number_of_episodes": 2939, "number_of_timesteps": 54563, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1730 4 visits [1.0, 1000.0, 1.0, 13.0, 237.0, 1.0, 1.0]  episode_count: 2939 q_vals: [-6.914, -inf, -8.182, -5.512, -4.523, -9.303, -7.919]
Step 1731 4 visits [1.0, 1000.0, 1.0, 13.0, 238.0, 1.0, 1.0]  episode_count: 2940 q_vals: [-6.914, -inf, -8.182, -5.512, -4.523, -9.303, -7.919]
Step 1732 4 visits [1.0, 1000.0, 1.0, 13.0, 239.0, 1.0, 1.0]  episode_count: 2942 q_vals: [-6.914, -inf, -8.182, -5.512, -4.526, -9.303, -7.919]
Step 1733 4 visits [1.0, 1000.0, 1.0, 13.0, 240.0, 1.0, 1.0]  episode_count: 2943 q_vals: [-6.914, -inf, -8.182, -5.512, -4.507, -9.303, -7.919]
Step 1734 4 visits [1.0, 1000.0, 1.0, 13.0, 241.0, 1.0, 1.0]  episode_count: 2944 q_vals: [-6.914, -inf, -8.182, -5.512, -4.508, -9.303, -7.919]
Step 1735 4 visits [1.0, 1000.0, 1.0, 13.0, 242.0, 1.0, 1.0]  episode_count: 2946 q_vals: [-6.914, -inf, -8.182, -5.512, -4.509, -9.303, -7.919]
Step 1736 4 visits [1.0, 1000.0, 1.0, 13.0, 243.0, 1.0, 1.0]  episode_count: 2947 q_vals: [-6.914, -inf, -8.182, -5.512, -4.543, -9.303, -7.919]
{"total_number_of_episodes": 2951, "number_of_timesteps": 54797, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1737 4 visits [1.0, 1000.0, 1.0, 13.0, 244.0, 1.0, 1.0]  episode_count: 2951 q_vals: [-6.914, -inf, -8.182, -5.512, -4.524, -9.303, -7.919]
Step 1738 4 visits [1.0, 1000.0, 1.0, 13.0, 245.0, 1.0, 1.0]  episode_count: 2953 q_vals: [-6.914, -inf, -8.182, -5.512, -4.528, -9.303, -7.919]
Step 1739 4 visits [1.0, 1000.0, 1.0, 13.0, 246.0, 1.0, 1.0]  episode_count: 2953 q_vals: [-6.914, -inf, -8.182, -5.512, -4.51, -9.303, -7.919]
Step 1740 4 visits [1.0, 1000.0, 1.0, 13.0, 247.0, 1.0, 1.0]  episode_count: 2956 q_vals: [-6.914, -inf, -8.182, -5.512, -4.51, -9.303, -7.919]
Step 1741 4 visits [1.0, 1000.0, 1.0, 13.0, 248.0, 1.0, 1.0]  episode_count: 2957 q_vals: [-6.914, -inf, -8.182, -5.512, -4.508, -9.303, -7.919]
Step 1742 4 visits [1.0, 1000.0, 1.0, 13.0, 249.0, 1.0, 1.0]  episode_count: 2958 q_vals: [-6.914, -inf, -8.182, -5.512, -4.507, -9.303, -7.919]
{"total_number_of_episodes": 2962, "number_of_timesteps": 54973, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1743 4 visits [1.0, 1000.0, 1.0, 13.0, 250.0, 1.0, 1.0]  episode_count: 2962 q_vals: [-6.914, -inf, -8.182, -5.512, -4.507, -9.303, -7.919]
Step 1744 4 visits [1.0, 1000.0, 1.0, 13.0, 251.0, 1.0, 1.0]  episode_count: 2964 q_vals: [-6.914, -inf, -8.182, -5.512, -4.508, -9.303, -7.919]
Step 1745 4 visits [1.0, 1000.0, 1.0, 13.0, 252.0, 1.0, 1.0]  episode_count: 2964 q_vals: [-6.914, -inf, -8.182, -5.512, -4.514, -9.303, -7.919]
Step 1746 4 visits [1.0, 1000.0, 1.0, 13.0, 253.0, 1.0, 1.0]  episode_count: 2965 q_vals: [-6.914, -inf, -8.182, -5.512, -4.496, -9.303, -7.919]
Step 1747 4 visits [1.0, 1000.0, 1.0, 13.0, 254.0, 1.0, 1.0]  episode_count: 2968 q_vals: [-6.914, -inf, -8.182, -5.512, -4.496, -9.303, -7.919]
Step 1748 4 visits [1.0, 1000.0, 1.0, 13.0, 255.0, 1.0, 1.0]  episode_count: 2971 q_vals: [-6.914, -inf, -8.182, -5.512, -4.496, -9.303, -7.919]
{"total_number_of_episodes": 2972, "number_of_timesteps": 55136, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1749 4 visits [1.0, 1000.0, 1.0, 13.0, 256.0, 1.0, 1.0]  episode_count: 2972 q_vals: [-6.914, -inf, -8.182, -5.512, -4.497, -9.303, -7.919]
Step 1750 4 visits [1.0, 1000.0, 1.0, 13.0, 257.0, 1.0, 1.0]  episode_count: 2973 q_vals: [-6.914, -inf, -8.182, -5.512, -4.507, -9.303, -7.919]
Step 1751 4 visits [1.0, 1000.0, 1.0, 13.0, 258.0, 1.0, 1.0]  episode_count: 2976 q_vals: [-6.914, -inf, -8.182, -5.512, -4.507, -9.303, -7.919]
Step 1752 4 visits [1.0, 1000.0, 1.0, 13.0, 259.0, 1.0, 1.0]  episode_count: 2978 q_vals: [-6.914, -inf, -8.182, -5.512, -4.507, -9.303, -7.919]
Step 1753 4 visits [1.0, 1000.0, 1.0, 13.0, 260.0, 1.0, 1.0]  episode_count: 2979 q_vals: [-6.914, -inf, -8.182, -5.512, -4.507, -9.303, -7.919]
Step 1754 4 visits [1.0, 1000.0, 1.0, 13.0, 261.0, 1.0, 1.0]  episode_count: 2981 q_vals: [-6.914, -inf, -8.182, -5.512, -4.508, -9.303, -7.919]
{"total_number_of_episodes": 2982, "number_of_timesteps": 55320, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1755 4 visits [1.0, 1000.0, 1.0, 13.0, 262.0, 1.0, 1.0]  episode_count: 2982 q_vals: [-6.914, -inf, -8.182, -5.512, -4.509, -9.303, -7.919]
Step 1756 4 visits [1.0, 1000.0, 1.0, 13.0, 263.0, 1.0, 1.0]  episode_count: 2983 q_vals: [-6.914, -inf, -8.182, -5.512, -4.517, -9.303, -7.919]
Step 1757 4 visits [1.0, 1000.0, 1.0, 13.0, 264.0, 1.0, 1.0]  episode_count: 2984 q_vals: [-6.914, -inf, -8.182, -5.512, -4.549, -9.303, -7.919]
Step 1758 4 visits [1.0, 1000.0, 1.0, 13.0, 265.0, 1.0, 1.0]  episode_count: 2988 q_vals: [-6.914, -inf, -8.182, -5.512, -4.532, -9.303, -7.919]
Step 1759 4 visits [1.0, 1000.0, 1.0, 13.0, 266.0, 1.0, 1.0]  episode_count: 2990 q_vals: [-6.914, -inf, -8.182, -5.512, -4.53, -9.303, -7.919]
Step 1760 4 visits [1.0, 1000.0, 1.0, 13.0, 267.0, 1.0, 1.0]  episode_count: 2990 q_vals: [-6.914, -inf, -8.182, -5.512, -4.561, -9.303, -7.919]
Step 1761 4 visits [1.0, 1000.0, 1.0, 13.0, 268.0, 1.0, 1.0]  episode_count: 2991 q_vals: [-6.914, -inf, -8.182, -5.512, -4.544, -9.303, -7.919]
{"total_number_of_episodes": 2995, "number_of_timesteps": 55566, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1762 4 visits [1.0, 1000.0, 1.0, 13.0, 269.0, 1.0, 1.0]  episode_count: 2995 q_vals: [-6.914, -inf, -8.182, -5.512, -4.544, -9.303, -7.919]
Step 1763 4 visits [1.0, 1000.0, 1.0, 13.0, 270.0, 1.0, 1.0]  episode_count: 2996 q_vals: [-6.914, -inf, -8.182, -5.512, -4.527, -9.303, -7.919]
Step 1764 4 visits [1.0, 1000.0, 1.0, 13.0, 271.0, 1.0, 1.0]  episode_count: 2997 q_vals: [-6.914, -inf, -8.182, -5.512, -4.526, -9.303, -7.919]
Step 1765 4 visits [1.0, 1000.0, 1.0, 13.0, 272.0, 1.0, 1.0]  episode_count: 2999 q_vals: [-6.914, -inf, -8.182, -5.512, -4.51, -9.303, -7.919]
Step 1766 4 visits [1.0, 1000.0, 1.0, 13.0, 273.0, 1.0, 1.0]  episode_count: 3001 q_vals: [-6.914, -inf, -8.182, -5.512, -4.511, -9.303, -7.919]
Step 1767 4 visits [1.0, 1000.0, 1.0, 13.0, 274.0, 1.0, 1.0]  episode_count: 3003 q_vals: [-6.914, -inf, -8.182, -5.512, -4.541, -9.303, -7.919]
{"total_number_of_episodes": 3006, "number_of_timesteps": 55781, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1768 4 visits [1.0, 1000.0, 1.0, 13.0, 275.0, 1.0, 1.0]  episode_count: 3006 q_vals: [-6.914, -inf, -8.182, -5.512, -4.525, -9.303, -7.919]
Step 1769 4 visits [1.0, 1000.0, 1.0, 13.0, 276.0, 1.0, 1.0]  episode_count: 3008 q_vals: [-6.914, -inf, -8.182, -5.512, -4.525, -9.303, -7.919]
Step 1770 4 visits [1.0, 1000.0, 1.0, 13.0, 277.0, 1.0, 1.0]  episode_count: 3009 q_vals: [-6.914, -inf, -8.182, -5.512, -4.509, -9.303, -7.919]
Step 1771 4 visits [1.0, 1000.0, 1.0, 13.0, 278.0, 1.0, 1.0]  episode_count: 3011 q_vals: [-6.914, -inf, -8.182, -5.512, -4.493, -9.303, -7.919]
Step 1772 4 visits [1.0, 1000.0, 1.0, 13.0, 279.0, 1.0, 1.0]  episode_count: 3012 q_vals: [-6.914, -inf, -8.182, -5.512, -4.493, -9.303, -7.919]
Step 1773 4 visits [1.0, 1000.0, 1.0, 13.0, 280.0, 1.0, 1.0]  episode_count: 3012 q_vals: [-6.914, -inf, -8.182, -5.512, -4.487, -9.303, -7.919]
Step 1774 4 visits [1.0, 1000.0, 1.0, 13.0, 281.0, 1.0, 1.0]  episode_count: 3014 q_vals: [-6.914, -inf, -8.182, -5.512, -4.471, -9.303, -7.919]
{"total_number_of_episodes": 3016, "number_of_timesteps": 55968, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1775 4 visits [1.0, 1000.0, 1.0, 13.0, 282.0, 1.0, 1.0]  episode_count: 3016 q_vals: [-6.914, -inf, -8.182, -5.512, -4.472, -9.303, -7.919]
Step 1776 4 visits [1.0, 1000.0, 1.0, 13.0, 283.0, 1.0, 1.0]  episode_count: 3019 q_vals: [-6.914, -inf, -8.182, -5.512, -4.472, -9.303, -7.919]
Step 1777 4 visits [1.0, 1000.0, 1.0, 13.0, 284.0, 1.0, 1.0]  episode_count: 3019 q_vals: [-6.914, -inf, -8.182, -5.512, -4.456, -9.303, -7.919]
Step 1778 4 visits [1.0, 1000.0, 1.0, 13.0, 285.0, 1.0, 1.0]  episode_count: 3021 q_vals: [-6.914, -inf, -8.182, -5.512, -4.461, -9.303, -7.919]
Step 1779 4 visits [1.0, 1000.0, 1.0, 13.0, 286.0, 1.0, 1.0]  episode_count: 3025 q_vals: [-6.914, -inf, -8.182, -5.512, -4.459, -9.303, -7.919]
{"total_number_of_episodes": 3026, "number_of_timesteps": 56147, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1780 4 visits [1.0, 1000.0, 1.0, 13.0, 287.0, 1.0, 1.0]  episode_count: 3026 q_vals: [-6.914, -inf, -8.182, -5.512, -4.464, -9.303, -7.919]
Step 1781 4 visits [1.0, 1000.0, 1.0, 13.0, 288.0, 1.0, 1.0]  episode_count: 3027 q_vals: [-6.914, -inf, -8.182, -5.512, -4.463, -9.303, -7.919]
Step 1782 4 visits [1.0, 1000.0, 1.0, 13.0, 289.0, 1.0, 1.0]  episode_count: 3029 q_vals: [-6.914, -inf, -8.182, -5.512, -4.447, -9.303, -7.919]
Step 1783 4 visits [1.0, 1000.0, 1.0, 13.0, 290.0, 1.0, 1.0]  episode_count: 3033 q_vals: [-6.914, -inf, -8.182, -5.512, -4.447, -9.303, -7.919]
Step 1784 4 visits [1.0, 1000.0, 1.0, 13.0, 291.0, 1.0, 1.0]  episode_count: 3034 q_vals: [-6.914, -inf, -8.182, -5.512, -4.451, -9.303, -7.919]
Step 1785 4 visits [1.0, 1000.0, 1.0, 13.0, 292.0, 1.0, 1.0]  episode_count: 3035 q_vals: [-6.914, -inf, -8.182, -5.512, -4.45, -9.303, -7.919]
{"total_number_of_episodes": 3038, "number_of_timesteps": 56336, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1786 4 visits [1.0, 1000.0, 1.0, 13.0, 293.0, 1.0, 1.0]  episode_count: 3038 q_vals: [-6.914, -inf, -8.182, -5.512, -4.435, -9.303, -7.919]
Step 1787 4 visits [1.0, 1000.0, 1.0, 13.0, 294.0, 1.0, 1.0]  episode_count: 3040 q_vals: [-6.914, -inf, -8.182, -5.512, -4.436, -9.303, -7.919]
Step 1788 4 visits [1.0, 1000.0, 1.0, 13.0, 295.0, 1.0, 1.0]  episode_count: 3042 q_vals: [-6.914, -inf, -8.182, -5.512, -4.437, -9.303, -7.919]
Step 1789 4 visits [1.0, 1000.0, 1.0, 13.0, 296.0, 1.0, 1.0]  episode_count: 3043 q_vals: [-6.914, -inf, -8.182, -5.512, -4.44, -9.303, -7.919]
Step 1790 4 visits [1.0, 1000.0, 1.0, 13.0, 297.0, 1.0, 1.0]  episode_count: 3045 q_vals: [-6.914, -inf, -8.182, -5.512, -4.425, -9.303, -7.919]
Step 1791 4 visits [1.0, 1000.0, 1.0, 13.0, 298.0, 1.0, 1.0]  episode_count: 3046 q_vals: [-6.914, -inf, -8.182, -5.512, -4.425, -9.303, -7.919]
{"total_number_of_episodes": 3048, "number_of_timesteps": 56518, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1792 4 visits [1.0, 1000.0, 1.0, 13.0, 299.0, 1.0, 1.0]  episode_count: 3048 q_vals: [-6.914, -inf, -8.182, -5.512, -4.41, -9.303, -7.919]
Step 1793 4 visits [1.0, 1000.0, 1.0, 13.0, 300.0, 1.0, 1.0]  episode_count: 3051 q_vals: [-6.914, -inf, -8.182, -5.512, -4.416, -9.303, -7.919]
Step 1794 4 visits [1.0, 1000.0, 1.0, 13.0, 301.0, 1.0, 1.0]  episode_count: 3051 q_vals: [-6.914, -inf, -8.182, -5.512, -4.421, -9.303, -7.919]
Step 1795 4 visits [1.0, 1000.0, 1.0, 13.0, 302.0, 1.0, 1.0]  episode_count: 3053 q_vals: [-6.914, -inf, -8.182, -5.512, -4.425, -9.303, -7.919]
Step 1796 4 visits [1.0, 1000.0, 1.0, 13.0, 303.0, 1.0, 1.0]  episode_count: 3053 q_vals: [-6.914, -inf, -8.182, -5.512, -4.41, -9.303, -7.919]
Step 1797 4 visits [1.0, 1000.0, 1.0, 13.0, 304.0, 1.0, 1.0]  episode_count: 3057 q_vals: [-6.914, -inf, -8.182, -5.512, -4.438, -9.303, -7.919]
Step 1798 4 visits [1.0, 1000.0, 1.0, 13.0, 305.0, 1.0, 1.0]  episode_count: 3057 q_vals: [-6.914, -inf, -8.182, -5.512, -4.423, -9.303, -7.919]
Step 1799 4 visits [1.0, 1000.0, 1.0, 13.0, 306.0, 1.0, 1.0]  episode_count: 3057 q_vals: [-6.914, -inf, -8.182, -5.512, -4.409, -9.303, -7.919]
{"total_number_of_episodes": 3061, "number_of_timesteps": 56747, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1800 4 visits [1.0, 1000.0, 1.0, 13.0, 307.0, 1.0, 1.0]  episode_count: 3061 q_vals: [-6.914, -inf, -8.182, -5.512, -4.408, -9.303, -7.919]
Step 1801 4 visits [1.0, 1000.0, 1.0, 13.0, 308.0, 1.0, 1.0]  episode_count: 3061 q_vals: [-6.914, -inf, -8.182, -5.512, -4.394, -9.303, -7.919]
Step 1802 4 visits [1.0, 1000.0, 1.0, 13.0, 309.0, 1.0, 1.0]  episode_count: 3062 q_vals: [-6.914, -inf, -8.182, -5.512, -4.393, -9.303, -7.919]
Step 1803 4 visits [1.0, 1000.0, 1.0, 13.0, 310.0, 1.0, 1.0]  episode_count: 3063 q_vals: [-6.914, -inf, -8.182, -5.512, -4.421, -9.303, -7.919]
Step 1804 4 visits [1.0, 1000.0, 1.0, 13.0, 311.0, 1.0, 1.0]  episode_count: 3066 q_vals: [-6.914, -inf, -8.182, -5.512, -4.422, -9.303, -7.919]
Step 1805 4 visits [1.0, 1000.0, 1.0, 13.0, 312.0, 1.0, 1.0]  episode_count: 3067 q_vals: [-6.914, -inf, -8.182, -5.512, -4.449, -9.303, -7.919]
Step 1806 4 visits [1.0, 1000.0, 1.0, 13.0, 313.0, 1.0, 1.0]  episode_count: 3069 q_vals: [-6.914, -inf, -8.182, -5.512, -4.451, -9.303, -7.919]
{"total_number_of_episodes": 3071, "number_of_timesteps": 56939, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1807 4 visits [1.0, 1000.0, 1.0, 13.0, 314.0, 1.0, 1.0]  episode_count: 3071 q_vals: [-6.914, -inf, -8.182, -5.512, -4.437, -9.303, -7.919]
Step 1808 4 visits [1.0, 1000.0, 1.0, 13.0, 315.0, 1.0, 1.0]  episode_count: 3073 q_vals: [-6.914, -inf, -8.182, -5.512, -4.423, -9.303, -7.919]
Step 1809 4 visits [1.0, 1000.0, 1.0, 13.0, 316.0, 1.0, 1.0]  episode_count: 3075 q_vals: [-6.914, -inf, -8.182, -5.512, -4.409, -9.303, -7.919]
Step 1810 4 visits [1.0, 1000.0, 1.0, 13.0, 317.0, 1.0, 1.0]  episode_count: 3077 q_vals: [-6.914, -inf, -8.182, -5.512, -4.395, -9.303, -7.919]
Step 1811 4 visits [1.0, 1000.0, 1.0, 13.0, 318.0, 1.0, 1.0]  episode_count: 3079 q_vals: [-6.914, -inf, -8.182, -5.512, -4.391, -9.303, -7.919]
Step 1812 4 visits [1.0, 1000.0, 1.0, 13.0, 319.0, 1.0, 1.0]  episode_count: 3079 q_vals: [-6.914, -inf, -8.182, -5.512, -4.396, -9.303, -7.919]
{"total_number_of_episodes": 3082, "number_of_timesteps": 57177, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1813 4 visits [1.0, 1000.0, 1.0, 13.0, 320.0, 1.0, 1.0]  episode_count: 3082 q_vals: [-6.914, -inf, -8.182, -5.512, -4.383, -9.303, -7.919]
Step 1814 4 visits [1.0, 1000.0, 1.0, 13.0, 321.0, 1.0, 1.0]  episode_count: 3084 q_vals: [-6.914, -inf, -8.182, -5.512, -4.383, -9.303, -7.919]
Step 1815 4 visits [1.0, 1000.0, 1.0, 13.0, 322.0, 1.0, 1.0]  episode_count: 3085 q_vals: [-6.914, -inf, -8.182, -5.512, -4.387, -9.303, -7.919]
Step 1816 4 visits [1.0, 1000.0, 1.0, 13.0, 323.0, 1.0, 1.0]  episode_count: 3086 q_vals: [-6.914, -inf, -8.182, -5.512, -4.39, -9.303, -7.919]
Step 1817 4 visits [1.0, 1000.0, 1.0, 13.0, 324.0, 1.0, 1.0]  episode_count: 3089 q_vals: [-6.914, -inf, -8.182, -5.512, -4.389, -9.303, -7.919]
Step 1818 4 visits [1.0, 1000.0, 1.0, 13.0, 325.0, 1.0, 1.0]  episode_count: 3091 q_vals: [-6.914, -inf, -8.182, -5.512, -4.415, -9.303, -7.919]
{"total_number_of_episodes": 3092, "number_of_timesteps": 57369, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1819 4 visits [1.0, 1000.0, 1.0, 13.0, 326.0, 1.0, 1.0]  episode_count: 3092 q_vals: [-6.914, -inf, -8.182, -5.512, -4.441, -9.303, -7.919]
Step 1820 4 visits [1.0, 1000.0, 1.0, 13.0, 327.0, 1.0, 1.0]  episode_count: 3093 q_vals: [-6.914, -inf, -8.182, -5.512, -4.427, -9.303, -7.919]
Step 1821 4 visits [1.0, 1000.0, 1.0, 13.0, 328.0, 1.0, 1.0]  episode_count: 3096 q_vals: [-6.914, -inf, -8.182, -5.512, -4.431, -9.303, -7.919]
Step 1822 4 visits [1.0, 1000.0, 1.0, 13.0, 329.0, 1.0, 1.0]  episode_count: 3098 q_vals: [-6.914, -inf, -8.182, -5.512, -4.437, -9.303, -7.919]
Step 1823 4 visits [1.0, 1000.0, 1.0, 13.0, 330.0, 1.0, 1.0]  episode_count: 3100 q_vals: [-6.914, -inf, -8.182, -5.512, -4.438, -9.303, -7.919]
Step 1824 4 visits [1.0, 1000.0, 1.0, 13.0, 331.0, 1.0, 1.0]  episode_count: 3100 q_vals: [-6.914, -inf, -8.182, -5.512, -4.439, -9.303, -7.919]
{"total_number_of_episodes": 3103, "number_of_timesteps": 57566, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1825 4 visits [1.0, 1000.0, 1.0, 13.0, 332.0, 1.0, 1.0]  episode_count: 3103 q_vals: [-6.914, -inf, -8.182, -5.512, -4.445, -9.303, -7.919]
Step 1826 4 visits [1.0, 1000.0, 1.0, 13.0, 333.0, 1.0, 1.0]  episode_count: 3104 q_vals: [-6.914, -inf, -8.182, -5.512, -4.444, -9.303, -7.919]
Step 1827 4 visits [1.0, 1000.0, 1.0, 13.0, 334.0, 1.0, 1.0]  episode_count: 3106 q_vals: [-6.914, -inf, -8.182, -5.512, -4.431, -9.303, -7.919]
Step 1828 4 visits [1.0, 1000.0, 1.0, 13.0, 335.0, 1.0, 1.0]  episode_count: 3107 q_vals: [-6.914, -inf, -8.182, -5.512, -4.43, -9.303, -7.919]
Step 1829 4 visits [1.0, 1000.0, 1.0, 13.0, 336.0, 1.0, 1.0]  episode_count: 3110 q_vals: [-6.914, -inf, -8.182, -5.512, -4.438, -9.303, -7.919]
Step 1830 4 visits [1.0, 1000.0, 1.0, 13.0, 337.0, 1.0, 1.0]  episode_count: 3111 q_vals: [-6.914, -inf, -8.182, -5.512, -4.437, -9.303, -7.919]
Step 1831 4 visits [1.0, 1000.0, 1.0, 13.0, 338.0, 1.0, 1.0]  episode_count: 3111 q_vals: [-6.914, -inf, -8.182, -5.512, -4.439, -9.303, -7.919]
Step 1832 4 visits [1.0, 1000.0, 1.0, 13.0, 339.0, 1.0, 1.0]  episode_count: 3112 q_vals: [-6.914, -inf, -8.182, -5.512, -4.463, -9.303, -7.919]
{"total_number_of_episodes": 3114, "number_of_timesteps": 57789, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1833 4 visits [1.0, 1000.0, 1.0, 13.0, 340.0, 1.0, 1.0]  episode_count: 3114 q_vals: [-6.914, -inf, -8.182, -5.512, -4.464, -9.303, -7.919]
Step 1834 4 visits [1.0, 1000.0, 1.0, 13.0, 341.0, 1.0, 1.0]  episode_count: 3115 q_vals: [-6.914, -inf, -8.182, -5.512, -4.451, -9.303, -7.919]
Step 1835 4 visits [1.0, 1000.0, 1.0, 13.0, 342.0, 1.0, 1.0]  episode_count: 3118 q_vals: [-6.914, -inf, -8.182, -5.512, -4.453, -9.303, -7.919]
Step 1836 4 visits [1.0, 1000.0, 1.0, 13.0, 343.0, 1.0, 1.0]  episode_count: 3120 q_vals: [-6.914, -inf, -8.182, -5.512, -4.455, -9.303, -7.919]
Step 1837 4 visits [1.0, 1000.0, 1.0, 13.0, 344.0, 1.0, 1.0]  episode_count: 3120 q_vals: [-6.914, -inf, -8.182, -5.512, -4.456, -9.303, -7.919]
Step 1838 4 visits [1.0, 1000.0, 1.0, 13.0, 345.0, 1.0, 1.0]  episode_count: 3120 q_vals: [-6.914, -inf, -8.182, -5.512, -4.443, -9.303, -7.919]
Step 1839 4 visits [1.0, 1000.0, 1.0, 13.0, 346.0, 1.0, 1.0]  episode_count: 3122 q_vals: [-6.914, -inf, -8.182, -5.512, -4.43, -9.303, -7.919]
Step 1840 4 visits [1.0, 1000.0, 1.0, 13.0, 347.0, 1.0, 1.0]  episode_count: 3123 q_vals: [-6.914, -inf, -8.182, -5.512, -4.417, -9.303, -7.919]
{"total_number_of_episodes": 3124, "number_of_timesteps": 57993, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1841 4 visits [1.0, 1000.0, 1.0, 13.0, 348.0, 1.0, 1.0]  episode_count: 3124 q_vals: [-6.914, -inf, -8.182, -5.512, -4.418, -9.303, -7.919]
Step 1842 4 visits [1.0, 1000.0, 1.0, 13.0, 349.0, 1.0, 1.0]  episode_count: 3125 q_vals: [-6.914, -inf, -8.182, -5.512, -4.42, -9.303, -7.919]
Step 1843 4 visits [1.0, 1000.0, 1.0, 13.0, 350.0, 1.0, 1.0]  episode_count: 3127 q_vals: [-6.914, -inf, -8.182, -5.512, -4.418, -9.303, -7.919]
Step 1844 4 visits [1.0, 1000.0, 1.0, 13.0, 351.0, 1.0, 1.0]  episode_count: 3127 q_vals: [-6.914, -inf, -8.182, -5.512, -4.418, -9.303, -7.919]
Step 1845 4 visits [1.0, 1000.0, 1.0, 13.0, 352.0, 1.0, 1.0]  episode_count: 3127 q_vals: [-6.914, -inf, -8.182, -5.512, -4.442, -9.303, -7.919]
Step 1846 4 visits [1.0, 1000.0, 1.0, 13.0, 353.0, 1.0, 1.0]  episode_count: 3130 q_vals: [-6.914, -inf, -8.182, -5.512, -4.44, -9.303, -7.919]
Step 1847 4 visits [1.0, 1000.0, 1.0, 13.0, 354.0, 1.0, 1.0]  episode_count: 3131 q_vals: [-6.914, -inf, -8.182, -5.512, -4.427, -9.303, -7.919]
Step 1848 4 visits [1.0, 1000.0, 1.0, 13.0, 355.0, 1.0, 1.0]  episode_count: 3133 q_vals: [-6.914, -inf, -8.182, -5.512, -4.451, -9.303, -7.919]
{"total_number_of_episodes": 3134, "number_of_timesteps": 58318, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1849 4 visits [1.0, 1000.0, 1.0, 13.0, 356.0, 1.0, 1.0]  episode_count: 3134 q_vals: [-6.914, -inf, -8.182, -5.512, -4.452, -9.303, -7.919]
Step 1850 4 visits [1.0, 1000.0, 1.0, 13.0, 357.0, 1.0, 1.0]  episode_count: 3135 q_vals: [-6.914, -inf, -8.182, -5.512, -4.44, -9.303, -7.919]
Step 1851 4 visits [1.0, 1000.0, 1.0, 13.0, 358.0, 1.0, 1.0]  episode_count: 3136 q_vals: [-6.914, -inf, -8.182, -5.512, -4.43, -9.303, -7.919]
Step 1852 4 visits [1.0, 1000.0, 1.0, 13.0, 359.0, 1.0, 1.0]  episode_count: 3137 q_vals: [-6.914, -inf, -8.182, -5.512, -4.449, -9.303, -7.919]
Step 1853 4 visits [1.0, 1000.0, 1.0, 13.0, 360.0, 1.0, 1.0]  episode_count: 3138 q_vals: [-6.914, -inf, -8.182, -5.512, -4.45, -9.303, -7.919]
Step 1854 4 visits [1.0, 1000.0, 1.0, 13.0, 361.0, 1.0, 1.0]  episode_count: 3140 q_vals: [-6.914, -inf, -8.182, -5.512, -4.457, -9.303, -7.919]
Step 1855 4 visits [1.0, 1000.0, 1.0, 13.0, 362.0, 1.0, 1.0]  episode_count: 3141 q_vals: [-6.914, -inf, -8.182, -5.512, -4.46, -9.303, -7.919]
Step 1856 4 visits [1.0, 1000.0, 1.0, 13.0, 363.0, 1.0, 1.0]  episode_count: 3142 q_vals: [-6.914, -inf, -8.182, -5.512, -4.458, -9.303, -7.919]
{"total_number_of_episodes": 3147, "number_of_timesteps": 58620, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1857 4 visits [1.0, 1000.0, 1.0, 13.0, 364.0, 1.0, 1.0]  episode_count: 3147 q_vals: [-6.914, -inf, -8.182, -5.512, -4.457, -9.303, -7.919]
Step 1858 4 visits [1.0, 1000.0, 1.0, 13.0, 365.0, 1.0, 1.0]  episode_count: 3147 q_vals: [-6.914, -inf, -8.182, -5.512, -4.453, -9.303, -7.919]
Step 1859 4 visits [1.0, 1000.0, 1.0, 13.0, 366.0, 1.0, 1.0]  episode_count: 3148 q_vals: [-6.914, -inf, -8.182, -5.512, -4.452, -9.303, -7.919]
Step 1860 4 visits [1.0, 1000.0, 1.0, 13.0, 367.0, 1.0, 1.0]  episode_count: 3151 q_vals: [-6.914, -inf, -8.182, -5.512, -4.44, -9.303, -7.919]
Step 1861 4 visits [1.0, 1000.0, 1.0, 13.0, 368.0, 1.0, 1.0]  episode_count: 3153 q_vals: [-6.914, -inf, -8.182, -5.512, -4.445, -9.303, -7.919]
Step 1862 4 visits [1.0, 1000.0, 1.0, 13.0, 369.0, 1.0, 1.0]  episode_count: 3154 q_vals: [-6.914, -inf, -8.182, -5.512, -4.447, -9.303, -7.919]
Step 1863 4 visits [1.0, 1000.0, 1.0, 13.0, 370.0, 1.0, 1.0]  episode_count: 3155 q_vals: [-6.914, -inf, -8.182, -5.512, -4.447, -9.303, -7.919]
{"total_number_of_episodes": 3158, "number_of_timesteps": 58810, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1864 4 visits [1.0, 1000.0, 1.0, 13.0, 371.0, 1.0, 1.0]  episode_count: 3158 q_vals: [-6.914, -inf, -8.182, -5.512, -4.448, -9.303, -7.919]
Step 1865 4 visits [1.0, 1000.0, 1.0, 13.0, 372.0, 1.0, 1.0]  episode_count: 3159 q_vals: [-6.914, -inf, -8.182, -5.512, -4.446, -9.303, -7.919]
Step 1866 4 visits [1.0, 1000.0, 1.0, 13.0, 373.0, 1.0, 1.0]  episode_count: 3161 q_vals: [-6.914, -inf, -8.182, -5.512, -4.434, -9.303, -7.919]
Step 1867 4 visits [1.0, 1000.0, 1.0, 13.0, 374.0, 1.0, 1.0]  episode_count: 3163 q_vals: [-6.914, -inf, -8.182, -5.512, -4.435, -9.303, -7.919]
Step 1868 4 visits [1.0, 1000.0, 1.0, 13.0, 375.0, 1.0, 1.0]  episode_count: 3164 q_vals: [-6.914, -inf, -8.182, -5.512, -4.423, -9.303, -7.919]
Step 1869 4 visits [1.0, 1000.0, 1.0, 13.0, 376.0, 1.0, 1.0]  episode_count: 3167 q_vals: [-6.914, -inf, -8.182, -5.512, -4.425, -9.303, -7.919]
{"total_number_of_episodes": 3168, "number_of_timesteps": 58979, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1870 4 visits [1.0, 1000.0, 1.0, 13.0, 377.0, 1.0, 1.0]  episode_count: 3168 q_vals: [-6.914, -inf, -8.182, -5.512, -4.447, -9.303, -7.919]
Step 1871 4 visits [1.0, 1000.0, 1.0, 13.0, 378.0, 1.0, 1.0]  episode_count: 3171 q_vals: [-6.914, -inf, -8.182, -5.512, -4.449, -9.303, -7.919]
Step 1872 4 visits [1.0, 1000.0, 1.0, 13.0, 379.0, 1.0, 1.0]  episode_count: 3174 q_vals: [-6.914, -inf, -8.182, -5.512, -4.449, -9.303, -7.919]
Step 1873 4 visits [1.0, 1000.0, 1.0, 13.0, 380.0, 1.0, 1.0]  episode_count: 3176 q_vals: [-6.914, -inf, -8.182, -5.512, -4.447, -9.303, -7.919]
Step 1874 4 visits [1.0, 1000.0, 1.0, 13.0, 381.0, 1.0, 1.0]  episode_count: 3177 q_vals: [-6.914, -inf, -8.182, -5.512, -4.449, -9.303, -7.919]
{"total_number_of_episodes": 3180, "number_of_timesteps": 59152, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1875 4 visits [1.0, 1000.0, 1.0, 13.0, 382.0, 1.0, 1.0]  episode_count: 3180 q_vals: [-6.914, -inf, -8.182, -5.512, -4.437, -9.303, -7.919]
Step 1876 4 visits [1.0, 1000.0, 1.0, 13.0, 383.0, 1.0, 1.0]  episode_count: 3183 q_vals: [-6.914, -inf, -8.182, -5.512, -4.425, -9.303, -7.919]
Step 1877 4 visits [1.0, 1000.0, 1.0, 13.0, 384.0, 1.0, 1.0]  episode_count: 3184 q_vals: [-6.914, -inf, -8.182, -5.512, -4.447, -9.303, -7.919]
Step 1878 4 visits [1.0, 1000.0, 1.0, 13.0, 385.0, 1.0, 1.0]  episode_count: 3186 q_vals: [-6.914, -inf, -8.182, -5.512, -4.453, -9.303, -7.919]
Step 1879 4 visits [1.0, 1000.0, 1.0, 13.0, 386.0, 1.0, 1.0]  episode_count: 3188 q_vals: [-6.914, -inf, -8.182, -5.512, -4.451, -9.303, -7.919]
{"total_number_of_episodes": 3190, "number_of_timesteps": 59308, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1880 4 visits [1.0, 1000.0, 1.0, 13.0, 387.0, 1.0, 1.0]  episode_count: 3190 q_vals: [-6.914, -inf, -8.182, -5.512, -4.45, -9.303, -7.919]
Step 1881 4 visits [1.0, 1000.0, 1.0, 13.0, 388.0, 1.0, 1.0]  episode_count: 3192 q_vals: [-6.914, -inf, -8.182, -5.512, -4.438, -9.303, -7.919]
Step 1882 4 visits [1.0, 1000.0, 1.0, 13.0, 389.0, 1.0, 1.0]  episode_count: 3195 q_vals: [-6.914, -inf, -8.182, -5.512, -4.438, -9.303, -7.919]
Step 1883 4 visits [1.0, 1000.0, 1.0, 13.0, 390.0, 1.0, 1.0]  episode_count: 3197 q_vals: [-6.914, -inf, -8.182, -5.512, -4.439, -9.303, -7.919]
Step 1884 4 visits [1.0, 1000.0, 1.0, 13.0, 391.0, 1.0, 1.0]  episode_count: 3199 q_vals: [-6.914, -inf, -8.182, -5.512, -4.441, -9.303, -7.919]
{"total_number_of_episodes": 3202, "number_of_timesteps": 59469, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1885 4 visits [1.0, 1000.0, 1.0, 13.0, 392.0, 1.0, 1.0]  episode_count: 3202 q_vals: [-6.914, -inf, -8.182, -5.512, -4.442, -9.303, -7.919]
Step 1886 4 visits [1.0, 1000.0, 1.0, 13.0, 393.0, 1.0, 1.0]  episode_count: 3202 q_vals: [-6.914, -inf, -8.182, -5.512, -4.43, -9.303, -7.919]
Step 1887 4 visits [1.0, 1000.0, 1.0, 13.0, 394.0, 1.0, 1.0]  episode_count: 3205 q_vals: [-6.914, -inf, -8.182, -5.512, -4.432, -9.303, -7.919]
Step 1888 4 visits [1.0, 1000.0, 1.0, 13.0, 395.0, 1.0, 1.0]  episode_count: 3207 q_vals: [-6.914, -inf, -8.182, -5.512, -4.434, -9.303, -7.919]
Step 1889 4 visits [1.0, 1000.0, 1.0, 13.0, 396.0, 1.0, 1.0]  episode_count: 3209 q_vals: [-6.914, -inf, -8.182, -5.512, -4.435, -9.303, -7.919]
Step 1890 4 visits [1.0, 1000.0, 1.0, 13.0, 397.0, 1.0, 1.0]  episode_count: 3210 q_vals: [-6.914, -inf, -8.182, -5.512, -4.434, -9.303, -7.919]
{"total_number_of_episodes": 3212, "number_of_timesteps": 59627, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1891 4 visits [1.0, 1000.0, 1.0, 13.0, 398.0, 1.0, 1.0]  episode_count: 3212 q_vals: [-6.914, -inf, -8.182, -5.512, -4.434, -9.303, -7.919]
Step 1892 4 visits [1.0, 1000.0, 1.0, 13.0, 399.0, 1.0, 1.0]  episode_count: 3214 q_vals: [-6.914, -inf, -8.182, -5.512, -4.423, -9.303, -7.919]
Step 1893 4 visits [1.0, 1000.0, 1.0, 13.0, 400.0, 1.0, 1.0]  episode_count: 3214 q_vals: [-6.914, -inf, -8.182, -5.512, -4.423, -9.303, -7.919]
Step 1894 4 visits [1.0, 1000.0, 1.0, 13.0, 401.0, 1.0, 1.0]  episode_count: 3216 q_vals: [-6.914, -inf, -8.182, -5.512, -4.421, -9.303, -7.919]
Step 1895 4 visits [1.0, 1000.0, 1.0, 13.0, 402.0, 1.0, 1.0]  episode_count: 3219 q_vals: [-6.914, -inf, -8.182, -5.512, -4.425, -9.303, -7.919]
Step 1896 4 visits [1.0, 1000.0, 1.0, 13.0, 403.0, 1.0, 1.0]  episode_count: 3219 q_vals: [-6.914, -inf, -8.182, -5.512, -4.428, -9.303, -7.919]
Step 1897 4 visits [1.0, 1000.0, 1.0, 13.0, 404.0, 1.0, 1.0]  episode_count: 3221 q_vals: [-6.914, -inf, -8.182, -5.512, -4.417, -9.303, -7.919]
{"total_number_of_episodes": 3224, "number_of_timesteps": 59837, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1898 4 visits [1.0, 1000.0, 1.0, 13.0, 405.0, 1.0, 1.0]  episode_count: 3224 q_vals: [-6.914, -inf, -8.182, -5.512, -4.406, -9.303, -7.919]
Step 1899 4 visits [1.0, 1000.0, 1.0, 13.0, 406.0, 1.0, 1.0]  episode_count: 3224 q_vals: [-6.914, -inf, -8.182, -5.512, -4.395, -9.303, -7.919]
Step 1900 4 visits [1.0, 1000.0, 1.0, 13.0, 407.0, 1.0, 1.0]  episode_count: 3224 q_vals: [-6.914, -inf, -8.182, -5.512, -4.394, -9.303, -7.919]
Step 1901 4 visits [1.0, 1000.0, 1.0, 13.0, 408.0, 1.0, 1.0]  episode_count: 3226 q_vals: [-6.914, -inf, -8.182, -5.512, -4.383, -9.303, -7.919]
Step 1902 4 visits [1.0, 1000.0, 1.0, 13.0, 409.0, 1.0, 1.0]  episode_count: 3229 q_vals: [-6.914, -inf, -8.182, -5.512, -4.373, -9.303, -7.919]
Step 1903 4 visits [1.0, 1000.0, 1.0, 13.0, 410.0, 1.0, 1.0]  episode_count: 3229 q_vals: [-6.914, -inf, -8.182, -5.512, -4.393, -9.303, -7.919]
Step 1904 4 visits [1.0, 1000.0, 1.0, 13.0, 411.0, 1.0, 1.0]  episode_count: 3231 q_vals: [-6.914, -inf, -8.182, -5.512, -4.414, -9.303, -7.919]
{"total_number_of_episodes": 3234, "number_of_timesteps": 60082, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1905 4 visits [1.0, 1000.0, 1.0, 13.0, 412.0, 1.0, 1.0]  episode_count: 3234 q_vals: [-6.914, -inf, -8.182, -5.512, -4.412, -9.303, -7.919]
Step 1906 4 visits [1.0, 1000.0, 1.0, 13.0, 413.0, 1.0, 1.0]  episode_count: 3234 q_vals: [-6.914, -inf, -8.182, -5.512, -4.402, -9.303, -7.919]
Step 1907 4 visits [1.0, 1000.0, 1.0, 13.0, 414.0, 1.0, 1.0]  episode_count: 3237 q_vals: [-6.914, -inf, -8.182, -5.512, -4.403, -9.303, -7.919]
Step 1908 4 visits [1.0, 1000.0, 1.0, 13.0, 415.0, 1.0, 1.0]  episode_count: 3237 q_vals: [-6.914, -inf, -8.182, -5.512, -4.402, -9.303, -7.919]
Step 1909 4 visits [1.0, 1000.0, 1.0, 13.0, 416.0, 1.0, 1.0]  episode_count: 3238 q_vals: [-6.914, -inf, -8.182, -5.512, -4.391, -9.303, -7.919]
Step 1910 4 visits [1.0, 1000.0, 1.0, 13.0, 417.0, 1.0, 1.0]  episode_count: 3240 q_vals: [-6.914, -inf, -8.182, -5.512, -4.39, -9.303, -7.919]
{"total_number_of_episodes": 3244, "number_of_timesteps": 60271, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1911 4 visits [1.0, 1000.0, 1.0, 13.0, 418.0, 1.0, 1.0]  episode_count: 3244 q_vals: [-6.914, -inf, -8.182, -5.512, -4.389, -9.303, -7.919]
Step 1912 4 visits [1.0, 1000.0, 1.0, 13.0, 419.0, 1.0, 1.0]  episode_count: 3244 q_vals: [-6.914, -inf, -8.182, -5.512, -4.378, -9.303, -7.919]
Step 1913 4 visits [1.0, 1000.0, 1.0, 13.0, 420.0, 1.0, 1.0]  episode_count: 3246 q_vals: [-6.914, -inf, -8.182, -5.512, -4.368, -9.303, -7.919]
Step 1914 4 visits [1.0, 1000.0, 1.0, 13.0, 421.0, 1.0, 1.0]  episode_count: 3248 q_vals: [-6.914, -inf, -8.182, -5.512, -4.358, -9.303, -7.919]
Step 1915 4 visits [1.0, 1000.0, 1.0, 13.0, 422.0, 1.0, 1.0]  episode_count: 3251 q_vals: [-6.914, -inf, -8.182, -5.512, -4.358, -9.303, -7.919]
Step 1916 4 visits [1.0, 1000.0, 1.0, 13.0, 423.0, 1.0, 1.0]  episode_count: 3253 q_vals: [-6.914, -inf, -8.182, -5.512, -4.347, -9.303, -7.919]
{"total_number_of_episodes": 3254, "number_of_timesteps": 60446, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1917 4 visits [1.0, 1000.0, 1.0, 13.0, 424.0, 1.0, 1.0]  episode_count: 3254 q_vals: [-6.914, -inf, -8.182, -5.512, -4.337, -9.303, -7.919]
Step 1918 4 visits [1.0, 1000.0, 1.0, 13.0, 425.0, 1.0, 1.0]  episode_count: 3256 q_vals: [-6.914, -inf, -8.182, -5.512, -4.327, -9.303, -7.919]
Step 1919 4 visits [1.0, 1000.0, 1.0, 13.0, 426.0, 1.0, 1.0]  episode_count: 3260 q_vals: [-6.914, -inf, -8.182, -5.512, -4.325, -9.303, -7.919]
Step 1920 4 visits [1.0, 1000.0, 1.0, 13.0, 427.0, 1.0, 1.0]  episode_count: 3260 q_vals: [-6.914, -inf, -8.182, -5.512, -4.324, -9.303, -7.919]
Step 1921 4 visits [1.0, 1000.0, 1.0, 13.0, 428.0, 1.0, 1.0]  episode_count: 3260 q_vals: [-6.914, -inf, -8.182, -5.512, -4.325, -9.303, -7.919]
Step 1922 4 visits [1.0, 1000.0, 1.0, 13.0, 429.0, 1.0, 1.0]  episode_count: 3262 q_vals: [-6.914, -inf, -8.182, -5.512, -4.325, -9.303, -7.919]
{"total_number_of_episodes": 3264, "number_of_timesteps": 60612, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1923 4 visits [1.0, 1000.0, 1.0, 13.0, 430.0, 1.0, 1.0]  episode_count: 3264 q_vals: [-6.914, -inf, -8.182, -5.512, -4.315, -9.303, -7.919]
Step 1924 4 visits [1.0, 1000.0, 1.0, 13.0, 431.0, 1.0, 1.0]  episode_count: 3264 q_vals: [-6.914, -inf, -8.182, -5.512, -4.314, -9.303, -7.919]
Step 1925 4 visits [1.0, 1000.0, 1.0, 13.0, 432.0, 1.0, 1.0]  episode_count: 3265 q_vals: [-6.914, -inf, -8.182, -5.512, -4.313, -9.303, -7.919]
Step 1926 4 visits [1.0, 1000.0, 1.0, 13.0, 433.0, 1.0, 1.0]  episode_count: 3267 q_vals: [-6.914, -inf, -8.182, -5.512, -4.314, -9.303, -7.919]
Step 1927 4 visits [1.0, 1000.0, 1.0, 13.0, 434.0, 1.0, 1.0]  episode_count: 3267 q_vals: [-6.914, -inf, -8.182, -5.512, -4.312, -9.303, -7.919]
Step 1928 4 visits [1.0, 1000.0, 1.0, 13.0, 435.0, 1.0, 1.0]  episode_count: 3270 q_vals: [-6.914, -inf, -8.182, -5.512, -4.313, -9.303, -7.919]
Step 1929 4 visits [1.0, 1000.0, 1.0, 13.0, 436.0, 1.0, 1.0]  episode_count: 3271 q_vals: [-6.914, -inf, -8.182, -5.512, -4.304, -9.303, -7.919]
Step 1930 4 visits [1.0, 1000.0, 1.0, 13.0, 437.0, 1.0, 1.0]  episode_count: 3273 q_vals: [-6.914, -inf, -8.182, -5.512, -4.307, -9.303, -7.919]
Step 1931 4 visits [1.0, 1000.0, 1.0, 13.0, 438.0, 1.0, 1.0]  episode_count: 3273 q_vals: [-6.914, -inf, -8.182, -5.512, -4.297, -9.303, -7.919]
Step 1932 4 visits [1.0, 1000.0, 1.0, 13.0, 439.0, 1.0, 1.0]  episode_count: 3273 q_vals: [-6.914, -inf, -8.182, -5.512, -4.296, -9.303, -7.919]
{"total_number_of_episodes": 3276, "number_of_timesteps": 60927, "per_episode_reward": 13.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1933 4 visits [1.0, 1000.0, 1.0, 13.0, 440.0, 1.0, 1.0]  episode_count: 3276 q_vals: [-6.914, -inf, -8.182, -5.512, -4.286, -9.303, -7.919]
Step 1934 4 visits [1.0, 1000.0, 1.0, 13.0, 441.0, 1.0, 1.0]  episode_count: 3277 q_vals: [-6.914, -inf, -8.182, -5.512, -4.277, -9.303, -7.919]
Step 1935 4 visits [1.0, 1000.0, 1.0, 13.0, 442.0, 1.0, 1.0]  episode_count: 3278 q_vals: [-6.914, -inf, -8.182, -5.512, -4.28, -9.303, -7.919]
Step 1936 4 visits [1.0, 1000.0, 1.0, 13.0, 443.0, 1.0, 1.0]  episode_count: 3281 q_vals: [-6.914, -inf, -8.182, -5.512, -4.27, -9.303, -7.919]
Step 1937 4 visits [1.0, 1000.0, 1.0, 13.0, 444.0, 1.0, 1.0]  episode_count: 3282 q_vals: [-6.914, -inf, -8.182, -5.512, -4.26, -9.303, -7.919]
Step 1938 4 visits [1.0, 1000.0, 1.0, 13.0, 445.0, 1.0, 1.0]  episode_count: 3282 q_vals: [-6.914, -inf, -8.182, -5.512, -4.259, -9.303, -7.919]
Step 1939 4 visits [1.0, 1000.0, 1.0, 13.0, 446.0, 1.0, 1.0]  episode_count: 3284 q_vals: [-6.914, -inf, -8.182, -5.512, -4.25, -9.303, -7.919]
{"total_number_of_episodes": 3289, "number_of_timesteps": 61228, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.14285714285714235},
Step 1940 4 visits [1.0, 1000.0, 1.0, 13.0, 447.0, 1.0, 1.0]  episode_count: 3289 q_vals: [-6.914, -inf, -8.182, -5.512, -4.25, -9.303, -7.919]
Step 1941 4 visits [1.0, 1000.0, 1.0, 13.0, 448.0, 1.0, 1.0]  episode_count: 3289 q_vals: [-6.914, -inf, -8.182, -5.512, -4.269, -9.303, -7.919]
Step 1942 4 visits [1.0, 1000.0, 1.0, 13.0, 449.0, 1.0, 1.0]  episode_count: 3291 q_vals: [-6.914, -inf, -8.182, -5.512, -4.26, -9.303, -7.919]
Step 1943 4 visits [1.0, 1000.0, 1.0, 13.0, 450.0, 1.0, 1.0]  episode_count: 3291 q_vals: [-6.914, -inf, -8.182, -5.512, -4.25, -9.303, -7.919]
Step 1944 4 visits [1.0, 1000.0, 1.0, 13.0, 451.0, 1.0, 1.0]  episode_count: 3293 q_vals: [-6.914, -inf, -8.182, -5.512, -4.251, -9.303, -7.919]
Step 1945 4 visits [1.0, 1000.0, 1.0, 13.0, 452.0, 1.0, 1.0]  episode_count: 3297 q_vals: [-6.914, -inf, -8.182, -5.512, -4.241, -9.303, -7.919]
Step 1946 4 visits [1.0, 1000.0, 1.0, 13.0, 453.0, 1.0, 1.0]  episode_count: 3298 q_vals: [-6.914, -inf, -8.182, -5.512, -4.232, -9.303, -7.919]
{"total_number_of_episodes": 3301, "number_of_timesteps": 61420, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714235},
Step 1947 4 visits [1.0, 1000.0, 1.0, 13.0, 454.0, 1.0, 1.0]  episode_count: 3301 q_vals: [-6.914, -inf, -8.182, -5.512, -4.231, -9.303, -7.919]
Step 1948 4 visits [1.0, 1000.0, 1.0, 13.0, 455.0, 1.0, 1.0]  episode_count: 3303 q_vals: [-6.914, -inf, -8.182, -5.512, -4.221, -9.303, -7.919]
Step 1949 4 visits [1.0, 1000.0, 1.0, 13.0, 456.0, 1.0, 1.0]  episode_count: 3304 q_vals: [-6.914, -inf, -8.182, -5.512, -4.222, -9.303, -7.919]
Step 1950 4 visits [1.0, 1000.0, 1.0, 13.0, 457.0, 1.0, 1.0]  episode_count: 3307 q_vals: [-6.914, -inf, -8.182, -5.512, -4.224, -9.303, -7.919]
Step 1951 4 visits [1.0, 1000.0, 1.0, 13.0, 458.0, 1.0, 1.0]  episode_count: 3310 q_vals: [-6.914, -inf, -8.182, -5.512, -4.223, -9.303, -7.919]
{"total_number_of_episodes": 3311, "number_of_timesteps": 61569, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714235},
Step 1952 4 visits [1.0, 1000.0, 1.0, 13.0, 459.0, 1.0, 1.0]  episode_count: 3311 q_vals: [-6.914, -inf, -8.182, -5.512, -4.224, -9.303, -7.919]
Step 1953 4 visits [1.0, 1000.0, 1.0, 13.0, 460.0, 1.0, 1.0]  episode_count: 3312 q_vals: [-6.914, -inf, -8.182, -5.512, -4.214, -9.303, -7.919]
Step 1954 4 visits [1.0, 1000.0, 1.0, 13.0, 461.0, 1.0, 1.0]  episode_count: 3314 q_vals: [-6.914, -inf, -8.182, -5.512, -4.215, -9.303, -7.919]
Step 1955 4 visits [1.0, 1000.0, 1.0, 13.0, 462.0, 1.0, 1.0]  episode_count: 3318 q_vals: [-6.914, -inf, -8.182, -5.512, -4.213, -9.303, -7.919]
Step 1956 4 visits [1.0, 1000.0, 1.0, 13.0, 463.0, 1.0, 1.0]  episode_count: 3318 q_vals: [-6.914, -inf, -8.182, -5.512, -4.209, -9.303, -7.919]
Step 1957 4 visits [1.0, 1000.0, 1.0, 13.0, 464.0, 1.0, 1.0]  episode_count: 3319 q_vals: [-6.914, -inf, -8.182, -5.512, -4.2, -9.303, -7.919]
{"total_number_of_episodes": 3323, "number_of_timesteps": 61757, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.14285714285714235},
Step 1958 4 visits [1.0, 1000.0, 1.0, 13.0, 465.0, 1.0, 1.0]  episode_count: 3323 q_vals: [-6.914, -inf, -8.182, -5.512, -4.191, -9.303, -7.919]
Step 1959 4 visits [1.0, 1000.0, 1.0, 13.0, 466.0, 1.0, 1.0]  episode_count: 3324 q_vals: [-6.914, -inf, -8.182, -5.512, -4.192, -9.303, -7.919]
Step 1960 4 visits [1.0, 1000.0, 1.0, 13.0, 467.0, 1.0, 1.0]  episode_count: 3324 q_vals: [-6.914, -inf, -8.182, -5.512, -4.183, -9.303, -7.919]
Step 1961 4 visits [1.0, 1000.0, 1.0, 13.0, 468.0, 1.0, 1.0]  episode_count: 3326 q_vals: [-6.914, -inf, -8.182, -5.512, -4.181, -9.303, -7.919]
Step 1962 4 visits [1.0, 1000.0, 1.0, 13.0, 469.0, 1.0, 1.0]  episode_count: 3327 q_vals: [-6.914, -inf, -8.182, -5.512, -4.18, -9.303, -7.919]
Step 1963 4 visits [1.0, 1000.0, 1.0, 13.0, 470.0, 1.0, 1.0]  episode_count: 3328 q_vals: [-6.914, -inf, -8.182, -5.512, -4.171, -9.303, -7.919]
Step 1964 4 visits [1.0, 1000.0, 1.0, 13.0, 471.0, 1.0, 1.0]  episode_count: 3331 q_vals: [-6.914, -inf, -8.182, -5.512, -4.162, -9.303, -7.919]
{"total_number_of_episodes": 3334, "number_of_timesteps": 61998, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714235},
Step 1965 4 visits [1.0, 1000.0, 1.0, 13.0, 472.0, 1.0, 1.0]  episode_count: 3334 q_vals: [-6.914, -inf, -8.182, -5.512, -4.18, -9.303, -7.919]
Step 1966 4 visits [1.0, 1000.0, 1.0, 13.0, 473.0, 1.0, 1.0]  episode_count: 3335 q_vals: [-6.914, -inf, -8.182, -5.512, -4.171, -9.303, -7.919]
Step 1967 4 visits [1.0, 1000.0, 1.0, 13.0, 474.0, 1.0, 1.0]  episode_count: 3337 q_vals: [-6.914, -inf, -8.182, -5.512, -4.171, -9.303, -7.919]
Step 1968 4 visits [1.0, 1000.0, 1.0, 13.0, 475.0, 1.0, 1.0]  episode_count: 3338 q_vals: [-6.914, -inf, -8.182, -5.512, -4.17, -9.303, -7.919]
Step 1969 4 visits [1.0, 1000.0, 1.0, 13.0, 476.0, 1.0, 1.0]  episode_count: 3340 q_vals: [-6.914, -inf, -8.182, -5.512, -4.169, -9.303, -7.919]
Step 1970 4 visits [1.0, 1000.0, 1.0, 13.0, 477.0, 1.0, 1.0]  episode_count: 3342 q_vals: [-6.914, -inf, -8.182, -5.512, -4.161, -9.303, -7.919]
Step 1971 4 visits [1.0, 1000.0, 1.0, 13.0, 478.0, 1.0, 1.0]  episode_count: 3342 q_vals: [-6.914, -inf, -8.182, -5.512, -4.16, -9.303, -7.919]
{"total_number_of_episodes": 3344, "number_of_timesteps": 62150, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714235},
Step 1972 4 visits [1.0, 1000.0, 1.0, 13.0, 479.0, 1.0, 1.0]  episode_count: 3344 q_vals: [-6.914, -inf, -8.182, -5.512, -4.163, -9.303, -7.919]
Step 1973 4 visits [1.0, 1000.0, 1.0, 13.0, 480.0, 1.0, 1.0]  episode_count: 3348 q_vals: [-6.914, -inf, -8.182, -5.512, -4.154, -9.303, -7.919]
Step 1974 4 visits [1.0, 1000.0, 1.0, 13.0, 481.0, 1.0, 1.0]  episode_count: 3348 q_vals: [-6.914, -inf, -8.182, -5.512, -4.169, -9.303, -7.919]
Step 1975 4 visits [1.0, 1000.0, 1.0, 13.0, 482.0, 1.0, 1.0]  episode_count: 3349 q_vals: [-6.914, -inf, -8.182, -5.512, -4.17, -9.303, -7.919]
Step 1976 4 visits [1.0, 1000.0, 1.0, 13.0, 483.0, 1.0, 1.0]  episode_count: 3349 q_vals: [-6.914, -inf, -8.182, -5.512, -4.172, -9.303, -7.919]
Step 1977 4 visits [1.0, 1000.0, 1.0, 13.0, 484.0, 1.0, 1.0]  episode_count: 3350 q_vals: [-6.914, -inf, -8.182, -5.512, -4.164, -9.303, -7.919]
Step 1978 4 visits [1.0, 1000.0, 1.0, 13.0, 485.0, 1.0, 1.0]  episode_count: 3351 q_vals: [-6.914, -inf, -8.182, -5.512, -4.155, -9.303, -7.919]
{"total_number_of_episodes": 3354, "number_of_timesteps": 62419, "per_episode_reward": 13.36, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
Step 1979 4 visits [1.0, 1000.0, 1.0, 13.0, 486.0, 1.0, 1.0]  episode_count: 3354 q_vals: [-6.914, -inf, -8.182, -5.512, -4.155, -9.303, -7.919]
Step 1980 4 visits [1.0, 1000.0, 1.0, 13.0, 487.0, 1.0, 1.0]  episode_count: 3354 q_vals: [-6.914, -inf, -8.182, -5.512, -4.155, -9.303, -7.919]
Step 1981 4 visits [1.0, 1000.0, 1.0, 13.0, 488.0, 1.0, 1.0]  episode_count: 3357 q_vals: [-6.914, -inf, -8.182, -5.512, -4.154, -9.303, -7.919]
Step 1982 4 visits [1.0, 1000.0, 1.0, 13.0, 489.0, 1.0, 1.0]  episode_count: 3358 q_vals: [-6.914, -inf, -8.182, -5.512, -4.145, -9.303, -7.919]
Step 1983 4 visits [1.0, 1000.0, 1.0, 13.0, 490.0, 1.0, 1.0]  episode_count: 3358 q_vals: [-6.914, -inf, -8.182, -5.512, -4.163, -9.303, -7.919]
Step 1984 4 visits [1.0, 1000.0, 1.0, 13.0, 491.0, 1.0, 1.0]  episode_count: 3360 q_vals: [-6.914, -inf, -8.182, -5.512, -4.162, -9.303, -7.919]
Step 1985 4 visits [1.0, 1000.0, 1.0, 13.0, 492.0, 1.0, 1.0]  episode_count: 3363 q_vals: [-6.914, -inf, -8.182, -5.512, -4.162, -9.303, -7.919]
{"total_number_of_episodes": 3365, "number_of_timesteps": 62669, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
[1.0, 1000.0, 1.0, 13.0, 493.0, 1.0, 1.0]  episode_count: 3365 q_vals: [-6.914, -inf, -8.182, -5.512, -4.154, -9.303, -7.919]
Step 1987 4 visits [1.0, 1000.0, 1.0, 13.0, 494.0, 1.0, 1.0]  episode_count: 3368 q_vals: [-6.914, -inf, -8.182, -5.512, -4.155, -9.303, -7.919]
Step 1988 4 visits [1.0, 1000.0, 1.0, 13.0, 495.0, 1.0, 1.0]  episode_count: 3370 q_vals: [-6.914, -inf, -8.182, -5.512, -4.172, -9.303, -7.919]
Step 1989 4 visits [1.0, 1000.0, 1.0, 13.0, 496.0, 1.0, 1.0]  episode_count: 3373 q_vals: [-6.914, -inf, -8.182, -5.512, -4.171, -9.303, -7.919]
{"total_number_of_episodes": 3375, "number_of_timesteps": 62789, "per_episode_reward": 13.36, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1990 4 visits [1.0, 1000.0, 1.0, 13.0, 497.0, 1.0, 1.0]  episode_count: 3375 q_vals: [-6.914, -inf, -8.182, -5.512, -4.171, -9.303, -7.919]
Step 1991 4 visits [1.0, 1000.0, 1.0, 13.0, 498.0, 1.0, 1.0]  episode_count: 3376 q_vals: [-6.914, -inf, -8.182, -5.512, -4.162, -9.303, -7.919]
Step 1992 4 visits [1.0, 1000.0, 1.0, 13.0, 499.0, 1.0, 1.0]  episode_count: 3379 q_vals: [-6.914, -inf, -8.182, -5.512, -4.161, -9.303, -7.919]
Step 1993 4 visits [1.0, 1000.0, 1.0, 13.0, 500.0, 1.0, 1.0]  episode_count: 3382 q_vals: [-6.914, -inf, -8.182, -5.512, -4.161, -9.303, -7.919]
{"total_number_of_episodes": 3385, "number_of_timesteps": 62915, "per_episode_reward": 13.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1994 4 visits [1.0, 1000.0, 1.0, 13.0, 501.0, 1.0, 1.0]  episode_count: 3385 q_vals: [-6.914, -inf, -8.182, -5.512, -4.161, -9.303, -7.919]
Step 1995 4 visits [1.0, 1000.0, 1.0, 13.0, 502.0, 1.0, 1.0]  episode_count: 3386 q_vals: [-6.914, -inf, -8.182, -5.512, -4.153, -9.303, -7.919]
Step 1996 4 visits [1.0, 1000.0, 1.0, 13.0, 503.0, 1.0, 1.0]  episode_count: 3389 q_vals: [-6.914, -inf, -8.182, -5.512, -4.153, -9.303, -7.919]
Step 1997 4 visits [1.0, 1000.0, 1.0, 13.0, 504.0, 1.0, 1.0]  episode_count: 3391 q_vals: [-6.914, -inf, -8.182, -5.512, -4.152, -9.303, -7.919]
Step 1998 4 visits [1.0, 1000.0, 1.0, 13.0, 505.0, 1.0, 1.0]  episode_count: 3394 q_vals: [-6.914, -inf, -8.182, -5.512, -4.144, -9.303, -7.919]
{"total_number_of_episodes": 3396, "number_of_timesteps": 63057, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1999 4 visits [1.0, 1000.0, 1.0, 13.0, 506.0, 1.0, 1.0]  episode_count: 3396 q_vals: [-6.914, -inf, -8.182, -5.512, -4.143, -9.303, -7.919]
Step 2000 4 visits [1.0, 1000.0, 1.0, 13.0, 507.0, 1.0, 1.0]  episode_count: 3398 q_vals: [-6.914, -inf, -8.182, -5.512, -4.142, -9.303, -7.919]
Step 2001 4 visits [1.0, 1000.0, 1.0, 13.0, 508.0, 1.0, 1.0]  episode_count: 3400 q_vals: [-6.914, -inf, -8.182, -5.512, -4.142, -9.303, -7.919]
Step 2002 4 visits [1.0, 1000.0, 1.0, 13.0, 509.0, 1.0, 1.0]  episode_count: 3403 q_vals: [-6.914, -inf, -8.182, -5.512, -4.143, -9.303, -7.919]
Step 2003 4 visits [1.0, 1000.0, 1.0, 13.0, 510.0, 1.0, 1.0]  episode_count: 3405 q_vals: [-6.914, -inf, -8.182, -5.512, -4.134, -9.303, -7.919]
{"total_number_of_episodes": 3407, "number_of_timesteps": 63188, "per_episode_reward": 13.21, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.2142857142857153},
Step 2004 4 visits [1.0, 1000.0, 1.0, 13.0, 511.0, 1.0, 1.0]  episode_count: 3407 q_vals: [-6.914, -inf, -8.182, -5.512, -4.135, -9.303, -7.919]
Step 2005 4 visits [1.0, 1000.0, 1.0, 13.0, 512.0, 1.0, 1.0]  episode_count: 3410 q_vals: [-6.914, -inf, -8.182, -5.512, -4.127, -9.303, -7.919]
Step 2006 4 visits [1.0, 1000.0, 1.0, 13.0, 513.0, 1.0, 1.0]  episode_count: 3412 q_vals: [-6.914, -inf, -8.182, -5.512, -4.128, -9.303, -7.919]
Step 2007 4 visits [1.0, 1000.0, 1.0, 13.0, 514.0, 1.0, 1.0]  episode_count: 3413 q_vals: [-6.914, -inf, -8.182, -5.512, -4.127, -9.303, -7.919]
{"total_number_of_episodes": 3417, "number_of_timesteps": 63329, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.2142857142857153},
Step 2008 4 visits [1.0, 1000.0, 1.0, 13.0, 515.0, 1.0, 1.0]  episode_count: 3417 q_vals: [-6.914, -inf, -8.182, -5.512, -4.127, -9.303, -7.919]
Step 2009 4 visits [1.0, 1000.0, 1.0, 13.0, 516.0, 1.0, 1.0]  episode_count: 3419 q_vals: [-6.914, -inf, -8.182, -5.512, -4.126, -9.303, -7.919]
Step 2010 4 visits [1.0, 1000.0, 1.0, 13.0, 517.0, 1.0, 1.0]  episode_count: 3420 q_vals: [-6.914, -inf, -8.182, -5.512, -4.118, -9.303, -7.919]
Step 2011 4 visits [1.0, 1000.0, 1.0, 13.0, 518.0, 1.0, 1.0]  episode_count: 3425 q_vals: [-6.914, -inf, -8.182, -5.512, -4.11, -9.303, -7.919]
Step 2012 4 visits [1.0, 1000.0, 1.0, 13.0, 519.0, 1.0, 1.0]  episode_count: 3426 q_vals: [-6.914, -inf, -8.182, -5.512, -4.11, -9.303, -7.919]
{"total_number_of_episodes": 3427, "number_of_timesteps": 63453, "per_episode_reward": 13.21, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.2142857142857153},
Step 2013 4 visits [1.0, 1000.0, 1.0, 13.0, 520.0, 1.0, 1.0]  episode_count: 3427 q_vals: [-6.914, -inf, -8.182, -5.512, -4.102, -9.303, -7.919]
Step 2014 4 visits [1.0, 1000.0, 1.0, 13.0, 521.0, 1.0, 1.0]  episode_count: 3431 q_vals: [-6.914, -inf, -8.182, -5.512, -4.094, -9.303, -7.919]
Step 2015 4 visits [1.0, 1000.0, 1.0, 13.0, 522.0, 1.0, 1.0]  episode_count: 3434 q_vals: [-6.914, -inf, -8.182, -5.512, -4.086, -9.303, -7.919]
Step 2016 4 visits [1.0, 1000.0, 1.0, 13.0, 523.0, 1.0, 1.0]  episode_count: 3435 q_vals: [-6.914, -inf, -8.182, -5.512, -4.085, -9.303, -7.919]
Step 2017 4 visits [1.0, 1000.0, 1.0, 13.0, 524.0, 1.0, 1.0]  episode_count: 3436 q_vals: [-6.914, -inf, -8.182, -5.512, -4.085, -9.303, -7.919]
{"total_number_of_episodes": 3439, "number_of_timesteps": 63612, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.2142857142857153},
Step 2018 4 visits [1.0, 1000.0, 1.0, 13.0, 525.0, 1.0, 1.0]  episode_count: 3439 q_vals: [-6.914, -inf, -8.182, -5.512, -4.086, -9.303, -7.919]
Step 2019 4 visits [1.0, 1000.0, 1.0, 13.0, 526.0, 1.0, 1.0]  episode_count: 3441 q_vals: [-6.914, -inf, -8.182, -5.512, -4.088, -9.303, -7.919]
Step 2020 4 visits [1.0, 1000.0, 1.0, 13.0, 527.0, 1.0, 1.0]  episode_count: 3442 q_vals: [-6.914, -inf, -8.182, -5.512, -4.104, -9.303, -7.919]
Step 2021 4 visits [1.0, 1000.0, 1.0, 13.0, 528.0, 1.0, 1.0]  episode_count: 3447 q_vals: [-6.914, -inf, -8.182, -5.512, -4.104, -9.303, -7.919]
{"total_number_of_episodes": 3449, "number_of_timesteps": 63754, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.2142857142857153},
Step 2022 4 visits [1.0, 1000.0, 1.0, 13.0, 529.0, 1.0, 1.0]  episode_count: 3449 q_vals: [-6.914, -inf, -8.182, -5.512, -4.104, -9.303, -7.919]
Step 2023 4 visits [1.0, 1000.0, 1.0, 13.0, 530.0, 1.0, 1.0]  episode_count: 3450 q_vals: [-6.914, -inf, -8.182, -5.512, -4.105, -9.303, -7.919]
Step 2024 4 visits [1.0, 1000.0, 1.0, 13.0, 531.0, 1.0, 1.0]  episode_count: 3453 q_vals: [-6.914, -inf, -8.182, -5.512, -4.104, -9.303, -7.919]
Step 2025 4 visits [1.0, 1000.0, 1.0, 13.0, 532.0, 1.0, 1.0]  episode_count: 3456 q_vals: [-6.914, -inf, -8.182, -5.512, -4.096, -9.303, -7.919]
Step 2026 4 visits [1.0, 1000.0, 1.0, 13.0, 533.0, 1.0, 1.0]  episode_count: 3457 q_vals: [-6.914, -inf, -8.182, -5.512, -4.089, -9.303, -7.919]
Step 2027 4 visits [1.0, 1000.0, 1.0, 13.0, 534.0, 1.0, 1.0]  episode_count: 3458 q_vals: [-6.914, -inf, -8.182, -5.512, -4.089, -9.303, -7.919]
{"total_number_of_episodes": 3463, "number_of_timesteps": 63942, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.2142857142857153},
Step 2028 4 visits [1.0, 1000.0, 1.0, 13.0, 535.0, 1.0, 1.0]  episode_count: 3463 q_vals: [-6.914, -inf, -8.182, -5.512, -4.088, -9.303, -7.919]
Step 2029 4 visits [1.0, 1000.0, 1.0, 13.0, 536.0, 1.0, 1.0]  episode_count: 3463 q_vals: [-6.914, -inf, -8.182, -5.512, -4.088, -9.303, -7.919]
Step 2030 4 visits [1.0, 1000.0, 1.0, 13.0, 537.0, 1.0, 1.0]  episode_count: 3464 q_vals: [-6.914, -inf, -8.182, -5.512, -4.087, -9.303, -7.919]
Step 2031 4 visits [1.0, 1000.0, 1.0, 13.0, 538.0, 1.0, 1.0]  episode_count: 3466 q_vals: [-6.914, -inf, -8.182, -5.512, -4.089, -9.303, -7.919]
Step 2032 4 visits [1.0, 1000.0, 1.0, 13.0, 539.0, 1.0, 1.0]  episode_count: 3469 q_vals: [-6.914, -inf, -8.182, -5.512, -4.082, -9.303, -7.919]
Step 2033 4 visits [1.0, 1000.0, 1.0, 13.0, 540.0, 1.0, 1.0]  episode_count: 3471 q_vals: [-6.914, -inf, -8.182, -5.512, -4.074, -9.303, -7.919]
Step 2034 4 visits [1.0, 1000.0, 1.0, 13.0, 541.0, 1.0, 1.0]  episode_count: 3472 q_vals: [-6.914, -inf, -8.182, -5.512, -4.074, -9.303, -7.919]
{"total_number_of_episodes": 3474, "number_of_timesteps": 64129, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.2142857142857153},
Step 2035 4 visits [1.0, 1000.0, 1.0, 13.0, 542.0, 1.0, 1.0]  episode_count: 3474 q_vals: [-6.914, -inf, -8.182, -5.512, -4.073, -9.303, -7.919]
Step 2036 4 visits [1.0, 1000.0, 1.0, 13.0, 543.0, 1.0, 1.0]  episode_count: 3474 q_vals: [-6.914, -inf, -8.182, -5.512, -4.074, -9.303, -7.919]
Step 2037 4 visits [1.0, 1000.0, 1.0, 13.0, 544.0, 1.0, 1.0]  episode_count: 3475 q_vals: [-6.914, -inf, -8.182, -5.512, -4.073, -9.303, -7.919]
Step 2038 4 visits [1.0, 1000.0, 1.0, 13.0, 545.0, 1.0, 1.0]  episode_count: 3478 q_vals: [-6.914, -inf, -8.182, -5.512, -4.076, -9.303, -7.919]
Step 2039 4 visits [1.0, 1000.0, 1.0, 13.0, 546.0, 1.0, 1.0]  episode_count: 3480 q_vals: [-6.914, -inf, -8.182, -5.512, -4.075, -9.303, -7.919]
Step 2040 4 visits [1.0, 1000.0, 1.0, 13.0, 547.0, 1.0, 1.0]  episode_count: 3482 q_vals: [-6.914, -inf, -8.182, -5.512, -4.075, -9.303, -7.919]
Step 2041 4 visits [1.0, 1000.0, 1.0, 13.0, 548.0, 1.0, 1.0]  episode_count: 3483 q_vals: [-6.914, -inf, -8.182, -5.512, -4.091, -9.303, -7.919]
{"total_number_of_episodes": 3485, "number_of_timesteps": 64347, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.2142857142857153},
Step 2042 4 visits [1.0, 1000.0, 1.0, 13.0, 549.0, 1.0, 1.0]  episode_count: 3485 q_vals: [-6.914, -inf, -8.182, -5.512, -4.09, -9.303, -7.919]
Step 2043 4 visits [1.0, 1000.0, 1.0, 13.0, 550.0, 1.0, 1.0]  episode_count: 3486 q_vals: [-6.914, -inf, -8.182, -5.512, -4.082, -9.303, -7.919]
Step 2044 4 visits [1.0, 1000.0, 1.0, 13.0, 551.0, 1.0, 1.0]  episode_count: 3486 q_vals: [-6.914, -inf, -8.182, -5.512, -4.075, -9.303, -7.919]
Step 2045 4 visits [1.0, 1000.0, 1.0, 13.0, 552.0, 1.0, 1.0]  episode_count: 3489 q_vals: [-6.914, -inf, -8.182, -5.512, -4.075, -9.303, -7.919]
Step 2046 4 visits [1.0, 1000.0, 1.0, 13.0, 553.0, 1.0, 1.0]  episode_count: 3490 q_vals: [-6.914, -inf, -8.182, -5.512, -4.075, -9.303, -7.919]
Step 2047 4 visits [1.0, 1000.0, 1.0, 13.0, 554.0, 1.0, 1.0]  episode_count: 3492 q_vals: [-6.914, -inf, -8.182, -5.512, -4.091, -9.303, -7.919]
{"total_number_of_episodes": 3495, "number_of_timesteps": 64549, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.2142857142857153},
Step 2048 4 visits [1.0, 1000.0, 1.0, 13.0, 555.0, 1.0, 1.0]  episode_count: 3495 q_vals: [-6.914, -inf, -8.182, -5.512, -4.083, -9.303, -7.919]
Step 2049 4 visits [1.0, 1000.0, 1.0, 13.0, 556.0, 1.0, 1.0]  episode_count: 3495 q_vals: [-6.914, -inf, -8.182, -5.512, -4.076, -9.303, -7.919]
Step 2050 4 visits [1.0, 1000.0, 1.0, 13.0, 557.0, 1.0, 1.0]  episode_count: 3497 q_vals: [-6.914, -inf, -8.182, -5.512, -4.076, -9.303, -7.919]
Step 2051 4 visits [1.0, 1000.0, 1.0, 13.0, 558.0, 1.0, 1.0]  episode_count: 3500 q_vals: [-6.914, -inf, -8.182, -5.512, -4.076, -9.303, -7.919]
Step 2052 4 visits [1.0, 1000.0, 1.0, 13.0, 559.0, 1.0, 1.0]  episode_count: 3501 q_vals: [-6.914, -inf, -8.182, -5.512, -4.091, -9.303, -7.919]
Step 2053 4 visits [1.0, 1000.0, 1.0, 13.0, 560.0, 1.0, 1.0]  episode_count: 3503 q_vals: [-6.914, -inf, -8.182, -5.512, -4.091, -9.303, -7.919]
Step 2054 4 visits [1.0, 1000.0, 1.0, 13.0, 561.0, 1.0, 1.0]  episode_count: 3504 q_vals: [-6.914, -inf, -8.182, -5.512, -4.093, -9.303, -7.919]
{"total_number_of_episodes": 3505, "number_of_timesteps": 64738, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857295},
Step 2055 4 visits [1.0, 1000.0, 1.0, 13.0, 562.0, 1.0, 1.0]  episode_count: 3505 q_vals: [-6.914, -inf, -8.182, -5.512, -4.093, -9.303, -7.919]
Step 2056 4 visits [1.0, 1000.0, 1.0, 13.0, 563.0, 1.0, 1.0]  episode_count: 3506 q_vals: [-6.914, -inf, -8.182, -5.512, -4.085, -9.303, -7.919]
Step 2057 4 visits [1.0, 1000.0, 1.0, 13.0, 564.0, 1.0, 1.0]  episode_count: 3507 q_vals: [-6.914, -inf, -8.182, -5.512, -4.085, -9.303, -7.919]
Step 2058 4 visits [1.0, 1000.0, 1.0, 13.0, 565.0, 1.0, 1.0]  episode_count: 3509 q_vals: [-6.914, -inf, -8.182, -5.512, -4.078, -9.303, -7.919]
Step 2059 4 visits [1.0, 1000.0, 1.0, 13.0, 566.0, 1.0, 1.0]  episode_count: 3509 q_vals: [-6.914, -inf, -8.182, -5.512, -4.078, -9.303, -7.919]
Step 2060 4 visits [1.0, 1000.0, 1.0, 13.0, 567.0, 1.0, 1.0]  episode_count: 3510 q_vals: [-6.914, -inf, -8.182, -5.512, -4.081, -9.303, -7.919]
Step 2061 4 visits [1.0, 1000.0, 1.0, 13.0, 568.0, 1.0, 1.0]  episode_count: 3514 q_vals: [-6.914, -inf, -8.182, -5.512, -4.074, -9.303, -7.919]
{"total_number_of_episodes": 3515, "number_of_timesteps": 64999, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 2062 4 visits [1.0, 1000.0, 1.0, 13.0, 569.0, 1.0, 1.0]  episode_count: 3515 q_vals: [-6.914, -inf, -8.182, -5.512, -4.073, -9.303, -7.919]
Step 2063 4 visits [1.0, 1000.0, 1.0, 13.0, 570.0, 1.0, 1.0]  episode_count: 3516 q_vals: [-6.914, -inf, -8.182, -5.512, -4.071, -9.303, -7.919]
Step 2064 4 visits [1.0, 1000.0, 1.0, 13.0, 571.0, 1.0, 1.0]  episode_count: 3519 q_vals: [-6.914, -inf, -8.182, -5.512, -4.07, -9.303, -7.919]
Step 2065 4 visits [1.0, 1000.0, 1.0, 13.0, 572.0, 1.0, 1.0]  episode_count: 3521 q_vals: [-6.914, -inf, -8.182, -5.512, -4.07, -9.303, -7.919]
Step 2066 4 visits [1.0, 1000.0, 1.0, 13.0, 573.0, 1.0, 1.0]  episode_count: 3522 q_vals: [-6.914, -inf, -8.182, -5.512, -4.067, -9.303, -7.919]
Step 2067 4 visits [1.0, 1000.0, 1.0, 13.0, 574.0, 1.0, 1.0]  episode_count: 3522 q_vals: [-6.914, -inf, -8.182, -5.512, -4.07, -9.303, -7.919]
Step 2068 4 visits [1.0, 1000.0, 1.0, 13.0, 575.0, 1.0, 1.0]  episode_count: 3524 q_vals: [-6.914, -inf, -8.182, -5.512, -4.071, -9.303, -7.919]
{"total_number_of_episodes": 3525, "number_of_timesteps": 65164, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2069 4 visits [1.0, 1000.0, 1.0, 13.0, 576.0, 1.0, 1.0]  episode_count: 3525 q_vals: [-6.914, -inf, -8.182, -5.512, -4.072, -9.303, -7.919]
Step 2070 4 visits [1.0, 1000.0, 1.0, 13.0, 577.0, 1.0, 1.0]  episode_count: 3527 q_vals: [-6.914, -inf, -8.182, -5.512, -4.065, -9.303, -7.919]
Step 2071 4 visits [1.0, 1000.0, 1.0, 13.0, 578.0, 1.0, 1.0]  episode_count: 3528 q_vals: [-6.914, -inf, -8.182, -5.512, -4.065, -9.303, -7.919]
Step 2072 4 visits [1.0, 1000.0, 1.0, 13.0, 579.0, 1.0, 1.0]  episode_count: 3530 q_vals: [-6.914, -inf, -8.182, -5.512, -4.064, -9.303, -7.919]
Step 2073 4 visits [1.0, 1000.0, 1.0, 13.0, 580.0, 1.0, 1.0]  episode_count: 3533 q_vals: [-6.914, -inf, -8.182, -5.512, -4.064, -9.303, -7.919]
Step 2074 4 visits [1.0, 1000.0, 1.0, 13.0, 581.0, 1.0, 1.0]  episode_count: 3534 q_vals: [-6.914, -inf, -8.182, -5.512, -4.063, -9.303, -7.919]
{"total_number_of_episodes": 3536, "number_of_timesteps": 65401, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2075 4 visits [1.0, 1000.0, 1.0, 13.0, 582.0, 1.0, 1.0]  episode_count: 3536 q_vals: [-6.914, -inf, -8.182, -5.512, -4.062, -9.303, -7.919]
Step 2076 4 visits [1.0, 1000.0, 1.0, 13.0, 583.0, 1.0, 1.0]  episode_count: 3539 q_vals: [-6.914, -inf, -8.182, -5.512, -4.062, -9.303, -7.919]
Step 2077 4 visits [1.0, 1000.0, 1.0, 13.0, 584.0, 1.0, 1.0]  episode_count: 3540 q_vals: [-6.914, -inf, -8.182, -5.512, -4.055, -9.303, -7.919]
Step 2078 4 visits [1.0, 1000.0, 1.0, 13.0, 585.0, 1.0, 1.0]  episode_count: 3543 q_vals: [-6.914, -inf, -8.182, -5.512, -4.055, -9.303, -7.919]
Step 2079 4 visits [1.0, 1000.0, 1.0, 13.0, 586.0, 1.0, 1.0]  episode_count: 3544 q_vals: [-6.914, -inf, -8.182, -5.512, -4.069, -9.303, -7.919]
{"total_number_of_episodes": 3548, "number_of_timesteps": 65581, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2080 4 visits [1.0, 1000.0, 1.0, 13.0, 587.0, 1.0, 1.0]  episode_count: 3548 q_vals: [-6.914, -inf, -8.182, -5.512, -4.07, -9.303, -7.919]
Step 2081 4 visits [1.0, 1000.0, 1.0, 13.0, 588.0, 1.0, 1.0]  episode_count: 3550 q_vals: [-6.914, -inf, -8.182, -5.512, -4.064, -9.303, -7.919]
Step 2082 4 visits [1.0, 1000.0, 1.0, 13.0, 589.0, 1.0, 1.0]  episode_count: 3552 q_vals: [-6.914, -inf, -8.182, -5.512, -4.063, -9.303, -7.919]
Step 2083 4 visits [1.0, 1000.0, 1.0, 13.0, 590.0, 1.0, 1.0]  episode_count: 3556 q_vals: [-6.914, -inf, -8.182, -5.512, -4.064, -9.303, -7.919]
Step 2084 4 visits [1.0, 1000.0, 1.0, 13.0, 591.0, 1.0, 1.0]  episode_count: 3557 q_vals: [-6.914, -inf, -8.182, -5.512, -4.063, -9.303, -7.919]
{"total_number_of_episodes": 3560, "number_of_timesteps": 65735, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2085 4 visits [1.0, 1000.0, 1.0, 13.0, 592.0, 1.0, 1.0]  episode_count: 3560 q_vals: [-6.914, -inf, -8.182, -5.512, -4.064, -9.303, -7.919]
Step 2086 4 visits [1.0, 1000.0, 1.0, 13.0, 593.0, 1.0, 1.0]  episode_count: 3560 q_vals: [-6.914, -inf, -8.182, -5.512, -4.065, -9.303, -7.919]
Step 2087 4 visits [1.0, 1000.0, 1.0, 13.0, 594.0, 1.0, 1.0]  episode_count: 3562 q_vals: [-6.914, -inf, -8.182, -5.512, -4.064, -9.303, -7.919]
Step 2088 4 visits [1.0, 1000.0, 1.0, 13.0, 595.0, 1.0, 1.0]  episode_count: 3567 q_vals: [-6.914, -inf, -8.182, -5.512, -4.065, -9.303, -7.919]
Step 2089 4 visits [1.0, 1000.0, 1.0, 13.0, 596.0, 1.0, 1.0]  episode_count: 3567 q_vals: [-6.914, -inf, -8.182, -5.512, -4.065, -9.303, -7.919]
{"total_number_of_episodes": 3571, "number_of_timesteps": 65891, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2090 4 visits [1.0, 1000.0, 1.0, 13.0, 597.0, 1.0, 1.0]  episode_count: 3571 q_vals: [-6.914, -inf, -8.182, -5.512, -4.059, -9.303, -7.919]
Step 2091 4 visits [1.0, 1000.0, 1.0, 13.0, 598.0, 1.0, 1.0]  episode_count: 3572 q_vals: [-6.914, -inf, -8.182, -5.512, -4.073, -9.303, -7.919]
Step 2092 4 visits [1.0, 1000.0, 1.0, 13.0, 599.0, 1.0, 1.0]  episode_count: 3574 q_vals: [-6.914, -inf, -8.182, -5.512, -4.073, -9.303, -7.919]
Step 2093 4 visits [1.0, 1000.0, 1.0, 13.0, 600.0, 1.0, 1.0]  episode_count: 3576 q_vals: [-6.914, -inf, -8.182, -5.512, -4.087, -9.303, -7.919]
Step 2094 4 visits [1.0, 1000.0, 1.0, 13.0, 601.0, 1.0, 1.0]  episode_count: 3579 q_vals: [-6.914, -inf, -8.182, -5.512, -4.081, -9.303, -7.919]
Step 2095 4 visits [1.0, 1000.0, 1.0, 13.0, 602.0, 1.0, 1.0]  episode_count: 3580 q_vals: [-6.914, -inf, -8.182, -5.512, -4.08, -9.303, -7.919]
{"total_number_of_episodes": 3581, "number_of_timesteps": 66034, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2096 4 visits [1.0, 1000.0, 1.0, 13.0, 603.0, 1.0, 1.0]  episode_count: 3581 q_vals: [-6.914, -inf, -8.182, -5.512, -4.073, -9.303, -7.919]
Step 2097 4 visits [1.0, 1000.0, 1.0, 13.0, 604.0, 1.0, 1.0]  episode_count: 3585 q_vals: [-6.914, -inf, -8.182, -5.512, -4.073, -9.303, -7.919]
Step 2098 4 visits [1.0, 1000.0, 1.0, 13.0, 605.0, 1.0, 1.0]  episode_count: 3586 q_vals: [-6.914, -inf, -8.182, -5.512, -4.074, -9.303, -7.919]
Step 2099 4 visits [1.0, 1000.0, 1.0, 13.0, 606.0, 1.0, 1.0]  episode_count: 3587 q_vals: [-6.914, -inf, -8.182, -5.512, -4.073, -9.303, -7.919]
Step 2100 4 visits [1.0, 1000.0, 1.0, 13.0, 607.0, 1.0, 1.0]  episode_count: 3588 q_vals: [-6.914, -inf, -8.182, -5.512, -4.073, -9.303, -7.919]
{"total_number_of_episodes": 3591, "number_of_timesteps": 66216, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2101 4 visits [1.0, 1000.0, 1.0, 13.0, 608.0, 1.0, 1.0]  episode_count: 3591 q_vals: [-6.914, -inf, -8.182, -5.512, -4.073, -9.303, -7.919]
Step 2102 4 visits [1.0, 1000.0, 1.0, 13.0, 609.0, 1.0, 1.0]  episode_count: 3594 q_vals: [-6.914, -inf, -8.182, -5.512, -4.072, -9.303, -7.919]
Step 2103 4 visits [1.0, 1000.0, 1.0, 13.0, 610.0, 1.0, 1.0]  episode_count: 3596 q_vals: [-6.914, -inf, -8.182, -5.512, -4.072, -9.303, -7.919]
Step 2104 4 visits [1.0, 1000.0, 1.0, 13.0, 611.0, 1.0, 1.0]  episode_count: 3598 q_vals: [-6.914, -inf, -8.182, -5.512, -4.065, -9.303, -7.919]
Step 2105 4 visits [1.0, 1000.0, 1.0, 13.0, 612.0, 1.0, 1.0]  episode_count: 3598 q_vals: [-6.914, -inf, -8.182, -5.512, -4.065, -9.303, -7.919]
Step 2106 4 visits [1.0, 1000.0, 1.0, 13.0, 613.0, 1.0, 1.0]  episode_count: 3599 q_vals: [-6.914, -inf, -8.182, -5.512, -4.065, -9.303, -7.919]
{"total_number_of_episodes": 3601, "number_of_timesteps": 66365, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2107 4 visits [1.0, 1000.0, 1.0, 13.0, 614.0, 1.0, 1.0]  episode_count: 3601 q_vals: [-6.914, -inf, -8.182, -5.512, -4.064, -9.303, -7.919]
Step 2108 4 visits [1.0, 1000.0, 1.0, 13.0, 615.0, 1.0, 1.0]  episode_count: 3602 q_vals: [-6.914, -inf, -8.182, -5.512, -4.064, -9.303, -7.919]
Step 2109 4 visits [1.0, 1000.0, 1.0, 13.0, 616.0, 1.0, 1.0]  episode_count: 3602 q_vals: [-6.914, -inf, -8.182, -5.512, -4.065, -9.303, -7.919]
Step 2110 4 visits [1.0, 1000.0, 1.0, 13.0, 617.0, 1.0, 1.0]  episode_count: 3602 q_vals: [-6.914, -inf, -8.182, -5.512, -4.059, -9.303, -7.919]
Step 2111 4 visits [1.0, 1000.0, 1.0, 13.0, 618.0, 1.0, 1.0]  episode_count: 3602 q_vals: [-6.914, -inf, -8.182, -5.512, -4.059, -9.303, -7.919]
Step 2112 4 visits [1.0, 1000.0, 1.0, 13.0, 619.0, 1.0, 1.0]  episode_count: 3604 q_vals: [-6.914, -inf, -8.182, -5.512, -4.056, -9.303, -7.919]
Step 2113 4 visits [1.0, 1000.0, 1.0, 13.0, 620.0, 1.0, 1.0]  episode_count: 3605 q_vals: [-6.914, -inf, -8.182, -5.512, -4.059, -9.303, -7.919]
Step 2114 4 visits [1.0, 1000.0, 1.0, 13.0, 621.0, 1.0, 1.0]  episode_count: 3607 q_vals: [-6.914, -inf, -8.182, -5.512, -4.059, -9.303, -7.919]
Step 2115 4 visits [1.0, 1000.0, 1.0, 13.0, 622.0, 1.0, 1.0]  episode_count: 3607 q_vals: [-6.914, -inf, -8.182, -5.512, -4.058, -9.303, -7.919]
Step 2116 4 visits [1.0, 1000.0, 1.0, 13.0, 623.0, 1.0, 1.0]  episode_count: 3609 q_vals: [-6.914, -inf, -8.182, -5.512, -4.052, -9.303, -7.919]
Step 2117 4 visits [1.0, 1000.0, 1.0, 13.0, 624.0, 1.0, 1.0]  episode_count: 3609 q_vals: [-6.914, -inf, -8.182, -5.512, -4.052, -9.303, -7.919]
{"total_number_of_episodes": 3611, "number_of_timesteps": 66730, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2118 4 visits [1.0, 1000.0, 1.0, 13.0, 625.0, 1.0, 1.0]  episode_count: 3611 q_vals: [-6.914, -inf, -8.182, -5.512, -4.051, -9.303, -7.919]
Step 2119 4 visits [1.0, 1000.0, 1.0, 13.0, 626.0, 1.0, 1.0]  episode_count: 3612 q_vals: [-6.914, -inf, -8.182, -5.512, -4.05, -9.303, -7.919]
Step 2120 4 visits [1.0, 1000.0, 1.0, 13.0, 627.0, 1.0, 1.0]  episode_count: 3613 q_vals: [-6.914, -inf, -8.182, -5.512, -4.05, -9.303, -7.919]
Step 2121 4 visits [1.0, 1000.0, 1.0, 13.0, 628.0, 1.0, 1.0]  episode_count: 3615 q_vals: [-6.914, -inf, -8.182, -5.512, -4.044, -9.303, -7.919]
Step 2122 4 visits [1.0, 1000.0, 1.0, 13.0, 629.0, 1.0, 1.0]  episode_count: 3615 q_vals: [-6.914, -inf, -8.182, -5.512, -4.057, -9.303, -7.919]
Step 2123 4 visits [1.0, 1000.0, 1.0, 13.0, 630.0, 1.0, 1.0]  episode_count: 3616 q_vals: [-6.914, -inf, -8.182, -5.512, -4.057, -9.303, -7.919]
Step 2124 4 visits [1.0, 1000.0, 1.0, 13.0, 631.0, 1.0, 1.0]  episode_count: 3619 q_vals: [-6.914, -inf, -8.182, -5.512, -4.051, -9.303, -7.919]
{"total_number_of_episodes": 3621, "number_of_timesteps": 66993, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2125 4 visits [1.0, 1000.0, 1.0, 13.0, 632.0, 1.0, 1.0]  episode_count: 3621 q_vals: [-6.914, -inf, -8.182, -5.512, -4.051, -9.303, -7.919]
Step 2126 4 visits [1.0, 1000.0, 1.0, 13.0, 633.0, 1.0, 1.0]  episode_count: 3622 q_vals: [-6.914, -inf, -8.182, -5.512, -4.045, -9.303, -7.919]
Step 2127 4 visits [1.0, 1000.0, 1.0, 13.0, 634.0, 1.0, 1.0]  episode_count: 3624 q_vals: [-6.914, -inf, -8.182, -5.512, -4.044, -9.303, -7.919]
Step 2128 4 visits [1.0, 1000.0, 1.0, 13.0, 635.0, 1.0, 1.0]  episode_count: 3626 q_vals: [-6.914, -inf, -8.182, -5.512, -4.058, -9.303, -7.919]
Step 2129 4 visits [1.0, 1000.0, 1.0, 13.0, 636.0, 1.0, 1.0]  episode_count: 3627 q_vals: [-6.914, -inf, -8.182, -5.512, -4.057, -9.303, -7.919]
Step 2130 4 visits [1.0, 1000.0, 1.0, 13.0, 637.0, 1.0, 1.0]  episode_count: 3629 q_vals: [-6.914, -inf, -8.182, -5.512, -4.056, -9.303, -7.919]
Step 2131 4 visits [1.0, 1000.0, 1.0, 13.0, 638.0, 1.0, 1.0]  episode_count: 3630 q_vals: [-6.914, -inf, -8.182, -5.512, -4.05, -9.303, -7.919]
Step 2132 4 visits [1.0, 1000.0, 1.0, 13.0, 639.0, 1.0, 1.0]  episode_count: 3630 q_vals: [-6.914, -inf, -8.182, -5.512, -4.043, -9.303, -7.919]
{"total_number_of_episodes": 3634, "number_of_timesteps": 67234, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2133 4 visits [1.0, 1000.0, 1.0, 13.0, 640.0, 1.0, 1.0]  episode_count: 3634 q_vals: [-6.914, -inf, -8.182, -5.512, -4.045, -9.303, -7.919]
Step 2134 4 visits [1.0, 1000.0, 1.0, 13.0, 641.0, 1.0, 1.0]  episode_count: 3635 q_vals: [-6.914, -inf, -8.182, -5.512, -4.045, -9.303, -7.919]
Step 2135 4 visits [1.0, 1000.0, 1.0, 13.0, 642.0, 1.0, 1.0]  episode_count: 3636 q_vals: [-6.914, -inf, -8.182, -5.512, -4.045, -9.303, -7.919]
Step 2136 4 visits [1.0, 1000.0, 1.0, 13.0, 643.0, 1.0, 1.0]  episode_count: 3639 q_vals: [-6.914, -inf, -8.182, -5.512, -4.039, -9.303, -7.919]
Step 2137 4 visits [1.0, 1000.0, 1.0, 13.0, 644.0, 1.0, 1.0]  episode_count: 3640 q_vals: [-6.914, -inf, -8.182, -5.512, -4.041, -9.303, -7.919]
Step 2138 4 visits [1.0, 1000.0, 1.0, 13.0, 645.0, 1.0, 1.0]  episode_count: 3641 q_vals: [-6.914, -inf, -8.182, -5.512, -4.04, -9.303, -7.919]
Step 2139 4 visits [1.0, 1000.0, 1.0, 13.0, 646.0, 1.0, 1.0]  episode_count: 3643 q_vals: [-6.914, -inf, -8.182, -5.512, -4.033, -9.303, -7.919]
{"total_number_of_episodes": 3645, "number_of_timesteps": 67454, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2140 4 visits [1.0, 1000.0, 1.0, 13.0, 647.0, 1.0, 1.0]  episode_count: 3645 q_vals: [-6.914, -inf, -8.182, -5.512, -4.033, -9.303, -7.919]
Step 2141 4 visits [1.0, 1000.0, 1.0, 13.0, 648.0, 1.0, 1.0]  episode_count: 3646 q_vals: [-6.914, -inf, -8.182, -5.512, -4.034, -9.303, -7.919]
Step 2142 4 visits [1.0, 1000.0, 1.0, 13.0, 649.0, 1.0, 1.0]  episode_count: 3648 q_vals: [-6.914, -inf, -8.182, -5.512, -4.027, -9.303, -7.919]
Step 2143 4 visits [1.0, 1000.0, 1.0, 13.0, 650.0, 1.0, 1.0]  episode_count: 3650 q_vals: [-6.914, -inf, -8.182, -5.512, -4.026, -9.303, -7.919]
Step 2144 4 visits [1.0, 1000.0, 1.0, 13.0, 651.0, 1.0, 1.0]  episode_count: 3650 q_vals: [-6.914, -inf, -8.182, -5.512, -4.02, -9.303, -7.919]
Step 2145 4 visits [1.0, 1000.0, 1.0, 13.0, 652.0, 1.0, 1.0]  episode_count: 3654 q_vals: [-6.914, -inf, -8.182, -5.512, -4.014, -9.303, -7.919]
{"total_number_of_episodes": 3655, "number_of_timesteps": 67642, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2146 4 visits [1.0, 1000.0, 1.0, 13.0, 653.0, 1.0, 1.0]  episode_count: 3655 q_vals: [-6.914, -inf, -8.182, -5.512, -4.013, -9.303, -7.919]
Step 2147 4 visits [1.0, 1000.0, 1.0, 13.0, 654.0, 1.0, 1.0]  episode_count: 3657 q_vals: [-6.914, -inf, -8.182, -5.512, -4.013, -9.303, -7.919]
Step 2148 4 visits [1.0, 1000.0, 1.0, 13.0, 655.0, 1.0, 1.0]  episode_count: 3660 q_vals: [-6.914, -inf, -8.182, -5.512, -4.014, -9.303, -7.919]
Step 2149 4 visits [1.0, 1000.0, 1.0, 13.0, 656.0, 1.0, 1.0]  episode_count: 3661 q_vals: [-6.914, -inf, -8.182, -5.512, -4.008, -9.303, -7.919]
Step 2150 4 visits [1.0, 1000.0, 1.0, 13.0, 657.0, 1.0, 1.0]  episode_count: 3663 q_vals: [-6.914, -inf, -8.182, -5.512, -4.008, -9.303, -7.919]
{"total_number_of_episodes": 3666, "number_of_timesteps": 67806, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2151 4 visits [1.0, 1000.0, 1.0, 13.0, 658.0, 1.0, 1.0]  episode_count: 3666 q_vals: [-6.914, -inf, -8.182, -5.512, -4.002, -9.303, -7.919]
Step 2152 4 visits [1.0, 1000.0, 1.0, 13.0, 659.0, 1.0, 1.0]  episode_count: 3668 q_vals: [-6.914, -inf, -8.182, -5.512, -4.002, -9.303, -7.919]
Step 2153 4 visits [1.0, 1000.0, 1.0, 13.0, 660.0, 1.0, 1.0]  episode_count: 3670 q_vals: [-6.914, -inf, -8.182, -5.512, -4.002, -9.303, -7.919]
Step 2154 4 visits [1.0, 1000.0, 1.0, 13.0, 661.0, 1.0, 1.0]  episode_count: 3673 q_vals: [-6.914, -inf, -8.182, -5.512, -4.001, -9.303, -7.919]
Step 2155 4 visits [1.0, 1000.0, 1.0, 13.0, 662.0, 1.0, 1.0]  episode_count: 3674 q_vals: [-6.914, -inf, -8.182, -5.512, -4.014, -9.303, -7.919]
{"total_number_of_episodes": 3677, "number_of_timesteps": 67982, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2156 4 visits [1.0, 1000.0, 1.0, 13.0, 663.0, 1.0, 1.0]  episode_count: 3677 q_vals: [-6.914, -inf, -8.182, -5.512, -4.015, -9.303, -7.919]
Step 2157 4 visits [1.0, 1000.0, 1.0, 13.0, 664.0, 1.0, 1.0]  episode_count: 3677 q_vals: [-6.914, -inf, -8.182, -5.512, -4.009, -9.303, -7.919]
Step 2158 4 visits [1.0, 1000.0, 1.0, 13.0, 665.0, 1.0, 1.0]  episode_count: 3679 q_vals: [-6.914, -inf, -8.182, -5.512, -4.008, -9.303, -7.919]
Step 2159 4 visits [1.0, 1000.0, 1.0, 13.0, 666.0, 1.0, 1.0]  episode_count: 3682 q_vals: [-6.914, -inf, -8.182, -5.512, -4.008, -9.303, -7.919]
Step 2160 4 visits [1.0, 1000.0, 1.0, 13.0, 667.0, 1.0, 1.0]  episode_count: 3685 q_vals: [-6.914, -inf, -8.182, -5.512, -4.007, -9.303, -7.919]
Step 2161 4 visits [1.0, 1000.0, 1.0, 13.0, 668.0, 1.0, 1.0]  episode_count: 3686 q_vals: [-6.914, -inf, -8.182, -5.512, -4.02, -9.303, -7.919]
{"total_number_of_episodes": 3688, "number_of_timesteps": 68157, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2162 4 visits [1.0, 1000.0, 1.0, 13.0, 669.0, 1.0, 1.0]  episode_count: 3688 q_vals: [-6.914, -inf, -8.182, -5.512, -4.02, -9.303, -7.919]
Step 2163 4 visits [1.0, 1000.0, 1.0, 13.0, 670.0, 1.0, 1.0]  episode_count: 3689 q_vals: [-6.914, -inf, -8.182, -5.512, -4.019, -9.303, -7.919]
Step 2164 4 visits [1.0, 1000.0, 1.0, 13.0, 671.0, 1.0, 1.0]  episode_count: 3692 q_vals: [-6.914, -inf, -8.182, -5.512, -4.022, -9.303, -7.919]
Step 2165 4 visits [1.0, 1000.0, 1.0, 13.0, 672.0, 1.0, 1.0]  episode_count: 3694 q_vals: [-6.914, -inf, -8.182, -5.512, -4.022, -9.303, -7.919]
Step 2166 4 visits [1.0, 1000.0, 1.0, 13.0, 673.0, 1.0, 1.0]  episode_count: 3696 q_vals: [-6.914, -inf, -8.182, -5.512, -4.016, -9.303, -7.919]
{"total_number_of_episodes": 3698, "number_of_timesteps": 68320, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2167 4 visits [1.0, 1000.0, 1.0, 13.0, 674.0, 1.0, 1.0]  episode_count: 3698 q_vals: [-6.914, -inf, -8.182, -5.512, -4.017, -9.303, -7.919]
Step 2168 4 visits [1.0, 1000.0, 1.0, 13.0, 675.0, 1.0, 1.0]  episode_count: 3700 q_vals: [-6.914, -inf, -8.182, -5.512, -4.015, -9.303, -7.919]
Step 2169 4 visits [1.0, 1000.0, 1.0, 13.0, 676.0, 1.0, 1.0]  episode_count: 3701 q_vals: [-6.914, -inf, -8.182, -5.512, -4.009, -9.303, -7.919]
Step 2170 4 visits [1.0, 1000.0, 1.0, 13.0, 677.0, 1.0, 1.0]  episode_count: 3702 q_vals: [-6.914, -inf, -8.182, -5.512, -4.009, -9.303, -7.919]
Step 2171 4 visits [1.0, 1000.0, 1.0, 13.0, 678.0, 1.0, 1.0]  episode_count: 3704 q_vals: [-6.914, -inf, -8.182, -5.512, -4.009, -9.303, -7.919]
Step 2172 4 visits [1.0, 1000.0, 1.0, 13.0, 679.0, 1.0, 1.0]  episode_count: 3705 q_vals: [-6.914, -inf, -8.182, -5.512, -4.003, -9.303, -7.919]
Step 2173 4 visits [1.0, 1000.0, 1.0, 13.0, 680.0, 1.0, 1.0]  episode_count: 3706 q_vals: [-6.914, -inf, -8.182, -5.512, -3.997, -9.303, -7.919]
{"total_number_of_episodes": 3709, "number_of_timesteps": 68505, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2174 4 visits [1.0, 1000.0, 1.0, 13.0, 681.0, 1.0, 1.0]  episode_count: 3709 q_vals: [-6.914, -inf, -8.182, -5.512, -3.998, -9.303, -7.919]
Step 2175 4 visits [1.0, 1000.0, 1.0, 13.0, 682.0, 1.0, 1.0]  episode_count: 3711 q_vals: [-6.914, -inf, -8.182, -5.512, -3.992, -9.303, -7.919]
Step 2176 4 visits [1.0, 1000.0, 1.0, 13.0, 683.0, 1.0, 1.0]  episode_count: 3713 q_vals: [-6.914, -inf, -8.182, -5.512, -3.988, -9.303, -7.919]
Step 2177 4 visits [1.0, 1000.0, 1.0, 13.0, 684.0, 1.0, 1.0]  episode_count: 3714 q_vals: [-6.914, -inf, -8.182, -5.512, -3.982, -9.303, -7.919]
Step 2178 4 visits [1.0, 1000.0, 1.0, 13.0, 685.0, 1.0, 1.0]  episode_count: 3715 q_vals: [-6.914, -inf, -8.182, -5.512, -3.995, -9.303, -7.919]
Step 2179 4 visits [1.0, 1000.0, 1.0, 13.0, 686.0, 1.0, 1.0]  episode_count: 3718 q_vals: [-6.914, -inf, -8.182, -5.512, -3.995, -9.303, -7.919]
{"total_number_of_episodes": 3720, "number_of_timesteps": 68739, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 2180 4 visits [1.0, 1000.0, 1.0, 13.0, 687.0, 1.0, 1.0]  episode_count: 3720 q_vals: [-6.914, -inf, -8.182, -5.512, -3.989, -9.303, -7.919]
Step 2181 4 visits [1.0, 1000.0, 1.0, 13.0, 688.0, 1.0, 1.0]  episode_count: 3722 q_vals: [-6.914, -inf, -8.182, -5.512, -3.988, -9.303, -7.919]
Step 2182 4 visits [1.0, 1000.0, 1.0, 13.0, 689.0, 1.0, 1.0]  episode_count: 3722 q_vals: [-6.914, -inf, -8.182, -5.512, -3.989, -9.303, -7.919]
Step 2183 4 visits [1.0, 1000.0, 1.0, 13.0, 690.0, 1.0, 1.0]  episode_count: 3726 q_vals: [-6.914, -inf, -8.182, -5.512, -3.983, -9.303, -7.919]
Step 2184 4 visits [1.0, 1000.0, 1.0, 13.0, 691.0, 1.0, 1.0]  episode_count: 3728 q_vals: [-6.914, -inf, -8.182, -5.512, -3.982, -9.303, -7.919]
Step 2185 4 visits [1.0, 1000.0, 1.0, 13.0, 692.0, 1.0, 1.0]  episode_count: 3729 q_vals: [-6.914, -inf, -8.182, -5.512, -3.982, -9.303, -7.919]
{"total_number_of_episodes": 3732, "number_of_timesteps": 68932, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2186 4 visits [1.0, 1000.0, 1.0, 13.0, 693.0, 1.0, 1.0]  episode_count: 3732 q_vals: [-6.914, -inf, -8.182, -5.512, -3.976, -9.303, -7.919]
Step 2187 4 visits [1.0, 1000.0, 1.0, 13.0, 694.0, 1.0, 1.0]  episode_count: 3735 q_vals: [-6.914, -inf, -8.182, -5.512, -3.976, -9.303, -7.919]
Step 2188 4 visits [1.0, 1000.0, 1.0, 13.0, 695.0, 1.0, 1.0]  episode_count: 3735 q_vals: [-6.914, -inf, -8.182, -5.512, -3.979, -9.303, -7.919]
Step 2189 4 visits [1.0, 1000.0, 1.0, 13.0, 696.0, 1.0, 1.0]  episode_count: 3737 q_vals: [-6.914, -inf, -8.182, -5.512, -3.98, -9.303, -7.919]
Step 2190 4 visits [1.0, 1000.0, 1.0, 13.0, 697.0, 1.0, 1.0]  episode_count: 3737 q_vals: [-6.914, -inf, -8.182, -5.512, -3.98, -9.303, -7.919]
Step 2191 4 visits [1.0, 1000.0, 1.0, 13.0, 698.0, 1.0, 1.0]  episode_count: 3739 q_vals: [-6.914, -inf, -8.182, -5.512, -3.992, -9.303, -7.919]
Step 2192 4 visits [1.0, 1000.0, 1.0, 13.0, 699.0, 1.0, 1.0]  episode_count: 3741 q_vals: [-6.914, -inf, -8.182, -5.512, -3.987, -9.303, -7.919]
{"total_number_of_episodes": 3742, "number_of_timesteps": 69116, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2193 4 visits [1.0, 1000.0, 1.0, 13.0, 700.0, 1.0, 1.0]  episode_count: 3742 q_vals: [-6.914, -inf, -8.182, -5.512, -3.987, -9.303, -7.919]
Step 2194 4 visits [1.0, 1000.0, 1.0, 13.0, 701.0, 1.0, 1.0]  episode_count: 3743 q_vals: [-6.914, -inf, -8.182, -5.512, -3.989, -9.303, -7.919]
Step 2195 4 visits [1.0, 1000.0, 1.0, 13.0, 702.0, 1.0, 1.0]  episode_count: 3747 q_vals: [-6.914, -inf, -8.182, -5.512, -3.989, -9.303, -7.919]
Step 2196 4 visits [1.0, 1000.0, 1.0, 13.0, 703.0, 1.0, 1.0]  episode_count: 3749 q_vals: [-6.914, -inf, -8.182, -5.512, -3.989, -9.303, -7.919]
Step 2197 4 visits [1.0, 1000.0, 1.0, 13.0, 704.0, 1.0, 1.0]  episode_count: 3749 q_vals: [-6.914, -inf, -8.182, -5.512, -3.988, -9.303, -7.919]
Step 2198 4 visits [1.0, 1000.0, 1.0, 13.0, 705.0, 1.0, 1.0]  episode_count: 3751 q_vals: [-6.914, -inf, -8.182, -5.512, -3.983, -9.303, -7.919]
{"total_number_of_episodes": 3752, "number_of_timesteps": 69311, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2199 4 visits [1.0, 1000.0, 1.0, 13.0, 706.0, 1.0, 1.0]  episode_count: 3752 q_vals: [-6.914, -inf, -8.182, -5.512, -3.982, -9.303, -7.919]
Step 2200 4 visits [1.0, 1000.0, 1.0, 13.0, 707.0, 1.0, 1.0]  episode_count: 3754 q_vals: [-6.914, -inf, -8.182, -5.512, -3.977, -9.303, -7.919]
Step 2201 4 visits [1.0, 1000.0, 1.0, 13.0, 708.0, 1.0, 1.0]  episode_count: 3755 q_vals: [-6.914, -inf, -8.182, -5.512, -3.976, -9.303, -7.919]
Step 2202 4 visits [1.0, 1000.0, 1.0, 13.0, 709.0, 1.0, 1.0]  episode_count: 3757 q_vals: [-6.914, -inf, -8.182, -5.512, -3.971, -9.303, -7.919]
Step 2203 4 visits [1.0, 1000.0, 1.0, 13.0, 710.0, 1.0, 1.0]  episode_count: 3759 q_vals: [-6.914, -inf, -8.182, -5.512, -3.971, -9.303, -7.919]
Step 2204 4 visits [1.0, 1000.0, 1.0, 13.0, 711.0, 1.0, 1.0]  episode_count: 3760 q_vals: [-6.914, -inf, -8.182, -5.512, -3.971, -9.303, -7.919]
{"total_number_of_episodes": 3762, "number_of_timesteps": 69530, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 2205 4 visits [1.0, 1000.0, 1.0, 13.0, 712.0, 1.0, 1.0]  episode_count: 3762 q_vals: [-6.914, -inf, -8.182, -5.512, -3.971, -9.303, -7.919]
Step 2206 4 visits [1.0, 1000.0, 1.0, 13.0, 713.0, 1.0, 1.0]  episode_count: 3763 q_vals: [-6.914, -inf, -8.182, -5.512, -3.965, -9.303, -7.919]
Step 2207 4 visits [1.0, 1000.0, 1.0, 13.0, 714.0, 1.0, 1.0]  episode_count: 3764 q_vals: [-6.914, -inf, -8.182, -5.512, -3.959, -9.303, -7.919]
Step 2208 4 visits [1.0, 1000.0, 1.0, 13.0, 715.0, 1.0, 1.0]  episode_count: 3766 q_vals: [-6.914, -inf, -8.182, -5.512, -3.958, -9.303, -7.919]
Step 2209 4 visits [1.0, 1000.0, 1.0, 13.0, 716.0, 1.0, 1.0]  episode_count: 3769 q_vals: [-6.914, -inf, -8.182, -5.512, -3.957, -9.303, -7.919]
Step 2210 4 visits [1.0, 1000.0, 1.0, 13.0, 717.0, 1.0, 1.0]  episode_count: 3771 q_vals: [-6.914, -inf, -8.182, -5.512, -3.951, -9.303, -7.919]
{"total_number_of_episodes": 3773, "number_of_timesteps": 69730, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 2211 4 visits [1.0, 1000.0, 1.0, 13.0, 718.0, 1.0, 1.0]  episode_count: 3773 q_vals: [-6.914, -inf, -8.182, -5.512, -3.952, -9.303, -7.919]
Step 2212 4 visits [1.0, 1000.0, 1.0, 13.0, 719.0, 1.0, 1.0]  episode_count: 3774 q_vals: [-6.914, -inf, -8.182, -5.512, -3.954, -9.303, -7.919]
Step 2213 4 visits [1.0, 1000.0, 1.0, 13.0, 720.0, 1.0, 1.0]  episode_count: 3776 q_vals: [-6.914, -inf, -8.182, -5.512, -3.949, -9.303, -7.919]
Step 2214 4 visits [1.0, 1000.0, 1.0, 13.0, 721.0, 1.0, 1.0]  episode_count: 3777 q_vals: [-6.914, -inf, -8.182, -5.512, -3.949, -9.303, -7.919]
Step 2215 4 visits [1.0, 1000.0, 1.0, 13.0, 722.0, 1.0, 1.0]  episode_count: 3777 q_vals: [-6.914, -inf, -8.182, -5.512, -3.952, -9.303, -7.919]
Step 2216 4 visits [1.0, 1000.0, 1.0, 13.0, 723.0, 1.0, 1.0]  episode_count: 3781 q_vals: [-6.914, -inf, -8.182, -5.512, -3.964, -9.303, -7.919]
Step 2217 4 visits [1.0, 1000.0, 1.0, 13.0, 724.0, 1.0, 1.0]  episode_count: 3781 q_vals: [-6.914, -inf, -8.182, -5.512, -3.965, -9.303, -7.919]
Step 2218 4 visits [1.0, 1000.0, 1.0, 13.0, 725.0, 1.0, 1.0]  episode_count: 3782 q_vals: [-6.914, -inf, -8.182, -5.512, -3.965, -9.303, -7.919]
{"total_number_of_episodes": 3784, "number_of_timesteps": 69936, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2219 4 visits [1.0, 1000.0, 1.0, 13.0, 726.0, 1.0, 1.0]  episode_count: 3784 q_vals: [-6.914, -inf, -8.182, -5.512, -3.962, -9.303, -7.919]
Step 2220 4 visits [1.0, 1000.0, 1.0, 13.0, 727.0, 1.0, 1.0]  episode_count: 3785 q_vals: [-6.914, -inf, -8.182, -5.512, -3.957, -9.303, -7.919]
Step 2221 4 visits [1.0, 1000.0, 1.0, 13.0, 728.0, 1.0, 1.0]  episode_count: 3788 q_vals: [-6.914, -inf, -8.182, -5.512, -3.951, -9.303, -7.919]
Step 2222 4 visits [1.0, 1000.0, 1.0, 13.0, 729.0, 1.0, 1.0]  episode_count: 3790 q_vals: [-6.914, -inf, -8.182, -5.512, -3.954, -9.303, -7.919]
Step 2223 4 visits [1.0, 1000.0, 1.0, 13.0, 730.0, 1.0, 1.0]  episode_count: 3791 q_vals: [-6.914, -inf, -8.182, -5.512, -3.953, -9.303, -7.919]
Step 2224 4 visits [1.0, 1000.0, 1.0, 13.0, 731.0, 1.0, 1.0]  episode_count: 3793 q_vals: [-6.914, -inf, -8.182, -5.512, -3.948, -9.303, -7.919]
{"total_number_of_episodes": 3794, "number_of_timesteps": 70136, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2225 4 visits [1.0, 1000.0, 1.0, 13.0, 732.0, 1.0, 1.0]  episode_count: 3794 q_vals: [-6.914, -inf, -8.182, -5.512, -3.951, -9.303, -7.919]
Step 2226 4 visits [1.0, 1000.0, 1.0, 13.0, 733.0, 1.0, 1.0]  episode_count: 3794 q_vals: [-6.914, -inf, -8.182, -5.512, -3.963, -9.303, -7.919]
Step 2227 4 visits [1.0, 1000.0, 1.0, 13.0, 734.0, 1.0, 1.0]  episode_count: 3797 q_vals: [-6.914, -inf, -8.182, -5.512, -3.958, -9.303, -7.919]
Step 2228 4 visits [1.0, 1000.0, 1.0, 13.0, 735.0, 1.0, 1.0]  episode_count: 3799 q_vals: [-6.914, -inf, -8.182, -5.512, -3.959, -9.303, -7.919]
Step 2229 4 visits [1.0, 1000.0, 1.0, 13.0, 736.0, 1.0, 1.0]  episode_count: 3799 q_vals: [-6.914, -inf, -8.182, -5.512, -3.954, -9.303, -7.919]
Step 2230 4 visits [1.0, 1000.0, 1.0, 13.0, 737.0, 1.0, 1.0]  episode_count: 3800 q_vals: [-6.914, -inf, -8.182, -5.512, -3.954, -9.303, -7.919]
Step 2231 4 visits [1.0, 1000.0, 1.0, 13.0, 738.0, 1.0, 1.0]  episode_count: 3803 q_vals: [-6.914, -inf, -8.182, -5.512, -3.948, -9.303, -7.919]
{"total_number_of_episodes": 3804, "number_of_timesteps": 70363, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2232 4 visits [1.0, 1000.0, 1.0, 13.0, 739.0, 1.0, 1.0]  episode_count: 3804 q_vals: [-6.914, -inf, -8.182, -5.512, -3.947, -9.303, -7.919]
Step 2233 4 visits [1.0, 1000.0, 1.0, 13.0, 740.0, 1.0, 1.0]  episode_count: 3805 q_vals: [-6.914, -inf, -8.182, -5.512, -3.959, -9.303, -7.919]
Step 2234 4 visits [1.0, 1000.0, 1.0, 13.0, 741.0, 1.0, 1.0]  episode_count: 3809 q_vals: [-6.914, -inf, -8.182, -5.512, -3.959, -9.303, -7.919]
Step 2235 4 visits [1.0, 1000.0, 1.0, 13.0, 742.0, 1.0, 1.0]  episode_count: 3810 q_vals: [-6.914, -inf, -8.182, -5.512, -3.953, -9.303, -7.919]
Step 2236 4 visits [1.0, 1000.0, 1.0, 13.0, 743.0, 1.0, 1.0]  episode_count: 3812 q_vals: [-6.914, -inf, -8.182, -5.512, -3.953, -9.303, -7.919]
{"total_number_of_episodes": 3814, "number_of_timesteps": 70535, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 2237 4 visits [1.0, 1000.0, 1.0, 13.0, 744.0, 1.0, 1.0]  episode_count: 3814 q_vals: [-6.914, -inf, -8.182, -5.512, -3.948, -9.303, -7.919]
Step 2238 4 visits [1.0, 1000.0, 1.0, 13.0, 745.0, 1.0, 1.0]  episode_count: 3816 q_vals: [-6.914, -inf, -8.182, -5.512, -3.948, -9.303, -7.919]
Step 2239 4 visits [1.0, 1000.0, 1.0, 13.0, 746.0, 1.0, 1.0]  episode_count: 3819 q_vals: [-6.914, -inf, -8.182, -5.512, -3.947, -9.303, -7.919]
Step 2240 4 visits [1.0, 1000.0, 1.0, 13.0, 747.0, 1.0, 1.0]  episode_count: 3819 q_vals: [-6.914, -inf, -8.182, -5.512, -3.941, -9.303, -7.919]
Step 2241 4 visits [1.0, 1000.0, 1.0, 13.0, 748.0, 1.0, 1.0]  episode_count: 3820 q_vals: [-6.914, -inf, -8.182, -5.512, -3.941, -9.303, -7.919]
{"total_number_of_episodes": 3824, "number_of_timesteps": 70711, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2242 4 visits [1.0, 1000.0, 1.0, 13.0, 749.0, 1.0, 1.0]  episode_count: 3824 q_vals: [-6.914, -inf, -8.182, -5.512, -3.94, -9.303, -7.919]

Step 2244 4 visits [1.0, 1000.0, 1.0, 13.0, 751.0, 1.0, 1.0]  episode_count: 3825 q_vals: [-6.914, -inf, -8.182, -5.512, -3.934, -9.303, -7.919]
Step 2245 4 visits [1.0, 1000.0, 1.0, 13.0, 752.0, 1.0, 1.0]  episode_count: 3825 q_vals: [-6.914, -inf, -8.182, -5.512, -3.935, -9.303, -7.919]
Step 2246 4 visits [1.0, 1000.0, 1.0, 13.0, 753.0, 1.0, 1.0]  episode_count: 3829 q_vals: [-6.914, -inf, -8.182, -5.512, -3.93, -9.303, -7.919]
Step 2247 4 visits [1.0, 1000.0, 1.0, 13.0, 754.0, 1.0, 1.0]  episode_count: 3832 q_vals: [-6.914, -inf, -8.182, -5.512, -3.942, -9.303, -7.919]
Step 2248 4 visits [1.0, 1000.0, 1.0, 13.0, 755.0, 1.0, 1.0]  episode_count: 3832 q_vals: [-6.914, -inf, -8.182, -5.512, -3.942, -9.303, -7.919]
{"total_number_of_episodes": 3834, "number_of_timesteps": 70908, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2249 4 visits [1.0, 1000.0, 1.0, 13.0, 756.0, 1.0, 1.0]  episode_count: 3834 q_vals: [-6.914, -inf, -8.182, -5.512, -3.942, -9.303, -7.919]
Step 2250 4 visits [1.0, 1000.0, 1.0, 13.0, 757.0, 1.0, 1.0]  episode_count: 3834 q_vals: [-6.914, -inf, -8.182, -5.512, -3.947, -9.303, -7.919]
Step 2251 4 visits [1.0, 1000.0, 1.0, 13.0, 758.0, 1.0, 1.0]  episode_count: 3834 q_vals: [-6.914, -inf, -8.182, -5.512, -3.958, -9.303, -7.919]
Step 2252 4 visits [1.0, 1000.0, 1.0, 13.0, 759.0, 1.0, 1.0]  episode_count: 3836 q_vals: [-6.914, -inf, -8.182, -5.512, -3.958, -9.303, -7.919]
Step 2253 4 visits [1.0, 1000.0, 1.0, 13.0, 760.0, 1.0, 1.0]  episode_count: 3838 q_vals: [-6.914, -inf, -8.182, -5.512, -3.957, -9.303, -7.919]
Step 2254 4 visits [1.0, 1000.0, 1.0, 13.0, 761.0, 1.0, 1.0]  episode_count: 3840 q_vals: [-6.914, -inf, -8.182, -5.512, -3.958, -9.303, -7.919]
Step 2255 4 visits [1.0, 1000.0, 1.0, 13.0, 762.0, 1.0, 1.0]  episode_count: 3842 q_vals: [-6.914, -inf, -8.182, -5.512, -3.97, -9.303, -7.919]
{"total_number_of_episodes": 3844, "number_of_timesteps": 71138, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2256 4 visits [1.0, 1000.0, 1.0, 13.0, 763.0, 1.0, 1.0]  episode_count: 3844 q_vals: [-6.914, -inf, -8.182, -5.512, -3.97, -9.303, -7.919]
Step 2257 4 visits [1.0, 1000.0, 1.0, 13.0, 764.0, 1.0, 1.0]  episode_count: 3847 q_vals: [-6.914, -inf, -8.182, -5.512, -3.965, -9.303, -7.919]
Step 2258 4 visits [1.0, 1000.0, 1.0, 13.0, 765.0, 1.0, 1.0]  episode_count: 3848 q_vals: [-6.914, -inf, -8.182, -5.512, -3.96, -9.303, -7.919]
Step 2259 4 visits [1.0, 1000.0, 1.0, 13.0, 766.0, 1.0, 1.0]  episode_count: 3849 q_vals: [-6.914, -inf, -8.182, -5.512, -3.961, -9.303, -7.919]
Step 2260 4 visits [1.0, 1000.0, 1.0, 13.0, 767.0, 1.0, 1.0]  episode_count: 3851 q_vals: [-6.914, -inf, -8.182, -5.512, -3.973, -9.303, -7.919]
Step 2261 4 visits [1.0, 1000.0, 1.0, 13.0, 768.0, 1.0, 1.0]  episode_count: 3853 q_vals: [-6.914, -inf, -8.182, -5.512, -3.973, -9.303, -7.919]
{"total_number_of_episodes": 3855, "number_of_timesteps": 71328, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2262 4 visits [1.0, 1000.0, 1.0, 13.0, 769.0, 1.0, 1.0]  episode_count: 3855 q_vals: [-6.914, -inf, -8.182, -5.512, -3.973, -9.303, -7.919]
Step 2263 4 visits [1.0, 1000.0, 1.0, 13.0, 770.0, 1.0, 1.0]  episode_count: 3856 q_vals: [-6.914, -inf, -8.182, -5.512, -3.974, -9.303, -7.919]
Step 2264 4 visits [1.0, 1000.0, 1.0, 13.0, 771.0, 1.0, 1.0]  episode_count: 3858 q_vals: [-6.914, -inf, -8.182, -5.512, -3.974, -9.303, -7.919]
Step 2265 4 visits [1.0, 1000.0, 1.0, 13.0, 772.0, 1.0, 1.0]  episode_count: 3861 q_vals: [-6.914, -inf, -8.182, -5.512, -3.968, -9.303, -7.919]
Step 2266 4 visits [1.0, 1000.0, 1.0, 13.0, 773.0, 1.0, 1.0]  episode_count: 3862 q_vals: [-6.914, -inf, -8.182, -5.512, -3.969, -9.303, -7.919]
Step 2267 4 visits [1.0, 1000.0, 1.0, 13.0, 774.0, 1.0, 1.0]  episode_count: 3864 q_vals: [-6.914, -inf, -8.182, -5.512, -3.969, -9.303, -7.919]
{"total_number_of_episodes": 3867, "number_of_timesteps": 71517, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2268 4 visits [1.0, 1000.0, 1.0, 13.0, 775.0, 1.0, 1.0]  episode_count: 3867 q_vals: [-6.914, -inf, -8.182, -5.512, -3.968, -9.303, -7.919]
Step 2269 4 visits [1.0, 1000.0, 1.0, 13.0, 776.0, 1.0, 1.0]  episode_count: 3868 q_vals: [-6.914, -inf, -8.182, -5.512, -3.969, -9.303, -7.919]
Step 2270 4 visits [1.0, 1000.0, 1.0, 13.0, 777.0, 1.0, 1.0]  episode_count: 3869 q_vals: [-6.914, -inf, -8.182, -5.512, -3.969, -9.303, -7.919]
Step 2271 4 visits [1.0, 1000.0, 1.0, 13.0, 778.0, 1.0, 1.0]  episode_count: 3872 q_vals: [-6.914, -inf, -8.182, -5.512, -3.968, -9.303, -7.919]
Step 2272 4 visits [1.0, 1000.0, 1.0, 13.0, 779.0, 1.0, 1.0]  episode_count: 3874 q_vals: [-6.914, -inf, -8.182, -5.512, -3.968, -9.303, -7.919]
Step 2273 4 visits [1.0, 1000.0, 1.0, 13.0, 780.0, 1.0, 1.0]  episode_count: 3876 q_vals: [-6.914, -inf, -8.182, -5.512, -3.968, -9.303, -7.919]
{"total_number_of_episodes": 3878, "number_of_timesteps": 71693, "per_episode_reward": 13.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2274 4 visits [1.0, 1000.0, 1.0, 13.0, 781.0, 1.0, 1.0]  episode_count: 3878 q_vals: [-6.914, -inf, -8.182, -5.512, -3.963, -9.303, -7.919]
Step 2275 4 visits [1.0, 1000.0, 1.0, 13.0, 782.0, 1.0, 1.0]  episode_count: 3882 q_vals: [-6.914, -inf, -8.182, -5.512, -3.963, -9.303, -7.919]
Step 2276 4 visits [1.0, 1000.0, 1.0, 13.0, 783.0, 1.0, 1.0]  episode_count: 3882 q_vals: [-6.914, -inf, -8.182, -5.512, -3.958, -9.303, -7.919]
Step 2277 4 visits [1.0, 1000.0, 1.0, 13.0, 784.0, 1.0, 1.0]  episode_count: 3884 q_vals: [-6.914, -inf, -8.182, -5.512, -3.953, -9.303, -7.919]
Step 2278 4 visits [1.0, 1000.0, 1.0, 13.0, 785.0, 1.0, 1.0]  episode_count: 3886 q_vals: [-6.914, -inf, -8.182, -5.512, -3.953, -9.303, -7.919]
{"total_number_of_episodes": 3891, "number_of_timesteps": 71883, "per_episode_reward": 13.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2279 4 visits [1.0, 1000.0, 1.0, 13.0, 786.0, 1.0, 1.0]  episode_count: 3891 q_vals: [-6.914, -inf, -8.182, -5.512, -3.952, -9.303, -7.919]
Step 2280 4 visits [1.0, 1000.0, 1.0, 13.0, 787.0, 1.0, 1.0]  episode_count: 3892 q_vals: [-6.914, -inf, -8.182, -5.512, -3.954, -9.303, -7.919]
[-6.914, -inf, -8.182, -5.512, -3.953, -9.303, -7.919]
Step 2282 4 visits [1.0, 1000.0, 1.0, 13.0, 789.0, 1.0, 1.0]  episode_count: 3897 q_vals: [-6.914, -inf, -8.182, -5.512, -3.948, -9.303, -7.919]
Step 2283 4 visits [1.0, 1000.0, 1.0, 13.0, 790.0, 1.0, 1.0]  episode_count: 3900 q_vals: [-6.914, -inf, -8.182, -5.512, -3.948, -9.303, -7.919]
{"total_number_of_episodes": 3901, "number_of_timesteps": 72002, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2284 4 visits [1.0, 1000.0, 1.0, 13.0, 791.0, 1.0, 1.0]  episode_count: 3901 q_vals: [-6.914, -inf, -8.182, -5.512, -3.943, -9.303, -7.919]
Step 2285 4 visits [1.0, 1000.0, 1.0, 13.0, 792.0, 1.0, 1.0]  episode_count: 3902 q_vals: [-6.914, -inf, -8.182, -5.512, -3.943, -9.303, -7.919]
Step 2286 4 visits [1.0, 1000.0, 1.0, 13.0, 793.0, 1.0, 1.0]  episode_count: 3906 q_vals: [-6.914, -inf, -8.182, -5.512, -3.943, -9.303, -7.919]
Step 2287 4 visits [1.0, 1000.0, 1.0, 13.0, 794.0, 1.0, 1.0]  episode_count: 3908 q_vals: [-6.914, -inf, -8.182, -5.512, -3.938, -9.303, -7.919]
Step 2288 4 visits [1.0, 1000.0, 1.0, 13.0, 795.0, 1.0, 1.0]  episode_count: 3908 q_vals: [-6.914, -inf, -8.182, -5.512, -3.933, -9.303, -7.919]
Step 2289 4 visits [1.0, 1000.0, 1.0, 13.0, 796.0, 1.0, 1.0]  episode_count: 3909 q_vals: [-6.914, -inf, -8.182, -5.512, -3.928, -9.303, -7.919]
{"total_number_of_episodes": 3913, "number_of_timesteps": 72192, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2290 4 visits [1.0, 1000.0, 1.0, 13.0, 797.0, 1.0, 1.0]  episode_count: 3913 q_vals: [-6.914, -inf, -8.182, -5.512, -3.928, -9.303, -7.919]
Step 2291 4 visits [1.0, 1000.0, 1.0, 13.0, 798.0, 1.0, 1.0]  episode_count: 3915 q_vals: [-6.914, -inf, -8.182, -5.512, -3.923, -9.303, -7.919]
Step 2292 4 visits [1.0, 1000.0, 1.0, 13.0, 799.0, 1.0, 1.0]  episode_count: 3915 q_vals: [-6.914, -inf, -8.182, -5.512, -3.934, -9.303, -7.919]
Step 2293 4 visits [1.0, 1000.0, 1.0, 13.0, 800.0, 1.0, 1.0]  episode_count: 3920 q_vals: [-6.914, -inf, -8.182, -5.512, -3.935, -9.303, -7.919]
Step 2294 4 visits [1.0, 1000.0, 1.0, 13.0, 801.0, 1.0, 1.0]  episode_count: 3920 q_vals: [-6.914, -inf, -8.182, -5.512, -3.936, -9.303, -7.919]
{"total_number_of_episodes": 3923, "number_of_timesteps": 72339, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2295 4 visits [1.0, 1000.0, 1.0, 13.0, 802.0, 1.0, 1.0]  episode_count: 3923 q_vals: [-6.914, -inf, -8.182, -5.512, -3.931, -9.303, -7.919]
Step 2296 4 visits [1.0, 1000.0, 1.0, 13.0, 803.0, 1.0, 1.0]  episode_count: 3925 q_vals: [-6.914, -inf, -8.182, -5.512, -3.93, -9.303, -7.919]
Step 2297 4 visits [1.0, 1000.0, 1.0, 13.0, 804.0, 1.0, 1.0]  episode_count: 3926 q_vals: [-6.914, -inf, -8.182, -5.512, -3.941, -9.303, -7.919]
Step 2298 4 visits [1.0, 1000.0, 1.0, 13.0, 805.0, 1.0, 1.0]  episode_count: 3929 q_vals: [-6.914, -inf, -8.182, -5.512, -3.941, -9.303, -7.919]
Step 2299 4 visits [1.0, 1000.0, 1.0, 13.0, 806.0, 1.0, 1.0]  episode_count: 3932 q_vals: [-6.914, -inf, -8.182, -5.512, -3.941, -9.303, -7.919]
{"total_number_of_episodes": 3933, "number_of_timesteps": 72494, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2300 4 visits [1.0, 1000.0, 1.0, 13.0, 807.0, 1.0, 1.0]  episode_count: 3933 q_vals: [-6.914, -inf, -8.182, -5.512, -3.937, -9.303, -7.919]
Step 2301 4 visits [1.0, 1000.0, 1.0, 13.0, 808.0, 1.0, 1.0]  episode_count: 3935 q_vals: [-6.914, -inf, -8.182, -5.512, -3.936, -9.303, -7.919]
Step 2302 4 visits [1.0, 1000.0, 1.0, 13.0, 809.0, 1.0, 1.0]  episode_count: 3936 q_vals: [-6.914, -inf, -8.182, -5.512, -3.947, -9.303, -7.919]
Step 2303 4 visits [1.0, 1000.0, 1.0, 13.0, 810.0, 1.0, 1.0]  episode_count: 3940 q_vals: [-6.914, -inf, -8.182, -5.512, -3.947, -9.303, -7.919]
Step 2304 4 visits [1.0, 1000.0, 1.0, 13.0, 811.0, 1.0, 1.0]  episode_count: 3941 q_vals: [-6.914, -inf, -8.182, -5.512, -3.947, -9.303, -7.919]
{"total_number_of_episodes": 3944, "number_of_timesteps": 72645, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2305 4 visits [1.0, 1000.0, 1.0, 13.0, 812.0, 1.0, 1.0]  episode_count: 3944 q_vals: [-6.914, -inf, -8.182, -5.512, -3.947, -9.303, -7.919]
Step 2306 4 visits [1.0, 1000.0, 1.0, 13.0, 813.0, 1.0, 1.0]  episode_count: 3945 q_vals: [-6.914, -inf, -8.182, -5.512, -3.948, -9.303, -7.919]
Step 2307 4 visits [1.0, 1000.0, 1.0, 13.0, 814.0, 1.0, 1.0]  episode_count: 3948 q_vals: [-6.914, -inf, -8.182, -5.512, -3.943, -9.303, -7.919]
Step 2308 4 visits [1.0, 1000.0, 1.0, 13.0, 815.0, 1.0, 1.0]  episode_count: 3951 q_vals: [-6.914, -inf, -8.182, -5.512, -3.938, -9.303, -7.919]
Step 2309 4 visits [1.0, 1000.0, 1.0, 13.0, 816.0, 1.0, 1.0]  episode_count: 3951 q_vals: [-6.914, -inf, -8.182, -5.512, -3.949, -9.303, -7.919]
{"total_number_of_episodes": 3954, "number_of_timesteps": 72808, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2310 4 visits [1.0, 1000.0, 1.0, 13.0, 817.0, 1.0, 1.0]  episode_count: 3954 q_vals: [-6.914, -inf, -8.182, -5.512, -3.954, -9.303, -7.919]
Step 2311 4 visits [1.0, 1000.0, 1.0, 13.0, 818.0, 1.0, 1.0]  episode_count: 3955 q_vals: [-6.914, -inf, -8.182, -5.512, -3.965, -9.303, -7.919]
Step 2312 4 visits [1.0, 1000.0, 1.0, 13.0, 819.0, 1.0, 1.0]  episode_count: 3956 q_vals: [-6.914, -inf, -8.182, -5.512, -3.965, -9.303, -7.919]
Step 2313 4 visits [1.0, 1000.0, 1.0, 13.0, 820.0, 1.0, 1.0]  episode_count: 3959 q_vals: [-6.914, -inf, -8.182, -5.512, -3.965, -9.303, -7.919]
Step 2314 4 visits [1.0, 1000.0, 1.0, 13.0, 821.0, 1.0, 1.0]  episode_count: 3960 q_vals: [-6.914, -inf, -8.182, -5.512, -3.966, -9.303, -7.919]
Step 2315 4 visits [1.0, 1000.0, 1.0, 13.0, 822.0, 1.0, 1.0]  episode_count: 3961 q_vals: [-6.914, -inf, -8.182, -5.512, -3.974, -9.303, -7.919]
Step 2316 4 visits [1.0, 1000.0, 1.0, 13.0, 823.0, 1.0, 1.0]  episode_count: 3962 q_vals: [-6.914, -inf, -8.182, -5.512, -3.985, -9.303, -7.919]
Step 2317 4 visits [1.0, 1000.0, 1.0, 13.0, 824.0, 1.0, 1.0]  episode_count: 3963 q_vals: [-6.914, -inf, -8.182, -5.512, -3.985, -9.303, -7.919]
{"total_number_of_episodes": 3966, "number_of_timesteps": 73041, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2318 4 visits [1.0, 1000.0, 1.0, 13.0, 825.0, 1.0, 1.0]  episode_count: 3966 q_vals: [-6.914, -inf, -8.182, -5.512, -3.984, -9.303, -7.919]
Step 2319 4 visits [1.0, 1000.0, 1.0, 13.0, 826.0, 1.0, 1.0]  episode_count: 3968 q_vals: [-6.914, -inf, -8.182, -5.512, -3.985, -9.303, -7.919]
Step 2320 4 visits [1.0, 1000.0, 1.0, 13.0, 827.0, 1.0, 1.0]  episode_count: 3968 q_vals: [-6.914, -inf, -8.182, -5.512, -3.985, -9.303, -7.919]
Step 2321 4 visits [1.0, 1000.0, 1.0, 13.0, 828.0, 1.0, 1.0]  episode_count: 3970 q_vals: [-6.914, -inf, -8.182, -5.512, -3.98, -9.303, -7.919]
Step 2322 4 visits [1.0, 1000.0, 1.0, 13.0, 829.0, 1.0, 1.0]  episode_count: 3971 q_vals: [-6.914, -inf, -8.182, -5.512, -3.975, -9.303, -7.919]
Step 2323 4 visits [1.0, 1000.0, 1.0, 13.0, 830.0, 1.0, 1.0]  episode_count: 3972 q_vals: [-6.914, -inf, -8.182, -5.512, -3.97, -9.303, -7.919]
{"total_number_of_episodes": 3976, "number_of_timesteps": 73253, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2324 4 visits [1.0, 1000.0, 1.0, 13.0, 831.0, 1.0, 1.0]  episode_count: 3976 q_vals: [-6.914, -inf, -8.182, -5.512, -3.97, -9.303, -7.919]
Step 2325 4 visits [1.0, 1000.0, 1.0, 13.0, 832.0, 1.0, 1.0]  episode_count: 3976 q_vals: [-6.914, -inf, -8.182, -5.512, -3.97, -9.303, -7.919]
Step 2326 4 visits [1.0, 1000.0, 1.0, 13.0, 833.0, 1.0, 1.0]  episode_count: 3977 q_vals: [-6.914, -inf, -8.182, -5.512, -3.969, -9.303, -7.919]
Step 2327 4 visits [1.0, 1000.0, 1.0, 13.0, 834.0, 1.0, 1.0]  episode_count: 3978 q_vals: [-6.914, -inf, -8.182, -5.512, -3.97, -9.303, -7.919]
Step 2328 4 visits [1.0, 1000.0, 1.0, 13.0, 835.0, 1.0, 1.0]  episode_count: 3980 q_vals: [-6.914, -inf, -8.182, -5.512, -3.971, -9.303, -7.919]
Step 2329 4 visits [1.0, 1000.0, 1.0, 13.0, 836.0, 1.0, 1.0]  episode_count: 3981 q_vals: [-6.914, -inf, -8.182, -5.512, -3.981, -9.303, -7.919]
Step 2330 4 visits [1.0, 1000.0, 1.0, 13.0, 837.0, 1.0, 1.0]  episode_count: 3983 q_vals: [-6.914, -inf, -8.182, -5.512, -3.992, -9.303, -7.919]
Step 2331 4 visits [1.0, 1000.0, 1.0, 13.0, 838.0, 1.0, 1.0]  episode_count: 3985 q_vals: [-6.914, -inf, -8.182, -5.512, -3.991, -9.303, -7.919]
{"total_number_of_episodes": 3987, "number_of_timesteps": 73490, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2332 4 visits [1.0, 1000.0, 1.0, 13.0, 839.0, 1.0, 1.0]  episode_count: 3987 q_vals: [-6.914, -inf, -8.182, -5.512, -3.987, -9.303, -7.919]
Step 2333 4 visits [1.0, 1000.0, 1.0, 13.0, 840.0, 1.0, 1.0]  episode_count: 3989 q_vals: [-6.914, -inf, -8.182, -5.512, -3.986, -9.303, -7.919]
Step 2334 4 visits [1.0, 1000.0, 1.0, 13.0, 841.0, 1.0, 1.0]  episode_count: 3991 q_vals: [-6.914, -inf, -8.182, -5.512, -3.997, -9.303, -7.919]
Step 2335 4 visits [1.0, 1000.0, 1.0, 13.0, 842.0, 1.0, 1.0]  episode_count: 3991 q_vals: [-6.914, -inf, -8.182, -5.512, -4.007, -9.303, -7.919]
Step 2336 4 visits [1.0, 1000.0, 1.0, 13.0, 843.0, 1.0, 1.0]  episode_count: 3994 q_vals: [-6.914, -inf, -8.182, -5.512, -4.007, -9.303, -7.919]
Step 2337 4 visits [1.0, 1000.0, 1.0, 13.0, 844.0, 1.0, 1.0]  episode_count: 3996 q_vals: [-6.914, -inf, -8.182, -5.512, -4.007, -9.303, -7.919]
Step 2338 4 visits [1.0, 1000.0, 1.0, 13.0, 845.0, 1.0, 1.0]  episode_count: 3996 q_vals: [-6.914, -inf, -8.182, -5.512, -4.006, -9.303, -7.919]
{"total_number_of_episodes": 3999, "number_of_timesteps": 73702, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2339 4 visits [1.0, 1000.0, 1.0, 13.0, 846.0, 1.0, 1.0]  episode_count: 3999 q_vals: [-6.914, -inf, -8.182, -5.512, -4.002, -9.303, -7.919]
Step 2340 4 visits [1.0, 1000.0, 1.0, 13.0, 847.0, 1.0, 1.0]  episode_count: 4000 q_vals: [-6.914, -inf, -8.182, -5.512, -3.997, -9.303, -7.919]
Step 2341 4 visits [1.0, 1000.0, 1.0, 13.0, 848.0, 1.0, 1.0]  episode_count: 4002 q_vals: [-6.914, -inf, -8.182, -5.512, -4.004, -9.303, -7.919]
Step 2342 4 visits [1.0, 1000.0, 1.0, 13.0, 849.0, 1.0, 1.0]  episode_count: 4004 q_vals: [-6.914, -inf, -8.182, -5.512, -4.003, -9.303, -7.919]
Step 2343 4 visits [1.0, 1000.0, 1.0, 13.0, 850.0, 1.0, 1.0]  episode_count: 4005 q_vals: [-6.914, -inf, -8.182, -5.512, -4.003, -9.303, -7.919]
Step 2344 4 visits [1.0, 1000.0, 1.0, 13.0, 851.0, 1.0, 1.0]  episode_count: 4007 q_vals: [-6.914, -inf, -8.182, -5.512, -4.003, -9.303, -7.919]
{"total_number_of_episodes": 4009, "number_of_timesteps": 73899, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2345 4 visits [1.0, 1000.0, 1.0, 13.0, 852.0, 1.0, 1.0]  episode_count: 4009 q_vals: [-6.914, -inf, -8.182, -5.512, -3.998, -9.303, -7.919]
Step 2346 4 visits [1.0, 1000.0, 1.0, 13.0, 853.0, 1.0, 1.0]  episode_count: 4013 q_vals: [-6.914, -inf, -8.182, -5.512, -3.999, -9.303, -7.919]
Step 2347 4 visits [1.0, 1000.0, 1.0, 13.0, 854.0, 1.0, 1.0]  episode_count: 4013 q_vals: [-6.914, -inf, -8.182, -5.512, -4.0, -9.303, -7.919]
Step 2348 4 visits [1.0, 1000.0, 1.0, 13.0, 855.0, 1.0, 1.0]  episode_count: 4015 q_vals: [-6.914, -inf, -8.182, -5.512, -3.995, -9.303, -7.919]
Step 2349 4 visits [1.0, 1000.0, 1.0, 13.0, 856.0, 1.0, 1.0]  episode_count: 4018 q_vals: [-6.914, -inf, -8.182, -5.512, -3.996, -9.303, -7.919]
Step 2350 4 visits [1.0, 1000.0, 1.0, 13.0, 857.0, 1.0, 1.0]  episode_count: 4018 q_vals: [-6.914, -inf, -8.182, -5.512, -3.991, -9.303, -7.919]
{"total_number_of_episodes": 4020, "number_of_timesteps": 74079, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2351 4 visits [1.0, 1000.0, 1.0, 13.0, 858.0, 1.0, 1.0]  episode_count: 4020 q_vals: [-6.914, -inf, -8.182, -5.512, -3.991, -9.303, -7.919]
Step 2352 4 visits [1.0, 1000.0, 1.0, 13.0, 859.0, 1.0, 1.0]  episode_count: 4022 q_vals: [-6.914, -inf, -8.182, -5.512, -3.986, -9.303, -7.919]
Step 2353 4 visits [1.0, 1000.0, 1.0, 13.0, 860.0, 1.0, 1.0]  episode_count: 4023 q_vals: [-6.914, -inf, -8.182, -5.512, -3.982, -9.303, -7.919]
Step 2354 4 visits [1.0, 1000.0, 1.0, 13.0, 861.0, 1.0, 1.0]  episode_count: 4026 q_vals: [-6.914, -inf, -8.182, -5.512, -3.982, -9.303, -7.919]
Step 2355 4 visits [1.0, 1000.0, 1.0, 13.0, 862.0, 1.0, 1.0]  episode_count: 4029 q_vals: [-6.914, -inf, -8.182, -5.512, -3.982, -9.303, -7.919]
Step 2356 4 visits [1.0, 1000.0, 1.0, 13.0, 863.0, 1.0, 1.0]  episode_count: 4029 q_vals: [-6.914, -inf, -8.182, -5.512, -3.981, -9.303, -7.919]
{"total_number_of_episodes": 4031, "number_of_timesteps": 74272, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2357 4 visits [1.0, 1000.0, 1.0, 13.0, 864.0, 1.0, 1.0]  episode_count: 4031 q_vals: [-6.914, -inf, -8.182, -5.512, -3.981, -9.303, -7.919]
Step 2358 4 visits [1.0, 1000.0, 1.0, 13.0, 865.0, 1.0, 1.0]  episode_count: 4033 q_vals: [-6.914, -inf, -8.182, -5.512, -3.981, -9.303, -7.919]
Step 2359 4 visits [1.0, 1000.0, 1.0, 13.0, 866.0, 1.0, 1.0]  episode_count: 4035 q_vals: [-6.914, -inf, -8.182, -5.512, -3.981, -9.303, -7.919]
Step 2360 4 visits [1.0, 1000.0, 1.0, 13.0, 867.0, 1.0, 1.0]  episode_count: 4035 q_vals: [-6.914, -inf, -8.182, -5.512, -3.976, -9.303, -7.919]
Step 2361 4 visits [1.0, 1000.0, 1.0, 13.0, 868.0, 1.0, 1.0]  episode_count: 4039 q_vals: [-6.914, -inf, -8.182, -5.512, -3.976, -9.303, -7.919]
Step 2362 4 visits [1.0, 1000.0, 1.0, 13.0, 869.0, 1.0, 1.0]  episode_count: 4039 q_vals: [-6.914, -inf, -8.182, -5.512, -3.972, -9.303, -7.919]
{"total_number_of_episodes": 4042, "number_of_timesteps": 74487, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2363 4 visits [1.0, 1000.0, 1.0, 13.0, 870.0, 1.0, 1.0]  episode_count: 4042 q_vals: [-6.914, -inf, -8.182, -5.512, -3.972, -9.303, -7.919]
Step 2364 4 visits [1.0, 1000.0, 1.0, 13.0, 871.0, 1.0, 1.0]  episode_count: 4042 q_vals: [-6.914, -inf, -8.182, -5.512, -3.971, -9.303, -7.919]
Step 2365 4 visits [1.0, 1000.0, 1.0, 13.0, 872.0, 1.0, 1.0]  episode_count: 4043 q_vals: [-6.914, -inf, -8.182, -5.512, -3.972, -9.303, -7.919]
Step 2366 4 visits [1.0, 1000.0, 1.0, 13.0, 873.0, 1.0, 1.0]  episode_count: 4045 q_vals: [-6.914, -inf, -8.182, -5.512, -3.972, -9.303, -7.919]
Step 2367 4 visits [1.0, 1000.0, 1.0, 13.0, 874.0, 1.0, 1.0]  episode_count: 4046 q_vals: [-6.914, -inf, -8.182, -5.512, -3.972, -9.303, -7.919]
Step 2368 4 visits [1.0, 1000.0, 1.0, 13.0, 875.0, 1.0, 1.0]  episode_count: 4048 q_vals: [-6.914, -inf, -8.182, -5.512, -3.982, -9.303, -7.919]
Step 2369 4 visits [1.0, 1000.0, 1.0, 13.0, 876.0, 1.0, 1.0]  episode_count: 4049 q_vals: [-6.914, -inf, -8.182, -5.512, -3.982, -9.303, -7.919]
Step 2370 4 visits [1.0, 1000.0, 1.0, 13.0, 877.0, 1.0, 1.0]  episode_count: 4051 q_vals: [-6.914, -inf, -8.182, -5.512, -3.982, -9.303, -7.919]
{"total_number_of_episodes": 4053, "number_of_timesteps": 74744, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2371 4 visits [1.0, 1000.0, 1.0, 13.0, 878.0, 1.0, 1.0]  episode_count: 4053 q_vals: [-6.914, -inf, -8.182, -5.512, -3.982, -9.303, -7.919]
Step 2372 4 visits [1.0, 1000.0, 1.0, 13.0, 879.0, 1.0, 1.0]  episode_count: 4053 q_vals: [-6.914, -inf, -8.182, -5.512, -3.992, -9.303, -7.919]
Step 2373 4 visits [1.0, 1000.0, 1.0, 13.0, 880.0, 1.0, 1.0]  episode_count: 4055 q_vals: [-6.914, -inf, -8.182, -5.512, -4.002, -9.303, -7.919]
Step 2374 4 visits [1.0, 1000.0, 1.0, 13.0, 881.0, 1.0, 1.0]  episode_count: 4058 q_vals: [-6.914, -inf, -8.182, -5.512, -4.001, -9.303, -7.919]
Step 2375 4 visits [1.0, 1000.0, 1.0, 13.0, 882.0, 1.0, 1.0]  episode_count: 4059 q_vals: [-6.914, -inf, -8.182, -5.512, -4.011, -9.303, -7.919]
Step 2376 4 visits [1.0, 1000.0, 1.0, 13.0, 883.0, 1.0, 1.0]  episode_count: 4060 q_vals: [-6.914, -inf, -8.182, -5.512, -4.007, -9.303, -7.919]
Step 2377 4 visits [1.0, 1000.0, 1.0, 13.0, 884.0, 1.0, 1.0]  episode_count: 4060 q_vals: [-6.914, -inf, -8.182, -5.512, -4.002, -9.303, -7.919]
Step 2378 4 visits [1.0, 1000.0, 1.0, 13.0, 885.0, 1.0, 1.0]  episode_count: 4062 q_vals: [-6.914, -inf, -8.182, -5.512, -3.997, -9.303, -7.919]
Step 2379 4 visits [1.0, 1000.0, 1.0, 13.0, 886.0, 1.0, 1.0]  episode_count: 4062 q_vals: [-6.914, -inf, -8.182, -5.512, -3.997, -9.303, -7.919]
{"total_number_of_episodes": 4066, "number_of_timesteps": 75028, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2380 4 visits [1.0, 1000.0, 1.0, 13.0, 887.0, 1.0, 1.0]  episode_count: 4066 q_vals: [-6.914, -inf, -8.182, -5.512, -3.997, -9.303, -7.919]
Step 2381 4 visits [1.0, 1000.0, 1.0, 13.0, 888.0, 1.0, 1.0]  episode_count: 4068 q_vals: [-6.914, -inf, -8.182, -5.512, -3.998, -9.303, -7.919]
Step 2382 4 visits [1.0, 1000.0, 1.0, 13.0, 889.0, 1.0, 1.0]  episode_count: 4068 q_vals: [-6.914, -inf, -8.182, -5.512, -4.008, -9.303, -7.919]
Step 2383 4 visits [1.0, 1000.0, 1.0, 13.0, 890.0, 1.0, 1.0]  episode_count: 4071 q_vals: [-6.914, -inf, -8.182, -5.512, -4.008, -9.303, -7.919]
Step 2384 4 visits [1.0, 1000.0, 1.0, 13.0, 891.0, 1.0, 1.0]  episode_count: 4074 q_vals: [-6.914, -inf, -8.182, -5.512, -4.008, -9.303, -7.919]
Step 2385 4 visits [1.0, 1000.0, 1.0, 13.0, 892.0, 1.0, 1.0]  episode_count: 4075 q_vals: [-6.914, -inf, -8.182, -5.512, -4.004, -9.303, -7.919]
Step 2386 4 visits [1.0, 1000.0, 1.0, 13.0, 893.0, 1.0, 1.0]  episode_count: 4075 q_vals: [-6.914, -inf, -8.182, -5.512, -4.004, -9.303, -7.919]
{"total_number_of_episodes": 4078, "number_of_timesteps": 75239, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2387 4 visits [1.0, 1000.0, 1.0, 13.0, 894.0, 1.0, 1.0]  episode_count: 4078 q_vals: [-6.914, -inf, -8.182, -5.512, -4.003, -9.303, -7.919]
Step 2388 4 visits [1.0, 1000.0, 1.0, 13.0, 895.0, 1.0, 1.0]  episode_count: 4081 q_vals: [-6.914, -inf, -8.182, -5.512, -4.003, -9.303, -7.919]
Step 2389 4 visits [1.0, 1000.0, 1.0, 13.0, 896.0, 1.0, 1.0]  episode_count: 4081 q_vals: [-6.914, -inf, -8.182, -5.512, -4.002, -9.303, -7.919]
Step 2390 4 visits [1.0, 1000.0, 1.0, 13.0, 897.0, 1.0, 1.0]  episode_count: 4082 q_vals: [-6.914, -inf, -8.182, -5.512, -4.002, -9.303, -7.919]
Step 2391 4 visits [1.0, 1000.0, 1.0, 13.0, 898.0, 1.0, 1.0]  episode_count: 4085 q_vals: [-6.914, -inf, -8.182, -5.512, -4.001, -9.303, -7.919]
Step 2392 4 visits [1.0, 1000.0, 1.0, 13.0, 899.0, 1.0, 1.0]  episode_count: 4087 q_vals: [-6.914, -inf, -8.182, -5.512, -4.001, -9.303, -7.919]
{"total_number_of_episodes": 4088, "number_of_timesteps": 75419, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2393 4 visits [1.0, 1000.0, 1.0, 13.0, 900.0, 1.0, 1.0]  episode_count: 4088 q_vals: [-6.914, -inf, -8.182, -5.512, -4.011, -9.303, -7.919]
Step 2394 4 visits [1.0, 1000.0, 1.0, 13.0, 901.0, 1.0, 1.0]  episode_count: 4090 q_vals: [-6.914, -inf, -8.182, -5.512, -4.006, -9.303, -7.919]
Step 2395 4 visits [1.0, 1000.0, 1.0, 13.0, 902.0, 1.0, 1.0]  episode_count: 4091 q_vals: [-6.914, -inf, -8.182, -5.512, -4.016, -9.303, -7.919]
Step 2396 4 visits [1.0, 1000.0, 1.0, 13.0, 903.0, 1.0, 1.0]  episode_count: 4092 q_vals: [-6.914, -inf, -8.182, -5.512, -4.018, -9.303, -7.919]
Step 2397 4 visits [1.0, 1000.0, 1.0, 13.0, 904.0, 1.0, 1.0]  episode_count: 4093 q_vals: [-6.914, -inf, -8.182, -5.512, -4.017, -9.303, -7.919]
Step 2398 4 visits [1.0, 1000.0, 1.0, 13.0, 905.0, 1.0, 1.0]  episode_count: 4095 q_vals: [-6.914, -inf, -8.182, -5.512, -4.018, -9.303, -7.919]
Step 2399 4 visits [1.0, 1000.0, 1.0, 13.0, 906.0, 1.0, 1.0]  episode_count: 4095 q_vals: [-6.914, -inf, -8.182, -5.512, -4.018, -9.303, -7.919]
{"total_number_of_episodes": 4098, "number_of_timesteps": 75634, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2400 4 visits [1.0, 1000.0, 1.0, 13.0, 907.0, 1.0, 1.0]  episode_count: 4098 q_vals: [-6.914, -inf, -8.182, -5.512, -4.019, -9.303, -7.919]
Step 2401 4 visits [1.0, 1000.0, 1.0, 13.0, 908.0, 1.0, 1.0]  episode_count: 4098 q_vals: [-6.914, -inf, -8.182, -5.512, -4.02, -9.303, -7.919]
Step 2402 4 visits [1.0, 1000.0, 1.0, 13.0, 909.0, 1.0, 1.0]  episode_count: 4100 q_vals: [-6.914, -inf, -8.182, -5.512, -4.02, -9.303, -7.919]
Step 2403 4 visits [1.0, 1000.0, 1.0, 13.0, 910.0, 1.0, 1.0]  episode_count: 4102 q_vals: [-6.914, -inf, -8.182, -5.512, -4.02, -9.303, -7.919]
Step 2404 4 visits [1.0, 1000.0, 1.0, 13.0, 911.0, 1.0, 1.0]  episode_count: 4104 q_vals: [-6.914, -inf, -8.182, -5.512, -4.02, -9.303, -7.919]
Step 2405 4 visits [1.0, 1000.0, 1.0, 13.0, 912.0, 1.0, 1.0]  episode_count: 4105 q_vals: [-6.914, -inf, -8.182, -5.512, -4.021, -9.303, -7.919]
Step 2406 4 visits [1.0, 1000.0, 1.0, 13.0, 913.0, 1.0, 1.0]  episode_count: 4107 q_vals: [-6.914, -inf, -8.182, -5.512, -4.016, -9.303, -7.919]
{"total_number_of_episodes": 4109, "number_of_timesteps": 75838, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2407 4 visits [1.0, 1000.0, 1.0, 13.0, 914.0, 1.0, 1.0]  episode_count: 4109 q_vals: [-6.914, -inf, -8.182, -5.512, -4.016, -9.303, -7.919]
Step 2408 4 visits [1.0, 1000.0, 1.0, 13.0, 915.0, 1.0, 1.0]  episode_count: 4112 q_vals: [-6.914, -inf, -8.182, -5.512, -4.015, -9.303, -7.919]
Step 2409 4 visits [1.0, 1000.0, 1.0, 13.0, 916.0, 1.0, 1.0]  episode_count: 4113 q_vals: [-6.914, -inf, -8.182, -5.512, -4.015, -9.303, -7.919]
Step 2410 4 visits [1.0, 1000.0, 1.0, 13.0, 917.0, 1.0, 1.0]  episode_count: 4115 q_vals: [-6.914, -inf, -8.182, -5.512, -4.014, -9.303, -7.919]
Step 2411 4 visits [1.0, 1000.0, 1.0, 13.0, 918.0, 1.0, 1.0]  episode_count: 4116 q_vals: [-6.914, -inf, -8.182, -5.512, -4.014, -9.303, -7.919]
Step 2412 4 visits [1.0, 1000.0, 1.0, 13.0, 919.0, 1.0, 1.0]  episode_count: 4118 q_vals: [-6.914, -inf, -8.182, -5.512, -4.01, -9.303, -7.919]
{"total_number_of_episodes": 4120, "number_of_timesteps": 76073, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2413 4 visits [1.0, 1000.0, 1.0, 13.0, 920.0, 1.0, 1.0]  episode_count: 4120 q_vals: [-6.914, -inf, -8.182, -5.512, -4.005, -9.303, -7.919]
Step 2414 4 visits [1.0, 1000.0, 1.0, 13.0, 921.0, 1.0, 1.0]  episode_count: 4121 q_vals: [-6.914, -inf, -8.182, -5.512, -4.005, -9.303, -7.919]
Step 2415 4 visits [1.0, 1000.0, 1.0, 13.0, 922.0, 1.0, 1.0]  episode_count: 4123 q_vals: [-6.914, -inf, -8.182, -5.512, -4.007, -9.303, -7.919]
Step 2416 4 visits [1.0, 1000.0, 1.0, 13.0, 923.0, 1.0, 1.0]  episode_count: 4125 q_vals: [-6.914, -inf, -8.182, -5.512, -4.006, -9.303, -7.919]
Step 2417 4 visits [1.0, 1000.0, 1.0, 13.0, 924.0, 1.0, 1.0]  episode_count: 4126 q_vals: [-6.914, -inf, -8.182, -5.512, -4.002, -9.303, -7.919]
Step 2418 4 visits [1.0, 1000.0, 1.0, 13.0, 925.0, 1.0, 1.0]  episode_count: 4126 q_vals: [-6.914, -inf, -8.182, -5.512, -4.002, -9.303, -7.919]
Step 2419 4 visits [1.0, 1000.0, 1.0, 13.0, 926.0, 1.0, 1.0]  episode_count: 4127 q_vals: [-6.914, -inf, -8.182, -5.512, -4.001, -9.303, -7.919]
Step 2420 4 visits [1.0, 1000.0, 1.0, 13.0, 927.0, 1.0, 1.0]  episode_count: 4127 q_vals: [-6.914, -inf, -8.182, -5.512, -4.002, -9.303, -7.919]
Step 2421 4 visits [1.0, 1000.0, 1.0, 13.0, 928.0, 1.0, 1.0]  episode_count: 4129 q_vals: [-6.914, -inf, -8.182, -5.512, -3.998, -9.303, -7.919]
{"total_number_of_episodes": 4132, "number_of_timesteps": 76337, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2422 4 visits [1.0, 1000.0, 1.0, 13.0, 929.0, 1.0, 1.0]  episode_count: 4132 q_vals: [-6.914, -inf, -8.182, -5.512, -3.997, -9.303, -7.919]
Step 2423 4 visits [1.0, 1000.0, 1.0, 13.0, 930.0, 1.0, 1.0]  episode_count: 4133 q_vals: [-6.914, -inf, -8.182, -5.512, -3.997, -9.303, -7.919]
Step 2424 4 visits [1.0, 1000.0, 1.0, 13.0, 931.0, 1.0, 1.0]  episode_count: 4134 q_vals: [-6.914, -inf, -8.182, -5.512, -3.993, -9.303, -7.919]
Step 2425 4 visits [1.0, 1000.0, 1.0, 13.0, 932.0, 1.0, 1.0]  episode_count: 4134 q_vals: [-6.914, -inf, -8.182, -5.512, -3.988, -9.303, -7.919]
Step 2426 4 visits [1.0, 1000.0, 1.0, 13.0, 933.0, 1.0, 1.0]  episode_count: 4136 q_vals: [-6.914, -inf, -8.182, -5.512, -3.988, -9.303, -7.919]
Step 2427 4 visits [1.0, 1000.0, 1.0, 13.0, 934.0, 1.0, 1.0]  episode_count: 4138 q_vals: [-6.914, -inf, -8.182, -5.512, -3.989, -9.303, -7.919]
Step 2428 4 visits [1.0, 1000.0, 1.0, 13.0, 935.0, 1.0, 1.0]  episode_count: 4139 q_vals: [-6.914, -inf, -8.182, -5.512, -3.997, -9.303, -7.919]
Step 2429 4 visits [1.0, 1000.0, 1.0, 13.0, 936.0, 1.0, 1.0]  episode_count: 4141 q_vals: [-6.914, -inf, -8.182, -5.512, -3.996, -9.303, -7.919]
{"total_number_of_episodes": 4142, "number_of_timesteps": 76600, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2430 4 visits [1.0, 1000.0, 1.0, 13.0, 937.0, 1.0, 1.0]  episode_count: 4142 q_vals: [-6.914, -inf, -8.182, -5.512, -3.996, -9.303, -7.919]
Step 2431 4 visits [1.0, 1000.0, 1.0, 13.0, 938.0, 1.0, 1.0]  episode_count: 4144 q_vals: [-6.914, -inf, -8.182, -5.512, -3.996, -9.303, -7.919]
Step 2432 4 visits [1.0, 1000.0, 1.0, 13.0, 939.0, 1.0, 1.0]  episode_count: 4145 q_vals: [-6.914, -inf, -8.182, -5.512, -3.992, -9.303, -7.919]
Step 2433 4 visits [1.0, 1000.0, 1.0, 13.0, 940.0, 1.0, 1.0]  episode_count: 4146 q_vals: [-6.914, -inf, -8.182, -5.512, -4.001, -9.303, -7.919]
Step 2434 4 visits [1.0, 1000.0, 1.0, 13.0, 941.0, 1.0, 1.0]  episode_count: 4149 q_vals: [-6.914, -inf, -8.182, -5.512, -4.001, -9.303, -7.919]
Step 2435 4 visits [1.0, 1000.0, 1.0, 13.0, 942.0, 1.0, 1.0]  episode_count: 4150 q_vals: [-6.914, -inf, -8.182, -5.512, -4.001, -9.303, -7.919]
Step 2436 4 visits [1.0, 1000.0, 1.0, 13.0, 943.0, 1.0, 1.0]  episode_count: 4151 q_vals: [-6.914, -inf, -8.182, -5.512, -3.996, -9.303, -7.919]
{"total_number_of_episodes": 4154, "number_of_timesteps": 76827, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2437 4 visits [1.0, 1000.0, 1.0, 13.0, 944.0, 1.0, 1.0]  episode_count: 4154 q_vals: [-6.914, -inf, -8.182, -5.512, -3.996, -9.303, -7.919]
Step 2438 4 visits [1.0, 1000.0, 1.0, 13.0, 945.0, 1.0, 1.0]  episode_count: 4155 q_vals: [-6.914, -inf, -8.182, -5.512, -3.992, -9.303, -7.919]
Step 2439 4 visits [1.0, 1000.0, 1.0, 13.0, 946.0, 1.0, 1.0]  episode_count: 4156 q_vals: [-6.914, -inf, -8.182, -5.512, -3.99, -9.303, -7.919]
Step 2440 4 visits [1.0, 1000.0, 1.0, 13.0, 947.0, 1.0, 1.0]  episode_count: 4159 q_vals: [-6.914, -inf, -8.182, -5.512, -3.99, -9.303, -7.919]
Step 2441 4 visits [1.0, 1000.0, 1.0, 13.0, 948.0, 1.0, 1.0]  episode_count: 4160 q_vals: [-6.914, -inf, -8.182, -5.512, -3.991, -9.303, -7.919]
Step 2442 4 visits [1.0, 1000.0, 1.0, 13.0, 949.0, 1.0, 1.0]  episode_count: 4161 q_vals: [-6.914, -inf, -8.182, -5.512, -4.0, -9.303, -7.919]
Step 2443 4 visits [1.0, 1000.0, 1.0, 13.0, 950.0, 1.0, 1.0]  episode_count: 4161 q_vals: [-6.914, -inf, -8.182, -5.512, -4.0, -9.303, -7.919]
{"total_number_of_episodes": 4164, "number_of_timesteps": 77009, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2444 4 visits [1.0, 1000.0, 1.0, 13.0, 951.0, 1.0, 1.0]  episode_count: 4164 q_vals: [-6.914, -inf, -8.182, -5.512, -4.001, -9.303, -7.919]
Step 2445 4 visits [1.0, 1000.0, 1.0, 13.0, 952.0, 1.0, 1.0]  episode_count: 4165 q_vals: [-6.914, -inf, -8.182, -5.512, -4.01, -9.303, -7.919]
Step 2446 4 visits [1.0, 1000.0, 1.0, 13.0, 953.0, 1.0, 1.0]  episode_count: 4169 q_vals: [-6.914, -inf, -8.182, -5.512, -4.01, -9.303, -7.919]
Step 2447 4 visits [1.0, 1000.0, 1.0, 13.0, 954.0, 1.0, 1.0]  episode_count: 4169 q_vals: [-6.914, -inf, -8.182, -5.512, -4.011, -9.303, -7.919]
Step 2448 4 visits [1.0, 1000.0, 1.0, 13.0, 955.0, 1.0, 1.0]  episode_count: 4170 q_vals: [-6.914, -inf, -8.182, -5.512, -4.006, -9.303, -7.919]
Step 2449 4 visits [1.0, 1000.0, 1.0, 13.0, 956.0, 1.0, 1.0]  episode_count: 4173 q_vals: [-6.914, -inf, -8.182, -5.512, -4.016, -9.303, -7.919]
{"total_number_of_episodes": 4174, "number_of_timesteps": 77202, "per_episode_reward": 13.21, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
Step 2450 4 visits [1.0, 1000.0, 1.0, 13.0, 957.0, 1.0, 1.0]  episode_count: 4174 q_vals: [-6.914, -inf, -8.182, -5.512, -4.015, -9.303, -7.919]
Step 2451 4 visits [1.0, 1000.0, 1.0, 13.0, 958.0, 1.0, 1.0]  episode_count: 4174 q_vals: [-6.914, -inf, -8.182, -5.512, -4.011, -9.303, -7.919]
Step 2452 4 visits [1.0, 1000.0, 1.0, 13.0, 959.0, 1.0, 1.0]  episode_count: 4177 q_vals: [-6.914, -inf, -8.182, -5.512, -4.012, -9.303, -7.919]
Step 2453 4 visits [1.0, 1000.0, 1.0, 13.0, 960.0, 1.0, 1.0]  episode_count: 4179 q_vals: [-6.914, -inf, -8.182, -5.512, -4.012, -9.303, -7.919]
Step 2454 4 visits [1.0, 1000.0, 1.0, 13.0, 961.0, 1.0, 1.0]  episode_count: 4182 q_vals: [-6.914, -inf, -8.182, -5.512, -4.014, -9.303, -7.919]
{"total_number_of_episodes": 4185, "number_of_timesteps": 77429, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2455 4 visits [1.0, 1000.0, 1.0, 13.0, 962.0, 1.0, 1.0]  episode_count: 4185 q_vals: [-6.914, -inf, -8.182, -5.512, -4.013, -9.303, -7.919]
Step 2456 4 visits [1.0, 1000.0, 1.0, 13.0, 963.0, 1.0, 1.0]  episode_count: 4186 q_vals: [-6.914, -inf, -8.182, -5.512, -4.015, -9.303, -7.919]
Step 2457 4 visits [1.0, 1000.0, 1.0, 13.0, 964.0, 1.0, 1.0]  episode_count: 4189 q_vals: [-6.914, -inf, -8.182, -5.512, -4.011, -9.303, -7.919]
Step 2458 4 visits [1.0, 1000.0, 1.0, 13.0, 965.0, 1.0, 1.0]  episode_count: 4190 q_vals: [-6.914, -inf, -8.182, -5.512, -4.01, -9.303, -7.919]
Step 2459 4 visits [1.0, 1000.0, 1.0, 13.0, 966.0, 1.0, 1.0]  episode_count: 4191 q_vals: [-6.914, -inf, -8.182, -5.512, -4.006, -9.303, -7.919]
Step 2460 4 visits [1.0, 1000.0, 1.0, 13.0, 967.0, 1.0, 1.0]  episode_count: 4193 q_vals: [-6.914, -inf, -8.182, -5.512, -4.006, -9.303, -7.919]
{"total_number_of_episodes": 4195, "number_of_timesteps": 77568, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2461 4 visits [1.0, 1000.0, 1.0, 13.0, 968.0, 1.0, 1.0]  episode_count: 4195 q_vals: [-6.914, -inf, -8.182, -5.512, -4.005, -9.303, -7.919]
Step 2462 4 visits [1.0, 1000.0, 1.0, 13.0, 969.0, 1.0, 1.0]  episode_count: 4196 q_vals: [-6.914, -inf, -8.182, -5.512, -4.004, -9.303, -7.919]
Step 2463 4 visits [1.0, 1000.0, 1.0, 13.0, 970.0, 1.0, 1.0]  episode_count: 4201 q_vals: [-6.914, -inf, -8.182, -5.512, -4.005, -9.303, -7.919]
Step 2464 4 visits [1.0, 1000.0, 1.0, 13.0, 971.0, 1.0, 1.0]  episode_count: 4201 q_vals: [-6.914, -inf, -8.182, -5.512, -4.005, -9.303, -7.919]
Step 2465 4 visits [1.0, 1000.0, 1.0, 13.0, 972.0, 1.0, 1.0]  episode_count: 4202 q_vals: [-6.914, -inf, -8.182, -5.512, -4.005, -9.303, -7.919]
{"total_number_of_episodes": 4205, "number_of_timesteps": 77738, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 2466 4 visits [1.0, 1000.0, 1.0, 13.0, 973.0, 1.0, 1.0]  episode_count: 4205 q_vals: [-6.914, -inf, -8.182, -5.512, -4.004, -9.303, -7.919]
Step 2467 4 visits [1.0, 1000.0, 1.0, 13.0, 974.0, 1.0, 1.0]  episode_count: 4208 q_vals: [-6.914, -inf, -8.182, -5.512, -4.004, -9.303, -7.919]
Step 2468 4 visits [1.0, 1000.0, 1.0, 13.0, 975.0, 1.0, 1.0]  episode_count: 4208 q_vals: [-6.914, -inf, -8.182, -5.512, -4.003, -9.303, -7.919]
Step 2469 4 visits [1.0, 1000.0, 1.0, 13.0, 976.0, 1.0, 1.0]  episode_count: 4211 q_vals: [-6.914, -inf, -8.182, -5.512, -4.003, -9.303, -7.919]
{"total_number_of_episodes": 4215, "number_of_timesteps": 77895, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 2470 4 visits [1.0, 1000.0, 1.0, 13.0, 977.0, 1.0, 1.0]  episode_count: 4215 q_vals: [-6.914, -inf, -8.182, -5.512, -4.003, -9.303, -7.919]
Step 2471 4 visits [1.0, 1000.0, 1.0, 13.0, 978.0, 1.0, 1.0]  episode_count: 4216 q_vals: [-6.914, -inf, -8.182, -5.512, -4.004, -9.303, -7.919]
Step 2472 4 visits [1.0, 1000.0, 1.0, 13.0, 979.0, 1.0, 1.0]  episode_count: 4218 q_vals: [-6.914, -inf, -8.182, -5.512, -4.003, -9.303, -7.919]
Step 2473 4 visits [1.0, 1000.0, 1.0, 13.0, 980.0, 1.0, 1.0]  episode_count: 4220 q_vals: [-6.914, -inf, -8.182, -5.512, -4.003, -9.303, -7.919]
Step 2474 4 visits [1.0, 1000.0, 1.0, 13.0, 981.0, 1.0, 1.0]  episode_count: 4222 q_vals: [-6.914, -inf, -8.182, -5.512, -3.999, -9.303, -7.919]
{"total_number_of_episodes": 4226, "number_of_timesteps": 78045, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 2475 4 visits [1.0, 1000.0, 1.0, 13.0, 982.0, 1.0, 1.0]  episode_count: 4226 q_vals: [-6.914, -inf, -8.182, -5.512, -3.999, -9.303, -7.919]
Step 2476 4 visits [1.0, 1000.0, 1.0, 13.0, 983.0, 1.0, 1.0]  episode_count: 4228 q_vals: [-6.914, -inf, -8.182, -5.512, -3.995, -9.303, -7.919]
Step 2477 4 visits [1.0, 1000.0, 1.0, 13.0, 984.0, 1.0, 1.0]  episode_count: 4231 q_vals: [-6.914, -inf, -8.182, -5.512, -3.994, -9.303, -7.919]
Step 2478 4 visits [1.0, 1000.0, 1.0, 13.0, 985.0, 1.0, 1.0]  episode_count: 4233 q_vals: [-6.914, -inf, -8.182, -5.512, -3.99, -9.303, -7.919]
Step 2479 4 visits [1.0, 1000.0, 1.0, 13.0, 986.0, 1.0, 1.0]  episode_count: 4235 q_vals: [-6.914, -inf, -8.182, -5.512, -3.986, -9.303, -7.919]
{"total_number_of_episodes": 4237, "number_of_timesteps": 78171, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2480 4 visits [1.0, 1000.0, 1.0, 13.0, 987.0, 1.0, 1.0]  episode_count: 4237 q_vals: [-6.914, -inf, -8.182, -5.512, -3.986, -9.303, -7.919]
Step 2481 4 visits [1.0, 1000.0, 1.0, 13.0, 988.0, 1.0, 1.0]  episode_count: 4239 q_vals: [-6.914, -inf, -8.182, -5.512, -3.982, -9.303, -7.919]
Step 2482 4 visits [1.0, 1000.0, 1.0, 13.0, 989.0, 1.0, 1.0]  episode_count: 4241 q_vals: [-6.914, -inf, -8.182, -5.512, -3.982, -9.303, -7.919]
Step 2483 4 visits [1.0, 1000.0, 1.0, 13.0, 990.0, 1.0, 1.0]  episode_count: 4244 q_vals: [-6.914, -inf, -8.182, -5.512, -3.981, -9.303, -7.919]
{"total_number_of_episodes": 4248, "number_of_timesteps": 78320, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2484 4 visits [1.0, 1000.0, 1.0, 13.0, 991.0, 1.0, 1.0]  episode_count: 4248 q_vals: [-6.914, -inf, -8.182, -5.512, -3.977, -9.303, -7.919]
Step 2485 4 visits [1.0, 1000.0, 1.0, 13.0, 992.0, 1.0, 1.0]  episode_count: 4250 q_vals: [-6.914, -inf, -8.182, -5.512, -3.977, -9.303, -7.919]
Step 2486 4 visits [1.0, 1000.0, 1.0, 13.0, 993.0, 1.0, 1.0]  episode_count: 4252 q_vals: [-6.914, -inf, -8.182, -5.512, -3.977, -9.303, -7.919]
Step 2487 4 visits [1.0, 1000.0, 1.0, 13.0, 994.0, 1.0, 1.0]  episode_count: 4255 q_vals: [-6.914, -inf, -8.182, -5.512, -3.973, -9.303, -7.919]
Step 2488 4 visits [1.0, 1000.0, 1.0, 13.0, 995.0, 1.0, 1.0]  episode_count: 4255 q_vals: [-6.914, -inf, -8.182, -5.512, -3.973, -9.303, -7.919]
{"total_number_of_episodes": 4259, "number_of_timesteps": 78449, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2489 4 visits [1.0, 1000.0, 1.0, 13.0, 996.0, 1.0, 1.0]  episode_count: 4259 q_vals: [-6.914, -inf, -8.182, -5.512, -3.974, -9.303, -7.919]
Step 2490 4 visits [1.0, 1000.0, 1.0, 13.0, 997.0, 1.0, 1.0]  episode_count: 4261 q_vals: [-6.914, -inf, -8.182, -5.512, -3.97, -9.303, -7.919]
Step 2491 4 visits [1.0, 1000.0, 1.0, 13.0, 998.0, 1.0, 1.0]  episode_count: 4264 q_vals: [-6.914, -inf, -8.182, -5.512, -3.97, -9.303, -7.919]
Step 2492 4 visits [1.0, 1000.0, 1.0, 13.0, 999.0, 1.0, 1.0]  episode_count: 4264 q_vals: [-6.914, -inf, -8.182, -5.512, -3.979, -9.303, -7.919]
Step 2493 4 visits [0.0, 1000.0, 0.0, 0.0, 1000.0, 0.0, 0.0]  episode_count: 4265 q_vals: [0.0, -inf, 0.0, 0.0, -inf, 0.0, 0.0]
{"total_number_of_episodes": 4269, "number_of_timesteps": 78602, "per_episode_reward": 10.86, "episode_reward_trend_value": -0.026190476190476174, "biggest_recent_change": 2.1428571428571423},
Step 2494 0 visits [1.0, 1000.0, 0.0, 0.0, 1000.0, 0.0, 0.0]  episode_count: 4269 q_vals: [0.0, -inf, 0.0, 0.0, -inf, 0.0, 0.0]
Step 2495 2 visits [1.0, 1000.0, 1.0, 0.0, 1000.0, 0.0, 0.0]  episode_count: 4270 q_vals: [0.0, -inf, 0.0, 0.0, -inf, 0.0, 0.0]
Step 2496 3 visits [1.0, 1000.0, 1.0, 1.0, 1000.0, 0.0, 0.0]  episode_count: 4270 q_vals: [0.0, -inf, 0.0, -5.11, -inf, 0.0, 0.0]
Step 2497 5 visits [1.0, 1000.0, 1.0, 1.0, 1000.0, 1.0, 0.0]  episode_count: 4273 q_vals: [0.0, -inf, 0.0, -5.11, -inf, -4.495, 0.0]
Step 2498 6 visits [1.0, 1000.0, 1.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4274 q_vals: [0.0, -inf, 0.0, -5.11, -inf, -4.495, -15.0]
Step 2499 0 visits [2.0, 1000.0, 1.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4276 q_vals: [0.0, -inf, 0.0, -5.11, -inf, -4.495, -15.0]
Step 2500 2 visits [2.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4276 q_vals: [0.0, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
Step 2501 0 visits [3.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4278 q_vals: [0.0, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
{"total_number_of_episodes": 4281, "number_of_timesteps": 78862, "per_episode_reward": 10.86, "episode_reward_trend_value": -0.025396825396825383, "biggest_recent_change": 2.1428571428571423},
Step 2502 0 visits [4.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4281 q_vals: [-1.286, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
Step 2503 0 visits [5.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4282 q_vals: [-1.029, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
Step 2504 0 visits [6.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4283 q_vals: [-1.57, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
Step 2505 0 visits [7.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4287 q_vals: [-1.346, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
Step 2506 0 visits [8.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4287 q_vals: [-1.177, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
Step 2507 0 visits [9.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4289 q_vals: [-1.601, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
{"total_number_of_episodes": 4291, "number_of_timesteps": 79049, "per_episode_reward": 10.86, "episode_reward_trend_value": -0.025396825396825383, "biggest_recent_change": 2.1428571428571423},
Step 2508 0 visits [10.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4291 q_vals: [-1.441, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
Step 2509 0 visits [11.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4291 q_vals: [-2.673, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
Step 2510 0 visits [12.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4295 q_vals: [-2.863, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
Step 2511 0 visits [13.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4297 q_vals: [-2.976, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
Step 2512 0 visits [14.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4298 q_vals: [-2.763, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
{"total_number_of_episodes": 4301, "number_of_timesteps": 79213, "per_episode_reward": 10.86, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
Step 2513 0 visits [15.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4301 q_vals: [-2.893, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
Step 2514 0 visits [16.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4303 q_vals: [-2.993, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
Step 2515 0 visits [17.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4305 q_vals: [-3.109, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
Step 2516 0 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 4307 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -4.495, -15.0]
Step 2517 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 2.0, 1.0]  episode_count: 4309 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -2.248, -15.0]
{"total_number_of_episodes": 4312, "number_of_timesteps": 79386, "per_episode_reward": 10.86, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
Step 2518 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 3.0, 1.0]  episode_count: 4312 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -3.112, -15.0]
Step 2519 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 4.0, 1.0]  episode_count: 4312 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -2.334, -15.0]
Step 2520 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 5.0, 1.0]  episode_count: 4317 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -1.867, -15.0]
Step 2521 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 6.0, 1.0]  episode_count: 4319 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -1.556, -15.0]
Step 2522 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 7.0, 1.0]  episode_count: 4321 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -1.334, -15.0]
{"total_number_of_episodes": 4324, "number_of_timesteps": 79532, "per_episode_reward": 10.86, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
Step 2523 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 8.0, 1.0]  episode_count: 4324 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -1.167, -15.0]
Step 2524 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 9.0, 1.0]  episode_count: 4327 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -1.037, -15.0]
Step 2525 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 10.0, 1.0]  episode_count: 4329 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -1.38, -15.0]
Step 2526 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 11.0, 1.0]  episode_count: 4331 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -1.254, -15.0]
{"total_number_of_episodes": 4334, "number_of_timesteps": 79635, "per_episode_reward": 10.86, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
Step 2527 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 12.0, 1.0]  episode_count: 4334 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -1.552, -15.0]
Step 2528 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 13.0, 1.0]  episode_count: 4338 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -1.812, -15.0]
Step 2529 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 14.0, 1.0]  episode_count: 4340 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -2.754, -15.0]
Step 2530 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 15.0, 1.0]  episode_count: 4343 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -2.57, -15.0]
{"total_number_of_episodes": 4344, "number_of_timesteps": 79756, "per_episode_reward": 10.86, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
Step 2531 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 16.0, 1.0]  episode_count: 4344 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -2.409, -15.0]
Step 2532 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 17.0, 1.0]  episode_count: 4347 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -2.577, -15.0]
Step 2533 5 visits [18.0, 1000.0, 2.0, 1.0, 1000.0, 18.0, 1.0]  episode_count: 4349 q_vals: [-3.172, -inf, -7.5, -5.11, -inf, -3.268, -15.0]
Step 2534 0 visits [19.0, 1000.0, 2.0, 1.0, 1000.0, 18.0, 1.0]  episode_count: 4351 q_vals: [-3.276, -inf, -7.5, -5.11, -inf, -3.268, -15.0]
Step 2535 5 visits [19.0, 1000.0, 2.0, 1.0, 1000.0, 19.0, 1.0]  episode_count: 4353 q_vals: [-3.276, -inf, -7.5, -5.11, -inf, -3.335, -15.0]
{"total_number_of_episodes": 4356, "number_of_timesteps": 79920, "per_episode_reward": 10.86, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
Step 2536 0 visits [20.0, 1000.0, 2.0, 1.0, 1000.0, 19.0, 1.0]  episode_count: 4356 q_vals: [-3.366, -inf, -7.5, -5.11, -inf, -3.335, -15.0]
Step 2537 5 visits [20.0, 1000.0, 2.0, 1.0, 1000.0, 20.0, 1.0]  episode_count: 4358 q_vals: [-3.366, -inf, -7.5, -5.11, -inf, -3.415, -15.0]
Step 2538 0 visits [21.0, 1000.0, 2.0, 1.0, 1000.0, 20.0, 1.0]  episode_count: 4360 q_vals: [-3.206, -inf, -7.5, -5.11, -inf, -3.415, -15.0]
Step 2539 0 visits [22.0, 1000.0, 2.0, 1.0, 1000.0, 20.0, 1.0]  episode_count: 4363 q_vals: [-3.742, -inf, -7.5, -5.11, -inf, -3.415, -15.0]
Step 2540 5 visits [22.0, 1000.0, 2.0, 1.0, 1000.0, 21.0, 1.0]  episode_count: 4365 q_vals: [-3.742, -inf, -7.5, -5.11, -inf, -3.47, -15.0]
{"total_number_of_episodes": 4368, "number_of_timesteps": 80047, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2541 5 visits [22.0, 1000.0, 2.0, 1.0, 1000.0, 22.0, 1.0]  episode_count: 4368 q_vals: [-3.742, -inf, -7.5, -5.11, -inf, -3.313, -15.0]
Step 2542 5 visits [22.0, 1000.0, 2.0, 1.0, 1000.0, 23.0, 1.0]  episode_count: 4368 q_vals: [-3.742, -inf, -7.5, -5.11, -inf, -3.821, -15.0]
Step 2543 3 visits [22.0, 1000.0, 2.0, 2.0, 1000.0, 23.0, 1.0]  episode_count: 4372 q_vals: [-3.742, -inf, -7.5, -2.555, -inf, -3.821, -15.0]
Step 2544 3 visits [22.0, 1000.0, 2.0, 3.0, 1000.0, 23.0, 1.0]  episode_count: 4375 q_vals: [-3.742, -inf, -7.5, -3.432, -inf, -3.821, -15.0]
{"total_number_of_episodes": 4378, "number_of_timesteps": 80201, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2545 3 visits [22.0, 1000.0, 2.0, 4.0, 1000.0, 23.0, 1.0]  episode_count: 4378 q_vals: [-3.742, -inf, -7.5, -6.324, -inf, -3.821, -15.0]
Step 2546 0 visits [23.0, 1000.0, 2.0, 4.0, 1000.0, 23.0, 1.0]  episode_count: 4381 q_vals: [-3.838, -inf, -7.5, -6.324, -inf, -3.821, -15.0]
Step 2547 5 visits [23.0, 1000.0, 2.0, 4.0, 1000.0, 24.0, 1.0]  episode_count: 4384 q_vals: [-3.838, -inf, -7.5, -6.324, -inf, -3.662, -15.0]
Step 2548 5 visits [23.0, 1000.0, 2.0, 4.0, 1000.0, 25.0, 1.0]  episode_count: 4385 q_vals: [-3.838, -inf, -7.5, -6.324, -inf, -3.515, -15.0]
Step 2549 5 visits [23.0, 1000.0, 2.0, 4.0, 1000.0, 26.0, 1.0]  episode_count: 4387 q_vals: [-3.838, -inf, -7.5, -6.324, -inf, -3.957, -15.0]
{"total_number_of_episodes": 4389, "number_of_timesteps": 80328, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2550 0 visits [24.0, 1000.0, 2.0, 4.0, 1000.0, 26.0, 1.0]  episode_count: 4389 q_vals: [-3.865, -inf, -7.5, -6.324, -inf, -3.957, -15.0]
Step 2551 0 visits [25.0, 1000.0, 2.0, 4.0, 1000.0, 26.0, 1.0]  episode_count: 4392 q_vals: [-3.71, -inf, -7.5, -6.324, -inf, -3.957, -15.0]
Step 2552 0 visits [26.0, 1000.0, 2.0, 4.0, 1000.0, 26.0, 1.0]  episode_count: 4394 q_vals: [-3.798, -inf, -7.5, -6.324, -inf, -3.957, -15.0]
Step 2553 0 visits [27.0, 1000.0, 2.0, 4.0, 1000.0, 26.0, 1.0]  episode_count: 4396 q_vals: [-3.657, -inf, -7.5, -6.324, -inf, -3.957, -15.0]
{"total_number_of_episodes": 4400, "number_of_timesteps": 80477, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2554 0 visits [28.0, 1000.0, 2.0, 4.0, 1000.0, 26.0, 1.0]  episode_count: 4400 q_vals: [-3.526, -inf, -7.5, -6.324, -inf, -3.957, -15.0]
Step 2555 0 visits [29.0, 1000.0, 2.0, 4.0, 1000.0, 26.0, 1.0]  episode_count: 4401 q_vals: [-3.922, -inf, -7.5, -6.324, -inf, -3.957, -15.0]
Step 2556 0 visits [30.0, 1000.0, 2.0, 4.0, 1000.0, 26.0, 1.0]  episode_count: 4403 q_vals: [-3.791, -inf, -7.5, -6.324, -inf, -3.957, -15.0]
Step 2557 0 visits [31.0, 1000.0, 2.0, 4.0, 1000.0, 26.0, 1.0]  episode_count: 4407 q_vals: [-3.669, -inf, -7.5, -6.324, -inf, -3.957, -15.0]
Step 2558 0 visits [32.0, 1000.0, 2.0, 4.0, 1000.0, 26.0, 1.0]  episode_count: 4408 q_vals: [-3.791, -inf, -7.5, -6.324, -inf, -3.957, -15.0]
Step 2559 0 visits [33.0, 1000.0, 2.0, 4.0, 1000.0, 26.0, 1.0]  episode_count: 4409 q_vals: [-3.9, -inf, -7.5, -6.324, -inf, -3.957, -15.0]
{"total_number_of_episodes": 4411, "number_of_timesteps": 80630, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2560 0 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 26.0, 1.0]  episode_count: 4411 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.957, -15.0]
Step 2561 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 27.0, 1.0]  episode_count: 4412 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.81, -15.0]
Step 2562 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 28.0, 1.0]  episode_count: 4413 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.674, -15.0]
Step 2563 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 29.0, 1.0]  episode_count: 4416 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.74, -15.0]
Step 2564 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 30.0, 1.0]  episode_count: 4417 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.792, -15.0]
Step 2565 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 31.0, 1.0]  episode_count: 4417 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.67, -15.0]
Step 2566 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 32.0, 1.0]  episode_count: 4419 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.786, -15.0]
Step 2567 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 33.0, 1.0]  episode_count: 4420 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.819, -15.0]
{"total_number_of_episodes": 4421, "number_of_timesteps": 80841, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2568 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 34.0, 1.0]  episode_count: 4421 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.707, -15.0]
Step 2569 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 35.0, 1.0]  episode_count: 4423 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.601, -15.0]
Step 2570 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 36.0, 1.0]  episode_count: 4424 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.625, -15.0]
Step 2571 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 37.0, 1.0]  episode_count: 4426 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.527, -15.0]
Step 2572 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 38.0, 1.0]  episode_count: 4426 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.559, -15.0]
Step 2573 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 39.0, 1.0]  episode_count: 4426 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.468, -15.0]
Step 2574 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 40.0, 1.0]  episode_count: 4430 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.381, -15.0]
Step 2575 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 41.0, 1.0]  episode_count: 4430 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.299, -15.0]
{"total_number_of_episodes": 4431, "number_of_timesteps": 81089, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2576 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 42.0, 1.0]  episode_count: 4431 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.382, -15.0]
[-3.955, -inf, -7.5, -6.324, -inf, -3.303, -15.0]
Step 2578 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 44.0, 1.0]  episode_count: 4437 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.358, -15.0]
Step 2579 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 45.0, 1.0]  episode_count: 4437 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.413, -15.0]
Step 2580 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 46.0, 1.0]  episode_count: 4438 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.339, -15.0]
{"total_number_of_episodes": 4442, "number_of_timesteps": 81335, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2581 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 47.0, 1.0]  episode_count: 4442 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.404, -15.0]
Step 2582 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 48.0, 1.0]  episode_count: 4442 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.333, -15.0]
Step 2583 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 49.0, 1.0]  episode_count: 4446 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.359, -15.0]
Step 2584 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 50.0, 1.0]  episode_count: 4448 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.392, -15.0]
Step 2585 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 51.0, 1.0]  episode_count: 4449 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.62, -15.0]
{"total_number_of_episodes": 4452, "number_of_timesteps": 81479, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2586 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 52.0, 1.0]  episode_count: 4452 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.642, -15.0]
Step 2587 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 53.0, 1.0]  episode_count: 4452 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.574, -15.0]
Step 2588 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 54.0, 1.0]  episode_count: 4454 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.785, -15.0]
Step 2589 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 55.0, 1.0]  episode_count: 4459 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.813, -15.0]
Step 2590 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 56.0, 1.0]  episode_count: 4459 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.745, -15.0]
Step 2591 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 57.0, 1.0]  episode_count: 4461 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.679, -15.0]
{"total_number_of_episodes": 4465, "number_of_timesteps": 81674, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2592 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 58.0, 1.0]  episode_count: 4465 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.616, -15.0]
Step 2593 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 59.0, 1.0]  episode_count: 4467 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.648, -15.0]
Step 2594 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 60.0, 1.0]  episode_count: 4468 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.678, -15.0]
Step 2595 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 61.0, 1.0]  episode_count: 4472 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.713, -15.0]
Step 2596 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 62.0, 1.0]  episode_count: 4472 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.654, -15.0]
{"total_number_of_episodes": 4476, "number_of_timesteps": 81825, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2597 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 63.0, 1.0]  episode_count: 4476 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.674, -15.0]
Step 2598 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 64.0, 1.0]  episode_count: 4476 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.851, -15.0]
Step 2599 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 65.0, 1.0]  episode_count: 4480 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.792, -15.0]
Step 2600 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 66.0, 1.0]  episode_count: 4482 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.806, -15.0]
Step 2601 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 67.0, 1.0]  episode_count: 4483 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.749, -15.0]
{"total_number_of_episodes": 4487, "number_of_timesteps": 81989, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2602 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 68.0, 1.0]  episode_count: 4487 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.694, -15.0]
Step 2603 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 69.0, 1.0]  episode_count: 4489 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.641, -15.0]
Step 2604 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 70.0, 1.0]  episode_count: 4492 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.672, -15.0]
Step 2605 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 71.0, 1.0]  episode_count: 4495 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.62, -15.0]
Step 2606 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 72.0, 1.0]  episode_count: 4495 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.57, -15.0]
Step 2607 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 73.0, 1.0]  episode_count: 4496 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.591, -15.0]
{"total_number_of_episodes": 4501, "number_of_timesteps": 82169, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2608 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 74.0, 1.0]  episode_count: 4501 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.606, -15.0]
Step 2609 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 75.0, 1.0]  episode_count: 4501 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.558, -15.0]
Step 2610 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 76.0, 1.0]  episode_count: 4502 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.709, -15.0]
Step 2611 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 77.0, 1.0]  episode_count: 4505 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.75, -15.0]
Step 2612 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 78.0, 1.0]  episode_count: 4508 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.77, -15.0]
Step 2613 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 79.0, 1.0]  episode_count: 4508 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.793, -15.0]
Step 2614 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 80.0, 1.0]  episode_count: 4509 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.745, -15.0]
{"total_number_of_episodes": 4511, "number_of_timesteps": 82329, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2615 5 visits [34.0, 1000.0, 2.0, 4.0, 1000.0, 81.0, 1.0]  episode_count: 4511 q_vals: [-3.955, -inf, -7.5, -6.324, -inf, -3.884, -15.0]
Step 2616 0 visits [35.0, 1000.0, 2.0, 4.0, 1000.0, 81.0, 1.0]  episode_count: 4514 q_vals: [-4.097, -inf, -7.5, -6.324, -inf, -3.884, -15.0]
Step 2617 5 visits [35.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4516 q_vals: [-4.097, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2618 0 visits [36.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4519 q_vals: [-3.983, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
{"total_number_of_episodes": 4521, "number_of_timesteps": 82484, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2619 0 visits [37.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4521 q_vals: [-4.029, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2620 0 visits [38.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4522 q_vals: [-3.923, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2621 0 visits [39.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4523 q_vals: [-3.822, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2622 0 visits [40.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4527 q_vals: [-3.846, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2623 0 visits [41.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4528 q_vals: [-3.875, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2624 0 visits [42.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4529 q_vals: [-3.893, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
{"total_number_of_episodes": 4532, "number_of_timesteps": 82660, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2625 0 visits [43.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4532 q_vals: [-3.802, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2626 0 visits [44.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4535 q_vals: [-3.716, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2627 0 visits [45.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4536 q_vals: [-3.8, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2628 0 visits [46.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4538 q_vals: [-3.852, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2629 0 visits [47.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4541 q_vals: [-3.77, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
{"total_number_of_episodes": 4542, "number_of_timesteps": 82800, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2630 0 visits [48.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4542 q_vals: [-3.859, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2631 0 visits [49.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4543 q_vals: [-3.879, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2632 0 visits [50.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4545 q_vals: [-3.898, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2633 0 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 82.0, 1.0]  episode_count: 4546 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2634 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 83.0, 1.0]  episode_count: 4548 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.971, -15.0]
Step 2635 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 84.0, 1.0]  episode_count: 4550 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.977, -15.0]
{"total_number_of_episodes": 4553, "number_of_timesteps": 83001, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2636 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 85.0, 1.0]  episode_count: 4553 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.93, -15.0]
Step 2637 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 86.0, 1.0]  episode_count: 4554 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.884, -15.0]
Step 2638 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 87.0, 1.0]  episode_count: 4554 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -4.012, -15.0]
Step 2639 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 88.0, 1.0]  episode_count: 4557 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -4.039, -15.0]
Step 2640 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 89.0, 1.0]  episode_count: 4560 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.994, -15.0]
Step 2641 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 90.0, 1.0]  episode_count: 4560 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -4.0, -15.0]
Step 2642 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 91.0, 1.0]  episode_count: 4560 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.956, -15.0]
{"total_number_of_episodes": 4564, "number_of_timesteps": 83207, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2643 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 92.0, 1.0]  episode_count: 4564 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.964, -15.0]
Step 2644 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 93.0, 1.0]  episode_count: 4565 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.966, -15.0]
Step 2645 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 94.0, 1.0]  episode_count: 4566 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.924, -15.0]
Step 2646 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 95.0, 1.0]  episode_count: 4568 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.883, -15.0]
Step 2647 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 96.0, 1.0]  episode_count: 4570 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.897, -15.0]
Step 2648 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 97.0, 1.0]  episode_count: 4571 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.857, -15.0]
Step 2649 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 98.0, 1.0]  episode_count: 4573 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.865, -15.0]
{"total_number_of_episodes": 4576, "number_of_timesteps": 83413, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2650 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 99.0, 1.0]  episode_count: 4576 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.977, -15.0]
Step 2651 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 100.0, 1.0]  episode_count: 4577 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.937, -15.0]
Step 2652 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 101.0, 1.0]  episode_count: 4579 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.964, -15.0]
Step 2653 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 102.0, 1.0]  episode_count: 4580 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.977, -15.0]
Step 2654 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 103.0, 1.0]  episode_count: 4584 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.938, -15.0]
{"total_number_of_episodes": 4586, "number_of_timesteps": 83618, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2655 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 104.0, 1.0]  episode_count: 4586 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.946, -15.0]
Step 2656 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 105.0, 1.0]  episode_count: 4586 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.909, -15.0]
Step 2657 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 106.0, 1.0]  episode_count: 4590 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.917, -15.0]
Step 2658 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 107.0, 1.0]  episode_count: 4592 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.88, -15.0]
Step 2659 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 108.0, 1.0]  episode_count: 4593 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.904, -15.0]
{"total_number_of_episodes": 4596, "number_of_timesteps": 83758, "per_episode_reward": 10.79, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2660 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 109.0, 1.0]  episode_count: 4596 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.919, -15.0]
Step 2661 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 110.0, 1.0]  episode_count: 4598 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.962, -15.0]
Step 2662 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 111.0, 1.0]  episode_count: 4601 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.926, -15.0]
Step 2663 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 112.0, 1.0]  episode_count: 4602 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.891, -15.0]
Step 2664 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 113.0, 1.0]  episode_count: 4602 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.857, -15.0]
Step 2665 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 114.0, 1.0]  episode_count: 4605 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.864, -15.0]
{"total_number_of_episodes": 4608, "number_of_timesteps": 83945, "per_episode_reward": 10.79, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2666 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 115.0, 1.0]  episode_count: 4608 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.96, -15.0]
Step 2667 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 116.0, 1.0]  episode_count: 4610 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.983, -15.0]
Step 2668 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 117.0, 1.0]  episode_count: 4611 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.997, -15.0]
Step 2669 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 118.0, 1.0]  episode_count: 4612 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.963, -15.0]
Step 2670 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 119.0, 1.0]  episode_count: 4616 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.93, -15.0]
Step 2671 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 120.0, 1.0]  episode_count: 4617 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.897, -15.0]
{"total_number_of_episodes": 4620, "number_of_timesteps": 84140, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2672 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 121.0, 1.0]  episode_count: 4620 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.904, -15.0]
Step 2673 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 122.0, 1.0]  episode_count: 4623 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -3.916, -15.0]
Step 2674 5 visits [51.0, 1000.0, 2.0, 4.0, 1000.0, 123.0, 1.0]  episode_count: 4624 q_vals: [-4.116, -inf, -7.5, -6.324, -inf, -4.006, -15.0]
Step 2675 0 visits [52.0, 1000.0, 2.0, 4.0, 1000.0, 123.0, 1.0]  episode_count: 4627 q_vals: [-4.037, -inf, -7.5, -6.324, -inf, -4.006, -15.0]
Step 2676 0 visits [53.0, 1000.0, 2.0, 4.0, 1000.0, 123.0, 1.0]  episode_count: 4628 q_vals: [-4.076, -inf, -7.5, -6.324, -inf, -4.006, -15.0]
Step 2677 0 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 123.0, 1.0]  episode_count: 4629 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.006, -15.0]
{"total_number_of_episodes": 4632, "number_of_timesteps": 84308, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 2678 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 124.0, 1.0]  episode_count: 4632 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.02, -15.0]
Step 2679 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 125.0, 1.0]  episode_count: 4632 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.057, -15.0]
Step 2680 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 126.0, 1.0]  episode_count: 4636 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.025, -15.0]
Step 2681 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 127.0, 1.0]  episode_count: 4638 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.993, -15.0]
Step 2682 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 128.0, 1.0]  episode_count: 4639 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.962, -15.0]
{"total_number_of_episodes": 4644, "number_of_timesteps": 84500, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 2683 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 129.0, 1.0]  episode_count: 4644 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.968, -15.0]
Step 2684 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 130.0, 1.0]  episode_count: 4644 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.973, -15.0]
Step 2685 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 131.0, 1.0]  episode_count: 4646 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.978, -15.0]
Step 2686 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 132.0, 1.0]  episode_count: 4648 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.948, -15.0]
Step 2687 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 133.0, 1.0]  episode_count: 4649 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.918, -15.0]
Step 2688 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 134.0, 1.0]  episode_count: 4653 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.889, -15.0]
Step 2689 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 135.0, 1.0]  episode_count: 4653 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.86, -15.0]
{"total_number_of_episodes": 4654, "number_of_timesteps": 84657, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 2690 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 136.0, 1.0]  episode_count: 4654 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.866, -15.0]
Step 2691 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 137.0, 1.0]  episode_count: 4659 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.837, -15.0]
Step 2692 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 138.0, 1.0]  episode_count: 4660 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.81, -15.0]
Step 2693 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 139.0, 1.0]  episode_count: 4660 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.82, -15.0]
{"total_number_of_episodes": 4664, "number_of_timesteps": 84802, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 2694 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 140.0, 1.0]  episode_count: 4664 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.832, -15.0]
Step 2695 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 141.0, 1.0]  episode_count: 4665 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.838, -15.0]
Step 2696 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 142.0, 1.0]  episode_count: 4665 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.917, -15.0]
Step 2697 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 143.0, 1.0]  episode_count: 4670 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.93, -15.0]
Step 2698 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 144.0, 1.0]  episode_count: 4671 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.937, -15.0]
Step 2699 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 145.0, 1.0]  episode_count: 4671 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.91, -15.0]
Step 2700 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 146.0, 1.0]  episode_count: 4673 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.883, -15.0]
{"total_number_of_episodes": 4676, "number_of_timesteps": 85026, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 2701 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 147.0, 1.0]  episode_count: 4676 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.857, -15.0]
Step 2702 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 148.0, 1.0]  episode_count: 4678 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.831, -15.0]
Step 2703 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 149.0, 1.0]  episode_count: 4679 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.805, -15.0]
Step 2704 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 150.0, 1.0]  episode_count: 4681 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.78, -15.0]
Step 2705 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 151.0, 1.0]  episode_count: 4685 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.755, -15.0]
Step 2706 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 152.0, 1.0]  episode_count: 4685 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.829, -15.0]
{"total_number_of_episodes": 4688, "number_of_timesteps": 85217, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 2707 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 153.0, 1.0]  episode_count: 4688 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.804, -15.0]
Step 2708 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 154.0, 1.0]  episode_count: 4690 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.811, -15.0]
Step 2709 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 155.0, 1.0]  episode_count: 4692 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.822, -15.0]
Step 2710 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 156.0, 1.0]  episode_count: 4695 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.832, -15.0]
Step 2711 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 157.0, 1.0]  episode_count: 4696 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.842, -15.0]
{"total_number_of_episodes": 4700, "number_of_timesteps": 85382, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
Step 2712 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 158.0, 1.0]  episode_count: 4700 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.847, -15.0]
Step 2713 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 159.0, 1.0]  episode_count: 4701 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.823, -15.0]
Step 2714 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 160.0, 1.0]  episode_count: 4704 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.893, -15.0]
Step 2715 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 161.0, 1.0]  episode_count: 4708 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.921, -15.0]
Step 2716 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 162.0, 1.0]  episode_count: 4709 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.897, -15.0]
{"total_number_of_episodes": 4711, "number_of_timesteps": 85518, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
Step 2717 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 163.0, 1.0]  episode_count: 4711 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.873, -15.0]
Step 2718 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 164.0, 1.0]  episode_count: 4713 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.849, -15.0]
Step 2719 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 165.0, 1.0]  episode_count: 4715 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.826, -15.0]
Step 2720 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 166.0, 1.0]  episode_count: 4719 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.833, -15.0]
Step 2721 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 167.0, 1.0]  episode_count: 4720 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.844, -15.0]
{"total_number_of_episodes": 4722, "number_of_timesteps": 85662, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 2722 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 168.0, 1.0]  episode_count: 4722 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.865, -15.0]
Step 2723 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 169.0, 1.0]  episode_count: 4724 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.842, -15.0]
Step 2724 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 170.0, 1.0]  episode_count: 4725 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.82, -15.0]
Step 2725 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 171.0, 1.0]  episode_count: 4726 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.833, -15.0]
Step 2726 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 172.0, 1.0]  episode_count: 4727 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.811, -15.0]
Step 2727 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 173.0, 1.0]  episode_count: 4730 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.805, -15.0]
{"total_number_of_episodes": 4732, "number_of_timesteps": 85844, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2728 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 174.0, 1.0]  episode_count: 4732 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.812, -15.0]
Step 2729 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 175.0, 1.0]  episode_count: 4732 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.803, -15.0]
Step 2730 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 176.0, 1.0]  episode_count: 4735 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.782, -15.0]
Step 2731 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 177.0, 1.0]  episode_count: 4737 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.788, -15.0]
Step 2732 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 178.0, 1.0]  episode_count: 4737 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.797, -15.0]
Step 2733 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 179.0, 1.0]  episode_count: 4738 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.808, -15.0]
Step 2734 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 180.0, 1.0]  episode_count: 4739 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.816, -15.0]
Step 2735 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 181.0, 1.0]  episode_count: 4740 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.838, -15.0]
Step 2736 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 182.0, 1.0]  episode_count: 4741 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.851, -15.0]
{"total_number_of_episodes": 4743, "number_of_timesteps": 86105, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2737 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 183.0, 1.0]  episode_count: 4743 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.83, -15.0]
Step 2738 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 184.0, 1.0]  episode_count: 4745 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.809, -15.0]
Step 2739 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 185.0, 1.0]  episode_count: 4745 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.815, -15.0]
Step 2740 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 186.0, 1.0]  episode_count: 4747 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.82, -15.0]
Step 2741 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 187.0, 1.0]  episode_count: 4749 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.824, -15.0]
Step 2742 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 188.0, 1.0]  episode_count: 4751 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.832, -15.0]
{"total_number_of_episodes": 4753, "number_of_timesteps": 86347, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2743 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 189.0, 1.0]  episode_count: 4753 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.845, -15.0]
Step 2744 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 190.0, 1.0]  episode_count: 4754 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.872, -15.0]
Step 2745 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 191.0, 1.0]  episode_count: 4756 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.891, -15.0]
Step 2746 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 192.0, 1.0]  episode_count: 4758 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.871, -15.0]
Step 2747 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 193.0, 1.0]  episode_count: 4759 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.875, -15.0]
Step 2748 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 194.0, 1.0]  episode_count: 4760 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.855, -15.0]
{"total_number_of_episodes": 4763, "number_of_timesteps": 86535, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2749 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 195.0, 1.0]  episode_count: 4763 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.835, -15.0]
Step 2750 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 196.0, 1.0]  episode_count: 4764 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.816, -15.0]
Step 2751 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 197.0, 1.0]  episode_count: 4765 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.82, -15.0]
Step 2752 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 198.0, 1.0]  episode_count: 4767 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.801, -15.0]
Step 2753 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 199.0, 1.0]  episode_count: 4769 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.806, -15.0]
Step 2754 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 200.0, 1.0]  episode_count: 4771 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.821, -15.0]
Step 2755 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 201.0, 1.0]  episode_count: 4771 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.802, -15.0]
{"total_number_of_episodes": 4776, "number_of_timesteps": 86786, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2756 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 202.0, 1.0]  episode_count: 4776 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.806, -15.0]
Step 2757 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 203.0, 1.0]  episode_count: 4777 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.807, -15.0]
Step 2758 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 204.0, 1.0]  episode_count: 4777 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.788, -15.0]
Step 2759 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 205.0, 1.0]  episode_count: 4781 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.77, -15.0]
Step 2760 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 206.0, 1.0]  episode_count: 4782 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.774, -15.0]
Step 2761 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 207.0, 1.0]  episode_count: 4783 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.784, -15.0]
Step 2762 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 208.0, 1.0]  episode_count: 4785 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.837, -15.0]
{"total_number_of_episodes": 4787, "number_of_timesteps": 86973, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2763 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 209.0, 1.0]  episode_count: 4787 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.819, -15.0]
Step 2764 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 210.0, 1.0]  episode_count: 4788 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.826, -15.0]
Step 2765 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 211.0, 1.0]  episode_count: 4789 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.833, -15.0]
Step 2766 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 212.0, 1.0]  episode_count: 4789 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.836, -15.0]
Step 2767 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 213.0, 1.0]  episode_count: 4791 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.841, -15.0]
Step 2768 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 214.0, 1.0]  episode_count: 4791 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.823, -15.0]
Step 2769 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 215.0, 1.0]  episode_count: 4793 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.875, -15.0]
Step 2770 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 216.0, 1.0]  episode_count: 4796 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.878, -15.0]
{"total_number_of_episodes": 4797, "number_of_timesteps": 87190, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2771 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 217.0, 1.0]  episode_count: 4797 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.86, -15.0]
Step 2772 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 218.0, 1.0]  episode_count: 4798 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.869, -15.0]
Step 2773 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 219.0, 1.0]  episode_count: 4799 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.851, -15.0]
Step 2774 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 220.0, 1.0]  episode_count: 4799 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.834, -15.0]
Step 2775 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 221.0, 1.0]  episode_count: 4801 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.844, -15.0]
Step 2776 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 222.0, 1.0]  episode_count: 4802 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.826, -15.0]
Step 2777 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 223.0, 1.0]  episode_count: 4805 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.841, -15.0]
Step 2778 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 224.0, 1.0]  episode_count: 4806 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.824, -15.0]
{"total_number_of_episodes": 4808, "number_of_timesteps": 87466, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2779 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 225.0, 1.0]  episode_count: 4808 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.874, -15.0]
Step 2780 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 226.0, 1.0]  episode_count: 4809 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.879, -15.0]
Step 2781 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 227.0, 1.0]  episode_count: 4812 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.895, -15.0]
Step 2782 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 228.0, 1.0]  episode_count: 4814 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.897, -15.0]
Step 2783 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 229.0, 1.0]  episode_count: 4816 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.9, -15.0]
Step 2784 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 230.0, 1.0]  episode_count: 4817 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.883, -15.0]
{"total_number_of_episodes": 4819, "number_of_timesteps": 87676, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2785 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 231.0, 1.0]  episode_count: 4819 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.885, -15.0]
Step 2786 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 232.0, 1.0]  episode_count: 4821 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.868, -15.0]
Step 2787 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 233.0, 1.0]  episode_count: 4823 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.871, -15.0]
Step 2788 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 234.0, 1.0]  episode_count: 4824 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.855, -15.0]
Step 2789 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 235.0, 1.0]  episode_count: 4828 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.857, -15.0]
{"total_number_of_episodes": 4829, "number_of_timesteps": 87832, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2790 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 236.0, 1.0]  episode_count: 4829 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.858, -15.0]
Step 2791 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 237.0, 1.0]  episode_count: 4830 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.86, -15.0]
Step 2792 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 238.0, 1.0]  episode_count: 4833 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.907, -15.0]
Step 2793 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 239.0, 1.0]  episode_count: 4837 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.891, -15.0]
Step 2794 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 240.0, 1.0]  episode_count: 4837 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.892, -15.0]
{"total_number_of_episodes": 4839, "number_of_timesteps": 87983, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2795 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 241.0, 1.0]  episode_count: 4839 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.9, -15.0]
Step 2796 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 242.0, 1.0]  episode_count: 4844 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.904, -15.0]
Step 2797 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 243.0, 1.0]  episode_count: 4845 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.888, -15.0]
Step 2798 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 244.0, 1.0]  episode_count: 4845 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.896, -15.0]
Step 2799 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 245.0, 1.0]  episode_count: 4845 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.892, -15.0]
Step 2800 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 246.0, 1.0]  episode_count: 4847 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.876, -15.0]
{"total_number_of_episodes": 4850, "number_of_timesteps": 88174, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2801 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 247.0, 1.0]  episode_count: 4850 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.861, -15.0]
Step 2802 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 248.0, 1.0]  episode_count: 4851 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.878, -15.0]
Step 2803 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 249.0, 1.0]  episode_count: 4851 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.862, -15.0]
 episode_count: 4854 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.847, -15.0]
Step 2805 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 251.0, 1.0]  episode_count: 4857 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.849, -15.0]
Step 2806 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 252.0, 1.0]  episode_count: 4857 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.85, -15.0]
Step 2807 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 253.0, 1.0]  episode_count: 4859 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.835, -15.0]
{"total_number_of_episodes": 4862, "number_of_timesteps": 88402, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2808 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 254.0, 1.0]  episode_count: 4862 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.838, -15.0]
Step 2809 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 255.0, 1.0]  episode_count: 4862 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.839, -15.0]
Step 2810 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 256.0, 1.0]  episode_count: 4863 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.824, -15.0]
Step 2811 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 257.0, 1.0]  episode_count: 4863 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.81, -15.0]
Step 2812 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 258.0, 1.0]  episode_count: 4865 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.795, -15.0]
Step 2813 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 259.0, 1.0]  episode_count: 4868 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.78, -15.0]
Step 2814 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 260.0, 1.0]  episode_count: 4869 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.823, -15.0]
Step 2815 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 261.0, 1.0]  episode_count: 4871 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.826, -15.0]
{"total_number_of_episodes": 4872, "number_of_timesteps": 88638, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2816 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 262.0, 1.0]  episode_count: 4872 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.855, -15.0]
Step 2817 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 263.0, 1.0]  episode_count: 4874 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.841, -15.0]
Step 2818 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 264.0, 1.0]  episode_count: 4874 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.845, -15.0]
Step 2819 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 265.0, 1.0]  episode_count: 4878 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.846, -15.0]
Step 2820 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 266.0, 1.0]  episode_count: 4880 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.849, -15.0]
{"total_number_of_episodes": 4882, "number_of_timesteps": 88834, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2821 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 267.0, 1.0]  episode_count: 4882 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.878, -15.0]
Step 2822 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 268.0, 1.0]  episode_count: 4883 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.863, -15.0]
Step 2823 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 269.0, 1.0]  episode_count: 4884 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.869, -15.0]
Step 2824 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 270.0, 1.0]  episode_count: 4885 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.879, -15.0]
Step 2825 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 271.0, 1.0]  episode_count: 4886 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.885, -15.0]
Step 2826 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 272.0, 1.0]  episode_count: 4888 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.889, -15.0]
Step 2827 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 273.0, 1.0]  episode_count: 4891 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.874, -15.0]
{"total_number_of_episodes": 4893, "number_of_timesteps": 89061, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2828 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 274.0, 1.0]  episode_count: 4893 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.877, -15.0]
Step 2829 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 275.0, 1.0]  episode_count: 4893 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.878, -15.0]
Step 2830 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 276.0, 1.0]  episode_count: 4895 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.864, -15.0]
Step 2831 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 277.0, 1.0]  episode_count: 4898 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.866, -15.0]
Step 2832 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 278.0, 1.0]  episode_count: 4899 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.852, -15.0]
Step 2833 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 279.0, 1.0]  episode_count: 4901 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.854, -15.0]
{"total_number_of_episodes": 4903, "number_of_timesteps": 89218, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2834 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 280.0, 1.0]  episode_count: 4903 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.855, -15.0]
Step 2835 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 281.0, 1.0]  episode_count: 4905 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.857, -15.0]
Step 2836 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 282.0, 1.0]  episode_count: 4908 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.843, -15.0]
Step 2837 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 283.0, 1.0]  episode_count: 4908 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.883, -15.0]
Step 2838 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 284.0, 1.0]  episode_count: 4910 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.885, -15.0]
{"total_number_of_episodes": 4914, "number_of_timesteps": 89396, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2839 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 285.0, 1.0]  episode_count: 4914 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.871, -15.0]
Step 2840 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 286.0, 1.0]  episode_count: 4914 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.906, -15.0]
Step 2841 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 287.0, 1.0]  episode_count: 4915 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.945, -15.0]
4915 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.983, -15.0]
Step 2843 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 289.0, 1.0]  episode_count: 4917 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.986, -15.0]
Step 2844 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 290.0, 1.0]  episode_count: 4918 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.972, -15.0]
Step 2845 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 291.0, 1.0]  episode_count: 4919 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.958, -15.0]
Step 2846 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 292.0, 1.0]  episode_count: 4921 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.958, -15.0]
Step 2847 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 293.0, 1.0]  episode_count: 4921 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.995, -15.0]
{"total_number_of_episodes": 4924, "number_of_timesteps": 89655, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2848 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 294.0, 1.0]  episode_count: 4924 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.982, -15.0]
Step 2849 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 295.0, 1.0]  episode_count: 4927 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.984, -15.0]
Step 2850 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 296.0, 1.0]  episode_count: 4928 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.987, -15.0]
Step 2851 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 297.0, 1.0]  episode_count: 4929 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.989, -15.0]
Step 2852 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 298.0, 1.0]  episode_count: 4933 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.026, -15.0]
{"total_number_of_episodes": 4936, "number_of_timesteps": 89850, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2853 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 299.0, 1.0]  episode_count: 4936 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.012, -15.0]
Step 2854 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 300.0, 1.0]  episode_count: 4936 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.999, -15.0]
Step 2855 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 301.0, 1.0]  episode_count: 4938 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.986, -15.0]
Step 2856 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 302.0, 1.0]  episode_count: 4939 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.972, -15.0]
Step 2857 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 303.0, 1.0]  episode_count: 4941 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.959, -15.0]
Step 2858 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 304.0, 1.0]  episode_count: 4944 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.946, -15.0]
Step 2859 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 305.0, 1.0]  episode_count: 4945 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.947, -15.0]
{"total_number_of_episodes": 4946, "number_of_timesteps": 90019, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2860 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 306.0, 1.0]  episode_count: 4946 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.934, -15.0]
Step 2861 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 307.0, 1.0]  episode_count: 4947 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.922, -15.0]
Step 2862 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 308.0, 1.0]  episode_count: 4952 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.909, -15.0]
Step 2863 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 309.0, 1.0]  episode_count: 4954 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.911, -15.0]
{"total_number_of_episodes": 4956, "number_of_timesteps": 90173, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2864 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 310.0, 1.0]  episode_count: 4956 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.913, -15.0]
Step 2865 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 311.0, 1.0]  episode_count: 4958 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.949, -15.0]
Step 2866 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 312.0, 1.0]  episode_count: 4961 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.95, -15.0]
Step 2867 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 313.0, 1.0]  episode_count: 4961 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.937, -15.0]
Step 2868 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 314.0, 1.0]  episode_count: 4962 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.972, -15.0]
{"total_number_of_episodes": 4966, "number_of_timesteps": 90332, "per_episode_reward": 10.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 2869 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 315.0, 1.0]  episode_count: 4966 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.974, -15.0]
Step 2870 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 316.0, 1.0]  episode_count: 4967 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.009, -15.0]
Step 2871 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 317.0, 1.0]  episode_count: 4968 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.044, -15.0]
Step 2872 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 318.0, 1.0]  episode_count: 4972 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.031, -15.0]
Step 2873 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 319.0, 1.0]  episode_count: 4973 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.032, -15.0]
Step 2874 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 320.0, 1.0]  episode_count: 4974 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.019, -15.0]
{"total_number_of_episodes": 4976, "number_of_timesteps": 90489, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
Step 2875 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 321.0, 1.0]  episode_count: 4976 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.007, -15.0]
Step 2876 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 322.0, 1.0]  episode_count: 4978 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.012, -15.0]
Step 2877 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 323.0, 1.0]  episode_count: 4980 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.046, -15.0]
Step 2878 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 324.0, 1.0]  episode_count: 4983 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.08, -15.0]
Step 2879 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 325.0, 1.0]  episode_count: 4983 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.067, -15.0]
Step 2880 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 326.0, 1.0]  episode_count: 4984 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.063, -15.0]
{"total_number_of_episodes": 4987, "number_of_timesteps": 90658, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
Step 2881 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 327.0, 1.0]  episode_count: 4987 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.067, -15.0]
Step 2882 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 328.0, 1.0]  episode_count: 4988 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.07, -15.0]
Step 2883 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 329.0, 1.0]  episode_count: 4990 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.058, -15.0]
Step 2884 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 330.0, 1.0]  episode_count: 4991 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.046, -15.0]
Step 2885 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 331.0, 1.0]  episode_count: 4992 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.079, -15.0]
Step 2886 5 visits [54.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 4995 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2887 0 visits [55.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 4995 q_vals: [-4.201, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2888 0 visits [56.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 4995 q_vals: [-4.126, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
{"total_number_of_episodes": 4998, "number_of_timesteps": 90910, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
Step 2889 0 visits [57.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 4998 q_vals: [-4.053, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2890 0 visits [58.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5001 q_vals: [-4.071, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2891 0 visits [59.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5002 q_vals: [-4.002, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2892 0 visits [60.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5003 q_vals: [-3.936, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2893 0 visits [61.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5007 q_vals: [-3.942, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
{"total_number_of_episodes": 5008, "number_of_timesteps": 91102, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
Step 2894 0 visits [62.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5008 q_vals: [-3.879, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2895 0 visits [63.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5010 q_vals: [-3.964, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2896 0 visits [64.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5012 q_vals: [-3.981, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2897 0 visits [65.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5015 q_vals: [-4.003, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2898 0 visits [66.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5015 q_vals: [-4.014, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
{"total_number_of_episodes": 5018, "number_of_timesteps": 91258, "per_episode_reward": 10.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 2899 0 visits [67.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5018 q_vals: [-3.954, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2900 0 visits [68.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5019 q_vals: [-3.961, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2901 0 visits [69.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5021 q_vals: [-3.995, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2902 0 visits [70.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5024 q_vals: [-4.026, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2903 0 visits [71.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5026 q_vals: [-4.038, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2904 0 visits [72.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5027 q_vals: [-3.981, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
{"total_number_of_episodes": 5029, "number_of_timesteps": 91427, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 2905 0 visits [73.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5029 q_vals: [-3.927, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2906 0 visits [74.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5030 q_vals: [-3.874, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2907 0 visits [75.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5030 q_vals: [-3.886, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2908 0 visits [76.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5032 q_vals: [-4.032, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2909 0 visits [77.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5033 q_vals: [-3.98, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2910 0 visits [78.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5036 q_vals: [-3.992, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2911 0 visits [79.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5037 q_vals: [-3.942, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2912 0 visits [80.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5037 q_vals: [-3.946, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
{"total_number_of_episodes": 5041, "number_of_timesteps": 91669, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 2913 0 visits [81.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5041 q_vals: [-3.898, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2914 0 visits [82.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5043 q_vals: [-3.918, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2915 0 visits [83.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5044 q_vals: [-3.932, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2916 0 visits [84.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5047 q_vals: [-3.937, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
[-3.95, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2918 0 visits [86.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5050 q_vals: [-4.079, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
{"total_number_of_episodes": 5054, "number_of_timesteps": 91895, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 2919 0 visits [87.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5054 q_vals: [-4.032, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2920 0 visits [88.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5055 q_vals: [-4.157, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2921 0 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 332.0, 1.0]  episode_count: 5058 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.081, -15.0]
Step 2922 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 333.0, 1.0]  episode_count: 5061 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.082, -15.0]
Step 2923 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 334.0, 1.0]  episode_count: 5061 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.07, -15.0]
{"total_number_of_episodes": 5064, "number_of_timesteps": 92027, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857295},
Step 2924 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 335.0, 1.0]  episode_count: 5064 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.058, -15.0]
Step 2925 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 336.0, 1.0]  episode_count: 5066 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.063, -15.0]
Step 2926 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 337.0, 1.0]  episode_count: 5066 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.065, -15.0]
Step 2927 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 338.0, 1.0]  episode_count: 5070 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.053, -15.0]
Step 2928 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 339.0, 1.0]  episode_count: 5071 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.057, -15.0]
Step 2929 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 340.0, 1.0]  episode_count: 5073 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.045, -15.0]
{"total_number_of_episodes": 5075, "number_of_timesteps": 92211, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 2930 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 341.0, 1.0]  episode_count: 5075 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.033, -15.0]
Step 2931 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 342.0, 1.0]  episode_count: 5077 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.021, -15.0]
Step 2932 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 343.0, 1.0]  episode_count: 5078 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.025, -15.0]
Step 2933 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 344.0, 1.0]  episode_count: 5078 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.013, -15.0]
Step 2934 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 345.0, 1.0]  episode_count: 5080 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.015, -15.0]
Step 2935 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 346.0, 1.0]  episode_count: 5081 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.003, -15.0]
Step 2936 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 347.0, 1.0]  episode_count: 5081 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.991, -15.0]
{"total_number_of_episodes": 5085, "number_of_timesteps": 92429, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 2937 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 348.0, 1.0]  episode_count: 5085 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.994, -15.0]
Step 2938 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 349.0, 1.0]  episode_count: 5086 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.995, -15.0]
Step 2939 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 350.0, 1.0]  episode_count: 5086 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.999, -15.0]
Step 2940 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 351.0, 1.0]  episode_count: 5088 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.002, -15.0]
Step 2941 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 352.0, 1.0]  episode_count: 5090 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.991, -15.0]
Step 2942 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 353.0, 1.0]  episode_count: 5091 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.979, -15.0]
Step 2943 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 354.0, 1.0]  episode_count: 5091 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.968, -15.0]
Step 2944 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 355.0, 1.0]  episode_count: 5091 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.982, -15.0]
Step 2945 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 356.0, 1.0]  episode_count: 5093 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.984, -15.0]
Step 2946 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 357.0, 1.0]  episode_count: 5094 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.987, -15.0]
{"total_number_of_episodes": 5096, "number_of_timesteps": 92712, "per_episode_reward": 10.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 2947 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 358.0, 1.0]  episode_count: 5096 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.976, -15.0]
Step 2948 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 359.0, 1.0]  episode_count: 5097 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.979, -15.0]
Step 2949 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 360.0, 1.0]  episode_count: 5099 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.982, -15.0]
Step 2950 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 361.0, 1.0]  episode_count: 5101 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.971, -15.0]
Step 2951 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 362.0, 1.0]  episode_count: 5103 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.973, -15.0]
{"total_number_of_episodes": 5106, "number_of_timesteps": 92938, "per_episode_reward": 10.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 2952 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 363.0, 1.0]  episode_count: 5106 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.974, -15.0]
Step 2953 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 364.0, 1.0]  episode_count: 5106 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.975, -15.0]
Step 2954 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 365.0, 1.0]  episode_count: 5110 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.964, -15.0]
Step 2955 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 366.0, 1.0]  episode_count: 5112 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.964, -15.0]
Step 2956 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 367.0, 1.0]  episode_count: 5115 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.965, -15.0]
{"total_number_of_episodes": 5118, "number_of_timesteps": 93110, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2957 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 368.0, 1.0]  episode_count: 5118 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.966, -15.0]
Step 2958 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 369.0, 1.0]  episode_count: 5119 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.968, -15.0]
Step 2959 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 370.0, 1.0]  episode_count: 5123 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.973, -15.0]
Step 2960 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 371.0, 1.0]  episode_count: 5124 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.976, -15.0]
Step 2961 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 372.0, 1.0]  episode_count: 5126 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.977, -15.0]
{"total_number_of_episodes": 5129, "number_of_timesteps": 93249, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2962 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 373.0, 1.0]  episode_count: 5129 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.978, -15.0]
Step 2963 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 374.0, 1.0]  episode_count: 5131 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.981, -15.0]
Step 2964 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 375.0, 1.0]  episode_count: 5132 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.971, -15.0]
Step 2965 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 376.0, 1.0]  episode_count: 5135 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.974, -15.0]
Step 2966 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 377.0, 1.0]  episode_count: 5138 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.964, -15.0]
{"total_number_of_episodes": 5140, "number_of_timesteps": 93394, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2967 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 378.0, 1.0]  episode_count: 5140 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.993, -15.0]
Step 2968 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 379.0, 1.0]  episode_count: 5143 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.001, -15.0]
Step 2969 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 380.0, 1.0]  episode_count: 5144 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.994, -15.0]
Step 2970 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 381.0, 1.0]  episode_count: 5146 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.983, -15.0]
Step 2971 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 382.0, 1.0]  episode_count: 5148 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.973, -15.0]
{"total_number_of_episodes": 5150, "number_of_timesteps": 93552, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2972 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 383.0, 1.0]  episode_count: 5150 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.962, -15.0]
Step 2973 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 384.0, 1.0]  episode_count: 5151 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.966, -15.0]
Step 2974 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 385.0, 1.0]  episode_count: 5152 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.956, -15.0]
Step 2975 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 386.0, 1.0]  episode_count: 5154 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.957, -15.0]
Step 2976 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 387.0, 1.0]  episode_count: 5155 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.947, -15.0]
Step 2977 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 388.0, 1.0]  episode_count: 5159 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.953, -15.0]
{"total_number_of_episodes": 5160, "number_of_timesteps": 93740, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2978 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 389.0, 1.0]  episode_count: 5160 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.943, -15.0]
Step 2979 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 390.0, 1.0]  episode_count: 5162 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.944, -15.0]
Step 2980 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 391.0, 1.0]  episode_count: 5162 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.945, -15.0]
Step 2981 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 392.0, 1.0]  episode_count: 5165 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.935, -15.0]
Step 2982 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 393.0, 1.0]  episode_count: 5167 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.939, -15.0]
{"total_number_of_episodes": 5170, "number_of_timesteps": 93920, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2983 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 394.0, 1.0]  episode_count: 5170 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.946, -15.0]
Step 2984 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 395.0, 1.0]  episode_count: 5171 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.95, -15.0]
Step 2985 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 396.0, 1.0]  episode_count: 5173 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.94, -15.0]
Step 2986 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 397.0, 1.0]  episode_count: 5175 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.941, -15.0]
Step 2987 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 398.0, 1.0]  episode_count: 5177 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.942, -15.0]
Step 2988 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 399.0, 1.0]  episode_count: 5178 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.932, -15.0]
Step 2989 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 400.0, 1.0]  episode_count: 5179 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.96, -15.0]
{"total_number_of_episodes": 5182, "number_of_timesteps": 94097, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 2990 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 401.0, 1.0]  episode_count: 5182 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.95, -15.0]
Step 2991 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 402.0, 1.0]  episode_count: 5184 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.94, -15.0]
Step 2992 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 403.0, 1.0]  episode_count: 5187 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.943, -15.0]
Step 2993 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 404.0, 1.0]  episode_count: 5187 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.933, -15.0]
Step 2994 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 405.0, 1.0]  episode_count: 5188 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.924, -15.0]
Step 2995 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 406.0, 1.0]  episode_count: 5191 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.914, -15.0]
{"total_number_of_episodes": 5192, "number_of_timesteps": 94282, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2996 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 407.0, 1.0]  episode_count: 5192 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.904, -15.0]
Step 2997 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 408.0, 1.0]  episode_count: 5192 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.895, -15.0]
Step 2998 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 409.0, 1.0]  episode_count: 5194 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.895, -15.0]
Step 2999 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 410.0, 1.0]  episode_count: 5194 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.897, -15.0]
Step 3000 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 411.0, 1.0]  episode_count: 5195 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.899, -15.0]
Step 3001 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 412.0, 1.0]  episode_count: 5196 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.889, -15.0]
Step 3002 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 413.0, 1.0]  episode_count: 5199 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.88, -15.0]
Step 3003 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 414.0, 1.0]  episode_count: 5200 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.871, -15.0]
Step 3004 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 415.0, 1.0]  episode_count: 5200 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.873, -15.0]
{"total_number_of_episodes": 5203, "number_of_timesteps": 94509, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 3005 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 416.0, 1.0]  episode_count: 5203 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.864, -15.0]
Step 3006 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 417.0, 1.0]  episode_count: 5204 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.855, -15.0]
Step 3007 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 418.0, 1.0]  episode_count: 5205 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.856, -15.0]
Step 3008 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 419.0, 1.0]  episode_count: 5207 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.856, -15.0]
Step 3009 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 420.0, 1.0]  episode_count: 5207 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.882, -15.0]
Step 3010 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 421.0, 1.0]  episode_count: 5208 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.873, -15.0]
Step 3011 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 422.0, 1.0]  episode_count: 5211 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.864, -15.0]
{"total_number_of_episodes": 5214, "number_of_timesteps": 94846, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3012 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 423.0, 1.0]  episode_count: 5214 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.855, -15.0]
Step 3013 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 424.0, 1.0]  episode_count: 5214 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.862, -15.0]
Step 3014 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 425.0, 1.0]  episode_count: 5215 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.864, -15.0]
Step 3015 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 426.0, 1.0]  episode_count: 5218 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.855, -15.0]
Step 3016 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 427.0, 1.0]  episode_count: 5220 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.857, -15.0]
Step 3017 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 428.0, 1.0]  episode_count: 5221 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.858, -15.0]
Step 3018 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 429.0, 1.0]  episode_count: 5223 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.861, -15.0]
{"total_number_of_episodes": 5224, "number_of_timesteps": 95020, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3019 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 430.0, 1.0]  episode_count: 5224 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.852, -15.0]
Step 3020 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 431.0, 1.0]  episode_count: 5227 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.857, -15.0]
Step 3021 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 432.0, 1.0]  episode_count: 5228 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.848, -15.0]
Step 3022 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 433.0, 1.0]  episode_count: 5230 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.85, -15.0]
Step 3023 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 434.0, 1.0]  episode_count: 5232 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.852, -15.0]
Step 3024 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 435.0, 1.0]  episode_count: 5233 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.854, -15.0]
Step 3025 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 436.0, 1.0]  episode_count: 5233 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.845, -15.0]
{"total_number_of_episodes": 5235, "number_of_timesteps": 95244, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3026 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 437.0, 1.0]  episode_count: 5235 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.846, -15.0]
Step 3027 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 438.0, 1.0]  episode_count: 5237 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.837, -15.0]
Step 3028 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 439.0, 1.0]  episode_count: 5240 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.828, -15.0]
Step 3029 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 440.0, 1.0]  episode_count: 5240 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.83, -15.0]
Step 3030 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 441.0, 1.0]  episode_count: 5241 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.831, -15.0]
Step 3031 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 442.0, 1.0]  episode_count: 5243 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.823, -15.0]
{"total_number_of_episodes": 5245, "number_of_timesteps": 95447, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3032 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 443.0, 1.0]  episode_count: 5245 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.822, -15.0]
Step 3033 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 444.0, 1.0]  episode_count: 5246 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.823, -15.0]
Step 3034 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 445.0, 1.0]  episode_count: 5247 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.814, -15.0]
Step 3035 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 446.0, 1.0]  episode_count: 5249 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.823, -15.0]
Step 3036 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 447.0, 1.0]  episode_count: 5249 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.848, -15.0]
Step 3037 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 448.0, 1.0]  episode_count: 5251 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.852, -15.0]
Step 3038 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 449.0, 1.0]  episode_count: 5253 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.852, -15.0]
Step 3039 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 450.0, 1.0]  episode_count: 5254 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.877, -15.0]
{"total_number_of_episodes": 5255, "number_of_timesteps": 95664, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3040 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 451.0, 1.0]  episode_count: 5255 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.881, -15.0]
Step 3041 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 452.0, 1.0]  episode_count: 5256 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.883, -15.0]
Step 3042 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 453.0, 1.0]  episode_count: 5256 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.874, -15.0]
Step 3043 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 454.0, 1.0]  episode_count: 5258 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.866, -15.0]
Step 3044 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 455.0, 1.0]  episode_count: 5262 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.857, -15.0]
Step 3045 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 456.0, 1.0]  episode_count: 5262 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.849, -15.0]
Step 3046 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 457.0, 1.0]  episode_count: 5264 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.85, -15.0]
{"total_number_of_episodes": 5265, "number_of_timesteps": 95924, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3047 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 458.0, 1.0]  episode_count: 5265 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.851, -15.0]
Step 3048 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 459.0, 1.0]  episode_count: 5265 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.855, -15.0]
Step 3049 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 460.0, 1.0]  episode_count: 5266 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.879, -15.0]
Step 3050 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 461.0, 1.0]  episode_count: 5270 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.87, -15.0]
Step 3051 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 462.0, 1.0]  episode_count: 5271 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.862, -15.0]
Step 3052 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 463.0, 1.0]  episode_count: 5273 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.863, -15.0]
Step 3053 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 464.0, 1.0]  episode_count: 5274 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.863, -15.0]
{"total_number_of_episodes": 5277, "number_of_timesteps": 96159, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3054 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 465.0, 1.0]  episode_count: 5277 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.866, -15.0]
Step 3055 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 466.0, 1.0]  episode_count: 5280 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.869, -15.0]
Step 3056 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 467.0, 1.0]  episode_count: 5283 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.869, -15.0]
Step 3057 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 468.0, 1.0]  episode_count: 5286 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.861, -15.0]
{"total_number_of_episodes": 5287, "number_of_timesteps": 96286, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3058 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 469.0, 1.0]  episode_count: 5287 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.885, -15.0]
Step 3059 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 470.0, 1.0]  episode_count: 5287 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.877, -15.0]
Step 3060 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 471.0, 1.0]  episode_count: 5290 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.877, -15.0]
Step 3061 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 472.0, 1.0]  episode_count: 5290 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.879, -15.0]
Step 3062 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 473.0, 1.0]  episode_count: 5294 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.871, -15.0]
Step 3063 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 474.0, 1.0]  episode_count: 5295 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.872, -15.0]
{"total_number_of_episodes": 5297, "number_of_timesteps": 96477, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3064 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 475.0, 1.0]  episode_count: 5297 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.873, -15.0]
Step 3065 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 476.0, 1.0]  episode_count: 5297 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.874, -15.0]
Step 3066 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 477.0, 1.0]  episode_count: 5300 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.866, -15.0]
Step 3067 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 478.0, 1.0]  episode_count: 5301 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.868, -15.0]
Step 3068 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 479.0, 1.0]  episode_count: 5302 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.869, -15.0]
Step 3069 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 480.0, 1.0]  episode_count: 5305 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.869, -15.0]
Step 3070 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 481.0, 1.0]  episode_count: 5306 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.876, -15.0]
{"total_number_of_episodes": 5308, "number_of_timesteps": 96687, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3071 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 482.0, 1.0]  episode_count: 5308 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.879, -15.0]
Step 3072 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 483.0, 1.0]  episode_count: 5310 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.88, -15.0]
Step 3073 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 484.0, 1.0]  episode_count: 5312 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.872, -15.0]
Step 3074 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 485.0, 1.0]  episode_count: 5313 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.864, -15.0]
Step 3075 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 486.0, 1.0]  episode_count: 5316 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.865, -15.0]
{"total_number_of_episodes": 5319, "number_of_timesteps": 96881, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3076 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 487.0, 1.0]  episode_count: 5319 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.888, -15.0]
Step 3077 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 488.0, 1.0]  episode_count: 5320 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.91, -15.0]
Step 3078 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 489.0, 1.0]  episode_count: 5324 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.913, -15.0]
Step 3079 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 490.0, 1.0]  episode_count: 5325 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.905, -15.0]
Step 3080 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 491.0, 1.0]  episode_count: 5326 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.897, -15.0]
Step 3081 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 492.0, 1.0]  episode_count: 5327 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.889, -15.0]
{"total_number_of_episodes": 5330, "number_of_timesteps": 97038, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3082 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 493.0, 1.0]  episode_count: 5330 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.881, -15.0]
Step 3083 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 494.0, 1.0]  episode_count: 5333 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.874, -15.0]
Step 3084 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 495.0, 1.0]  episode_count: 5333 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.866, -15.0]
Step 3085 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 496.0, 1.0]  episode_count: 5338 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.858, -15.0]
Step 3086 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 497.0, 1.0]  episode_count: 5339 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.85, -15.0]
{"total_number_of_episodes": 5343, "number_of_timesteps": 97222, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3087 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 498.0, 1.0]  episode_count: 5343 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.852, -15.0]
Step 3088 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 499.0, 1.0]  episode_count: 5346 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.853, -15.0]
Step 3089 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 500.0, 1.0]  episode_count: 5347 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.854, -15.0]
Step 3090 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 501.0, 1.0]  episode_count: 5350 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.855, -15.0]
{"total_number_of_episodes": 5354, "number_of_timesteps": 97346, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3091 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 502.0, 1.0]  episode_count: 5354 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.858, -15.0]
Step 3092 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 503.0, 1.0]  episode_count: 5355 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.88, -15.0]
Step 3093 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 504.0, 1.0]  episode_count: 5359 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.882, -15.0]
Step 3094 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 505.0, 1.0]  episode_count: 5360 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.904, -15.0]
Step 3095 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 506.0, 1.0]  episode_count: 5363 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.907, -15.0]
{"total_number_of_episodes": 5365, "number_of_timesteps": 97481, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3096 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 507.0, 1.0]  episode_count: 5365 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.907, -15.0]
Step 3097 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 508.0, 1.0]  episode_count: 5369 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.907, -15.0]
Step 3098 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 509.0, 1.0]  episode_count: 5369 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.911, -15.0]
Step 3099 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 510.0, 1.0]  episode_count: 5371 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.915, -15.0]
Step 3100 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 511.0, 1.0]  episode_count: 5373 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.907, -15.0]
{"total_number_of_episodes": 5375, "number_of_timesteps": 97616, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3101 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 512.0, 1.0]  episode_count: 5375 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.908, -15.0]
Step 3102 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 513.0, 1.0]  episode_count: 5377 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.901, -15.0]
Step 3103 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 514.0, 1.0]  episode_count: 5378 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.922, -15.0]
Step 3104 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 515.0, 1.0]  episode_count: 5381 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.923, -15.0]
[-4.278, -inf, -7.5, -6.324, -inf, -3.945, -15.0]
{"total_number_of_episodes": 5386, "number_of_timesteps": 97803, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3106 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 517.0, 1.0]  episode_count: 5386 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.966, -15.0]
Step 3107 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 518.0, 1.0]  episode_count: 5386 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.959, -15.0]
Step 3108 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 519.0, 1.0]  episode_count: 5389 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.961, -15.0]
Step 3109 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 520.0, 1.0]  episode_count: 5390 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.953, -15.0]
Step 3110 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 521.0, 1.0]  episode_count: 5390 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.955, -15.0]
Step 3111 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 522.0, 1.0]  episode_count: 5391 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.958, -15.0]
Step 3112 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 523.0, 1.0]  episode_count: 5395 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.95, -15.0]
{"total_number_of_episodes": 5396, "number_of_timesteps": 98000, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3113 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 524.0, 1.0]  episode_count: 5396 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.954, -15.0]
Step 3114 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 525.0, 1.0]  episode_count: 5398 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.954, -15.0]
Step 3115 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 526.0, 1.0]  episode_count: 5401 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.955, -15.0]
Step 3116 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 527.0, 1.0]  episode_count: 5402 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.947, -15.0]
Step 3117 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 528.0, 1.0]  episode_count: 5403 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.949, -15.0]
{"total_number_of_episodes": 5408, "number_of_timesteps": 98191, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3118 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 529.0, 1.0]  episode_count: 5408 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.951, -15.0]
Step 3119 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 530.0, 1.0]  episode_count: 5410 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.952, -15.0]
Step 3120 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 531.0, 1.0]  episode_count: 5411 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.953, -15.0]
Step 3121 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 532.0, 1.0]  episode_count: 5414 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.946, -15.0]
Step 3122 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 533.0, 1.0]  episode_count: 5417 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.939, -15.0]
{"total_number_of_episodes": 5419, "number_of_timesteps": 98335, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3123 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 534.0, 1.0]  episode_count: 5419 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.931, -15.0]
Step 3124 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 535.0, 1.0]  episode_count: 5421 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.934, -15.0]
Step 3125 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 536.0, 1.0]  episode_count: 5422 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.926, -15.0]
Step 3126 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 537.0, 1.0]  episode_count: 5426 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.929, -15.0]
{"total_number_of_episodes": 5429, "number_of_timesteps": 98481, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3127 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 538.0, 1.0]  episode_count: 5429 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.93, -15.0]
Step 3128 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 539.0, 1.0]  episode_count: 5431 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.931, -15.0]
Step 3129 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 540.0, 1.0]  episode_count: 5433 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.924, -15.0]
Step 3130 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 541.0, 1.0]  episode_count: 5434 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.945, -15.0]
Step 3131 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 542.0, 1.0]  episode_count: 5438 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.947, -15.0]
{"total_number_of_episodes": 5440, "number_of_timesteps": 98624, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3132 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 543.0, 1.0]  episode_count: 5440 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.95, -15.0]
Step 3133 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 544.0, 1.0]  episode_count: 5441 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.954, -15.0]
Step 3134 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 545.0, 1.0]  episode_count: 5445 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.946, -15.0]
Step 3135 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 546.0, 1.0]  episode_count: 5447 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.948, -15.0]
Step 3136 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 547.0, 1.0]  episode_count: 5449 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.941, -15.0]
{"total_number_of_episodes": 5451, "number_of_timesteps": 98757, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3137 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 548.0, 1.0]  episode_count: 5451 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.961, -15.0]
Step 3138 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 549.0, 1.0]  episode_count: 5454 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.962, -15.0]
Step 3139 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 550.0, 1.0]  episode_count: 5454 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.955, -15.0]
Step 3140 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 551.0, 1.0]  episode_count: 5458 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.956, -15.0]
Step 3141 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 552.0, 1.0]  episode_count: 5460 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.957, -15.0]
{"total_number_of_episodes": 5463, "number_of_timesteps": 98925, "per_episode_reward": 10.79, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
[-4.278, -inf, -7.5, -6.324, -inf, -3.961, -15.0]
Step 3143 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 554.0, 1.0]  episode_count: 5463 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.954, -15.0]
Step 3144 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 555.0, 1.0]  episode_count: 5466 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.947, -15.0]
Step 3145 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 556.0, 1.0]  episode_count: 5468 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.948, -15.0]
Step 3146 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 557.0, 1.0]  episode_count: 5469 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.949, -15.0]
Step 3147 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 558.0, 1.0]  episode_count: 5471 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.95, -15.0]
Step 3148 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 559.0, 1.0]  episode_count: 5472 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.952, -15.0]
{"total_number_of_episodes": 5474, "number_of_timesteps": 99087, "per_episode_reward": 10.79, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 3149 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 560.0, 1.0]  episode_count: 5474 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.953, -15.0]
Step 3150 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 561.0, 1.0]  episode_count: 5476 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.956, -15.0]
Step 3151 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 562.0, 1.0]  episode_count: 5478 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.959, -15.0]
Step 3152 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 563.0, 1.0]  episode_count: 5478 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.952, -15.0]
Step 3153 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 564.0, 1.0]  episode_count: 5481 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.945, -15.0]
Step 3154 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 565.0, 1.0]  episode_count: 5483 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.938, -15.0]
{"total_number_of_episodes": 5484, "number_of_timesteps": 99291, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 3155 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 566.0, 1.0]  episode_count: 5484 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.931, -15.0]
Step 3156 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 567.0, 1.0]  episode_count: 5486 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.934, -15.0]
Step 3157 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 568.0, 1.0]  episode_count: 5487 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.935, -15.0]
Step 3158 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 569.0, 1.0]  episode_count: 5489 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.928, -15.0]
Step 3159 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 570.0, 1.0]  episode_count: 5493 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.921, -15.0]
Step 3160 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 571.0, 1.0]  episode_count: 5493 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.941, -15.0]
{"total_number_of_episodes": 5496, "number_of_timesteps": 99489, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 3161 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 572.0, 1.0]  episode_count: 5496 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.934, -15.0]
Step 3162 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 573.0, 1.0]  episode_count: 5498 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.935, -15.0]
Step 3163 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 574.0, 1.0]  episode_count: 5500 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.936, -15.0]
Step 3164 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 575.0, 1.0]  episode_count: 5501 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.937, -15.0]
Step 3165 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 576.0, 1.0]  episode_count: 5502 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.938, -15.0]
{"total_number_of_episodes": 5506, "number_of_timesteps": 99659, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 3166 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 577.0, 1.0]  episode_count: 5506 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.942, -15.0]
Step 3167 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 578.0, 1.0]  episode_count: 5507 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.961, -15.0]
Step 3168 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 579.0, 1.0]  episode_count: 5509 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.963, -15.0]
Step 3169 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 580.0, 1.0]  episode_count: 5511 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.965, -15.0]
Step 3170 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 581.0, 1.0]  episode_count: 5512 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.958, -15.0]
{"total_number_of_episodes": 5516, "number_of_timesteps": 99813, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 3171 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 582.0, 1.0]  episode_count: 5516 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.951, -15.0]
Step 3172 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 583.0, 1.0]  episode_count: 5518 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.953, -15.0]
Step 3173 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 584.0, 1.0]  episode_count: 5520 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.947, -15.0]
Step 3174 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 585.0, 1.0]  episode_count: 5523 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.949, -15.0]
Step 3175 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 586.0, 1.0]  episode_count: 5525 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.95, -15.0]
{"total_number_of_episodes": 5527, "number_of_timesteps": 99941, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 3176 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 587.0, 1.0]  episode_count: 5527 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.952, -15.0]
Step 3177 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 588.0, 1.0]  episode_count: 5529 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.953, -15.0]
Step 3178 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 589.0, 1.0]  episode_count: 5530 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.954, -15.0]
Step 3179 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 590.0, 1.0]  episode_count: 5531 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.955, -15.0]
 episode_count: 5534 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.958, -15.0]
{"total_number_of_episodes": 5537, "number_of_timesteps": 100106, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 3181 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 592.0, 1.0]  episode_count: 5537 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.951, -15.0]
Step 3182 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 593.0, 1.0]  episode_count: 5539 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.954, -15.0]
Step 3183 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 594.0, 1.0]  episode_count: 5542 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.956, -15.0]
Step 3184 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 595.0, 1.0]  episode_count: 5543 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.949, -15.0]
Step 3185 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 596.0, 1.0]  episode_count: 5544 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.942, -15.0]
Step 3186 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 597.0, 1.0]  episode_count: 5546 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.947, -15.0]
{"total_number_of_episodes": 5549, "number_of_timesteps": 100277, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 3187 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 598.0, 1.0]  episode_count: 5549 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.95, -15.0]
Step 3188 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 599.0, 1.0]  episode_count: 5550 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.951, -15.0]
Step 3189 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 600.0, 1.0]  episode_count: 5552 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.952, -15.0]
Step 3190 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 601.0, 1.0]  episode_count: 5552 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.946, -15.0]
Step 3191 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 602.0, 1.0]  episode_count: 5552 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.939, -15.0]
Step 3192 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 603.0, 1.0]  episode_count: 5555 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.932, -15.0]
Step 3193 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 604.0, 1.0]  episode_count: 5555 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.942, -15.0]
Step 3194 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 605.0, 1.0]  episode_count: 5556 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.947, -15.0]
{"total_number_of_episodes": 5560, "number_of_timesteps": 100526, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 3195 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 606.0, 1.0]  episode_count: 5560 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.94, -15.0]
Step 3196 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 607.0, 1.0]  episode_count: 5560 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.934, -15.0]
Step 3197 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 608.0, 1.0]  episode_count: 5561 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.927, -15.0]
Step 3198 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 609.0, 1.0]  episode_count: 5565 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.921, -15.0]
Step 3199 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 610.0, 1.0]  episode_count: 5565 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.923, -15.0]
Step 3200 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 611.0, 1.0]  episode_count: 5566 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.925, -15.0]
Step 3201 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 612.0, 1.0]  episode_count: 5568 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.929, -15.0]
{"total_number_of_episodes": 5571, "number_of_timesteps": 100766, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 3202 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 613.0, 1.0]  episode_count: 5571 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.931, -15.0]
Step 3203 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 614.0, 1.0]  episode_count: 5573 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.932, -15.0]
Step 3204 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 615.0, 1.0]  episode_count: 5575 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.926, -15.0]
Step 3205 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 616.0, 1.0]  episode_count: 5577 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.919, -15.0]
Step 3206 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 617.0, 1.0]  episode_count: 5578 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.922, -15.0]
Step 3207 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 618.0, 1.0]  episode_count: 5579 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.924, -15.0]
{"total_number_of_episodes": 5583, "number_of_timesteps": 100962, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3208 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 619.0, 1.0]  episode_count: 5583 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.924, -15.0]
Step 3209 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 620.0, 1.0]  episode_count: 5584 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.918, -15.0]
Step 3210 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 621.0, 1.0]  episode_count: 5585 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.919, -15.0]
Step 3211 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 622.0, 1.0]  episode_count: 5590 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.913, -15.0]
Step 3212 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 623.0, 1.0]  episode_count: 5591 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.931, -15.0]
Step 3213 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 624.0, 1.0]  episode_count: 5592 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.932, -15.0]
{"total_number_of_episodes": 5594, "number_of_timesteps": 101121, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3214 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 625.0, 1.0]  episode_count: 5594 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.926, -15.0]
Step 3215 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 626.0, 1.0]  episode_count: 5596 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.927, -15.0]
Step 3216 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 627.0, 1.0]  episode_count: 5600 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.921, -15.0]
Step 3217 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 628.0, 1.0]  episode_count: 5601 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.915, -15.0]
Step 3218 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 629.0, 1.0]  episode_count: 5603 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.932, -15.0]
{"total_number_of_episodes": 5606, "number_of_timesteps": 101300, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3219 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 630.0, 1.0]  episode_count: 5606 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.926, -15.0]
Step 3220 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 631.0, 1.0]  episode_count: 5607 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.92, -15.0]
Step 3221 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 632.0, 1.0]  episode_count: 5609 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.914, -15.0]
Step 3222 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 633.0, 1.0]  episode_count: 5612 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.916, -15.0]
Step 3223 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 634.0, 1.0]  episode_count: 5613 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.923, -15.0]
Step 3224 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 635.0, 1.0]  episode_count: 5614 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.917, -15.0]
{"total_number_of_episodes": 5616, "number_of_timesteps": 101451, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3225 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 636.0, 1.0]  episode_count: 5616 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.911, -15.0]
Step 3226 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 637.0, 1.0]  episode_count: 5618 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.912, -15.0]
Step 3227 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 638.0, 1.0]  episode_count: 5620 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.906, -15.0]
Step 3228 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 639.0, 1.0]  episode_count: 5622 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.9, -15.0]
Step 3229 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 640.0, 1.0]  episode_count: 5622 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.904, -15.0]
Step 3230 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 641.0, 1.0]  episode_count: 5624 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.898, -15.0]
{"total_number_of_episodes": 5626, "number_of_timesteps": 101628, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3231 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 642.0, 1.0]  episode_count: 5626 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.892, -15.0]
Step 3232 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 643.0, 1.0]  episode_count: 5627 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.885, -15.0]
Step 3233 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 644.0, 1.0]  episode_count: 5628 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.889, -15.0]
Step 3234 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 645.0, 1.0]  episode_count: 5628 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.892, -15.0]
Step 3235 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 646.0, 1.0]  episode_count: 5630 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.893, -15.0]
Step 3236 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 647.0, 1.0]  episode_count: 5632 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.895, -15.0]
Step 3237 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 648.0, 1.0]  episode_count: 5632 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.912, -15.0]
Step 3238 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 649.0, 1.0]  episode_count: 5633 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.906, -15.0]
{"total_number_of_episodes": 5637, "number_of_timesteps": 101925, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3239 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 650.0, 1.0]  episode_count: 5637 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.9, -15.0]
Step 3240 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 651.0, 1.0]  episode_count: 5637 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.894, -15.0]
Step 3241 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 652.0, 1.0]  episode_count: 5637 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.895, -15.0]
Step 3242 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 653.0, 1.0]  episode_count: 5641 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.896, -15.0]
Step 3243 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 654.0, 1.0]  episode_count: 5643 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.897, -15.0]
Step 3244 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 655.0, 1.0]  episode_count: 5644 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.891, -15.0]
Step 3245 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 656.0, 1.0]  episode_count: 5645 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.892, -15.0]
{"total_number_of_episodes": 5648, "number_of_timesteps": 102148, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3246 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 657.0, 1.0]  episode_count: 5648 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.894, -15.0]
Step 3247 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 658.0, 1.0]  episode_count: 5648 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.895, -15.0]
Step 3248 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 659.0, 1.0]  episode_count: 5649 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.896, -15.0]
Step 3249 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 660.0, 1.0]  episode_count: 5651 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.89, -15.0]
Step 3250 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 661.0, 1.0]  episode_count: 5653 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.893, -15.0]
Step 3251 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 662.0, 1.0]  episode_count: 5655 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.888, -15.0]
Step 3252 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 663.0, 1.0]  episode_count: 5656 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.891, -15.0]
Step 3253 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 664.0, 1.0]  episode_count: 5657 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.908, -15.0]
{"total_number_of_episodes": 5661, "number_of_timesteps": 102407, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3254 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 665.0, 1.0]  episode_count: 5661 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.909, -15.0]
Step 3255 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 666.0, 1.0]  episode_count: 5663 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.903, -15.0]
Step 3256 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 667.0, 1.0]  episode_count: 5663 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.899, -15.0]
Step 3257 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 668.0, 1.0]  episode_count: 5665 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.893, -15.0]
Step 3258 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 669.0, 1.0]  episode_count: 5668 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.894, -15.0]
Step 3259 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 670.0, 1.0]  episode_count: 5669 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.896, -15.0]
Step 3260 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 671.0, 1.0]  episode_count: 5670 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.89, -15.0]
{"total_number_of_episodes": 5675, "number_of_timesteps": 102642, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3261 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 672.0, 1.0]  episode_count: 5675 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.892, -15.0]
Step 3262 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 673.0, 1.0]  episode_count: 5676 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.886, -15.0]
Step 3263 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 674.0, 1.0]  episode_count: 5677 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.887, -15.0]
Step 3264 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 675.0, 1.0]  episode_count: 5680 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.882, -15.0]
Step 3265 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 676.0, 1.0]  episode_count: 5683 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.876, -15.0]
{"total_number_of_episodes": 5686, "number_of_timesteps": 102784, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3266 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 677.0, 1.0]  episode_count: 5686 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.87, -15.0]
Step 3267 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 678.0, 1.0]  episode_count: 5687 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.864, -15.0]
Step 3268 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 679.0, 1.0]  episode_count: 5689 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.859, -15.0]
Step 3269 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 680.0, 1.0]  episode_count: 5692 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.853, -15.0]
Step 3270 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 681.0, 1.0]  episode_count: 5693 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.855, -15.0]
Step 3271 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 682.0, 1.0]  episode_count: 5695 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.857, -15.0]
{"total_number_of_episodes": 5698, "number_of_timesteps": 102949, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3272 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 683.0, 1.0]  episode_count: 5698 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.851, -15.0]
Step 3273 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 684.0, 1.0]  episode_count: 5699 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.852, -15.0]
Step 3274 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 685.0, 1.0]  episode_count: 5701 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.853, -15.0]
Step 3275 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 686.0, 1.0]  episode_count: 5704 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.854, -15.0]
Step 3276 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 687.0, 1.0]  episode_count: 5706 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.855, -15.0]
Step 3277 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 688.0, 1.0]  episode_count: 5707 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.849, -15.0]
{"total_number_of_episodes": 5710, "number_of_timesteps": 103138, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3278 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 689.0, 1.0]  episode_count: 5710 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.85, -15.0]
Step 3279 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 690.0, 1.0]  episode_count: 5713 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.851, -15.0]
Step 3280 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 691.0, 1.0]  episode_count: 5715 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.853, -15.0]
Step 3281 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 692.0, 1.0]  episode_count: 5715 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.854, -15.0]
Step 3282 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 693.0, 1.0]  episode_count: 5717 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.848, -15.0]
{"total_number_of_episodes": 5720, "number_of_timesteps": 103289, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3283 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 694.0, 1.0]  episode_count: 5720 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.843, -15.0]
Step 3284 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 695.0, 1.0]  episode_count: 5722 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.837, -15.0]
Step 3285 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 696.0, 1.0]  episode_count: 5723 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.838, -15.0]
Step 3286 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 697.0, 1.0]  episode_count: 5724 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.832, -15.0]
Step 3287 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 698.0, 1.0]  episode_count: 5726 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.848, -15.0]
Step 3288 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 699.0, 1.0]  episode_count: 5727 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.843, -15.0]
Step 3289 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 700.0, 1.0]  episode_count: 5729 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.837, -15.0]
{"total_number_of_episodes": 5732, "number_of_timesteps": 103514, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3290 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 701.0, 1.0]  episode_count: 5732 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.84, -15.0]
Step 3291 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 702.0, 1.0]  episode_count: 5734 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.835, -15.0]
Step 3292 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 703.0, 1.0]  episode_count: 5734 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.829, -15.0]
Step 3293 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 704.0, 1.0]  episode_count: 5736 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.831, -15.0]
Step 3294 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 705.0, 1.0]  episode_count: 5737 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.825, -15.0]
Step 3295 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 706.0, 1.0]  episode_count: 5739 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.826, -15.0]
Step 3296 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 707.0, 1.0]  episode_count: 5741 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.821, -15.0]
{"total_number_of_episodes": 5742, "number_of_timesteps": 103709, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3297 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 708.0, 1.0]  episode_count: 5742 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.815, -15.0]
Step 3298 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 709.0, 1.0]  episode_count: 5743 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.818, -15.0]
Step 3299 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 710.0, 1.0]  episode_count: 5745 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.82, -15.0]
Step 3300 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 711.0, 1.0]  episode_count: 5746 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.815, -15.0]
Step 3301 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 712.0, 1.0]  episode_count: 5747 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.831, -15.0]
Step 3302 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 713.0, 1.0]  episode_count: 5749 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.846, -15.0]
Step 3303 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 714.0, 1.0]  episode_count: 5750 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.848, -15.0]
{"total_number_of_episodes": 5752, "number_of_timesteps": 103914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3304 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 715.0, 1.0]  episode_count: 5752 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.85, -15.0]
Step 3305 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 716.0, 1.0]  episode_count: 5754 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.845, -15.0]
Step 3306 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 717.0, 1.0]  episode_count: 5755 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.846, -15.0]
Step 3307 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 718.0, 1.0]  episode_count: 5758 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.84, -15.0]
Step 3308 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 719.0, 1.0]  episode_count: 5758 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.835, -15.0]
{"total_number_of_episodes": 5762, "number_of_timesteps": 104104, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3309 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 720.0, 1.0]  episode_count: 5762 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.83, -15.0]
Step 3310 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 721.0, 1.0]  episode_count: 5762 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.845, -15.0]
Step 3311 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 722.0, 1.0]  episode_count: 5767 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.84, -15.0]
Step 3312 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 723.0, 1.0]  episode_count: 5768 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.843, -15.0]
Step 3313 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 724.0, 1.0]  episode_count: 5770 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.837, -15.0]
Step 3314 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 725.0, 1.0]  episode_count: 5771 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.832, -15.0]
{"total_number_of_episodes": 5773, "number_of_timesteps": 104290, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3315 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 726.0, 1.0]  episode_count: 5773 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.827, -15.0]
Step 3316 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 727.0, 1.0]  episode_count: 5775 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.829, -15.0]
Step 3317 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 728.0, 1.0]  episode_count: 5776 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.824, -15.0]
Step 3318 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 729.0, 1.0]  episode_count: 5779 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.819, -15.0]
Step 3319 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 730.0, 1.0]  episode_count: 5781 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.821, -15.0]
{"total_number_of_episodes": 5784, "number_of_timesteps": 104483, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3320 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 731.0, 1.0]  episode_count: 5784 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.823, -15.0]
Step 3321 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 732.0, 1.0]  episode_count: 5785 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.818, -15.0]
Step 3322 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 733.0, 1.0]  episode_count: 5786 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.812, -15.0]
Step 3323 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 734.0, 1.0]  episode_count: 5789 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.807, -15.0]
Step 3324 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 735.0, 1.0]  episode_count: 5790 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.809, -15.0]
Step 3325 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 736.0, 1.0]  episode_count: 5790 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.824, -15.0]
{"total_number_of_episodes": 5795, "number_of_timesteps": 104662, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3326 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 737.0, 1.0]  episode_count: 5795 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.819, -15.0]
Step 3327 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 738.0, 1.0]  episode_count: 5797 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.819, -15.0]
Step 3328 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 739.0, 1.0]  episode_count: 5798 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.821, -15.0]
Step 3329 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 740.0, 1.0]  episode_count: 5802 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.824, -15.0]
Step 3330 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 741.0, 1.0]  episode_count: 5803 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.825, -15.0]
Step 3331 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 742.0, 1.0]  episode_count: 5803 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.82, -15.0]
{"total_number_of_episodes": 5807, "number_of_timesteps": 104848, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3332 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 743.0, 1.0]  episode_count: 5807 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.822, -15.0]
Step 3333 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 744.0, 1.0]  episode_count: 5809 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.817, -15.0]
Step 3334 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 745.0, 1.0]  episode_count: 5809 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.812, -15.0]
Step 3335 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 746.0, 1.0]  episode_count: 5814 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.807, -15.0]
Step 3336 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 747.0, 1.0]  episode_count: 5814 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.822, -15.0]
{"total_number_of_episodes": 5817, "number_of_timesteps": 104968, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3337 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 748.0, 1.0]  episode_count: 5817 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.823, -15.0]
Step 3338 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 749.0, 1.0]  episode_count: 5819 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.824, -15.0]
Step 3339 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 750.0, 1.0]  episode_count: 5822 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.826, -15.0]
Step 3340 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 751.0, 1.0]  episode_count: 5824 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.829, -15.0]
Step 3341 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 752.0, 1.0]  episode_count: 5825 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.831, -15.0]
{"total_number_of_episodes": 5828, "number_of_timesteps": 105140, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3342 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 753.0, 1.0]  episode_count: 5828 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.846, -15.0]
Step 3343 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 754.0, 1.0]  episode_count: 5831 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.841, -15.0]
Step 3344 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 755.0, 1.0]  episode_count: 5831 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.836, -15.0]
Step 3345 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 756.0, 1.0]  episode_count: 5835 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.837, -15.0]
Step 3346 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 757.0, 1.0]  episode_count: 5837 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.838, -15.0]
{"total_number_of_episodes": 5838, "number_of_timesteps": 105299, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3347 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 758.0, 1.0]  episode_count: 5838 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.833, -15.0]
Step 3348 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 759.0, 1.0]  episode_count: 5838 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.828, -15.0]
Step 3349 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 760.0, 1.0]  episode_count: 5841 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.823, -15.0]
Step 3350 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 761.0, 1.0]  episode_count: 5842 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.835, -15.0]
Step 3351 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 762.0, 1.0]  episode_count: 5842 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.83, -15.0]
Step 3352 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 763.0, 1.0]  episode_count: 5844 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.825, -15.0]
Step 3353 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 764.0, 1.0]  episode_count: 5845 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.827, -15.0]
{"total_number_of_episodes": 5848, "number_of_timesteps": 105490, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3354 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 765.0, 1.0]  episode_count: 5848 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.822, -15.0]
Step 3355 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 766.0, 1.0]  episode_count: 5848 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.823, -15.0]
Step 3356 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 767.0, 1.0]  episode_count: 5849 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.825, -15.0]
Step 3357 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 768.0, 1.0]  episode_count: 5852 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.82, -15.0]
Step 3358 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 769.0, 1.0]  episode_count: 5853 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.834, -15.0]
Step 3359 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 770.0, 1.0]  episode_count: 5855 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.849, -15.0]
Step 3360 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 771.0, 1.0]  episode_count: 5855 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.844, -15.0]
{"total_number_of_episodes": 5858, "number_of_timesteps": 105743, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3361 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 772.0, 1.0]  episode_count: 5858 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.849, -15.0]
Step 3362 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 773.0, 1.0]  episode_count: 5860 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.85, -15.0]
Step 3363 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 774.0, 1.0]  episode_count: 5860 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.852, -15.0]
Step 3364 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 775.0, 1.0]  episode_count: 5862 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.853, -15.0]
Step 3365 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 776.0, 1.0]  episode_count: 5864 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.854, -15.0]
Step 3366 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 777.0, 1.0]  episode_count: 5866 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.85, -15.0]
Step 3367 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 778.0, 1.0]  episode_count: 5867 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.85, -15.0]
{"total_number_of_episodes": 5870, "number_of_timesteps": 105964, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3368 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 779.0, 1.0]  episode_count: 5870 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.851, -15.0]
Step 3369 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 780.0, 1.0]  episode_count: 5873 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.847, -15.0]
Step 3370 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 781.0, 1.0]  episode_count: 5875 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.861, -15.0]
Step 3371 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 782.0, 1.0]  episode_count: 5879 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.856, -15.0]
{"total_number_of_episodes": 5881, "number_of_timesteps": 106104, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3372 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 783.0, 1.0]  episode_count: 5881 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.851, -15.0]
Step 3373 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 784.0, 1.0]  episode_count: 5883 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.846, -15.0]
Step 3374 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 785.0, 1.0]  episode_count: 5886 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.85, -15.0]
Step 3375 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 786.0, 1.0]  episode_count: 5889 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.851, -15.0]
Step 3376 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 787.0, 1.0]  episode_count: 5889 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.846, -15.0]
{"total_number_of_episodes": 5892, "number_of_timesteps": 106234, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3377 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 788.0, 1.0]  episode_count: 5892 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.841, -15.0]
Step 3378 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 789.0, 1.0]  episode_count: 5893 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.837, -15.0]
Step 3379 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 790.0, 1.0]  episode_count: 5895 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.837, -15.0]
Step 3380 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 791.0, 1.0]  episode_count: 5895 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.838, -15.0]
Step 3381 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 792.0, 1.0]  episode_count: 5897 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.834, -15.0]
Step 3382 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 793.0, 1.0]  episode_count: 5899 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.835, -15.0]
Step 3383 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 794.0, 1.0]  episode_count: 5901 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.836, -15.0]
{"total_number_of_episodes": 5902, "number_of_timesteps": 106446, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3384 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 795.0, 1.0]  episode_count: 5902 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.838, -15.0]
Step 3385 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 796.0, 1.0]  episode_count: 5902 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.833, -15.0]
Step 3386 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 797.0, 1.0]  episode_count: 5904 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.834, -15.0]
Step 3387 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 798.0, 1.0]  episode_count: 5906 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.829, -15.0]
Step 3388 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 799.0, 1.0]  episode_count: 5908 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.83, -15.0]
Step 3389 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 800.0, 1.0]  episode_count: 5909 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.834, -15.0]
Step 3390 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 801.0, 1.0]  episode_count: 5909 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.838, -15.0]
{"total_number_of_episodes": 5913, "number_of_timesteps": 106679, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3391 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 802.0, 1.0]  episode_count: 5913 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.835, -15.0]
Step 3392 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 803.0, 1.0]  episode_count: 5914 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.837, -15.0]
Step 3393 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 804.0, 1.0]  episode_count: 5915 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.832, -15.0]
Step 3394 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 805.0, 1.0]  episode_count: 5916 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.835, -15.0]
Step 3395 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 806.0, 1.0]  episode_count: 5917 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.835, -15.0]
Step 3396 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 807.0, 1.0]  episode_count: 5920 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.83, -15.0]
Step 3397 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 808.0, 1.0]  episode_count: 5920 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.825, -15.0]
{"total_number_of_episodes": 5923, "number_of_timesteps": 106883, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3398 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 809.0, 1.0]  episode_count: 5923 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.82, -15.0]
Step 3399 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 810.0, 1.0]  episode_count: 5923 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.821, -15.0]
Step 3400 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 811.0, 1.0]  episode_count: 5925 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.816, -15.0]
Step 3401 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 812.0, 1.0]  episode_count: 5928 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.812, -15.0]
Step 3402 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 813.0, 1.0]  episode_count: 5930 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.813, -15.0]
Step 3403 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 814.0, 1.0]  episode_count: 5931 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.809, -15.0]
Step 3404 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 815.0, 1.0]  episode_count: 5931 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.804, -15.0]
{"total_number_of_episodes": 5933, "number_of_timesteps": 107081, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3405 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 816.0, 1.0]  episode_count: 5933 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.799, -15.0]
 episode_count: 5935 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.799, -15.0]
Step 3407 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 818.0, 1.0]  episode_count: 5936 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.794, -15.0]
Step 3408 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 819.0, 1.0]  episode_count: 5936 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.797, -15.0]
Step 3409 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 820.0, 1.0]  episode_count: 5937 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.792, -15.0]
Step 3410 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 821.0, 1.0]  episode_count: 5939 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.788, -15.0]
Step 3411 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 822.0, 1.0]  episode_count: 5939 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.783, -15.0]
Step 3412 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 823.0, 1.0]  episode_count: 5939 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.779, -15.0]
Step 3413 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 824.0, 1.0]  episode_count: 5941 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.779, -15.0]
{"total_number_of_episodes": 5943, "number_of_timesteps": 107311, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3414 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 825.0, 1.0]  episode_count: 5943 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.783, -15.0]
Step 3415 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 826.0, 1.0]  episode_count: 5944 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.779, -15.0]
Step 3416 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 827.0, 1.0]  episode_count: 5946 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.774, -15.0]
Step 3417 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 828.0, 1.0]  episode_count: 5950 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.77, -15.0]
Step 3418 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 829.0, 1.0]  episode_count: 5951 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.765, -15.0]
Step 3419 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 830.0, 1.0]  episode_count: 5952 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.762, -15.0]
{"total_number_of_episodes": 5953, "number_of_timesteps": 107557, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3420 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 831.0, 1.0]  episode_count: 5953 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.757, -15.0]
Step 3421 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 832.0, 1.0]  episode_count: 5955 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.771, -15.0]
Step 3422 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 833.0, 1.0]  episode_count: 5956 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.771, -15.0]
Step 3423 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 834.0, 1.0]  episode_count: 5958 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.771, -15.0]
Step 3424 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 835.0, 1.0]  episode_count: 5960 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.767, -15.0]
Step 3425 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 836.0, 1.0]  episode_count: 5962 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.762, -15.0]
Step 3426 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 837.0, 1.0]  episode_count: 5962 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.764, -15.0]
{"total_number_of_episodes": 5965, "number_of_timesteps": 107803, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3427 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 838.0, 1.0]  episode_count: 5965 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.761, -15.0]
Step 3428 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 839.0, 1.0]  episode_count: 5967 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.774, -15.0]
Step 3429 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 840.0, 1.0]  episode_count: 5968 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.776, -15.0]
Step 3430 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 841.0, 1.0]  episode_count: 5969 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.771, -15.0]
Step 3431 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 842.0, 1.0]  episode_count: 5970 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.779, -15.0]
Step 3432 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 843.0, 1.0]  episode_count: 5972 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.784, -15.0]
Step 3433 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 844.0, 1.0]  episode_count: 5973 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.786, -15.0]
Step 3434 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 845.0, 1.0]  episode_count: 5973 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.789, -15.0]
{"total_number_of_episodes": 5976, "number_of_timesteps": 108015, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3435 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 846.0, 1.0]  episode_count: 5976 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.785, -15.0]
Step 3436 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 847.0, 1.0]  episode_count: 5976 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.784, -15.0]
Step 3437 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 848.0, 1.0]  episode_count: 5977 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.779, -15.0]
Step 3438 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 849.0, 1.0]  episode_count: 5978 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.78, -15.0]
Step 3439 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 850.0, 1.0]  episode_count: 5979 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.78, -15.0]
Step 3440 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 851.0, 1.0]  episode_count: 5981 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.776, -15.0]
Step 3441 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 852.0, 1.0]  episode_count: 5983 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.771, -15.0]
Step 3442 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 853.0, 1.0]  episode_count: 5984 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.772, -15.0]
Step 3443 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 854.0, 1.0]  episode_count: 5985 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.785, -15.0]
{"total_number_of_episodes": 5987, "number_of_timesteps": 108345, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3444 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 855.0, 1.0]  episode_count: 5987 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.786, -15.0]
Step 3445 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 856.0, 1.0]  episode_count: 5987 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.799, -15.0]
Step 3446 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 857.0, 1.0]  episode_count: 5991 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.794, -15.0]
Step 3447 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 858.0, 1.0]  episode_count: 5992 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.79, -15.0]
Step 3448 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 859.0, 1.0]  episode_count: 5994 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.787, -15.0]
Step 3449 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 860.0, 1.0]  episode_count: 5994 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.786, -15.0]
Step 3450 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 861.0, 1.0]  episode_count: 5996 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.781, -15.0]
{"total_number_of_episodes": 5997, "number_of_timesteps": 108498, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3451 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 862.0, 1.0]  episode_count: 5997 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.79, -15.0]
Step 3452 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 863.0, 1.0]  episode_count: 5999 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.792, -15.0]
Step 3453 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 864.0, 1.0]  episode_count: 5999 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.794, -15.0]
Step 3454 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 865.0, 1.0]  episode_count: 6000 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.807, -15.0]
Step 3455 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 866.0, 1.0]  episode_count: 6003 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.808, -15.0]
Step 3456 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 867.0, 1.0]  episode_count: 6004 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.814, -15.0]
Step 3457 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 868.0, 1.0]  episode_count: 6005 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.816, -15.0]
{"total_number_of_episodes": 6007, "number_of_timesteps": 108766, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3458 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 869.0, 1.0]  episode_count: 6007 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.814, -15.0]
Step 3459 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 870.0, 1.0]  episode_count: 6008 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.815, -15.0]
Step 3460 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 871.0, 1.0]  episode_count: 6010 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.816, -15.0]
Step 3461 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 872.0, 1.0]  episode_count: 6010 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.815, -15.0]
Step 3462 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 873.0, 1.0]  episode_count: 6013 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.827, -15.0]
Step 3463 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 874.0, 1.0]  episode_count: 6014 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.823, -15.0]
{"total_number_of_episodes": 6017, "number_of_timesteps": 109006, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3464 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 875.0, 1.0]  episode_count: 6017 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.819, -15.0]
Step 3465 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 876.0, 1.0]  episode_count: 6019 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.816, -15.0]
Step 3466 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 877.0, 1.0]  episode_count: 6019 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.811, -15.0]
Step 3467 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 878.0, 1.0]  episode_count: 6021 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.807, -15.0]
Step 3468 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 879.0, 1.0]  episode_count: 6023 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.807, -15.0]
Step 3469 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 880.0, 1.0]  episode_count: 6025 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.804, -15.0]
{"total_number_of_episodes": 6027, "number_of_timesteps": 109195, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3470 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 881.0, 1.0]  episode_count: 6027 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.8, -15.0]
Step 3471 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 882.0, 1.0]  episode_count: 6028 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.797, -15.0]
Step 3472 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 883.0, 1.0]  episode_count: 6029 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.801, -15.0]
Step 3473 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 884.0, 1.0]  episode_count: 6031 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.803, -15.0]
Step 3474 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 885.0, 1.0]  episode_count: 6032 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.803, -15.0]
Step 3475 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 886.0, 1.0]  episode_count: 6033 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.815, -15.0]
Step 3476 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 887.0, 1.0]  episode_count: 6035 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.818, -15.0]
Step 3477 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 888.0, 1.0]  episode_count: 6036 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.814, -15.0]
{"total_number_of_episodes": 6038, "number_of_timesteps": 109406, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3478 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 889.0, 1.0]  episode_count: 6038 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.821, -15.0]
Step 3479 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 890.0, 1.0]  episode_count: 6040 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.823, -15.0]
Step 3480 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 891.0, 1.0]  episode_count: 6042 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.835, -15.0]
Step 3481 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 892.0, 1.0]  episode_count: 6043 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.848, -15.0]
Step 3482 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 893.0, 1.0]  episode_count: 6044 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.86, -15.0]
Step 3483 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 894.0, 1.0]  episode_count: 6047 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.856, -15.0]
{"total_number_of_episodes": 6050, "number_of_timesteps": 109630, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 895.0, 1.0]  episode_count: 6050 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.868, -15.0]
Step 3485 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 896.0, 1.0]  episode_count: 6051 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.864, -15.0]
Step 3486 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 897.0, 1.0]  episode_count: 6053 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.86, -15.0]
Step 3487 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 898.0, 1.0]  episode_count: 6054 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.855, -15.0]
Step 3488 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 899.0, 1.0]  episode_count: 6055 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.853, -15.0]
Step 3489 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 900.0, 1.0]  episode_count: 6059 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.849, -15.0]
Step 3490 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 901.0, 1.0]  episode_count: 6059 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.861, -15.0]
{"total_number_of_episodes": 6061, "number_of_timesteps": 109831, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3491 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 902.0, 1.0]  episode_count: 6061 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.874, -15.0]
Step 3492 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 903.0, 1.0]  episode_count: 6064 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.882, -15.0]
Step 3493 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 904.0, 1.0]  episode_count: 6065 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.894, -15.0]
Step 3494 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 905.0, 1.0]  episode_count: 6067 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.9, -15.0]
Step 3495 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 906.0, 1.0]  episode_count: 6068 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.895, -15.0]
Step 3496 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 907.0, 1.0]  episode_count: 6069 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.894, -15.0]
{"total_number_of_episodes": 6071, "number_of_timesteps": 110019, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3497 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 908.0, 1.0]  episode_count: 6071 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.906, -15.0]
Step 3498 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 909.0, 1.0]  episode_count: 6073 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.902, -15.0]
Step 3499 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 910.0, 1.0]  episode_count: 6074 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.898, -15.0]
Step 3500 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 911.0, 1.0]  episode_count: 6075 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.896, -15.0]
Step 3501 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 912.0, 1.0]  episode_count: 6077 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.909, -15.0]
Step 3502 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 913.0, 1.0]  episode_count: 6080 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.904, -15.0]
{"total_number_of_episodes": 6081, "number_of_timesteps": 110214, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3503 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 914.0, 1.0]  episode_count: 6081 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.9, -15.0]
Step 3504 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 915.0, 1.0]  episode_count: 6084 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.896, -15.0]
Step 3505 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 916.0, 1.0]  episode_count: 6087 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.895, -15.0]
Step 3506 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 917.0, 1.0]  episode_count: 6089 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.891, -15.0]
Step 3507 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 918.0, 1.0]  episode_count: 6090 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.886, -15.0]
{"total_number_of_episodes": 6094, "number_of_timesteps": 110399, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3508 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 919.0, 1.0]  episode_count: 6094 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.882, -15.0]
Step 3509 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 920.0, 1.0]  episode_count: 6097 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.881, -15.0]
Step 3510 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 921.0, 1.0]  episode_count: 6097 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.878, -15.0]
Step 3511 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 922.0, 1.0]  episode_count: 6101 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.874, -15.0]
Step 3512 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 923.0, 1.0]  episode_count: 6102 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.87, -15.0]
Step 3513 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 924.0, 1.0]  episode_count: 6103 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.87, -15.0]
{"total_number_of_episodes": 6106, "number_of_timesteps": 110577, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3514 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 925.0, 1.0]  episode_count: 6106 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.865, -15.0]
Step 3515 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 926.0, 1.0]  episode_count: 6109 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.865, -15.0]
Step 3516 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 927.0, 1.0]  episode_count: 6109 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.861, -15.0]
Step 3517 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 928.0, 1.0]  episode_count: 6111 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.873, -15.0]
Step 3518 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 929.0, 1.0]  episode_count: 6112 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.885, -15.0]
Step 3519 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 930.0, 1.0]  episode_count: 6113 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.881, -15.0]
Step 3520 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 931.0, 1.0]  episode_count: 6114 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.893, -15.0]
{"total_number_of_episodes": 6116, "number_of_timesteps": 110760, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3521 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 932.0, 1.0]  episode_count: 6116 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.9, -15.0]
Step 3522 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 933.0, 1.0]  episode_count: 6118 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.912, -15.0]
Step 3523 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 934.0, 1.0]  episode_count: 6119 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.908, -15.0]
Step 3524 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 935.0, 1.0]  episode_count: 6120 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.908, -15.0]
Step 3525 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 936.0, 1.0]  episode_count: 6120 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.904, -15.0]
Step 3526 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 937.0, 1.0]  episode_count: 6122 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.916, -15.0]
{"total_number_of_episodes": 6126, "number_of_timesteps": 111006, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3527 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 938.0, 1.0]  episode_count: 6126 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.912, -15.0]
Step 3528 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 939.0, 1.0]  episode_count: 6126 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.923, -15.0]
Step 3529 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 940.0, 1.0]  episode_count: 6127 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.931, -15.0]
Step 3530 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 941.0, 1.0]  episode_count: 6129 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.927, -15.0]
Step 3531 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 942.0, 1.0]  episode_count: 6130 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.939, -15.0]
Step 3532 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 943.0, 1.0]  episode_count: 6130 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.935, -15.0]
Step 3533 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 944.0, 1.0]  episode_count: 6130 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.947, -15.0]
Step 3534 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 945.0, 1.0]  episode_count: 6133 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.948, -15.0]
Step 3535 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 946.0, 1.0]  episode_count: 6135 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.952, -15.0]
Step 3536 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 947.0, 1.0]  episode_count: 6135 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.948, -15.0]
Step 3537 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 948.0, 1.0]  episode_count: 6135 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.951, -15.0]
{"total_number_of_episodes": 6136, "number_of_timesteps": 111243, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3538 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 949.0, 1.0]  episode_count: 6136 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.962, -15.0]
Step 3539 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 950.0, 1.0]  episode_count: 6139 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.958, -15.0]
Step 3540 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 951.0, 1.0]  episode_count: 6139 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.97, -15.0]
Step 3541 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 952.0, 1.0]  episode_count: 6140 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.971, -15.0]
Step 3542 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 953.0, 1.0]  episode_count: 6141 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.967, -15.0]
Step 3543 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 954.0, 1.0]  episode_count: 6141 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.968, -15.0]
Step 3544 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 955.0, 1.0]  episode_count: 6144 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.967, -15.0]
Step 3545 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 956.0, 1.0]  episode_count: 6145 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.979, -15.0]
Step 3546 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 957.0, 1.0]  episode_count: 6145 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.99, -15.0]
{"total_number_of_episodes": 6146, "number_of_timesteps": 111559, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3547 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 958.0, 1.0]  episode_count: 6146 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.986, -15.0]
Step 3548 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 959.0, 1.0]  episode_count: 6146 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.998, -15.0]
Step 3549 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 960.0, 1.0]  episode_count: 6146 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.993, -15.0]
Step 3550 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 961.0, 1.0]  episode_count: 6148 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.995, -15.0]
Step 3551 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 962.0, 1.0]  episode_count: 6149 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.991, -15.0]
Step 3552 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 963.0, 1.0]  episode_count: 6150 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.002, -15.0]
Step 3553 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 964.0, 1.0]  episode_count: 6151 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.003, -15.0]
Step 3554 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 965.0, 1.0]  episode_count: 6154 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.999, -15.0]
Step 3555 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 966.0, 1.0]  episode_count: 6154 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.001, -15.0]
{"total_number_of_episodes": 6156, "number_of_timesteps": 111915, "per_episode_reward": 10.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 3556 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 967.0, 1.0]  episode_count: 6156 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.001, -15.0]
Step 3557 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 968.0, 1.0]  episode_count: 6157 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.999, -15.0]
Step 3558 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 969.0, 1.0]  episode_count: 6160 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.0, -15.0]
Step 3559 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 970.0, 1.0]  episode_count: 6161 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.996, -15.0]
Step 3560 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 971.0, 1.0]  episode_count: 6162 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.992, -15.0]
Step 3561 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 972.0, 1.0]  episode_count: 6163 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.988, -15.0]
{"total_number_of_episodes": 6166, "number_of_timesteps": 112101, "per_episode_reward": 10.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 3562 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 973.0, 1.0]  episode_count: 6166 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.99, -15.0]
Step 3563 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 974.0, 1.0]  episode_count: 6167 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.986, -15.0]
Step 3564 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 975.0, 1.0]  episode_count: 6168 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.997, -15.0]
Step 3565 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 976.0, 1.0]  episode_count: 6170 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.0, -15.0]
Step 3566 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 977.0, 1.0]  episode_count: 6171 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -3.996, -15.0]
Step 3567 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 978.0, 1.0]  episode_count: 6173 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.007, -15.0]
Step 3568 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 979.0, 1.0]  episode_count: 6174 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.019, -15.0]
Step 3569 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 980.0, 1.0]  episode_count: 6174 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.021, -15.0]
Step 3570 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 981.0, 1.0]  episode_count: 6175 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.032, -15.0]
{"total_number_of_episodes": 6177, "number_of_timesteps": 112352, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
Step 3571 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 982.0, 1.0]  episode_count: 6177 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.036, -15.0]
Step 3572 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 983.0, 1.0]  episode_count: 6179 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.032, -15.0]
Step 3573 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 984.0, 1.0]  episode_count: 6181 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.028, -15.0]
Step 3574 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 985.0, 1.0]  episode_count: 6182 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.03, -15.0]
Step 3575 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 986.0, 1.0]  episode_count: 6183 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.029, -15.0]
Step 3576 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 987.0, 1.0]  episode_count: 6185 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.025, -15.0]
{"total_number_of_episodes": 6187, "number_of_timesteps": 112564, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 3577 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 988.0, 1.0]  episode_count: 6187 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.027, -15.0]
Step 3578 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 989.0, 1.0]  episode_count: 6188 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.029, -15.0]
Step 3579 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 990.0, 1.0]  episode_count: 6190 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.025, -15.0]
Step 3580 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 991.0, 1.0]  episode_count: 6191 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.021, -15.0]
Step 3581 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 992.0, 1.0]  episode_count: 6191 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.021, -15.0]
Step 3582 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 993.0, 1.0]  episode_count: 6193 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.023, -15.0]
Step 3583 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 994.0, 1.0]  episode_count: 6194 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.019, -15.0]
{"total_number_of_episodes": 6197, "number_of_timesteps": 112826, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 3584 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 995.0, 1.0]  episode_count: 6197 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.03, -15.0]
Step 3585 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 996.0, 1.0]  episode_count: 6199 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.028, -15.0]
Step 3586 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 997.0, 1.0]  episode_count: 6199 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.027, -15.0]
Step 3587 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 998.0, 1.0]  episode_count: 6201 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.023, -15.0]
Step 3588 5 visits [89.0, 1000.0, 2.0, 4.0, 1000.0, 999.0, 1.0]  episode_count: 6202 q_vals: [-4.278, -inf, -7.5, -6.324, -inf, -4.025, -15.0]
Step 3589 5 visits [0.0, 1000.0, 0.0, 0.0, 1000.0, 1000.0, 0.0]  episode_count: 6205 q_vals: [0.0, -inf, 0.0, 0.0, -inf, -inf, 0.0]
{"total_number_of_episodes": 6207, "number_of_timesteps": 113009, "per_episode_reward": 8.71, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 2.142857142857144},
{"total_number_of_episodes": 6218, "number_of_timesteps": 113246, "per_episode_reward": 8.71, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 2.142857142857144},
{"total_number_of_episodes": 6228, "number_of_timesteps": 113470, "per_episode_reward": 8.71, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 2.142857142857144},
{"total_number_of_episodes": 6239, "number_of_timesteps": 113714, "per_episode_reward": 8.71, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 2.142857142857144},
{"total_number_of_episodes": 6251, "number_of_timesteps": 114062, "per_episode_reward": 8.71, "episode_reward_trend_value": -0.023015873015873035, "biggest_recent_change": 2.142857142857144},
{"total_number_of_episodes": 6261, "number_of_timesteps": 114356, "per_episode_reward": 8.71, "episode_reward_trend_value": -0.023015873015873035, "biggest_recent_change": 2.142857142857144},
{"total_number_of_episodes": 6273, "number_of_timesteps": 114665, "per_episode_reward": 8.71, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 2.142857142857144},
{"total_number_of_episodes": 6285, "number_of_timesteps": 114947, "per_episode_reward": 8.71, "episode_reward_trend_value": -0.023809523809523826, "biggest_recent_change": 2.142857142857144},
{"total_number_of_episodes": 6295, "number_of_timesteps": 115160, "per_episode_reward": 8.71, "episode_reward_trend_value": -0.023809523809523826, "biggest_recent_change": 2.142857142857144},
{"total_number_of_episodes": 6306, "number_of_timesteps": 115476, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6317, "number_of_timesteps": 115891, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6327, "number_of_timesteps": 116143, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6337, "number_of_timesteps": 116474, "per_episode_reward": 8.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 6348, "number_of_timesteps": 116726, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 6358, "number_of_timesteps": 117021, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 6368, "number_of_timesteps": 117250, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 6379, "number_of_timesteps": 117566, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 6391, "number_of_timesteps": 117927, "per_episode_reward": 8.93, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 6403, "number_of_timesteps": 118241, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 6413, "number_of_timesteps": 118459, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 6423, "number_of_timesteps": 118768, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 6433, "number_of_timesteps": 119005, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6443, "number_of_timesteps": 119255, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6453, "number_of_timesteps": 119517, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6463, "number_of_timesteps": 119810, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6474, "number_of_timesteps": 120157, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6485, "number_of_timesteps": 120495, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6496, "number_of_timesteps": 120774, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6507, "number_of_timesteps": 121033, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6517, "number_of_timesteps": 121419, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6528, "number_of_timesteps": 121678, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6538, "number_of_timesteps": 121915, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6548, "number_of_timesteps": 122260, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6558, "number_of_timesteps": 122457, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6570, "number_of_timesteps": 122733, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6580, "number_of_timesteps": 122954, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6591, "number_of_timesteps": 123255, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6601, "number_of_timesteps": 123493, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6611, "number_of_timesteps": 123782, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6621, "number_of_timesteps": 124014, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6631, "number_of_timesteps": 124211, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6642, "number_of_timesteps": 124535, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6652, "number_of_timesteps": 124914, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6662, "number_of_timesteps": 125112, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6672, "number_of_timesteps": 125415, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6683, "number_of_timesteps": 125764, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6693, "number_of_timesteps": 126039, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6705, "number_of_timesteps": 126434, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6716, "number_of_timesteps": 126701, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6726, "number_of_timesteps": 126947, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6737, "number_of_timesteps": 127256, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6747, "number_of_timesteps": 127507, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6757, "number_of_timesteps": 127761, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6768, "number_of_timesteps": 128054, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6778, "number_of_timesteps": 128340, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6788, "number_of_timesteps": 128723, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6800, "number_of_timesteps": 129023, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6810, "number_of_timesteps": 129244, "per_episode_reward": 9.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6820, "number_of_timesteps": 129506, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6831, "number_of_timesteps": 129891, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6841, "number_of_timesteps": 130115, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6853, "number_of_timesteps": 130506, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6863, "number_of_timesteps": 130850, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6875, "number_of_timesteps": 131310, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6885, "number_of_timesteps": 131717, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6896, "number_of_timesteps": 132042, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6906, "number_of_timesteps": 132451, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6916, "number_of_timesteps": 132844, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6926, "number_of_timesteps": 133394, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6936, "number_of_timesteps": 133843, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6946, "number_of_timesteps": 134119, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6956, "number_of_timesteps": 134548, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6966, "number_of_timesteps": 134848, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6976, "number_of_timesteps": 135088, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6989, "number_of_timesteps": 135501, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6999, "number_of_timesteps": 135809, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7010, "number_of_timesteps": 136174, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7020, "number_of_timesteps": 136406, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7030, "number_of_timesteps": 136862, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7040, "number_of_timesteps": 137310, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7051, "number_of_timesteps": 137663, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7061, "number_of_timesteps": 137999, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7071, "number_of_timesteps": 138415, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7081, "number_of_timesteps": 138857, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7091, "number_of_timesteps": 139284, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7101, "number_of_timesteps": 139684, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7111, "number_of_timesteps": 140214, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7121, "number_of_timesteps": 140749, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7132, "number_of_timesteps": 141418, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7142, "number_of_timesteps": 141764, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7152, "number_of_timesteps": 142155, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7163, "number_of_timesteps": 142458, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7174, "number_of_timesteps": 143047, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7184, "number_of_timesteps": 143574, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7194, "number_of_timesteps": 144165, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7204, "number_of_timesteps": 144617, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7214, "number_of_timesteps": 145499, "per_episode_reward": 9.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 7224, "number_of_timesteps": 145806, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 7234, "number_of_timesteps": 146466, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 7244, "number_of_timesteps": 146988, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 7255, "number_of_timesteps": 147482, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 7266, "number_of_timesteps": 148157, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 7276, "number_of_timesteps": 148892, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 7286, "number_of_timesteps": 149487, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 7298, "number_of_timesteps": 150182, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 7308, "number_of_timesteps": 150919, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 7319, "number_of_timesteps": 151427, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7329, "number_of_timesteps": 152238, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7339, "number_of_timesteps": 152934, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7349, "number_of_timesteps": 154063, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7360, "number_of_timesteps": 155026, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7370, "number_of_timesteps": 156134, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7380, "number_of_timesteps": 157379, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7390, "number_of_timesteps": 158576, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7400, "number_of_timesteps": 159694, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7410, "number_of_timesteps": 160624, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7421, "number_of_timesteps": 161899, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7431, "number_of_timesteps": 163556, "per_episode_reward": 9.5, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7441, "number_of_timesteps": 164691, "per_episode_reward": 9.5, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7451, "number_of_timesteps": 166219, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 7461, "number_of_timesteps": 167425, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 7471, "number_of_timesteps": 168768, "per_episode_reward": 9.64, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 7482, "number_of_timesteps": 169848, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 7493, "number_of_timesteps": 171300, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 7503, "number_of_timesteps": 173101, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 7514, "number_of_timesteps": 174542, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 7525, "number_of_timesteps": 175883, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 7535, "number_of_timesteps": 177050, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 7545, "number_of_timesteps": 178711, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 7555, "number_of_timesteps": 180295, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 7565, "number_of_timesteps": 182146, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 7575, "number_of_timesteps": 184144, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7585, "number_of_timesteps": 185593, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7595, "number_of_timesteps": 187824, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7605, "number_of_timesteps": 189613, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7616, "number_of_timesteps": 190843, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7626, "number_of_timesteps": 191562, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7637, "number_of_timesteps": 193283, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7647, "number_of_timesteps": 194588, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7657, "number_of_timesteps": 195624, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7668, "number_of_timesteps": 197214, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7679, "number_of_timesteps": 198656, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7691, "number_of_timesteps": 200730, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7701, "number_of_timesteps": 202649, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7711, "number_of_timesteps": 204045, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7721, "number_of_timesteps": 205540, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7731, "number_of_timesteps": 207244, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7741, "number_of_timesteps": 208551, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7751, "number_of_timesteps": 209931, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7761, "number_of_timesteps": 211815, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7771, "number_of_timesteps": 213106, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7781, "number_of_timesteps": 215159, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7791, "number_of_timesteps": 216193, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7801, "number_of_timesteps": 217413, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7811, "number_of_timesteps": 218967, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7821, "number_of_timesteps": 220538, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7831, "number_of_timesteps": 222503, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7841, "number_of_timesteps": 224478, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7851, "number_of_timesteps": 225636, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 7861, "number_of_timesteps": 226516, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 7871, "number_of_timesteps": 228007, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 7881, "number_of_timesteps": 229319, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 7891, "number_of_timesteps": 230298, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 7901, "number_of_timesteps": 230877, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 7911, "number_of_timesteps": 231767, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 7921, "number_of_timesteps": 233515, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 7931, "number_of_timesteps": 234696, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 7941, "number_of_timesteps": 235806, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7951, "number_of_timesteps": 236370, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7961, "number_of_timesteps": 236751, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7971, "number_of_timesteps": 238491, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7981, "number_of_timesteps": 240389, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7991, "number_of_timesteps": 241568, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8001, "number_of_timesteps": 242222, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8011, "number_of_timesteps": 243348, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8021, "number_of_timesteps": 244033, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8031, "number_of_timesteps": 244571, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8041, "number_of_timesteps": 245771, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8051, "number_of_timesteps": 247067, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8061, "number_of_timesteps": 248070, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8071, "number_of_timesteps": 249039, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8081, "number_of_timesteps": 249988, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8091, "number_of_timesteps": 250516, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8101, "number_of_timesteps": 251182, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8111, "number_of_timesteps": 251851, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8122, "number_of_timesteps": 252646, "per_episode_reward": 9.93, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8132, "number_of_timesteps": 253664, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 8142, "number_of_timesteps": 255604, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 8152, "number_of_timesteps": 257564, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 8162, "number_of_timesteps": 258928, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 8172, "number_of_timesteps": 260106, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 8182, "number_of_timesteps": 261621, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 8192, "number_of_timesteps": 263034, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 8202, "number_of_timesteps": 264037, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 8212, "number_of_timesteps": 264969, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 8222, "number_of_timesteps": 265378, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 8232, "number_of_timesteps": 266135, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8243, "number_of_timesteps": 266925, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8253, "number_of_timesteps": 267303, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8263, "number_of_timesteps": 268170, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8273, "number_of_timesteps": 268877, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8283, "number_of_timesteps": 269804, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8293, "number_of_timesteps": 270922, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8303, "number_of_timesteps": 272264, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8313, "number_of_timesteps": 273690, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8323, "number_of_timesteps": 275166, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8333, "number_of_timesteps": 276473, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8343, "number_of_timesteps": 277799, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8353, "number_of_timesteps": 278785, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8363, "number_of_timesteps": 280083, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8373, "number_of_timesteps": 282549, "per_episode_reward": 10.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8383, "number_of_timesteps": 285422, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8393, "number_of_timesteps": 287555, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8403, "number_of_timesteps": 290666, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8413, "number_of_timesteps": 293149, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8423, "number_of_timesteps": 296223, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8433, "number_of_timesteps": 299093, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8444, "number_of_timesteps": 302523, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8454, "number_of_timesteps": 305597, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8464, "number_of_timesteps": 308587, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8474, "number_of_timesteps": 312723, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8484, "number_of_timesteps": 316507, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8494, "number_of_timesteps": 320618, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8504, "number_of_timesteps": 324734, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8514, "number_of_timesteps": 328317, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8524, "number_of_timesteps": 332755, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8534, "number_of_timesteps": 337059, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8544, "number_of_timesteps": 340210, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 8554, "number_of_timesteps": 344566, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8564, "number_of_timesteps": 348850, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8574, "number_of_timesteps": 353219, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8585, "number_of_timesteps": 357160, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8595, "number_of_timesteps": 360450, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8605, "number_of_timesteps": 364027, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8615, "number_of_timesteps": 367947, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8625, "number_of_timesteps": 371828, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8635, "number_of_timesteps": 376338, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8645, "number_of_timesteps": 380751, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8655, "number_of_timesteps": 385540, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8666, "number_of_timesteps": 390271, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8676, "number_of_timesteps": 395099, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 8686, "number_of_timesteps": 399984, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8696, "number_of_timesteps": 404633, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8706, "number_of_timesteps": 409212, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8716, "number_of_timesteps": 413548, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8726, "number_of_timesteps": 417925, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8736, "number_of_timesteps": 422391, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8746, "number_of_timesteps": 426877, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8756, "number_of_timesteps": 431833, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8766, "number_of_timesteps": 436527, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8776, "number_of_timesteps": 441292, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8786, "number_of_timesteps": 445776, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8796, "number_of_timesteps": 450103, "per_episode_reward": 10.64, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8806, "number_of_timesteps": 454811, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8816, "number_of_timesteps": 459311, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8826, "number_of_timesteps": 464311, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8836, "number_of_timesteps": 469217, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 8846, "number_of_timesteps": 474117, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 8856, "number_of_timesteps": 479117, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 8866, "number_of_timesteps": 484117, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 8876, "number_of_timesteps": 488970, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 8886, "number_of_timesteps": 493912, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 8896, "number_of_timesteps": 498678, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 8906, "number_of_timesteps": 502795, "per_episode_reward": 10.93, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 8916, "number_of_timesteps": 506881, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 8926, "number_of_timesteps": 511881, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8936, "number_of_timesteps": 516825, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8946, "number_of_timesteps": 521825, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8956, "number_of_timesteps": 526753, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8966, "number_of_timesteps": 531571, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8976, "number_of_timesteps": 536571, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8986, "number_of_timesteps": 541571, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8996, "number_of_timesteps": 546163, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9006, "number_of_timesteps": 550918, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9016, "number_of_timesteps": 555918, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9026, "number_of_timesteps": 559268, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9036, "number_of_timesteps": 562843, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9046, "number_of_timesteps": 567843, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9057, "number_of_timesteps": 573086, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9067, "number_of_timesteps": 577717, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9077, "number_of_timesteps": 582365, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9087, "number_of_timesteps": 586849, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9097, "number_of_timesteps": 591628, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9107, "number_of_timesteps": 596628, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9117, "number_of_timesteps": 601582, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9127, "number_of_timesteps": 606079, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9137, "number_of_timesteps": 610739, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9147, "number_of_timesteps": 615262, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9157, "number_of_timesteps": 619940, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9167, "number_of_timesteps": 624204, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9177, "number_of_timesteps": 629204, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9187, "number_of_timesteps": 634187, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9197, "number_of_timesteps": 639187, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9207, "number_of_timesteps": 644091, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9217, "number_of_timesteps": 649091, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9227, "number_of_timesteps": 653972, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 9237, "number_of_timesteps": 658972, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9247, "number_of_timesteps": 663473, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9257, "number_of_timesteps": 668137, "per_episode_reward": 11.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9267, "number_of_timesteps": 673092, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9277, "number_of_timesteps": 678092, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9287, "number_of_timesteps": 682807, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9297, "number_of_timesteps": 687807, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},

{"total_number_of_episodes": 9307, "number_of_timesteps": 692696, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9317, "number_of_timesteps": 697610, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},

{"total_number_of_episodes": 9327, "number_of_timesteps": 702034, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9337, "number_of_timesteps": 707031, "per_episode_reward": 11.36, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9347, "number_of_timesteps": 711803, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9357, "number_of_timesteps": 716803, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9367, "number_of_timesteps": 721803, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9377, "number_of_timesteps": 726803, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9387, "number_of_timesteps": 731033, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9397, "number_of_timesteps": 735849, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9407, "number_of_timesteps": 740849, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9417, "number_of_timesteps": 745849, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9427, "number_of_timesteps": 750656, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9437, "number_of_timesteps": 755656, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9447, "number_of_timesteps": 760158, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9457, "number_of_timesteps": 764886, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9467, "number_of_timesteps": 769403, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9477, "number_of_timesteps": 774012, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9487, "number_of_timesteps": 778522, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9497, "number_of_timesteps": 783522, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9507, "number_of_timesteps": 788356, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9517, "number_of_timesteps": 792930, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9527, "number_of_timesteps": 797727, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9537, "number_of_timesteps": 802573, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9547, "number_of_timesteps": 807573, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9557, "number_of_timesteps": 812139, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9567, "number_of_timesteps": 816750, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9577, "number_of_timesteps": 821515, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9587, "number_of_timesteps": 826484, "per_episode_reward": 11.64, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9597, "number_of_timesteps": 831484, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9607, "number_of_timesteps": 835979, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9617, "number_of_timesteps": 840740, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9627, "number_of_timesteps": 844988, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9637, "number_of_timesteps": 849988, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9647, "number_of_timesteps": 854938, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9657, "number_of_timesteps": 859938, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9667, "number_of_timesteps": 864938, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9677, "number_of_timesteps": 869911, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9687, "number_of_timesteps": 874911, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9697, "number_of_timesteps": 879911, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9707, "number_of_timesteps": 884879, "per_episode_reward": 11.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9717, "number_of_timesteps": 889879, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9727, "number_of_timesteps": 894879, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9737, "number_of_timesteps": 899879, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9747, "number_of_timesteps": 904750, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9757, "number_of_timesteps": 909750, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9767, "number_of_timesteps": 914750, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9777, "number_of_timesteps": 919421, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9787, "number_of_timesteps": 923936, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9797, "number_of_timesteps": 928832, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9807, "number_of_timesteps": 933645, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9817, "number_of_timesteps": 938328, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9827, "number_of_timesteps": 943231, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9837, "number_of_timesteps": 948231, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 9847, "number_of_timesteps": 953019, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9857, "number_of_timesteps": 957967, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9867, "number_of_timesteps": 962869, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9877, "number_of_timesteps": 967869, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9887, "number_of_timesteps": 972869, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9897, "number_of_timesteps": 977780, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9907, "number_of_timesteps": 982780, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9917, "number_of_timesteps": 987780, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9927, "number_of_timesteps": 992587, "per_episode_reward": 12.07, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9937, "number_of_timesteps": 997293, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9947, "number_of_timesteps": 1002293, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9957, "number_of_timesteps": 1007293, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9967, "number_of_timesteps": 1012293, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9977, "number_of_timesteps": 1017293, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 9987, "number_of_timesteps": 1022293, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9997, "number_of_timesteps": 1027190, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10007, "number_of_timesteps": 1032174, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10017, "number_of_timesteps": 1037038, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10027, "number_of_timesteps": 1042038, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10037, "number_of_timesteps": 1047038, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10047, "number_of_timesteps": 1051907, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10057, "number_of_timesteps": 1056520, "per_episode_reward": 12.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10067, "number_of_timesteps": 1061484, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10077, "number_of_timesteps": 1066484, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},

{"total_number_of_episodes": 10087, "number_of_timesteps": 1071169, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10097, "number_of_timesteps": 1076098, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10107, "number_of_timesteps": 1081098, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10117, "number_of_timesteps": 1085886, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10127, "number_of_timesteps": 1090464, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10137, "number_of_timesteps": 1095464, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10147, "number_of_timesteps": 1100424, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10157, "number_of_timesteps": 1105424, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10167, "number_of_timesteps": 1110424, "per_episode_reward": 12.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10177, "number_of_timesteps": 1115332, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 10187, "number_of_timesteps": 1120076, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10197, "number_of_timesteps": 1124994, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10207, "number_of_timesteps": 1129994, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10217, "number_of_timesteps": 1134818, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10227, "number_of_timesteps": 1139818, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10237, "number_of_timesteps": 1144818, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10247, "number_of_timesteps": 1149818, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10257, "number_of_timesteps": 1154676, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10267, "number_of_timesteps": 1159596, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10277, "number_of_timesteps": 1164596, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10287, "number_of_timesteps": 1169596, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10297, "number_of_timesteps": 1174461, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10307, "number_of_timesteps": 1179252, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 10317, "number_of_timesteps": 1184252, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10327, "number_of_timesteps": 1189252, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10337, "number_of_timesteps": 1193978, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10347, "number_of_timesteps": 1198224, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10357, "number_of_timesteps": 1202793, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10367, "number_of_timesteps": 1207529, "per_episode_reward": 12.64, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10377, "number_of_timesteps": 1212529, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10387, "number_of_timesteps": 1217462, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10397, "number_of_timesteps": 1222290, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10407, "number_of_timesteps": 1227290, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10417, "number_of_timesteps": 1232128, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10427, "number_of_timesteps": 1236626, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10437, "number_of_timesteps": 1241539, "per_episode_reward": 12.79, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10447, "number_of_timesteps": 1246510, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10457, "number_of_timesteps": 1251093, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10467, "number_of_timesteps": 1256093, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10477, "number_of_timesteps": 1261093, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10487, "number_of_timesteps": 1265978, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10497, "number_of_timesteps": 1270978, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10507, "number_of_timesteps": 1274652, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10517, "number_of_timesteps": 1279424, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10527, "number_of_timesteps": 1284334, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10537, "number_of_timesteps": 1289063, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10547, "number_of_timesteps": 1293666, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10557, "number_of_timesteps": 1298520, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10567, "number_of_timesteps": 1303113, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10577, "number_of_timesteps": 1307993, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10587, "number_of_timesteps": 1312993, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10597, "number_of_timesteps": 1317871, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10607, "number_of_timesteps": 1322694, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10618, "number_of_timesteps": 1328037, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10628, "number_of_timesteps": 1333037, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10639, "number_of_timesteps": 1338455, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10649, "number_of_timesteps": 1343039, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10659, "number_of_timesteps": 1347883, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10669, "number_of_timesteps": 1352564, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10679, "number_of_timesteps": 1357564, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10689, "number_of_timesteps": 1362305, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10699, "number_of_timesteps": 1367305, "per_episode_reward": 12.93, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10709, "number_of_timesteps": 1372305, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10719, "number_of_timesteps": 1377154, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10729, "number_of_timesteps": 1382154, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10739, "number_of_timesteps": 1387154, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10749, "number_of_timesteps": 1391979, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10759, "number_of_timesteps": 1396979, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10769, "number_of_timesteps": 1401979, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10779, "number_of_timesteps": 1406979, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10789, "number_of_timesteps": 1411355, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10799, "number_of_timesteps": 1415692, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10809, "number_of_timesteps": 1420465, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10819, "number_of_timesteps": 1425465, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10829, "number_of_timesteps": 1430301, "per_episode_reward": 13.21, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10839, "number_of_timesteps": 1435301, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10849, "number_of_timesteps": 1439640, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10859, "number_of_timesteps": 1444400, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10869, "number_of_timesteps": 1448531, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10879, "number_of_timesteps": 1453135, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10889, "number_of_timesteps": 1458135, "per_episode_reward": 13.36, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10899, "number_of_timesteps": 1463117, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10909, "number_of_timesteps": 1468117, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10919, "number_of_timesteps": 1473117, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10929, "number_of_timesteps": 1478117, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10939, "number_of_timesteps": 1483117, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10949, "number_of_timesteps": 1488117, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 10959, "number_of_timesteps": 1492789, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10969, "number_of_timesteps": 1497789, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10979, "number_of_timesteps": 1502789, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 10989, "number_of_timesteps": 1507789, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10999, "number_of_timesteps": 1512631, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11009, "number_of_timesteps": 1517631, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11019, "number_of_timesteps": 1522631, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11029, "number_of_timesteps": 1527628, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11039, "number_of_timesteps": 1532628, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11049, "number_of_timesteps": 1537628, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11059, "number_of_timesteps": 1542628, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11069, "number_of_timesteps": 1547440, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11079, "number_of_timesteps": 1552440, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11089, "number_of_timesteps": 1557317, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11099, "number_of_timesteps": 1562317, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11109, "number_of_timesteps": 1567317, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11119, "number_of_timesteps": 1572317, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11129, "number_of_timesteps": 1577005, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11139, "number_of_timesteps": 1581288, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 11149, "number_of_timesteps": 1586288, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 11159, "number_of_timesteps": 1591148, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 11169, "number_of_timesteps": 1596148, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 11179, "number_of_timesteps": 1601148, "per_episode_reward": 13.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11189, "number_of_timesteps": 1606070, "per_episode_reward": 13.93, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11199, "number_of_timesteps": 1611070, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11209, "number_of_timesteps": 1615799, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11219, "number_of_timesteps": 1620799, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11229, "number_of_timesteps": 1625711, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11239, "number_of_timesteps": 1630225, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11249, "number_of_timesteps": 1635225, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11259, "number_of_timesteps": 1640225, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11269, "number_of_timesteps": 1645225, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11279, "number_of_timesteps": 1650225, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11289, "number_of_timesteps": 1655225, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11299, "number_of_timesteps": 1660225, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11309, "number_of_timesteps": 1665225, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11319, "number_of_timesteps": 1670001, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11329, "number_of_timesteps": 1674859, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11339, "number_of_timesteps": 1679859, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11349, "number_of_timesteps": 1684859, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11359, "number_of_timesteps": 1689606, "per_episode_reward": 14.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11369, "number_of_timesteps": 1694606, "per_episode_reward": 14.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 11379, "number_of_timesteps": 1699606, "per_episode_reward": 14.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11389, "number_of_timesteps": 1704509, "per_episode_reward": 14.21, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11399, "number_of_timesteps": 1709509, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11409, "number_of_timesteps": 1714509, "per_episode_reward": 14.36, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11419, "number_of_timesteps": 1719162, "per_episode_reward": 14.43, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11429, "number_of_timesteps": 1723767, "per_episode_reward": 14.43, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11439, "number_of_timesteps": 1728596, "per_episode_reward": 14.43, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11450, "number_of_timesteps": 1734081, "per_episode_reward": 14.43, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11460, "number_of_timesteps": 1739081, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11471, "number_of_timesteps": 1744581, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11481, "number_of_timesteps": 1749468, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11492, "number_of_timesteps": 1754848, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11502, "number_of_timesteps": 1759637, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11512, "number_of_timesteps": 1764332, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11522, "number_of_timesteps": 1769332, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11532, "number_of_timesteps": 1774075, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11542, "number_of_timesteps": 1778797, "per_episode_reward": 14.64, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 11552, "number_of_timesteps": 1783797, "per_episode_reward": 14.71, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11562, "number_of_timesteps": 1788797, "per_episode_reward": 14.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11572, "number_of_timesteps": 1793797, "per_episode_reward": 14.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11582, "number_of_timesteps": 1798579, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11592, "number_of_timesteps": 1803579, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11602, "number_of_timesteps": 1808579, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11612, "number_of_timesteps": 1813242, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11622, "number_of_timesteps": 1818242, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11632, "number_of_timesteps": 1823242, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11642, "number_of_timesteps": 1828242, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11652, "number_of_timesteps": 1833242, "per_episode_reward": 14.93, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11662, "number_of_timesteps": 1838242, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11672, "number_of_timesteps": 1843242, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11682, "number_of_timesteps": 1848209, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11692, "number_of_timesteps": 1853197, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11702, "number_of_timesteps": 1858197, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11712, "number_of_timesteps": 1862821, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11722, "number_of_timesteps": 1867686, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11732, "number_of_timesteps": 1872686, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11742, "number_of_timesteps": 1877686, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11752, "number_of_timesteps": 1882686, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11762, "number_of_timesteps": 1887462, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11772, "number_of_timesteps": 1892462, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11782, "number_of_timesteps": 1897462, "per_episode_reward": 15.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11792, "number_of_timesteps": 1902327, "per_episode_reward": 15.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11802, "number_of_timesteps": 1907327, "per_episode_reward": 15.21, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11812, "number_of_timesteps": 1912327, "per_episode_reward": 15.29, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11822, "number_of_timesteps": 1917256, "per_episode_reward": 15.29, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11832, "number_of_timesteps": 1922256, "per_episode_reward": 15.36, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11842, "number_of_timesteps": 1927256, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.006349206349206346, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 11852, "number_of_timesteps": 1931934, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.006349206349206346, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 11862, "number_of_timesteps": 1936934, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.006349206349206346, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 11872, "number_of_timesteps": 1941934, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 11883, "number_of_timesteps": 1947289, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 11893, "number_of_timesteps": 1952289, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 11904, "number_of_timesteps": 1957789, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 11914, "number_of_timesteps": 1962789, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 11925, "number_of_timesteps": 1968289, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.21428571428571352},
{"total_number_of_episodes": 11935, "number_of_timesteps": 1973289, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11946, "number_of_timesteps": 1978789, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11956, "number_of_timesteps": 1983789, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 11966, "number_of_timesteps": 1988771, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11976, "number_of_timesteps": 1993771, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 11987, "number_of_timesteps": 1999271, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11997, "number_of_timesteps": 2004036, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12007, "number_of_timesteps": 2008892, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 12017, "number_of_timesteps": 2013720, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 12027, "number_of_timesteps": 2018720, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 12037, "number_of_timesteps": 2023570, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 12047, "number_of_timesteps": 2028570, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 12057, "number_of_timesteps": 2033570, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.006349206349206346, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 12067, "number_of_timesteps": 2038570, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.006349206349206346, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 12077, "number_of_timesteps": 2043143, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.006349206349206346, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 12087, "number_of_timesteps": 2048143, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 12097, "number_of_timesteps": 2053143, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12107, "number_of_timesteps": 2058143, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12117, "number_of_timesteps": 2063143, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12127, "number_of_timesteps": 2068143, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12137, "number_of_timesteps": 2073143, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12147, "number_of_timesteps": 2077853, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12157, "number_of_timesteps": 2082812, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12167, "number_of_timesteps": 2087812, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12177, "number_of_timesteps": 2092718, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12187, "number_of_timesteps": 2097718, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12197, "number_of_timesteps": 2102718, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12207, "number_of_timesteps": 2107716, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12217, "number_of_timesteps": 2112716, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12227, "number_of_timesteps": 2117713, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12237, "number_of_timesteps": 2122713, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12247, "number_of_timesteps": 2127713, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12257, "number_of_timesteps": 2132486, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12267, "number_of_timesteps": 2137486, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12277, "number_of_timesteps": 2142486, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12287, "number_of_timesteps": 2147486, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},

{"total_number_of_episodes": 12297, "number_of_timesteps": 2152486, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 12307, "number_of_timesteps": 2157428, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 12317, "number_of_timesteps": 2162428, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 12327, "number_of_timesteps": 2167428, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 12337, "number_of_timesteps": 2172428, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 12347, "number_of_timesteps": 2177428, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 12357, "number_of_timesteps": 2182428, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 12367, "number_of_timesteps": 2187428, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 12377, "number_of_timesteps": 2192428, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 12387, "number_of_timesteps": 2197428, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 12397, "number_of_timesteps": 2202428, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 12407, "number_of_timesteps": 2207428, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 12417, "number_of_timesteps": 2212428, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12427, "number_of_timesteps": 2217428, "per_episode_reward": 16.93, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.0714285714285694},
{"total_number_of_episodes": 12437, "number_of_timesteps": 2222428, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12447, "number_of_timesteps": 2227428, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12457, "number_of_timesteps": 2232428, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12467, "number_of_timesteps": 2237428, "per_episode_reward": 17.07, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12477, "number_of_timesteps": 2242428, "per_episode_reward": 17.21, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12487, "number_of_timesteps": 2247428, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 12497, "number_of_timesteps": 2252428, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 12507, "number_of_timesteps": 2257428, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 12517, "number_of_timesteps": 2262428, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 12527, "number_of_timesteps": 2267428, "per_episode_reward": 17.57, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 12537, "number_of_timesteps": 2272428, "per_episode_reward": 17.57, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 12547, "number_of_timesteps": 2277428, "per_episode_reward": 17.57, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 12557, "number_of_timesteps": 2282418, "per_episode_reward": 17.57, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 12567, "number_of_timesteps": 2287418, "per_episode_reward": 17.57, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 12577, "number_of_timesteps": 2292418, "per_episode_reward": 17.57, "episode_reward_trend_value": 0.0015873015873016211, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 12587, "number_of_timesteps": 2297418, "per_episode_reward": 17.57, "episode_reward_trend_value": 0.0015873015873016211, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 12597, "number_of_timesteps": 2302418, "per_episode_reward": 17.57, "episode_reward_trend_value": 0.0015873015873016211, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 12607, "number_of_timesteps": 2307418, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},

{"total_number_of_episodes": 12617, "number_of_timesteps": 2312418, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12627, "number_of_timesteps": 2317418, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12637, "number_of_timesteps": 2322418, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12647, "number_of_timesteps": 2327418, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12657, "number_of_timesteps": 2332418, "per_episode_reward": 17.79, "episode_reward_trend_value": 0.0023809523809523525, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12667, "number_of_timesteps": 2337418, "per_episode_reward": 17.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12677, "number_of_timesteps": 2342418, "per_episode_reward": 17.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12687, "number_of_timesteps": 2347418, "per_episode_reward": 17.93, "episode_reward_trend_value": 0.003968253968253935, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12697, "number_of_timesteps": 2352418, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12707, "number_of_timesteps": 2357418, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12717, "number_of_timesteps": 2362418, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12727, "number_of_timesteps": 2367418, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12737, "number_of_timesteps": 2372418, "per_episode_reward": 18.14, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12747, "number_of_timesteps": 2377418, "per_episode_reward": 18.14, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12757, "number_of_timesteps": 2382418, "per_episode_reward": 18.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12767, "number_of_timesteps": 2387418, "per_episode_reward": 18.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12777, "number_of_timesteps": 2392418, "per_episode_reward": 18.14, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12787, "number_of_timesteps": 2397418, "per_episode_reward": 18.21, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12797, "number_of_timesteps": 2402418, "per_episode_reward": 18.29, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12807, "number_of_timesteps": 2407418, "per_episode_reward": 18.29, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12817, "number_of_timesteps": 2412418, "per_episode_reward": 18.29, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12827, "number_of_timesteps": 2417418, "per_episode_reward": 18.29, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12837, "number_of_timesteps": 2422418, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 12847, "number_of_timesteps": 2427418, "per_episode_reward": 18.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 12857, "number_of_timesteps": 2432418, "per_episode_reward": 18.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 12867, "number_of_timesteps": 2437418, "per_episode_reward": 18.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 12877, "number_of_timesteps": 2442418, "per_episode_reward": 18.57, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 12887, "number_of_timesteps": 2447418, "per_episode_reward": 18.71, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 12897, "number_of_timesteps": 2452418, "per_episode_reward": 18.71, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 12907, "number_of_timesteps": 2457418, "per_episode_reward": 18.71, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.2142857142857153},

{"total_number_of_episodes": 12917, "number_of_timesteps": 2462418, "per_episode_reward": 18.71, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 12927, "number_of_timesteps": 2467152, "per_episode_reward": 18.79, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12937, "number_of_timesteps": 2472152, "per_episode_reward": 18.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12947, "number_of_timesteps": 2477152, "per_episode_reward": 18.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12957, "number_of_timesteps": 2482152, "per_episode_reward": 18.93, "episode_reward_trend_value": 0.003968253968253935, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12967, "number_of_timesteps": 2487152, "per_episode_reward": 19.14, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 12977, "number_of_timesteps": 2492152, "per_episode_reward": 19.14, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 12987, "number_of_timesteps": 2497152, "per_episode_reward": 19.14, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 12997, "number_of_timesteps": 2502152, "per_episode_reward": 19.21, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13007, "number_of_timesteps": 2507152, "per_episode_reward": 19.43, "episode_reward_trend_value": 0.007936507936507908, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13017, "number_of_timesteps": 2512152, "per_episode_reward": 19.43, "episode_reward_trend_value": 0.0071428571428571366, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13027, "number_of_timesteps": 2517152, "per_episode_reward": 19.43, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.2142857142857153},

{"total_number_of_episodes": 13037, "number_of_timesteps": 2522152, "per_episode_reward": 19.43, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13047, "number_of_timesteps": 2527152, "per_episode_reward": 19.43, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13057, "number_of_timesteps": 2532152, "per_episode_reward": 19.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13067, "number_of_timesteps": 2537152, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13077, "number_of_timesteps": 2542152, "per_episode_reward": 19.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13087, "number_of_timesteps": 2547152, "per_episode_reward": 19.57, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13097, "number_of_timesteps": 2552152, "per_episode_reward": 19.57, "episode_reward_trend_value": 0.0015873015873016211, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13107, "number_of_timesteps": 2557152, "per_episode_reward": 19.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13117, "number_of_timesteps": 2562152, "per_episode_reward": 19.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13127, "number_of_timesteps": 2567152, "per_episode_reward": 19.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13137, "number_of_timesteps": 2572152, "per_episode_reward": 19.93, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13147, "number_of_timesteps": 2577152, "per_episode_reward": 20.07, "episode_reward_trend_value": 0.007142857142857177, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13157, "number_of_timesteps": 2582152, "per_episode_reward": 20.14, "episode_reward_trend_value": 0.0071428571428571366, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13167, "number_of_timesteps": 2586947, "per_episode_reward": 20.14, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13177, "number_of_timesteps": 2591947, "per_episode_reward": 20.14, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13187, "number_of_timesteps": 2596947, "per_episode_reward": 20.14, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13197, "number_of_timesteps": 2601947, "per_episode_reward": 20.14, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13207, "number_of_timesteps": 2606947, "per_episode_reward": 20.14, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13217, "number_of_timesteps": 2611947, "per_episode_reward": 20.14, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13227, "number_of_timesteps": 2616873, "per_episode_reward": 20.14, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13237, "number_of_timesteps": 2621873, "per_episode_reward": 20.21, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13247, "number_of_timesteps": 2626873, "per_episode_reward": 20.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13257, "number_of_timesteps": 2631873, "per_episode_reward": 20.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13267, "number_of_timesteps": 2636873, "per_episode_reward": 20.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13277, "number_of_timesteps": 2641873, "per_episode_reward": 20.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13287, "number_of_timesteps": 2646873, "per_episode_reward": 20.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13297, "number_of_timesteps": 2651873, "per_episode_reward": 20.64, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13307, "number_of_timesteps": 2656873, "per_episode_reward": 20.71, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13317, "number_of_timesteps": 2661873, "per_episode_reward": 20.71, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13327, "number_of_timesteps": 2666873, "per_episode_reward": 20.86, "episode_reward_trend_value": 0.0071428571428571366, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 13337, "number_of_timesteps": 2671873, "per_episode_reward": 21.0, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13347, "number_of_timesteps": 2676873, "per_episode_reward": 21.0, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13357, "number_of_timesteps": 2681873, "per_episode_reward": 21.0, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13367, "number_of_timesteps": 2686873, "per_episode_reward": 21.07, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13377, "number_of_timesteps": 2691873, "per_episode_reward": 21.14, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13387, "number_of_timesteps": 2696873, "per_episode_reward": 21.14, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13397, "number_of_timesteps": 2701873, "per_episode_reward": 21.14, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13407, "number_of_timesteps": 2706873, "per_episode_reward": 21.14, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13417, "number_of_timesteps": 2711873, "per_episode_reward": 21.21, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13427, "number_of_timesteps": 2716360, "per_episode_reward": 21.29, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13437, "number_of_timesteps": 2721360, "per_episode_reward": 21.29, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13447, "number_of_timesteps": 2726360, "per_episode_reward": 21.29, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13457, "number_of_timesteps": 2731360, "per_episode_reward": 21.29, "episode_reward_trend_value": 0.0023809523809523525, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13467, "number_of_timesteps": 2736360, "per_episode_reward": 21.5, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13477, "number_of_timesteps": 2741360, "per_episode_reward": 21.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13487, "number_of_timesteps": 2746360, "per_episode_reward": 21.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13497, "number_of_timesteps": 2751360, "per_episode_reward": 21.64, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.2142857142857153},

{"total_number_of_episodes": 13507, "number_of_timesteps": 2756360, "per_episode_reward": 21.79, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13517, "number_of_timesteps": 2761360, "per_episode_reward": 21.86, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13527, "number_of_timesteps": 2766360, "per_episode_reward": 22.07, "episode_reward_trend_value": 0.008730158730158758, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13537, "number_of_timesteps": 2771360, "per_episode_reward": 22.14, "episode_reward_trend_value": 0.009523809523809528, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13547, "number_of_timesteps": 2776360, "per_episode_reward": 22.14, "episode_reward_trend_value": 0.009523809523809528, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13557, "number_of_timesteps": 2781360, "per_episode_reward": 22.14, "episode_reward_trend_value": 0.0071428571428571366, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13567, "number_of_timesteps": 2786360, "per_episode_reward": 22.29, "episode_reward_trend_value": 0.007936507936507908, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13577, "number_of_timesteps": 2791360, "per_episode_reward": 22.29, "episode_reward_trend_value": 0.007936507936507908, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13587, "number_of_timesteps": 2796360, "per_episode_reward": 22.29, "episode_reward_trend_value": 0.0071428571428571366, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13597, "number_of_timesteps": 2801360, "per_episode_reward": 22.29, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13607, "number_of_timesteps": 2806360, "per_episode_reward": 22.29, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 13617, "number_of_timesteps": 2811360, "per_episode_reward": 22.36, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13627, "number_of_timesteps": 2816360, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13637, "number_of_timesteps": 2821360, "per_episode_reward": 22.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13647, "number_of_timesteps": 2826360, "per_episode_reward": 22.64, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13657, "number_of_timesteps": 2831360, "per_episode_reward": 22.71, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13667, "number_of_timesteps": 2836360, "per_episode_reward": 22.71, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13677, "number_of_timesteps": 2841360, "per_episode_reward": 22.71, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13687, "number_of_timesteps": 2846360, "per_episode_reward": 22.71, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13697, "number_of_timesteps": 2851360, "per_episode_reward": 22.71, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13707, "number_of_timesteps": 2856360, "per_episode_reward": 22.79, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13717, "number_of_timesteps": 2861360, "per_episode_reward": 22.93, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13727, "number_of_timesteps": 2866360, "per_episode_reward": 23.07, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13737, "number_of_timesteps": 2871360, "per_episode_reward": 23.14, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13747, "number_of_timesteps": 2876360, "per_episode_reward": 23.14, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13757, "number_of_timesteps": 2881360, "per_episode_reward": 23.14, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13767, "number_of_timesteps": 2886360, "per_episode_reward": 23.29, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13777, "number_of_timesteps": 2891360, "per_episode_reward": 23.29, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13787, "number_of_timesteps": 2896360, "per_episode_reward": 23.57, "episode_reward_trend_value": 0.009523809523809528, "biggest_recent_change": 0.28571428571428825},

{"total_number_of_episodes": 13797, "number_of_timesteps": 2901360, "per_episode_reward": 23.57, "episode_reward_trend_value": 0.008730158730158758, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 13807, "number_of_timesteps": 2906360, "per_episode_reward": 23.57, "episode_reward_trend_value": 0.007142857142857177, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 13817, "number_of_timesteps": 2911360, "per_episode_reward": 23.57, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 13827, "number_of_timesteps": 2916360, "per_episode_reward": 23.71, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 13837, "number_of_timesteps": 2921360, "per_episode_reward": 23.86, "episode_reward_trend_value": 0.007936507936507946, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 13847, "number_of_timesteps": 2926360, "per_episode_reward": 23.86, "episode_reward_trend_value": 0.007936507936507946, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 13857, "number_of_timesteps": 2931360, "per_episode_reward": 24.0, "episode_reward_trend_value": 0.007936507936507946, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 13867, "number_of_timesteps": 2936360, "per_episode_reward": 24.07, "episode_reward_trend_value": 0.008730158730158758, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 13877, "number_of_timesteps": 2941360, "per_episode_reward": 24.14, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13887, "number_of_timesteps": 2946360, "per_episode_reward": 24.29, "episode_reward_trend_value": 0.007936507936507908, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13897, "number_of_timesteps": 2951360, "per_episode_reward": 24.43, "episode_reward_trend_value": 0.00952380952380949, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13907, "number_of_timesteps": 2956360, "per_episode_reward": 24.43, "episode_reward_trend_value": 0.00952380952380949, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13917, "number_of_timesteps": 2961360, "per_episode_reward": 24.57, "episode_reward_trend_value": 0.009523809523809528, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13927, "number_of_timesteps": 2966360, "per_episode_reward": 24.64, "episode_reward_trend_value": 0.008730158730158718, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13937, "number_of_timesteps": 2971360, "per_episode_reward": 24.79, "episode_reward_trend_value": 0.0103174603174603, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13947, "number_of_timesteps": 2976360, "per_episode_reward": 24.93, "episode_reward_trend_value": 0.0103174603174603, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13957, "number_of_timesteps": 2981360, "per_episode_reward": 25.0, "episode_reward_trend_value": 0.0103174603174603, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13967, "number_of_timesteps": 2986360, "per_episode_reward": 25.14, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13977, "number_of_timesteps": 2991360, "per_episode_reward": 25.29, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13987, "number_of_timesteps": 2996360, "per_episode_reward": 25.29, "episode_reward_trend_value": 0.009523809523809528, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 13997, "number_of_timesteps": 3001360, "per_episode_reward": 25.29, "episode_reward_trend_value": 0.009523809523809528, "biggest_recent_change": 0.1428571428571459},

{"total_number_of_episodes": 14007, "number_of_timesteps": 3006360, "per_episode_reward": 25.29, "episode_reward_trend_value": 0.007936507936507908, "biggest_recent_change": 0.14285714285714235},

{"total_number_of_episodes": 14017, "number_of_timesteps": 3011360, "per_episode_reward": 25.29, "episode_reward_trend_value": 0.0071428571428571366, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 14027, "number_of_timesteps": 3016360, "per_episode_reward": 25.5, "episode_reward_trend_value": 0.007936507936507946, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 14037, "number_of_timesteps": 3021360, "per_episode_reward": 25.57, "episode_reward_trend_value": 0.007142857142857177, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 14047, "number_of_timesteps": 3026360, "per_episode_reward": 25.79, "episode_reward_trend_value": 0.008730158730158718, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 14057, "number_of_timesteps": 3031360, "per_episode_reward": 25.86, "episode_reward_trend_value": 0.007936507936507946, "biggest_recent_change": 0.2142857142857153},

{"total_number_of_episodes": 14067, "number_of_timesteps": 3036360, "per_episode_reward": 26.07, "episode_reward_trend_value": 0.008730158730158758, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 14077, "number_of_timesteps": 3041360, "per_episode_reward": 26.14, "episode_reward_trend_value": 0.009523809523809528, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 14087, "number_of_timesteps": 3046360, "per_episode_reward": 26.29, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 14097, "number_of_timesteps": 3051360, "per_episode_reward": 26.43, "episode_reward_trend_value": 0.012698412698412691, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 14107, "number_of_timesteps": 3056360, "per_episode_reward": 26.43, "episode_reward_trend_value": 0.012698412698412691, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 14117, "number_of_timesteps": 3061360, "per_episode_reward": 26.5, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 14127, "number_of_timesteps": 3066360, "per_episode_reward": 26.57, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 14137, "number_of_timesteps": 3071360, "per_episode_reward": 26.79, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 14147, "number_of_timesteps": 3076360, "per_episode_reward": 26.86, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 14157, "number_of_timesteps": 3081360, "per_episode_reward": 26.86, "episode_reward_trend_value": 0.008730158730158718, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 14167, "number_of_timesteps": 3086360, "per_episode_reward": 26.86, "episode_reward_trend_value": 0.007936507936507946, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 14177, "number_of_timesteps": 3091360, "per_episode_reward": 26.93, "episode_reward_trend_value": 0.0071428571428571366, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 14187, "number_of_timesteps": 3096360, "per_episode_reward": 27.21, "episode_reward_trend_value": 0.008730158730158758, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 14197, "number_of_timesteps": 3101360, "per_episode_reward": 27.43, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 14207, "number_of_timesteps": 3106360, "per_episode_reward": 27.57, "episode_reward_trend_value": 0.011904761904761921, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 14217, "number_of_timesteps": 3111360, "per_episode_reward": 27.57, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 14227, "number_of_timesteps": 3116360, "per_episode_reward": 27.64, "episode_reward_trend_value": 0.009523809523809528, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 14237, "number_of_timesteps": 3121360, "per_episode_reward": 27.71, "episode_reward_trend_value": 0.009523809523809528, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 14247, "number_of_timesteps": 3126360, "per_episode_reward": 27.71, "episode_reward_trend_value": 0.009523809523809528, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 14257, "number_of_timesteps": 3131360, "per_episode_reward": 27.93, "episode_reward_trend_value": 0.011904761904761882, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 14267, "number_of_timesteps": 3136360, "per_episode_reward": 28.0, "episode_reward_trend_value": 0.011904761904761921, "biggest_recent_change": 0.28571428571428825},
{"total_number_of_episodes": 14277, "number_of_timesteps": 3141360, "per_episode_reward": 28.0, "episode_reward_trend_value": 0.008730158730158718, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 14287, "number_of_timesteps": 3146360, "per_episode_reward": 28.07, "episode_reward_trend_value": 0.007142857142857177, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 14297, "number_of_timesteps": 3151360, "per_episode_reward": 28.21, "episode_reward_trend_value": 0.0071428571428571366, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 14307, "number_of_timesteps": 3156360, "per_episode_reward": 28.5, "episode_reward_trend_value": 0.0103174603174603, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 14317, "number_of_timesteps": 3161360, "per_episode_reward": 28.64, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 14327, "number_of_timesteps": 3166360, "per_episode_reward": 28.86, "episode_reward_trend_value": 0.012698412698412691, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 14337, "number_of_timesteps": 3171360, "per_episode_reward": 28.86, "episode_reward_trend_value": 0.012698412698412691, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 14347, "number_of_timesteps": 3176360, "per_episode_reward": 29.0, "episode_reward_trend_value": 0.011904761904761921, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 14357, "number_of_timesteps": 3181360, "per_episode_reward": 29.14, "episode_reward_trend_value": 0.012698412698412691, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 14367, "number_of_timesteps": 3186360, "per_episode_reward": 29.43, "episode_reward_trend_value": 0.015873015873015855, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 14377, "number_of_timesteps": 3191360, "per_episode_reward": 29.79, "episode_reward_trend_value": 0.019047619047619018, "biggest_recent_change": 0.35714285714285765},
{"total_number_of_episodes": 14387, "number_of_timesteps": 3196360, "per_episode_reward": 29.86, "episode_reward_trend_value": 0.018253968253968248, "biggest_recent_change": 0.35714285714285765},
{"total_number_of_episodes": 14397, "number_of_timesteps": 3201360, "per_episode_reward": 30.0, "episode_reward_trend_value": 0.016666666666666666, "biggest_recent_change": 0.35714285714285765},
{"total_number_of_episodes": 14407, "number_of_timesteps": 3206360, "per_episode_reward": 30.0, "episode_reward_trend_value": 0.015079365079365085, "biggest_recent_change": 0.35714285714285765},
{"total_number_of_episodes": 14417, "number_of_timesteps": 3211360, "per_episode_reward": 30.07, "episode_reward_trend_value": 0.013492063492063503, "biggest_recent_change": 0.35714285714285765},
{"total_number_of_episodes": 14427, "number_of_timesteps": 3216360, "per_episode_reward": 30.29, "episode_reward_trend_value": 0.015873015873015855, "biggest_recent_change": 0.35714285714285765},
{"total_number_of_episodes": 14437, "number_of_timesteps": 3221360, "per_episode_reward": 30.86, "episode_reward_trend_value": 0.020634920634920638, "biggest_recent_change": 0.571428571428573},
{"total_number_of_episodes": 14447, "number_of_timesteps": 3226360, "per_episode_reward": 31.0, "episode_reward_trend_value": 0.020634920634920638, "biggest_recent_change": 0.571428571428573},
{"total_number_of_episodes": 14457, "number_of_timesteps": 3231360, "per_episode_reward": 31.0, "episode_reward_trend_value": 0.017460317460317475, "biggest_recent_change": 0.571428571428573},
{"total_number_of_episodes": 14467, "number_of_timesteps": 3236360, "per_episode_reward": 31.43, "episode_reward_trend_value": 0.018253968253968248, "biggest_recent_change": 0.571428571428573},
{"total_number_of_episodes": 14477, "number_of_timesteps": 3241360, "per_episode_reward": 31.86, "episode_reward_trend_value": 0.02222222222222222, "biggest_recent_change": 0.571428571428573},

{"total_number_of_episodes": 14487, "number_of_timesteps": 3246360, "per_episode_reward": 31.93, "episode_reward_trend_value": 0.02142857142857141, "biggest_recent_change": 0.571428571428573},
{"total_number_of_episodes": 14497, "number_of_timesteps": 3251360, "per_episode_reward": 32.0, "episode_reward_trend_value": 0.02222222222222222, "biggest_recent_change": 0.571428571428573},
{"total_number_of_episodes": 14507, "number_of_timesteps": 3256360, "per_episode_reward": 32.0, "episode_reward_trend_value": 0.02142857142857141, "biggest_recent_change": 0.571428571428573},
{"total_number_of_episodes": 14517, "number_of_timesteps": 3261360, "per_episode_reward": 32.14, "episode_reward_trend_value": 0.02063492063492068, "biggest_recent_change": 0.571428571428573},
{"total_number_of_episodes": 14527, "number_of_timesteps": 3266360, "per_episode_reward": 32.29, "episode_reward_trend_value": 0.015873015873015855, "biggest_recent_change": 0.4285714285714306},
{"total_number_of_episodes": 14537, "number_of_timesteps": 3271360, "per_episode_reward": 32.5, "episode_reward_trend_value": 0.016666666666666666, "biggest_recent_change": 0.4285714285714306},
{"total_number_of_episodes": 14547, "number_of_timesteps": 3276360, "per_episode_reward": 32.57, "episode_reward_trend_value": 0.017460317460317436, "biggest_recent_change": 0.4285714285714306},

{"total_number_of_episodes": 14557, "number_of_timesteps": 3281360, "per_episode_reward": 32.86, "episode_reward_trend_value": 0.015873015873015855, "biggest_recent_change": 0.4285714285714306},
{"total_number_of_episodes": 14567, "number_of_timesteps": 3286360, "per_episode_reward": 33.07, "episode_reward_trend_value": 0.013492063492063463, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 14577, "number_of_timesteps": 3291360, "per_episode_reward": 33.29, "episode_reward_trend_value": 0.015079365079365085, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 14587, "number_of_timesteps": 3296360, "per_episode_reward": 33.43, "episode_reward_trend_value": 0.015873015873015893, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 14597, "number_of_timesteps": 3301360, "per_episode_reward": 33.57, "episode_reward_trend_value": 0.017460317460317436, "biggest_recent_change": 0.2857142857142847},
{"total_number_of_episodes": 14607, "number_of_timesteps": 3306360, "per_episode_reward": 33.93, "episode_reward_trend_value": 0.01984126984126983, "biggest_recent_change": 0.3571428571428612},
{"total_number_of_episodes": 14617, "number_of_timesteps": 3311360, "per_episode_reward": 34.21, "episode_reward_trend_value": 0.021428571428571453, "biggest_recent_change": 0.3571428571428612},
{"total_number_of_episodes": 14627, "number_of_timesteps": 3316360, "per_episode_reward": 34.36, "episode_reward_trend_value": 0.0206349206349206, "biggest_recent_change": 0.3571428571428612},
{"total_number_of_episodes": 14637, "number_of_timesteps": 3321360, "per_episode_reward": 34.57, "episode_reward_trend_value": 0.02222222222222222, "biggest_recent_change": 0.3571428571428612},
{"total_number_of_episodes": 14647, "number_of_timesteps": 3326360, "per_episode_reward": 34.93, "episode_reward_trend_value": 0.023015873015873073, "biggest_recent_change": 0.3571428571428612},
{"total_number_of_episodes": 14657, "number_of_timesteps": 3331360, "per_episode_reward": 35.07, "episode_reward_trend_value": 0.02222222222222222, "biggest_recent_change": 0.3571428571428612},
{"total_number_of_episodes": 14667, "number_of_timesteps": 3336360, "per_episode_reward": 35.21, "episode_reward_trend_value": 0.021428571428571453, "biggest_recent_change": 0.3571428571428612},
{"total_number_of_episodes": 14677, "number_of_timesteps": 3341360, "per_episode_reward": 35.43, "episode_reward_trend_value": 0.02222222222222222, "biggest_recent_change": 0.3571428571428612},
{"total_number_of_episodes": 14687, "number_of_timesteps": 3346360, "per_episode_reward": 35.71, "episode_reward_trend_value": 0.023809523809523843, "biggest_recent_change": 0.3571428571428612},
{"total_number_of_episodes": 14697, "number_of_timesteps": 3351360, "per_episode_reward": 36.29, "episode_reward_trend_value": 0.02619047619047616, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 14707, "number_of_timesteps": 3356360, "per_episode_reward": 36.43, "episode_reward_trend_value": 0.024603174603174616, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 14717, "number_of_timesteps": 3361360, "per_episode_reward": 36.5, "episode_reward_trend_value": 0.023809523809523843, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 14727, "number_of_timesteps": 3366360, "per_episode_reward": 36.71, "episode_reward_trend_value": 0.023809523809523843, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 14737, "number_of_timesteps": 3371360, "per_episode_reward": 36.86, "episode_reward_trend_value": 0.021428571428571373, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 14747, "number_of_timesteps": 3376360, "per_episode_reward": 37.36, "episode_reward_trend_value": 0.025396825396825383, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 14757, "number_of_timesteps": 3381360, "per_episode_reward": 37.57, "episode_reward_trend_value": 0.02619047619047616, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 14767, "number_of_timesteps": 3386360, "per_episode_reward": 37.57, "episode_reward_trend_value": 0.023809523809523763, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 14777, "number_of_timesteps": 3391360, "per_episode_reward": 37.64, "episode_reward_trend_value": 0.021428571428571453, "biggest_recent_change": 0.5714285714285694},

{"total_number_of_episodes": 14787, "number_of_timesteps": 3396360, "per_episode_reward": 38.0, "episode_reward_trend_value": 0.019047619047619056, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14797, "number_of_timesteps": 3401360, "per_episode_reward": 38.29, "episode_reward_trend_value": 0.0206349206349206, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14807, "number_of_timesteps": 3406360, "per_episode_reward": 38.29, "episode_reward_trend_value": 0.01984126984126983, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14817, "number_of_timesteps": 3411360, "per_episode_reward": 38.43, "episode_reward_trend_value": 0.019047619047619056, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14827, "number_of_timesteps": 3416360, "per_episode_reward": 38.93, "episode_reward_trend_value": 0.023015873015873073, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14837, "number_of_timesteps": 3421360, "per_episode_reward": 39.29, "episode_reward_trend_value": 0.021428571428571453, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14847, "number_of_timesteps": 3426360, "per_episode_reward": 39.79, "episode_reward_trend_value": 0.024603174603174616, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14857, "number_of_timesteps": 3431360, "per_episode_reward": 40.21, "episode_reward_trend_value": 0.0293650793650794, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14867, "number_of_timesteps": 3436360, "per_episode_reward": 40.5, "episode_reward_trend_value": 0.03174603174603171, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14877, "number_of_timesteps": 3441360, "per_episode_reward": 40.64, "episode_reward_trend_value": 0.0293650793650794, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14887, "number_of_timesteps": 3446360, "per_episode_reward": 41.0, "episode_reward_trend_value": 0.03015873015873017, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14897, "number_of_timesteps": 3451360, "per_episode_reward": 41.36, "episode_reward_trend_value": 0.0341269841269841, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14907, "number_of_timesteps": 3456360, "per_episode_reward": 41.57, "episode_reward_trend_value": 0.03492063492063487, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14917, "number_of_timesteps": 3461360, "per_episode_reward": 41.57, "episode_reward_trend_value": 0.029365079365079323, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14927, "number_of_timesteps": 3466360, "per_episode_reward": 42.0, "episode_reward_trend_value": 0.03015873015873017, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 14937, "number_of_timesteps": 3471360, "per_episode_reward": 42.36, "episode_reward_trend_value": 0.028571428571428546, "biggest_recent_change": 0.4285714285714306},
{"total_number_of_episodes": 14947, "number_of_timesteps": 3476360, "per_episode_reward": 42.64, "episode_reward_trend_value": 0.026984126984127006, "biggest_recent_change": 0.4285714285714306},
{"total_number_of_episodes": 14957, "number_of_timesteps": 3481360, "per_episode_reward": 43.29, "episode_reward_trend_value": 0.030952380952380943, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 14967, "number_of_timesteps": 3486360, "per_episode_reward": 43.36, "episode_reward_trend_value": 0.03015873015873009, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 14977, "number_of_timesteps": 3491360, "per_episode_reward": 43.79, "episode_reward_trend_value": 0.030952380952380943, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 14987, "number_of_timesteps": 3496360, "per_episode_reward": 44.21, "episode_reward_trend_value": 0.031746031746031786, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 14997, "number_of_timesteps": 3501360, "per_episode_reward": 44.71, "episode_reward_trend_value": 0.03492063492063495, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 15007, "number_of_timesteps": 3506360, "per_episode_reward": 44.79, "episode_reward_trend_value": 0.035714285714285726, "biggest_recent_change": 0.6428571428571388},

{"total_number_of_episodes": 15017, "number_of_timesteps": 3511360, "per_episode_reward": 45.07, "episode_reward_trend_value": 0.0341269841269841, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 15027, "number_of_timesteps": 3516360, "per_episode_reward": 45.64, "episode_reward_trend_value": 0.03650793650793658, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 15037, "number_of_timesteps": 3521360, "per_episode_reward": 46.0, "episode_reward_trend_value": 0.037301587301587266, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 15047, "number_of_timesteps": 3526360, "per_episode_reward": 46.21, "episode_reward_trend_value": 0.03253968253968256, "biggest_recent_change": 0.5714285714285765},
{"total_number_of_episodes": 15057, "number_of_timesteps": 3531360, "per_episode_reward": 46.57, "episode_reward_trend_value": 0.035714285714285726, "biggest_recent_change": 0.5714285714285765},
{"total_number_of_episodes": 15067, "number_of_timesteps": 3536360, "per_episode_reward": 47.0, "episode_reward_trend_value": 0.035714285714285726, "biggest_recent_change": 0.5714285714285765},
{"total_number_of_episodes": 15077, "number_of_timesteps": 3541360, "per_episode_reward": 47.36, "episode_reward_trend_value": 0.03492063492063487, "biggest_recent_change": 0.5714285714285765},
{"total_number_of_episodes": 15087, "number_of_timesteps": 3546360, "per_episode_reward": 47.64, "episode_reward_trend_value": 0.03253968253968256, "biggest_recent_change": 0.5714285714285765},
{"total_number_of_episodes": 15097, "number_of_timesteps": 3551360, "per_episode_reward": 48.21, "episode_reward_trend_value": 0.03809523809523811, "biggest_recent_change": 0.5714285714285765},
{"total_number_of_episodes": 15107, "number_of_timesteps": 3556360, "per_episode_reward": 48.71, "episode_reward_trend_value": 0.04047619047619051, "biggest_recent_change": 0.5714285714285765},
{"total_number_of_episodes": 15117, "number_of_timesteps": 3561360, "per_episode_reward": 49.43, "episode_reward_trend_value": 0.04206349206349205, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15127, "number_of_timesteps": 3566360, "per_episode_reward": 49.79, "episode_reward_trend_value": 0.04206349206349205, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15137, "number_of_timesteps": 3571360, "per_episode_reward": 50.07, "episode_reward_trend_value": 0.04285714285714282, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15147, "number_of_timesteps": 3576360, "per_episode_reward": 50.36, "episode_reward_trend_value": 0.04206349206349205, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15157, "number_of_timesteps": 3581360, "per_episode_reward": 50.5, "episode_reward_trend_value": 0.03888888888888889, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15167, "number_of_timesteps": 3586360, "per_episode_reward": 51.07, "episode_reward_trend_value": 0.041269841269841276, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15177, "number_of_timesteps": 3591360, "per_episode_reward": 51.57, "episode_reward_trend_value": 0.04365079365079359, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15187, "number_of_timesteps": 3596360, "per_episode_reward": 51.79, "episode_reward_trend_value": 0.03968253968253966, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15197, "number_of_timesteps": 3601360, "per_episode_reward": 52.29, "episode_reward_trend_value": 0.03968253968253966, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15207, "number_of_timesteps": 3606360, "per_episode_reward": 52.86, "episode_reward_trend_value": 0.038095238095238036, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 15217, "number_of_timesteps": 3611360, "per_episode_reward": 53.21, "episode_reward_trend_value": 0.03809523809523811, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 15227, "number_of_timesteps": 3616360, "per_episode_reward": 53.5, "episode_reward_trend_value": 0.03809523809523811, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 15237, "number_of_timesteps": 3621360, "per_episode_reward": 53.71, "episode_reward_trend_value": 0.03730158730158735, "biggest_recent_change": 0.5714285714285694},

{"total_number_of_episodes": 15247, "number_of_timesteps": 3626360, "per_episode_reward": 54.07, "episode_reward_trend_value": 0.03968253968253966, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 15257, "number_of_timesteps": 3631360, "per_episode_reward": 54.64, "episode_reward_trend_value": 0.03968253968253974, "biggest_recent_change": 0.5714285714285765},
{"total_number_of_episodes": 15267, "number_of_timesteps": 3636360, "per_episode_reward": 55.21, "episode_reward_trend_value": 0.04047619047619051, "biggest_recent_change": 0.5714285714285765},
{"total_number_of_episodes": 15277, "number_of_timesteps": 3641360, "per_episode_reward": 55.71, "episode_reward_trend_value": 0.043650793650793676, "biggest_recent_change": 0.5714285714285765},
{"total_number_of_episodes": 15287, "number_of_timesteps": 3646360, "per_episode_reward": 55.86, "episode_reward_trend_value": 0.03968253968253966, "biggest_recent_change": 0.5714285714285765},
{"total_number_of_episodes": 15297, "number_of_timesteps": 3651360, "per_episode_reward": 56.21, "episode_reward_trend_value": 0.03730158730158735, "biggest_recent_change": 0.5714285714285765},
{"total_number_of_episodes": 15307, "number_of_timesteps": 3656360, "per_episode_reward": 56.93, "episode_reward_trend_value": 0.041269841269841276, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15317, "number_of_timesteps": 3661360, "per_episode_reward": 57.21, "episode_reward_trend_value": 0.041269841269841276, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15327, "number_of_timesteps": 3666360, "per_episode_reward": 57.36, "episode_reward_trend_value": 0.04047619047619043, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15337, "number_of_timesteps": 3671360, "per_episode_reward": 57.5, "episode_reward_trend_value": 0.03809523809523811, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15347, "number_of_timesteps": 3676360, "per_episode_reward": 58.21, "episode_reward_trend_value": 0.03968253968253966, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15357, "number_of_timesteps": 3681360, "per_episode_reward": 58.36, "episode_reward_trend_value": 0.03492063492063487, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15367, "number_of_timesteps": 3686360, "per_episode_reward": 58.71, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15377, "number_of_timesteps": 3691360, "per_episode_reward": 59.29, "episode_reward_trend_value": 0.03809523809523811, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15387, "number_of_timesteps": 3696360, "per_episode_reward": 59.64, "episode_reward_trend_value": 0.03809523809523811, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15397, "number_of_timesteps": 3701360, "per_episode_reward": 60.0, "episode_reward_trend_value": 0.0341269841269841, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15407, "number_of_timesteps": 3706360, "per_episode_reward": 60.14, "episode_reward_trend_value": 0.03253968253968256, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15417, "number_of_timesteps": 3711360, "per_episode_reward": 60.29, "episode_reward_trend_value": 0.03253968253968256, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15427, "number_of_timesteps": 3716360, "per_episode_reward": 60.64, "episode_reward_trend_value": 0.03492063492063495, "biggest_recent_change": 0.7142857142857153},
{"total_number_of_episodes": 15437, "number_of_timesteps": 3721360, "per_episode_reward": 60.79, "episode_reward_trend_value": 0.028571428571428546, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 15447, "number_of_timesteps": 3726360, "per_episode_reward": 61.14, "episode_reward_trend_value": 0.03095238095238102, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 15457, "number_of_timesteps": 3731360, "per_episode_reward": 61.29, "episode_reward_trend_value": 0.028571428571428546, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 15467, "number_of_timesteps": 3736360, "per_episode_reward": 61.64, "episode_reward_trend_value": 0.026190476190476236, "biggest_recent_change": 0.3571428571428612},
{"total_number_of_episodes": 15477, "number_of_timesteps": 3741360, "per_episode_reward": 61.86, "episode_reward_trend_value": 0.024603174603174537, "biggest_recent_change": 0.3571428571428612},

{"total_number_of_episodes": 15487, "number_of_timesteps": 3746360, "per_episode_reward": 63.0, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 1.142857142857146},

{"total_number_of_episodes": 15497, "number_of_timesteps": 3751360, "per_episode_reward": 64.14, "episode_reward_trend_value": 0.04444444444444436, "biggest_recent_change": 1.142857142857146},
{"total_number_of_episodes": 15507, "number_of_timesteps": 3756360, "per_episode_reward": 64.57, "episode_reward_trend_value": 0.0476190476190476, "biggest_recent_change": 1.142857142857146},
{"total_number_of_episodes": 15517, "number_of_timesteps": 3761360, "per_episode_reward": 65.0, "episode_reward_trend_value": 0.04841269841269838, "biggest_recent_change": 1.142857142857146},
{"total_number_of_episodes": 15527, "number_of_timesteps": 3766360, "per_episode_reward": 65.21, "episode_reward_trend_value": 0.04920634920634915, "biggest_recent_change": 1.142857142857146},
{"total_number_of_episodes": 15537, "number_of_timesteps": 3771360, "per_episode_reward": 65.43, "episode_reward_trend_value": 0.0476190476190476, "biggest_recent_change": 1.142857142857146},
{"total_number_of_episodes": 15547, "number_of_timesteps": 3776360, "per_episode_reward": 65.79, "episode_reward_trend_value": 0.05000000000000008, "biggest_recent_change": 1.142857142857146},

{"total_number_of_episodes": 15557, "number_of_timesteps": 3781360, "per_episode_reward": 66.29, "episode_reward_trend_value": 0.051587301587301626, "biggest_recent_change": 1.142857142857146},
{"total_number_of_episodes": 15567, "number_of_timesteps": 3786360, "per_episode_reward": 66.5, "episode_reward_trend_value": 0.051587301587301626, "biggest_recent_change": 1.142857142857146},
{"total_number_of_episodes": 15577, "number_of_timesteps": 3791360, "per_episode_reward": 66.64, "episode_reward_trend_value": 0.04047619047619043, "biggest_recent_change": 1.1428571428571388},
{"total_number_of_episodes": 15587, "number_of_timesteps": 3796360, "per_episode_reward": 66.93, "episode_reward_trend_value": 0.03095238095238102, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 15597, "number_of_timesteps": 3801360, "per_episode_reward": 67.36, "episode_reward_trend_value": 0.03095238095238102, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 15607, "number_of_timesteps": 3806360, "per_episode_reward": 68.0, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 15617, "number_of_timesteps": 3811360, "per_episode_reward": 68.36, "episode_reward_trend_value": 0.03492063492063503, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 15627, "number_of_timesteps": 3816360, "per_episode_reward": 68.57, "episode_reward_trend_value": 0.03492063492063487, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 15637, "number_of_timesteps": 3821360, "per_episode_reward": 69.0, "episode_reward_trend_value": 0.03571428571428565, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 15647, "number_of_timesteps": 3826360, "per_episode_reward": 69.57, "episode_reward_trend_value": 0.03650793650793642, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 15657, "number_of_timesteps": 3831360, "per_episode_reward": 70.0, "episode_reward_trend_value": 0.03888888888888889, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 15667, "number_of_timesteps": 3836360, "per_episode_reward": 70.07, "episode_reward_trend_value": 0.03809523809523811, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 15677, "number_of_timesteps": 3841360, "per_episode_reward": 70.36, "episode_reward_trend_value": 0.03809523809523811, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 15687, "number_of_timesteps": 3846360, "per_episode_reward": 70.71, "episode_reward_trend_value": 0.03730158730158719, "biggest_recent_change": 0.6428571428571388},
{"total_number_of_episodes": 15697, "number_of_timesteps": 3851360, "per_episode_reward": 71.5, "episode_reward_trend_value": 0.03888888888888889, "biggest_recent_change": 0.7857142857142918},
{"total_number_of_episodes": 15707, "number_of_timesteps": 3856360, "per_episode_reward": 72.0, "episode_reward_trend_value": 0.04047619047619043, "biggest_recent_change": 0.7857142857142918},
{"total_number_of_episodes": 15717, "number_of_timesteps": 3861360, "per_episode_reward": 72.29, "episode_reward_trend_value": 0.04126984126984136, "biggest_recent_change": 0.7857142857142918},
{"total_number_of_episodes": 15727, "number_of_timesteps": 3866360, "per_episode_reward": 72.5, "episode_reward_trend_value": 0.03888888888888889, "biggest_recent_change": 0.7857142857142918},
{"total_number_of_episodes": 15737, "number_of_timesteps": 3871360, "per_episode_reward": 73.36, "episode_reward_trend_value": 0.04206349206349213, "biggest_recent_change": 0.8571428571428612},
{"total_number_of_episodes": 15747, "number_of_timesteps": 3876360, "per_episode_reward": 73.79, "episode_reward_trend_value": 0.04206349206349213, "biggest_recent_change": 0.8571428571428612},
{"total_number_of_episodes": 15757, "number_of_timesteps": 3881360, "per_episode_reward": 74.0, "episode_reward_trend_value": 0.043650793650793676, "biggest_recent_change": 0.8571428571428612},
{"total_number_of_episodes": 15767, "number_of_timesteps": 3886360, "per_episode_reward": 75.14, "episode_reward_trend_value": 0.05317460317460308, "biggest_recent_change": 1.1428571428571388},
{"total_number_of_episodes": 15777, "number_of_timesteps": 3891360, "per_episode_reward": 75.71, "episode_reward_trend_value": 0.05555555555555556, "biggest_recent_change": 1.1428571428571388},
{"total_number_of_episodes": 15787, "number_of_timesteps": 3896360, "per_episode_reward": 76.21, "episode_reward_trend_value": 0.05238095238095232, "biggest_recent_change": 1.1428571428571388},
{"total_number_of_episodes": 15797, "number_of_timesteps": 3901360, "per_episode_reward": 76.71, "episode_reward_trend_value": 0.05238095238095232, "biggest_recent_change": 1.1428571428571388},
{"total_number_of_episodes": 15807, "number_of_timesteps": 3906360, "per_episode_reward": 76.71, "episode_reward_trend_value": 0.04920634920634907, "biggest_recent_change": 1.1428571428571388},
{"total_number_of_episodes": 15817, "number_of_timesteps": 3911360, "per_episode_reward": 77.14, "episode_reward_trend_value": 0.051587301587301536, "biggest_recent_change": 1.1428571428571388},
{"total_number_of_episodes": 15827, "number_of_timesteps": 3916360, "per_episode_reward": 77.14, "episode_reward_trend_value": 0.042063492063491977, "biggest_recent_change": 1.1428571428571388},
{"total_number_of_episodes": 15837, "number_of_timesteps": 3921360, "per_episode_reward": 77.21, "episode_reward_trend_value": 0.03809523809523796, "biggest_recent_change": 1.1428571428571388},
{"total_number_of_episodes": 15847, "number_of_timesteps": 3926360, "per_episode_reward": 77.79, "episode_reward_trend_value": 0.04206349206349213, "biggest_recent_change": 1.1428571428571388},
{"total_number_of_episodes": 15857, "number_of_timesteps": 3931360, "per_episode_reward": 78.21, "episode_reward_trend_value": 0.0341269841269841, "biggest_recent_change": 0.5714285714285836},
{"total_number_of_episodes": 15867, "number_of_timesteps": 3936360, "per_episode_reward": 79.64, "episode_reward_trend_value": 0.043650793650793676, "biggest_recent_change": 1.4285714285714306},
{"total_number_of_episodes": 15877, "number_of_timesteps": 3941360, "per_episode_reward": 79.71, "episode_reward_trend_value": 0.03888888888888889, "biggest_recent_change": 1.4285714285714306},
{"total_number_of_episodes": 15887, "number_of_timesteps": 3946360, "per_episode_reward": 80.86, "episode_reward_trend_value": 0.046031746031746146, "biggest_recent_change": 1.4285714285714306},
{"total_number_of_episodes": 15897, "number_of_timesteps": 3951360, "per_episode_reward": 81.36, "episode_reward_trend_value": 0.0515873015873017, "biggest_recent_change": 1.4285714285714306},
{"total_number_of_episodes": 15907, "number_of_timesteps": 3956360, "per_episode_reward": 81.79, "episode_reward_trend_value": 0.0515873015873017, "biggest_recent_change": 1.4285714285714306},
{"total_number_of_episodes": 15917, "number_of_timesteps": 3961360, "per_episode_reward": 82.36, "episode_reward_trend_value": 0.05793650793650803, "biggest_recent_change": 1.4285714285714306},
{"total_number_of_episodes": 15927, "number_of_timesteps": 3966360, "per_episode_reward": 82.64, "episode_reward_trend_value": 0.06031746031746034, "biggest_recent_change": 1.4285714285714306},
{"total_number_of_episodes": 15937, "number_of_timesteps": 3971360, "per_episode_reward": 83.14, "episode_reward_trend_value": 0.05952380952380941, "biggest_recent_change": 1.4285714285714306},
{"total_number_of_episodes": 15947, "number_of_timesteps": 3976360, "per_episode_reward": 83.57, "episode_reward_trend_value": 0.05952380952380957, "biggest_recent_change": 1.4285714285714306},
{"total_number_of_episodes": 15957, "number_of_timesteps": 3981360, "per_episode_reward": 83.93, "episode_reward_trend_value": 0.047619047619047686, "biggest_recent_change": 1.142857142857153},
{"total_number_of_episodes": 15967, "number_of_timesteps": 3986360, "per_episode_reward": 84.21, "episode_reward_trend_value": 0.05, "biggest_recent_change": 1.142857142857153},
{"total_number_of_episodes": 15977, "number_of_timesteps": 3991360, "per_episode_reward": 84.43, "episode_reward_trend_value": 0.03968253968253966, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 15987, "number_of_timesteps": 3996360, "per_episode_reward": 85.0, "episode_reward_trend_value": 0.04047619047619043, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 15997, "number_of_timesteps": 4001360, "per_episode_reward": 85.29, "episode_reward_trend_value": 0.03888888888888889, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 16007, "number_of_timesteps": 4006360, "per_episode_reward": 85.71, "episode_reward_trend_value": 0.03730158730158719, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 16017, "number_of_timesteps": 4011360, "per_episode_reward": 86.21, "episode_reward_trend_value": 0.03968253968253966, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 16027, "number_of_timesteps": 4016360, "per_episode_reward": 86.57, "episode_reward_trend_value": 0.03809523809523811, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 16037, "number_of_timesteps": 4021360, "per_episode_reward": 86.93, "episode_reward_trend_value": 0.03730158730158735, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 16047, "number_of_timesteps": 4026360, "per_episode_reward": 87.86, "episode_reward_trend_value": 0.043650793650793676, "biggest_recent_change": 0.9285714285714306},
{"total_number_of_episodes": 16057, "number_of_timesteps": 4031360, "per_episode_reward": 88.71, "episode_reward_trend_value": 0.05, "biggest_recent_change": 0.9285714285714306},
{"total_number_of_episodes": 16067, "number_of_timesteps": 4036360, "per_episode_reward": 89.36, "episode_reward_trend_value": 0.05476190476190479, "biggest_recent_change": 0.9285714285714306},
{"total_number_of_episodes": 16077, "number_of_timesteps": 4041360, "per_episode_reward": 89.86, "episode_reward_trend_value": 0.05396825396825401, "biggest_recent_change": 0.9285714285714306},
{"total_number_of_episodes": 16087, "number_of_timesteps": 4046360, "per_episode_reward": 90.21, "episode_reward_trend_value": 0.05476190476190462, "biggest_recent_change": 0.9285714285714306},
{"total_number_of_episodes": 16097, "number_of_timesteps": 4051360, "per_episode_reward": 90.79, "episode_reward_trend_value": 0.05634920634920648, "biggest_recent_change": 0.9285714285714306},
{"total_number_of_episodes": 16107, "number_of_timesteps": 4056360, "per_episode_reward": 91.0, "episode_reward_trend_value": 0.05317460317460324, "biggest_recent_change": 0.9285714285714306},
{"total_number_of_episodes": 16117, "number_of_timesteps": 4061360, "per_episode_reward": 91.36, "episode_reward_trend_value": 0.05317460317460324, "biggest_recent_change": 0.9285714285714306},
{"total_number_of_episodes": 16127, "number_of_timesteps": 4066360, "per_episode_reward": 91.57, "episode_reward_trend_value": 0.051587301587301536, "biggest_recent_change": 0.9285714285714306},
{"total_number_of_episodes": 16137, "number_of_timesteps": 4071360, "per_episode_reward": 91.86, "episode_reward_trend_value": 0.04444444444444444, "biggest_recent_change": 0.857142857142847},
{"total_number_of_episodes": 16147, "number_of_timesteps": 4076360, "per_episode_reward": 92.14, "episode_reward_trend_value": 0.03809523809523811, "biggest_recent_change": 0.642857142857153},
{"total_number_of_episodes": 16157, "number_of_timesteps": 4081360, "per_episode_reward": 92.36, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.5714285714285836},
{"total_number_of_episodes": 16167, "number_of_timesteps": 4086360, "per_episode_reward": 92.57, "episode_reward_trend_value": 0.03015873015873009, "biggest_recent_change": 0.5714285714285836},
{"total_number_of_episodes": 16177, "number_of_timesteps": 4091360, "per_episode_reward": 92.86, "episode_reward_trend_value": 0.029365079365079476, "biggest_recent_change": 0.5714285714285836},
{"total_number_of_episodes": 16187, "number_of_timesteps": 4096360, "per_episode_reward": 93.36, "episode_reward_trend_value": 0.028571428571428546, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 16197, "number_of_timesteps": 4101360, "per_episode_reward": 93.86, "episode_reward_trend_value": 0.031746031746031786, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 16207, "number_of_timesteps": 4106360, "per_episode_reward": 94.43, "episode_reward_trend_value": 0.0341269841269841, "biggest_recent_change": 0.5714285714285694},
{"total_number_of_episodes": 16217, "number_of_timesteps": 4111360, "per_episode_reward": 95.14, "episode_reward_trend_value": 0.03968253968253966, "biggest_recent_change": 0.7142857142857082},
{"total_number_of_episodes": 16227, "number_of_timesteps": 4116360, "per_episode_reward": 95.5, "episode_reward_trend_value": 0.04047619047619043, "biggest_recent_change": 0.7142857142857082},
{"total_number_of_episodes": 16237, "number_of_timesteps": 4121360, "per_episode_reward": 96.57, "episode_reward_trend_value": 0.04920634920634923, "biggest_recent_change": 1.0714285714285694},
{"total_number_of_episodes": 16247, "number_of_timesteps": 4126360, "per_episode_reward": 97.36, "episode_reward_trend_value": 0.05555555555555556, "biggest_recent_change": 1.0714285714285694},
{"total_number_of_episodes": 16257, "number_of_timesteps": 4131360, "per_episode_reward": 100.0, "episode_reward_trend_value": 0.08253968253968255, "biggest_recent_change": 2.642857142857139},
{"total_number_of_episodes": 16267, "number_of_timesteps": 4136360, "per_episode_reward": 100.79, "episode_reward_trend_value": 0.08809523809523812, "biggest_recent_change": 2.642857142857139},
{"total_number_of_episodes": 16277, "number_of_timesteps": 4141360, "per_episode_reward": 101.29, "episode_reward_trend_value": 0.08809523809523812, "biggest_recent_change": 2.642857142857139},
{"total_number_of_episodes": 16287, "number_of_timesteps": 4146360, "per_episode_reward": 102.79, "episode_reward_trend_value": 0.09920634920634923, "biggest_recent_change": 2.642857142857139},
{"total_number_of_episodes": 16297, "number_of_timesteps": 4151360, "per_episode_reward": 103.14, "episode_reward_trend_value": 0.09682539682539676, "biggest_recent_change": 2.642857142857139},
{"total_number_of_episodes": 16307, "number_of_timesteps": 4156360, "per_episode_reward": 103.71, "episode_reward_trend_value": 0.0952380952380952, "biggest_recent_change": 2.642857142857139},
{"total_number_of_episodes": 16317, "number_of_timesteps": 4161360, "per_episode_reward": 104.14, "episode_reward_trend_value": 0.096031746031746, "biggest_recent_change": 2.642857142857139},
{"total_number_of_episodes": 16327, "number_of_timesteps": 4166360, "per_episode_reward": 105.0, "episode_reward_trend_value": 0.09365079365079368, "biggest_recent_change": 2.642857142857139},
{"total_number_of_episodes": 16337, "number_of_timesteps": 4171360, "per_episode_reward": 105.36, "episode_reward_trend_value": 0.08888888888888888, "biggest_recent_change": 2.642857142857139},
{"total_number_of_episodes": 16347, "number_of_timesteps": 4176360, "per_episode_reward": 105.57, "episode_reward_trend_value": 0.061904761904761886, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 16357, "number_of_timesteps": 4181360, "per_episode_reward": 105.93, "episode_reward_trend_value": 0.05714285714285709, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 16367, "number_of_timesteps": 4186360, "per_episode_reward": 106.29, "episode_reward_trend_value": 0.05555555555555556, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 16377, "number_of_timesteps": 4191360, "per_episode_reward": 106.79, "episode_reward_trend_value": 0.04444444444444444, "biggest_recent_change": 0.8571428571428612},
{"total_number_of_episodes": 16387, "number_of_timesteps": 4196360, "per_episode_reward": 107.0, "episode_reward_trend_value": 0.042857142857142906, "biggest_recent_change": 0.8571428571428612},
{"total_number_of_episodes": 16397, "number_of_timesteps": 4201360, "per_episode_reward": 107.36, "episode_reward_trend_value": 0.04047619047619059, "biggest_recent_change": 0.8571428571428612},
{"total_number_of_episodes": 16407, "number_of_timesteps": 4206360, "per_episode_reward": 108.14, "episode_reward_trend_value": 0.04444444444444444, "biggest_recent_change": 0.8571428571428612},
{"total_number_of_episodes": 16417, "number_of_timesteps": 4211360, "per_episode_reward": 108.29, "episode_reward_trend_value": 0.03650793650793658, "biggest_recent_change": 0.7857142857142776},
{"total_number_of_episodes": 16427, "number_of_timesteps": 4216360, "per_episode_reward": 108.5, "episode_reward_trend_value": 0.03492063492063487, "biggest_recent_change": 0.7857142857142776},
{"total_number_of_episodes": 16437, "number_of_timesteps": 4221360, "per_episode_reward": 108.79, "episode_reward_trend_value": 0.0357142857142858, "biggest_recent_change": 0.7857142857142776},
{"total_number_of_episodes": 16447, "number_of_timesteps": 4226360, "per_episode_reward": 109.5, "episode_reward_trend_value": 0.03968253968253966, "biggest_recent_change": 0.7857142857142776},
{"total_number_of_episodes": 16457, "number_of_timesteps": 4231360, "per_episode_reward": 110.36, "episode_reward_trend_value": 0.045238095238095216, "biggest_recent_change": 0.8571428571428612},
{"total_number_of_episodes": 16467, "number_of_timesteps": 4236360, "per_episode_reward": 111.0, "episode_reward_trend_value": 0.046825396825396756, "biggest_recent_change": 0.8571428571428612},
{"total_number_of_episodes": 16477, "number_of_timesteps": 4241360, "per_episode_reward": 111.57, "episode_reward_trend_value": 0.050793650793650766, "biggest_recent_change": 0.8571428571428612},
{"total_number_of_episodes": 16487, "number_of_timesteps": 4246360, "per_episode_reward": 112.21, "episode_reward_trend_value": 0.05396825396825385, "biggest_recent_change": 0.8571428571428612},
{"total_number_of_episodes": 16497, "number_of_timesteps": 4251360, "per_episode_reward": 112.71, "episode_reward_trend_value": 0.050793650793650766, "biggest_recent_change": 0.8571428571428612},
{"total_number_of_episodes": 16507, "number_of_timesteps": 4256360, "per_episode_reward": 113.5, "episode_reward_trend_value": 0.05793650793650786, "biggest_recent_change": 0.8571428571428612},
{"total_number_of_episodes": 16517, "number_of_timesteps": 4261360, "per_episode_reward": 115.79, "episode_reward_trend_value": 0.08095238095238103, "biggest_recent_change": 2.285714285714292},
{"total_number_of_episodes": 16527, "number_of_timesteps": 4266360, "per_episode_reward": 116.36, "episode_reward_trend_value": 0.0841269841269841, "biggest_recent_change": 2.285714285714292},
{"total_number_of_episodes": 16537, "number_of_timesteps": 4271360, "per_episode_reward": 117.21, "episode_reward_trend_value": 0.08571428571428565, "biggest_recent_change": 2.285714285714292},
{"total_number_of_episodes": 16547, "number_of_timesteps": 4276360, "per_episode_reward": 118.86, "episode_reward_trend_value": 0.09444444444444444, "biggest_recent_change": 2.285714285714292},
{"total_number_of_episodes": 16557, "number_of_timesteps": 4281360, "per_episode_reward": 119.36, "episode_reward_trend_value": 0.0928571428571429, "biggest_recent_change": 2.285714285714292},
{"total_number_of_episodes": 16567, "number_of_timesteps": 4286360, "per_episode_reward": 120.43, "episode_reward_trend_value": 0.09841269841269847, "biggest_recent_change": 2.285714285714292},
{"total_number_of_episodes": 16577, "number_of_timesteps": 4291360, "per_episode_reward": 121.07, "episode_reward_trend_value": 0.09841269841269847, "biggest_recent_change": 2.285714285714292},
{"total_number_of_episodes": 16587, "number_of_timesteps": 4296360, "per_episode_reward": 122.93, "episode_reward_trend_value": 0.11349206349206357, "biggest_recent_change": 2.285714285714292},
{"total_number_of_episodes": 16597, "number_of_timesteps": 4301360, "per_episode_reward": 124.0, "episode_reward_trend_value": 0.11666666666666667, "biggest_recent_change": 2.285714285714292},
{"total_number_of_episodes": 16607, "number_of_timesteps": 4306360, "per_episode_reward": 125.21, "episode_reward_trend_value": 0.10476190476190464, "biggest_recent_change": 1.8571428571428612},
{"total_number_of_episodes": 16617, "number_of_timesteps": 4311360, "per_episode_reward": 126.5, "episode_reward_trend_value": 0.11269841269841266, "biggest_recent_change": 1.8571428571428612},
{"total_number_of_episodes": 16627, "number_of_timesteps": 4316360, "per_episode_reward": 126.79, "episode_reward_trend_value": 0.10634920634920648, "biggest_recent_change": 1.8571428571428612},
{"total_number_of_episodes": 16637, "number_of_timesteps": 4321360, "per_episode_reward": 127.29, "episode_reward_trend_value": 0.09365079365079368, "biggest_recent_change": 1.8571428571428612},
{"total_number_of_episodes": 16647, "number_of_timesteps": 4326360, "per_episode_reward": 128.86, "episode_reward_trend_value": 0.10555555555555556, "biggest_recent_change": 1.8571428571428612},
{"total_number_of_episodes": 16657, "number_of_timesteps": 4331360, "per_episode_reward": 131.21, "episode_reward_trend_value": 0.1198412698412699, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 16667, "number_of_timesteps": 4336360, "per_episode_reward": 131.86, "episode_reward_trend_value": 0.1198412698412699, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 16677, "number_of_timesteps": 4341360, "per_episode_reward": 132.29, "episode_reward_trend_value": 0.10396825396825386, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 16687, "number_of_timesteps": 4346360, "per_episode_reward": 132.5, "episode_reward_trend_value": 0.09444444444444444, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 16697, "number_of_timesteps": 4351360, "per_episode_reward": 133.21, "episode_reward_trend_value": 0.08888888888888904, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 16707, "number_of_timesteps": 4356360, "per_episode_reward": 135.07, "episode_reward_trend_value": 0.09523809523809537, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 16717, "number_of_timesteps": 4361360, "per_episode_reward": 136.14, "episode_reward_trend_value": 0.10396825396825386, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 16727, "number_of_timesteps": 4366360, "per_episode_reward": 136.5, "episode_reward_trend_value": 0.10238095238095231, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 16737, "number_of_timesteps": 4371360, "per_episode_reward": 136.93, "episode_reward_trend_value": 0.0896825396825395, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 16747, "number_of_timesteps": 4376360, "per_episode_reward": 138.29, "episode_reward_trend_value": 0.07857142857142839, "biggest_recent_change": 1.8571428571428612},
{"total_number_of_episodes": 16757, "number_of_timesteps": 4381360, "per_episode_reward": 139.43, "episode_reward_trend_value": 0.08412698412698395, "biggest_recent_change": 1.8571428571428612},
{"total_number_of_episodes": 16767, "number_of_timesteps": 4386360, "per_episode_reward": 139.79, "episode_reward_trend_value": 0.08333333333333334, "biggest_recent_change": 1.8571428571428612},
{"total_number_of_episodes": 16777, "number_of_timesteps": 4391360, "per_episode_reward": 143.71, "episode_reward_trend_value": 0.12460317460317469, "biggest_recent_change": 3.928571428571445},
{"total_number_of_episodes": 16787, "number_of_timesteps": 4396360, "per_episode_reward": 145.71, "episode_reward_trend_value": 0.1388888888888889, "biggest_recent_change": 3.928571428571445},
{"total_number_of_episodes": 16797, "number_of_timesteps": 4401360, "per_episode_reward": 147.36, "episode_reward_trend_value": 0.1365079365079364, "biggest_recent_change": 3.928571428571445},
{"total_number_of_episodes": 16807, "number_of_timesteps": 4406360, "per_episode_reward": 148.14, "episode_reward_trend_value": 0.13333333333333333, "biggest_recent_change": 3.928571428571445},
{"total_number_of_episodes": 16817, "number_of_timesteps": 4411360, "per_episode_reward": 148.86, "episode_reward_trend_value": 0.13730158730158734, "biggest_recent_change": 3.928571428571445},
{"total_number_of_episodes": 16827, "number_of_timesteps": 4416360, "per_episode_reward": 150.21, "episode_reward_trend_value": 0.14761904761904784, "biggest_recent_change": 3.928571428571445},
{"total_number_of_episodes": 16837, "number_of_timesteps": 4421360, "per_episode_reward": 151.71, "episode_reward_trend_value": 0.1492063492063494, "biggest_recent_change": 3.928571428571445},
{"total_number_of_episodes": 16847, "number_of_timesteps": 4426360, "per_episode_reward": 153.93, "episode_reward_trend_value": 0.16111111111111112, "biggest_recent_change": 3.928571428571445},
{"total_number_of_episodes": 16857, "number_of_timesteps": 4431360, "per_episode_reward": 156.07, "episode_reward_trend_value": 0.18095238095238117, "biggest_recent_change": 3.928571428571445},
{"total_number_of_episodes": 16867, "number_of_timesteps": 4436360, "per_episode_reward": 157.93, "episode_reward_trend_value": 0.1579365079365077, "biggest_recent_change": 2.214285714285694},
{"total_number_of_episodes": 16877, "number_of_timesteps": 4441360, "per_episode_reward": 159.0, "episode_reward_trend_value": 0.14761904761904754, "biggest_recent_change": 2.214285714285694},
{"total_number_of_episodes": 16887, "number_of_timesteps": 4446360, "per_episode_reward": 160.07, "episode_reward_trend_value": 0.14126984126984138, "biggest_recent_change": 2.214285714285694},
{"total_number_of_episodes": 16897, "number_of_timesteps": 4451360, "per_episode_reward": 160.93, "episode_reward_trend_value": 0.14206349206349198, "biggest_recent_change": 2.214285714285694},
{"total_number_of_episodes": 16907, "number_of_timesteps": 4456360, "per_episode_reward": 161.57, "episode_reward_trend_value": 0.14126984126984138, "biggest_recent_change": 2.214285714285694},
{"total_number_of_episodes": 16917, "number_of_timesteps": 4461360, "per_episode_reward": 162.5, "episode_reward_trend_value": 0.1365079365079364, "biggest_recent_change": 2.214285714285694},
{"total_number_of_episodes": 16927, "number_of_timesteps": 4466360, "per_episode_reward": 163.0, "episode_reward_trend_value": 0.1253968253968253, "biggest_recent_change": 2.214285714285694},
{"total_number_of_episodes": 16937, "number_of_timesteps": 4471360, "per_episode_reward": 165.07, "episode_reward_trend_value": 0.12380952380952408, "biggest_recent_change": 2.142857142857167},
{"total_number_of_episodes": 16947, "number_of_timesteps": 4476360, "per_episode_reward": 165.57, "episode_reward_trend_value": 0.10555555555555556, "biggest_recent_change": 2.0714285714285836},
{"total_number_of_episodes": 16957, "number_of_timesteps": 4481360, "per_episode_reward": 167.21, "episode_reward_trend_value": 0.1031746031746034, "biggest_recent_change": 2.0714285714285836},
{"total_number_of_episodes": 16967, "number_of_timesteps": 4486360, "per_episode_reward": 168.64, "episode_reward_trend_value": 0.1071428571428571, "biggest_recent_change": 2.0714285714285836},
{"total_number_of_episodes": 16977, "number_of_timesteps": 4491360, "per_episode_reward": 170.07, "episode_reward_trend_value": 0.11111111111111112, "biggest_recent_change": 2.0714285714285836},
{"total_number_of_episodes": 16987, "number_of_timesteps": 4496360, "per_episode_reward": 172.07, "episode_reward_trend_value": 0.12380952380952408, "biggest_recent_change": 2.0714285714285836},
{"total_number_of_episodes": 16997, "number_of_timesteps": 4501360, "per_episode_reward": 172.71, "episode_reward_trend_value": 0.12380952380952377, "biggest_recent_change": 2.0714285714285836},
{"total_number_of_episodes": 17007, "number_of_timesteps": 4506360, "per_episode_reward": 173.36, "episode_reward_trend_value": 0.12063492063492068, "biggest_recent_change": 2.0714285714285836},
{"total_number_of_episodes": 17017, "number_of_timesteps": 4511360, "per_episode_reward": 175.0, "episode_reward_trend_value": 0.13333333333333333, "biggest_recent_change": 2.0714285714285836},
{"total_number_of_episodes": 17027, "number_of_timesteps": 4516360, "per_episode_reward": 177.86, "episode_reward_trend_value": 0.14206349206349198, "biggest_recent_change": 2.857142857142861},
{"total_number_of_episodes": 17037, "number_of_timesteps": 4521360, "per_episode_reward": 181.36, "episode_reward_trend_value": 0.1753968253968253, "biggest_recent_change": 3.5},
{"total_number_of_episodes": 17047, "number_of_timesteps": 4526360, "per_episode_reward": 182.93, "episode_reward_trend_value": 0.17460317460317437, "biggest_recent_change": 3.5},
{"total_number_of_episodes": 17057, "number_of_timesteps": 4531360, "per_episode_reward": 185.0, "episode_reward_trend_value": 0.1817460317460318, "biggest_recent_change": 3.5},
{"total_number_of_episodes": 17067, "number_of_timesteps": 4536360, "per_episode_reward": 185.64, "episode_reward_trend_value": 0.17301587301587285, "biggest_recent_change": 3.5},
{"total_number_of_episodes": 17077, "number_of_timesteps": 4541360, "per_episode_reward": 186.57, "episode_reward_trend_value": 0.16111111111111112, "biggest_recent_change": 3.5},
{"total_number_of_episodes": 17087, "number_of_timesteps": 4546360, "per_episode_reward": 188.21, "episode_reward_trend_value": 0.17222222222222222, "biggest_recent_change": 3.5},
{"total_number_of_episodes": 17097, "number_of_timesteps": 4551360, "per_episode_reward": 189.64, "episode_reward_trend_value": 0.18095238095238086, "biggest_recent_change": 3.5},
{"total_number_of_episodes": 17107, "number_of_timesteps": 4556360, "per_episode_reward": 191.0, "episode_reward_trend_value": 0.17777777777777776, "biggest_recent_change": 3.5},
{"total_number_of_episodes": 17117, "number_of_timesteps": 4561360, "per_episode_reward": 192.07, "episode_reward_trend_value": 0.157936507936508, "biggest_recent_change": 3.5},
{"total_number_of_episodes": 17127, "number_of_timesteps": 4566360, "per_episode_reward": 193.79, "episode_reward_trend_value": 0.13809523809523797, "biggest_recent_change": 2.0714285714285836},
{"total_number_of_episodes": 17137, "number_of_timesteps": 4571360, "per_episode_reward": 194.79, "episode_reward_trend_value": 0.13174603174603178, "biggest_recent_change": 2.0714285714285836},
{"total_number_of_episodes": 17147, "number_of_timesteps": 4576360, "per_episode_reward": 196.29, "episode_reward_trend_value": 0.1253968253968253, "biggest_recent_change": 1.714285714285694},
{"total_number_of_episodes": 17157, "number_of_timesteps": 4581360, "per_episode_reward": 197.36, "episode_reward_trend_value": 0.13015873015873025, "biggest_recent_change": 1.714285714285694},
{"total_number_of_episodes": 17167, "number_of_timesteps": 4586360, "per_episode_reward": 200.07, "episode_reward_trend_value": 0.15, "biggest_recent_change": 2.7142857142857224},
{"total_number_of_episodes": 17177, "number_of_timesteps": 4591360, "per_episode_reward": 202.07, "episode_reward_trend_value": 0.15396825396825403, "biggest_recent_change": 2.7142857142857224},
{"total_number_of_episodes": 17187, "number_of_timesteps": 4596360, "per_episode_reward": 202.64, "episode_reward_trend_value": 0.14444444444444443, "biggest_recent_change": 2.7142857142857224},
{"total_number_of_episodes": 17197, "number_of_timesteps": 4601360, "per_episode_reward": 204.36, "episode_reward_trend_value": 0.14841269841269847, "biggest_recent_change": 2.7142857142857224},
{"total_number_of_episodes": 17207, "number_of_timesteps": 4606360, "per_episode_reward": 205.07, "episode_reward_trend_value": 0.14444444444444443, "biggest_recent_change": 2.7142857142857224},
{"total_number_of_episodes": 17217, "number_of_timesteps": 4611360, "per_episode_reward": 206.14, "episode_reward_trend_value": 0.13730158730158734, "biggest_recent_change": 2.7142857142857224},
{"total_number_of_episodes": 17227, "number_of_timesteps": 4616360, "per_episode_reward": 207.5, "episode_reward_trend_value": 0.14126984126984138, "biggest_recent_change": 2.7142857142857224},
{"total_number_of_episodes": 17237, "number_of_timesteps": 4621360, "per_episode_reward": 209.21, "episode_reward_trend_value": 0.14365079365079383, "biggest_recent_change": 2.7142857142857224},
{"total_number_of_episodes": 17247, "number_of_timesteps": 4626360, "per_episode_reward": 210.71, "episode_reward_trend_value": 0.14841269841269847, "biggest_recent_change": 2.7142857142857224},
{"total_number_of_episodes": 17257, "number_of_timesteps": 4631360, "per_episode_reward": 211.71, "episode_reward_trend_value": 0.12936507936507932, "biggest_recent_change": 2.0},
{"total_number_of_episodes": 17267, "number_of_timesteps": 4636360, "per_episode_reward": 212.5, "episode_reward_trend_value": 0.11587301587301573, "biggest_recent_change": 1.7142857142857224},
{"total_number_of_episodes": 17277, "number_of_timesteps": 4641360, "per_episode_reward": 214.36, "episode_reward_trend_value": 0.13015873015873025, "biggest_recent_change": 1.8571428571428612},

{"total_number_of_episodes": 17287, "number_of_timesteps": 4646360, "per_episode_reward": 216.71, "episode_reward_trend_value": 0.13730158730158734, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 17297, "number_of_timesteps": 4651360, "per_episode_reward": 218.0, "episode_reward_trend_value": 0.14365079365079353, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 17307, "number_of_timesteps": 4656360, "per_episode_reward": 219.79, "episode_reward_trend_value": 0.15158730158730155, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 17317, "number_of_timesteps": 4661360, "per_episode_reward": 220.43, "episode_reward_trend_value": 0.14365079365079353, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 17327, "number_of_timesteps": 4666360, "per_episode_reward": 220.93, "episode_reward_trend_value": 0.13015873015872995, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 17337, "number_of_timesteps": 4671360, "per_episode_reward": 221.79, "episode_reward_trend_value": 0.12301587301587284, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 17347, "number_of_timesteps": 4676360, "per_episode_reward": 221.93, "episode_reward_trend_value": 0.11349206349206327, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 17357, "number_of_timesteps": 4681360, "per_episode_reward": 222.57, "episode_reward_trend_value": 0.11190476190476203, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 17367, "number_of_timesteps": 4686360, "per_episode_reward": 223.29, "episode_reward_trend_value": 0.09920634920634908, "biggest_recent_change": 2.357142857142861},
{"total_number_of_episodes": 17377, "number_of_timesteps": 4691360, "per_episode_reward": 223.79, "episode_reward_trend_value": 0.07857142857142839, "biggest_recent_change": 1.7857142857142776},
{"total_number_of_episodes": 17387, "number_of_timesteps": 4696360, "per_episode_reward": 226.07, "episode_reward_trend_value": 0.08968253968253982, "biggest_recent_change": 2.285714285714306},
{"total_number_of_episodes": 17397, "number_of_timesteps": 4701360, "per_episode_reward": 226.93, "episode_reward_trend_value": 0.07936507936507932, "biggest_recent_change": 2.285714285714306},
{"total_number_of_episodes": 17407, "number_of_timesteps": 4706360, "per_episode_reward": 229.0, "episode_reward_trend_value": 0.09523809523809537, "biggest_recent_change": 2.285714285714306},
{"total_number_of_episodes": 17417, "number_of_timesteps": 4711360, "per_episode_reward": 230.07, "episode_reward_trend_value": 0.10158730158730185, "biggest_recent_change": 2.285714285714306},
{"total_number_of_episodes": 17427, "number_of_timesteps": 4716360, "per_episode_reward": 234.71, "episode_reward_trend_value": 0.14365079365079383, "biggest_recent_change": 4.642857142857139},
{"total_number_of_episodes": 17437, "number_of_timesteps": 4721360, "per_episode_reward": 235.57, "episode_reward_trend_value": 0.15158730158730185, "biggest_recent_change": 4.642857142857139},
{"total_number_of_episodes": 17447, "number_of_timesteps": 4726360, "per_episode_reward": 236.0, "episode_reward_trend_value": 0.14920634920634906, "biggest_recent_change": 4.642857142857139},
{"total_number_of_episodes": 17457, "number_of_timesteps": 4731360, "per_episode_reward": 236.57, "episode_reward_trend_value": 0.14761904761904784, "biggest_recent_change": 4.642857142857139},
{"total_number_of_episodes": 17467, "number_of_timesteps": 4736360, "per_episode_reward": 237.57, "episode_reward_trend_value": 0.1531746031746034, "biggest_recent_change": 4.642857142857139},

{"total_number_of_episodes": 17477, "number_of_timesteps": 4741360, "per_episode_reward": 239.79, "episode_reward_trend_value": 0.15238095238095214, "biggest_recent_change": 4.642857142857139},
{"total_number_of_episodes": 17487, "number_of_timesteps": 4746360, "per_episode_reward": 240.93, "episode_reward_trend_value": 0.15555555555555556, "biggest_recent_change": 4.642857142857139},
{"total_number_of_episodes": 17497, "number_of_timesteps": 4751360, "per_episode_reward": 242.5, "episode_reward_trend_value": 0.15, "biggest_recent_change": 4.642857142857139},
{"total_number_of_episodes": 17507, "number_of_timesteps": 4756360, "per_episode_reward": 243.79, "episode_reward_trend_value": 0.15238095238095214, "biggest_recent_change": 4.642857142857139},
{"total_number_of_episodes": 17517, "number_of_timesteps": 4761360, "per_episode_reward": 246.21, "episode_reward_trend_value": 0.12777777777777777, "biggest_recent_change": 2.428571428571445},
{"total_number_of_episodes": 17527, "number_of_timesteps": 4766360, "per_episode_reward": 248.71, "episode_reward_trend_value": 0.14603174603174598, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 17537, "number_of_timesteps": 4771360, "per_episode_reward": 250.14, "episode_reward_trend_value": 0.15714285714285708, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 17547, "number_of_timesteps": 4776360, "per_episode_reward": 251.86, "episode_reward_trend_value": 0.16984126984126974, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 17557, "number_of_timesteps": 4781360, "per_episode_reward": 254.86, "episode_reward_trend_value": 0.192063492063492, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 17567, "number_of_timesteps": 4786360, "per_episode_reward": 255.21, "episode_reward_trend_value": 0.17142857142857162, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 17577, "number_of_timesteps": 4791360, "per_episode_reward": 255.57, "episode_reward_trend_value": 0.16269841269841295, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 17587, "number_of_timesteps": 4796360, "per_episode_reward": 256.14, "episode_reward_trend_value": 0.15158730158730185, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 17597, "number_of_timesteps": 4801360, "per_episode_reward": 256.5, "episode_reward_trend_value": 0.14126984126984138, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 17607, "number_of_timesteps": 4806360, "per_episode_reward": 257.36, "episode_reward_trend_value": 0.12380952380952345, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 17617, "number_of_timesteps": 4811360, "per_episode_reward": 258.36, "episode_reward_trend_value": 0.10714285714285679, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 17627, "number_of_timesteps": 4816360, "per_episode_reward": 259.43, "episode_reward_trend_value": 0.1031746031746034, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 17637, "number_of_timesteps": 4821360, "per_episode_reward": 259.57, "episode_reward_trend_value": 0.08571428571428549, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 17647, "number_of_timesteps": 4826360, "per_episode_reward": 259.86, "episode_reward_trend_value": 0.05555555555555523, "biggest_recent_change": 1.071428571428612},
{"total_number_of_episodes": 17657, "number_of_timesteps": 4831360, "per_episode_reward": 260.86, "episode_reward_trend_value": 0.06269841269841234, "biggest_recent_change": 1.071428571428612},
{"total_number_of_episodes": 17667, "number_of_timesteps": 4836360, "per_episode_reward": 261.07, "episode_reward_trend_value": 0.0611111111111108, "biggest_recent_change": 1.071428571428612},
{"total_number_of_episodes": 17677, "number_of_timesteps": 4841360, "per_episode_reward": 262.14, "episode_reward_trend_value": 0.06666666666666667, "biggest_recent_change": 1.071428571428612},
{"total_number_of_episodes": 17687, "number_of_timesteps": 4846360, "per_episode_reward": 265.0, "episode_reward_trend_value": 0.09444444444444444, "biggest_recent_change": 2.857142857142833},
{"total_number_of_episodes": 17697, "number_of_timesteps": 4851360, "per_episode_reward": 265.43, "episode_reward_trend_value": 0.08968253968254013, "biggest_recent_change": 2.857142857142833},
{"total_number_of_episodes": 17707, "number_of_timesteps": 4856360, "per_episode_reward": 265.71, "episode_reward_trend_value": 0.08174603174603211, "biggest_recent_change": 2.857142857142833},
{"total_number_of_episodes": 17717, "number_of_timesteps": 4861360, "per_episode_reward": 266.0, "episode_reward_trend_value": 0.07301587301587284, "biggest_recent_change": 2.857142857142833},
{"total_number_of_episodes": 17727, "number_of_timesteps": 4866360, "per_episode_reward": 266.14, "episode_reward_trend_value": 0.07301587301587346, "biggest_recent_change": 2.857142857142833},
{"total_number_of_episodes": 17737, "number_of_timesteps": 4871360, "per_episode_reward": 266.5, "episode_reward_trend_value": 0.07380952380952407, "biggest_recent_change": 2.857142857142833},
{"total_number_of_episodes": 17747, "number_of_timesteps": 4876360, "per_episode_reward": 267.43, "episode_reward_trend_value": 0.07301587301587346, "biggest_recent_change": 2.857142857142833},
{"total_number_of_episodes": 17757, "number_of_timesteps": 4881360, "per_episode_reward": 268.0, "episode_reward_trend_value": 0.07698412698412717, "biggest_recent_change": 2.857142857142833},
{"total_number_of_episodes": 17767, "number_of_timesteps": 4886360, "per_episode_reward": 268.14, "episode_reward_trend_value": 0.06666666666666667, "biggest_recent_change": 2.857142857142833},
{"total_number_of_episodes": 17777, "number_of_timesteps": 4891360, "per_episode_reward": 268.29, "episode_reward_trend_value": 0.03650793650793642, "biggest_recent_change": 0.9285714285714448},
{"total_number_of_episodes": 17787, "number_of_timesteps": 4896360, "per_episode_reward": 268.43, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.9285714285714448},
{"total_number_of_episodes": 17797, "number_of_timesteps": 4901360, "per_episode_reward": 268.57, "episode_reward_trend_value": 0.03174603174603148, "biggest_recent_change": 0.9285714285714448},
{"total_number_of_episodes": 17807, "number_of_timesteps": 4906360, "per_episode_reward": 269.07, "episode_reward_trend_value": 0.03412698412698394, "biggest_recent_change": 0.9285714285714448},
{"total_number_of_episodes": 17817, "number_of_timesteps": 4911360, "per_episode_reward": 269.64, "episode_reward_trend_value": 0.03888888888888889, "biggest_recent_change": 0.9285714285714448},
{"total_number_of_episodes": 17827, "number_of_timesteps": 4916360, "per_episode_reward": 269.71, "episode_reward_trend_value": 0.0357142857142858, "biggest_recent_change": 0.9285714285714448},
{"total_number_of_episodes": 17837, "number_of_timesteps": 4921360, "per_episode_reward": 269.86, "episode_reward_trend_value": 0.026984126984126534, "biggest_recent_change": 0.571428571428612},

{"total_number_of_episodes": 17847, "number_of_timesteps": 4926360, "per_episode_reward": 269.93, "episode_reward_trend_value": 0.02142857142857161, "biggest_recent_change": 0.571428571428612},
{"total_number_of_episodes": 17857, "number_of_timesteps": 4931360, "per_episode_reward": 270.0, "episode_reward_trend_value": 0.020634920634920364, "biggest_recent_change": 0.571428571428612},
{"total_number_of_episodes": 17867, "number_of_timesteps": 4936360, "per_episode_reward": 270.14, "episode_reward_trend_value": 0.020634920634920995, "biggest_recent_change": 0.571428571428612},
{"total_number_of_episodes": 17877, "number_of_timesteps": 4941360, "per_episode_reward": 270.57, "episode_reward_trend_value": 0.023809523809523447, "biggest_recent_change": 0.571428571428612},
{"total_number_of_episodes": 17887, "number_of_timesteps": 4946360, "per_episode_reward": 271.0, "episode_reward_trend_value": 0.026984126984127166, "biggest_recent_change": 0.571428571428612},
{"total_number_of_episodes": 17897, "number_of_timesteps": 4951360, "per_episode_reward": 271.0, "episode_reward_trend_value": 0.02142857142857161, "biggest_recent_change": 0.571428571428612},
{"total_number_of_episodes": 17907, "number_of_timesteps": 4956360, "per_episode_reward": 271.14, "episode_reward_trend_value": 0.016666666666666666, "biggest_recent_change": 0.4285714285714448},
{"total_number_of_episodes": 17917, "number_of_timesteps": 4961360, "per_episode_reward": 271.14, "episode_reward_trend_value": 0.015873015873016053, "biggest_recent_change": 0.4285714285714448},
{"total_number_of_episodes": 17927, "number_of_timesteps": 4966360, "per_episode_reward": 271.14, "episode_reward_trend_value": 0.014285714285714827, "biggest_recent_change": 0.4285714285714448},
{"total_number_of_episodes": 17937, "number_of_timesteps": 4971360, "per_episode_reward": 271.71, "episode_reward_trend_value": 0.01984126984126975, "biggest_recent_change": 0.5714285714285552},
{"total_number_of_episodes": 17947, "number_of_timesteps": 4976360, "per_episode_reward": 272.36, "episode_reward_trend_value": 0.02619047619047592, "biggest_recent_change": 0.6428571428571104},

{"total_number_of_episodes": 17957, "number_of_timesteps": 4981360, "per_episode_reward": 274.0, "episode_reward_trend_value": 0.04285714285714259, "biggest_recent_change": 1.6428571428571672},
{"total_number_of_episodes": 17967, "number_of_timesteps": 4986360, "per_episode_reward": 275.0, "episode_reward_trend_value": 0.049206349206349385, "biggest_recent_change": 1.6428571428571672},
{"total_number_of_episodes": 17977, "number_of_timesteps": 4991360, "per_episode_reward": 276.71, "episode_reward_trend_value": 0.06349206349206357, "biggest_recent_change": 1.7142857142857224},
{"total_number_of_episodes": 17987, "number_of_timesteps": 4996360, "per_episode_reward": 277.0, "episode_reward_trend_value": 0.06666666666666667, "biggest_recent_change": 1.7142857142857224},
{"total_number_of_episodes": 17997, "number_of_timesteps": 5001360, "per_episode_reward": 277.29, "episode_reward_trend_value": 0.06825396825396789, "biggest_recent_change": 1.7142857142857224},
{"total_number_of_episodes": 18007, "number_of_timesteps": 5006331, "per_episode_reward": 277.43, "episode_reward_trend_value": 0.06984126984126975, "biggest_recent_change": 1.7142857142857224},
{"total_number_of_episodes": 18017, "number_of_timesteps": 5011331, "per_episode_reward": 277.43, "episode_reward_trend_value": 0.06984126984126975, "biggest_recent_change": 1.7142857142857224},
{"total_number_of_episodes": 18027, "number_of_timesteps": 5016193, "per_episode_reward": 278.0, "episode_reward_trend_value": 0.06984126984126975, "biggest_recent_change": 1.7142857142857224},
{"total_number_of_episodes": 18037, "number_of_timesteps": 5021193, "per_episode_reward": 278.57, "episode_reward_trend_value": 0.06904761904761914, "biggest_recent_change": 1.7142857142857224},
{"total_number_of_episodes": 18047, "number_of_timesteps": 5026123, "per_episode_reward": 278.86, "episode_reward_trend_value": 0.0539682539682537, "biggest_recent_change": 1.7142857142857224},
{"total_number_of_episodes": 18058, "number_of_timesteps": 5031427, "per_episode_reward": 279.29, "episode_reward_trend_value": 0.047619047619047526, "biggest_recent_change": 1.7142857142857224},
{"total_number_of_episodes": 18068, "number_of_timesteps": 5035890, "per_episode_reward": 279.71, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.5714285714285552},
{"total_number_of_episodes": 18078, "number_of_timesteps": 5040155, "per_episode_reward": 279.79, "episode_reward_trend_value": 0.030952380952380863, "biggest_recent_change": 0.5714285714285552},
{"total_number_of_episodes": 18088, "number_of_timesteps": 5044902, "per_episode_reward": 279.86, "episode_reward_trend_value": 0.028571428571428394, "biggest_recent_change": 0.5714285714285552},
{"total_number_of_episodes": 18098, "number_of_timesteps": 5049637, "per_episode_reward": 280.14, "episode_reward_trend_value": 0.030158730158730253, "biggest_recent_change": 0.5714285714285552},
{"total_number_of_episodes": 18108, "number_of_timesteps": 5054478, "per_episode_reward": 280.43, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.5714285714285552},
{"total_number_of_episodes": 18118, "number_of_timesteps": 5059298, "per_episode_reward": 280.57, "episode_reward_trend_value": 0.028571428571428394, "biggest_recent_change": 0.5714285714285552},
{"total_number_of_episodes": 18128, "number_of_timesteps": 5064289, "per_episode_reward": 280.71, "episode_reward_trend_value": 0.02380952380952408, "biggest_recent_change": 0.4285714285714448},
{"total_number_of_episodes": 18138, "number_of_timesteps": 5069289, "per_episode_reward": 280.93, "episode_reward_trend_value": 0.02301587301587347, "biggest_recent_change": 0.4285714285714448},
{"total_number_of_episodes": 18148, "number_of_timesteps": 5074219, "per_episode_reward": 281.0, "episode_reward_trend_value": 0.01904761904761914, "biggest_recent_change": 0.4285714285714448},
{"total_number_of_episodes": 18158, "number_of_timesteps": 5079198, "per_episode_reward": 281.07, "episode_reward_trend_value": 0.015079365079364809, "biggest_recent_change": 0.28571428571433444},

{"total_number_of_episodes": 18168, "number_of_timesteps": 5084198, "per_episode_reward": 281.36, "episode_reward_trend_value": 0.01746031746031728, "biggest_recent_change": 0.28571428571433444},
{"total_number_of_episodes": 18178, "number_of_timesteps": 5089186, "per_episode_reward": 281.57, "episode_reward_trend_value": 0.01904761904761914, "biggest_recent_change": 0.28571428571433444},
{"total_number_of_episodes": 18188, "number_of_timesteps": 5094186, "per_episode_reward": 281.86, "episode_reward_trend_value": 0.019047619047618505, "biggest_recent_change": 0.2857142857142776},
{"total_number_of_episodes": 18198, "number_of_timesteps": 5098943, "per_episode_reward": 281.86, "episode_reward_trend_value": 0.01587301587301542, "biggest_recent_change": 0.2857142857142776},
{"total_number_of_episodes": 18208, "number_of_timesteps": 5103925, "per_episode_reward": 281.86, "episode_reward_trend_value": 0.014285714285714197, "biggest_recent_change": 0.2857142857142776},
{"total_number_of_episodes": 18218, "number_of_timesteps": 5108834, "per_episode_reward": 282.0, "episode_reward_trend_value": 0.014285714285714197, "biggest_recent_change": 0.2857142857142776},
{"total_number_of_episodes": 18228, "number_of_timesteps": 5113834, "per_episode_reward": 282.36, "episode_reward_trend_value": 0.01587301587301542, "biggest_recent_change": 0.3571428571428328},
{"total_number_of_episodes": 18238, "number_of_timesteps": 5118834, "per_episode_reward": 282.71, "episode_reward_trend_value": 0.01904761904761914, "biggest_recent_change": 0.3571428571428896},

{"total_number_of_episodes": 18248, "number_of_timesteps": 5123834, "per_episode_reward": 282.71, "episode_reward_trend_value": 0.018253968253968526, "biggest_recent_change": 0.3571428571428896},
{"total_number_of_episodes": 18258, "number_of_timesteps": 5128834, "per_episode_reward": 283.0, "episode_reward_trend_value": 0.018253968253968526, "biggest_recent_change": 0.3571428571428896},
{"total_number_of_episodes": 18268, "number_of_timesteps": 5133704, "per_episode_reward": 283.5, "episode_reward_trend_value": 0.02142857142857161, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 18278, "number_of_timesteps": 5138702, "per_episode_reward": 284.0, "episode_reward_trend_value": 0.02380952380952408, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 18288, "number_of_timesteps": 5143702, "per_episode_reward": 284.43, "episode_reward_trend_value": 0.028571428571429025, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 18298, "number_of_timesteps": 5148702, "per_episode_reward": 284.5, "episode_reward_trend_value": 0.02936507936507964, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 18308, "number_of_timesteps": 5153702, "per_episode_reward": 284.93, "episode_reward_trend_value": 0.032539682539682716, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 18318, "number_of_timesteps": 5158702, "per_episode_reward": 285.29, "episode_reward_trend_value": 0.032539682539682716, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 18329, "number_of_timesteps": 5164202, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 18339, "number_of_timesteps": 5169202, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 18350, "number_of_timesteps": 5174563, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.030158730158730253, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 18360, "number_of_timesteps": 5179563, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.024603174603174693, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 18371, "number_of_timesteps": 5185063, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.01904761904761914, "biggest_recent_change": 0.4285714285714448},
{"total_number_of_episodes": 18381, "number_of_timesteps": 5190063, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.014285714285714197, "biggest_recent_change": 0.4285714285714448},
{"total_number_of_episodes": 18392, "number_of_timesteps": 5195563, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.013492063492063583, "biggest_recent_change": 0.4285714285714448},
{"total_number_of_episodes": 18402, "number_of_timesteps": 5200563, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.00873015873015864, "biggest_recent_change": 0.4285714285714448},
{"total_number_of_episodes": 18413, "number_of_timesteps": 5206063, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.004761904761904942, "biggest_recent_change": 0.4285714285714448},
{"total_number_of_episodes": 18423, "number_of_timesteps": 5211063, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18434, "number_of_timesteps": 5216563, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18444, "number_of_timesteps": 5221563, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18455, "number_of_timesteps": 5227063, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18465, "number_of_timesteps": 5232063, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18476, "number_of_timesteps": 5237563, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18486, "number_of_timesteps": 5242563, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18497, "number_of_timesteps": 5248063, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18507, "number_of_timesteps": 5253063, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18518, "number_of_timesteps": 5258563, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18528, "number_of_timesteps": 5263563, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18539, "number_of_timesteps": 5269063, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18549, "number_of_timesteps": 5273976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18560, "number_of_timesteps": 5279476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18570, "number_of_timesteps": 5284476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18581, "number_of_timesteps": 5289976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18591, "number_of_timesteps": 5294976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18602, "number_of_timesteps": 5300476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18612, "number_of_timesteps": 5305476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18623, "number_of_timesteps": 5310976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18633, "number_of_timesteps": 5315976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18644, "number_of_timesteps": 5321476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18654, "number_of_timesteps": 5326476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18665, "number_of_timesteps": 5331976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18675, "number_of_timesteps": 5336976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18686, "number_of_timesteps": 5342476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18696, "number_of_timesteps": 5347476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18707, "number_of_timesteps": 5352976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18717, "number_of_timesteps": 5357976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18728, "number_of_timesteps": 5363476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18738, "number_of_timesteps": 5368476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18749, "number_of_timesteps": 5373976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18759, "number_of_timesteps": 5378976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18770, "number_of_timesteps": 5384476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18780, "number_of_timesteps": 5389476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18791, "number_of_timesteps": 5394976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18801, "number_of_timesteps": 5399976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18812, "number_of_timesteps": 5405476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18822, "number_of_timesteps": 5410476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18833, "number_of_timesteps": 5415976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18843, "number_of_timesteps": 5420976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18854, "number_of_timesteps": 5426476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18864, "number_of_timesteps": 5431476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18875, "number_of_timesteps": 5436976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18885, "number_of_timesteps": 5441976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18896, "number_of_timesteps": 5447476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18906, "number_of_timesteps": 5452476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18917, "number_of_timesteps": 5457976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18927, "number_of_timesteps": 5462976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18938, "number_of_timesteps": 5468476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18948, "number_of_timesteps": 5473476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18959, "number_of_timesteps": 5478976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18969, "number_of_timesteps": 5483976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18980, "number_of_timesteps": 5489476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18990, "number_of_timesteps": 5494476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19001, "number_of_timesteps": 5499976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19011, "number_of_timesteps": 5504976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19022, "number_of_timesteps": 5510476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19032, "number_of_timesteps": 5515476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19043, "number_of_timesteps": 5520976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19053, "number_of_timesteps": 5525976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19064, "number_of_timesteps": 5531476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19074, "number_of_timesteps": 5536476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19085, "number_of_timesteps": 5541976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19095, "number_of_timesteps": 5546976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19106, "number_of_timesteps": 5552476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19116, "number_of_timesteps": 5557476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19127, "number_of_timesteps": 5562976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19137, "number_of_timesteps": 5567976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19148, "number_of_timesteps": 5573476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19158, "number_of_timesteps": 5578476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19169, "number_of_timesteps": 5583976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19179, "number_of_timesteps": 5588976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19190, "number_of_timesteps": 5594476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19200, "number_of_timesteps": 5599476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19211, "number_of_timesteps": 5604976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19221, "number_of_timesteps": 5609976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19232, "number_of_timesteps": 5615476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19242, "number_of_timesteps": 5620476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19253, "number_of_timesteps": 5625976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19263, "number_of_timesteps": 5630976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19274, "number_of_timesteps": 5636476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19284, "number_of_timesteps": 5641476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19295, "number_of_timesteps": 5646976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19305, "number_of_timesteps": 5651976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19316, "number_of_timesteps": 5657476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19326, "number_of_timesteps": 5662476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19337, "number_of_timesteps": 5667976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19347, "number_of_timesteps": 5672976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19358, "number_of_timesteps": 5678476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19368, "number_of_timesteps": 5683476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19379, "number_of_timesteps": 5688976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19389, "number_of_timesteps": 5693976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19400, "number_of_timesteps": 5699476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19410, "number_of_timesteps": 5704476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19421, "number_of_timesteps": 5709976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19431, "number_of_timesteps": 5714976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19442, "number_of_timesteps": 5720476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19452, "number_of_timesteps": 5725476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19463, "number_of_timesteps": 5730976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19473, "number_of_timesteps": 5735976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19484, "number_of_timesteps": 5741476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19494, "number_of_timesteps": 5746476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19505, "number_of_timesteps": 5751976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19515, "number_of_timesteps": 5756976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19526, "number_of_timesteps": 5762476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19536, "number_of_timesteps": 5767476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19547, "number_of_timesteps": 5772976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19557, "number_of_timesteps": 5777976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19568, "number_of_timesteps": 5783476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19578, "number_of_timesteps": 5788476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19589, "number_of_timesteps": 5793976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19599, "number_of_timesteps": 5798976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19610, "number_of_timesteps": 5804476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19620, "number_of_timesteps": 5809476, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19631, "number_of_timesteps": 5814976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19641, "number_of_timesteps": 5819976, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19651, "number_of_timesteps": 5824499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19661, "number_of_timesteps": 5829499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19671, "number_of_timesteps": 5834499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19681, "number_of_timesteps": 5839499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19691, "number_of_timesteps": 5844499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19701, "number_of_timesteps": 5849499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19711, "number_of_timesteps": 5854499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19721, "number_of_timesteps": 5859499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19731, "number_of_timesteps": 5864499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19741, "number_of_timesteps": 5869499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19751, "number_of_timesteps": 5874499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19761, "number_of_timesteps": 5879499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19771, "number_of_timesteps": 5884499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19781, "number_of_timesteps": 5889499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19791, "number_of_timesteps": 5894499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19801, "number_of_timesteps": 5899499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19811, "number_of_timesteps": 5904499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19821, "number_of_timesteps": 5909499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19831, "number_of_timesteps": 5914499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19841, "number_of_timesteps": 5919499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19851, "number_of_timesteps": 5924499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19861, "number_of_timesteps": 5929499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19871, "number_of_timesteps": 5934499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19881, "number_of_timesteps": 5939499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19891, "number_of_timesteps": 5944499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19901, "number_of_timesteps": 5949499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19911, "number_of_timesteps": 5954499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19921, "number_of_timesteps": 5959499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19931, "number_of_timesteps": 5964499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19941, "number_of_timesteps": 5969499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19951, "number_of_timesteps": 5974499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19961, "number_of_timesteps": 5979499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19971, "number_of_timesteps": 5984499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19981, "number_of_timesteps": 5989499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19991, "number_of_timesteps": 5994499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20001, "number_of_timesteps": 5999499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20011, "number_of_timesteps": 6004499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20021, "number_of_timesteps": 6009499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20031, "number_of_timesteps": 6014499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20041, "number_of_timesteps": 6019499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20051, "number_of_timesteps": 6024499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20061, "number_of_timesteps": 6029499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20071, "number_of_timesteps": 6034499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20081, "number_of_timesteps": 6039499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20091, "number_of_timesteps": 6044499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20101, "number_of_timesteps": 6049499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20111, "number_of_timesteps": 6054499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20121, "number_of_timesteps": 6059499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20131, "number_of_timesteps": 6064499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20141, "number_of_timesteps": 6069499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20151, "number_of_timesteps": 6074499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20161, "number_of_timesteps": 6079499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20171, "number_of_timesteps": 6084499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20181, "number_of_timesteps": 6089499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20191, "number_of_timesteps": 6094499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20201, "number_of_timesteps": 6099499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20211, "number_of_timesteps": 6104499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20221, "number_of_timesteps": 6109499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20231, "number_of_timesteps": 6114499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20241, "number_of_timesteps": 6119499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20251, "number_of_timesteps": 6124499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20261, "number_of_timesteps": 6129499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20271, "number_of_timesteps": 6134499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20281, "number_of_timesteps": 6139499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20291, "number_of_timesteps": 6144499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20301, "number_of_timesteps": 6149499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20311, "number_of_timesteps": 6154499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20321, "number_of_timesteps": 6159499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20331, "number_of_timesteps": 6164499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20341, "number_of_timesteps": 6169499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20351, "number_of_timesteps": 6174499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20361, "number_of_timesteps": 6179499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20371, "number_of_timesteps": 6184499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20381, "number_of_timesteps": 6189499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20391, "number_of_timesteps": 6194499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20401, "number_of_timesteps": 6199499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20411, "number_of_timesteps": 6204499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20421, "number_of_timesteps": 6209499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20431, "number_of_timesteps": 6214499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20441, "number_of_timesteps": 6219499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20451, "number_of_timesteps": 6224499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20461, "number_of_timesteps": 6229499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20471, "number_of_timesteps": 6234499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20481, "number_of_timesteps": 6239499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20491, "number_of_timesteps": 6244499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20501, "number_of_timesteps": 6249499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20511, "number_of_timesteps": 6254499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20521, "number_of_timesteps": 6259499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20531, "number_of_timesteps": 6264499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20541, "number_of_timesteps": 6269499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20551, "number_of_timesteps": 6274499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20561, "number_of_timesteps": 6279499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20571, "number_of_timesteps": 6284499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20581, "number_of_timesteps": 6289499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20591, "number_of_timesteps": 6294499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20601, "number_of_timesteps": 6299499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20611, "number_of_timesteps": 6304499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20621, "number_of_timesteps": 6309499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20631, "number_of_timesteps": 6314499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20641, "number_of_timesteps": 6319499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20651, "number_of_timesteps": 6324499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20661, "number_of_timesteps": 6329499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20671, "number_of_timesteps": 6334499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20681, "number_of_timesteps": 6339499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20691, "number_of_timesteps": 6344499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20701, "number_of_timesteps": 6349499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20711, "number_of_timesteps": 6354499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20721, "number_of_timesteps": 6359499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20731, "number_of_timesteps": 6364499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20741, "number_of_timesteps": 6369499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20751, "number_of_timesteps": 6374499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20761, "number_of_timesteps": 6379499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20771, "number_of_timesteps": 6384499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20781, "number_of_timesteps": 6389499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20791, "number_of_timesteps": 6394499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20801, "number_of_timesteps": 6399499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20811, "number_of_timesteps": 6404499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20821, "number_of_timesteps": 6409499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20831, "number_of_timesteps": 6414499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20841, "number_of_timesteps": 6419499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20851, "number_of_timesteps": 6424499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20861, "number_of_timesteps": 6429499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20871, "number_of_timesteps": 6434499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20881, "number_of_timesteps": 6439499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20891, "number_of_timesteps": 6444499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20901, "number_of_timesteps": 6449499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20911, "number_of_timesteps": 6454499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20921, "number_of_timesteps": 6459499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20931, "number_of_timesteps": 6464499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20941, "number_of_timesteps": 6469499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20951, "number_of_timesteps": 6474499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20961, "number_of_timesteps": 6479499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20971, "number_of_timesteps": 6484499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20981, "number_of_timesteps": 6489499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
exited at update_barrier.wait(): 5, error = 
None
exited at update_barrier.wait(): 6, error = 
None
exited at update_barrier.wait(): 2, error = 
None
exited at all_updated_barrier.wait(): 0, error = 
None
{"total_number_of_episodes": 20991, "number_of_timesteps": 6494499, "per_episode_reward": 285.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
exited at all_updated_barrier.wait(): 3, error = 
None
exited at all_updated_barrier.wait(): 4, error = 
None
[done calling async_.run_async()]
final_eval: {'number_of_steps': 125000, 'number_of_episodes': None, 'mean': 500.0, 'median': 500.0, 'stdev': 0.0}
[starting train_a3c()]
[starting train_agent_async()]
[about to call async_.run_async()]
[starting run_func()]
[starting train_loop()]
Step 0 0 visits [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1 0 visits [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-4.107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2 1 visits [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-4.107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 3 2 visits [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 1 q_vals: [-4.107, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0]
Step 4 3 visits [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 2 q_vals: [-4.107, 0.0, -5.017, -6.18, 0.0, 0.0, 0.0]
Step 5 4 visits [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 5 q_vals: [-4.107, 0.0, -5.017, -6.18, -5.105, 0.0, 0.0]
Step 6 5 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 5 q_vals: [-4.107, 0.0, -5.017, -6.18, -5.105, -4.439, 0.0]
Step 7 6 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 7 q_vals: [-4.107, 0.0, -5.017, -6.18, -5.105, -4.439, -3.846]
Step 8 1 visits [1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 8 q_vals: [-4.107, -3.0, -5.017, -6.18, -5.105, -4.439, -3.846]
Step 9 1 visits [1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 9 q_vals: [-4.107, -3.442, -5.017, -6.18, -5.105, -4.439, -3.846]
Step 10 6 visits [1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0]  episode_count: 9 q_vals: [-4.107, -3.442, -5.017, -6.18, -5.105, -4.439, -4.071]
Step 11 1 visits [1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0]  episode_count: 11 q_vals: [-4.107, -3.717, -5.017, -6.18, -5.105, -4.439, -4.071]
Step 12 0 visits [2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0]  episode_count: 13 q_vals: [-4.19, -3.717, -5.017, -6.18, -5.105, -4.439, -4.071]
Step 13 5 visits [2.0, 4.0, 1.0, 1.0, 1.0, 2.0, 2.0]  episode_count: 15 q_vals: [-4.19, -3.717, -5.017, -6.18, -5.105, -4.435, -4.071]
Step 14 1 visits [2.0, 5.0, 1.0, 1.0, 1.0, 2.0, 2.0]  episode_count: 16 q_vals: [-4.19, -3.886, -5.017, -6.18, -5.105, -4.435, -4.071]
Step 15 6 visits [2.0, 5.0, 1.0, 1.0, 1.0, 2.0, 3.0]  episode_count: 16 q_vals: [-4.19, -3.886, -5.017, -6.18, -5.105, -4.435, -4.117]
Step 16 0 visits [3.0, 5.0, 1.0, 1.0, 1.0, 2.0, 3.0]  episode_count: 20 q_vals: [-4.356, -3.886, -5.017, -6.18, -5.105, -4.435, -4.117]
Step 17 1 visits [3.0, 6.0, 1.0, 1.0, 1.0, 2.0, 3.0]  episode_count: 20 q_vals: [-4.356, -4.08, -5.017, -6.18, -5.105, -4.435, -4.117]
Step 18 6 visits [3.0, 6.0, 1.0, 1.0, 1.0, 2.0, 4.0]  episode_count: 20 q_vals: [-4.356, -4.08, -5.017, -6.18, -5.105, -4.435, -3.088]
Step 19 6 visits [3.0, 6.0, 1.0, 1.0, 1.0, 2.0, 5.0]  episode_count: 22 q_vals: [-4.356, -4.08, -5.017, -6.18, -5.105, -4.435, -2.47]
Step 20 6 visits [3.0, 6.0, 1.0, 1.0, 1.0, 2.0, 6.0]  episode_count: 24 q_vals: [-4.356, -4.08, -5.017, -6.18, -5.105, -4.435, -3.094]
Step 21 6 visits [3.0, 6.0, 1.0, 1.0, 1.0, 2.0, 7.0]  episode_count: 26 q_vals: [-4.356, -4.08, -5.017, -6.18, -5.105, -4.435, -3.409]
Step 22 6 visits [3.0, 6.0, 1.0, 1.0, 1.0, 2.0, 8.0]  episode_count: 26 q_vals: [-4.356, -4.08, -5.017, -6.18, -5.105, -4.435, -3.303]
Step 23 6 visits [3.0, 6.0, 1.0, 1.0, 1.0, 2.0, 9.0]  episode_count: 30 q_vals: [-4.356, -4.08, -5.017, -6.18, -5.105, -4.435, -3.518]
{"total_number_of_episodes": 32, "number_of_timesteps": 747, "per_episode_reward": 24.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Step 24 6 visits [3.0, 6.0, 1.0, 1.0, 1.0, 2.0, 10.0]  episode_count: 32 q_vals: [-4.356, -4.08, -5.017, -6.18, -5.105, -4.435, -3.166]
Step 25 6 visits [3.0, 6.0, 1.0, 1.0, 1.0, 2.0, 11.0]  episode_count: 32 q_vals: [-4.356, -4.08, -5.017, -6.18, -5.105, -4.435, -3.34]
Step 26 6 visits [3.0, 6.0, 1.0, 1.0, 1.0, 2.0, 12.0]  episode_count: 36 q_vals: [-4.356, -4.08, -5.017, -6.18, -5.105, -4.435, -3.481]
Step 27 6 visits [3.0, 6.0, 1.0, 1.0, 1.0, 2.0, 13.0]  episode_count: 37 q_vals: [-4.356, -4.08, -5.017, -6.18, -5.105, -4.435, -3.68]
Step 28 5 visits [3.0, 6.0, 1.0, 1.0, 1.0, 3.0, 13.0]  episode_count: 37 q_vals: [-4.356, -4.08, -5.017, -6.18, -5.105, -5.01, -3.68]
Step 29 6 visits [3.0, 6.0, 1.0, 1.0, 1.0, 3.0, 14.0]  episode_count: 38 q_vals: [-4.356, -4.08, -5.017, -6.18, -5.105, -5.01, -3.417]
Step 30 6 visits [3.0, 6.0, 1.0, 1.0, 1.0, 3.0, 15.0]  episode_count: 38 q_vals: [-4.356, -4.08, -5.017, -6.18, -5.105, -5.01, -3.751]
Step 31 2 visits [3.0, 6.0, 2.0, 1.0, 1.0, 3.0, 15.0]  episode_count: 39 q_vals: [-4.356, -4.08, -3.229, -6.18, -5.105, -5.01, -3.751]
{"total_number_of_episodes": 42, "number_of_timesteps": 966, "per_episode_reward": 21.79, "episode_reward_trend_value": -0.23571428571428577, "biggest_recent_change": NaN},
Step 32 2 visits [3.0, 6.0, 3.0, 1.0, 1.0, 3.0, 15.0]  episode_count: 42 q_vals: [-4.356, -4.08, -4.117, -6.18, -5.105, -5.01, -3.751]
Step 33 2 visits [3.0, 6.0, 4.0, 1.0, 1.0, 3.0, 15.0]  episode_count: 43 q_vals: [-4.356, -4.08, -5.354, -6.18, -5.105, -5.01, -3.751]
Step 34 4 visits [3.0, 6.0, 4.0, 1.0, 2.0, 3.0, 15.0]  episode_count: 45 q_vals: [-4.356, -4.08, -5.354, -6.18, -6.354, -5.01, -3.751]
Step 35 6 visits [3.0, 6.0, 4.0, 1.0, 2.0, 3.0, 16.0]  episode_count: 46 q_vals: [-4.356, -4.08, -5.354, -6.18, -6.354, -5.01, -3.954]
Step 36 0 visits [4.0, 6.0, 4.0, 1.0, 2.0, 3.0, 16.0]  episode_count: 47 q_vals: [-3.267, -4.08, -5.354, -6.18, -6.354, -5.01, -3.954]
Step 37 0 visits [5.0, 6.0, 4.0, 1.0, 2.0, 3.0, 16.0]  episode_count: 47 q_vals: [-2.613, -4.08, -5.354, -6.18, -6.354, -5.01, -3.954]
Step 38 0 visits [6.0, 6.0, 4.0, 1.0, 2.0, 3.0, 16.0]  episode_count: 49 q_vals: [-3.594, -4.08, -5.354, -6.18, -6.354, -5.01, -3.954]
Step 39 0 visits [7.0, 6.0, 4.0, 1.0, 2.0, 3.0, 16.0]  episode_count: 49 q_vals: [-3.346, -4.08, -5.354, -6.18, -6.354, -5.01, -3.954]
Step 40 0 visits [8.0, 6.0, 4.0, 1.0, 2.0, 3.0, 16.0]  episode_count: 51 q_vals: [-3.823, -4.08, -5.354, -6.18, -6.354, -5.01, -3.954]
Step 41 0 visits [9.0, 6.0, 4.0, 1.0, 2.0, 3.0, 16.0]  episode_count: 51 q_vals: [-4.369, -4.08, -5.354, -6.18, -6.354, -5.01, -3.954]
{"total_number_of_episodes": 52, "number_of_timesteps": 1227, "per_episode_reward": 21.07, "episode_reward_trend_value": -0.15357142857142847, "biggest_recent_change": NaN},
Step 42 1 visits [9.0, 7.0, 4.0, 1.0, 2.0, 3.0, 16.0]  episode_count: 52 q_vals: [-4.369, -4.829, -5.354, -6.18, -6.354, -5.01, -3.954]
Step 43 6 visits [9.0, 7.0, 4.0, 1.0, 2.0, 3.0, 17.0]  episode_count: 53 q_vals: [-4.369, -4.829, -5.354, -6.18, -6.354, -5.01, -4.21]
Step 44 0 visits [10.0, 7.0, 4.0, 1.0, 2.0, 3.0, 17.0]  episode_count: 54 q_vals: [-5.043, -4.829, -5.354, -6.18, -6.354, -5.01, -4.21]
Step 45 6 visits [10.0, 7.0, 4.0, 1.0, 2.0, 3.0, 18.0]  episode_count: 54 q_vals: [-5.043, -4.829, -5.354, -6.18, -6.354, -5.01, -4.508]
Step 46 5 visits [10.0, 7.0, 4.0, 1.0, 2.0, 4.0, 18.0]  episode_count: 57 q_vals: [-5.043, -4.829, -5.354, -6.18, -6.354, -6.535, -4.508]
Step 47 6 visits [10.0, 7.0, 4.0, 1.0, 2.0, 4.0, 19.0]  episode_count: 59 q_vals: [-5.043, -4.829, -5.354, -6.18, -6.354, -6.535, -4.271]
Step 48 6 visits [10.0, 7.0, 4.0, 1.0, 2.0, 4.0, 20.0]  episode_count: 59 q_vals: [-5.043, -4.829, -5.354, -6.18, -6.354, -6.535, -4.613]
Step 49 1 visits [10.0, 8.0, 4.0, 1.0, 2.0, 4.0, 20.0]  episode_count: 59 q_vals: [-5.043, -4.728, -5.354, -6.18, -6.354, -6.535, -4.613]
{"total_number_of_episodes": 64, "number_of_timesteps": 1567, "per_episode_reward": 22.0, "episode_reward_trend_value": -0.07142857142857141, "biggest_recent_change": NaN},
Step 50 1 visits [10.0, 9.0, 4.0, 1.0, 2.0, 4.0, 20.0]  episode_count: 64 q_vals: [-5.043, -5.419, -5.354, -6.18, -6.354, -6.535, -4.613]
Step 51 6 visits [10.0, 9.0, 4.0, 1.0, 2.0, 4.0, 21.0]  episode_count: 65 q_vals: [-5.043, -5.419, -5.354, -6.18, -6.354, -6.535, -4.873]
Step 52 3 visits [10.0, 9.0, 4.0, 2.0, 2.0, 4.0, 21.0]  episode_count: 66 q_vals: [-5.043, -5.419, -5.354, -8.646, -6.354, -6.535, -4.873]
Step 53 2 visits [10.0, 9.0, 5.0, 2.0, 2.0, 4.0, 21.0]  episode_count: 67 q_vals: [-5.043, -5.419, -5.4, -8.646, -6.354, -6.535, -4.873]
Step 54 0 visits [11.0, 9.0, 5.0, 2.0, 2.0, 4.0, 21.0]  episode_count: 70 q_vals: [-5.595, -5.419, -5.4, -8.646, -6.354, -6.535, -4.873]
Step 55 6 visits [11.0, 9.0, 5.0, 2.0, 2.0, 4.0, 22.0]  episode_count: 72 q_vals: [-5.595, -5.419, -5.4, -8.646, -6.354, -6.535, -5.131]
{"total_number_of_episodes": 74, "number_of_timesteps": 1767, "per_episode_reward": 21.71, "episode_reward_trend_value": -0.06071428571428568, "biggest_recent_change": NaN},
Step 56 2 visits [11.0, 9.0, 6.0, 2.0, 2.0, 4.0, 22.0]  episode_count: 74 q_vals: [-5.595, -5.419, -6.352, -8.646, -6.354, -6.535, -5.131]
Step 57 6 visits [11.0, 9.0, 6.0, 2.0, 2.0, 4.0, 23.0]  episode_count: 77 q_vals: [-5.595, -5.419, -6.352, -8.646, -6.354, -6.535, -5.391]
Step 58 1 visits [11.0, 10.0, 6.0, 2.0, 2.0, 4.0, 23.0]  episode_count: 78 q_vals: [-5.595, -5.988, -6.352, -8.646, -6.354, -6.535, -5.391]
Step 59 4 visits [11.0, 10.0, 6.0, 2.0, 3.0, 4.0, 23.0]  episode_count: 81 q_vals: [-5.595, -5.988, -6.352, -8.646, -6.763, -6.535, -5.391]
{"total_number_of_episodes": 84, "number_of_timesteps": 1901, "per_episode_reward": 20.0, "episode_reward_trend_value": -0.08285714285714285, "biggest_recent_change": NaN},
Step 60 6 visits [11.0, 10.0, 6.0, 2.0, 3.0, 4.0, 24.0]  episode_count: 84 q_vals: [-5.595, -5.988, -6.352, -8.646, -6.763, -6.535, -5.629]
Step 61 0 visits [12.0, 10.0, 6.0, 2.0, 3.0, 4.0, 24.0]  episode_count: 85 q_vals: [-6.054, -5.988, -6.352, -8.646, -6.763, -6.535, -5.629]
Step 62 6 visits [12.0, 10.0, 6.0, 2.0, 3.0, 4.0, 25.0]  episode_count: 87 q_vals: [-6.054, -5.988, -6.352, -8.646, -6.763, -6.535, -5.849]
Step 63 1 visits [12.0, 11.0, 6.0, 2.0, 3.0, 4.0, 25.0]  episode_count: 90 q_vals: [-6.054, -5.444, -6.352, -8.646, -6.763, -6.535, -5.849]
Step 64 1 visits [12.0, 12.0, 6.0, 2.0, 3.0, 4.0, 25.0]  episode_count: 92 q_vals: [-6.054, -5.916, -6.352, -8.646, -6.763, -6.535, -5.849]
{"total_number_of_episodes": 94, "number_of_timesteps": 2040, "per_episode_reward": 17.43, "episode_reward_trend_value": -0.11190476190476192, "biggest_recent_change": NaN},
Step 65 1 visits [12.0, 13.0, 6.0, 2.0, 3.0, 4.0, 25.0]  episode_count: 94 q_vals: [-6.054, -6.316, -6.352, -8.646, -6.763, -6.535, -5.849]
Step 66 6 visits [12.0, 13.0, 6.0, 2.0, 3.0, 4.0, 26.0]  episode_count: 97 q_vals: [-6.054, -6.316, -6.352, -8.646, -6.763, -6.535, -5.624]
Step 67 6 visits [12.0, 13.0, 6.0, 2.0, 3.0, 4.0, 27.0]  episode_count: 98 q_vals: [-6.054, -6.316, -6.352, -8.646, -6.763, -6.535, -5.827]
Step 68 6 visits [12.0, 13.0, 6.0, 2.0, 3.0, 4.0, 28.0]  episode_count: 101 q_vals: [-6.054, -6.316, -6.352, -8.646, -6.763, -6.535, -6.016]
Step 69 0 visits [13.0, 13.0, 6.0, 2.0, 3.0, 4.0, 28.0]  episode_count: 102 q_vals: [-6.443, -6.316, -6.352, -8.646, -6.763, -6.535, -6.016]
{"total_number_of_episodes": 104, "number_of_timesteps": 2177, "per_episode_reward": 16.43, "episode_reward_trend_value": -0.11020408163265308, "biggest_recent_change": NaN},
Step 70 5 visits [13.0, 13.0, 6.0, 2.0, 3.0, 5.0, 28.0]  episode_count: 104 q_vals: [-6.443, -6.316, -6.352, -8.646, -6.763, -7.45, -6.016]
Step 71 2 visits [13.0, 13.0, 7.0, 2.0, 3.0, 5.0, 28.0]  episode_count: 107 q_vals: [-6.443, -6.316, -7.032, -8.646, -6.763, -7.45, -6.016]
Step 72 4 visits [13.0, 13.0, 7.0, 2.0, 4.0, 5.0, 28.0]  episode_count: 108 q_vals: [-6.443, -6.316, -7.032, -8.646, -7.85, -7.45, -6.016]
Step 73 6 visits [13.0, 13.0, 7.0, 2.0, 4.0, 5.0, 29.0]  episode_count: 111 q_vals: [-6.443, -6.316, -7.032, -8.646, -7.85, -7.45, -6.191]
Step 74 1 visits [13.0, 14.0, 7.0, 2.0, 4.0, 5.0, 29.0]  episode_count: 113 q_vals: [-6.443, -6.658, -7.032, -8.646, -7.85, -7.45, -6.191]
{"total_number_of_episodes": 114, "number_of_timesteps": 2328, "per_episode_reward": 16.36, "episode_reward_trend_value": -0.09732142857142856, "biggest_recent_change": NaN},
Step 75 6 visits [13.0, 14.0, 7.0, 2.0, 4.0, 5.0, 30.0]  episode_count: 114 q_vals: [-6.443, -6.658, -7.032, -8.646, -7.85, -7.45, -6.355]
Step 76 0 visits [14.0, 14.0, 7.0, 2.0, 4.0, 5.0, 30.0]  episode_count: 116 q_vals: [-6.777, -6.658, -7.032, -8.646, -7.85, -7.45, -6.355]
Step 77 6 visits [14.0, 14.0, 7.0, 2.0, 4.0, 5.0, 31.0]  episode_count: 116 q_vals: [-6.777, -6.658, -7.032, -8.646, -7.85, -7.45, -6.15]
Step 78 6 visits [14.0, 14.0, 7.0, 2.0, 4.0, 5.0, 32.0]  episode_count: 119 q_vals: [-6.777, -6.658, -7.032, -8.646, -7.85, -7.45, -6.305]
Step 79 6 visits [14.0, 14.0, 7.0, 2.0, 4.0, 5.0, 33.0]  episode_count: 122 q_vals: [-6.777, -6.658, -7.032, -8.646, -7.85, -7.45, -6.451]
Step 80 6 visits [14.0, 14.0, 7.0, 2.0, 4.0, 5.0, 34.0]  episode_count: 122 q_vals: [-6.777, -6.658, -7.032, -8.646, -7.85, -7.45, -6.588]
Step 81 1 visits [14.0, 15.0, 7.0, 2.0, 4.0, 5.0, 34.0]  episode_count: 123 q_vals: [-6.777, -6.955, -7.032, -8.646, -7.85, -7.45, -6.588]
{"total_number_of_episodes": 124, "number_of_timesteps": 2508, "per_episode_reward": 16.43, "episode_reward_trend_value": -0.08571428571428572, "biggest_recent_change": 2.571428571428573},
Step 82 0 visits [15.0, 15.0, 7.0, 2.0, 4.0, 5.0, 34.0]  episode_count: 124 q_vals: [-7.066, -6.955, -7.032, -8.646, -7.85, -7.45, -6.588]
Step 83 6 visits [15.0, 15.0, 7.0, 2.0, 4.0, 5.0, 35.0]  episode_count: 126 q_vals: [-7.066, -6.955, -7.032, -8.646, -7.85, -7.45, -6.717]
Step 84 2 visits [15.0, 15.0, 8.0, 2.0, 4.0, 5.0, 35.0]  episode_count: 127 q_vals: [-7.066, -6.955, -7.542, -8.646, -7.85, -7.45, -6.717]
Step 85 6 visits [15.0, 15.0, 8.0, 2.0, 4.0, 5.0, 36.0]  episode_count: 129 q_vals: [-7.066, -6.955, -7.542, -8.646, -7.85, -7.45, -6.839]
Step 86 1 visits [15.0, 16.0, 8.0, 2.0, 4.0, 5.0, 36.0]  episode_count: 130 q_vals: [-7.066, -7.215, -7.542, -8.646, -7.85, -7.45, -6.839]
{"total_number_of_episodes": 134, "number_of_timesteps": 2736, "per_episode_reward": 17.14, "episode_reward_trend_value": -0.051587301587301584, "biggest_recent_change": 2.571428571428573},
Step 87 6 visits [15.0, 16.0, 8.0, 2.0, 4.0, 5.0, 37.0]  episode_count: 134 q_vals: [-7.066, -7.215, -7.542, -8.646, -7.85, -7.45, -6.955]
Step 88 5 visits [15.0, 16.0, 8.0, 2.0, 4.0, 6.0, 37.0]  episode_count: 135 q_vals: [-7.066, -7.215, -7.542, -8.646, -7.85, -8.06, -6.955]
Step 89 0 visits [16.0, 16.0, 8.0, 2.0, 4.0, 6.0, 37.0]  episode_count: 136 q_vals: [-7.319, -7.215, -7.542, -8.646, -7.85, -8.06, -6.955]
Step 90 6 visits [16.0, 16.0, 8.0, 2.0, 4.0, 6.0, 38.0]  episode_count: 137 q_vals: [-7.319, -7.215, -7.542, -8.646, -7.85, -8.06, -7.064]
Step 91 1 visits [16.0, 17.0, 8.0, 2.0, 4.0, 6.0, 38.0]  episode_count: 138 q_vals: [-7.319, -7.444, -7.542, -8.646, -7.85, -8.06, -7.064]
Step 92 6 visits [16.0, 17.0, 8.0, 2.0, 4.0, 6.0, 39.0]  episode_count: 140 q_vals: [-7.319, -7.444, -7.542, -8.646, -7.85, -8.06, -7.168]
Step 93 4 visits [16.0, 17.0, 8.0, 2.0, 5.0, 6.0, 39.0]  episode_count: 140 q_vals: [-7.319, -7.444, -7.542, -8.646, -6.28, -8.06, -7.168]
Step 94 4 visits [16.0, 17.0, 8.0, 2.0, 6.0, 6.0, 39.0]  episode_count: 141 q_vals: [-7.319, -7.444, -7.542, -8.646, -7.085, -8.06, -7.168]
Step 95 4 visits [16.0, 17.0, 8.0, 2.0, 7.0, 6.0, 39.0]  episode_count: 143 q_vals: [-7.319, -7.444, -7.542, -8.646, -6.073, -8.06, -7.168]
Step 96 4 visits [16.0, 17.0, 8.0, 2.0, 8.0, 6.0, 39.0]  episode_count: 143 q_vals: [-7.319, -7.444, -7.542, -8.646, -6.703, -8.06, -7.168]
{"total_number_of_episodes": 144, "number_of_timesteps": 2945, "per_episode_reward": 17.36, "episode_reward_trend_value": -0.041269841269841276, "biggest_recent_change": 2.571428571428573},
Step 97 4 visits [16.0, 17.0, 8.0, 2.0, 9.0, 6.0, 39.0]  episode_count: 144 q_vals: [-7.319, -7.444, -7.542, -8.646, -7.193, -8.06, -7.168]
Step 98 4 visits [16.0, 17.0, 8.0, 2.0, 10.0, 6.0, 39.0]  episode_count: 145 q_vals: [-7.319, -7.444, -7.542, -8.646, -7.584, -8.06, -7.168]
Step 99 0 visits [17.0, 17.0, 8.0, 2.0, 10.0, 6.0, 39.0]  episode_count: 148 q_vals: [-7.542, -7.444, -7.542, -8.646, -7.584, -8.06, -7.168]
Step 100 2 visits [17.0, 17.0, 9.0, 2.0, 10.0, 6.0, 39.0]  episode_count: 149 q_vals: [-7.542, -7.444, -7.939, -8.646, -7.584, -8.06, -7.168]
Step 101 6 visits [17.0, 17.0, 9.0, 2.0, 10.0, 6.0, 40.0]  episode_count: 152 q_vals: [-7.542, -7.444, -7.939, -8.646, -7.584, -8.06, -7.267]
Step 102 4 visits [17.0, 17.0, 9.0, 2.0, 11.0, 6.0, 40.0]  episode_count: 152 q_vals: [-7.542, -7.444, -7.939, -8.646, -7.905, -8.06, -7.267]
Step 103 1 visits [17.0, 18.0, 9.0, 2.0, 11.0, 6.0, 40.0]  episode_count: 153 q_vals: [-7.542, -7.648, -7.939, -8.646, -7.905, -8.06, -7.267]
{"total_number_of_episodes": 155, "number_of_timesteps": 3240, "per_episode_reward": 17.5, "episode_reward_trend_value": -0.05, "biggest_recent_change": 2.571428571428573},
Step 104 6 visits [17.0, 18.0, 9.0, 2.0, 11.0, 6.0, 41.0]  episode_count: 155 q_vals: [-7.542, -7.648, -7.939, -8.646, -7.905, -8.06, -7.36]
Step 105 0 visits [18.0, 18.0, 9.0, 2.0, 11.0, 6.0, 41.0]  episode_count: 156 q_vals: [-7.74, -7.648, -7.939, -8.646, -7.905, -8.06, -7.36]
Step 106 6 visits [18.0, 18.0, 9.0, 2.0, 11.0, 6.0, 42.0]  episode_count: 158 q_vals: [-7.74, -7.648, -7.939, -8.646, -7.905, -8.06, -7.45]
Step 107 6 visits [18.0, 18.0, 9.0, 2.0, 11.0, 6.0, 43.0]  episode_count: 160 q_vals: [-7.74, -7.648, -7.939, -8.646, -7.905, -8.06, -7.535]
Step 108 3 visits [18.0, 18.0, 9.0, 3.0, 11.0, 6.0, 43.0]  episode_count: 162 q_vals: [-7.74, -7.648, -7.939, -9.468, -7.905, -8.06, -7.535]
Step 109 1 visits [18.0, 19.0, 9.0, 3.0, 11.0, 6.0, 43.0]  episode_count: 164 q_vals: [-7.74, -7.83, -7.939, -9.468, -7.905, -8.06, -7.535]
Step 110 5 visits [18.0, 19.0, 9.0, 3.0, 11.0, 7.0, 43.0]  episode_count: 164 q_vals: [-7.74, -7.83, -7.939, -9.468, -7.905, -8.496, -7.535]
{"total_number_of_episodes": 167, "number_of_timesteps": 3483, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.041269841269841276, "biggest_recent_change": 2.571428571428573},
Step 111 6 visits [18.0, 19.0, 9.0, 3.0, 11.0, 7.0, 44.0]  episode_count: 167 q_vals: [-7.74, -7.83, -7.939, -9.468, -7.905, -8.496, -7.616]
Step 112 2 visits [18.0, 19.0, 10.0, 3.0, 11.0, 7.0, 44.0]  episode_count: 167 q_vals: [-7.74, -7.83, -8.256, -9.468, -7.905, -8.496, -7.616]
Step 113 0 visits [19.0, 19.0, 10.0, 3.0, 11.0, 7.0, 44.0]  episode_count: 169 q_vals: [-7.917, -7.83, -8.256, -9.468, -7.905, -8.496, -7.616]
Step 114 4 visits [19.0, 19.0, 10.0, 3.0, 12.0, 7.0, 44.0]  episode_count: 171 q_vals: [-7.917, -7.83, -8.256, -9.468, -8.172, -8.496, -7.616]
Step 115 6 visits [19.0, 19.0, 10.0, 3.0, 12.0, 7.0, 45.0]  episode_count: 173 q_vals: [-7.917, -7.83, -8.256, -9.468, -8.172, -8.496, -7.694]
Step 116 1 visits [19.0, 20.0, 10.0, 3.0, 12.0, 7.0, 45.0]  episode_count: 175 q_vals: [-7.917, -7.994, -8.256, -9.468, -8.172, -8.496, -7.694]
Step 117 6 visits [19.0, 20.0, 10.0, 3.0, 12.0, 7.0, 46.0]  episode_count: 175 q_vals: [-7.917, -7.994, -8.256, -9.468, -8.172, -8.496, -7.526]
Step 118 6 visits [19.0, 20.0, 10.0, 3.0, 12.0, 7.0, 47.0]  episode_count: 176 q_vals: [-7.917, -7.994, -8.256, -9.468, -8.172, -8.496, -7.603]
{"total_number_of_episodes": 178, "number_of_timesteps": 3699, "per_episode_reward": 17.79, "episode_reward_trend_value": -0.024603174603174616, "biggest_recent_change": 2.571428571428573},
Step 119 6 visits [19.0, 20.0, 10.0, 3.0, 12.0, 7.0, 48.0]  episode_count: 178 q_vals: [-7.917, -7.994, -8.256, -9.468, -8.172, -8.496, -7.676]
Step 120 6 visits [19.0, 20.0, 10.0, 3.0, 12.0, 7.0, 49.0]  episode_count: 180 q_vals: [-7.917, -7.994, -8.256, -9.468, -8.172, -8.496, -7.746]
Step 121 0 visits [20.0, 20.0, 10.0, 3.0, 12.0, 7.0, 49.0]  episode_count: 180 q_vals: [-7.522, -7.994, -8.256, -9.468, -8.172, -8.496, -7.746]
Step 122 0 visits [21.0, 20.0, 10.0, 3.0, 12.0, 7.0, 49.0]  episode_count: 180 q_vals: [-7.692, -7.994, -8.256, -9.468, -8.172, -8.496, -7.746]
Step 123 0 visits [22.0, 20.0, 10.0, 3.0, 12.0, 7.0, 49.0]  episode_count: 182 q_vals: [-7.848, -7.994, -8.256, -9.468, -8.172, -8.496, -7.746]
Step 124 0 visits [23.0, 20.0, 10.0, 3.0, 12.0, 7.0, 49.0]  episode_count: 184 q_vals: [-7.99, -7.994, -8.256, -9.468, -8.172, -8.496, -7.746]
Step 125 6 visits [23.0, 20.0, 10.0, 3.0, 12.0, 7.0, 50.0]  episode_count: 184 q_vals: [-7.99, -7.994, -8.256, -9.468, -8.172, -8.496, -7.813]
Step 126 6 visits [23.0, 20.0, 10.0, 3.0, 12.0, 7.0, 51.0]  episode_count: 184 q_vals: [-7.99, -7.994, -8.256, -9.468, -8.172, -8.496, -7.878]
Step 127 1 visits [23.0, 21.0, 10.0, 3.0, 12.0, 7.0, 51.0]  episode_count: 186 q_vals: [-7.99, -8.143, -8.256, -9.468, -8.172, -8.496, -7.878]
{"total_number_of_episodes": 189, "number_of_timesteps": 3997, "per_episode_reward": 17.79, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 1.0},
Step 128 0 visits [24.0, 21.0, 10.0, 3.0, 12.0, 7.0, 51.0]  episode_count: 189 q_vals: [-8.12, -8.143, -8.256, -9.468, -8.172, -8.496, -7.878]
Step 129 4 visits [24.0, 21.0, 10.0, 3.0, 13.0, 7.0, 51.0]  episode_count: 190 q_vals: [-8.12, -8.143, -8.256, -9.468, -8.398, -8.496, -7.878]
Step 130 2 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 51.0]  episode_count: 191 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.878]
Step 131 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 52.0]  episode_count: 193 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.726]
Step 132 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 53.0]  episode_count: 195 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.79]
Step 133 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 54.0]  episode_count: 196 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.852]
Step 134 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 55.0]  episode_count: 198 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.709]
{"total_number_of_episodes": 200, "number_of_timesteps": 4248, "per_episode_reward": 17.86, "episode_reward_trend_value": 0.015873015873015893, "biggest_recent_change": 0.7142857142857153},
Step 135 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 56.0]  episode_count: 200 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.77]
Step 136 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 57.0]  episode_count: 203 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.828]
Step 137 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 58.0]  episode_count: 205 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.885]
Step 138 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 59.0]  episode_count: 205 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.751]
Step 139 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 60.0]  episode_count: 206 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.807]
Step 140 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 61.0]  episode_count: 209 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.861]
Step 141 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 62.0]  episode_count: 209 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.735]
{"total_number_of_episodes": 212, "number_of_timesteps": 4451, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.015079365079365085, "biggest_recent_change": 0.7142857142857153},
Step 142 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 63.0]  episode_count: 212 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.788]
Step 143 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 64.0]  episode_count: 214 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.84]
Step 144 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 65.0]  episode_count: 215 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.72]
Step 145 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 66.0]  episode_count: 215 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.771]
Step 146 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 67.0]  episode_count: 218 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.821]
Step 147 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 68.0]  episode_count: 218 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.869]
Step 148 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 69.0]  episode_count: 219 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.916]
Step 149 6 visits [24.0, 21.0, 11.0, 3.0, 13.0, 7.0, 70.0]  episode_count: 221 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.496, -7.962]
{"total_number_of_episodes": 223, "number_of_timesteps": 4718, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.014285714285714313, "biggest_recent_change": 0.7142857142857153},
Step 150 5 visits [24.0, 21.0, 11.0, 3.0, 13.0, 8.0, 70.0]  episode_count: 223 q_vals: [-8.12, -8.143, -8.515, -9.468, -8.398, -8.823, -7.962]
Step 151 1 visits [24.0, 22.0, 11.0, 3.0, 13.0, 8.0, 70.0]  episode_count: 223 q_vals: [-8.12, -8.278, -8.515, -9.468, -8.398, -8.823, -7.962]
Step 152 0 visits [25.0, 22.0, 11.0, 3.0, 13.0, 8.0, 70.0]  episode_count: 226 q_vals: [-8.239, -8.278, -8.515, -9.468, -8.398, -8.823, -7.962]
Step 153 6 visits [25.0, 22.0, 11.0, 3.0, 13.0, 8.0, 71.0]  episode_count: 228 q_vals: [-8.239, -8.278, -8.515, -9.468, -8.398, -8.823, -8.006]
Step 154 6 visits [25.0, 22.0, 11.0, 3.0, 13.0, 8.0, 72.0]  episode_count: 230 q_vals: [-8.239, -8.278, -8.515, -9.468, -8.398, -8.823, -8.049]
Step 155 4 visits [25.0, 22.0, 11.0, 3.0, 14.0, 8.0, 72.0]  episode_count: 231 q_vals: [-8.239, -8.278, -8.515, -9.468, -8.592, -8.823, -8.049]
Step 156 6 visits [25.0, 22.0, 11.0, 3.0, 14.0, 8.0, 73.0]  episode_count: 231 q_vals: [-8.239, -8.278, -8.515, -9.468, -8.592, -8.823, -8.091]
{"total_number_of_episodes": 234, "number_of_timesteps": 4962, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.5},
Step 157 0 visits [26.0, 22.0, 11.0, 3.0, 14.0, 8.0, 73.0]  episode_count: 234 q_vals: [-8.35, -8.278, -8.515, -9.468, -8.592, -8.823, -8.091]
Step 158 1 visits [26.0, 23.0, 11.0, 3.0, 14.0, 8.0, 73.0]  episode_count: 236 q_vals: [-8.35, -8.401, -8.515, -9.468, -8.592, -8.823, -8.091]
Step 159 6 visits [26.0, 23.0, 11.0, 3.0, 14.0, 8.0, 74.0]  episode_count: 236 q_vals: [-8.35, -8.401, -8.515, -9.468, -8.592, -8.823, -8.132]
Step 160 2 visits [26.0, 23.0, 12.0, 3.0, 14.0, 8.0, 74.0]  episode_count: 239 q_vals: [-8.35, -8.401, -8.732, -9.468, -8.592, -8.823, -8.132]
Step 161 6 visits [26.0, 23.0, 12.0, 3.0, 14.0, 8.0, 75.0]  episode_count: 240 q_vals: [-8.35, -8.401, -8.732, -9.468, -8.592, -8.823, -8.172]
Step 162 0 visits [27.0, 23.0, 12.0, 3.0, 14.0, 8.0, 75.0]  episode_count: 241 q_vals: [-8.452, -8.401, -8.732, -9.468, -8.592, -8.823, -8.172]
Step 163 6 visits [27.0, 23.0, 12.0, 3.0, 14.0, 8.0, 76.0]  episode_count: 242 q_vals: [-8.452, -8.401, -8.732, -9.468, -8.592, -8.823, -8.064]
Step 164 6 visits [27.0, 23.0, 12.0, 3.0, 14.0, 8.0, 77.0]  episode_count: 242 q_vals: [-8.452, -8.401, -8.732, -9.468, -8.592, -8.823, -8.104]
Step 165 6 visits [27.0, 23.0, 12.0, 3.0, 14.0, 8.0, 78.0]  episode_count: 243 q_vals: [-8.452, -8.401, -8.732, -9.468, -8.592, -8.823, -8.142]
{"total_number_of_episodes": 245, "number_of_timesteps": 5191, "per_episode_reward": 17.79, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.5},
Step 166 6 visits [27.0, 23.0, 12.0, 3.0, 14.0, 8.0, 79.0]  episode_count: 245 q_vals: [-8.452, -8.401, -8.732, -9.468, -8.592, -8.823, -8.18]
Step 167 6 visits [27.0, 23.0, 12.0, 3.0, 14.0, 8.0, 80.0]  episode_count: 248 q_vals: [-8.452, -8.401, -8.732, -9.468, -8.592, -8.823, -8.217]
Step 168 1 visits [27.0, 24.0, 12.0, 3.0, 14.0, 8.0, 80.0]  episode_count: 249 q_vals: [-8.452, -8.514, -8.732, -9.468, -8.592, -8.823, -8.217]
Step 169 6 visits [27.0, 24.0, 12.0, 3.0, 14.0, 8.0, 81.0]  episode_count: 249 q_vals: [-8.452, -8.514, -8.732, -9.468, -8.592, -8.823, -8.115]
Step 170 6 visits [27.0, 24.0, 12.0, 3.0, 14.0, 8.0, 82.0]  episode_count: 254 q_vals: [-8.452, -8.514, -8.732, -9.468, -8.592, -8.823, -8.152]
Step 171 6 visits [27.0, 24.0, 12.0, 3.0, 14.0, 8.0, 83.0]  episode_count: 254 q_vals: [-8.452, -8.514, -8.732, -9.468, -8.592, -8.823, -8.187]
{"total_number_of_episodes": 256, "number_of_timesteps": 5454, "per_episode_reward": 17.86, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.5},
Step 172 6 visits [27.0, 24.0, 12.0, 3.0, 14.0, 8.0, 84.0]  episode_count: 256 q_vals: [-8.452, -8.514, -8.732, -9.468, -8.592, -8.823, -8.222]
Step 173 6 visits [27.0, 24.0, 12.0, 3.0, 14.0, 8.0, 85.0]  episode_count: 258 q_vals: [-8.452, -8.514, -8.732, -9.468, -8.592, -8.823, -8.256]
Step 174 4 visits [27.0, 24.0, 12.0, 3.0, 15.0, 8.0, 85.0]  episode_count: 259 q_vals: [-8.452, -8.514, -8.732, -9.468, -8.76, -8.823, -8.256]
Step 175 6 visits [27.0, 24.0, 12.0, 3.0, 15.0, 8.0, 86.0]  episode_count: 260 q_vals: [-8.452, -8.514, -8.732, -9.468, -8.76, -8.823, -8.289]
Step 176 0 visits [28.0, 24.0, 12.0, 3.0, 15.0, 8.0, 86.0]  episode_count: 260 q_vals: [-8.547, -8.514, -8.732, -9.468, -8.76, -8.823, -8.289]
Step 177 5 visits [28.0, 24.0, 12.0, 3.0, 15.0, 9.0, 86.0]  episode_count: 263 q_vals: [-8.547, -8.514, -8.732, -9.468, -8.76, -9.077, -8.289]
Step 178 6 visits [28.0, 24.0, 12.0, 3.0, 15.0, 9.0, 87.0]  episode_count: 263 q_vals: [-8.547, -8.514, -8.732, -9.468, -8.76, -9.077, -8.322]
Step 179 1 visits [28.0, 25.0, 12.0, 3.0, 15.0, 9.0, 87.0]  episode_count: 265 q_vals: [-8.547, -8.618, -8.732, -9.468, -8.76, -9.077, -8.322]
{"total_number_of_episodes": 266, "number_of_timesteps": 5683, "per_episode_reward": 18.29, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.42857142857142705},
Step 180 2 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 87.0]  episode_count: 266 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.322]
Step 181 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 88.0]  episode_count: 267 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.227]
Step 182 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 89.0]  episode_count: 269 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.135]
Step 183 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 90.0]  episode_count: 270 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.168]
Step 184 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 91.0]  episode_count: 270 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.078]
Step 185 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 92.0]  episode_count: 270 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.111]
Step 186 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 93.0]  episode_count: 272 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.143]
Step 187 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 94.0]  episode_count: 275 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.175]
{"total_number_of_episodes": 277, "number_of_timesteps": 5992, "per_episode_reward": 18.36, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.42857142857142705},
Step 188 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 95.0]  episode_count: 277 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.206]
Step 189 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 96.0]  episode_count: 278 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.236]
Step 190 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 97.0]  episode_count: 282 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.151]
Step 191 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 98.0]  episode_count: 283 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.181]
Step 192 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 99.0]  episode_count: 284 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.211]
Step 193 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 100.0]  episode_count: 286 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.24]
{"total_number_of_episodes": 287, "number_of_timesteps": 6139, "per_episode_reward": 18.21, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.42857142857142705},
Step 194 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 101.0]  episode_count: 287 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.268]
Step 195 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 102.0]  episode_count: 288 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.296]
Step 196 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 103.0]  episode_count: 289 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.324]
Step 197 6 visits [28.0, 25.0, 13.0, 3.0, 15.0, 9.0, 104.0]  episode_count: 290 q_vals: [-8.547, -8.618, -8.915, -9.468, -8.76, -9.077, -8.35]
Step 198 0 visits [29.0, 25.0, 13.0, 3.0, 15.0, 9.0, 104.0]  episode_count: 291 q_vals: [-8.636, -8.618, -8.915, -9.468, -8.76, -9.077, -8.35]
Step 199 6 visits [29.0, 25.0, 13.0, 3.0, 15.0, 9.0, 105.0]  episode_count: 293 q_vals: [-8.636, -8.618, -8.915, -9.468, -8.76, -9.077, -8.377]
Step 200 3 visits [29.0, 25.0, 13.0, 4.0, 15.0, 9.0, 105.0]  episode_count: 296 q_vals: [-8.636, -8.618, -8.915, -9.878, -8.76, -9.077, -8.377]
Step 201 6 visits [29.0, 25.0, 13.0, 4.0, 15.0, 9.0, 106.0]  episode_count: 296 q_vals: [-8.636, -8.618, -8.915, -9.878, -8.76, -9.077, -8.402]
{"total_number_of_episodes": 297, "number_of_timesteps": 6396, "per_episode_reward": 18.29, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.42857142857142705},
Step 202 1 visits [29.0, 26.0, 13.0, 4.0, 15.0, 9.0, 106.0]  episode_count: 297 q_vals: [-8.636, -8.286, -8.915, -9.878, -8.76, -9.077, -8.402]
Step 203 1 visits [29.0, 27.0, 13.0, 4.0, 15.0, 9.0, 106.0]  episode_count: 299 q_vals: [-8.636, -8.391, -8.915, -9.878, -8.76, -9.077, -8.402]
Step 204 1 visits [29.0, 28.0, 13.0, 4.0, 15.0, 9.0, 106.0]  episode_count: 302 q_vals: [-8.636, -8.488, -8.915, -9.878, -8.76, -9.077, -8.402]
Step 205 1 visits [29.0, 29.0, 13.0, 4.0, 15.0, 9.0, 106.0]  episode_count: 302 q_vals: [-8.636, -8.578, -8.915, -9.878, -8.76, -9.077, -8.402]
Step 206 1 visits [29.0, 30.0, 13.0, 4.0, 15.0, 9.0, 106.0]  episode_count: 303 q_vals: [-8.636, -8.663, -8.915, -9.878, -8.76, -9.077, -8.402]
{"total_number_of_episodes": 307, "number_of_timesteps": 6586, "per_episode_reward": 18.29, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.42857142857142705},
Step 207 4 visits [29.0, 30.0, 13.0, 4.0, 16.0, 9.0, 106.0]  episode_count: 307 q_vals: [-8.636, -8.663, -8.915, -9.878, -8.907, -9.077, -8.402]
Step 208 6 visits [29.0, 30.0, 13.0, 4.0, 16.0, 9.0, 107.0]  episode_count: 307 q_vals: [-8.636, -8.663, -8.915, -9.878, -8.907, -9.077, -8.428]
Step 209 6 visits [29.0, 30.0, 13.0, 4.0, 16.0, 9.0, 108.0]  episode_count: 310 q_vals: [-8.636, -8.663, -8.915, -9.878, -8.907, -9.077, -8.453]
Step 210 0 visits [30.0, 30.0, 13.0, 4.0, 16.0, 9.0, 108.0]  episode_count: 312 q_vals: [-8.718, -8.663, -8.915, -9.878, -8.907, -9.077, -8.453]
Step 211 6 visits [30.0, 30.0, 13.0, 4.0, 16.0, 9.0, 109.0]  episode_count: 313 q_vals: [-8.718, -8.663, -8.915, -9.878, -8.907, -9.077, -8.477]
Step 212 1 visits [30.0, 31.0, 13.0, 4.0, 16.0, 9.0, 109.0]  episode_count: 315 q_vals: [-8.718, -8.742, -8.915, -9.878, -8.907, -9.077, -8.477]
Step 213 6 visits [30.0, 31.0, 13.0, 4.0, 16.0, 9.0, 110.0]  episode_count: 316 q_vals: [-8.718, -8.742, -8.915, -9.878, -8.907, -9.077, -8.501]
Step 214 2 visits [30.0, 31.0, 14.0, 4.0, 16.0, 9.0, 110.0]  episode_count: 316 q_vals: [-8.718, -8.742, -9.072, -9.878, -8.907, -9.077, -8.501]
{"total_number_of_episodes": 317, "number_of_timesteps": 6747, "per_episode_reward": 18.14, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.42857142857142705},
Step 215 6 visits [30.0, 31.0, 14.0, 4.0, 16.0, 9.0, 111.0]  episode_count: 317 q_vals: [-8.718, -8.742, -9.072, -9.878, -8.907, -9.077, -8.524]
Step 216 0 visits [31.0, 31.0, 14.0, 4.0, 16.0, 9.0, 111.0]  episode_count: 319 q_vals: [-8.795, -8.742, -9.072, -9.878, -8.907, -9.077, -8.524]
Step 217 6 visits [31.0, 31.0, 14.0, 4.0, 16.0, 9.0, 112.0]  episode_count: 320 q_vals: [-8.795, -8.742, -9.072, -9.878, -8.907, -9.077, -8.548]
Step 218 5 visits [31.0, 31.0, 14.0, 4.0, 16.0, 10.0, 112.0]  episode_count: 321 q_vals: [-8.795, -8.742, -9.072, -9.878, -8.907, -9.281, -8.548]
Step 219 1 visits [31.0, 32.0, 14.0, 4.0, 16.0, 10.0, 112.0]  episode_count: 324 q_vals: [-8.795, -8.816, -9.072, -9.878, -8.907, -9.281, -8.548]
Step 220 4 visits [31.0, 32.0, 14.0, 4.0, 17.0, 10.0, 112.0]  episode_count: 324 q_vals: [-8.795, -8.816, -9.072, -9.878, -9.037, -9.281, -8.548]
Step 221 6 visits [31.0, 32.0, 14.0, 4.0, 17.0, 10.0, 113.0]  episode_count: 326 q_vals: [-8.795, -8.816, -9.072, -9.878, -9.037, -9.281, -8.57]
{"total_number_of_episodes": 327, "number_of_timesteps": 7021, "per_episode_reward": 18.07, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.42857142857142705},
Step 222 6 visits [31.0, 32.0, 14.0, 4.0, 17.0, 10.0, 114.0]  episode_count: 327 q_vals: [-8.795, -8.816, -9.072, -9.878, -9.037, -9.281, -8.593]
Step 223 6 visits [31.0, 32.0, 14.0, 4.0, 17.0, 10.0, 115.0]  episode_count: 329 q_vals: [-8.795, -8.816, -9.072, -9.878, -9.037, -9.281, -8.614]
Step 224 0 visits [32.0, 32.0, 14.0, 4.0, 17.0, 10.0, 115.0]  episode_count: 330 q_vals: [-8.868, -8.816, -9.072, -9.878, -9.037, -9.281, -8.614]
Step 225 6 visits [32.0, 32.0, 14.0, 4.0, 17.0, 10.0, 116.0]  episode_count: 332 q_vals: [-8.868, -8.816, -9.072, -9.878, -9.037, -9.281, -8.636]
Step 226 1 visits [32.0, 33.0, 14.0, 4.0, 17.0, 10.0, 116.0]  episode_count: 334 q_vals: [-8.868, -8.885, -9.072, -9.878, -9.037, -9.281, -8.636]
Step 227 6 visits [32.0, 33.0, 14.0, 4.0, 17.0, 10.0, 117.0]  episode_count: 335 q_vals: [-8.868, -8.885, -9.072, -9.878, -9.037, -9.281, -8.657]
{"total_number_of_episodes": 337, "number_of_timesteps": 7250, "per_episode_reward": 18.14, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.42857142857142705},
Step 228 6 visits [32.0, 33.0, 14.0, 4.0, 17.0, 10.0, 118.0]  episode_count: 337 q_vals: [-8.868, -8.885, -9.072, -9.878, -9.037, -9.281, -8.678]
Step 229 2 visits [32.0, 33.0, 15.0, 4.0, 17.0, 10.0, 118.0]  episode_count: 339 q_vals: [-8.868, -8.885, -9.208, -9.878, -9.037, -9.281, -8.678]
Step 230 0 visits [33.0, 33.0, 15.0, 4.0, 17.0, 10.0, 118.0]  episode_count: 341 q_vals: [-8.936, -8.885, -9.208, -9.878, -9.037, -9.281, -8.678]
Step 231 6 visits [33.0, 33.0, 15.0, 4.0, 17.0, 10.0, 119.0]  episode_count: 341 q_vals: [-8.936, -8.885, -9.208, -9.878, -9.037, -9.281, -8.698]
Step 232 4 visits [33.0, 33.0, 15.0, 4.0, 18.0, 10.0, 119.0]  episode_count: 341 q_vals: [-8.936, -8.885, -9.208, -9.878, -9.152, -9.281, -8.698]
Step 233 1 visits [33.0, 34.0, 15.0, 4.0, 18.0, 10.0, 119.0]  episode_count: 343 q_vals: [-8.936, -8.951, -9.208, -9.878, -9.152, -9.281, -8.698]
Step 234 6 visits [33.0, 34.0, 15.0, 4.0, 18.0, 10.0, 120.0]  episode_count: 345 q_vals: [-8.936, -8.951, -9.208, -9.878, -9.152, -9.281, -8.718]
Step 235 6 visits [33.0, 34.0, 15.0, 4.0, 18.0, 10.0, 121.0]  episode_count: 346 q_vals: [-8.936, -8.951, -9.208, -9.878, -9.152, -9.281, -8.738]
{"total_number_of_episodes": 348, "number_of_timesteps": 7471, "per_episode_reward": 18.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.42857142857142705},
Step 236 6 visits [33.0, 34.0, 15.0, 4.0, 18.0, 10.0, 122.0]  episode_count: 348 q_vals: [-8.936, -8.951, -9.208, -9.878, -9.152, -9.281, -8.758]
Step 237 0 visits [34.0, 34.0, 15.0, 4.0, 18.0, 10.0, 122.0]  episode_count: 350 q_vals: [-9.0, -8.951, -9.208, -9.878, -9.152, -9.281, -8.758]
Step 238 5 visits [34.0, 34.0, 15.0, 4.0, 18.0, 11.0, 122.0]  episode_count: 351 q_vals: [-9.0, -8.951, -9.208, -9.878, -9.152, -9.447, -8.758]
Step 239 6 visits [34.0, 34.0, 15.0, 4.0, 18.0, 11.0, 123.0]  episode_count: 352 q_vals: [-9.0, -8.951, -9.208, -9.878, -9.152, -9.447, -8.777]
Step 240 1 visits [34.0, 35.0, 15.0, 4.0, 18.0, 11.0, 123.0]  episode_count: 355 q_vals: [-9.0, -9.013, -9.208, -9.878, -9.152, -9.447, -8.777]
Step 241 6 visits [34.0, 35.0, 15.0, 4.0, 18.0, 11.0, 124.0]  episode_count: 356 q_vals: [-9.0, -9.013, -9.208, -9.878, -9.152, -9.447, -8.796]
Step 242 6 visits [34.0, 35.0, 15.0, 4.0, 18.0, 11.0, 125.0]  episode_count: 357 q_vals: [-9.0, -9.013, -9.208, -9.878, -9.152, -9.447, -8.814]
{"total_number_of_episodes": 358, "number_of_timesteps": 7653, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 243 0 visits [35.0, 35.0, 15.0, 4.0, 18.0, 11.0, 125.0]  episode_count: 358 q_vals: [-9.06, -9.013, -9.208, -9.878, -9.152, -9.447, -8.814]
Step 244 4 visits [35.0, 35.0, 15.0, 4.0, 19.0, 11.0, 125.0]  episode_count: 359 q_vals: [-9.06, -9.013, -9.208, -9.878, -9.255, -9.447, -8.814]
Step 245 2 visits [35.0, 35.0, 16.0, 4.0, 19.0, 11.0, 125.0]  episode_count: 361 q_vals: [-9.06, -9.013, -9.327, -9.878, -9.255, -9.447, -8.814]
Step 246 6 visits [35.0, 35.0, 16.0, 4.0, 19.0, 11.0, 126.0]  episode_count: 361 q_vals: [-9.06, -9.013, -9.327, -9.878, -9.255, -9.447, -8.832]
Step 247 1 visits [35.0, 36.0, 16.0, 4.0, 19.0, 11.0, 126.0]  episode_count: 364 q_vals: [-9.06, -9.071, -9.327, -9.878, -9.255, -9.447, -8.832]
Step 248 6 visits [35.0, 36.0, 16.0, 4.0, 19.0, 11.0, 127.0]  episode_count: 365 q_vals: [-9.06, -9.071, -9.327, -9.878, -9.255, -9.447, -8.85]
Step 249 6 visits [35.0, 36.0, 16.0, 4.0, 19.0, 11.0, 128.0]  episode_count: 366 q_vals: [-9.06, -9.071, -9.327, -9.878, -9.255, -9.447, -8.868]
{"total_number_of_episodes": 369, "number_of_timesteps": 7961, "per_episode_reward": 18.07, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 250 6 visits [35.0, 36.0, 16.0, 4.0, 19.0, 11.0, 129.0]  episode_count: 369 q_vals: [-9.06, -9.071, -9.327, -9.878, -9.255, -9.447, -8.885]
Step 251 0 visits [36.0, 36.0, 16.0, 4.0, 19.0, 11.0, 129.0]  episode_count: 370 q_vals: [-8.808, -9.071, -9.327, -9.878, -9.255, -9.447, -8.885]
Step 252 0 visits [37.0, 36.0, 16.0, 4.0, 19.0, 11.0, 129.0]  episode_count: 372 q_vals: [-8.87, -9.071, -9.327, -9.878, -9.255, -9.447, -8.885]
Step 253 0 visits [38.0, 36.0, 16.0, 4.0, 19.0, 11.0, 129.0]  episode_count: 372 q_vals: [-8.929, -9.071, -9.327, -9.878, -9.255, -9.447, -8.885]
Step 254 0 visits [39.0, 36.0, 16.0, 4.0, 19.0, 11.0, 129.0]  episode_count: 375 q_vals: [-8.985, -9.071, -9.327, -9.878, -9.255, -9.447, -8.885]
Step 255 0 visits [40.0, 36.0, 16.0, 4.0, 19.0, 11.0, 129.0]  episode_count: 375 q_vals: [-9.039, -9.071, -9.327, -9.878, -9.255, -9.447, -8.885]
Step 256 0 visits [41.0, 36.0, 16.0, 4.0, 19.0, 11.0, 129.0]  episode_count: 376 q_vals: [-8.818, -9.071, -9.327, -9.878, -9.255, -9.447, -8.885]
{"total_number_of_episodes": 379, "number_of_timesteps": 8151, "per_episode_reward": 18.07, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 257 0 visits [42.0, 36.0, 16.0, 4.0, 19.0, 11.0, 129.0]  episode_count: 379 q_vals: [-8.873, -9.071, -9.327, -9.878, -9.255, -9.447, -8.885]
Step 258 0 visits [43.0, 36.0, 16.0, 4.0, 19.0, 11.0, 129.0]  episode_count: 381 q_vals: [-8.925, -9.071, -9.327, -9.878, -9.255, -9.447, -8.885]
Step 259 0 visits [44.0, 36.0, 16.0, 4.0, 19.0, 11.0, 129.0]  episode_count: 384 q_vals: [-8.974, -9.071, -9.327, -9.878, -9.255, -9.447, -8.885]
Step 260 0 visits [45.0, 36.0, 16.0, 4.0, 19.0, 11.0, 129.0]  episode_count: 385 q_vals: [-9.022, -9.071, -9.327, -9.878, -9.255, -9.447, -8.885]
Step 261 0 visits [46.0, 36.0, 16.0, 4.0, 19.0, 11.0, 129.0]  episode_count: 386 q_vals: [-9.067, -9.071, -9.327, -9.878, -9.255, -9.447, -8.885]
Step 262 6 visits [46.0, 36.0, 16.0, 4.0, 19.0, 11.0, 130.0]  episode_count: 388 q_vals: [-9.067, -9.071, -9.327, -9.878, -9.255, -9.447, -8.903]
{"total_number_of_episodes": 390, "number_of_timesteps": 8358, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 263 1 visits [46.0, 37.0, 16.0, 4.0, 19.0, 11.0, 130.0]  episode_count: 390 q_vals: [-9.067, -9.126, -9.327, -9.878, -9.255, -9.447, -8.903]
Step 264 6 visits [46.0, 37.0, 16.0, 4.0, 19.0, 11.0, 131.0]  episode_count: 392 q_vals: [-9.067, -9.126, -9.327, -9.878, -9.255, -9.447, -8.919]
Step 265 3 visits [46.0, 37.0, 16.0, 5.0, 19.0, 11.0, 131.0]  episode_count: 396 q_vals: [-9.067, -9.126, -9.327, -10.125, -9.255, -9.447, -8.919]
Step 266 6 visits [46.0, 37.0, 16.0, 5.0, 19.0, 11.0, 132.0]  episode_count: 396 q_vals: [-9.067, -9.126, -9.327, -10.125, -9.255, -9.447, -8.936]
Step 267 4 visits [46.0, 37.0, 16.0, 5.0, 20.0, 11.0, 132.0]  episode_count: 398 q_vals: [-9.067, -9.126, -9.327, -10.125, -8.792, -9.447, -8.936]
{"total_number_of_episodes": 402, "number_of_timesteps": 8548, "per_episode_reward": 17.71, "episode_reward_trend_value": -0.006349206349206327, "biggest_recent_change": 0.2857142857142847},
Step 268 4 visits [46.0, 37.0, 16.0, 5.0, 21.0, 11.0, 132.0]  episode_count: 402 q_vals: [-9.067, -9.126, -9.327, -10.125, -8.903, -9.447, -8.936]
Step 269 4 visits [46.0, 37.0, 16.0, 5.0, 22.0, 11.0, 132.0]  episode_count: 404 q_vals: [-9.067, -9.126, -9.327, -10.125, -9.003, -9.447, -8.936]
Step 270 4 visits [46.0, 37.0, 16.0, 5.0, 23.0, 11.0, 132.0]  episode_count: 405 q_vals: [-9.067, -9.126, -9.327, -10.125, -9.095, -9.447, -8.936]
Step 271 4 visits [starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[46.0, 37.0, 16.0, 5.0, 24.0, 11.0, 132.0]  episode_count: 407 q_vals: [-9.067, -9.126, -9.327, -10.125, -9.179, -9.447, -8.936]
Step 272 4 visits [46.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 409 q_vals: [-9.067, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 273 0 visits [47.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 409 q_vals: [-8.874, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 274 0 visits [48.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 410 q_vals: [-8.921, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
{"total_number_of_episodes": 414, "number_of_timesteps": 8736, "per_episode_reward": 17.64, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.2857142857142847},
Step 275 0 visits [49.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 414 q_vals: [-8.966, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 276 0 visits [50.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 417 q_vals: [-9.009, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 277 0 visits [51.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 418 q_vals: [-8.832, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 278 0 visits [52.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 419 q_vals: [-8.662, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 279 0 visits [53.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 422 q_vals: [-8.499, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 280 0 visits [54.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 422 q_vals: [-8.547, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
{"total_number_of_episodes": 425, "number_of_timesteps": 8907, "per_episode_reward": 17.57, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.2857142857142847},
Step 281 0 visits [55.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 425 q_vals: [-8.594, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 282 0 visits [56.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 429 q_vals: [-8.639, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 283 0 visits [57.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 429 q_vals: [-8.682, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 284 0 visits [58.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 432 q_vals: [-8.724, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 285 0 visits [59.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 434 q_vals: [-8.764, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
{"total_number_of_episodes": 435, "number_of_timesteps": 9067, "per_episode_reward": 17.36, "episode_reward_trend_value": -0.008730158730158718, "biggest_recent_change": 0.2857142857142847},
Step 286 0 visits [60.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 435 q_vals: [-8.803, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 287 0 visits [61.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 436 q_vals: [-8.841, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 288 0 visits [62.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 437 q_vals: [-8.878, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 289 0 visits [63.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 441 q_vals: [-8.913, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 290 0 visits [64.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 441 q_vals: [-8.948, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 291 0 visits [65.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 444 q_vals: [-8.981, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
{"total_number_of_episodes": 447, "number_of_timesteps": 9297, "per_episode_reward": 17.29, "episode_reward_trend_value": -0.009523809523809528, "biggest_recent_change": 0.2857142857142847},
Step 292 0 visits [66.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 447 q_vals: [-9.013, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 293 0 visits [67.0, 37.0, 16.0, 5.0, 25.0, 11.0, 132.0]  episode_count: 449 q_vals: [-9.045, -9.126, -9.327, -10.125, -9.256, -9.447, -8.936]
Step 294 5 visits [67.0, 37.0, 16.0, 5.0, 25.0, 12.0, 132.0]  episode_count: 453 q_vals: [-9.045, -9.126, -9.327, -10.125, -9.256, -9.586, -8.936]
Step 295 6 visits [67.0, 37.0, 16.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 454 q_vals: [-9.045, -9.126, -9.327, -10.125, -9.256, -9.586, -8.952]
Step 296 2 visits [67.0, 37.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 456 q_vals: [-9.045, -9.126, -9.432, -10.125, -9.256, -9.586, -8.952]
{"total_number_of_episodes": 458, "number_of_timesteps": 9418, "per_episode_reward": 17.29, "episode_reward_trend_value": -0.007936507936507946, "biggest_recent_change": 0.2857142857142847},
Step 297 1 visits [67.0, 38.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 458 q_vals: [-9.045, -8.886, -9.432, -10.125, -9.256, -9.586, -8.952]
Step 298 1 visits [67.0, 39.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 461 q_vals: [-9.045, -8.943, -9.432, -10.125, -9.256, -9.586, -8.952]
Step 299 1 visits [67.0, 40.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 463 q_vals: [-9.045, -8.719, -9.432, -10.125, -9.256, -9.586, -8.952]
Step 300 1 visits [67.0, 41.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 466 q_vals: [-9.045, -8.778, -9.432, -10.125, -9.256, -9.586, -8.952]
{"total_number_of_episodes": 469, "number_of_timesteps": 9576, "per_episode_reward": 17.29, "episode_reward_trend_value": -0.008730158730158758, "biggest_recent_change": 0.2857142857142847},
Step 301 1 visits [67.0, 42.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 469 q_vals: [-9.045, -8.569, -9.432, -10.125, -9.256, -9.586, -8.952]
Step 302 1 visits [67.0, 43.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 470 q_vals: [-9.045, -8.628, -9.432, -10.125, -9.256, -9.586, -8.952]
Step 303 1 visits [67.0, 44.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 474 q_vals: [-9.045, -8.684, -9.432, -10.125, -9.256, -9.586, -8.952]
Step 304 1 visits [67.0, 45.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 476 q_vals: [-9.045, -8.738, -9.432, -10.125, -9.256, -9.586, -8.952]
Step 305 1 visits [67.0, 46.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 478 q_vals: [-9.045, -8.79, -9.432, -10.125, -9.256, -9.586, -8.952]
{"total_number_of_episodes": 480, "number_of_timesteps": 9705, "per_episode_reward": 17.14, "episode_reward_trend_value": -0.01031746031746034, "biggest_recent_change": 0.2857142857142847},
Step 306 1 visits [67.0, 47.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 480 q_vals: [-9.045, -8.839, -9.432, -10.125, -9.256, -9.586, -8.952]
Step 307 1 visits [67.0, 48.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 482 q_vals: [-9.045, -8.886, -9.432, -10.125, -9.256, -9.586, -8.952]
Step 308 1 visits [67.0, 49.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 483 q_vals: [-9.045, -8.932, -9.432, -10.125, -9.256, -9.586, -8.952]
Step 309 1 visits [67.0, 50.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 484 q_vals: [-9.045, -8.975, -9.432, -10.125, -9.256, -9.586, -8.952]
Step 310 1 visits [67.0, 51.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 486 q_vals: [-9.045, -9.017, -9.432, -10.125, -9.256, -9.586, -8.952]
{"total_number_of_episodes": 490, "number_of_timesteps": 9866, "per_episode_reward": 17.29, "episode_reward_trend_value": -0.007936507936507946, "biggest_recent_change": 0.2857142857142847},
Step 311 1 visits [67.0, 52.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 490 q_vals: [-9.045, -9.058, -9.432, -10.125, -9.256, -9.586, -8.952]
Step 312 1 visits [67.0, 53.0, 17.0, 5.0, 25.0, 12.0, 133.0]  episode_count: 491 q_vals: [-9.045, -9.096, -9.432, -10.125, -9.256, -9.586, -8.952]
Step 313 6 visits [67.0, 53.0, 17.0, 5.0, 25.0, 12.0, 134.0]  episode_count: 491 q_vals: [-9.045, -9.096, -9.432, -10.125, -9.256, -9.586, -8.886]
Step 314 6 visits [67.0, 53.0, 17.0, 5.0, 25.0, 12.0, 135.0]  episode_count: 496 q_vals: [-9.045, -9.096, -9.432, -10.125, -9.256, -9.586, -8.902]
Step 315 6 visits [67.0, 53.0, 17.0, 5.0, 25.0, 12.0, 136.0]  episode_count: 498 q_vals: [-9.045, -9.096, -9.432, -10.125, -9.256, -9.586, -8.837]
{"total_number_of_episodes": 500, "number_of_timesteps": 10017, "per_episode_reward": 17.14, "episode_reward_trend_value": -0.006349206349206366, "biggest_recent_change": 0.2142857142857153},
Step 316 6 visits [67.0, 53.0, 17.0, 5.0, 25.0, 12.0, 137.0]  episode_count: 500 q_vals: [-9.045, -9.096, -9.432, -10.125, -9.256, -9.586, -8.853]
Step 317 6 visits [67.0, 53.0, 17.0, 5.0, 25.0, 12.0, 138.0]  episode_count: 504 q_vals: [-9.045, -9.096, -9.432, -10.125, -9.256, -9.586, -8.87]
Step 318 6 visits [67.0, 53.0, 17.0, 5.0, 25.0, 12.0, 139.0]  episode_count: 506 q_vals: [-9.045, -9.096, -9.432, -10.125, -9.256, -9.586, -8.886]
Step 319 6 visits [67.0, 53.0, 17.0, 5.0, 25.0, 12.0, 140.0]  episode_count: 507 q_vals: [-9.045, -9.096, -9.432, -10.125, -9.256, -9.586, -8.902]
{"total_number_of_episodes": 510, "number_of_timesteps": 10136, "per_episode_reward": 17.0, "episode_reward_trend_value": -0.0071428571428571366, "biggest_recent_change": 0.2142857142857153},
Step 320 6 visits [67.0, 53.0, 17.0, 5.0, 25.0, 12.0, 141.0]  episode_count: 510 q_vals: [-9.045, -9.096, -9.432, -10.125, -9.256, -9.586, -8.917]
Step 321 6 visits [67.0, 53.0, 17.0, 5.0, 25.0, 12.0, 142.0]  episode_count: 513 q_vals: [-9.045, -9.096, -9.432, -10.125, -9.256, -9.586, -8.933]
Step 322 6 visits [67.0, 53.0, 17.0, 5.0, 25.0, 12.0, 143.0]  episode_count: 513 q_vals: [-9.045, -9.096, -9.432, -10.125, -9.256, -9.586, -8.948]
Step 323 6 visits [67.0, 53.0, 17.0, 5.0, 25.0, 12.0, 144.0]  episode_count: 515 q_vals: [-9.045, -9.096, -9.432, -10.125, -9.256, -9.586, -8.963]
Step 324 0 visits [68.0, 53.0, 17.0, 5.0, 25.0, 12.0, 144.0]  episode_count: 516 q_vals: [-9.075, -9.096, -9.432, -10.125, -9.256, -9.586, -8.963]
Step 325 6 visits [68.0, 53.0, 17.0, 5.0, 25.0, 12.0, 145.0]  episode_count: 517 q_vals: [-9.075, -9.096, -9.432, -10.125, -9.256, -9.586, -8.978]
Step 326 1 visits [68.0, 54.0, 17.0, 5.0, 25.0, 12.0, 145.0]  episode_count: 519 q_vals: [-9.075, -9.134, -9.432, -10.125, -9.256, -9.586, -8.978]
{"total_number_of_episodes": 521, "number_of_timesteps": 10352, "per_episode_reward": 17.0, "episode_reward_trend_value": -0.006349206349206366, "biggest_recent_change": 0.2142857142857153},
Step 327 4 visits [68.0, 54.0, 17.0, 5.0, 26.0, 12.0, 145.0]  episode_count: 521 q_vals: [-9.075, -9.134, -9.432, -10.125, -9.327, -9.586, -8.978]
Step 328 6 visits [68.0, 54.0, 17.0, 5.0, 26.0, 12.0, 146.0]  episode_count: 522 q_vals: [-9.075, -9.134, -9.432, -10.125, -9.327, -9.586, -8.992]
Step 329 0 visits [69.0, 54.0, 17.0, 5.0, 26.0, 12.0, 146.0]  episode_count: 523 q_vals: [-9.104, -9.134, -9.432, -10.125, -9.327, -9.586, -8.992]
Step 330 6 visits [69.0, 54.0, 17.0, 5.0, 26.0, 12.0, 147.0]  episode_count: 524 q_vals: [-9.104, -9.134, -9.432, -10.125, -9.327, -9.586, -9.007]
Step 331 1 visits [69.0, 55.0, 17.0, 5.0, 26.0, 12.0, 147.0]  episode_count: 526 q_vals: [-9.104, -9.17, -9.432, -10.125, -9.327, -9.586, -9.007]
Step 332 6 visits [69.0, 55.0, 17.0, 5.0, 26.0, 12.0, 148.0]  episode_count: 527 q_vals: [-9.104, -9.17, -9.432, -10.125, -9.327, -9.586, -9.021]
Step 333 0 visits [70.0, 55.0, 17.0, 5.0, 26.0, 12.0, 148.0]  episode_count: 527 q_vals: [-9.133, -9.17, -9.432, -10.125, -9.327, -9.586, -9.021]
Step 334 6 visits [70.0, 55.0, 17.0, 5.0, 26.0, 12.0, 149.0]  episode_count: 530 q_vals: [-9.133, -9.17, -9.432, -10.125, -9.327, -9.586, -9.035]
{"total_number_of_episodes": 532, "number_of_timesteps": 10591, "per_episode_reward": 17.21, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 335 6 visits [70.0, 55.0, 17.0, 5.0, 26.0, 12.0, 150.0]  episode_count: 532 q_vals: [-9.133, -9.17, -9.432, -10.125, -9.327, -9.586, -9.049]
Step 336 1 visits [70.0, 56.0, 17.0, 5.0, 26.0, 12.0, 150.0]  episode_count: 532 q_vals: [-9.133, -9.204, -9.432, -10.125, -9.327, -9.586, -9.049]
Step 337 0 visits [71.0, 56.0, 17.0, 5.0, 26.0, 12.0, 150.0]  episode_count: 533 q_vals: [-9.161, -9.204, -9.432, -10.125, -9.327, -9.586, -9.049]
Step 338 2 visits [71.0, 56.0, 18.0, 5.0, 26.0, 12.0, 150.0]  episode_count: 536 q_vals: [-9.161, -9.204, -9.525, -10.125, -9.327, -9.586, -9.049]
Step 339 6 visits [71.0, 56.0, 18.0, 5.0, 26.0, 12.0, 151.0]  episode_count: 536 q_vals: [-9.161, -9.204, -9.525, -10.125, -9.327, -9.586, -9.063]
Step 340 4 visits [71.0, 56.0, 18.0, 5.0, 27.0, 12.0, 151.0]  episode_count: 536 q_vals: [-9.161, -9.204, -9.525, -10.125, -9.393, -9.586, -9.063]
Step 341 6 visits [71.0, 56.0, 18.0, 5.0, 27.0, 12.0, 152.0]  episode_count: 539 q_vals: [-9.161, -9.204, -9.525, -10.125, -9.393, -9.586, -9.076]
Step 342 0 visits [72.0, 56.0, 18.0, 5.0, 27.0, 12.0, 152.0]  episode_count: 539 q_vals: [-9.188, -9.204, -9.525, -10.125, -9.393, -9.586, -9.076]
{"total_number_of_episodes": 542, "number_of_timesteps": 10845, "per_episode_reward": 17.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.2142857142857153},
Step 343 6 visits [72.0, 56.0, 18.0, 5.0, 27.0, 12.0, 153.0]  episode_count: 542 q_vals: [-9.188, -9.204, -9.525, -10.125, -9.393, -9.586, -9.089]
Step 344 1 visits [72.0, 57.0, 18.0, 5.0, 27.0, 12.0, 153.0]  episode_count: 545 q_vals: [-9.188, -9.238, -9.525, -10.125, -9.393, -9.586, -9.089]
Step 345 5 visits [72.0, 57.0, 18.0, 5.0, 27.0, 13.0, 153.0]  episode_count: 547 q_vals: [-9.188, -9.238, -9.525, -10.125, -9.393, -9.703, -9.089]
Step 346 6 visits [72.0, 57.0, 18.0, 5.0, 27.0, 13.0, 154.0]  episode_count: 548 q_vals: [-9.188, -9.238, -9.525, -10.125, -9.393, -9.703, -9.102]
Step 347 0 visits [73.0, 57.0, 18.0, 5.0, 27.0, 13.0, 154.0]  episode_count: 550 q_vals: [-9.062, -9.238, -9.525, -10.125, -9.393, -9.703, -9.102]
Step 348 0 visits [74.0, 57.0, 18.0, 5.0, 27.0, 13.0, 154.0]  episode_count: 550 q_vals: [-9.09, -9.238, -9.525, -10.125, -9.393, -9.703, -9.102]
{"total_number_of_episodes": 553, "number_of_timesteps": 11038, "per_episode_reward": 17.21, "episode_reward_trend_value": -0.0007936507936507711, "biggest_recent_change": 0.2142857142857153},
Step 349 0 visits [75.0, 57.0, 18.0, 5.0, 27.0, 13.0, 154.0]  episode_count: 553 q_vals: [-9.117, -9.238, -9.525, -10.125, -9.393, -9.703, -9.102]
Step 350 0 visits [76.0, 57.0, 18.0, 5.0, 27.0, 13.0, 154.0]  episode_count: 554 q_vals: [-9.143, -9.238, -9.525, -10.125, -9.393, -9.703, -9.102]
Step 351 0 visits [77.0, 57.0, 18.0, 5.0, 27.0, 13.0, 154.0]  episode_count: 556 q_vals: [-9.169, -9.238, -9.525, -10.125, -9.393, -9.703, -9.102]
Step 352 0 visits [78.0, 57.0, 18.0, 5.0, 27.0, 13.0, 154.0]  episode_count: 558 q_vals: [-9.194, -9.238, -9.525, -10.125, -9.393, -9.703, -9.102]
Step 353 6 visits [78.0, 57.0, 18.0, 5.0, 27.0, 13.0, 155.0]  episode_count: 559 q_vals: [-9.194, -9.238, -9.525, -10.125, -9.393, -9.703, -9.115]
Step 354 1 visits [78.0, 58.0, 18.0, 5.0, 27.0, 13.0, 155.0]  episode_count: 562 q_vals: [-9.194, -9.27, -9.525, -10.125, -9.393, -9.703, -9.115]
{"total_number_of_episodes": 564, "number_of_timesteps": 11225, "per_episode_reward": 17.14, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 355 0 visits [79.0, 58.0, 18.0, 5.0, 27.0, 13.0, 155.0]  episode_count: 564 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.393, -9.703, -9.115]
Step 356 6 visits [79.0, 58.0, 18.0, 5.0, 27.0, 13.0, 156.0]  episode_count: 566 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.393, -9.703, -9.128]
Step 357 4 visits [79.0, 58.0, 18.0, 5.0, 28.0, 13.0, 156.0]  episode_count: 566 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.058, -9.703, -9.128]
Step 358 4 visits [79.0, 58.0, 18.0, 5.0, 29.0, 13.0, 156.0]  episode_count: 566 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.746, -9.703, -9.128]
Step 359 4 visits [79.0, 58.0, 18.0, 5.0, 30.0, 13.0, 156.0]  episode_count: 569 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.824, -9.703, -9.128]
Step 360 4 visits [79.0, 58.0, 18.0, 5.0, 31.0, 13.0, 156.0]  episode_count: 571 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.898, -9.703, -9.128]
Step 361 4 visits [79.0, 58.0, 18.0, 5.0, 32.0, 13.0, 156.0]  episode_count: 573 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.967, -9.703, -9.128]
{"total_number_of_episodes": 574, "number_of_timesteps": 11471, "per_episode_reward": 16.86, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.2857142857142847},
Step 362 4 visits [79.0, 58.0, 18.0, 5.0, 33.0, 13.0, 156.0]  episode_count: 574 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.032, -9.703, -9.128]
Step 363 4 visits [79.0, 58.0, 18.0, 5.0, 34.0, 13.0, 156.0]  episode_count: 575 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.767, -9.703, -9.128]
Step 364 4 visits [79.0, 58.0, 18.0, 5.0, 35.0, 13.0, 156.0]  episode_count: 576 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.834, -9.703, -9.128]
Step 365 4 visits [79.0, 58.0, 18.0, 5.0, 36.0, 13.0, 156.0]  episode_count: 579 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.588, -9.703, -9.128]
Step 366 4 visits [79.0, 58.0, 18.0, 5.0, 37.0, 13.0, 156.0]  episode_count: 579 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.656, -9.703, -9.128]
Step 367 4 visits [79.0, 58.0, 18.0, 5.0, 38.0, 13.0, 156.0]  episode_count: 581 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.721, -9.703, -9.128]
{"total_number_of_episodes": 584, "number_of_timesteps": 11674, "per_episode_reward": 17.0, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.2857142857142847},
Step 368 4 visits [79.0, 58.0, 18.0, 5.0, 39.0, 13.0, 156.0]  episode_count: 584 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.782, -9.703, -9.128]
Step 369 4 visits [79.0, 58.0, 18.0, 5.0, 40.0, 13.0, 156.0]  episode_count: 585 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.841, -9.703, -9.128]
Step 370 4 visits [79.0, 58.0, 18.0, 5.0, 41.0, 13.0, 156.0]  episode_count: 587 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.896, -9.703, -9.128]
Step 371 4 visits [79.0, 58.0, 18.0, 5.0, 42.0, 13.0, 156.0]  episode_count: 590 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.684, -9.703, -9.128]
Step 372 4 visits [79.0, 58.0, 18.0, 5.0, 43.0, 13.0, 156.0]  episode_count: 591 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.741, -9.703, -9.128]
Step 373 4 visits [79.0, 58.0, 18.0, 5.0, 44.0, 13.0, 156.0]  episode_count: 592 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.794, -9.703, -9.128]
{"total_number_of_episodes": 595, "number_of_timesteps": 11839, "per_episode_reward": 16.86, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.2857142857142847},
Step 374 4 visits [79.0, 58.0, 18.0, 5.0, 45.0, 13.0, 156.0]  episode_count: 595 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.846, -9.703, -9.128]
Step 375 4 visits [79.0, 58.0, 18.0, 5.0, 46.0, 13.0, 156.0]  episode_count: 596 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.895, -9.703, -9.128]
Step 376 4 visits [79.0, 58.0, 18.0, 5.0, 47.0, 13.0, 156.0]  episode_count: 597 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.942, -9.703, -9.128]
Step 377 4 visits [79.0, 58.0, 18.0, 5.0, 48.0, 13.0, 156.0]  episode_count: 600 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.987, -9.703, -9.128]
Step 378 4 visits [79.0, 58.0, 18.0, 5.0, 49.0, 13.0, 156.0]  episode_count: 600 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.031, -9.703, -9.128]
Step 379 4 visits [79.0, 58.0, 18.0, 5.0, 50.0, 13.0, 156.0]  episode_count: 602 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.072, -9.703, -9.128]
{"total_number_of_episodes": 607, "number_of_timesteps": 12084, "per_episode_reward": 16.93, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.2857142857142847},
Step 380 4 visits [79.0, 58.0, 18.0, 5.0, 51.0, 13.0, 156.0]  episode_count: 607 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.112, -9.703, -9.128]
Step 381 4 visits [79.0, 58.0, 18.0, 5.0, 52.0, 13.0, 156.0]  episode_count: 608 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.151, -9.703, -9.128]
Step 382 4 visits [79.0, 58.0, 18.0, 5.0, 53.0, 13.0, 156.0]  episode_count: 609 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.188, -9.703, -9.128]
Step 383 4 visits [79.0, 58.0, 18.0, 5.0, 54.0, 13.0, 156.0]  episode_count: 613 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.223, -9.703, -9.128]
Step 384 4 visits [79.0, 58.0, 18.0, 5.0, 55.0, 13.0, 156.0]  episode_count: 615 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.258, -9.703, -9.128]
Step 385 4 visits [79.0, 58.0, 18.0, 5.0, 56.0, 13.0, 156.0]  episode_count: 616 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.092, -9.703, -9.128]
{"total_number_of_episodes": 621, "number_of_timesteps": 12260, "per_episode_reward": 16.71, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.2857142857142847},
Step 386 4 visits [79.0, 58.0, 18.0, 5.0, 57.0, 13.0, 156.0]  episode_count: 621 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.128, -9.703, -9.128]
Step 387 4 visits [79.0, 58.0, 18.0, 5.0, 58.0, 13.0, 156.0]  episode_count: 621 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.162, -9.703, -9.128]
Step 388 4 visits [79.0, 58.0, 18.0, 5.0, 59.0, 13.0, 156.0]  episode_count: 621 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.195, -9.703, -9.128]
Step 389 4 visits [79.0, 58.0, 18.0, 5.0, 60.0, 13.0, 156.0]  episode_count: 624 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.227, -9.703, -9.128]
Step 390 4 visits [79.0, 58.0, 18.0, 5.0, 61.0, 13.0, 156.0]  episode_count: 626 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.076, -9.703, -9.128]
Step 391 4 visits [79.0, 58.0, 18.0, 5.0, 62.0, 13.0, 156.0]  episode_count: 626 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.109, -9.703, -9.128]
Step 392 4 visits [79.0, 58.0, 18.0, 5.0, 63.0, 13.0, 156.0]  episode_count: 628 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.14, -9.703, -9.128]
Step 393 4 visits [79.0, 58.0, 18.0, 5.0, 64.0, 13.0, 156.0]  episode_count: 629 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.171, -9.703, -9.128]
{"total_number_of_episodes": 632, "number_of_timesteps": 12463, "per_episode_reward": 16.64, "episode_reward_trend_value": -0.006349206349206366, "biggest_recent_change": 0.2857142857142847},
Step 394 4 visits [79.0, 58.0, 18.0, 5.0, 65.0, 13.0, 156.0]  episode_count: 632 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.2, -9.703, -9.128]
Step 395 4 visits [79.0, 58.0, 18.0, 5.0, 66.0, 13.0, 156.0]  episode_count: 634 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.229, -9.703, -9.128]
Step 396 4 visits [79.0, 58.0, 18.0, 5.0, 67.0, 13.0, 156.0]  episode_count: 634 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.092, -9.703, -9.128]
Step 397 4 visits [79.0, 58.0, 18.0, 5.0, 68.0, 13.0, 156.0]  episode_count: 638 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.958, -9.703, -9.128]
Step 398 4 visits [79.0, 58.0, 18.0, 5.0, 69.0, 13.0, 156.0]  episode_count: 639 q_vals: [-9.218, -9.27, -9.525, -10.125, -8.989, -9.703, -9.128]
Step 399 4 visits [79.0, 58.0, 18.0, 5.0, 70.0, 13.0, 156.0]  episode_count: 641 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.019, -9.703, -9.128]
{"total_number_of_episodes": 643, "number_of_timesteps": 12666, "per_episode_reward": 16.79, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.2857142857142847},
Step 400 4 visits [79.0, 58.0, 18.0, 5.0, 71.0, 13.0, 156.0]  episode_count: 643 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.049, -9.703, -9.128]
Step 401 4 visits [79.0, 58.0, 18.0, 5.0, 72.0, 13.0, 156.0]  episode_count: 645 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.078, -9.703, -9.128]
Step 402 4 visits [79.0, 58.0, 18.0, 5.0, 73.0, 13.0, 156.0]  episode_count: 645 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.105, -9.703, -9.128]
Step 403 4 visits [79.0, 58.0, 18.0, 5.0, 74.0, 13.0, 156.0]  episode_count: 647 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.133, -9.703, -9.128]
Step 404 4 visits [79.0, 58.0, 18.0, 5.0, 75.0, 13.0, 156.0]  episode_count: 648 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.159, -9.703, -9.128]
Step 405 4 visits [79.0, 58.0, 18.0, 5.0, 76.0, 13.0, 156.0]  episode_count: 648 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.185, -9.703, -9.128]
Step 406 4 visits [79.0, 58.0, 18.0, 5.0, 77.0, 13.0, 156.0]  episode_count: 649 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.21, -9.703, -9.128]
Step 407 4 visits [79.0, 58.0, 18.0, 5.0, 78.0, 13.0, 156.0]  episode_count: 650 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.234, -9.703, -9.128]
Step 408 6 visits [79.0, 58.0, 18.0, 5.0, 78.0, 13.0, 157.0]  episode_count: 650 q_vals: [-9.218, -9.27, -9.525, -10.125, -9.234, -9.703, -9.141]
Step 409 0 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 157.0]  episode_count: 651 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.141]
Step 410 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 158.0]  episode_count: 651 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.083]
Step 411 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 159.0]  episode_count: 652 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.096]
Step 412 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 160.0]  episode_count: 652 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.108]
{"total_number_of_episodes": 654, "number_of_timesteps": 12944, "per_episode_reward": 16.79, "episode_reward_trend_value": -0.004761904761904785, "biggest_recent_change": 0.2857142857142847},
Step 413 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 161.0]  episode_count: 654 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.121]
Step 414 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 162.0]  episode_count: 654 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.133]
Step 415 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 163.0]  episode_count: 658 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.077]
Step 416 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 164.0]  episode_count: 661 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.089]
Step 417 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 165.0]  episode_count: 661 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.102]
{"total_number_of_episodes": 665, "number_of_timesteps": 13261, "per_episode_reward": 16.71, "episode_reward_trend_value": -0.004761904761904745, "biggest_recent_change": 0.2857142857142847},
Step 418 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 166.0]  episode_count: 665 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.047]
Step 419 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 167.0]  episode_count: 665 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.059]
Step 420 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 168.0]  episode_count: 666 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.071]
Step 421 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 169.0]  episode_count: 668 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.083]
Step 422 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 170.0]  episode_count: 670 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.095]
Step 423 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 171.0]  episode_count: 670 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.107]
Step 424 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 172.0]  episode_count: 670 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.054]
Step 425 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 173.0]  episode_count: 672 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.066]
Step 426 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 174.0]  episode_count: 672 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.078]
{"total_number_of_episodes": 676, "number_of_timesteps": 13536, "per_episode_reward": 16.79, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.21428571428571175},
Step 427 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 175.0]  episode_count: 676 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.089]
Step 428 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 176.0]  episode_count: 676 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.101]
Step 429 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 177.0]  episode_count: 678 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.112]
Step 430 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 178.0]  episode_count: 680 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.124]
Step 431 6 visits [80.0, 58.0, 18.0, 5.0, 78.0, 13.0, 179.0]  episode_count: 681 q_vals: [-9.241, -9.27, -9.525, -10.125, -9.234, -9.703, -9.135]
Step 432 2 visits [80.0, 58.0, 19.0, 5.0, 78.0, 13.0, 179.0]  episode_count: 683 q_vals: [-9.241, -9.27, -9.608, -10.125, -9.234, -9.703, -9.135]
Step 433 1 visits [80.0, 59.0, 19.0, 5.0, 78.0, 13.0, 179.0]  episode_count: 685 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.234, -9.703, -9.135]
{"total_number_of_episodes": 686, "number_of_timesteps": 13738, "per_episode_reward": 16.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.21428571428571175},
Step 434 6 visits [80.0, 59.0, 19.0, 5.0, 78.0, 13.0, 180.0]  episode_count: 686 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.234, -9.703, -9.146]
Step 435 4 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 180.0]  episode_count: 688 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.146]
Step 436 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 181.0]  episode_count: 690 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.095]
Step 437 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 182.0]  episode_count: 693 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.045]
Step 438 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 183.0]  episode_count: 693 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.056]
Step 439 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 184.0]  episode_count: 693 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.007]
Step 440 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 185.0]  episode_count: 695 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.019]
{"total_number_of_episodes": 699, "number_of_timesteps": 14008, "per_episode_reward": 16.93, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.21428571428571175},
Step 441 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 186.0]  episode_count: 699 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.03]
Step 442 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 187.0]  episode_count: 699 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.041]
Step 443 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 188.0]  episode_count: 699 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.052]
Step 444 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 189.0]  episode_count: 699 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.063]
Step 445 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 190.0]  episode_count: 701 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.074]
Step 446 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 191.0]  episode_count: 704 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.084]
Step 447 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 192.0]  episode_count: 704 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.095]
Step 448 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 193.0]  episode_count: 704 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.105]
Step 449 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 194.0]  episode_count: 705 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.116]
Step 450 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 195.0]  episode_count: 707 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.069]
Step 451 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 196.0]  episode_count: 708 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.079]
{"total_number_of_episodes": 709, "number_of_timesteps": 14284, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.21428571428571175},
Step 452 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 197.0]  episode_count: 709 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.09]
Step 453 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 198.0]  episode_count: 712 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.094]
Step 454 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 199.0]  episode_count: 714 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.104]
Step 455 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 200.0]  episode_count: 715 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.114]
Step 456 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 201.0]  episode_count: 716 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.124]
{"total_number_of_episodes": 719, "number_of_timesteps": 14504, "per_episode_reward": 17.07, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
Step 457 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 202.0]  episode_count: 719 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.079]
Step 458 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 203.0]  episode_count: 721 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.089]
Step 459 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 204.0]  episode_count: 721 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.099]
Step 460 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 205.0]  episode_count: 723 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.109]
Step 461 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 206.0]  episode_count: 724 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.119]
Step 462 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 207.0]  episode_count: 725 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.128]
Step 463 6 visits [80.0, 59.0, 19.0, 5.0, 79.0, 13.0, 208.0]  episode_count: 726 q_vals: [-9.241, -9.301, -9.608, -10.125, -9.258, -9.703, -9.138]
Step 464 0 visits [81.0, 59.0, 19.0, 5.0, 79.0, 13.0, 208.0]  episode_count: 727 q_vals: [-9.265, -9.301, -9.608, -10.125, -9.258, -9.703, -9.138]
{"total_number_of_episodes": 729, "number_of_timesteps": 14744, "per_episode_reward": 17.21, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.14285714285714235},
Step 465 6 visits [81.0, 59.0, 19.0, 5.0, 79.0, 13.0, 209.0]  episode_count: 729 q_vals: [-9.265, -9.301, -9.608, -10.125, -9.258, -9.703, -9.147]
Step 466 6 visits [81.0, 59.0, 19.0, 5.0, 79.0, 13.0, 210.0]  episode_count: 731 q_vals: [-9.265, -9.301, -9.608, -10.125, -9.258, -9.703, -9.157]
Step 467 1 visits [81.0, 60.0, 19.0, 5.0, 79.0, 13.0, 210.0]  episode_count: 731 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.258, -9.703, -9.157]
Step 468 4 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 210.0]  episode_count: 732 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.157]
Step 469 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 211.0]  episode_count: 735 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.113]
Step 470 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 212.0]  episode_count: 736 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.123]
Step 471 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 213.0]  episode_count: 737 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.132]
{"total_number_of_episodes": 740, "number_of_timesteps": 15000, "per_episode_reward": 17.14, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
Step 472 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 214.0]  episode_count: 740 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.141]
Step 473 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 215.0]  episode_count: 741 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.099]
Step 474 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 216.0]  episode_count: 743 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.108]
Step 475 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 217.0]  episode_count: 743 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.066]
Step 476 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 218.0]  episode_count: 747 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.024]
Step 477 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 219.0]  episode_count: 747 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.034]
Step 478 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 220.0]  episode_count: 749 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.043]
{"total_number_of_episodes": 750, "number_of_timesteps": 15192, "per_episode_reward": 17.36, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.2142857142857153},
Step 479 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 221.0]  episode_count: 750 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.053]
Step 480 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 222.0]  episode_count: 751 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.062]
Step 481 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 223.0]  episode_count: 752 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.071]
Step 482 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 224.0]  episode_count: 756 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.031]
Step 483 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 225.0]  episode_count: 757 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.04]
Step 484 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 226.0]  episode_count: 759 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.049]
{"total_number_of_episodes": 762, "number_of_timesteps": 15421, "per_episode_reward": 17.29, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.2142857142857153},
Step 485 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 227.0]  episode_count: 762 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.009]
Step 486 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 228.0]  episode_count: 763 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.019]
Step 487 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 229.0]  episode_count: 763 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.028]
Step 488 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 230.0]  episode_count: 767 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.037]
Step 489 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 231.0]  episode_count: 769 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -8.998]
Step 490 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 232.0]  episode_count: 769 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.007]
{"total_number_of_episodes": 772, "number_of_timesteps": 15595, "per_episode_reward": 17.14, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.2142857142857153},
Step 491 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 233.0]  episode_count: 772 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.016]
Step 492 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 234.0]  episode_count: 773 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.025]
Step 493 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 235.0]  episode_count: 774 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.034]
Step 494 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 236.0]  episode_count: 776 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.042]
Step 495 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 237.0]  episode_count: 779 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.051]
Step 496 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 238.0]  episode_count: 781 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.06]
{"total_number_of_episodes": 782, "number_of_timesteps": 15774, "per_episode_reward": 17.07, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.2142857142857153},
Step 497 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 239.0]  episode_count: 782 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.068]
Step 498 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 240.0]  episode_count: 783 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.077]
Step 499 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 241.0]  episode_count: 786 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.085]
Step 500 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 242.0]  episode_count: 788 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.094]
Step 501 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 243.0]  episode_count: 788 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.102]
Step 502 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 244.0]  episode_count: 791 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.11]
{"total_number_of_episodes": 793, "number_of_timesteps": 15964, "per_episode_reward": 17.07, "episode_reward_trend_value": 0.0015873015873016211, "biggest_recent_change": 0.2142857142857153},
Step 503 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 245.0]  episode_count: 793 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.117]
Step 504 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 246.0]  episode_count: 795 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.125]
Step 505 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 247.0]  episode_count: 795 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.133]
Step 506 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 248.0]  episode_count: 797 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.096]
Step 507 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 249.0]  episode_count: 799 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.104]
Step 508 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 250.0]  episode_count: 801 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.113]
Step 509 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 251.0]  episode_count: 802 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.12]
Step 510 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 252.0]  episode_count: 802 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.128]
{"total_number_of_episodes": 804, "number_of_timesteps": 16190, "per_episode_reward": 17.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 511 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 253.0]  episode_count: 804 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.134]
Step 512 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 254.0]  episode_count: 805 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.142]
Step 513 6 visits [81.0, 60.0, 19.0, 5.0, 80.0, 13.0, 255.0]  episode_count: 806 q_vals: [-9.265, -9.331, -9.608, -10.125, -9.281, -9.703, -9.15]
Step 514 0 visits [82.0, 60.0, 19.0, 5.0, 80.0, 13.0, 255.0]  episode_count: 806 q_vals: [-9.152, -9.331, -9.608, -10.125, -9.281, -9.703, -9.15]
Step 515 0 visits [83.0, 60.0, 19.0, 5.0, 80.0, 13.0, 255.0]  episode_count: 807 q_vals: [-9.175, -9.331, -9.608, -10.125, -9.281, -9.703, -9.15]
Step 516 0 visits [84.0, 60.0, 19.0, 5.0, 80.0, 13.0, 255.0]  episode_count: 808 q_vals: [-9.198, -9.331, -9.608, -10.125, -9.281, -9.703, -9.15]
Step 517 0 visits [85.0, 60.0, 19.0, 5.0, 80.0, 13.0, 255.0]  episode_count: 810 q_vals: [-9.09, -9.331, -9.608, -10.125, -9.281, -9.703, -9.15]
Step 518 0 visits [86.0, 60.0, 19.0, 5.0, 80.0, 13.0, 255.0]  episode_count: 811 q_vals: [-9.114, -9.331, -9.608, -10.125, -9.281, -9.703, -9.15]
Step 519 0 visits [87.0, 60.0, 19.0, 5.0, 80.0, 13.0, 255.0]  episode_count: 811 q_vals: [-9.136, -9.331, -9.608, -10.125, -9.281, -9.703, -9.15]
Step 520 0 visits [88.0, 60.0, 19.0, 5.0, 80.0, 13.0, 255.0]  episode_count: 812 q_vals: [-9.159, -9.331, -9.608, -10.125, -9.281, -9.703, -9.15]
Step 521 0 visits [89.0, 60.0, 19.0, 5.0, 80.0, 13.0, 255.0]  episode_count: 812 q_vals: [-9.181, -9.331, -9.608, -10.125, -9.281, -9.703, -9.15]
{"total_number_of_episodes": 814, "number_of_timesteps": 16494, "per_episode_reward": 17.21, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 522 0 visits [90.0, 60.0, 19.0, 5.0, 80.0, 13.0, 255.0]  episode_count: 814 q_vals: [-9.198, -9.331, -9.608, -10.125, -9.281, -9.703, -9.15]
Step 523 0 visits [91.0, 60.0, 19.0, 5.0, 80.0, 13.0, 255.0]  episode_count: 814 q_vals: [-9.219, -9.331, -9.608, -10.125, -9.281, -9.703, -9.15]
Step 524 0 visits [92.0, 60.0, 19.0, 5.0, 80.0, 13.0, 255.0]  episode_count: 817 q_vals: [-9.24, -9.331, -9.608, -10.125, -9.281, -9.703, -9.15]
Step 525 0 visits [93.0, 60.0, 19.0, 5.0, 80.0, 13.0, 255.0]  episode_count: 820 q_vals: [-9.26, -9.331, -9.608, -10.125, -9.281, -9.703, -9.15]
Step 526 6 visits [93.0, 60.0, 19.0, 5.0, 80.0, 13.0, 256.0]  episode_count: 821 q_vals: [-9.26, -9.331, -9.608, -10.125, -9.281, -9.703, -9.158]
Step 527 0 visits [94.0, 60.0, 19.0, 5.0, 80.0, 13.0, 256.0]  episode_count: 822 q_vals: [-9.279, -9.331, -9.608, -10.125, -9.281, -9.703, -9.158]
{"total_number_of_episodes": 825, "number_of_timesteps": 16788, "per_episode_reward": 17.21, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.2142857142857153},
Step 528 4 visits [94.0, 60.0, 19.0, 5.0, 81.0, 13.0, 256.0]  episode_count: 825 q_vals: [-9.279, -9.331, -9.608, -10.125, -9.304, -9.703, -9.158]
[-9.279, -9.331, -9.608, -10.125, -9.304, -9.703, -9.165]
Step 530 3 visits [94.0, 60.0, 19.0, 6.0, 81.0, 13.0, 257.0]  episode_count: 826 q_vals: [-9.279, -9.331, -9.608, -10.289, -9.304, -9.703, -9.165]
Step 531 1 visits [94.0, 61.0, 19.0, 6.0, 81.0, 13.0, 257.0]  episode_count: 826 q_vals: [-9.279, -9.361, -9.608, -10.289, -9.304, -9.703, -9.165]
Step 532 5 visits [94.0, 61.0, 19.0, 6.0, 81.0, 14.0, 257.0]  episode_count: 827 q_vals: [-9.279, -9.361, -9.608, -10.289, -9.304, -9.804, -9.165]
Step 533 6 visits [94.0, 61.0, 19.0, 6.0, 81.0, 14.0, 258.0]  episode_count: 830 q_vals: [-9.279, -9.361, -9.608, -10.289, -9.304, -9.804, -9.173]
Step 534 6 visits [94.0, 61.0, 19.0, 6.0, 81.0, 14.0, 259.0]  episode_count: 831 q_vals: [-9.279, -9.361, -9.608, -10.289, -9.304, -9.804, -9.18]
Step 535 0 visits [95.0, 61.0, 19.0, 6.0, 81.0, 14.0, 259.0]  episode_count: 833 q_vals: [-9.299, -9.361, -9.608, -10.289, -9.304, -9.804, -9.18]
Step 536 6 visits [95.0, 61.0, 19.0, 6.0, 81.0, 14.0, 260.0]  episode_count: 833 q_vals: [-9.299, -9.361, -9.608, -10.289, -9.304, -9.804, -9.187]
{"total_number_of_episodes": 835, "number_of_timesteps": 17004, "per_episode_reward": 17.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.2142857142857153},
Step 537 4 visits [95.0, 61.0, 19.0, 6.0, 82.0, 14.0, 260.0]  episode_count: 835 q_vals: [-9.299, -9.361, -9.608, -10.289, -9.326, -9.804, -9.187]
Step 538 6 visits [95.0, 61.0, 19.0, 6.0, 82.0, 14.0, 261.0]  episode_count: 837 q_vals: [-9.299, -9.361, -9.608, -10.289, -9.326, -9.804, -9.194]
Step 539 2 visits [95.0, 61.0, 20.0, 6.0, 82.0, 14.0, 261.0]  episode_count: 839 q_vals: [-9.299, -9.361, -9.683, -10.289, -9.326, -9.804, -9.194]
Step 540 6 visits [95.0, 61.0, 20.0, 6.0, 82.0, 14.0, 262.0]  episode_count: 841 q_vals: [-9.299, -9.361, -9.683, -10.289, -9.326, -9.804, -9.202]
Step 541 1 visits [95.0, 62.0, 20.0, 6.0, 82.0, 14.0, 262.0]  episode_count: 841 q_vals: [-9.299, -9.389, -9.683, -10.289, -9.326, -9.804, -9.202]
Step 542 0 visits [96.0, 62.0, 20.0, 6.0, 82.0, 14.0, 262.0]  episode_count: 844 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.326, -9.804, -9.202]
{"total_number_of_episodes": 846, "number_of_timesteps": 17256, "per_episode_reward": 17.0, "episode_reward_trend_value": -0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
Step 543 6 visits [96.0, 62.0, 20.0, 6.0, 82.0, 14.0, 263.0]  episode_count: 846 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.326, -9.804, -9.209]
Step 544 4 visits [96.0, 62.0, 20.0, 6.0, 83.0, 14.0, 263.0]  episode_count: 847 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.213, -9.804, -9.209]
Step 545 4 visits [96.0, 62.0, 20.0, 6.0, 84.0, 14.0, 263.0]  episode_count: 847 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.236, -9.804, -9.209]
Step 546 4 visits [96.0, 62.0, 20.0, 6.0, 85.0, 14.0, 263.0]  episode_count: 850 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.258, -9.804, -9.209]
Step 547 4 visits [96.0, 62.0, 20.0, 6.0, 86.0, 14.0, 263.0]  episode_count: 852 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.15, -9.804, -9.209]
Step 548 4 visits [96.0, 62.0, 20.0, 6.0, 87.0, 14.0, 263.0]  episode_count: 852 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.173, -9.804, -9.209]
Step 549 4 visits [96.0, 62.0, 20.0, 6.0, 88.0, 14.0, 263.0]  episode_count: 852 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.195, -9.804, -9.209]
Step 550 4 visits [96.0, 62.0, 20.0, 6.0, 89.0, 14.0, 263.0]  episode_count: 854 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.216, -9.804, -9.209]
Step 551 4 visits [96.0, 62.0, 20.0, 6.0, 90.0, 14.0, 263.0]  episode_count: 854 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.114, -9.804, -9.209]
{"total_number_of_episodes": 856, "number_of_timesteps": 17428, "per_episode_reward": 17.0, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 552 4 visits [96.0, 62.0, 20.0, 6.0, 91.0, 14.0, 263.0]  episode_count: 856 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.136, -9.804, -9.209]
Step 553 4 visits [96.0, 62.0, 20.0, 6.0, 92.0, 14.0, 263.0]  episode_count: 857 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.157, -9.804, -9.209]
Step 554 4 visits [96.0, 62.0, 20.0, 6.0, 93.0, 14.0, 263.0]  episode_count: 858 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.178, -9.804, -9.209]
Step 555 4 visits [96.0, 62.0, 20.0, 6.0, 94.0, 14.0, 263.0]  episode_count: 861 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.199, -9.804, -9.209]
Step 556 4 visits [96.0, 62.0, 20.0, 6.0, 95.0, 14.0, 263.0]  episode_count: 862 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.152, -9.804, -9.209]
Step 557 4 visits [96.0, 62.0, 20.0, 6.0, 96.0, 14.0, 263.0]  episode_count: 863 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.173, -9.804, -9.209]
Step 558 4 visits [96.0, 62.0, 20.0, 6.0, 97.0, 14.0, 263.0]  episode_count: 865 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.193, -9.804, -9.209]
{"total_number_of_episodes": 866, "number_of_timesteps": 17712, "per_episode_reward": 17.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 559 4 visits [96.0, 62.0, 20.0, 6.0, 98.0, 14.0, 263.0]  episode_count: 866 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.212, -9.804, -9.209]
Step 560 4 visits [96.0, 62.0, 20.0, 6.0, 99.0, 14.0, 263.0]  episode_count: 867 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.232, -9.804, -9.209]
Step 561 4 visits [96.0, 62.0, 20.0, 6.0, 100.0, 14.0, 263.0]  episode_count: 868 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.225, -9.804, -9.209]
Step 562 4 visits [96.0, 62.0, 20.0, 6.0, 101.0, 14.0, 263.0]  episode_count: 869 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.243, -9.804, -9.209]
Step 563 4 visits [96.0, 62.0, 20.0, 6.0, 102.0, 14.0, 263.0]  episode_count: 870 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.259, -9.804, -9.209]
Step 564 4 visits [96.0, 62.0, 20.0, 6.0, 103.0, 14.0, 263.0]  episode_count: 871 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.277, -9.804, -9.209]
Step 565 4 visits [96.0, 62.0, 20.0, 6.0, 104.0, 14.0, 263.0]  episode_count: 872 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.294, -9.804, -9.209]
Step 566 4 visits [96.0, 62.0, 20.0, 6.0, 105.0, 14.0, 263.0]  episode_count: 873 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.312, -9.804, -9.209]
Step 567 6 visits [96.0, 62.0, 20.0, 6.0, 105.0, 14.0, 264.0]  episode_count: 874 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.312, -9.804, -9.214]
{"total_number_of_episodes": 876, "number_of_timesteps": 17994, "per_episode_reward": 17.07, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 568 6 visits [96.0, 62.0, 20.0, 6.0, 105.0, 14.0, 265.0]  episode_count: 876 q_vals: [-9.318, -9.389, -9.683, -10.289, -9.312, -9.804, -9.221]
Step 569 0 visits [97.0, 62.0, 20.0, 6.0, 105.0, 14.0, 265.0]  episode_count: 877 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.312, -9.804, -9.221]
Step 570 4 visits [97.0, 62.0, 20.0, 6.0, 106.0, 14.0, 265.0]  episode_count: 878 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.329, -9.804, -9.221]
Step 571 6 visits [97.0, 62.0, 20.0, 6.0, 106.0, 14.0, 266.0]  episode_count: 881 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.329, -9.804, -9.187]
Step 572 6 visits [97.0, 62.0, 20.0, 6.0, 106.0, 14.0, 267.0]  episode_count: 881 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.329, -9.804, -9.152]
Step 573 6 visits [97.0, 62.0, 20.0, 6.0, 106.0, 14.0, 268.0]  episode_count: 882 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.329, -9.804, -9.16]
Step 574 6 visits [97.0, 62.0, 20.0, 6.0, 106.0, 14.0, 269.0]  episode_count: 884 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.329, -9.804, -9.166]
{"total_number_of_episodes": 887, "number_of_timesteps": 18187, "per_episode_reward": 17.14, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.14285714285714235},
Step 575 6 visits [97.0, 62.0, 20.0, 6.0, 106.0, 14.0, 270.0]  episode_count: 887 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.329, -9.804, -9.17]
Step 576 6 visits [97.0, 62.0, 20.0, 6.0, 106.0, 14.0, 271.0]  episode_count: 887 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.329, -9.804, -9.178]
Step 577 6 visits [97.0, 62.0, 20.0, 6.0, 106.0, 14.0, 272.0]  episode_count: 887 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.329, -9.804, -9.185]
Step 578 6 visits [97.0, 62.0, 20.0, 6.0, 106.0, 14.0, 273.0]  episode_count: 891 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.329, -9.804, -9.192]
Step 579 6 visits [97.0, 62.0, 20.0, 6.0, 106.0, 14.0, 274.0]  episode_count: 892 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.329, -9.804, -9.199]
Step 580 6 visits [97.0, 62.0, 20.0, 6.0, 106.0, 14.0, 275.0]  episode_count: 892 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.329, -9.804, -9.204]
Step 581 6 visits [97.0, 62.0, 20.0, 6.0, 106.0, 14.0, 276.0]  episode_count: 894 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.329, -9.804, -9.211]
Step 582 6 visits [97.0, 62.0, 20.0, 6.0, 106.0, 14.0, 277.0]  episode_count: 896 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.329, -9.804, -9.218]
Step 583 6 visits [97.0, 62.0, 20.0, 6.0, 106.0, 14.0, 278.0]  episode_count: 896 q_vals: [-9.336, -9.389, -9.683, -10.289, -9.329, -9.804, -9.224]
{"total_number_of_episodes": 898, "number_of_timesteps": 18536, "per_episode_reward": 17.21, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.14285714285714235},
Step 584 1 visits [97.0, 63.0, 20.0, 6.0, 106.0, 14.0, 278.0]  episode_count: 898 q_vals: [-9.336, -9.416, -9.683, -10.289, -9.329, -9.804, -9.224]
Step 585 6 visits [97.0, 63.0, 20.0, 6.0, 106.0, 14.0, 279.0]  episode_count: 901 q_vals: [-9.336, -9.416, -9.683, -10.289, -9.329, -9.804, -9.231]
Step 586 0 visits [98.0, 63.0, 20.0, 6.0, 106.0, 14.0, 279.0]  episode_count: 902 q_vals: [-9.354, -9.416, -9.683, -10.289, -9.329, -9.804, -9.231]
Step 587 6 visits [98.0, 63.0, 20.0, 6.0, 106.0, 14.0, 280.0]  episode_count: 904 q_vals: [-9.354, -9.416, -9.683, -10.289, -9.329, -9.804, -9.238]
Step 588 4 visits [98.0, 63.0, 20.0, 6.0, 107.0, 14.0, 280.0]  episode_count: 906 q_vals: [-9.354, -9.416, -9.683, -10.289, -9.345, -9.804, -9.238]
{"total_number_of_episodes": 908, "number_of_timesteps": 18727, "per_episode_reward": 17.07, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 589 6 visits [98.0, 63.0, 20.0, 6.0, 107.0, 14.0, 281.0]  episode_count: 908 q_vals: [-9.354, -9.416, -9.683, -10.289, -9.345, -9.804, -9.243]
Step 590 6 visits [98.0, 63.0, 20.0, 6.0, 107.0, 14.0, 282.0]  episode_count: 910 q_vals: [-9.354, -9.416, -9.683, -10.289, -9.345, -9.804, -9.25]
Step 591 1 visits [98.0, 64.0, 20.0, 6.0, 107.0, 14.0, 282.0]  episode_count: 913 q_vals: [-9.354, -9.443, -9.683, -10.289, -9.345, -9.804, -9.25]
Step 592 0 visits [99.0, 64.0, 20.0, 6.0, 107.0, 14.0, 282.0]  episode_count: 915 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.345, -9.804, -9.25]
Step 593 6 visits [99.0, 64.0, 20.0, 6.0, 107.0, 14.0, 283.0]  episode_count: 917 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.345, -9.804, -9.217]
{"total_number_of_episodes": 920, "number_of_timesteps": 18886, "per_episode_reward": 16.93, "episode_reward_trend_value": -0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
Step 594 6 visits [99.0, 64.0, 20.0, 6.0, 107.0, 14.0, 284.0]  episode_count: 920 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.345, -9.804, -9.224]
Step 595 6 visits [99.0, 64.0, 20.0, 6.0, 107.0, 14.0, 285.0]  episode_count: 922 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.345, -9.804, -9.231]
Step 596 6 visits [99.0, 64.0, 20.0, 6.0, 107.0, 14.0, 286.0]  episode_count: 926 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.345, -9.804, -9.198]
Step 597 6 visits [99.0, 64.0, 20.0, 6.0, 107.0, 14.0, 287.0]  episode_count: 927 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.345, -9.804, -9.204]
{"total_number_of_episodes": 932, "number_of_timesteps": 19023, "per_episode_reward": 16.86, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.1428571428571459},
Step 598 6 visits [99.0, 64.0, 20.0, 6.0, 107.0, 14.0, 288.0]  episode_count: 932 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.345, -9.804, -9.21]
Step 599 6 visits [99.0, 64.0, 20.0, 6.0, 107.0, 14.0, 289.0]  episode_count: 933 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.345, -9.804, -9.217]
Step 600 6 visits [99.0, 64.0, 20.0, 6.0, 107.0, 14.0, 290.0]  episode_count: 935 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.345, -9.804, -9.224]
Step 601 6 visits [99.0, 64.0, 20.0, 6.0, 107.0, 14.0, 291.0]  episode_count: 940 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.345, -9.804, -9.23]
Step 602 6 visits [99.0, 64.0, 20.0, 6.0, 107.0, 14.0, 292.0]  episode_count: 941 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.345, -9.804, -9.236]
{"total_number_of_episodes": 942, "number_of_timesteps": 19132, "per_episode_reward": 16.71, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.1428571428571459},
Step 603 6 visits [99.0, 64.0, 20.0, 6.0, 107.0, 14.0, 293.0]  episode_count: 942 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.345, -9.804, -9.243]
Step 604 6 visits [99.0, 64.0, 20.0, 6.0, 107.0, 14.0, 294.0]  episode_count: 946 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.345, -9.804, -9.249]
Step 605 4 visits [99.0, 64.0, 20.0, 6.0, 108.0, 14.0, 294.0]  episode_count: 947 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.362, -9.804, -9.249]
Step 606 6 visits [99.0, 64.0, 20.0, 6.0, 108.0, 14.0, 295.0]  episode_count: 950 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.362, -9.804, -9.256]
{"total_number_of_episodes": 953, "number_of_timesteps": 19283, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.2142857142857153},
Step 607 6 visits [99.0, 64.0, 20.0, 6.0, 108.0, 14.0, 296.0]  episode_count: 953 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.362, -9.804, -9.262]
Step 608 6 visits [99.0, 64.0, 20.0, 6.0, 108.0, 14.0, 297.0]  episode_count: 955 q_vals: [-9.372, -9.443, -9.683, -10.289, -9.362, -9.804, -9.268]
Step 609 2 visits [99.0, 64.0, 21.0, 6.0, 108.0, 14.0, 297.0]  episode_count: 956 q_vals: [-9.372, -9.443, -9.751, -10.289, -9.362, -9.804, -9.268]
Step 610 0 visits [100.0, 64.0, 21.0, 6.0, 108.0, 14.0, 297.0]  episode_count: 957 q_vals: [-9.389, -9.443, -9.751, -10.289, -9.362, -9.804, -9.268]
Step 611 4 visits [100.0, 64.0, 21.0, 6.0, 109.0, 14.0, 297.0]  episode_count: 960 q_vals: [-9.389, -9.443, -9.751, -10.289, -9.276, -9.804, -9.268]
{"total_number_of_episodes": 963, "number_of_timesteps": 19432, "per_episode_reward": 16.57, "episode_reward_trend_value": -0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
Step 612 4 visits [100.0, 64.0, 21.0, 6.0, 110.0, 14.0, 297.0]  episode_count: 963 q_vals: [-9.389, -9.443, -9.751, -10.289, -9.292, -9.804, -9.268]
Step 613 4 visits [100.0, 64.0, 21.0, 6.0, 111.0, 14.0, 297.0]  episode_count: 964 q_vals: [-9.389, -9.443, -9.751, -10.289, -9.309, -9.804, -9.268]
Step 614 4 visits [100.0, 64.0, 21.0, 6.0, 112.0, 14.0, 297.0]  episode_count: 964 q_vals: [-9.389, -9.443, -9.751, -10.289, -9.325, -9.804, -9.268]
Step 615 4 visits [100.0, 64.0, 21.0, 6.0, 113.0, 14.0, 297.0]  episode_count: 969 q_vals: [-9.389, -9.443, -9.751, -10.289, -9.341, -9.804, -9.268]
Step 616 4 visits [100.0, 64.0, 21.0, 6.0, 114.0, 14.0, 297.0]  episode_count: 971 q_vals: [-9.389, -9.443, -9.751, -10.289, -9.356, -9.804, -9.268]
Step 617 4 visits [100.0, 64.0, 21.0, 6.0, 115.0, 14.0, 297.0]  episode_count: 972 q_vals: [-9.389, -9.443, -9.751, -10.289, -9.371, -9.804, -9.268]
{"total_number_of_episodes": 975, "number_of_timesteps": 19614, "per_episode_reward": 16.57, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.2142857142857153},
Step 618 6 visits [100.0, 64.0, 21.0, 6.0, 115.0, 14.0, 298.0]  episode_count: 975 q_vals: [-9.389, -9.443, -9.751, -10.289, -9.371, -9.804, -9.274]
Step 619 1 visits [100.0, 65.0, 21.0, 6.0, 115.0, 14.0, 298.0]  episode_count: 977 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.371, -9.804, -9.274]
Step 620 5 visits [100.0, 65.0, 21.0, 6.0, 115.0, 15.0, 298.0]  episode_count: 980 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.371, -9.891, -9.274]
Step 621 6 visits [100.0, 65.0, 21.0, 6.0, 115.0, 15.0, 299.0]  episode_count: 984 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.371, -9.891, -9.28]
Step 622 6 visits [100.0, 65.0, 21.0, 6.0, 115.0, 15.0, 300.0]  episode_count: 984 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.371, -9.891, -9.284]
{"total_number_of_episodes": 988, "number_of_timesteps": 19774, "per_episode_reward": 16.36, "episode_reward_trend_value": -0.008730158730158718, "biggest_recent_change": 0.2142857142857153},
Step 623 4 visits [100.0, 65.0, 21.0, 6.0, 116.0, 15.0, 300.0]  episode_count: 988 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.291, -9.891, -9.284]
Step 624 4 visits [100.0, 65.0, 21.0, 6.0, 117.0, 15.0, 300.0]  episode_count: 991 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.306, -9.891, -9.284]
Step 625 4 visits [100.0, 65.0, 21.0, 6.0, 118.0, 15.0, 300.0]  episode_count: 991 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.322, -9.891, -9.284]
Step 626 4 visits [100.0, 65.0, 21.0, 6.0, 119.0, 15.0, 300.0]  episode_count: 996 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.243, -9.891, -9.284]
Step 627 4 visits [100.0, 65.0, 21.0, 6.0, 120.0, 15.0, 300.0]  episode_count: 997 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.259, -9.891, -9.284]
{"total_number_of_episodes": 999, "number_of_timesteps": 19909, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.011904761904761921, "biggest_recent_change": 0.2142857142857153},
Step 628 4 visits [100.0, 65.0, 21.0, 6.0, 121.0, 15.0, 300.0]  episode_count: 999 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.274, -9.891, -9.284]
Step 629 4 visits [100.0, 65.0, 21.0, 6.0, 122.0, 15.0, 300.0]  episode_count: 1001 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.198, -9.891, -9.284]
Step 630 4 visits [100.0, 65.0, 21.0, 6.0, 123.0, 15.0, 300.0]  episode_count: 1002 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.123, -9.891, -9.284]
Step 631 4 visits [100.0, 65.0, 21.0, 6.0, 124.0, 15.0, 300.0]  episode_count: 1004 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.05, -9.891, -9.284]
Step 632 4 visits [100.0, 65.0, 21.0, 6.0, 125.0, 15.0, 300.0]  episode_count: 1006 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.066, -9.891, -9.284]
{"total_number_of_episodes": 1009, "number_of_timesteps": 20083, "per_episode_reward": 16.07, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.2142857142857153},
Step 633 4 visits [100.0, 65.0, 21.0, 6.0, 126.0, 15.0, 300.0]  episode_count: 1009 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.082, -9.891, -9.284]
Step 634 4 visits [100.0, 65.0, 21.0, 6.0, 127.0, 15.0, 300.0]  episode_count: 1010 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.098, -9.891, -9.284]
Step 635 4 visits [100.0, 65.0, 21.0, 6.0, 128.0, 15.0, 300.0]  episode_count: 1011 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.114, -9.891, -9.284]
Step 636 4 visits [100.0, 65.0, 21.0, 6.0, 129.0, 15.0, 300.0]  episode_count: 1013 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.13, -9.891, -9.284]
Step 637 4 visits [100.0, 65.0, 21.0, 6.0, 130.0, 15.0, 300.0]  episode_count: 1017 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.059, -9.891, -9.284]
{"total_number_of_episodes": 1019, "number_of_timesteps": 20236, "per_episode_reward": 16.21, "episode_reward_trend_value": -0.007936507936507908, "biggest_recent_change": 0.2142857142857153},
Step 638 4 visits [100.0, 65.0, 21.0, 6.0, 131.0, 15.0, 300.0]  episode_count: 1019 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.075, -9.891, -9.284]
Step 639 4 visits [100.0, 65.0, 21.0, 6.0, 132.0, 15.0, 300.0]  episode_count: 1020 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.09, -9.891, -9.284]
Step 640 4 visits [100.0, 65.0, 21.0, 6.0, 133.0, 15.0, 300.0]  episode_count: 1021 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.106, -9.891, -9.284]
Step 641 4 visits [100.0, 65.0, 21.0, 6.0, 134.0, 15.0, 300.0]  episode_count: 1022 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.121, -9.891, -9.284]
Step 642 4 visits [100.0, 65.0, 21.0, 6.0, 135.0, 15.0, 300.0]  episode_count: 1023 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.131, -9.891, -9.284]
Step 643 4 visits [100.0, 65.0, 21.0, 6.0, 136.0, 15.0, 300.0]  episode_count: 1025 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.146, -9.891, -9.284]
Step 644 4 visits [100.0, 65.0, 21.0, 6.0, 137.0, 15.0, 300.0]  episode_count: 1026 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.16, -9.891, -9.284]
Step 645 4 visits [100.0, 65.0, 21.0, 6.0, 138.0, 15.0, 300.0]  episode_count: 1027 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.174, -9.891, -9.284]
{"total_number_of_episodes": 1029, "number_of_timesteps": 20421, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.007936507936507946, "biggest_recent_change": 0.2142857142857153},
Step 646 4 visits [100.0, 65.0, 21.0, 6.0, 139.0, 15.0, 300.0]  episode_count: 1029 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.185, -9.891, -9.284]
Step 647 4 visits [100.0, 65.0, 21.0, 6.0, 140.0, 15.0, 300.0]  episode_count: 1031 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.199, -9.891, -9.284]
Step 648 4 visits [100.0, 65.0, 21.0, 6.0, 141.0, 15.0, 300.0]  episode_count: 1033 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.211, -9.891, -9.284]
Step 649 4 visits [100.0, 65.0, 21.0, 6.0, 142.0, 15.0, 300.0]  episode_count: 1033 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.223, -9.891, -9.284]
Step 650 4 visits [100.0, 65.0, 21.0, 6.0, 143.0, 15.0, 300.0]  episode_count: 1035 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.217, -9.891, -9.284]
Step 651 4 visits [100.0, 65.0, 21.0, 6.0, 144.0, 15.0, 300.0]  episode_count: 1038 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.153, -9.891, -9.284]
{"total_number_of_episodes": 1039, "number_of_timesteps": 20643, "per_episode_reward": 16.21, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.2142857142857153},
Step 652 4 visits [100.0, 65.0, 21.0, 6.0, 145.0, 15.0, 300.0]  episode_count: 1039 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.09, -9.891, -9.284]
Step 653 4 visits [100.0, 65.0, 21.0, 6.0, 146.0, 15.0, 300.0]  episode_count: 1040 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.103, -9.891, -9.284]
Step 654 4 visits [100.0, 65.0, 21.0, 6.0, 147.0, 15.0, 300.0]  episode_count: 1040 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.117, -9.891, -9.284]
Step 655 4 visits [100.0, 65.0, 21.0, 6.0, 148.0, 15.0, 300.0]  episode_count: 1041 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.131, -9.891, -9.284]
Step 656 4 visits [100.0, 65.0, 21.0, 6.0, 149.0, 15.0, 300.0]  episode_count: 1042 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.14, -9.891, -9.284]
Step 657 4 visits [100.0, 65.0, 21.0, 6.0, 150.0, 15.0, 300.0]  episode_count: 1043 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.079, -9.891, -9.284]
Step 658 4 visits [100.0, 65.0, 21.0, 6.0, 151.0, 15.0, 300.0]  episode_count: 1046 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.019, -9.891, -9.284]
Step 659 4 visits [100.0, 65.0, 21.0, 6.0, 152.0, 15.0, 300.0]  episode_count: 1047 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.032, -9.891, -9.284]
Step 660 4 visits [100.0, 65.0, 21.0, 6.0, 153.0, 15.0, 300.0]  episode_count: 1048 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.046, -9.891, -9.284]
Step 661 4 visits [100.0, 65.0, 21.0, 6.0, 154.0, 15.0, 300.0]  episode_count: 1048 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.059, -9.891, -9.284]
{"total_number_of_episodes": 1049, "number_of_timesteps": 20922, "per_episode_reward": 16.29, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.2142857142857153},
Step 662 4 visits [100.0, 65.0, 21.0, 6.0, 155.0, 15.0, 300.0]  episode_count: 1049 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.073, -9.891, -9.284]
Step 663 4 visits [100.0, 65.0, 21.0, 6.0, 156.0, 15.0, 300.0]  episode_count: 1050 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.086, -9.891, -9.284]
Step 664 4 visits [100.0, 65.0, 21.0, 6.0, 157.0, 15.0, 300.0]  episode_count: 1051 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.094, -9.891, -9.284]
Step 665 4 visits [100.0, 65.0, 21.0, 6.0, 158.0, 15.0, 300.0]  episode_count: 1053 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.107, -9.891, -9.284]
Step 666 4 visits [100.0, 65.0, 21.0, 6.0, 159.0, 15.0, 300.0]  episode_count: 1055 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.12, -9.891, -9.284]
Step 667 4 visits [100.0, 65.0, 21.0, 6.0, 160.0, 15.0, 300.0]  episode_count: 1058 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.132, -9.891, -9.284]
{"total_number_of_episodes": 1059, "number_of_timesteps": 21170, "per_episode_reward": 16.29, "episode_reward_trend_value": -0.003174603174603203, "biggest_recent_change": 0.2142857142857153},
Step 668 4 visits [100.0, 65.0, 21.0, 6.0, 161.0, 15.0, 300.0]  episode_count: 1059 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.145, -9.891, -9.284]
Step 669 4 visits [100.0, 65.0, 21.0, 6.0, 162.0, 15.0, 300.0]  episode_count: 1059 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.15, -9.891, -9.284]
Step 670 4 visits [100.0, 65.0, 21.0, 6.0, 163.0, 15.0, 300.0]  episode_count: 1061 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.162, -9.891, -9.284]
Step 671 4 visits [100.0, 65.0, 21.0, 6.0, 164.0, 15.0, 300.0]  episode_count: 1064 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.166, -9.891, -9.284]
Step 672 4 visits [100.0, 65.0, 21.0, 6.0, 165.0, 15.0, 300.0]  episode_count: 1064 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.178, -9.891, -9.284]
Step 673 4 visits [100.0, 65.0, 21.0, 6.0, 166.0, 15.0, 300.0]  episode_count: 1067 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.19, -9.891, -9.284]
{"total_number_of_episodes": 1070, "number_of_timesteps": 21382, "per_episode_reward": 16.29, "episode_reward_trend_value": -0.003174603174603203, "biggest_recent_change": 0.2142857142857153},
Step 674 4 visits [100.0, 65.0, 21.0, 6.0, 167.0, 15.0, 300.0]  episode_count: 1070 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.194, -9.891, -9.284]
Step 675 4 visits [100.0, 65.0, 21.0, 6.0, 168.0, 15.0, 300.0]  episode_count: 1071 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.139, -9.891, -9.284]
Step 676 4 visits [100.0, 65.0, 21.0, 6.0, 169.0, 15.0, 300.0]  episode_count: 1071 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.151, -9.891, -9.284]
Step 677 4 visits [100.0, 65.0, 21.0, 6.0, 170.0, 15.0, 300.0]  episode_count: 1074 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.097, -9.891, -9.284]
Step 678 4 visits [100.0, 65.0, 21.0, 6.0, 171.0, 15.0, 300.0]  episode_count: 1075 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.109, -9.891, -9.284]
Step 679 4 visits [100.0, 65.0, 21.0, 6.0, 172.0, 15.0, 300.0]  episode_count: 1077 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.121, -9.891, -9.284]
{"total_number_of_episodes": 1080, "number_of_timesteps": 21546, "per_episode_reward": 16.36, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.2142857142857153},
Step 680 4 visits [100.0, 65.0, 21.0, 6.0, 173.0, 15.0, 300.0]  episode_count: 1080 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.068, -9.891, -9.284]
Step 681 4 visits [100.0, 65.0, 21.0, 6.0, 174.0, 15.0, 300.0]  episode_count: 1081 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.079, -9.891, -9.284]
Step 682 4 visits [100.0, 65.0, 21.0, 6.0, 175.0, 15.0, 300.0]  episode_count: 1083 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.091, -9.891, -9.284]
Step 683 4 visits [100.0, 65.0, 21.0, 6.0, 176.0, 15.0, 300.0]  episode_count: 1085 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.1, -9.891, -9.284]
Step 684 4 visits [100.0, 65.0, 21.0, 6.0, 177.0, 15.0, 300.0]  episode_count: 1088 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.104, -9.891, -9.284]
{"total_number_of_episodes": 1090, "number_of_timesteps": 21733, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 685 4 visits [100.0, 65.0, 21.0, 6.0, 178.0, 15.0, 300.0]  episode_count: 1090 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.108, -9.891, -9.284]
Step 686 4 visits [100.0, 65.0, 21.0, 6.0, 179.0, 15.0, 300.0]  episode_count: 1091 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.114, -9.891, -9.284]
Step 687 4 visits [100.0, 65.0, 21.0, 6.0, 180.0, 15.0, 300.0]  episode_count: 1092 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.063, -9.891, -9.284]
Step 688 4 visits [100.0, 65.0, 21.0, 6.0, 181.0, 15.0, 300.0]  episode_count: 1093 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.068, -9.891, -9.284]
Step 689 4 visits [100.0, 65.0, 21.0, 6.0, 182.0, 15.0, 300.0]  episode_count: 1094 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.072, -9.891, -9.284]
Step 690 4 visits [100.0, 65.0, 21.0, 6.0, 183.0, 15.0, 300.0]  episode_count: 1095 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.083, -9.891, -9.284]
Step 691 4 visits [100.0, 65.0, 21.0, 6.0, 184.0, 15.0, 300.0]  episode_count: 1096 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.09, -9.891, -9.284]
{"total_number_of_episodes": 1100, "number_of_timesteps": 21937, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0023809523809523525, "biggest_recent_change": 0.14285714285714235},
Step 692 4 visits [100.0, 65.0, 21.0, 6.0, 185.0, 15.0, 300.0]  episode_count: 1100 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.101, -9.891, -9.284]
Step 693 4 visits [100.0, 65.0, 21.0, 6.0, 186.0, 15.0, 300.0]  episode_count: 1100 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.112, -9.891, -9.284]
Step 694 4 visits [100.0, 65.0, 21.0, 6.0, 187.0, 15.0, 300.0]  episode_count: 1101 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.123, -9.891, -9.284]
Step 695 4 visits [100.0, 65.0, 21.0, 6.0, 188.0, 15.0, 300.0]  episode_count: 1103 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.133, -9.891, -9.284]
Step 696 4 visits [100.0, 65.0, 21.0, 6.0, 189.0, 15.0, 300.0]  episode_count: 1103 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.085, -9.891, -9.284]
Step 697 4 visits [100.0, 65.0, 21.0, 6.0, 190.0, 15.0, 300.0]  episode_count: 1105 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.096, -9.891, -9.284]
{"total_number_of_episodes": 1110, "number_of_timesteps": 22164, "per_episode_reward": 16.36, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
Step 698 4 visits [100.0, 65.0, 21.0, 6.0, 191.0, 15.0, 300.0]  episode_count: 1110 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.106, -9.891, -9.284]
Step 699 4 visits [100.0, 65.0, 21.0, 6.0, 192.0, 15.0, 300.0]  episode_count: 1110 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.112, -9.891, -9.284]
Step 700 4 visits [100.0, 65.0, 21.0, 6.0, 193.0, 15.0, 300.0]  episode_count: 1111 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.119, -9.891, -9.284]
Step 701 4 visits [100.0, 65.0, 21.0, 6.0, 194.0, 15.0, 300.0]  episode_count: 1112 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.124, -9.891, -9.284]
Step 702 4 visits [100.0, 65.0, 21.0, 6.0, 195.0, 15.0, 300.0]  episode_count: 1114 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.077, -9.891, -9.284]
Step 703 4 visits [100.0, 65.0, 21.0, 6.0, 196.0, 15.0, 300.0]  episode_count: 1115 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.031, -9.891, -9.284]
Step 704 4 visits [100.0, 65.0, 21.0, 6.0, 197.0, 15.0, 300.0]  episode_count: 1118 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.042, -9.891, -9.284]
Step 705 4 visits [100.0, 65.0, 21.0, 6.0, 198.0, 15.0, 300.0]  episode_count: 1119 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.046, -9.891, -9.284]
Step 706 4 visits [100.0, 65.0, 21.0, 6.0, 199.0, 15.0, 300.0]  episode_count: 1119 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.048, -9.891, -9.284]
{"total_number_of_episodes": 1120, "number_of_timesteps": 22353, "per_episode_reward": 16.21, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.14285714285714235},
Step 707 4 visits [100.0, 65.0, 21.0, 6.0, 200.0, 15.0, 300.0]  episode_count: 1120 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.059, -9.891, -9.284]
Step 708 4 visits [100.0, 65.0, 21.0, 6.0, 201.0, 15.0, 300.0]  episode_count: 1121 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.069, -9.891, -9.284]
Step 709 4 visits [100.0, 65.0, 21.0, 6.0, 202.0, 15.0, 300.0]  episode_count: 1122 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.073, -9.891, -9.284]
Step 710 4 visits [100.0, 65.0, 21.0, 6.0, 203.0, 15.0, 300.0]  episode_count: 1124 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.028, -9.891, -9.284]
Step 711 4 visits [100.0, 65.0, 21.0, 6.0, 204.0, 15.0, 300.0]  episode_count: 1125 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.031, -9.891, -9.284]
Step 712 4 visits [100.0, 65.0, 21.0, 6.0, 205.0, 15.0, 300.0]  episode_count: 1126 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.037, -9.891, -9.284]
Step 713 4 visits [100.0, 65.0, 21.0, 6.0, 206.0, 15.0, 300.0]  episode_count: 1128 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.047, -9.891, -9.284]
{"total_number_of_episodes": 1131, "number_of_timesteps": 22618, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.14285714285714235},
Step 714 4 visits [100.0, 65.0, 21.0, 6.0, 207.0, 15.0, 300.0]  episode_count: 1131 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.05, -9.891, -9.284]
Step 715 4 visits [100.0, 65.0, 21.0, 6.0, 208.0, 15.0, 300.0]  episode_count: 1132 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.058, -9.891, -9.284]
Step 716 4 visits [100.0, 65.0, 21.0, 6.0, 209.0, 15.0, 300.0]  episode_count: 1135 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.068, -9.891, -9.284]
Step 717 4 visits [100.0, 65.0, 21.0, 6.0, 210.0, 15.0, 300.0]  episode_count: 1137 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.078, -9.891, -9.284]
Step 718 4 visits [100.0, 65.0, 21.0, 6.0, 211.0, 15.0, 300.0]  episode_count: 1138 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.088, -9.891, -9.284]
Step 719 4 visits [100.0, 65.0, 21.0, 6.0, 212.0, 15.0, 300.0]  episode_count: 1140 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.097, -9.891, -9.284]
{"total_number_of_episodes": 1143, "number_of_timesteps": 22834, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 720 4 visits [100.0, 65.0, 21.0, 6.0, 213.0, 15.0, 300.0]  episode_count: 1143 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.107, -9.891, -9.284]
Step 721 4 visits [100.0, 65.0, 21.0, 6.0, 214.0, 15.0, 300.0]  episode_count: 1144 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.11, -9.891, -9.284]
Step 722 4 visits [100.0, 65.0, 21.0, 6.0, 215.0, 15.0, 300.0]  episode_count: 1145 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.119, -9.891, -9.284]
Step 723 4 visits [100.0, 65.0, 21.0, 6.0, 216.0, 15.0, 300.0]  episode_count: 1148 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.12, -9.891, -9.284]
Step 724 4 visits [100.0, 65.0, 21.0, 6.0, 217.0, 15.0, 300.0]  episode_count: 1150 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.129, -9.891, -9.284]
{"total_number_of_episodes": 1153, "number_of_timesteps": 22990, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 725 4 visits [100.0, 65.0, 21.0, 6.0, 218.0, 15.0, 300.0]  episode_count: 1153 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.131, -9.891, -9.284]
Step 726 4 visits [100.0, 65.0, 21.0, 6.0, 219.0, 15.0, 300.0]  episode_count: 1153 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.133, -9.891, -9.284]
Step 727 4 visits [100.0, 65.0, 21.0, 6.0, 220.0, 15.0, 300.0]  episode_count: 1156 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.142, -9.891, -9.284]
Step 728 4 visits [100.0, 65.0, 21.0, 6.0, 221.0, 15.0, 300.0]  episode_count: 1156 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.15, -9.891, -9.284]
Step 729 4 visits [100.0, 65.0, 21.0, 6.0, 222.0, 15.0, 300.0]  episode_count: 1156 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.159, -9.891, -9.284]
Step 730 4 visits [100.0, 65.0, 21.0, 6.0, 223.0, 15.0, 300.0]  episode_count: 1160 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.117, -9.891, -9.284]
Step 731 4 visits [100.0, 65.0, 21.0, 6.0, 224.0, 15.0, 300.0]  episode_count: 1161 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.126, -9.891, -9.284]
{"total_number_of_episodes": 1164, "number_of_timesteps": 23203, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 732 4 visits [100.0, 65.0, 21.0, 6.0, 225.0, 15.0, 300.0]  episode_count: 1164 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.129, -9.891, -9.284]
Step 733 4 visits [100.0, 65.0, 21.0, 6.0, 226.0, 15.0, 300.0]  episode_count: 1164 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.134, -9.891, -9.284]
Step 734 4 visits [100.0, 65.0, 21.0, 6.0, 227.0, 15.0, 300.0]  episode_count: 1165 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.139, -9.891, -9.284]
Step 735 4 visits [100.0, 65.0, 21.0, 6.0, 228.0, 15.0, 300.0]  episode_count: 1167 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.148, -9.891, -9.284]
Step 736 4 visits [100.0, 65.0, 21.0, 6.0, 229.0, 15.0, 300.0]  episode_count: 1170 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.148, -9.891, -9.284]
Step 737 4 visits [100.0, 65.0, 21.0, 6.0, 230.0, 15.0, 300.0]  episode_count: 1170 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.157, -9.891, -9.284]
Step 738 4 visits [100.0, 65.0, 21.0, 6.0, 231.0, 15.0, 300.0]  episode_count: 1173 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.16, -9.891, -9.284]
Step 739 4 visits [100.0, 65.0, 21.0, 6.0, 232.0, 15.0, 300.0]  episode_count: 1173 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.169, -9.891, -9.284]
Step 740 4 visits [100.0, 65.0, 21.0, 6.0, 233.0, 15.0, 300.0]  episode_count: 1173 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.169, -9.891, -9.284]
{"total_number_of_episodes": 1177, "number_of_timesteps": 23467, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 741 4 visits [100.0, 65.0, 21.0, 6.0, 234.0, 15.0, 300.0]  episode_count: 1177 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.13, -9.891, -9.284]
Step 742 4 visits [100.0, 65.0, 21.0, 6.0, 235.0, 15.0, 300.0]  episode_count: 1179 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.133, -9.891, -9.284]
Step 743 4 visits [100.0, 65.0, 21.0, 6.0, 236.0, 15.0, 300.0]  episode_count: 1181 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.141, -9.891, -9.284]
Step 744 4 visits [100.0, 65.0, 21.0, 6.0, 237.0, 15.0, 300.0]  episode_count: 1181 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.15, -9.891, -9.284]
Step 745 4 visits [100.0, 65.0, 21.0, 6.0, 238.0, 15.0, 300.0]  episode_count: 1184 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.158, -9.891, -9.284]
Step 746 4 visits [100.0, 65.0, 21.0, 6.0, 239.0, 15.0, 300.0]  episode_count: 1186 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.161, -9.891, -9.284]
Step 747 4 visits [100.0, 65.0, 21.0, 6.0, 240.0, 15.0, 300.0]  episode_count: 1186 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.123, -9.891, -9.284]
{"total_number_of_episodes": 1189, "number_of_timesteps": 23679, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 748 4 visits [100.0, 65.0, 21.0, 6.0, 241.0, 15.0, 300.0]  episode_count: 1189 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.131, -9.891, -9.284]
Step 749 4 visits [100.0, 65.0, 21.0, 6.0, 242.0, 15.0, 300.0]  episode_count: 1190 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.139, -9.891, -9.284]
Step 750 4 visits [100.0, 65.0, 21.0, 6.0, 243.0, 15.0, 300.0]  episode_count: 1191 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.147, -9.891, -9.284]
Step 751 4 visits [100.0, 65.0, 21.0, 6.0, 244.0, 15.0, 300.0]  episode_count: 1193 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.141, -9.891, -9.284]
Step 752 4 visits [100.0, 65.0, 21.0, 6.0, 245.0, 15.0, 300.0]  episode_count: 1195 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.149, -9.891, -9.284]
Step 753 4 visits [100.0, 65.0, 21.0, 6.0, 246.0, 15.0, 300.0]  episode_count: 1196 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.111, -9.891, -9.284]
Step 754 4 visits [100.0, 65.0, 21.0, 6.0, 247.0, 15.0, 300.0]  episode_count: 1198 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.12, -9.891, -9.284]
{"total_number_of_episodes": 1200, "number_of_timesteps": 23892, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 755 4 visits [100.0, 65.0, 21.0, 6.0, 248.0, 15.0, 300.0]  episode_count: 1200 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.128, -9.891, -9.284]
Step 756 4 visits [100.0, 65.0, 21.0, 6.0, 249.0, 15.0, 300.0]  episode_count: 1200 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.135, -9.891, -9.284]
Step 757 4 visits [100.0, 65.0, 21.0, 6.0, 250.0, 15.0, 300.0]  episode_count: 1201 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.143, -9.891, -9.284]
Step 758 4 visits [100.0, 65.0, 21.0, 6.0, 251.0, 15.0, 300.0]  episode_count: 1205 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.151, -9.891, -9.284]
Step 759 4 visits [100.0, 65.0, 21.0, 6.0, 252.0, 15.0, 300.0]  episode_count: 1205 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.159, -9.891, -9.284]
Step 760 4 visits [100.0, 65.0, 21.0, 6.0, 253.0, 15.0, 300.0]  episode_count: 1208 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.122, -9.891, -9.284]
Step 761 4 visits [100.0, 65.0, 21.0, 6.0, 254.0, 15.0, 300.0]  episode_count: 1209 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.086, -9.891, -9.284]
{"total_number_of_episodes": 1211, "number_of_timesteps": 24132, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.2142857142857153},
Step 762 4 visits [100.0, 65.0, 21.0, 6.0, 255.0, 15.0, 300.0]  episode_count: 1211 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.094, -9.891, -9.284]
Step 763 4 visits [100.0, 65.0, 21.0, 6.0, 256.0, 15.0, 300.0]  episode_count: 1213 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.095, -9.891, -9.284]
Step 764 4 visits [100.0, 65.0, 21.0, 6.0, 257.0, 15.0, 300.0]  episode_count: 1214 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.097, -9.891, -9.284]
Step 765 4 visits [100.0, 65.0, 21.0, 6.0, 258.0, 15.0, 300.0]  episode_count: 1216 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.105, -9.891, -9.284]
Step 766 4 visits [100.0, 65.0, 21.0, 6.0, 259.0, 15.0, 300.0]  episode_count: 1218 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.11, -9.891, -9.284]
Step 767 4 visits [100.0, 65.0, 21.0, 6.0, 260.0, 15.0, 300.0]  episode_count: 1219 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.117, -9.891, -9.284]
{"total_number_of_episodes": 1221, "number_of_timesteps": 24313, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0023809523809523525, "biggest_recent_change": 0.2142857142857153},
Step 768 4 visits [100.0, 65.0, 21.0, 6.0, 261.0, 15.0, 300.0]  episode_count: 1221 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.114, -9.891, -9.284]
Step 769 4 visits [100.0, 65.0, 21.0, 6.0, 262.0, 15.0, 300.0]  episode_count: 1222 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.122, -9.891, -9.284]
Step 770 4 visits [100.0, 65.0, 21.0, 6.0, 263.0, 15.0, 300.0]  episode_count: 1224 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.129, -9.891, -9.284]
Step 771 4 visits [100.0, 65.0, 21.0, 6.0, 264.0, 15.0, 300.0]  episode_count: 1225 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.137, -9.891, -9.284]
Step 772 4 visits [100.0, 65.0, 21.0, 6.0, 265.0, 15.0, 300.0]  episode_count: 1227 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.136, -9.891, -9.284]
Step 773 4 visits [100.0, 65.0, 21.0, 6.0, 266.0, 15.0, 300.0]  episode_count: 1228 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.142, -9.891, -9.284]
Step 774 4 visits [100.0, 65.0, 21.0, 6.0, 267.0, 15.0, 300.0]  episode_count: 1230 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.145, -9.891, -9.284]
{"total_number_of_episodes": 1231, "number_of_timesteps": 24510, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 775 4 visits [100.0, 65.0, 21.0, 6.0, 268.0, 15.0, 300.0]  episode_count: 1231 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.148, -9.891, -9.284]
Step 776 4 visits [100.0, 65.0, 21.0, 6.0, 269.0, 15.0, 300.0]  episode_count: 1233 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.114, -9.891, -9.284]
Step 777 4 visits [100.0, 65.0, 21.0, 6.0, 270.0, 15.0, 300.0]  episode_count: 1236 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.121, -9.891, -9.284]
Step 778 4 visits [100.0, 65.0, 21.0, 6.0, 271.0, 15.0, 300.0]  episode_count: 1236 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.128, -9.891, -9.284]
Step 779 4 visits [100.0, 65.0, 21.0, 6.0, 272.0, 15.0, 300.0]  episode_count: 1240 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.131, -9.891, -9.284]
{"total_number_of_episodes": 1242, "number_of_timesteps": 24709, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 780 4 visits [100.0, 65.0, 21.0, 6.0, 273.0, 15.0, 300.0]  episode_count: 1242 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.138, -9.891, -9.284]
Step 781 4 visits [100.0, 65.0, 21.0, 6.0, 274.0, 15.0, 300.0]  episode_count: 1245 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.145, -9.891, -9.284]
Step 782 4 visits [100.0, 65.0, 21.0, 6.0, 275.0, 15.0, 300.0]  episode_count: 1246 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.145, -9.891, -9.284]
Step 783 4 visits [100.0, 65.0, 21.0, 6.0, 276.0, 15.0, 300.0]  episode_count: 1248 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.152, -9.891, -9.284]
Step 784 4 visits [100.0, 65.0, 21.0, 6.0, 277.0, 15.0, 300.0]  episode_count: 1250 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.155, -9.891, -9.284]
{"total_number_of_episodes": 1253, "number_of_timesteps": 24869, "per_episode_reward": 16.21, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.2142857142857153},
Step 785 4 visits [100.0, 65.0, 21.0, 6.0, 278.0, 15.0, 300.0]  episode_count: 1253 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.122, -9.891, -9.284]
Step 786 4 visits [100.0, 65.0, 21.0, 6.0, 279.0, 15.0, 300.0]  episode_count: 1254 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.129, -9.891, -9.284]
Step 787 4 visits [100.0, 65.0, 21.0, 6.0, 280.0, 15.0, 300.0]  episode_count: 1257 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.129, -9.891, -9.284]
Step 788 4 visits [100.0, 65.0, 21.0, 6.0, 281.0, 15.0, 300.0]  episode_count: 1258 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.136, -9.891, -9.284]
Step 789 4 visits [100.0, 65.0, 21.0, 6.0, 282.0, 15.0, 300.0]  episode_count: 1261 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.136, -9.891, -9.284]
{"total_number_of_episodes": 1263, "number_of_timesteps": 25020, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 790 4 visits [100.0, 65.0, 21.0, 6.0, 283.0, 15.0, 300.0]  episode_count: 1263 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.137, -9.891, -9.284]
Step 791 4 visits [100.0, 65.0, 21.0, 6.0, 284.0, 15.0, 300.0]  episode_count: 1263 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.144, -9.891, -9.284]
Step 792 4 visits [100.0, 65.0, 21.0, 6.0, 285.0, 15.0, 300.0]  episode_count: 1267 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.146, -9.891, -9.284]
Step 793 4 visits [100.0, 65.0, 21.0, 6.0, 286.0, 15.0, 300.0]  episode_count: 1270 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.146, -9.891, -9.284]
Step 794 4 visits [100.0, 65.0, 21.0, 6.0, 287.0, 15.0, 300.0]  episode_count: 1270 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.153, -9.891, -9.284]
{"total_number_of_episodes": 1276, "number_of_timesteps": 25195, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
Step 795 4 visits [100.0, 65.0, 21.0, 6.0, 288.0, 15.0, 300.0]  episode_count: 1276 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.156, -9.891, -9.284]
Step 796 4 visits [100.0, 65.0, 21.0, 6.0, 289.0, 15.0, 300.0]  episode_count: 1277 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.161, -9.891, -9.284]
Step 797 4 visits [100.0, 65.0, 21.0, 6.0, 290.0, 15.0, 300.0]  episode_count: 1277 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.168, -9.891, -9.284]
Step 798 4 visits [100.0, 65.0, 21.0, 6.0, 291.0, 15.0, 300.0]  episode_count: 1282 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.174, -9.891, -9.284]
Step 799 4 visits [100.0, 65.0, 21.0, 6.0, 292.0, 15.0, 300.0]  episode_count: 1283 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.181, -9.891, -9.284]
Step 800 4 visits [100.0, 65.0, 21.0, 6.0, 293.0, 15.0, 300.0]  episode_count: 1283 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.18, -9.891, -9.284]
Step 801 4 visits [100.0, 65.0, 21.0, 6.0, 294.0, 15.0, 300.0]  episode_count: 1285 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.187, -9.891, -9.284]
{"total_number_of_episodes": 1286, "number_of_timesteps": 25340, "per_episode_reward": 16.07, "episode_reward_trend_value": -0.003968253968253935, "biggest_recent_change": 0.14285714285714235},
Step 802 4 visits [100.0, 65.0, 21.0, 6.0, 295.0, 15.0, 300.0]  episode_count: 1286 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.186, -9.891, -9.284]
Step 803 4 visits [100.0, 65.0, 21.0, 6.0, 296.0, 15.0, 300.0]  episode_count: 1288 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.19, -9.891, -9.284]
Step 804 4 visits [100.0, 65.0, 21.0, 6.0, 297.0, 15.0, 300.0]  episode_count: 1289 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.197, -9.891, -9.284]
Step 805 4 visits [100.0, 65.0, 21.0, 6.0, 298.0, 15.0, 300.0]  episode_count: 1289 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.201, -9.891, -9.284]
Step 806 4 visits [100.0, 65.0, 21.0, 6.0, 299.0, 15.0, 300.0]  episode_count: 1292 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.208, -9.891, -9.284]
Step 807 4 visits [100.0, 65.0, 21.0, 6.0, 300.0, 15.0, 300.0]  episode_count: 1293 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.214, -9.891, -9.284]
{"total_number_of_episodes": 1296, "number_of_timesteps": 25570, "per_episode_reward": 16.21, "episode_reward_trend_value": -0.0023809523809523525, "biggest_recent_change": 0.14285714285714235},
Step 808 4 visits [100.0, 65.0, 21.0, 6.0, 301.0, 15.0, 300.0]  episode_count: 1296 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.22, -9.891, -9.284]
Step 809 4 visits [100.0, 65.0, 21.0, 6.0, 302.0, 15.0, 300.0]  episode_count: 1298 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.227, -9.891, -9.284]
Step 810 4 visits [100.0, 65.0, 21.0, 6.0, 303.0, 15.0, 300.0]  episode_count: 1298 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.196, -9.891, -9.284]
Step 811 4 visits [100.0, 65.0, 21.0, 6.0, 304.0, 15.0, 300.0]  episode_count: 1299 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.201, -9.891, -9.284]
Step 812 4 visits [100.0, 65.0, 21.0, 6.0, 305.0, 15.0, 300.0]  episode_count: 1302 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.207, -9.891, -9.284]
Step 813 4 visits [100.0, 65.0, 21.0, 6.0, 306.0, 15.0, 300.0]  episode_count: 1303 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.213, -9.891, -9.284]
Step 814 4 visits [100.0, 65.0, 21.0, 6.0, 307.0, 15.0, 300.0]  episode_count: 1305 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.212, -9.891, -9.284]
{"total_number_of_episodes": 1307, "number_of_timesteps": 25783, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 815 4 visits [100.0, 65.0, 21.0, 6.0, 308.0, 15.0, 300.0]  episode_count: 1307 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.218, -9.891, -9.284]
Step 816 4 visits [100.0, 65.0, 21.0, 6.0, 309.0, 15.0, 300.0]  episode_count: 1307 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.217, -9.891, -9.284]
Step 817 4 visits [100.0, 65.0, 21.0, 6.0, 310.0, 15.0, 300.0]  episode_count: 1310 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.223, -9.891, -9.284]
Step 818 4 visits [100.0, 65.0, 21.0, 6.0, 311.0, 15.0, 300.0]  episode_count: 1312 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.223, -9.891, -9.284]
Step 819 4 visits [100.0, 65.0, 21.0, 6.0, 312.0, 15.0, 300.0]  episode_count: 1312 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.229, -9.891, -9.284]
Step 820 4 visits [100.0, 65.0, 21.0, 6.0, 313.0, 15.0, 300.0]  episode_count: 1315 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.231, -9.891, -9.284]
{"total_number_of_episodes": 1317, "number_of_timesteps": 25966, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 821 4 visits [100.0, 65.0, 21.0, 6.0, 314.0, 15.0, 300.0]  episode_count: 1317 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.234, -9.891, -9.284]
Step 822 4 visits [100.0, 65.0, 21.0, 6.0, 315.0, 15.0, 300.0]  episode_count: 1318 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.24, -9.891, -9.284]
Step 823 4 visits [100.0, 65.0, 21.0, 6.0, 316.0, 15.0, 300.0]  episode_count: 1321 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.242, -9.891, -9.284]
Step 824 4 visits [100.0, 65.0, 21.0, 6.0, 317.0, 15.0, 300.0]  episode_count: 1322 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.246, -9.891, -9.284]
Step 825 4 visits [100.0, 65.0, 21.0, 6.0, 318.0, 15.0, 300.0]  episode_count: 1322 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.245, -9.891, -9.284]
Step 826 4 visits [100.0, 65.0, 21.0, 6.0, 319.0, 15.0, 300.0]  episode_count: 1325 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.251, -9.891, -9.284]
Step 827 4 visits [100.0, 65.0, 21.0, 6.0, 320.0, 15.0, 300.0]  episode_count: 1326 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.252, -9.891, -9.284]
{"total_number_of_episodes": 1328, "number_of_timesteps": 26189, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 828 4 visits [100.0, 65.0, 21.0, 6.0, 321.0, 15.0, 300.0]  episode_count: 1328 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.258, -9.891, -9.284]
Step 829 4 visits [100.0, 65.0, 21.0, 6.0, 322.0, 15.0, 300.0]  episode_count: 1331 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.263, -9.891, -9.284]
Step 830 4 visits [100.0, 65.0, 21.0, 6.0, 323.0, 15.0, 300.0]  episode_count: 1333 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.269, -9.891, -9.284]
Step 831 4 visits [100.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1334 q_vals: [-9.389, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1338, "number_of_timesteps": 26346, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 832 0 visits [101.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1338 q_vals: [-9.296, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 833 0 visits [102.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1340 q_vals: [-9.293, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 834 0 visits [103.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1342 q_vals: [-9.305, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 835 0 visits [104.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1343 q_vals: [-9.215, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 836 0 visits [105.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1345 q_vals: [-9.211, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1348, "number_of_timesteps": 26489, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.14285714285714235},
Step 837 0 visits [106.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1348 q_vals: [-9.124, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 838 0 visits [107.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1350 q_vals: [-9.126, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 839 0 visits [108.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1353 q_vals: [-9.144, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 840 0 visits [109.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1354 q_vals: [-9.141, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 841 0 visits [110.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1357 q_vals: [-9.148, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1358, "number_of_timesteps": 26632, "per_episode_reward": 16.07, "episode_reward_trend_value": -0.0007936507936507711, "biggest_recent_change": 0.14285714285714235},
Step 842 0 visits [111.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1358 q_vals: [-9.166, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 843 0 visits [112.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1362 q_vals: [-9.084, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 844 0 visits [113.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1363 q_vals: [-9.081, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 845 0 visits [114.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1364 q_vals: [-9.093, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1369, "number_of_timesteps": 26797, "per_episode_reward": 16.07, "episode_reward_trend_value": -0.0007936507936507711, "biggest_recent_change": 0.14285714285714235},
Step 846 0 visits [115.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1369 q_vals: [-9.11, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 847 0 visits [116.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1371 q_vals: [-9.128, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 848 0 visits [117.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1371 q_vals: [-9.145, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 849 0 visits [118.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1375 q_vals: [-9.067, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 850 0 visits [119.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1377 q_vals: [-9.081, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1380, "number_of_timesteps": 26930, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.14285714285714235},
Step 851 0 visits [120.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1380 q_vals: [-9.005, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 852 0 visits [121.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1381 q_vals: [-9.007, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 853 0 visits [122.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1383 q_vals: [-9.024, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 854 0 visits [123.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1386 q_vals: [-9.041, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 855 0 visits [124.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1389 q_vals: [-8.968, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1390, "number_of_timesteps": 27086, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.14285714285714235},
Step 856 0 visits [125.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1390 q_vals: [-8.969, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
[126.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1392 q_vals: [-8.977, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 858 0 visits [127.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1394 q_vals: [-8.992, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 859 0 visits [128.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1396 q_vals: [-8.991, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 860 0 visits [129.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1398 q_vals: [-9.0, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1400, "number_of_timesteps": 27241, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 861 0 visits [130.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1400 q_vals: [-8.93, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 862 0 visits [131.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1402 q_vals: [-8.94, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 863 0 visits [132.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1403 q_vals: [-8.944, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 864 0 visits [133.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1405 q_vals: [-8.876, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 865 0 visits [134.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1408 q_vals: [-8.875, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1410, "number_of_timesteps": 27412, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 866 0 visits [135.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1410 q_vals: [-8.891, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 867 0 visits [136.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1411 q_vals: [-8.889, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 868 0 visits [137.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1412 q_vals: [-8.891, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 869 0 visits [138.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1414 q_vals: [-8.892, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 870 0 visits [139.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1415 q_vals: [-8.908, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 871 0 visits [140.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1416 q_vals: [-8.924, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1420, "number_of_timesteps": 27573, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 872 0 visits [141.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1420 q_vals: [-8.94, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 873 0 visits [142.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1420 q_vals: [-8.955, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 874 0 visits [143.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1420 q_vals: [-8.96, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 875 0 visits [144.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1421 q_vals: [-8.961, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 876 0 visits [145.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1425 q_vals: [-8.976, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 877 0 visits [146.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1426 q_vals: [-8.99, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 878 0 visits [147.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1427 q_vals: [-9.005, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 879 0 visits [148.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1429 q_vals: [-9.003, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1431, "number_of_timesteps": 27821, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 880 0 visits [149.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1431 q_vals: [-9.007, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 881 0 visits [150.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1433 q_vals: [-9.01, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 882 0 visits [151.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1434 q_vals: [-9.007, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 883 0 visits [152.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1436 q_vals: [-9.021, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 884 0 visits [153.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1438 q_vals: [-9.034, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 885 0 visits [154.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1439 q_vals: [-9.047, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1443, "number_of_timesteps": 28026, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 886 0 visits [155.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1443 q_vals: [-9.044, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 887 0 visits [156.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1445 q_vals: [-9.043, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 888 0 visits [157.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1445 q_vals: [-9.056, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 889 0 visits [158.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1447 q_vals: [-9.069, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 890 0 visits [159.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1448 q_vals: [-9.067, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 891 0 visits [160.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1451 q_vals: [-9.08, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1453, "number_of_timesteps": 28215, "per_episode_reward": 15.93, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714235},
Step 892 0 visits [161.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1453 q_vals: [-9.092, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 893 0 visits [162.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1455 q_vals: [-9.105, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 894 0 visits [163.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1456 q_vals: [-9.049, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 895 0 visits [164.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1459 q_vals: [-9.051, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 896 0 visits [165.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1460 q_vals: [-8.996, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 897 0 visits [166.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1462 q_vals: [-9.009, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1465, "number_of_timesteps": 28402, "per_episode_reward": 15.93, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714235},
Step 898 0 visits [167.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1465 q_vals: [-9.007, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 899 0 visits [168.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1467 q_vals: [-9.003, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 900 0 visits [169.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1469 q_vals: [-9.016, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 901 0 visits [170.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1472 q_vals: [-9.017, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 902 0 visits [171.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1474 q_vals: [-9.029, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1475, "number_of_timesteps": 28536, "per_episode_reward": 15.86, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
Step 903 0 visits [172.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1475 q_vals: [-8.976, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 904 0 visits [173.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1478 q_vals: [-8.985, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 905 0 visits [174.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1481 q_vals: [-8.983, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 906 0 visits [175.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1483 q_vals: [-8.986, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 907 0 visits [176.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1483 q_vals: [-8.935, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1488, "number_of_timesteps": 28725, "per_episode_reward": 15.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 908 0 visits [177.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1488 q_vals: [-8.933, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 909 0 visits [178.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1490 q_vals: [-8.883, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 910 0 visits [179.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1490 q_vals: [-8.884, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 911 0 visits [180.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1493 q_vals: [-8.882, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 912 0 visits [181.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1496 q_vals: [-8.894, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 913 0 visits [182.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1497 q_vals: [-8.895, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1499, "number_of_timesteps": 28883, "per_episode_reward": 15.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 914 0 visits [183.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1499 q_vals: [-8.893, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 915 0 visits [184.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1502 q_vals: [-8.905, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 916 0 visits [185.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1505 q_vals: [-8.903, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 917 0 visits [186.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1505 q_vals: [-8.915, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 918 0 visits [187.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1508 q_vals: [-8.92, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1511, "number_of_timesteps": 29053, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
Step 919 0 visits [188.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1511 q_vals: [-8.931, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 920 0 visits [189.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1513 q_vals: [-8.928, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 921 0 visits [190.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1515 q_vals: [-8.923, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 922 0 visits [191.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1517 q_vals: [-8.925, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 923 0 visits [192.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1520 q_vals: [-8.936, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 924 0 visits [193.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1520 q_vals: [-8.948, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1523, "number_of_timesteps": 29235, "per_episode_reward": 15.79, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.14285714285714413},
Step 925 0 visits [194.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1523 q_vals: [-8.948, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 926 0 visits [195.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1523 q_vals: [-8.959, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 927 0 visits [196.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1526 q_vals: [-8.955, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 928 0 visits [197.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1528 q_vals: [-8.949, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 929 0 visits [198.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1528 q_vals: [-8.945, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 930 0 visits [199.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1531 q_vals: [-8.956, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 931 0 visits [200.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1532 q_vals: [-8.911, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1536, "number_of_timesteps": 29487, "per_episode_reward": 15.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714413},
Step 932 0 visits [201.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1536 q_vals: [-8.914, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 933 0 visits [202.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1537 q_vals: [-8.911, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 934 0 visits [203.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1538 q_vals: [-8.908, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 935 0 visits [204.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1540 q_vals: [-8.915, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 936 0 visits [205.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1542 q_vals: [-8.915, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 937 0 visits [206.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1542 q_vals: [-8.926, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 938 0 visits [207.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1545 q_vals: [-8.883, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1547, "number_of_timesteps": 29691, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
Step 939 0 visits [208.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1547 q_vals: [-8.88, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 940 0 visits [209.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1550 q_vals: [-8.879, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 941 0 visits [210.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1552 q_vals: [-8.837, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 942 0 visits [211.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1554 q_vals: [-8.837, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 943 0 visits [212.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1554 q_vals: [-8.804, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 944 0 visits [213.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1556 q_vals: [-8.814, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1560, "number_of_timesteps": 29885, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.14285714285714413},
Step 945 0 visits [214.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1560 q_vals: [-8.825, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 946 0 visits [215.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1560 q_vals: [-8.833, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 947 0 visits [216.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1563 q_vals: [-8.792, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 948 0 visits [217.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1565 q_vals: [-8.793, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 949 0 visits [218.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1567 q_vals: [-8.804, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1570, "number_of_timesteps": 30042, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.14285714285714413},
Step 950 0 visits [219.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1570 q_vals: [-8.803, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 951 0 visits [220.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1572 q_vals: [-8.807, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 952 0 visits [221.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1572 q_vals: [-8.806, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 953 0 visits [222.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1575 q_vals: [-8.766, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 954 0 visits [223.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1576 q_vals: [-8.763, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 955 0 visits [224.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1577 q_vals: [-8.762, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 956 0 visits [225.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1579 q_vals: [-8.768, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1582, "number_of_timesteps": 30238, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 957 0 visits [226.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1582 q_vals: [-8.778, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 958 0 visits [227.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1583 q_vals: [-8.74, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 959 0 visits [228.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1585 q_vals: [-8.74, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 960 0 visits [229.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1588 q_vals: [-8.739, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 961 0 visits [230.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1588 q_vals: [-8.744, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 962 0 visits [231.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1589 q_vals: [-8.754, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 963 0 visits [232.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1591 q_vals: [-8.764, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1592, "number_of_timesteps": 30446, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 964 0 visits [233.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1592 q_vals: [-8.774, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 965 0 visits [234.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1593 q_vals: [-8.77, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 966 0 visits [235.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1595 q_vals: [-8.768, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 967 0 visits [236.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1596 q_vals: [-8.731, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 968 0 visits [237.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1600 q_vals: [-8.729, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 969 0 visits [238.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1601 q_vals: [-8.726, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1604, "number_of_timesteps": 30653, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 970 0 visits [239.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1604 q_vals: [-8.69, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 971 0 visits [240.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1605 q_vals: [-8.7, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 972 0 visits [241.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1605 q_vals: [-8.698, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 973 0 visits [242.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1606 q_vals: [-8.695, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 974 0 visits [243.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1608 q_vals: [-8.705, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 975 0 visits [244.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1609 q_vals: [-8.669, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 976 0 visits [245.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1610 q_vals: [-8.638, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 977 0 visits [246.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1613 q_vals: [-8.648, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1614, "number_of_timesteps": 30907, "per_episode_reward": 15.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
Step 978 0 visits [247.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1614 q_vals: [-8.648, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 979 0 visits [248.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1615 q_vals: [-8.649, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 980 0 visits [249.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1618 q_vals: [-8.648, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 981 0 visits [250.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1618 q_vals: [-8.658, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 982 0 visits [251.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1620 q_vals: [-8.657, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 983 0 visits [252.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1621 q_vals: [-8.66, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 984 0 visits [253.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1621 q_vals: [-8.67, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1624, "number_of_timesteps": 31108, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714413},
Step 985 0 visits [254.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1624 q_vals: [-8.68, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 986 0 visits [255.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1627 q_vals: [-8.646, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 987 0 visits [256.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1629 q_vals: [-8.642, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 988 0 visits [257.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1630 q_vals: [-8.639, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 989 0 visits [258.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1633 q_vals: [-8.649, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 990 0 visits [259.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1633 q_vals: [-8.647, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1635, "number_of_timesteps": 31307, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
Step 991 0 visits [260.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1635 q_vals: [-8.65, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 992 0 visits [261.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1637 q_vals: [-8.617, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 993 0 visits [262.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1639 q_vals: [-8.623, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 994 0 visits [263.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1639 q_vals: [-8.633, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 995 0 visits [264.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1641 q_vals: [-8.637, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 996 0 visits [265.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1641 q_vals: [-8.644, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 997 0 visits [266.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1642 q_vals: [-8.647, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 998 0 visits [267.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1644 q_vals: [-8.615, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1646, "number_of_timesteps": 31544, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 999 0 visits [268.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1646 q_vals: [-8.606, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1000 0 visits [269.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1647 q_vals: [-8.614, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1001 0 visits [270.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1648 q_vals: [-8.611, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1002 0 visits [271.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1649 q_vals: [-8.61, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1003 0 visits [272.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1650 q_vals: [-8.578, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1004 0 visits [273.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1653 q_vals: [-8.575, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1005 0 visits [274.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1655 q_vals: [-8.576, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1656, "number_of_timesteps": 31802, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1006 0 visits [275.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1656 q_vals: [-8.545, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1007 0 visits [276.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1658 q_vals: [-8.546, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1008 0 visits [277.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1658 q_vals: [-8.515, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1009 0 visits [278.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1659 q_vals: [-8.484, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1010 0 visits [279.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1660 q_vals: [-8.483, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1011 0 visits [280.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1663 q_vals: [-8.492, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1012 0 visits [281.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1664 q_vals: [-8.494, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1013 0 visits [282.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1665 q_vals: [-8.464, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1667, "number_of_timesteps": 32020, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1014 0 visits [283.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1667 q_vals: [-8.469, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1015 0 visits [284.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1670 q_vals: [-8.466, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1016 0 visits [285.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1673 q_vals: [-8.464, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1017 0 visits [286.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1676 q_vals: [-8.467, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1677, "number_of_timesteps": 32196, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1018 0 visits [287.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1677 q_vals: [-8.464, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1019 0 visits [288.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1682 q_vals: [-8.462, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1020 0 visits [289.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1682 q_vals: [-8.433, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1021 0 visits [290.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1686 q_vals: [-8.442, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1689, "number_of_timesteps": 32339, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1022 0 visits [291.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1689 q_vals: [-8.413, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1023 0 visits [292.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1689 q_vals: [-8.408, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1024 0 visits [293.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1690 q_vals: [-8.379, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1025 0 visits [294.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1693 q_vals: [-8.382, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1026 0 visits [295.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1694 q_vals: [-8.391, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1699, "number_of_timesteps": 32483, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1027 0 visits [296.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1699 q_vals: [-8.394, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1028 0 visits [297.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1699 q_vals: [-8.391, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1029 0 visits [298.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1701 q_vals: [-8.389, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1030 0 visits [299.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1704 q_vals: [-8.39, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1031 0 visits [300.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1705 q_vals: [-8.396, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1032 0 visits [301.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1707 q_vals: [-8.397, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1033 0 visits [302.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1708 q_vals: [-8.369, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1709, "number_of_timesteps": 32620, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1034 0 visits [303.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1709 q_vals: [-8.378, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1035 0 visits [304.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1711 q_vals: [-8.377, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1036 0 visits [305.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1713 q_vals: [-8.386, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1037 0 visits [306.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1714 q_vals: [-8.394, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1038 0 visits [307.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1715 q_vals: [-8.403, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1039 0 visits [308.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1718 q_vals: [-8.4, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1720, "number_of_timesteps": 32894, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1040 0 visits [309.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1720 q_vals: [-8.397, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1041 0 visits [310.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1721 q_vals: [-8.406, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1042 0 visits [311.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1724 q_vals: [-8.403, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1043 0 visits [312.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1726 q_vals: [-8.412, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1044 0 visits [313.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1726 q_vals: [-8.41, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1045 0 visits [314.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1728 q_vals: [-8.418, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1046 0 visits [315.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1729 q_vals: [-8.416, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1730, "number_of_timesteps": 33064, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1047 0 visits [316.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1730 q_vals: [-8.419, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1048 0 visits [317.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1731 q_vals: [-8.416, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1049 0 visits [318.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1733 q_vals: [-8.425, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1050 0 visits [319.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1735 q_vals: [-8.422, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1051 0 visits [320.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1735 q_vals: [-8.431, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1052 0 visits [321.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1738 q_vals: [-8.428, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1741, "number_of_timesteps": 33323, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1053 0 visits [322.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1741 q_vals: [-8.425, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1054 0 visits [323.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1741 q_vals: [-8.422, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1055 0 visits [324.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1743 q_vals: [-8.419, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1056 0 visits [325.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1745 q_vals: [-8.427, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1057 0 visits [326.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1746 q_vals: [-8.436, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1058 0 visits [327.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1749 q_vals: [-8.434, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1059 0 visits [328.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1750 q_vals: [-8.442, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1751, "number_of_timesteps": 33503, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1060 0 visits [329.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1751 q_vals: [-8.44, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1061 0 visits [330.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1754 q_vals: [-8.437, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1062 0 visits [331.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1756 q_vals: [-8.435, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1063 0 visits [332.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1758 q_vals: [-8.441, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1761, "number_of_timesteps": 33662, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1064 0 visits [333.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1761 q_vals: [-8.442, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1065 0 visits [334.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1763 q_vals: [-8.439, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1066 0 visits [335.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1763 q_vals: [-8.447, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1067 0 visits [336.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1768 q_vals: [-8.453, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1068 0 visits [337.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1770 q_vals: [-8.451, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1771, "number_of_timesteps": 33798, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1069 0 visits [338.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1771 q_vals: [-8.451, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1070 0 visits [339.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1775 q_vals: [-8.452, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1071 0 visits [340.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1778 q_vals: [-8.449, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1072 0 visits [341.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1780 q_vals: [-8.45, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1783, "number_of_timesteps": 33937, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1073 0 visits [342.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1783 q_vals: [-8.457, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1074 0 visits [343.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1785 q_vals: [-8.456, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1075 0 visits [344.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1787 q_vals: [-8.453, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1076 0 visits [345.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1789 q_vals: [-8.457, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1077 0 visits [346.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1791 q_vals: [-8.459, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1793, "number_of_timesteps": 34078, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1078 0 visits [347.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1793 q_vals: [-8.466, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1079 0 visits [348.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1795 q_vals: [-8.464, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1080 0 visits [349.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1799 q_vals: [-8.464, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1081 0 visits [350.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1800 q_vals: [-8.463, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1082 0 visits [351.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1802 q_vals: [-8.459, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1803, "number_of_timesteps": 34214, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1083 0 visits [352.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1803 q_vals: [-8.467, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1084 0 visits [353.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1805 q_vals: [-8.469, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1085 0 visits [354.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1808 q_vals: [-8.467, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1086 0 visits [355.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1810 q_vals: [-8.466, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1087 0 visits [356.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1812 q_vals: [-8.465, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1815, "number_of_timesteps": 34398, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1088 0 visits [357.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1815 q_vals: [-8.463, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1089 0 visits [358.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1817 q_vals: [-8.462, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1090 0 visits [359.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1821 q_vals: [-8.438, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1091 0 visits [360.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1821 q_vals: [-8.441, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1092 0 visits [361.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1824 q_vals: [-8.438, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1827, "number_of_timesteps": 34562, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1093 0 visits [362.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1827 q_vals: [-8.44, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1094 0 visits [363.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1830 q_vals: [-8.444, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1095 0 visits [364.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1831 q_vals: [-8.451, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1096 0 visits [365.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1833 q_vals: [-8.449, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1097 0 visits [366.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1835 q_vals: [-8.426, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1098 0 visits [367.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1836 q_vals: [-8.403, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1838, "number_of_timesteps": 34701, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1099 0 visits [368.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1838 q_vals: [-8.4, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1100 0 visits [369.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1840 q_vals: [-8.4, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1101 0 visits [370.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1842 q_vals: [-8.407, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1102 0 visits [371.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1843 q_vals: [-8.405, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1103 0 visits [372.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1846 q_vals: [-8.401, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1848, "number_of_timesteps": 34898, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1104 0 visits [373.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1848 q_vals: [-8.408, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1105 0 visits [374.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1850 q_vals: [-8.386, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1106 0 visits [375.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1851 q_vals: [-8.389, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1107 0 visits [376.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1853 q_vals: [-8.392, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
[377.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1857 q_vals: [-8.389, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1109 0 visits [378.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1857 q_vals: [-8.396, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1858, "number_of_timesteps": 35062, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1110 0 visits [379.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1858 q_vals: [-8.4, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1111 0 visits [380.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1861 q_vals: [-8.397, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1112 0 visits [381.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1862 q_vals: [-8.39, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1113 0 visits [382.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1862 q_vals: [-8.398, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1114 0 visits [383.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1866 q_vals: [-8.376, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1115 0 visits [384.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1867 q_vals: [-8.376, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1116 0 visits [385.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1867 q_vals: [-8.383, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1870, "number_of_timesteps": 35286, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1117 0 visits [386.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1870 q_vals: [-8.381, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1118 0 visits [387.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1873 q_vals: [-8.378, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1119 0 visits [388.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1873 q_vals: [-8.375, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1120 0 visits [389.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1873 q_vals: [-8.382, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1121 0 visits [390.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1876 q_vals: [-8.36, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1122 0 visits [391.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1878 q_vals: [-8.358, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1123 0 visits [392.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1878 q_vals: [-8.356, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1880, "number_of_timesteps": 35459, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1124 0 visits [393.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1880 q_vals: [-8.353, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1125 0 visits [394.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1883 q_vals: [-8.35, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1126 0 visits [395.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1883 q_vals: [-8.329, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1127 0 visits [396.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1884 q_vals: [-8.326, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1128 0 visits [397.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1887 q_vals: [-8.333, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1129 0 visits [398.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1889 q_vals: [-8.33, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1890, "number_of_timesteps": 35695, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1130 0 visits [399.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1890 q_vals: [-8.327, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1131 0 visits [400.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1890 q_vals: [-8.326, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1132 0 visits [401.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1892 q_vals: [-8.333, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1133 0 visits [402.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1895 q_vals: [-8.33, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1134 0 visits [403.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1895 q_vals: [-8.327, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1135 0 visits [404.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1897 q_vals: [-8.327, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1136 0 visits [405.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1897 q_vals: [-8.329, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1137 0 visits [406.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1898 q_vals: [-8.336, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1900, "number_of_timesteps": 35914, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1138 0 visits [407.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1900 q_vals: [-8.333, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1139 0 visits [408.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1902 q_vals: [-8.331, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1140 0 visits [409.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1904 q_vals: [-8.338, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1141 0 visits [410.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1906 q_vals: [-8.317, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1142 0 visits [411.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1907 q_vals: [-8.314, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1910, "number_of_timesteps": 36136, "per_episode_reward": 15.93, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1143 0 visits [412.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1910 q_vals: [-8.312, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1144 0 visits [413.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1913 q_vals: [-8.292, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
[414.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1914 q_vals: [-8.289, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1146 0 visits [415.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1915 q_vals: [-8.291, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1147 0 visits [416.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1917 q_vals: [-8.287, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1148 0 visits [417.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1917 q_vals: [-8.286, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1149 0 visits [418.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1919 q_vals: [-8.287, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1921, "number_of_timesteps": 36324, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1150 0 visits [419.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1921 q_vals: [-8.288, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1151 0 visits [420.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1922 q_vals: [-8.295, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1152 0 visits [421.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1922 q_vals: [-8.292, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1153 0 visits [422.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1925 q_vals: [-8.29, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1154 0 visits [423.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1925 q_vals: [-8.297, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1155 0 visits [424.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1925 q_vals: [-8.304, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1156 0 visits [425.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1929 q_vals: [-8.303, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1157 0 visits [426.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1930 q_vals: [-8.3, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1932, "number_of_timesteps": 36615, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1158 0 visits [427.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1932 q_vals: [-8.305, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1159 0 visits [428.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1933 q_vals: [-8.303, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1160 0 visits [429.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1934 q_vals: [-8.283, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1161 0 visits [430.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1935 q_vals: [-8.288, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1162 0 visits [431.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1936 q_vals: [-8.285, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1163 0 visits [432.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1939 q_vals: [-8.282, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1164 0 visits [433.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1940 q_vals: [-8.279, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1165 0 visits [434.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1940 q_vals: [-8.279, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1166 0 visits [435.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1940 q_vals: [-8.286, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1944, "number_of_timesteps": 36875, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1167 0 visits [436.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1944 q_vals: [-8.287, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1168 0 visits [437.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1944 q_vals: [-8.286, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1169 0 visits [438.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1946 q_vals: [-8.284, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1170 0 visits [439.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1948 q_vals: [-8.275, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1171 0 visits [440.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1950 q_vals: [-8.272, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1172 0 visits [441.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1951 q_vals: [-8.253, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1173 0 visits [442.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1953 q_vals: [-8.252, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1956, "number_of_timesteps": 37123, "per_episode_reward": 15.93, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1174 0 visits [443.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1956 q_vals: [-8.254, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1175 0 visits [444.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1958 q_vals: [-8.235, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1176 0 visits [445.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1959 q_vals: [-8.231, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1177 0 visits [446.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1962 q_vals: [-8.213, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1178 0 visits [447.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1963 q_vals: [-8.209, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1179 0 visits [448.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1964 q_vals: [-8.216, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1180 0 visits [449.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1964 q_vals: [-8.222, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1969, "number_of_timesteps": 37348, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1181 0 visits [450.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1969 q_vals: [-8.219, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1182 0 visits [451.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1971 q_vals: [-8.215, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1183 0 visits [452.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1971 q_vals: [-8.222, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1184 0 visits [453.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1973 q_vals: [-8.222, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1185 0 visits [454.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1977 q_vals: [-8.219, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1186 0 visits [455.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1977 q_vals: [-8.201, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1979, "number_of_timesteps": 37499, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1187 0 visits [456.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1979 q_vals: [-8.207, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1188 0 visits [457.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1983 q_vals: [-8.204, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1189 0 visits [458.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1985 q_vals: [-8.202, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1190 0 visits [459.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1986 q_vals: [-8.199, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1191 0 visits [460.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1988 q_vals: [-8.196, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 1991, "number_of_timesteps": 37684, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1192 0 visits [461.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1991 q_vals: [-8.192, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1193 0 visits [462.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1991 q_vals: [-8.199, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1194 0 visits [463.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1994 q_vals: [-8.195, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1195 0 visits [464.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1995 q_vals: [-8.193, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1196 0 visits [465.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 1996 q_vals: [-8.199, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1197 0 visits [466.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2000 q_vals: [-8.197, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2001, "number_of_timesteps": 37834, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1198 0 visits [467.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2001 q_vals: [-8.198, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1199 0 visits [468.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2001 q_vals: [-8.194, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1200 0 visits [469.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2005 q_vals: [-8.191, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1201 0 visits [470.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2007 q_vals: [-8.189, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1202 0 visits [471.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2008 q_vals: [-8.171, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2011, "number_of_timesteps": 38022, "per_episode_reward": 15.79, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1203 0 visits [472.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2011 q_vals: [-8.171, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1204 0 visits [473.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2012 q_vals: [-8.177, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1205 0 visits [474.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2015 q_vals: [-8.173, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1206 0 visits [475.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2017 q_vals: [-8.169, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1207 0 visits [476.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2018 q_vals: [-8.152, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1208 0 visits [477.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2020 q_vals: [-8.15, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2022, "number_of_timesteps": 38193, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714235},
Step 1209 0 visits [478.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2022 q_vals: [-8.146, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1210 0 visits [479.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2023 q_vals: [-8.152, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1211 0 visits [480.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2027 q_vals: [-8.148, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1212 0 visits [481.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2029 q_vals: [-8.155, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1213 0 visits [482.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2030 q_vals: [-8.151, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2033, "number_of_timesteps": 38354, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
Step 1214 0 visits [483.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2033 q_vals: [-8.134, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1215 0 visits [484.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2036 q_vals: [-8.133, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1216 0 visits [485.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2037 q_vals: [-8.13, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1217 0 visits [486.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2040 q_vals: [-8.136, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1218 0 visits [487.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2041 q_vals: [-8.132, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1219 0 visits [488.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2041 q_vals: [-8.138, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2046, "number_of_timesteps": 38548, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
Step 1220 0 visits [489.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2046 q_vals: [-8.136, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1221 0 visits [490.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2046 q_vals: [-8.12, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1222 0 visits [491.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2048 q_vals: [-8.117, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1223 0 visits [492.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2049 q_vals: [-8.113, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1224 0 visits [493.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2050 q_vals: [-8.119, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1225 0 visits [494.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2052 q_vals: [-8.118, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1226 0 visits [495.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2054 q_vals: [-8.116, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2058, "number_of_timesteps": 38782, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
Step 1227 0 visits [496.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2058 q_vals: [-8.115, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1228 0 visits [497.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2058 q_vals: [-8.112, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1229 0 visits [498.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2062 q_vals: [-8.108, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1230 0 visits [499.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2063 q_vals: [-8.105, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1231 0 visits [500.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2065 q_vals: [-8.108, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1232 0 visits [501.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2067 q_vals: [-8.104, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1233 0 visits [502.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2067 q_vals: [-8.102, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2070, "number_of_timesteps": 38961, "per_episode_reward": 15.79, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857295},
Step 1234 0 visits [503.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2070 q_vals: [-8.098, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1235 0 visits [504.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2073 q_vals: [-8.101, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1236 0 visits [505.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2074 q_vals: [-8.097, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1237 0 visits [506.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2075 q_vals: [-8.095, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1238 0 visits [507.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2075 q_vals: [-8.079, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1239 0 visits [508.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2078 q_vals: [-8.077, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2080, "number_of_timesteps": 39161, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1240 0 visits [509.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2080 q_vals: [-8.08, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1241 0 visits [510.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2083 q_vals: [-8.064, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1242 0 visits [511.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2084 q_vals: [-8.063, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1243 0 visits [512.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2085 q_vals: [-8.069, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1244 0 visits [513.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2087 q_vals: [-8.066, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2091, "number_of_timesteps": 39344, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
Step 1245 0 visits [514.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2091 q_vals: [-8.066, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1246 0 visits [515.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2092 q_vals: [-8.062, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1247 0 visits [516.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2093 q_vals: [-8.059, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1248 0 visits [517.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2094 q_vals: [-8.065, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1249 0 visits [518.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2099 q_vals: [-8.065, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1250 0 visits [519.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2099 q_vals: [-8.062, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2103, "number_of_timesteps": 39518, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
Step 1251 0 visits [520.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2103 q_vals: [-8.062, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1252 0 visits [521.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2104 q_vals: [-8.068, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1253 0 visits [522.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2107 q_vals: [-8.065, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1254 0 visits [523.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2109 q_vals: [-8.05, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1255 0 visits [524.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2111 q_vals: [-8.047, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2114, "number_of_timesteps": 39665, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714413},
Step 1256 0 visits [525.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2114 q_vals: [-8.05, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1257 0 visits [526.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2116 q_vals: [-8.049, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1258 0 visits [527.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2118 q_vals: [-8.055, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1259 0 visits [528.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2120 q_vals: [-8.04, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1260 0 visits [529.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2122 q_vals: [-8.038, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2124, "number_of_timesteps": 39817, "per_episode_reward": 15.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
Step 1261 0 visits [530.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2124 q_vals: [-8.037, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1262 0 visits [531.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2125 q_vals: [-8.038, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1263 0 visits [532.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2126 q_vals: [-8.044, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1264 0 visits [533.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2129 q_vals: [-8.043, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1265 0 visits [534.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2129 q_vals: [-8.028, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1266 0 visits [535.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2131 q_vals: [-8.027, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1267 0 visits [536.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2132 q_vals: [-8.024, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1268 0 visits [537.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2132 q_vals: [-8.028, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1269 0 visits [538.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2133 q_vals: [-8.013, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1270 0 visits [539.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2133 q_vals: [-8.019, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2134, "number_of_timesteps": 40025, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 1271 0 visits [540.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2134 q_vals: [-8.014, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1272 0 visits [541.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2136 q_vals: [-7.999, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1273 0 visits [542.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2136 q_vals: [-7.998, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1274 0 visits [543.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2139 q_vals: [-7.997, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1275 0 visits [544.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2140 q_vals: [-7.995, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1276 0 visits [545.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2142 q_vals: [-7.98, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1277 0 visits [546.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2142 q_vals: [-7.978, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1278 0 visits [547.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2142 q_vals: [-7.963, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1279 0 visits [548.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2143 q_vals: [-7.968, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2145, "number_of_timesteps": 40339, "per_episode_reward": 15.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
Step 1280 0 visits [549.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2145 q_vals: [-7.966, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1281 0 visits [550.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2146 q_vals: [-7.963, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1282 0 visits [551.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2146 q_vals: [-7.969, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1283 0 visits [552.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2149 q_vals: [-7.955, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1284 0 visits [553.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2151 q_vals: [-7.954, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1285 0 visits [554.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2152 q_vals: [-7.951, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1286 0 visits [555.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2153 q_vals: [-7.949, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2156, "number_of_timesteps": 40660, "per_episode_reward": 15.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
Step 1287 0 visits [556.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2156 q_vals: [-7.948, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1288 0 visits [557.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2158 q_vals: [-7.945, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1289 0 visits [558.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2159 q_vals: [-7.941, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1290 0 visits [559.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2162 q_vals: [-7.938, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1291 0 visits [560.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2164 q_vals: [-7.938, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2166, "number_of_timesteps": 40826, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714413},
Step 1292 0 visits [561.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2166 q_vals: [-7.935, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1293 0 visits [562.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2168 q_vals: [-7.936, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1294 0 visits [563.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2171 q_vals: [-7.934, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1295 0 visits [564.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2172 q_vals: [-7.93, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1296 0 visits [565.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2173 q_vals: [-7.926, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1297 0 visits [566.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2175 q_vals: [-7.912, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2177, "number_of_timesteps": 40994, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 1298 0 visits [567.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2177 q_vals: [-7.911, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1299 0 visits [568.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2179 q_vals: [-7.907, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1300 0 visits [569.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2179 q_vals: [-7.893, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1301 0 visits [570.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2181 q_vals: [-7.89, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1302 0 visits [571.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2183 q_vals: [-7.889, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1303 0 visits [572.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2185 q_vals: [-7.886, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1304 0 visits [573.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2186 q_vals: [-7.892, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2187, "number_of_timesteps": 41168, "per_episode_reward": 15.79, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1305 0 visits [574.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2187 q_vals: [-7.891, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1306 0 visits [575.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2189 q_vals: [-7.888, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1307 0 visits [576.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2189 q_vals: [-7.885, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1308 0 visits [577.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2190 q_vals: [-7.882, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1309 0 visits [578.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2193 q_vals: [-7.881, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1310 0 visits [579.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2194 q_vals: [-7.882, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1311 0 visits [580.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2194 q_vals: [-7.878, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1312 0 visits [581.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2195 q_vals: [-7.878, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2197, "number_of_timesteps": 41399, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1313 0 visits [582.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2197 q_vals: [-7.875, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1314 0 visits [583.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2197 q_vals: [-7.872, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1315 0 visits [584.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2199 q_vals: [-7.868, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1316 0 visits [585.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2201 q_vals: [-7.865, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1317 0 visits [586.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2202 q_vals: [-7.87, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1318 0 visits [587.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2205 q_vals: [-7.869, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1319 0 visits [588.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2206 q_vals: [-7.866, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2208, "number_of_timesteps": 41700, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1320 0 visits [589.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2208 q_vals: [-7.872, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1321 0 visits [590.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2209 q_vals: [-7.873, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1322 0 visits [591.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2211 q_vals: [-7.869, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1323 0 visits [592.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2211 q_vals: [-7.869, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1324 0 visits [593.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2211 q_vals: [-7.874, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1325 0 visits [594.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2215 q_vals: [-7.871, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2218, "number_of_timesteps": 41909, "per_episode_reward": 15.93, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1326 0 visits [595.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2218 q_vals: [-7.868, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1327 0 visits [596.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2218 q_vals: [-7.873, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1328 0 visits [597.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2218 q_vals: [-7.872, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1329 0 visits [598.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2221 q_vals: [-7.869, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1330 0 visits [599.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2223 q_vals: [-7.867, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1331 0 visits [600.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2225 q_vals: [-7.864, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1332 0 visits [601.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2225 q_vals: [-7.869, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2229, "number_of_timesteps": 42111, "per_episode_reward": 15.93, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1333 0 visits [602.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2229 q_vals: [-7.867, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1334 0 visits [603.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2230 q_vals: [-7.864, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1335 0 visits [604.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2230 q_vals: [-7.861, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1336 0 visits [605.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2232 q_vals: [-7.866, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1337 0 visits [606.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2235 q_vals: [-7.862, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1338 0 visits [607.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2236 q_vals: [-7.849, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1339 0 visits [608.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2236 q_vals: [-7.842, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1340 0 visits [609.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2237 q_vals: [-7.84, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2239, "number_of_timesteps": 42325, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
Step 1341 0 visits [610.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2239 q_vals: [-7.839, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1342 0 visits [611.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2241 q_vals: [-7.826, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1343 0 visits [612.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2242 q_vals: [-7.826, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1344 0 visits [613.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2243 q_vals: [-7.824, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1345 0 visits [614.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2245 q_vals: [-7.821, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1346 0 visits [615.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2246 q_vals: [-7.809, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1347 0 visits [616.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2248 q_vals: [-7.814, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2251, "number_of_timesteps": 42597, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
Step 1348 0 visits [617.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2251 q_vals: [-7.811, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1349 0 visits [618.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2252 q_vals: [-7.809, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1350 0 visits [619.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2253 q_vals: [-7.805, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1351 0 visits [620.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2253 q_vals: [-7.801, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1352 0 visits [621.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2259 q_vals: [-7.789, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1353 0 visits [622.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2260 q_vals: [-7.776, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2261, "number_of_timesteps": 42776, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1354 0 visits [623.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2261 q_vals: [-7.772, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1355 0 visits [624.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2263 q_vals: [-7.778, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1356 0 visits [625.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2264 q_vals: [-7.783, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1357 0 visits [626.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2266 q_vals: [-7.78, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1358 0 visits [627.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2269 q_vals: [-7.777, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1359 0 visits [628.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2269 q_vals: [-7.783, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2272, "number_of_timesteps": 42973, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1360 0 visits [629.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2272 q_vals: [-7.78, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1361 0 visits [630.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2274 q_vals: [-7.778, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1362 0 visits [631.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2275 q_vals: [-7.775, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1363 0 visits [632.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2276 q_vals: [-7.772, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1364 0 visits [633.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2278 q_vals: [-7.768, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1365 0 visits [634.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2279 q_vals: [-7.769, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1366 0 visits [635.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2279 q_vals: [-7.775, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2282, "number_of_timesteps": 43176, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
Step 1367 0 visits [636.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2282 q_vals: [-7.773, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1368 0 visits [637.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2283 q_vals: [-7.77, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1369 0 visits [638.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2285 q_vals: [-7.767, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1370 0 visits [639.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2286 q_vals: [-7.765, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1371 0 visits [640.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2288 q_vals: [-7.761, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1372 0 visits [641.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2291 q_vals: [-7.756, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2292, "number_of_timesteps": 43380, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1373 0 visits [642.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2292 q_vals: [-7.761, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1374 0 visits [643.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2294 q_vals: [-7.759, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1375 0 visits [644.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2294 q_vals: [-7.755, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1376 0 visits [645.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2296 q_vals: [-7.756, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1377 0 visits [646.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2298 q_vals: [-7.753, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1378 0 visits [647.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2298 q_vals: [-7.741, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1379 0 visits [648.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2300 q_vals: [-7.737, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2303, "number_of_timesteps": 43594, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1380 0 visits [649.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2303 q_vals: [-7.733, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1381 0 visits [650.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2305 q_vals: [-7.73, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1382 0 visits [651.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2307 q_vals: [-7.726, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1383 0 visits [652.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2308 q_vals: [-7.723, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2313, "number_of_timesteps": 43767, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1384 0 visits [653.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2313 q_vals: [-7.72, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1385 0 visits [654.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2314 q_vals: [-7.716, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1386 0 visits [655.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2316 q_vals: [-7.713, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1387 0 visits [656.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2319 q_vals: [-7.701, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1388 0 visits [657.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2320 q_vals: [-7.706, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2323, "number_of_timesteps": 43903, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1389 0 visits [658.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2323 q_vals: [-7.705, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1390 0 visits [659.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2323 q_vals: [-7.704, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1391 0 visits [660.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2329 q_vals: [-7.692, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1392 0 visits [661.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2330 q_vals: [-7.69, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1393 0 visits [662.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2331 q_vals: [-7.687, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2334, "number_of_timesteps": 44055, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1394 0 visits [663.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2334 q_vals: [-7.683, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1395 0 visits [664.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2336 q_vals: [-7.679, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1396 0 visits [665.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2337 q_vals: [-7.685, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1397 0 visits [666.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2341 q_vals: [-7.687, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1398 0 visits [667.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2343 q_vals: [-7.675, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2345, "number_of_timesteps": 44202, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
[668.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2345 q_vals: [-7.681, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1400 0 visits [669.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2348 q_vals: [-7.678, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1401 0 visits [670.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2350 q_vals: [-7.683, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1402 0 visits [671.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2353 q_vals: [-7.682, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2355, "number_of_timesteps": 44330, "per_episode_reward": 15.79, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.21428571428571352},
Step 1403 0 visits [672.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2355 q_vals: [-7.671, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1404 0 visits [673.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2358 q_vals: [-7.667, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1405 0 visits [674.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2360 q_vals: [-7.656, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1406 0 visits [675.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2361 q_vals: [-7.653, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2365, "number_of_timesteps": 44458, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.21428571428571352},
Step 1407 0 visits [676.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2365 q_vals: [-7.651, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1408 0 visits [677.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2366 q_vals: [-7.651, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1409 0 visits [678.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2368 q_vals: [-7.646, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1410 0 visits [679.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2369 q_vals: [-7.643, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1411 0 visits [680.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2371 q_vals: [-7.639, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1412 0 visits [681.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2373 q_vals: [-7.637, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2375, "number_of_timesteps": 44626, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.21428571428571352},
Step 1413 0 visits [682.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2375 q_vals: [-7.634, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1414 0 visits [683.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2376 q_vals: [-7.63, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1415 0 visits [684.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2376 q_vals: [-7.627, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1416 0 visits [685.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2377 q_vals: [-7.616, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1417 0 visits [686.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2378 q_vals: [-7.612, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1418 0 visits [687.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2379 q_vals: [-7.611, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1419 0 visits [688.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2381 q_vals: [-7.608, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1420 0 visits [689.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2382 q_vals: [-7.609, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1421 0 visits [690.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2382 q_vals: [-7.607, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1422 0 visits [691.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2383 q_vals: [-7.607, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1423 0 visits [692.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2383 q_vals: [-7.596, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2385, "number_of_timesteps": 44882, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.21428571428571352},
Step 1424 0 visits [693.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2385 q_vals: [-7.594, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1425 0 visits [694.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2386 q_vals: [-7.591, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1426 0 visits [695.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2387 q_vals: [-7.589, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1427 0 visits [696.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2389 q_vals: [-7.583, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1428 0 visits [697.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2390 q_vals: [-7.58, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1429 0 visits [698.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2393 q_vals: [-7.576, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1430 0 visits [699.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2393 q_vals: [-7.582, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1431 0 visits [700.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2394 q_vals: [-7.587, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2396, "number_of_timesteps": 45193, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.21428571428571352},
Step 1432 0 visits [701.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2396 q_vals: [-7.576, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1433 0 visits [702.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2399 q_vals: [-7.573, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1434 0 visits [703.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2399 q_vals: [-7.57, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
[-7.567, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1436 0 visits [705.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2403 q_vals: [-7.572, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2406, "number_of_timesteps": 45404, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.21428571428571352},
Step 1437 0 visits [706.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2406 q_vals: [-7.571, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1438 0 visits [707.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2406 q_vals: [-7.568, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1439 0 visits [708.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2407 q_vals: [-7.565, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1440 0 visits [709.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2411 q_vals: [-7.562, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1441 0 visits [710.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2412 q_vals: [-7.558, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1442 0 visits [711.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2413 q_vals: [-7.557, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1443 0 visits [712.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2415 q_vals: [-7.546, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2417, "number_of_timesteps": 45604, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.21428571428571352},
Step 1444 0 visits [713.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2417 q_vals: [-7.543, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1445 0 visits [714.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2419 q_vals: [-7.539, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1446 0 visits [715.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2420 q_vals: [-7.538, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1447 0 visits [716.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2423 q_vals: [-7.534, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1448 0 visits [717.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2425 q_vals: [-7.533, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2427, "number_of_timesteps": 45778, "per_episode_reward": 15.79, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.21428571428571352},
Step 1449 0 visits [718.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2427 q_vals: [-7.532, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1450 0 visits [719.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2428 q_vals: [-7.537, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1451 0 visits [720.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2431 q_vals: [-7.527, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1452 0 visits [721.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2433 q_vals: [-7.527, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1453 0 visits [722.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2434 q_vals: [-7.525, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1454 0 visits [723.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2436 q_vals: [-7.522, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2437, "number_of_timesteps": 45917, "per_episode_reward": 15.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.21428571428571352},
Step 1455 0 visits [724.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2437 q_vals: [-7.52, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1456 0 visits [725.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2438 q_vals: [-7.517, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1457 0 visits [726.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2440 q_vals: [-7.514, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1458 0 visits [727.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2442 q_vals: [-7.51, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1459 0 visits [728.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2444 q_vals: [-7.507, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2447, "number_of_timesteps": 46124, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857295},
Step 1460 0 visits [729.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2447 q_vals: [-7.503, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1461 0 visits [730.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2447 q_vals: [-7.502, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1462 0 visits [731.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2448 q_vals: [-7.499, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1463 0 visits [732.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2449 q_vals: [-7.489, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1464 0 visits [733.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2451 q_vals: [-7.488, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1465 0 visits [734.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2452 q_vals: [-7.485, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1466 0 visits [735.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2453 q_vals: [-7.49, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2457, "number_of_timesteps": 46340, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1467 0 visits [736.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2457 q_vals: [-7.486, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1468 0 visits [737.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2457 q_vals: [-7.484, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1469 0 visits [738.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2457 q_vals: [-7.483, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1470 0 visits [739.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2458 q_vals: [-7.479, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1471 0 visits [740.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2458 q_vals: [-7.476, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1472 0 visits [741.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2458 q_vals: [-7.473, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1473 0 visits [742.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2461 q_vals: [-7.47, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1474 0 visits [743.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2462 q_vals: [-7.467, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1475 0 visits [744.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2464 q_vals: [-7.463, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2467, "number_of_timesteps": 46596, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1476 0 visits [745.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2467 q_vals: [-7.461, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1477 0 visits [746.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2469 q_vals: [-7.46, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1478 0 visits [747.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2473 q_vals: [-7.457, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1479 0 visits [748.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2473 q_vals: [-7.454, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1480 0 visits [749.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2475 q_vals: [-7.45, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2477, "number_of_timesteps": 46764, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1481 0 visits [750.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2477 q_vals: [-7.447, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1482 0 visits [751.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2479 q_vals: [-7.443, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1483 0 visits [752.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2481 q_vals: [-7.44, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1484 0 visits [753.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2484 q_vals: [-7.43, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1485 0 visits [754.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2486 q_vals: [-7.435, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2488, "number_of_timesteps": 46927, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1486 0 visits [755.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2488 q_vals: [-7.434, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1487 0 visits [756.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2489 q_vals: [-7.424, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1488 0 visits [757.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2493 q_vals: [-7.422, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1489 0 visits [758.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2493 q_vals: [-7.427, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1490 0 visits [759.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2496 q_vals: [-7.425, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2500, "number_of_timesteps": 47095, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1491 0 visits [760.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2500 q_vals: [-7.421, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1492 0 visits [761.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2501 q_vals: [-7.419, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1493 0 visits [762.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2501 q_vals: [-7.416, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1494 0 visits [763.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2504 q_vals: [-7.421, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1495 0 visits [764.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2508 q_vals: [-7.417, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1496 0 visits [765.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2508 q_vals: [-7.408, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2510, "number_of_timesteps": 47243, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1497 0 visits [766.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2510 q_vals: [-7.412, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1498 0 visits [767.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2514 q_vals: [-7.403, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1499 0 visits [768.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2515 q_vals: [-7.401, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1500 0 visits [769.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2517 q_vals: [-7.391, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2520, "number_of_timesteps": 47371, "per_episode_reward": 15.79, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1501 0 visits [770.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2520 q_vals: [-7.388, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1502 0 visits [771.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2523 q_vals: [-7.385, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1503 0 visits [772.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2526 q_vals: [-7.383, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1504 0 visits [773.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2527 q_vals: [-7.376, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2530, "number_of_timesteps": 47506, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1505 0 visits [774.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2530 q_vals: [-7.381, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1506 0 visits [775.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2532 q_vals: [-7.378, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1507 0 visits [776.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2536 q_vals: [-7.375, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1508 0 visits [777.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2536 q_vals: [-7.38, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1509 0 visits [778.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2539 q_vals: [-7.378, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2541, "number_of_timesteps": 47658, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1510 0 visits [779.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2541 q_vals: [-7.369, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1511 0 visits [780.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2544 q_vals: [-7.365, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1512 0 visits [781.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2546 q_vals: [-7.356, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1513 0 visits [782.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2547 q_vals: [-7.361, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2551, "number_of_timesteps": 47793, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1514 0 visits [783.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2551 q_vals: [-7.359, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1515 0 visits [784.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2553 q_vals: [-7.356, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1516 0 visits [785.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2553 q_vals: [-7.354, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1517 0 visits [786.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2556 q_vals: [-7.351, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1518 0 visits [787.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2558 q_vals: [-7.35, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1519 0 visits [788.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2560 q_vals: [-7.347, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2562, "number_of_timesteps": 47937, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1520 0 visits [789.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2562 q_vals: [-7.343, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1521 0 visits [790.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2564 q_vals: [-7.341, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1522 0 visits [791.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2566 q_vals: [-7.34, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1523 0 visits [792.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2566 q_vals: [-7.338, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1524 0 visits [793.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2569 q_vals: [-7.335, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2572, "number_of_timesteps": 48130, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1525 0 visits [794.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2572 q_vals: [-7.332, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1526 0 visits [795.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2573 q_vals: [-7.328, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1527 0 visits [796.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2576 q_vals: [-7.333, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1528 0 visits [797.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2578 q_vals: [-7.33, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1529 0 visits [798.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2579 q_vals: [-7.327, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1530 0 visits [799.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2580 q_vals: [-7.325, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2582, "number_of_timesteps": 48281, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1531 0 visits [800.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2582 q_vals: [-7.316, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1532 0 visits [801.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2585 q_vals: [-7.316, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1533 0 visits [802.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2586 q_vals: [-7.313, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1534 0 visits [803.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2586 q_vals: [-7.313, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1535 0 visits [804.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2588 q_vals: [-7.311, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1536 0 visits [805.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2591 q_vals: [-7.316, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1537 0 visits [806.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2591 q_vals: [-7.316, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2592, "number_of_timesteps": 48463, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1538 0 visits [807.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2592 q_vals: [-7.321, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1539 0 visits [808.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2594 q_vals: [-7.32, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1540 0 visits [809.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2594 q_vals: [-7.324, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1541 0 visits [810.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2595 q_vals: [-7.329, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1542 0 visits [811.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2597 q_vals: [-7.328, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1543 0 visits [812.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2599 q_vals: [-7.324, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1544 0 visits [813.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2599 q_vals: [-7.321, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1545 0 visits [814.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2601 q_vals: [-7.319, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2602, "number_of_timesteps": 48751, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1546 0 visits [815.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2602 q_vals: [-7.318, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1547 0 visits [816.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2605 q_vals: [-7.315, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1548 0 visits [817.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2606 q_vals: [-7.312, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1549 0 visits [818.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2608 q_vals: [-7.307, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1550 0 visits [819.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2609 q_vals: [-7.306, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1551 0 visits [820.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2611 q_vals: [-7.305, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1552 0 visits [821.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2611 q_vals: [-7.302, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2614, "number_of_timesteps": 48985, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 1553 0 visits [822.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2614 q_vals: [-7.302, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1554 0 visits [823.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2615 q_vals: [-7.306, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1555 0 visits [824.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2618 q_vals: [-7.297, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1556 0 visits [825.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2618 q_vals: [-7.294, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1557 0 visits [826.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2618 q_vals: [-7.285, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1558 0 visits [827.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2621 q_vals: [-7.29, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2625, "number_of_timesteps": 49233, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1559 0 visits [828.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2625 q_vals: [-7.281, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1560 0 visits [829.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2625 q_vals: [-7.277, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1561 0 visits [830.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2627 q_vals: [-7.274, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1562 0 visits [831.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2630 q_vals: [-7.272, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1563 0 visits [832.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2631 q_vals: [-7.27, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1564 0 visits [833.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2634 q_vals: [-7.266, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2636, "number_of_timesteps": 49391, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1565 0 visits [834.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2636 q_vals: [-7.263, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1566 0 visits [835.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2637 q_vals: [-7.268, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1567 0 visits [836.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2641 q_vals: [-7.266, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1568 0 visits [837.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2642 q_vals: [-7.263, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1569 0 visits [838.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2642 q_vals: [-7.259, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1570 0 visits [839.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2644 q_vals: [-7.258, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2647, "number_of_timesteps": 49559, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1571 0 visits [840.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2647 q_vals: [-7.255, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1572 0 visits [841.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2649 q_vals: [-7.247, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1573 0 visits [842.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2650 q_vals: [-7.238, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1574 0 visits [843.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2654 q_vals: [-7.237, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1575 0 visits [844.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2655 q_vals: [-7.234, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1576 0 visits [845.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2656 q_vals: [-7.226, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2659, "number_of_timesteps": 49757, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1577 0 visits [846.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2659 q_vals: [-7.222, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1578 0 visits [847.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2660 q_vals: [-7.22, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1579 0 visits [848.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2662 q_vals: [-7.217, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1580 0 visits [849.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2662 q_vals: [-7.222, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1581 0 visits [850.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2662 q_vals: [-7.219, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1582 0 visits [851.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2665 q_vals: [-7.217, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1583 0 visits [852.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2665 q_vals: [-7.209, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1584 0 visits [853.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2665 q_vals: [-7.206, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1585 0 visits [854.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2668 q_vals: [-7.202, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2670, "number_of_timesteps": 50023, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1586 0 visits [855.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2670 q_vals: [-7.199, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1587 0 visits [856.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2670 q_vals: [-7.196, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1588 0 visits [857.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2670 q_vals: [-7.188, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1589 0 visits [858.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2673 q_vals: [-7.185, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1590 0 visits [859.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2674 q_vals: [-7.184, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1591 0 visits [860.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2675 q_vals: [-7.184, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1592 0 visits [861.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2675 q_vals: [-7.181, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1593 0 visits [862.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2676 q_vals: [-7.173, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1594 0 visits [863.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2679 q_vals: [-7.17, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2680, "number_of_timesteps": 50301, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1595 0 visits [864.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2680 q_vals: [-7.166, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1596 0 visits [865.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2680 q_vals: [-7.164, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1597 0 visits [866.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2682 q_vals: [-7.161, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1598 0 visits [867.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2683 q_vals: [-7.153, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1599 0 visits [868.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2685 q_vals: [-7.149, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1600 0 visits [869.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2688 q_vals: [-7.146, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1601 0 visits [870.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2689 q_vals: [-7.142, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2690, "number_of_timesteps": 50550, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1602 0 visits [871.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2690 q_vals: [-7.139, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1603 0 visits [872.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2692 q_vals: [-7.136, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1604 0 visits [873.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2696 q_vals: [-7.133, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1605 0 visits [874.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2696 q_vals: [-7.137, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1606 0 visits [875.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2699 q_vals: [-7.135, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2701, "number_of_timesteps": 50732, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1607 0 visits [876.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2701 q_vals: [-7.127, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1608 0 visits [877.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2702 q_vals: [-7.125, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1609 0 visits [878.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2705 q_vals: [-7.121, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1610 0 visits [879.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2707 q_vals: [-7.118, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1611 0 visits [880.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2708 q_vals: [-7.116, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1612 0 visits [881.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2710 q_vals: [-7.108, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2713, "number_of_timesteps": 50925, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1613 0 visits [882.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2713 q_vals: [-7.104, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1614 0 visits [883.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2715 q_vals: [-7.102, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1615 0 visits [884.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2717 q_vals: [-7.099, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1616 0 visits [885.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2720 q_vals: [-7.091, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1617 0 visits [886.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2721 q_vals: [-7.088, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1618 0 visits [887.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2722 q_vals: [-7.085, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2723, "number_of_timesteps": 51056, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1619 0 visits [888.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2723 q_vals: [-7.082, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1620 0 visits [889.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2727 q_vals: [-7.074, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1621 0 visits [890.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2728 q_vals: [-7.071, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1622 0 visits [891.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2731 q_vals: [-7.069, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2733, "number_of_timesteps": 51227, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1623 0 visits [892.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2733 q_vals: [-7.068, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1624 0 visits [893.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2736 q_vals: [-7.065, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1625 0 visits [894.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2738 q_vals: [-7.062, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1626 0 visits [895.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2739 q_vals: [-7.06, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1627 0 visits [896.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2741 q_vals: [-7.057, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2743, "number_of_timesteps": 51356, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1628 0 visits [897.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2743 q_vals: [-7.054, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1629 0 visits [898.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2745 q_vals: [-7.051, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1630 0 visits [899.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2748 q_vals: [-7.048, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1631 0 visits [900.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2750 q_vals: [-7.046, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1632 0 visits [901.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2751 q_vals: [-7.05, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2755, "number_of_timesteps": 51551, "per_episode_reward": 15.64, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1633 0 visits [902.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2755 q_vals: [-7.047, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1634 0 visits [903.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2757 q_vals: [-7.044, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1635 0 visits [904.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2757 q_vals: [-7.041, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1636 0 visits [905.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2761 q_vals: [-7.034, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1637 0 visits [906.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2762 q_vals: [-7.031, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1638 0 visits [907.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2764 q_vals: [-7.029, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2765, "number_of_timesteps": 51691, "per_episode_reward": 15.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1639 0 visits [908.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2765 q_vals: [-7.026, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1640 0 visits [909.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2766 q_vals: [-7.024, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1641 0 visits [910.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2767 q_vals: [-7.023, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1642 0 visits [911.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2769 q_vals: [-7.02, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1643 0 visits [912.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2769 q_vals: [-7.017, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1644 0 visits [913.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2770 q_vals: [-7.013, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1645 0 visits [914.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2771 q_vals: [-7.011, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1646 0 visits [915.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2774 q_vals: [-7.008, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1647 0 visits [916.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2774 q_vals: [-7.004, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2777, "number_of_timesteps": 52002, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1648 0 visits [917.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2777 q_vals: [-7.001, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1649 0 visits [918.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2778 q_vals: [-7.006, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1650 0 visits [919.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2779 q_vals: [-7.003, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1651 0 visits [920.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2781 q_vals: [-7.0, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1652 0 visits [921.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2782 q_vals: [-6.999, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1653 0 visits [922.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2783 q_vals: [-6.996, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2787, "number_of_timesteps": 52193, "per_episode_reward": 15.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1654 0 visits [923.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2787 q_vals: [-6.993, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1655 0 visits [924.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2788 q_vals: [-6.991, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1656 0 visits [925.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2789 q_vals: [-6.988, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1657 0 visits [926.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2791 q_vals: [-6.985, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1658 0 visits [927.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2795 q_vals: [-6.982, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1659 0 visits [928.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2796 q_vals: [-6.987, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1660 0 visits [929.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2796 q_vals: [-6.984, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2799, "number_of_timesteps": 52401, "per_episode_reward": 15.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1661 0 visits [930.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2799 q_vals: [-6.981, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1662 0 visits [931.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2800 q_vals: [-6.978, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1663 0 visits [932.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2801 q_vals: [-6.975, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1664 0 visits [933.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2803 q_vals: [-6.972, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1665 0 visits [934.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2804 q_vals: [-6.964, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1666 0 visits [935.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2807 q_vals: [-6.969, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1667 0 visits [936.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2808 q_vals: [-6.966, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2809, "number_of_timesteps": 52599, "per_episode_reward": 15.64, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1668 0 visits [937.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2809 q_vals: [-6.963, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1669 0 visits [938.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2814 q_vals: [-6.96, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1670 0 visits [939.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2815 q_vals: [-6.953, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1671 0 visits [940.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2816 q_vals: [-6.95, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2820, "number_of_timesteps": 52773, "per_episode_reward": 15.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1672 0 visits [941.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2820 q_vals: [-6.949, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1673 0 visits [942.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2821 q_vals: [-6.946, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1674 0 visits [943.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2825 q_vals: [-6.944, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1675 0 visits [944.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2826 q_vals: [-6.941, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1676 0 visits [945.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2827 q_vals: [-6.938, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1677 0 visits [946.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2827 q_vals: [-6.935, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2830, "number_of_timesteps": 52904, "per_episode_reward": 15.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1678 0 visits [947.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2830 q_vals: [-6.932, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1679 0 visits [948.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2831 q_vals: [-6.93, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1680 0 visits [949.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2834 q_vals: [-6.934, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1681 0 visits [950.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2837 q_vals: [-6.931, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1682 0 visits [951.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2838 q_vals: [-6.928, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2841, "number_of_timesteps": 53116, "per_episode_reward": 15.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1683 0 visits [952.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2841 q_vals: [-6.932, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1684 0 visits [953.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2841 q_vals: [-6.93, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1685 0 visits [954.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2843 q_vals: [-6.927, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
[955.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2844 q_vals: [-6.926, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1687 0 visits [956.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2846 q_vals: [-6.926, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1688 0 visits [957.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2846 q_vals: [-6.919, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1689 0 visits [958.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2847 q_vals: [-6.914, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1690 0 visits [959.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2848 q_vals: [-6.913, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1691 0 visits [960.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2848 q_vals: [-6.911, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2851, "number_of_timesteps": 53310, "per_episode_reward": 15.64, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1692 0 visits [961.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2851 q_vals: [-6.915, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1693 0 visits [962.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2855 q_vals: [-6.914, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1694 0 visits [963.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2856 q_vals: [-6.912, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1695 0 visits [964.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2856 q_vals: [-6.909, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1696 0 visits [965.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2858 q_vals: [-6.906, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2863, "number_of_timesteps": 53588, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1697 0 visits [966.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2863 q_vals: [-6.902, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1698 0 visits [967.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2864 q_vals: [-6.901, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1699 0 visits [968.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2865 q_vals: [-6.905, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1700 0 visits [969.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2869 q_vals: [-6.902, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1701 0 visits [970.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2870 q_vals: [-6.895, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1702 0 visits [971.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2871 q_vals: [-6.893, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2873, "number_of_timesteps": 53720, "per_episode_reward": 15.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1703 0 visits [972.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2873 q_vals: [-6.891, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1704 0 visits [973.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2876 q_vals: [-6.89, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1705 0 visits [974.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2878 q_vals: [-6.887, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1706 0 visits [975.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2879 q_vals: [-6.884, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1707 0 visits [976.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2882 q_vals: [-6.881, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2883, "number_of_timesteps": 53881, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1708 0 visits [977.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2883 q_vals: [-6.878, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1709 0 visits [978.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2885 q_vals: [-6.875, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1710 0 visits [979.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2889 q_vals: [-6.88, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1711 0 visits [980.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2889 q_vals: [-6.878, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1712 0 visits [981.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2891 q_vals: [-6.882, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1713 0 visits [982.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2892 q_vals: [-6.881, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2893, "number_of_timesteps": 54044, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1714 0 visits [983.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2893 q_vals: [-6.874, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1715 0 visits [984.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2896 q_vals: [-6.872, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1716 0 visits [985.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2896 q_vals: [-6.871, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1717 0 visits [986.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2899 q_vals: [-6.875, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1718 0 visits [987.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2901 q_vals: [-6.874, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2905, "number_of_timesteps": 54277, "per_episode_reward": 15.57, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1719 0 visits [988.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2905 q_vals: [-6.867, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1720 0 visits [989.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2906 q_vals: [-6.865, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1721 0 visits [990.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2906 q_vals: [-6.862, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1722 0 visits [991.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2909 q_vals: [-6.86, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1723 0 visits [992.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2910 q_vals: [-6.864, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1724 0 visits [993.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2914 q_vals: [-6.861, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1725 0 visits [994.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2914 q_vals: [-6.858, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
{"total_number_of_episodes": 2917, "number_of_timesteps": 54474, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1726 0 visits [995.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2917 q_vals: [-6.855, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1727 0 visits [996.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2917 q_vals: [-6.852, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1728 0 visits [997.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2917 q_vals: [-6.849, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1729 0 visits [998.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2919 q_vals: [-6.847, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1730 0 visits [999.0, 65.0, 21.0, 6.0, 324.0, 15.0, 300.0]  episode_count: 2920 q_vals: [-6.844, -9.468, -9.751, -10.289, -9.275, -9.891, -9.284]
Step 1731 0 visits [1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 2921 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1732 1 visits [1000.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 2923 q_vals: [-inf, -4.692, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1733 2 visits [1000.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 2924 q_vals: [-inf, -4.692, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1734 3 visits [1000.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 2925 q_vals: [-inf, -4.692, 0.0, -4.623, 0.0, 0.0, 0.0]
{"total_number_of_episodes": 2927, "number_of_timesteps": 54746, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.025396825396825383, "biggest_recent_change": 2.2857142857142847},
Step 1735 4 visits [1000.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 2927 q_vals: [-inf, -4.692, 0.0, -4.623, -6.312, 0.0, 0.0]
Step 1736 5 visits [1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 2928 q_vals: [-inf, -4.692, 0.0, -4.623, -6.312, 0.0, 0.0]
Step 1737 6 visits [1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 2930 q_vals: [-inf, -4.692, 0.0, -4.623, -6.312, 0.0, 0.0]
Step 1738 2 visits [1000.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 2930 q_vals: [-inf, -4.692, -6.4, -4.623, -6.312, 0.0, 0.0]
Step 1739 5 visits [1000.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0]  episode_count: 2934 q_vals: [-inf, -4.692, -6.4, -4.623, -6.312, 0.0, 0.0]
Step 1740 6 visits [1000.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0]  episode_count: 2936 q_vals: [-inf, -4.692, -6.4, -4.623, -6.312, 0.0, -2.506]
{"total_number_of_episodes": 2937, "number_of_timesteps": 54946, "per_episode_reward": 13.21, "episode_reward_trend_value": -0.026190476190476198, "biggest_recent_change": 2.2857142857142847},
Step 1741 5 visits [1000.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0]  episode_count: 2937 q_vals: [-inf, -4.692, -6.4, -4.623, -6.312, -1.408, -2.506]
Step 1742 5 visits [1000.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0]  episode_count: 2939 q_vals: [-inf, -4.692, -6.4, -4.623, -6.312, -2.162, -2.506]
Step 1743 5 visits [1000.0, 1.0, 2.0, 1.0, 1.0, 5.0, 2.0]  episode_count: 2941 q_vals: [-inf, -4.692, -6.4, -4.623, -6.312, -2.858, -2.506]
Step 1744 6 visits [1000.0, 1.0, 2.0, 1.0, 1.0, 5.0, 3.0]  episode_count: 2942 q_vals: [-inf, -4.692, -6.4, -4.623, -6.312, -2.858, -1.67]
Step 1745 6 visits [1000.0, 1.0, 2.0, 1.0, 1.0, 5.0, 4.0]  episode_count: 2943 q_vals: [-inf, -4.692, -6.4, -4.623, -6.312, -2.858, -2.243]
Step 1746 6 visits [1000.0, 1.0, 2.0, 1.0, 1.0, 5.0, 5.0]  episode_count: 2945 q_vals: [-inf, -4.692, -6.4, -4.623, -6.312, -2.858, -4.354]
{"total_number_of_episodes": 2948, "number_of_timesteps": 55155, "per_episode_reward": 13.21, "episode_reward_trend_value": -0.02698412698412699, "biggest_recent_change": 2.2857142857142847},
Step 1747 5 visits [1000.0, 1.0, 2.0, 1.0, 1.0, 6.0, 5.0]  episode_count: 2948 q_vals: [-inf, -4.692, -6.4, -4.623, -6.312, -3.259, -4.354]
Step 1748 5 visits [1000.0, 1.0, 2.0, 1.0, 1.0, 7.0, 5.0]  episode_count: 2948 q_vals: [-inf, -4.692, -6.4, -4.623, -6.312, -2.793, -4.354]
Step 1749 5 visits [1000.0, 1.0, 2.0, 1.0, 1.0, 8.0, 5.0]  episode_count: 2950 q_vals: [-inf, -4.692, -6.4, -4.623, -6.312, -3.038, -4.354]
Step 1750 5 visits [1000.0, 1.0, 2.0, 1.0, 1.0, 9.0, 5.0]  episode_count: 2951 q_vals: [-inf, -4.692, -6.4, -4.623, -6.312, -4.122, -4.354]
Step 1751 3 visits [1000.0, 1.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2951 q_vals: [-inf, -4.692, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1752 1 visits [1000.0, 2.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2955 q_vals: [-inf, -2.346, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1753 1 visits [1000.0, 3.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2956 q_vals: [-inf, -3.262, -6.4, -4.619, -6.312, -4.122, -4.354]
{"total_number_of_episodes": 2958, "number_of_timesteps": 55360, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.02698412698412699, "biggest_recent_change": 2.2857142857142847},
Step 1754 1 visits [1000.0, 4.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2958 q_vals: [-inf, -2.447, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1755 1 visits [1000.0, 5.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2958 q_vals: [-inf, -2.965, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1756 1 visits [1000.0, 6.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2961 q_vals: [-inf, -3.183, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1757 1 visits [1000.0, 7.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2961 q_vals: [-inf, -3.315, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1758 1 visits [1000.0, 8.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2962 q_vals: [-inf, -3.809, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1759 1 visits [1000.0, 9.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2964 q_vals: [-inf, -3.917, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1760 1 visits [1000.0, 10.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2966 q_vals: [-inf, -3.525, -6.4, -4.619, -6.312, -4.122, -4.354]
{"total_number_of_episodes": 2968, "number_of_timesteps": 55596, "per_episode_reward": 13.21, "episode_reward_trend_value": -0.026190476190476198, "biggest_recent_change": 2.2857142857142847},
Step 1761 1 visits [1000.0, 11.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2968 q_vals: [-inf, -3.652, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1762 1 visits [1000.0, 12.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2970 q_vals: [-inf, -3.733, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1763 1 visits [1000.0, 13.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2972 q_vals: [-inf, -3.446, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1764 1 visits [1000.0, 14.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2973 q_vals: [-inf, -3.49, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1765 1 visits [1000.0, 15.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2975 q_vals: [-inf, -3.533, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1766 1 visits [1000.0, 16.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2977 q_vals: [-inf, -3.312, -6.4, -4.619, -6.312, -4.122, -4.354]
{"total_number_of_episodes": 2980, "number_of_timesteps": 55798, "per_episode_reward": 13.21, "episode_reward_trend_value": -0.026190476190476198, "biggest_recent_change": 2.2857142857142847},
Step 1767 1 visits [1000.0, 17.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2980 q_vals: [-inf, -3.117, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1768 1 visits [1000.0, 18.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2981 q_vals: [-inf, -3.175, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1769 1 visits [1000.0, 19.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2984 q_vals: [-inf, -3.234, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1770 1 visits [1000.0, 20.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2987 q_vals: [-inf, -3.314, -6.4, -4.619, -6.312, -4.122, -4.354]
Step 1771 1 visits [1000.0, 21.0, 2.0, 2.0, 1.0, 9.0, 5.0]  episode_count: 2989 q_vals: [-inf, -3.766, -6.4, -4.619, -6.312, -4.122, -4.354]
{"total_number_of_episodes": 2993, "number_of_timesteps": 55955, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.02698412698412699, "biggest_recent_change": 2.2857142857142847},
Step 1772 3 visits [1000.0, 21.0, 2.0, 3.0, 1.0, 9.0, 5.0]  episode_count: 2993 q_vals: [-inf, -3.766, -6.4, -4.556, -6.312, -4.122, -4.354]
Step 1773 1 visits [1000.0, 22.0, 2.0, 3.0, 1.0, 9.0, 5.0]  episode_count: 2994 q_vals: [-inf, -3.826, -6.4, -4.556, -6.312, -4.122, -4.354]
Step 1774 1 visits [1000.0, 23.0, 2.0, 3.0, 1.0, 9.0, 5.0]  episode_count: 2995 q_vals: [-inf, -3.84, -6.4, -4.556, -6.312, -4.122, -4.354]
Step 1775 1 visits [1000.0, 24.0, 2.0, 3.0, 1.0, 9.0, 5.0]  episode_count: 3000 q_vals: [-inf, -3.68, -6.4, -4.556, -6.312, -4.122, -4.354]
Step 1776 1 visits [1000.0, 25.0, 2.0, 3.0, 1.0, 9.0, 5.0]  episode_count: 3001 q_vals: [-inf, -3.732, -6.4, -4.556, -6.312, -4.122, -4.354]
{"total_number_of_episodes": 3004, "number_of_timesteps": 56092, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.02698412698412699, "biggest_recent_change": 2.2857142857142847},
Step 1777 1 visits [1000.0, 26.0, 2.0, 3.0, 1.0, 9.0, 5.0]  episode_count: 3004 q_vals: [-inf, -3.589, -6.4, -4.556, -6.312, -4.122, -4.354]
Step 1778 1 visits [1000.0, 27.0, 2.0, 3.0, 1.0, 9.0, 5.0]  episode_count: 3006 q_vals: [-inf, -3.64, -6.4, -4.556, -6.312, -4.122, -4.354]
Step 1779 1 visits [1000.0, 28.0, 2.0, 3.0, 1.0, 9.0, 5.0]  episode_count: 3007 q_vals: [-inf, -3.665, -6.4, -4.556, -6.312, -4.122, -4.354]
Step 1780 1 visits [1000.0, 29.0, 2.0, 3.0, 1.0, 9.0, 5.0]  episode_count: 3010 q_vals: [-inf, -3.715, -6.4, -4.556, -6.312, -4.122, -4.354]
Step 1781 1 visits [1000.0, 30.0, 2.0, 3.0, 1.0, 9.0, 5.0]  episode_count: 3012 q_vals: [-inf, -3.791, -6.4, -4.556, -6.312, -4.122, -4.354]
{"total_number_of_episodes": 3014, "number_of_timesteps": 56237, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.02698412698412699, "biggest_recent_change": 2.2857142857142847},
Step 1782 3 visits [1000.0, 30.0, 2.0, 4.0, 1.0, 9.0, 5.0]  episode_count: 3014 q_vals: [-inf, -3.791, -6.4, -3.417, -6.312, -4.122, -4.354]
Step 1783 3 visits [1000.0, 30.0, 2.0, 5.0, 1.0, 9.0, 5.0]  episode_count: 3017 q_vals: [-inf, -3.791, -6.4, -5.293, -6.312, -4.122, -4.354]
Step 1784 1 visits [1000.0, 31.0, 2.0, 5.0, 1.0, 9.0, 5.0]  episode_count: 3020 q_vals: [-inf, -3.822, -6.4, -5.293, -6.312, -4.122, -4.354]
Step 1785 5 visits [1000.0, 31.0, 2.0, 5.0, 1.0, 10.0, 5.0]  episode_count: 3022 q_vals: [-inf, -3.822, -6.4, -5.293, -6.312, -4.127, -4.354]
{"total_number_of_episodes": 3024, "number_of_timesteps": 56358, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1786 6 visits [1000.0, 31.0, 2.0, 5.0, 1.0, 10.0, 6.0]  episode_count: 3024 q_vals: [-inf, -3.822, -6.4, -5.293, -6.312, -4.127, -4.449]
Step 1787 1 visits [1000.0, 32.0, 2.0, 5.0, 1.0, 10.0, 6.0]  episode_count: 3026 q_vals: [-inf, -3.86, -6.4, -5.293, -6.312, -4.127, -4.449]
Step 1788 5 visits [1000.0, 32.0, 2.0, 5.0, 1.0, 11.0, 6.0]  episode_count: 3029 q_vals: [-inf, -3.86, -6.4, -5.293, -6.312, -4.916, -4.449]
Step 1789 1 visits [1000.0, 33.0, 2.0, 5.0, 1.0, 11.0, 6.0]  episode_count: 3032 q_vals: [-inf, -3.891, -6.4, -5.293, -6.312, -4.916, -4.449]
{"total_number_of_episodes": 3035, "number_of_timesteps": 56497, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1790 1 visits [1000.0, 34.0, 2.0, 5.0, 1.0, 11.0, 6.0]  episode_count: 3035 q_vals: [-inf, -3.777, -6.4, -5.293, -6.312, -4.916, -4.449]
Step 1791 1 visits [1000.0, 35.0, 2.0, 5.0, 1.0, 11.0, 6.0]  episode_count: 3036 q_vals: [-inf, -3.79, -6.4, -5.293, -6.312, -4.916, -4.449]
Step 1792 1 visits [1000.0, 36.0, 2.0, 5.0, 1.0, 11.0, 6.0]  episode_count: 3038 q_vals: [-inf, -3.685, -6.4, -5.293, -6.312, -4.916, -4.449]
Step 1793 1 visits [1000.0, 37.0, 2.0, 5.0, 1.0, 11.0, 6.0]  episode_count: 3042 q_vals: [-inf, -3.931, -6.4, -5.293, -6.312, -4.916, -4.449]
Step 1794 1 visits [1000.0, 38.0, 2.0, 5.0, 1.0, 11.0, 6.0]  episode_count: 3042 q_vals: [-inf, -3.828, -6.4, -5.293, -6.312, -4.916, -4.449]
Step 1795 1 visits [1000.0, 39.0, 2.0, 5.0, 1.0, 11.0, 6.0]  episode_count: 3044 q_vals: [-inf, -3.859, -6.4, -5.293, -6.312, -4.916, -4.449]
{"total_number_of_episodes": 3045, "number_of_timesteps": 56637, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1796 1 visits [1000.0, 40.0, 2.0, 5.0, 1.0, 11.0, 6.0]  episode_count: 3045 q_vals: [-inf, -3.886, -6.4, -5.293, -6.312, -4.916, -4.449]
Step 1797 1 visits [1000.0, 41.0, 2.0, 5.0, 1.0, 11.0, 6.0]  episode_count: 3046 q_vals: [-inf, -3.899, -6.4, -5.293, -6.312, -4.916, -4.449]
Step 1798 1 visits [1000.0, 42.0, 2.0, 5.0, 1.0, 11.0, 6.0]  episode_count: 3049 q_vals: [-inf, -3.93, -6.4, -5.293, -6.312, -4.916, -4.449]
Step 1799 6 visits [1000.0, 42.0, 2.0, 5.0, 1.0, 11.0, 7.0]  episode_count: 3050 q_vals: [-inf, -3.93, -6.4, -5.293, -6.312, -4.916, -4.569]
Step 1800 1 visits [1000.0, 43.0, 2.0, 5.0, 1.0, 11.0, 7.0]  episode_count: 3053 q_vals: [-inf, -3.839, -6.4, -5.293, -6.312, -4.916, -4.569]
{"total_number_of_episodes": 3056, "number_of_timesteps": 56836, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1801 1 visits [1000.0, 44.0, 2.0, 5.0, 1.0, 11.0, 7.0]  episode_count: 3056 q_vals: [-inf, -3.906, -6.4, -5.293, -6.312, -4.916, -4.569]
Step 1802 1 visits [1000.0, 45.0, 2.0, 5.0, 1.0, 11.0, 7.0]  episode_count: 3056 q_vals: [-inf, -3.953, -6.4, -5.293, -6.312, -4.916, -4.569]
Step 1803 1 visits [1000.0, 46.0, 2.0, 5.0, 1.0, 11.0, 7.0]  episode_count: 3060 q_vals: [-inf, -3.974, -6.4, -5.293, -6.312, -4.916, -4.569]
Step 1804 1 visits [1000.0, 47.0, 2.0, 5.0, 1.0, 11.0, 7.0]  episode_count: 3061 q_vals: [-inf, -3.985, -6.4, -5.293, -6.312, -4.916, -4.569]
Step 1805 1 visits [1000.0, 48.0, 2.0, 5.0, 1.0, 11.0, 7.0]  episode_count: 3063 q_vals: [-inf, -4.02, -6.4, -5.293, -6.312, -4.916, -4.569]
{"total_number_of_episodes": 3066, "number_of_timesteps": 56985, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1806 1 visits [1000.0, 49.0, 2.0, 5.0, 1.0, 11.0, 7.0]  episode_count: 3066 q_vals: [-inf, -4.033, -6.4, -5.293, -6.312, -4.916, -4.569]
Step 1807 1 visits [1000.0, 50.0, 2.0, 5.0, 1.0, 11.0, 7.0]  episode_count: 3067 q_vals: [-inf, -4.037, -6.4, -5.293, -6.312, -4.916, -4.569]
Step 1808 1 visits [1000.0, 51.0, 2.0, 5.0, 1.0, 11.0, 7.0]  episode_count: 3068 q_vals: [-inf, -4.046, -6.4, -5.293, -6.312, -4.916, -4.569]
Step 1809 1 visits [1000.0, 52.0, 2.0, 5.0, 1.0, 11.0, 7.0]  episode_count: 3068 q_vals: [-inf, -4.092, -6.4, -5.293, -6.312, -4.916, -4.569]
Step 1810 6 visits [1000.0, 52.0, 2.0, 5.0, 1.0, 11.0, 8.0]  episode_count: 3071 q_vals: [-inf, -4.092, -6.4, -5.293, -6.312, -4.916, -3.998]
Step 1811 6 visits [1000.0, 52.0, 2.0, 5.0, 1.0, 11.0, 9.0]  episode_count: 3071 q_vals: [-inf, -4.092, -6.4, -5.293, -6.312, -4.916, -3.554]
Step 1812 6 visits [1000.0, 52.0, 2.0, 5.0, 1.0, 11.0, 10.0]  episode_count: 3073 q_vals: [-inf, -4.092, -6.4, -5.293, -6.312, -4.916, -3.651]
Step 1813 6 visits [1000.0, 52.0, 2.0, 5.0, 1.0, 11.0, 11.0]  episode_count: 3073 q_vals: [-inf, -4.092, -6.4, -5.293, -6.312, -4.916, -4.483]
{"total_number_of_episodes": 3077, "number_of_timesteps": 57222, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1814 1 visits [1000.0, 53.0, 2.0, 5.0, 1.0, 11.0, 11.0]  episode_count: 3077 q_vals: [-inf, -4.147, -6.4, -5.293, -6.312, -4.916, -4.483]
Step 1815 6 visits [1000.0, 53.0, 2.0, 5.0, 1.0, 11.0, 12.0]  episode_count: 3078 q_vals: [-inf, -4.147, -6.4, -5.293, -6.312, -4.916, -4.109]
Step 1816 6 visits [1000.0, 53.0, 2.0, 5.0, 1.0, 11.0, 13.0]  episode_count: 3078 q_vals: [-inf, -4.147, -6.4, -5.293, -6.312, -4.916, -4.153]
Step 1817 6 visits [1000.0, 53.0, 2.0, 5.0, 1.0, 11.0, 14.0]  episode_count: 3079 q_vals: [-inf, -4.147, -6.4, -5.293, -6.312, -4.916, -3.857]
Step 1818 6 visits [1000.0, 53.0, 2.0, 5.0, 1.0, 11.0, 15.0]  episode_count: 3081 q_vals: [-inf, -4.147, -6.4, -5.293, -6.312, -4.916, -3.6]
Step 1819 6 visits [1000.0, 53.0, 2.0, 5.0, 1.0, 11.0, 16.0]  episode_count: 3083 q_vals: [-inf, -4.147, -6.4, -5.293, -6.312, -4.916, -3.615]
Step 1820 6 visits [1000.0, 53.0, 2.0, 5.0, 1.0, 11.0, 17.0]  episode_count: 3083 q_vals: [-inf, -4.147, -6.4, -5.293, -6.312, -4.916, -3.705]
Step 1821 6 visits [1000.0, 53.0, 2.0, 5.0, 1.0, 11.0, 18.0]  episode_count: 3084 q_vals: [-inf, -4.147, -6.4, -5.293, -6.312, -4.916, -3.727]
Step 1822 6 visits [1000.0, 53.0, 2.0, 5.0, 1.0, 11.0, 19.0]  episode_count: 3085 q_vals: [-inf, -4.147, -6.4, -5.293, -6.312, -4.916, -3.766]
Step 1823 6 visits [1000.0, 53.0, 2.0, 5.0, 1.0, 11.0, 20.0]  episode_count: 3085 q_vals: [-inf, -4.147, -6.4, -5.293, -6.312, -4.916, -3.577]
Step 1824 6 visits [1000.0, 53.0, 2.0, 5.0, 1.0, 11.0, 21.0]  episode_count: 3086 q_vals: [-inf, -4.147, -6.4, -5.293, -6.312, -4.916, -4.017]
{"total_number_of_episodes": 3088, "number_of_timesteps": 57500, "per_episode_reward": 13.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1825 6 visits [1000.0, 53.0, 2.0, 5.0, 1.0, 11.0, 22.0]  episode_count: 3088 q_vals: [-inf, -4.147, -6.4, -5.293, -6.312, -4.916, -3.941]
Step 1826 6 visits [1000.0, 53.0, 2.0, 5.0, 1.0, 11.0, 23.0]  episode_count: 3089 q_vals: [-inf, -4.147, -6.4, -5.293, -6.312, -4.916, -4.326]
Step 1827 1 visits [1000.0, 54.0, 2.0, 5.0, 1.0, 11.0, 23.0]  episode_count: 3089 q_vals: [-inf, -4.307, -6.4, -5.293, -6.312, -4.916, -4.326]
Step 1828 6 visits [1000.0, 54.0, 2.0, 5.0, 1.0, 11.0, 24.0]  episode_count: 3093 q_vals: [-inf, -4.307, -6.4, -5.293, -6.312, -4.916, -4.395]
Step 1829 6 visits [1000.0, 54.0, 2.0, 5.0, 1.0, 11.0, 25.0]  episode_count: 3094 q_vals: [-inf, -4.307, -6.4, -5.293, -6.312, -4.916, -4.219]
Step 1830 6 visits [1000.0, 54.0, 2.0, 5.0, 1.0, 11.0, 26.0]  episode_count: 3095 q_vals: [-inf, -4.307, -6.4, -5.293, -6.312, -4.916, -4.217]
Step 1831 6 visits [1000.0, 54.0, 2.0, 5.0, 1.0, 11.0, 27.0]  episode_count: 3096 q_vals: [-inf, -4.307, -6.4, -5.293, -6.312, -4.916, -4.25]
{"total_number_of_episodes": 3098, "number_of_timesteps": 57740, "per_episode_reward": 13.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1832 6 visits [1000.0, 54.0, 2.0, 5.0, 1.0, 11.0, 28.0]  episode_count: 3098 q_vals: [-inf, -4.307, -6.4, -5.293, -6.312, -4.916, -4.25]
Step 1833 6 visits [1000.0, 54.0, 2.0, 5.0, 1.0, 11.0, 29.0]  episode_count: 3098 q_vals: [-inf, -4.307, -6.4, -5.293, -6.312, -4.916, -4.545]
Step 1834 1 visits [1000.0, 55.0, 2.0, 5.0, 1.0, 11.0, 29.0]  episode_count: 3103 q_vals: [-inf, -4.303, -6.4, -5.293, -6.312, -4.916, -4.545]
Step 1835 1 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 29.0]  episode_count: 3103 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.545]
Step 1836 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 30.0]  episode_count: 3105 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.394]
Step 1837 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 31.0]  episode_count: 3105 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.381]
{"total_number_of_episodes": 3108, "number_of_timesteps": 57983, "per_episode_reward": 13.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1838 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 32.0]  episode_count: 3108 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.244]
Step 1839 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 33.0]  episode_count: 3111 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.259]
Step 1840 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 34.0]  episode_count: 3111 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.134]
Step 1841 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 35.0]  episode_count: 3113 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.13]
Step 1842 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 36.0]  episode_count: 3114 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.186]
Step 1843 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 37.0]  episode_count: 3115 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.072]
{"total_number_of_episodes": 3118, "number_of_timesteps": 58153, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1844 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 38.0]  episode_count: 3118 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.072]
Step 1845 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 39.0]  episode_count: 3118 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.295]
Step 1846 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 40.0]  episode_count: 3119 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.286]
Step 1847 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 41.0]  episode_count: 3121 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.182]
Step 1848 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 42.0]  episode_count: 3123 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.125]
Step 1849 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 43.0]  episode_count: 3124 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.158]
Step 1850 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 44.0]  episode_count: 3126 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.355]
{"total_number_of_episodes": 3130, "number_of_timesteps": 58441, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1851 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 45.0]  episode_count: 3130 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.258]
Step 1852 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 46.0]  episode_count: 3132 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.248]
Step 1853 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 47.0]  episode_count: 3133 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.24]
Step 1854 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 48.0]  episode_count: 3135 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.152]
Step 1855 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 49.0]  episode_count: 3138 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.145]
Step 1856 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 50.0]  episode_count: 3138 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.156]
{"total_number_of_episodes": 3140, "number_of_timesteps": 58604, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1857 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 51.0]  episode_count: 3140 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.149]
Step 1858 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 52.0]  episode_count: 3142 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.316]
Step 1859 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 53.0]  episode_count: 3144 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.306]
Step 1860 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 54.0]  episode_count: 3145 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.297]
Step 1861 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 55.0]  episode_count: 3148 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.288]
{"total_number_of_episodes": 3151, "number_of_timesteps": 58761, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1862 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 56.0]  episode_count: 3151 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.297]
Step 1863 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 57.0]  episode_count: 3152 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.289]
Step 1864 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 58.0]  episode_count: 3157 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.312]
Step 1865 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 59.0]  episode_count: 3158 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.239]
Step 1866 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 60.0]  episode_count: 3159 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.231]
{"total_number_of_episodes": 3163, "number_of_timesteps": 58941, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1867 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 61.0]  episode_count: 3163 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.174]
Step 1868 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 62.0]  episode_count: 3165 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.107]
Step 1869 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 63.0]  episode_count: 3167 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.107]
Step 1870 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 64.0]  episode_count: 3169 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.104]
Step 1871 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 65.0]  episode_count: 3170 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.041]
{"total_number_of_episodes": 3176, "number_of_timesteps": 59122, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1872 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 66.0]  episode_count: 3176 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.052]
Step 1873 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 67.0]  episode_count: 3176 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.05]
Step 1874 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 68.0]  episode_count: 3176 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.063]
Step 1875 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 69.0]  episode_count: 3179 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.004]
Step 1876 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 70.0]  episode_count: 3183 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.001]
Step 1877 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 71.0]  episode_count: 3183 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.945]
Step 1878 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 72.0]  episode_count: 3185 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.945]
{"total_number_of_episodes": 3188, "number_of_timesteps": 59305, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
Step 1879 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 73.0]  episode_count: 3188 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.954]
Step 1880 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 74.0]  episode_count: 3190 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.962]
Step 1881 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 75.0]  episode_count: 3191 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.08]
Step 1882 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 76.0]  episode_count: 3194 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.077]
Step 1883 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 77.0]  episode_count: 3194 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.024]
Step 1884 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 78.0]  episode_count: 3195 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.022]
{"total_number_of_episodes": 3200, "number_of_timesteps": 59512, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
Step 1885 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 79.0]  episode_count: 3200 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.022]
Step 1886 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 80.0]  episode_count: 3200 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.019]
Step 1887 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 81.0]  episode_count: 3202 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.023]
Step 1888 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 82.0]  episode_count: 3205 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.022]
Step 1889 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 83.0]  episode_count: 3206 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.02]
Step 1890 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 84.0]  episode_count: 3209 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.028]
{"total_number_of_episodes": 3210, "number_of_timesteps": 59665, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
Step 1891 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 85.0]  episode_count: 3210 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.98]
Step 1892 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 86.0]  episode_count: 3212 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.083]
Step 1893 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 87.0]  episode_count: 3217 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.091]
Step 1894 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 88.0]  episode_count: 3218 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.09]
{"total_number_of_episodes": 3220, "number_of_timesteps": 59797, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1895 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 89.0]  episode_count: 3220 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.094]
Step 1896 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 90.0]  episode_count: 3222 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.049]
Step 1897 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 91.0]  episode_count: 3224 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.055]
Step 1898 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 92.0]  episode_count: 3228 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.073]
Step 1899 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 93.0]  episode_count: 3228 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.029]
{"total_number_of_episodes": 3230, "number_of_timesteps": 59927, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1900 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 94.0]  episode_count: 3230 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.041]
Step 1901 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 95.0]  episode_count: 3231 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.044]
Step 1902 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 96.0]  episode_count: 3233 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.002]
Step 1903 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 97.0]  episode_count: 3234 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.987]
Step 1904 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 98.0]  episode_count: 3234 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.946]
Step 1905 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 99.0]  episode_count: 3235 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.958]
Step 1906 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 100.0]  episode_count: 3236 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.971]
Step 1907 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 101.0]  episode_count: 3238 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.002]
Step 1908 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 102.0]  episode_count: 3239 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.963]
{"total_number_of_episodes": 3242, "number_of_timesteps": 60184, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1909 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 103.0]  episode_count: 3242 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.96]
Step 1910 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 104.0]  episode_count: 3242 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.978]
Step 1911 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 105.0]  episode_count: 3243 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.995]
Step 1912 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 106.0]  episode_count: 3243 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.993]
Step 1913 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 107.0]  episode_count: 3243 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.991]
Step 1914 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 108.0]  episode_count: 3245 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.981]
Step 1915 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 109.0]  episode_count: 3248 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.978]
Step 1916 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 110.0]  episode_count: 3249 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.942]
Step 1917 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 111.0]  episode_count: 3249 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.943]
{"total_number_of_episodes": 3253, "number_of_timesteps": 60544, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1918 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 112.0]  episode_count: 3253 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.908]
Step 1919 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 113.0]  episode_count: 3253 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.903]
Step 1920 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 114.0]  episode_count: 3255 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.884]
Step 1921 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 115.0]  episode_count: 3255 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.962]
Step 1922 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 116.0]  episode_count: 3257 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.965]
Step 1923 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 117.0]  episode_count: 3259 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.963]
Step 1924 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 118.0]  episode_count: 3260 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.964]
{"total_number_of_episodes": 3263, "number_of_timesteps": 60771, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1925 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 119.0]  episode_count: 3263 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.966]
Step 1926 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 120.0]  episode_count: 3266 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.97]
Step 1927 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 121.0]  episode_count: 3267 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.97]
Step 1928 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 122.0]  episode_count: 3269 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.995]
Step 1929 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 123.0]  episode_count: 3270 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -3.99]
Step 1930 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 124.0]  episode_count: 3270 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.061]
Step 1931 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 125.0]  episode_count: 3270 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.131]
{"total_number_of_episodes": 3273, "number_of_timesteps": 60929, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1932 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 126.0]  episode_count: 3273 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.129]
Step 1933 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 127.0]  episode_count: 3273 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.097]
Step 1934 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 128.0]  episode_count: 3276 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.101]
Step 1935 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 129.0]  episode_count: 3278 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.102]
Step 1936 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 130.0]  episode_count: 3279 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.071]
{"total_number_of_episodes": 3283, "number_of_timesteps": 61164, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1937 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 131.0]  episode_count: 3283 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.076]
Step 1938 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 132.0]  episode_count: 3286 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.075]
Step 1939 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 133.0]  episode_count: 3288 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.044]
Step 1940 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 134.0]  episode_count: 3291 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.042]
{"total_number_of_episodes": 3295, "number_of_timesteps": 61298, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1941 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 135.0]  episode_count: 3295 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.042]
Step 1942 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 136.0]  episode_count: 3297 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.05]
Step 1943 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 137.0]  episode_count: 3300 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.05]
Step 1944 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 138.0]  episode_count: 3303 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.052]
{"total_number_of_episodes": 3305, "number_of_timesteps": 61399, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1945 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 139.0]  episode_count: 3305 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.115]
Step 1946 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 140.0]  episode_count: 3310 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.114]
Step 1947 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 141.0]  episode_count: 3310 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.175]
{"total_number_of_episodes": 3315, "number_of_timesteps": 61513, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1948 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 142.0]  episode_count: 3315 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.174]
Step 1949 6 visits [1000.0, 56.0, 2.0, 5.0, 1.0, 11.0, 143.0]  episode_count: 3317 q_vals: [-inf, -4.455, -6.4, -5.293, -6.312, -4.916, -4.235]
Step 1950 4 visits [1000.0, 56.0, 2.0, 5.0, 2.0, 11.0, 143.0]  episode_count: 3320 q_vals: [-inf, -4.455, -6.4, -5.293, -5.192, -4.916, -4.235]
Step 1951 4 visits [1000.0, 56.0, 2.0, 5.0, 3.0, 11.0, 143.0]  episode_count: 3323 q_vals: [-inf, -4.455, -6.4, -5.293, -4.738, -4.916, -4.235]
{"total_number_of_episodes": 3326, "number_of_timesteps": 61633, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1952 4 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 143.0]  episode_count: 3326 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.235]
Step 1953 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 144.0]  episode_count: 3328 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.234]
Step 1954 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 145.0]  episode_count: 3331 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.205]
Step 1955 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 146.0]  episode_count: 3333 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.216]
Step 1956 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 147.0]  episode_count: 3335 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.216]
{"total_number_of_episodes": 3336, "number_of_timesteps": 61753, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1957 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 148.0]  episode_count: 3336 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.215]
Step 1958 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 149.0]  episode_count: 3341 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.187]
Step 1959 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 150.0]  episode_count: 3343 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.187]
Step 1960 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 151.0]  episode_count: 3344 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.189]
{"total_number_of_episodes": 3347, "number_of_timesteps": 61890, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1961 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 152.0]  episode_count: 3347 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.188]
Step 1962 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 153.0]  episode_count: 3349 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.192]
Step 1963 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 154.0]  episode_count: 3351 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.165]
Step 1964 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 155.0]  episode_count: 3354 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.138]
Step 1965 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 156.0]  episode_count: 3356 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.111]
{"total_number_of_episodes": 3357, "number_of_timesteps": 62029, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1966 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 157.0]  episode_count: 3357 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.085]
Step 1967 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 158.0]  episode_count: 3359 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.059]
Step 1968 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 159.0]  episode_count: 3361 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.034]
Step 1969 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 160.0]  episode_count: 3363 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.036]
Step 1970 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 161.0]  episode_count: 3364 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.037]
Step 1971 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 162.0]  episode_count: 3366 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.041]
{"total_number_of_episodes": 3368, "number_of_timesteps": 62177, "per_episode_reward": 12.93, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
Step 1972 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 163.0]  episode_count: 3368 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.016]
Step 1973 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 164.0]  episode_count: 3370 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.041]
Step 1974 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 165.0]  episode_count: 3372 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.017]
Step 1975 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 166.0]  episode_count: 3374 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.017]
Step 1976 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 167.0]  episode_count: 3375 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -3.993]
Step 1977 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 168.0]  episode_count: 3377 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -3.995]
{"total_number_of_episodes": 3378, "number_of_timesteps": 62389, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
Step 1978 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 169.0]  episode_count: 3378 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -3.997]
Step 1979 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 170.0]  episode_count: 3381 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -3.973]
Step 1980 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 171.0]  episode_count: 3381 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -3.975]
Step 1981 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 172.0]  episode_count: 3382 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -3.952]
Step 1982 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 173.0]  episode_count: 3385 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -3.954]
Step 1983 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 174.0]  episode_count: 3387 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -3.967]
Step 1984 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 175.0]  episode_count: 3387 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.017]
{"total_number_of_episodes": 3393, "number_of_timesteps": 62678, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
Step 1985 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 176.0]  episode_count: 3393 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.067]
Step 1986 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 177.0]  episode_count: 3394 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.067]
Step 1987 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 178.0]  episode_count: 3394 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.106]
Step 1988 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 179.0]  episode_count: 3397 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.106]
Step 1989 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 180.0]  episode_count: 3398 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.106]
Step 1990 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 181.0]  episode_count: 3401 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.084]
{"total_number_of_episodes": 3405, "number_of_timesteps": 62867, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1991 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 182.0]  episode_count: 3405 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.083]
Step 1992 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 183.0]  episode_count: 3405 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.061]
Step 1993 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 184.0]  episode_count: 3408 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.039]
Step 1994 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 185.0]  episode_count: 3410 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.086]
Step 1995 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 186.0]  episode_count: 3413 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.086]
Step 1996 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 187.0]  episode_count: 3414 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.085]
{"total_number_of_episodes": 3417, "number_of_timesteps": 63032, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1997 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 188.0]  episode_count: 3417 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.132]
Step 1998 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 189.0]  episode_count: 3420 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.135]
Step 1999 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 190.0]  episode_count: 3422 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.113]
Step 2000 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 191.0]  episode_count: 3424 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.091]
Step 2001 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 192.0]  episode_count: 3426 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.137]
{"total_number_of_episodes": 3431, "number_of_timesteps": 63207, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2002 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 193.0]  episode_count: 3431 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.138]
Step 2003 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 194.0]  episode_count: 3431 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.153]
Step 2004 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 195.0]  episode_count: 3432 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.152]
Step 2005 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 196.0]  episode_count: 3435 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.153]
Step 2006 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 197.0]  episode_count: 3437 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.155]
Step 2007 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 198.0]  episode_count: 3438 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.134]
Step 2008 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 199.0]  episode_count: 3440 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.137]
{"total_number_of_episodes": 3441, "number_of_timesteps": 63367, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2009 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 200.0]  episode_count: 3441 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.137]
Step 2010 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 201.0]  episode_count: 3442 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.116]
Step 2011 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 202.0]  episode_count: 3445 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.115]
Step 2012 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 203.0]  episode_count: 3447 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.119]
Step 2013 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 204.0]  episode_count: 3449 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.13]
Step 2014 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 205.0]  episode_count: 3449 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.172]
Step 2015 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 206.0]  episode_count: 3450 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.214]
{"total_number_of_episodes": 3451, "number_of_timesteps": 63544, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2016 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 207.0]  episode_count: 3451 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.221]
Step 2017 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 208.0]  episode_count: 3453 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.222]
Step 2018 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 209.0]  episode_count: 3453 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.263]
 episode_count: 3453 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.243]
Step 2020 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 211.0]  episode_count: 3456 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.241]
Step 2021 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 212.0]  episode_count: 3458 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.24]
Step 2022 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 213.0]  episode_count: 3460 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.247]
Step 2023 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 214.0]  episode_count: 3460 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.227]
{"total_number_of_episodes": 3462, "number_of_timesteps": 63845, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2024 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 215.0]  episode_count: 3462 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.233]
Step 2025 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 216.0]  episode_count: 3463 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.272]
Step 2026 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 217.0]  episode_count: 3466 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.273]
Step 2027 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 218.0]  episode_count: 3466 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.253]
Step 2028 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 219.0]  episode_count: 3469 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.254]
Step 2029 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 220.0]  episode_count: 3471 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.251]
{"total_number_of_episodes": 3472, "number_of_timesteps": 64040, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2030 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 221.0]  episode_count: 3472 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.249]
Step 2031 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 222.0]  episode_count: 3474 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.23]
Step 2032 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 223.0]  episode_count: 3476 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.211]
Step 2033 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 224.0]  episode_count: 3476 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.21]
Step 2034 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 225.0]  episode_count: 3479 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.213]
Step 2035 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 226.0]  episode_count: 3480 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.213]
{"total_number_of_episodes": 3482, "number_of_timesteps": 64226, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2036 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 227.0]  episode_count: 3482 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.194]
Step 2037 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 228.0]  episode_count: 3483 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.2]
Step 2038 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 229.0]  episode_count: 3485 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.182]
Step 2039 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 230.0]  episode_count: 3487 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.188]
Step 2040 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 231.0]  episode_count: 3488 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.189]
Step 2041 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 232.0]  episode_count: 3491 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.187]
{"total_number_of_episodes": 3493, "number_of_timesteps": 64424, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2042 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 233.0]  episode_count: 3493 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.187]
Step 2043 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 234.0]  episode_count: 3494 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.169]
Step 2044 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 235.0]  episode_count: 3497 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.151]
Step 2045 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 236.0]  episode_count: 3499 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.154]
Step 2046 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 237.0]  episode_count: 3500 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.136]
{"total_number_of_episodes": 3504, "number_of_timesteps": 64595, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2047 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 238.0]  episode_count: 3504 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.138]
Step 2048 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 239.0]  episode_count: 3505 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.138]
Step 2049 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 240.0]  episode_count: 3507 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.138]
Step 2050 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 241.0]  episode_count: 3508 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.137]
Step 2051 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 242.0]  episode_count: 3510 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.137]
Step 2052 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 243.0]  episode_count: 3512 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.136]
{"total_number_of_episodes": 3515, "number_of_timesteps": 64781, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2053 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 244.0]  episode_count: 3515 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.136]
Step 2054 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 245.0]  episode_count: 3516 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.119]
Step 2055 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 246.0]  episode_count: 3517 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.123]
Step 2056 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 247.0]  episode_count: 3519 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.13]
Step 2057 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 248.0]  episode_count: 3522 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.165]
Step 2058 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 249.0]  episode_count: 3523 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.164]
{"total_number_of_episodes": 3525, "number_of_timesteps": 64922, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2059 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 250.0]  episode_count: 3525 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.163]
Step 2060 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 251.0]  episode_count: 3527 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.147]
Step 2061 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 252.0]  episode_count: 3528 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.147]
Step 2062 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 253.0]  episode_count: 3530 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.147]
Step 2063 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 254.0]  episode_count: 3532 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.149]
Step 2064 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 255.0]  episode_count: 3534 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.159]
{"total_number_of_episodes": 3535, "number_of_timesteps": 65123, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2065 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 256.0]  episode_count: 3535 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.158]
Step 2066 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 257.0]  episode_count: 3537 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.163]
Step 2067 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 258.0]  episode_count: 3539 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.147]
Step 2068 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 259.0]  episode_count: 3542 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.147]
Step 2069 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 260.0]  episode_count: 3543 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.146]
{"total_number_of_episodes": 3546, "number_of_timesteps": 65309, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2070 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 261.0]  episode_count: 3546 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.147]
Step 2071 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 262.0]  episode_count: 3548 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.146]
Step 2072 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 263.0]  episode_count: 3548 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.145]
Step 2073 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 264.0]  episode_count: 3551 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.144]
Step 2074 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 265.0]  episode_count: 3552 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.145]
Step 2075 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 266.0]  episode_count: 3554 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.145]
{"total_number_of_episodes": 3557, "number_of_timesteps": 65500, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2076 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 267.0]  episode_count: 3557 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.145]
Step 2077 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 268.0]  episode_count: 3559 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.13]
Step 2078 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 269.0]  episode_count: 3562 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.133]
Step 2079 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 270.0]  episode_count: 3563 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.138]
Step 2080 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 271.0]  episode_count: 3564 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.142]
Step 2081 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 272.0]  episode_count: 3565 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.142]
{"total_number_of_episodes": 3568, "number_of_timesteps": 65649, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2082 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 273.0]  episode_count: 3568 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.145]
Step 2083 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 274.0]  episode_count: 3570 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.144]
Step 2084 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 275.0]  episode_count: 3571 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.144]
Step 2085 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 276.0]  episode_count: 3573 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.143]
Step 2086 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 277.0]  episode_count: 3575 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.141]
Step 2087 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 278.0]  episode_count: 3576 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.141]
{"total_number_of_episodes": 3578, "number_of_timesteps": 65858, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2088 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 279.0]  episode_count: 3578 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.172]
Step 2089 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 280.0]  episode_count: 3579 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.171]
Step 2090 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 281.0]  episode_count: 3579 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.169]
Step 2091 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 282.0]  episode_count: 3583 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.177]
Step 2092 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 283.0]  episode_count: 3584 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.162]
Step 2093 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 284.0]  episode_count: 3585 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.192]
Step 2094 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 285.0]  episode_count: 3585 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.223]
{"total_number_of_episodes": 3588, "number_of_timesteps": 66072, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2095 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 286.0]  episode_count: 3588 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.222]
Step 2096 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 287.0]  episode_count: 3588 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.228]
Step 2097 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 288.0]  episode_count: 3591 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.258]
Step 2098 6 visits [1000.0, 56.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3591 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2099 1 visits [1000.0, 57.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3595 q_vals: [-inf, -4.444, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2100 1 visits [1000.0, 58.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3596 q_vals: [-inf, -4.455, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2101 1 visits [1000.0, 59.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3596 q_vals: [-inf, -4.446, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3599, "number_of_timesteps": 66306, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2102 1 visits [1000.0, 60.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3599 q_vals: [-inf, -4.44, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2103 1 visits [1000.0, 61.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3601 q_vals: [-inf, -4.367, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2104 1 visits [1000.0, 62.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3602 q_vals: [-inf, -4.373, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2105 1 visits [1000.0, 63.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3605 q_vals: [-inf, -4.367, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2106 1 visits [1000.0, 64.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3607 q_vals: [-inf, -4.299, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2107 1 visits [1000.0, 65.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3608 q_vals: [-inf, -4.308, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3609, "number_of_timesteps": 66480, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2108 1 visits [1000.0, 66.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3609 q_vals: [-inf, -4.301, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2109 1 visits [1000.0, 67.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3611 q_vals: [-inf, -4.237, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2110 1 visits [1000.0, 68.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3612 q_vals: [-inf, -4.226, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2111 1 visits [1000.0, 69.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3612 q_vals: [-inf, -4.165, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2112 1 visits [1000.0, 70.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3613 q_vals: [-inf, -4.173, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2113 1 visits [1000.0, 71.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3614 q_vals: [-inf, -4.294, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2114 1 visits [1000.0, 72.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3616 q_vals: [-inf, -4.32, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2115 1 visits [1000.0, 73.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3617 q_vals: [-inf, -4.261, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2116 1 visits [1000.0, 74.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3618 q_vals: [-inf, -4.204, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3620, "number_of_timesteps": 66716, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2117 1 visits [1000.0, 75.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3620 q_vals: [-inf, -4.22, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2118 1 visits [1000.0, 76.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3621 q_vals: [-inf, -4.217, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2119 1 visits [1000.0, 77.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3622 q_vals: [-inf, -4.222, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2120 1 visits [1000.0, 78.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3625 q_vals: [-inf, -4.221, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2121 1 visits [1000.0, 79.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3627 q_vals: [-inf, -4.219, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2122 1 visits [1000.0, 80.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3627 q_vals: [-inf, -4.167, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2123 1 visits [1000.0, 81.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3627 q_vals: [-inf, -4.183, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2124 1 visits [1000.0, 82.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3629 q_vals: [-inf, -4.141, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3632, "number_of_timesteps": 67042, "per_episode_reward": 12.93, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2125 1 visits [1000.0, 83.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3632 q_vals: [-inf, -4.138, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2126 1 visits [1000.0, 84.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3632 q_vals: [-inf, -4.14, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2127 1 visits [1000.0, 85.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3634 q_vals: [-inf, -4.136, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2128 1 visits [1000.0, 86.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3635 q_vals: [-inf, -4.148, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2129 1 visits [1000.0, 87.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3635 q_vals: [-inf, -4.158, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2130 1 visits [1000.0, 88.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3637 q_vals: [-inf, -4.152, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2131 1 visits [1000.0, 89.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3638 q_vals: [-inf, -4.106, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2132 1 visits [1000.0, 90.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3640 q_vals: [-inf, -4.06, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2133 1 visits [1000.0, 91.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3641 q_vals: [-inf, -4.077, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3642, "number_of_timesteps": 67281, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2134 1 visits [1000.0, 92.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3642 q_vals: [-inf, -4.033, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2135 1 visits [1000.0, 93.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3644 q_vals: [-inf, -4.04, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2136 1 visits [1000.0, 94.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3646 q_vals: [-inf, -4.056, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2137 1 visits [1000.0, 95.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3648 q_vals: [-inf, -4.052, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2138 1 visits [1000.0, 96.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3649 q_vals: [-inf, -4.044, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2139 1 visits [1000.0, 97.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3650 q_vals: [-inf, -4.04, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3653, "number_of_timesteps": 67521, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
Step 2140 1 visits [1000.0, 98.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3653 q_vals: [-inf, -4.037, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2141 1 visits [1000.0, 99.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3656 q_vals: [-inf, -4.036, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2142 1 visits [1000.0, 100.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3657 q_vals: [-inf, -4.044, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2143 1 visits [1000.0, 101.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3657 q_vals: [-inf, -4.13, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2144 1 visits [1000.0, 102.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3660 q_vals: [-inf, -4.127, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2145 1 visits [1000.0, 103.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3661 q_vals: [-inf, -4.122, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2146 1 visits [1000.0, 104.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3661 q_vals: [-inf, -4.083, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3663, "number_of_timesteps": 67690, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
Step 2147 1 visits [1000.0, 105.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3663 q_vals: [-inf, -4.087, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2148 1 visits [1000.0, 106.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3665 q_vals: [-inf, -4.1, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2149 1 visits [1000.0, 107.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3666 q_vals: [-inf, -4.061, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2150 1 visits [1000.0, 108.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3667 q_vals: [-inf, -4.024, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2151 1 visits [1000.0, 109.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3668 q_vals: [-inf, -3.987, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2152 1 visits [1000.0, 110.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3671 q_vals: [-inf, -3.998, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2153 1 visits [1000.0, 111.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3672 q_vals: [-inf, -3.999, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3674, "number_of_timesteps": 67930, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
Step 2154 1 visits [1000.0, 112.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3674 q_vals: [-inf, -3.996, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2155 1 visits [1000.0, 113.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3675 q_vals: [-inf, -4.003, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2156 1 visits [1000.0, 114.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3677 q_vals: [-inf, -3.968, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2157 1 visits [1000.0, 115.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3677 q_vals: [-inf, -3.976, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2158 1 visits [1000.0, 116.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3678 q_vals: [-inf, -3.976, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2159 1 visits [1000.0, 117.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3681 q_vals: [-inf, -3.972, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2160 1 visits [1000.0, 118.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3681 q_vals: [-inf, -3.988, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2161 1 visits [1000.0, 119.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3682 q_vals: [-inf, -3.989, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2162 1 visits [1000.0, 120.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3683 q_vals: [-inf, -3.984, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3684, "number_of_timesteps": 68210, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
Step 2163 1 visits [1000.0, 121.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3684 q_vals: [-inf, -4.057, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2164 1 visits [1000.0, 122.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3687 q_vals: [-inf, -4.062, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2165 1 visits [1000.0, 123.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3688 q_vals: [-inf, -4.066, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2166 1 visits [1000.0, 124.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3690 q_vals: [-inf, -4.062, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2167 1 visits [1000.0, 125.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3691 q_vals: [-inf, -4.058, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2168 1 visits [1000.0, 126.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3693 q_vals: [-inf, -4.053, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3694, "number_of_timesteps": 68409, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2169 1 visits [1000.0, 127.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3694 q_vals: [-inf, -4.05, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2170 1 visits [1000.0, 128.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3695 q_vals: [-inf, -4.045, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2171 1 visits [1000.0, 129.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3698 q_vals: [-inf, -4.041, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2172 1 visits [1000.0, 130.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3700 q_vals: [-inf, -4.039, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2173 1 visits [1000.0, 131.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3701 q_vals: [-inf, -4.106, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3706, "number_of_timesteps": 68645, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2174 1 visits [1000.0, 132.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3706 q_vals: [-inf, -4.101, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2175 1 visits [1000.0, 133.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3706 q_vals: [-inf, -4.096, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2176 1 visits [1000.0, 134.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3708 q_vals: [-inf, -4.161, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2177 1 visits [1000.0, 135.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3713 q_vals: [-inf, -4.13, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2178 1 visits [1000.0, 136.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3714 q_vals: [-inf, -4.132, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2179 1 visits [1000.0, 137.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3715 q_vals: [-inf, -4.128, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3717, "number_of_timesteps": 68792, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2180 1 visits [1000.0, 138.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3717 q_vals: [-inf, -4.098, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2181 1 visits [1000.0, 139.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3719 q_vals: [-inf, -4.094, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2182 1 visits [1000.0, 140.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3720 q_vals: [-inf, -4.156, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2183 1 visits [1000.0, 141.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3721 q_vals: [-inf, -4.126, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2184 1 visits [1000.0, 142.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3724 q_vals: [-inf, -4.097, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2185 1 visits [1000.0, 143.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3725 q_vals: [-inf, -4.158, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3727, "number_of_timesteps": 68971, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2186 1 visits [1000.0, 144.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3727 q_vals: [-inf, -4.155, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2187 1 visits [1000.0, 145.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3728 q_vals: [-inf, -4.152, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2188 1 visits [1000.0, 146.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3731 q_vals: [-inf, -4.154, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2189 1 visits [1000.0, 147.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3732 q_vals: [-inf, -4.15, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2190 1 visits [1000.0, 148.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3734 q_vals: [-inf, -4.154, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2191 1 visits [1000.0, 149.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3734 q_vals: [-inf, -4.212, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3738, "number_of_timesteps": 69162, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 2192 1 visits [1000.0, 150.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3738 q_vals: [-inf, -4.213, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2193 1 visits [1000.0, 151.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3739 q_vals: [-inf, -4.213, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2194 1 visits [1000.0, 152.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3740 q_vals: [-inf, -4.208, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2195 1 visits [1000.0, 153.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3741 q_vals: [-inf, -4.202, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2196 1 visits [1000.0, 154.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3744 q_vals: [-inf, -4.198, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2197 1 visits [1000.0, 155.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3746 q_vals: [-inf, -4.177, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2198 1 visits [1000.0, 156.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3747 q_vals: [-inf, -4.233, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3750, "number_of_timesteps": 69411, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2199 1 visits [1000.0, 157.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3750 q_vals: [-inf, -4.232, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2200 1 visits [1000.0, 158.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3752 q_vals: [-inf, -4.227, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2201 1 visits [1000.0, 159.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3754 q_vals: [-inf, -4.228, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2202 1 visits [1000.0, 160.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3755 q_vals: [-inf, -4.223, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2203 1 visits [1000.0, 161.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3759 q_vals: [-inf, -4.197, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3760, "number_of_timesteps": 69567, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2204 1 visits [1000.0, 162.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3760 q_vals: [-inf, -4.193, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2205 1 visits [1000.0, 163.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3762 q_vals: [-inf, -4.196, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2206 1 visits [1000.0, 164.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3765 q_vals: [-inf, -4.171, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2207 1 visits [1000.0, 165.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3767 q_vals: [-inf, -4.145, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2208 1 visits [1000.0, 166.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3767 q_vals: [-inf, -4.146, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2209 1 visits [1000.0, 167.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3768 q_vals: [-inf, -4.122, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2210 1 visits [1000.0, 168.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3769 q_vals: [-inf, -4.119, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3772, "number_of_timesteps": 69778, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2211 1 visits [1000.0, 169.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3772 q_vals: [-inf, -4.117, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2212 1 visits [1000.0, 170.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3775 q_vals: [-inf, -4.093, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2213 1 visits [1000.0, 171.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3775 q_vals: [-inf, -4.069, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2214 1 visits [1000.0, 172.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3778 q_vals: [-inf, -4.065, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2215 1 visits [1000.0, 173.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3778 q_vals: [-inf, -4.042, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2216 1 visits [1000.0, 174.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3780 q_vals: [-inf, -4.039, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2217 1 visits [1000.0, 175.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3780 q_vals: [-inf, -4.041, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2218 1 visits [1000.0, 176.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3780 q_vals: [-inf, -4.046, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3783, "number_of_timesteps": 70000, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2219 1 visits [1000.0, 177.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3783 q_vals: [-inf, -4.023, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2220 1 visits [1000.0, 178.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3784 q_vals: [-inf, -4.0, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2221 1 visits [1000.0, 179.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3787 q_vals: [-inf, -3.978, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2222 1 visits [1000.0, 180.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3788 q_vals: [-inf, -3.977, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2223 1 visits [1000.0, 181.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3790 q_vals: [-inf, -4.025, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2224 1 visits [1000.0, 182.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3790 q_vals: [-inf, -4.003, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3793, "number_of_timesteps": 70216, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2225 1 visits [1000.0, 183.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3793 q_vals: [-inf, -4.003, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2226 1 visits [1000.0, 184.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3793 q_vals: [-inf, -3.998, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2227 1 visits [1000.0, 185.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3793 q_vals: [-inf, -4.002, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2228 1 visits [1000.0, 186.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3795 q_vals: [-inf, -3.98, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2229 1 visits [1000.0, 187.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3797 q_vals: [-inf, -4.027, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2230 1 visits [1000.0, 188.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3798 q_vals: [-inf, -4.074, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2231 1 visits [1000.0, 189.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3800 q_vals: [-inf, -4.052, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2232 1 visits [1000.0, 190.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3802 q_vals: [-inf, -4.031, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3804, "number_of_timesteps": 70500, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2233 1 visits [1000.0, 191.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3804 q_vals: [-inf, -4.029, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2234 1 visits [1000.0, 192.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3804 q_vals: [-inf, -4.031, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2235 1 visits [1000.0, 193.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3806 q_vals: [-inf, -4.021, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2236 1 visits [1000.0, 194.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3807 q_vals: [-inf, -4.0, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2237 1 visits [1000.0, 195.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3808 q_vals: [-inf, -4.004, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2238 1 visits [1000.0, 196.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3810 q_vals: [-inf, -4.009, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2239 1 visits [1000.0, 197.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3813 q_vals: [-inf, -3.988, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2240 1 visits [1000.0, 198.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3813 q_vals: [-inf, -3.989, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2241 1 visits [1000.0, 199.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3813 q_vals: [-inf, -4.033, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3817, "number_of_timesteps": 70763, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2242 1 visits [1000.0, 200.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3817 q_vals: [-inf, -4.029, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2243 1 visits [1000.0, 201.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3819 q_vals: [-inf, -4.027, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2244 1 visits [1000.0, 202.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3820 q_vals: [-inf, -4.071, -6.4, -5.293, -6.754, -4.916, -4.288]
[-inf, -4.068, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2246 1 visits [1000.0, 204.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3821 q_vals: [-inf, -4.048, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2247 1 visits [1000.0, 205.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3822 q_vals: [-inf, -4.054, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2248 1 visits [1000.0, 206.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3825 q_vals: [-inf, -4.034, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3827, "number_of_timesteps": 71001, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2249 1 visits [1000.0, 207.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3827 q_vals: [-inf, -4.033, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2250 1 visits [1000.0, 208.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3829 q_vals: [-inf, -4.03, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2251 1 visits [1000.0, 209.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3831 q_vals: [-inf, -4.01, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2252 1 visits [1000.0, 210.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3832 q_vals: [-inf, -4.008, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2253 1 visits [1000.0, 211.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3834 q_vals: [-inf, -4.011, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2254 1 visits [1000.0, 212.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3836 q_vals: [-inf, -4.012, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3837, "number_of_timesteps": 71175, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2255 1 visits [1000.0, 213.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3837 q_vals: [-inf, -4.014, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2256 1 visits [1000.0, 214.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3840 q_vals: [-inf, -3.995, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2257 1 visits [1000.0, 215.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3842 q_vals: [-inf, -3.977, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2258 1 visits [1000.0, 216.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3844 q_vals: [-inf, -3.975, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3847, "number_of_timesteps": 71338, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2259 1 visits [1000.0, 217.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3847 q_vals: [-inf, -3.974, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2260 1 visits [1000.0, 218.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3849 q_vals: [-inf, -3.97, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2261 1 visits [1000.0, 219.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3849 q_vals: [-inf, -3.969, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2262 1 visits [1000.0, 220.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3852 q_vals: [-inf, -3.968, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2263 1 visits [1000.0, 221.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3853 q_vals: [-inf, -3.969, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2264 1 visits [1000.0, 222.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3855 q_vals: [-inf, -3.951, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3858, "number_of_timesteps": 71513, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2265 1 visits [1000.0, 223.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3858 q_vals: [-inf, -3.95, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2266 1 visits [1000.0, 224.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3858 q_vals: [-inf, -3.948, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2267 1 visits [1000.0, 225.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3861 q_vals: [-inf, -3.949, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2268 1 visits [1000.0, 226.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3864 q_vals: [-inf, -3.946, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2269 1 visits [1000.0, 227.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3866 q_vals: [-inf, -3.946, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3869, "number_of_timesteps": 71674, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2270 1 visits [1000.0, 228.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3869 q_vals: [-inf, -3.945, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2271 1 visits [1000.0, 229.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3872 q_vals: [-inf, -3.928, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2272 1 visits [1000.0, 230.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3872 q_vals: [-inf, -3.927, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2273 1 visits [1000.0, 231.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3874 q_vals: [-inf, -3.924, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2274 1 visits [1000.0, 232.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3876 q_vals: [-inf, -3.926, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2275 1 visits [1000.0, 233.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3878 q_vals: [-inf, -3.909, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3881, "number_of_timesteps": 71859, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2276 1 visits [1000.0, 234.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3881 q_vals: [-inf, -3.907, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2277 1 visits [1000.0, 235.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3881 q_vals: [-inf, -3.909, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2278 1 visits [1000.0, 236.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3883 q_vals: [-inf, -3.908, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2279 1 visits [1000.0, 237.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3886 q_vals: [-inf, -3.908, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2280 1 visits [1000.0, 238.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3888 q_vals: [-inf, -3.907, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2281 1 visits [1000.0, 239.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3889 q_vals: [-inf, -3.906, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3892, "number_of_timesteps": 72041, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
 episode_count: 3892 q_vals: [-inf, -3.89, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2283 1 visits [1000.0, 241.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3894 q_vals: [-inf, -3.927, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2284 1 visits [1000.0, 242.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3897 q_vals: [-inf, -3.911, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2285 1 visits [1000.0, 243.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3898 q_vals: [-inf, -3.909, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2286 1 visits [1000.0, 244.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3900 q_vals: [-inf, -3.893, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3902, "number_of_timesteps": 72184, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2287 1 visits [1000.0, 245.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3902 q_vals: [-inf, -3.877, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2288 1 visits [1000.0, 246.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3904 q_vals: [-inf, -3.881, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2289 1 visits [1000.0, 247.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3906 q_vals: [-inf, -3.917, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2290 1 visits [1000.0, 248.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3907 q_vals: [-inf, -3.917, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2291 1 visits [1000.0, 249.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3910 q_vals: [-inf, -3.953, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3913, "number_of_timesteps": 72372, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2292 1 visits [1000.0, 250.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3913 q_vals: [-inf, -3.955, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2293 1 visits [1000.0, 251.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3913 q_vals: [-inf, -3.939, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2294 1 visits [1000.0, 252.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3915 q_vals: [-inf, -3.939, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2295 1 visits [1000.0, 253.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3917 q_vals: [-inf, -3.939, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2296 1 visits [1000.0, 254.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3918 q_vals: [-inf, -3.974, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2297 1 visits [1000.0, 255.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3920 q_vals: [-inf, -4.009, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2298 1 visits [1000.0, 256.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3922 q_vals: [-inf, -4.009, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3923, "number_of_timesteps": 72555, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2299 1 visits [1000.0, 257.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3923 q_vals: [-inf, -3.993, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2300 1 visits [1000.0, 258.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3924 q_vals: [-inf, -3.992, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2301 1 visits [1000.0, 259.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3927 q_vals: [-inf, -3.99, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2302 1 visits [1000.0, 260.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3928 q_vals: [-inf, -3.975, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2303 1 visits [1000.0, 261.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3928 q_vals: [-inf, -3.979, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2304 1 visits [1000.0, 262.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3929 q_vals: [-inf, -3.964, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2305 1 visits [1000.0, 263.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3930 q_vals: [-inf, -3.964, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3934, "number_of_timesteps": 72797, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2306 1 visits [1000.0, 264.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3934 q_vals: [-inf, -3.962, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2307 1 visits [1000.0, 265.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3934 q_vals: [-inf, -3.961, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2308 1 visits [1000.0, 266.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3935 q_vals: [-inf, -3.994, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2309 1 visits [1000.0, 267.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3939 q_vals: [-inf, -3.994, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2310 1 visits [1000.0, 268.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3940 q_vals: [-inf, -3.993, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2311 1 visits [1000.0, 269.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3940 q_vals: [-inf, -3.992, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2312 1 visits [1000.0, 270.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3942 q_vals: [-inf, -3.977, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2313 1 visits [1000.0, 271.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3943 q_vals: [-inf, -3.963, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3945, "number_of_timesteps": 73015, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2314 1 visits [1000.0, 272.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3945 q_vals: [-inf, -3.948, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2315 1 visits [1000.0, 273.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3947 q_vals: [-inf, -3.947, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2316 1 visits [1000.0, 274.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3949 q_vals: [-inf, -3.932, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2317 1 visits [1000.0, 275.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3949 q_vals: [-inf, -3.932, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2318 1 visits [1000.0, 276.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3951 q_vals: [-inf, -3.918, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2319 1 visits [1000.0, 277.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3951 q_vals: [-inf, -3.903, -6.4, -5.293, -6.754, -4.916, -4.288]
[-inf, -3.889, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2321 1 visits [1000.0, 279.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3954 q_vals: [-inf, -3.876, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2322 1 visits [1000.0, 280.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3954 q_vals: [-inf, -3.862, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3955, "number_of_timesteps": 73225, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2323 1 visits [1000.0, 281.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3955 q_vals: [-inf, -3.848, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2324 1 visits [1000.0, 282.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3955 q_vals: [-inf, -3.88, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2325 1 visits [1000.0, 283.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3958 q_vals: [-inf, -3.866, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2326 1 visits [1000.0, 284.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3958 q_vals: [-inf, -3.852, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2327 1 visits [1000.0, 285.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3959 q_vals: [-inf, -3.851, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2328 1 visits [1000.0, 286.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3961 q_vals: [-inf, -3.854, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2329 1 visits [1000.0, 287.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3962 q_vals: [-inf, -3.853, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2330 1 visits [1000.0, 288.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3963 q_vals: [-inf, -3.884, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2331 1 visits [1000.0, 289.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3964 q_vals: [-inf, -3.885, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3966, "number_of_timesteps": 73542, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2332 1 visits [1000.0, 290.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3966 q_vals: [-inf, -3.916, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2333 1 visits [1000.0, 291.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3969 q_vals: [-inf, -3.916, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2334 1 visits [1000.0, 292.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3970 q_vals: [-inf, -3.903, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2335 1 visits [1000.0, 293.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3972 q_vals: [-inf, -3.903, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2336 1 visits [1000.0, 294.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3973 q_vals: [-inf, -3.901, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2337 1 visits [1000.0, 295.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3974 q_vals: [-inf, -3.888, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2338 1 visits [1000.0, 296.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3974 q_vals: [-inf, -3.918, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3978, "number_of_timesteps": 73857, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2339 1 visits [1000.0, 297.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3978 q_vals: [-inf, -3.916, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2340 1 visits [1000.0, 298.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3979 q_vals: [-inf, -3.903, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2341 1 visits [1000.0, 299.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3979 q_vals: [-inf, -3.933, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2342 1 visits [1000.0, 300.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3980 q_vals: [-inf, -3.963, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2343 1 visits [1000.0, 301.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3982 q_vals: [-inf, -3.957, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2344 1 visits [1000.0, 302.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3982 q_vals: [-inf, -3.944, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2345 1 visits [1000.0, 303.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3985 q_vals: [-inf, -3.942, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2346 1 visits [1000.0, 304.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3987 q_vals: [-inf, -3.94, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2347 1 visits [1000.0, 305.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3987 q_vals: [-inf, -3.938, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3988, "number_of_timesteps": 74118, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2348 1 visits [1000.0, 306.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3988 q_vals: [-inf, -3.925, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2349 1 visits [1000.0, 307.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3992 q_vals: [-inf, -3.925, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2350 1 visits [1000.0, 308.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3993 q_vals: [-inf, -3.923, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2351 1 visits [1000.0, 309.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3994 q_vals: [-inf, -3.91, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2352 1 visits [1000.0, 310.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3996 q_vals: [-inf, -3.913, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2353 1 visits [1000.0, 311.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3997 q_vals: [-inf, -3.916, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 3998, "number_of_timesteps": 74297, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2354 1 visits [1000.0, 312.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 3998 q_vals: [-inf, -3.904, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2355 1 visits [1000.0, 313.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4000 q_vals: [-inf, -3.903, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2356 1 visits [1000.0, 314.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4001 q_vals: [-inf, -3.89, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2357 1 visits [1000.0, 315.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4002 q_vals: [-inf, -3.891, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2358 1 visits [1000.0, 316.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4003 q_vals: [-inf, -3.895, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2359 1 visits [1000.0, 317.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4005 q_vals: [-inf, -3.882, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2360 1 visits [1000.0, 318.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4006 q_vals: [-inf, -3.87, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2361 1 visits [1000.0, 319.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4006 q_vals: [-inf, -3.873, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2362 1 visits [1000.0, 320.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4007 q_vals: [-inf, -3.861, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4011, "number_of_timesteps": 74634, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2363 1 visits [1000.0, 321.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4011 q_vals: [-inf, -3.849, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2364 1 visits [1000.0, 322.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4013 q_vals: [-inf, -3.837, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2365 1 visits [1000.0, 323.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4013 q_vals: [-inf, -3.836, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2366 1 visits [1000.0, 324.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4015 q_vals: [-inf, -3.824, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2367 1 visits [1000.0, 325.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4017 q_vals: [-inf, -3.823, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2368 1 visits [1000.0, 326.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4019 q_vals: [-inf, -3.822, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2369 1 visits [1000.0, 327.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4020 q_vals: [-inf, -3.82, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4023, "number_of_timesteps": 74862, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2370 1 visits [1000.0, 328.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4023 q_vals: [-inf, -3.822, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2371 1 visits [1000.0, 329.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4024 q_vals: [-inf, -3.81, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2372 1 visits [1000.0, 330.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4027 q_vals: [-inf, -3.803, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2373 1 visits [1000.0, 331.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4027 q_vals: [-inf, -3.791, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2374 1 visits [1000.0, 332.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4028 q_vals: [-inf, -3.78, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2375 1 visits [1000.0, 333.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4029 q_vals: [-inf, -3.807, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2376 1 visits [1000.0, 334.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4030 q_vals: [-inf, -3.806, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2377 1 visits [1000.0, 335.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4030 q_vals: [-inf, -3.805, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2378 1 visits [1000.0, 336.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4032 q_vals: [-inf, -3.807, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4033, "number_of_timesteps": 75058, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2379 1 visits [1000.0, 337.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4033 q_vals: [-inf, -3.806, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2380 1 visits [1000.0, 338.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4035 q_vals: [-inf, -3.806, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2381 1 visits [1000.0, 339.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4038 q_vals: [-inf, -3.795, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2382 1 visits [1000.0, 340.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4041 q_vals: [-inf, -3.784, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2383 1 visits [1000.0, 341.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4042 q_vals: [-inf, -3.773, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4043, "number_of_timesteps": 75285, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2384 1 visits [1000.0, 342.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4043 q_vals: [-inf, -3.799, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2385 1 visits [1000.0, 343.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4047 q_vals: [-inf, -3.801, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2386 1 visits [1000.0, 344.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4049 q_vals: [-inf, -3.79, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2387 1 visits [1000.0, 345.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4049 q_vals: [-inf, -3.779, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4054, "number_of_timesteps": 75429, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2388 1 visits [1000.0, 346.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4054 q_vals: [-inf, -3.768, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2389 1 visits [1000.0, 347.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4055 q_vals: [-inf, -3.757, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2390 1 visits [1000.0, 348.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4056 q_vals: [-inf, -3.756, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2391 1 visits [1000.0, 349.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4059 q_vals: [-inf, -3.754, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2392 1 visits [1000.0, 350.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4062 q_vals: [-inf, -3.744, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2393 1 visits [1000.0, 351.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4062 q_vals: [-inf, -3.742, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4064, "number_of_timesteps": 75573, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2394 1 visits [1000.0, 352.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4064 q_vals: [-inf, -3.744, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2395 1 visits [1000.0, 353.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4065 q_vals: [-inf, -3.744, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2396 1 visits [1000.0, 354.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4068 q_vals: [-inf, -3.733, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2397 1 visits [1000.0, 355.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4069 q_vals: [-inf, -3.732, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2398 1 visits [1000.0, 356.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4070 q_vals: [-inf, -3.733, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2399 1 visits [1000.0, 357.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4072 q_vals: [-inf, -3.732, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2400 1 visits [1000.0, 358.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4073 q_vals: [-inf, -3.722, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4075, "number_of_timesteps": 75798, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2401 1 visits [1000.0, 359.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4075 q_vals: [-inf, -3.712, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2402 1 visits [1000.0, 360.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4077 q_vals: [-inf, -3.71, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2403 1 visits [1000.0, 361.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4078 q_vals: [-inf, -3.711, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2404 1 visits [1000.0, 362.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4080 q_vals: [-inf, -3.701, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2405 1 visits [1000.0, 363.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4082 q_vals: [-inf, -3.691, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2406 1 visits [1000.0, 364.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4082 q_vals: [-inf, -3.716, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2407 1 visits [1000.0, 365.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4083 q_vals: [-inf, -3.74, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4086, "number_of_timesteps": 76000, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2408 1 visits [1000.0, 366.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4086 q_vals: [-inf, -3.74, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2409 1 visits [1000.0, 367.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4087 q_vals: [-inf, -3.741, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2410 1 visits [1000.0, 368.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4088 q_vals: [-inf, -3.745, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2411 1 visits [1000.0, 369.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4089 q_vals: [-inf, -3.735, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2412 1 visits [1000.0, 370.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4089 q_vals: [-inf, -3.725, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2413 1 visits [1000.0, 371.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4091 q_vals: [-inf, -3.715, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2414 1 visits [1000.0, 372.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4091 q_vals: [-inf, -3.713, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2415 1 visits [1000.0, 373.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4092 q_vals: [-inf, -3.715, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2416 1 visits [1000.0, 374.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4092 q_vals: [-inf, -3.715, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4097, "number_of_timesteps": 76341, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2417 1 visits [1000.0, 375.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4097 q_vals: [-inf, -3.714, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2418 1 visits [1000.0, 376.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4097 q_vals: [-inf, -3.714, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2419 1 visits [1000.0, 377.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4097 q_vals: [-inf, -3.704, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2420 1 visits [1000.0, 378.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4100 q_vals: [-inf, -3.696, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2421 1 visits [1000.0, 379.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4101 q_vals: [-inf, -3.7, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2422 1 visits [1000.0, 380.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4104 q_vals: [-inf, -3.707, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2423 1 visits [1000.0, 381.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4105 q_vals: [-inf, -3.706, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4107, "number_of_timesteps": 76549, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2424 1 visits [1000.0, 382.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4107 q_vals: [-inf, -3.696, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2425 1 visits [1000.0, 383.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4110 q_vals: [-inf, -3.698, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2426 1 visits [1000.0, 384.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4110 q_vals: [-inf, -3.697, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2427 1 visits [1000.0, 385.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4112 q_vals: [-inf, -3.695, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2428 1 visits [1000.0, 386.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4114 q_vals: [-inf, -3.694, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4117, "number_of_timesteps": 76725, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2429 1 visits [1000.0, 387.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4117 q_vals: [-inf, -3.695, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2430 1 visits [1000.0, 388.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4117 q_vals: [-inf, -3.719, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2431 1 visits [1000.0, 389.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4122 q_vals: [-inf, -3.717, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2432 1 visits [1000.0, 390.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4123 q_vals: [-inf, -3.716, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2433 1 visits [1000.0, 391.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4124 q_vals: [-inf, -3.707, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4129, "number_of_timesteps": 76881, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2434 1 visits [1000.0, 392.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4129 q_vals: [-inf, -3.697, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2435 1 visits [1000.0, 393.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4130 q_vals: [-inf, -3.698, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2436 1 visits [1000.0, 394.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4132 q_vals: [-inf, -3.697, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2437 1 visits [1000.0, 395.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4136 q_vals: [-inf, -3.696, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2438 1 visits [1000.0, 396.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4138 q_vals: [-inf, -3.697, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4140, "number_of_timesteps": 77015, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2439 1 visits [1000.0, 397.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4140 q_vals: [-inf, -3.696, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2440 1 visits [1000.0, 398.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4144 q_vals: [-inf, -3.686, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2441 1 visits [1000.0, 399.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4145 q_vals: [-inf, -3.685, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2442 1 visits [1000.0, 400.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4146 q_vals: [-inf, -3.708, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4151, "number_of_timesteps": 77155, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2443 1 visits [1000.0, 401.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4151 q_vals: [-inf, -3.708, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2444 1 visits [1000.0, 402.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4152 q_vals: [-inf, -3.708, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2445 1 visits [1000.0, 403.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4154 q_vals: [-inf, -3.708, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2446 1 visits [1000.0, 404.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4158 q_vals: [-inf, -3.708, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2447 1 visits [1000.0, 405.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4160 q_vals: [-inf, -3.699, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4161, "number_of_timesteps": 77278, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2448 1 visits [1000.0, 406.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4161 q_vals: [-inf, -3.693, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2449 1 visits [1000.0, 407.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4164 q_vals: [-inf, -3.695, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2450 1 visits [1000.0, 408.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4167 q_vals: [-inf, -3.686, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2451 1 visits [1000.0, 409.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4169 q_vals: [-inf, -3.677, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2452 1 visits [1000.0, 410.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4170 q_vals: [-inf, -3.679, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4172, "number_of_timesteps": 77427, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2453 1 visits [1000.0, 411.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4172 q_vals: [-inf, -3.679, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2454 1 visits [1000.0, 412.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4172 q_vals: [-inf, -3.68, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2455 1 visits [1000.0, 413.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4172 q_vals: [-inf, -3.671, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2456 1 visits [1000.0, 414.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4175 q_vals: [-inf, -3.671, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2457 1 visits [1000.0, 415.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4177 q_vals: [-inf, -3.674, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2458 1 visits [1000.0, 416.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4178 q_vals: [-inf, -3.665, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2459 1 visits [1000.0, 417.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4181 q_vals: [-inf, -3.667, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4182, "number_of_timesteps": 77651, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2460 1 visits [1000.0, 418.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4182 q_vals: [-inf, -3.66, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2461 1 visits [1000.0, 419.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4183 q_vals: [-inf, -3.659, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2462 1 visits [1000.0, 420.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4185 q_vals: [-inf, -3.659, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2463 1 visits [1000.0, 421.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4187 q_vals: [-inf, -3.66, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2464 1 visits [1000.0, 422.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4189 q_vals: [-inf, -3.651, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2465 1 visits [1000.0, 423.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4191 q_vals: [-inf, -3.651, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2466 1 visits [1000.0, 424.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4191 q_vals: [-inf, -3.65, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4194, "number_of_timesteps": 77865, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2467 1 visits [1000.0, 425.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4194 q_vals: [-inf, -3.65, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2468 1 visits [1000.0, 426.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4194 q_vals: [-inf, -3.641, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2469 1 visits [1000.0, 427.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4197 q_vals: [-inf, -3.644, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2470 1 visits [1000.0, 428.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4199 q_vals: [-inf, -3.644, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2471 1 visits [1000.0, 429.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4200 q_vals: [-inf, -3.644, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2472 1 visits [1000.0, 430.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4203 q_vals: [-inf, -3.635, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2473 1 visits [1000.0, 431.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4203 q_vals: [-inf, -3.636, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4206, "number_of_timesteps": 78090, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 2474 1 visits [1000.0, 432.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4206 q_vals: [-inf, -3.638, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2475 1 visits [1000.0, 433.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4208 q_vals: [-inf, -3.63, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2476 1 visits [1000.0, 434.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4209 q_vals: [-inf, -3.63, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2477 1 visits [1000.0, 435.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4209 q_vals: [-inf, -3.63, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2478 1 visits [1000.0, 436.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4210 q_vals: [-inf, -3.63, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2479 1 visits [1000.0, 437.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4212 q_vals: [-inf, -3.63, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2480 1 visits [1000.0, 438.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4215 q_vals: [-inf, -3.632, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4217, "number_of_timesteps": 78323, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 2481 1 visits [1000.0, 439.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4217 q_vals: [-inf, -3.634, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2482 1 visits [1000.0, 440.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4217 q_vals: [-inf, -3.634, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2483 1 visits [1000.0, 441.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4220 q_vals: [-inf, -3.633, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2484 1 visits [1000.0, 442.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4220 q_vals: [-inf, -3.635, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2485 1 visits [1000.0, 443.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4221 q_vals: [-inf, -3.638, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2486 1 visits [1000.0, 444.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4222 q_vals: [-inf, -3.659, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2487 1 visits [1000.0, 445.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4225 q_vals: [-inf, -3.658, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4228, "number_of_timesteps": 78551, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 2488 1 visits [1000.0, 446.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4228 q_vals: [-inf, -3.658, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2489 1 visits [1000.0, 447.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4228 q_vals: [-inf, -3.658, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2490 1 visits [1000.0, 448.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4230 q_vals: [-inf, -3.658, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2491 1 visits [1000.0, 449.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4232 q_vals: [-inf, -3.678, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2492 1 visits [1000.0, 450.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4235 q_vals: [-inf, -3.679, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2493 1 visits [1000.0, 451.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4236 q_vals: [-inf, -3.682, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4239, "number_of_timesteps": 78719, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2494 1 visits [1000.0, 452.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4239 q_vals: [-inf, -3.684, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2495 1 visits [1000.0, 453.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4241 q_vals: [-inf, -3.683, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2496 1 visits [1000.0, 454.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4242 q_vals: [-inf, -3.683, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2497 1 visits [1000.0, 455.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4245 q_vals: [-inf, -3.675, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2498 1 visits [1000.0, 456.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4247 q_vals: [-inf, -3.675, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2499 1 visits [1000.0, 457.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4247 q_vals: [-inf, -3.674, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4249, "number_of_timesteps": 78880, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 2500 1 visits [1000.0, 458.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4249 q_vals: [-inf, -3.694, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2501 1 visits [1000.0, 459.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4253 q_vals: [-inf, -3.689, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2502 1 visits [1000.0, 460.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4253 q_vals: [-inf, -3.69, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2503 1 visits [1000.0, 461.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4254 q_vals: [-inf, -3.691, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2504 1 visits [1000.0, 462.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4257 q_vals: [-inf, -3.683, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2505 1 visits [1000.0, 463.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4258 q_vals: [-inf, -3.675, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4261, "number_of_timesteps": 79081, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2506 1 visits [1000.0, 464.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4261 q_vals: [-inf, -3.695, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2507 1 visits [1000.0, 465.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4264 q_vals: [-inf, -3.695, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2508 1 visits [1000.0, 466.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4265 q_vals: [-inf, -3.687, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2509 1 visits [1000.0, 467.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4267 q_vals: [-inf, -3.679, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2510 1 visits [1000.0, 468.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4270 q_vals: [-inf, -3.68, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4271, "number_of_timesteps": 79230, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 2511 1 visits [1000.0, 469.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4271 q_vals: [-inf, -3.699, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2512 1 visits [1000.0, 470.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4273 q_vals: [-inf, -3.691, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2513 1 visits [1000.0, 471.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4276 q_vals: [-inf, -3.71, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2514 1 visits [1000.0, 472.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4279 q_vals: [-inf, -3.711, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2515 1 visits [1000.0, 473.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4280 q_vals: [-inf, -3.711, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4284, "number_of_timesteps": 79415, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 2516 1 visits [1000.0, 474.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4284 q_vals: [-inf, -3.703, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2517 1 visits [1000.0, 475.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4285 q_vals: [-inf, -3.703, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2518 1 visits [1000.0, 476.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4288 q_vals: [-inf, -3.695, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2519 1 visits [1000.0, 477.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4291 q_vals: [-inf, -3.695, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2520 1 visits [1000.0, 478.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4293 q_vals: [-inf, -3.714, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4296, "number_of_timesteps": 79566, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 2521 1 visits [1000.0, 479.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4296 q_vals: [-inf, -3.714, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2522 1 visits [1000.0, 480.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4299 q_vals: [-inf, -3.733, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2523 1 visits [1000.0, 481.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4302 q_vals: [-inf, -3.733, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4306, "number_of_timesteps": 79675, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2524 1 visits [1000.0, 482.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4306 q_vals: [-inf, -3.733, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2525 1 visits [1000.0, 483.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4306 q_vals: [-inf, -3.733, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2526 1 visits [1000.0, 484.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4310 q_vals: [-inf, -3.725, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2527 1 visits [1000.0, 485.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4313 q_vals: [-inf, -3.725, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2528 1 visits [1000.0, 486.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4313 q_vals: [-inf, -3.744, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4319, "number_of_timesteps": 79830, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2529 1 visits [1000.0, 487.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4319 q_vals: [-inf, -3.751, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2530 1 visits [1000.0, 488.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4319 q_vals: [-inf, -3.769, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2531 1 visits [1000.0, 489.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4322 q_vals: [-inf, -3.788, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2532 1 visits [1000.0, 490.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4324 q_vals: [-inf, -3.806, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4329, "number_of_timesteps": 79952, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2533 1 visits [1000.0, 491.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4329 q_vals: [-inf, -3.798, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2534 1 visits [1000.0, 492.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4331 q_vals: [-inf, -3.799, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2535 1 visits [1000.0, 493.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4332 q_vals: [-inf, -3.799, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2536 1 visits [1000.0, 494.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4334 q_vals: [-inf, -3.799, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2537 1 visits [1000.0, 495.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4334 q_vals: [-inf, -3.802, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2538 1 visits [1000.0, 496.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4337 q_vals: [-inf, -3.802, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2539 1 visits [1000.0, 497.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4337 q_vals: [-inf, -3.804, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4339, "number_of_timesteps": 80104, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2540 1 visits [1000.0, 498.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4339 q_vals: [-inf, -3.804, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2541 1 visits [1000.0, 499.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4342 q_vals: [-inf, -3.806, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2542 1 visits [1000.0, 500.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4345 q_vals: [-inf, -3.811, -6.4, -5.293, -6.754, -4.916, -4.288]
 [-inf, -3.829, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2544 1 visits [1000.0, 502.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4348 q_vals: [-inf, -3.829, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4350, "number_of_timesteps": 80298, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2545 1 visits [1000.0, 503.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4350 q_vals: [-inf, -3.83, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2546 1 visits [1000.0, 504.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4351 q_vals: [-inf, -3.831, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2547 1 visits [1000.0, 505.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4353 q_vals: [-inf, -3.849, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2548 1 visits [1000.0, 506.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4356 q_vals: [-inf, -3.85, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2549 1 visits [1000.0, 507.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4357 q_vals: [-inf, -3.85, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4360, "number_of_timesteps": 80461, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2550 1 visits [1000.0, 508.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4360 q_vals: [-inf, -3.851, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2551 1 visits [1000.0, 509.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4362 q_vals: [-inf, -3.844, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2552 1 visits [1000.0, 510.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4364 q_vals: [-inf, -3.844, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2553 1 visits [1000.0, 511.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4366 q_vals: [-inf, -3.836, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2554 1 visits [1000.0, 512.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4367 q_vals: [-inf, -3.829, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2555 1 visits [1000.0, 513.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4368 q_vals: [-inf, -3.846, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4372, "number_of_timesteps": 80658, "per_episode_reward": 12.93, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
Step 2556 1 visits [1000.0, 514.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4372 q_vals: [-inf, -3.847, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2557 1 visits [1000.0, 515.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4374 q_vals: [-inf, -3.848, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2558 1 visits [1000.0, 516.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4375 q_vals: [-inf, -3.841, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2559 1 visits [1000.0, 517.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4380 q_vals: [-inf, -3.842, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2560 1 visits [1000.0, 518.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4381 q_vals: [-inf, -3.843, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4384, "number_of_timesteps": 80813, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
Step 2561 1 visits [1000.0, 519.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4384 q_vals: [-inf, -3.843, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2562 1 visits [1000.0, 520.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4387 q_vals: [-inf, -3.836, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2563 1 visits [1000.0, 521.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4389 q_vals: [-inf, -3.836, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2564 1 visits [1000.0, 522.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4391 q_vals: [-inf, -3.837, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4394, "number_of_timesteps": 80935, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
Step 2565 1 visits [1000.0, 523.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4394 q_vals: [-inf, -3.839, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2566 1 visits [1000.0, 524.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4397 q_vals: [-inf, -3.839, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2567 1 visits [1000.0, 525.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4399 q_vals: [-inf, -3.839, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2568 1 visits [1000.0, 526.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4400 q_vals: [-inf, -3.832, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2569 1 visits [1000.0, 527.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4403 q_vals: [-inf, -3.832, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4405, "number_of_timesteps": 81085, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
Step 2570 1 visits [1000.0, 528.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4405 q_vals: [-inf, -3.832, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2571 1 visits [1000.0, 529.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4406 q_vals: [-inf, -3.825, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2572 1 visits [1000.0, 530.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4408 q_vals: [-inf, -3.825, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2573 1 visits [1000.0, 531.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4412 q_vals: [-inf, -3.827, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2574 1 visits [1000.0, 532.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4412 q_vals: [-inf, -3.82, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2575 1 visits [1000.0, 533.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4413 q_vals: [-inf, -3.822, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4417, "number_of_timesteps": 81249, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
Step 2576 1 visits [1000.0, 534.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4417 q_vals: [-inf, -3.822, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2577 1 visits [1000.0, 535.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4418 q_vals: [-inf, -3.823, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2578 1 visits [1000.0, 536.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4419 q_vals: [-inf, -3.825, -6.4, -5.293, -6.754, -4.916, -4.288]
[-inf, -3.826, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2580 1 visits [1000.0, 538.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4424 q_vals: [-inf, -3.829, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2581 1 visits [1000.0, 539.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4426 q_vals: [-inf, -3.829, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2582 1 visits [1000.0, 540.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4426 q_vals: [-inf, -3.822, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4429, "number_of_timesteps": 81461, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2583 1 visits [1000.0, 541.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4429 q_vals: [-inf, -3.816, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2584 1 visits [1000.0, 542.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4431 q_vals: [-inf, -3.818, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2585 1 visits [1000.0, 543.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4433 q_vals: [-inf, -3.811, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2586 1 visits [1000.0, 544.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4434 q_vals: [-inf, -3.811, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2587 1 visits [1000.0, 545.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4436 q_vals: [-inf, -3.813, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2588 1 visits [1000.0, 546.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4437 q_vals: [-inf, -3.816, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4440, "number_of_timesteps": 81654, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2589 1 visits [1000.0, 547.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4440 q_vals: [-inf, -3.821, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2590 1 visits [1000.0, 548.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4441 q_vals: [-inf, -3.837, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2591 1 visits [1000.0, 549.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4443 q_vals: [-inf, -3.83, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2592 1 visits [1000.0, 550.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4445 q_vals: [-inf, -3.83, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2593 1 visits [1000.0, 551.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4445 q_vals: [-inf, -3.846, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2594 1 visits [1000.0, 552.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4445 q_vals: [-inf, -3.839, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2595 1 visits [1000.0, 553.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4446 q_vals: [-inf, -3.84, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4450, "number_of_timesteps": 81874, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2596 1 visits [1000.0, 554.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4450 q_vals: [-inf, -3.833, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2597 1 visits [1000.0, 555.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4451 q_vals: [-inf, -3.833, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2598 1 visits [1000.0, 556.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4451 q_vals: [-inf, -3.826, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2599 1 visits [1000.0, 557.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4455 q_vals: [-inf, -3.826, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2600 1 visits [1000.0, 558.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4457 q_vals: [-inf, -3.82, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2601 1 visits [1000.0, 559.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4458 q_vals: [-inf, -3.82, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4461, "number_of_timesteps": 82066, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 2602 1 visits [1000.0, 560.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4461 q_vals: [-inf, -3.82, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2603 1 visits [1000.0, 561.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4464 q_vals: [-inf, -3.821, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2604 1 visits [1000.0, 562.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4465 q_vals: [-inf, -3.829, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2605 1 visits [1000.0, 563.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4468 q_vals: [-inf, -3.822, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2606 1 visits [1000.0, 564.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4470 q_vals: [-inf, -3.838, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4473, "number_of_timesteps": 82240, "per_episode_reward": 12.86, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 2607 1 visits [1000.0, 565.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4473 q_vals: [-inf, -3.839, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2608 1 visits [1000.0, 566.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4475 q_vals: [-inf, -3.84, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2609 1 visits [1000.0, 567.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4477 q_vals: [-inf, -3.833, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2610 1 visits [1000.0, 568.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4481 q_vals: [-inf, -3.833, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4483, "number_of_timesteps": 82355, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2611 1 visits [1000.0, 569.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4483 q_vals: [-inf, -3.834, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2612 1 visits [1000.0, 570.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4485 q_vals: [-inf, -3.827, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2613 1 visits [1000.0, 571.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4488 q_vals: [-inf, -3.828, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2614 1 visits [1000.0, 572.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4490 q_vals: [-inf, -3.821, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2615 1 visits [1000.0, 573.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4492 q_vals: [-inf, -3.821, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4496, "number_of_timesteps": 82516, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2616 1 visits [1000.0, 574.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4496 q_vals: [-inf, -3.822, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2617 1 visits [1000.0, 575.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4497 q_vals: [-inf, -3.823, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2618 1 visits [1000.0, 576.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4502 q_vals: [-inf, -3.816, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2619 1 visits [1000.0, 577.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4503 q_vals: [-inf, -3.81, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4506, "number_of_timesteps": 82625, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2620 1 visits [1000.0, 578.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4506 q_vals: [-inf, -3.803, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2621 1 visits [1000.0, 579.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4509 q_vals: [-inf, -3.804, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2622 1 visits [1000.0, 580.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4512 q_vals: [-inf, -3.805, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2623 1 visits [1000.0, 581.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4513 q_vals: [-inf, -3.806, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4518, "number_of_timesteps": 82770, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2624 1 visits [1000.0, 582.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4518 q_vals: [-inf, -3.799, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2625 1 visits [1000.0, 583.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4520 q_vals: [-inf, -3.8, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2626 1 visits [1000.0, 584.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4523 q_vals: [-inf, -3.816, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2627 1 visits [1000.0, 585.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4526 q_vals: [-inf, -3.809, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4529, "number_of_timesteps": 82888, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2628 1 visits [1000.0, 586.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4529 q_vals: [-inf, -3.803, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2629 1 visits [1000.0, 587.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4532 q_vals: [-inf, -3.804, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2630 1 visits [1000.0, 588.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4534 q_vals: [-inf, -3.798, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2631 1 visits [1000.0, 589.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4537 q_vals: [-inf, -3.791, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4540, "number_of_timesteps": 83013, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2632 1 visits [1000.0, 590.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4540 q_vals: [-inf, -3.792, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2633 1 visits [1000.0, 591.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4543 q_vals: [-inf, -3.794, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2634 1 visits [1000.0, 592.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4543 q_vals: [-inf, -3.795, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2635 1 visits [1000.0, 593.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4546 q_vals: [-inf, -3.797, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2636 1 visits [1000.0, 594.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4549 q_vals: [-inf, -3.802, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2637 1 visits [1000.0, 595.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4549 q_vals: [-inf, -3.795, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4551, "number_of_timesteps": 83147, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2638 1 visits [1000.0, 596.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4551 q_vals: [-inf, -3.797, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2639 1 visits [1000.0, 597.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4556 q_vals: [-inf, -3.79, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2640 1 visits [1000.0, 598.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4557 q_vals: [-inf, -3.791, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2641 1 visits [1000.0, 599.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4558 q_vals: [-inf, -3.785, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4562, "number_of_timesteps": 83313, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2642 1 visits [1000.0, 600.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4562 q_vals: [-inf, -3.778, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2643 1 visits [1000.0, 601.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4565 q_vals: [-inf, -3.781, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2644 1 visits [1000.0, 602.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4566 q_vals: [-inf, -3.783, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2645 1 visits [1000.0, 603.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4569 q_vals: [-inf, -3.784, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4572, "number_of_timesteps": 83436, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2646 1 visits [1000.0, 604.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4572 q_vals: [-inf, -3.786, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2647 1 visits [1000.0, 605.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4574 q_vals: [-inf, -3.779, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2648 1 visits [1000.0, 606.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4576 q_vals: [-inf, -3.773, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2649 1 visits [1000.0, 607.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4577 q_vals: [-inf, -3.788, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2650 1 visits [1000.0, 608.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4580 q_vals: [-inf, -3.789, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4583, "number_of_timesteps": 83582, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2651 1 visits [1000.0, 609.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4583 q_vals: [-inf, -3.782, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2652 1 visits [1000.0, 610.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4583 q_vals: [-inf, -3.785, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2653 1 visits [1000.0, 611.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4584 q_vals: [-inf, -3.786, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2654 1 visits [1000.0, 612.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4587 q_vals: [-inf, -3.788, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2655 1 visits [1000.0, 613.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4589 q_vals: [-inf, -3.781, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2656 1 visits [1000.0, 614.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4591 q_vals: [-inf, -3.785, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2657 1 visits [1000.0, 615.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4592 q_vals: [-inf, -3.786, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4596, "number_of_timesteps": 83808, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2658 1 visits [1000.0, 616.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4596 q_vals: [-inf, -3.78, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2659 1 visits [1000.0, 617.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4596 q_vals: [-inf, -3.774, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2660 1 visits [1000.0, 618.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4598 q_vals: [-inf, -3.774, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2661 1 visits [1000.0, 619.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4599 q_vals: [-inf, -3.775, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2662 1 visits [1000.0, 620.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4603 q_vals: [-inf, -3.769, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2663 1 visits [1000.0, 621.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4604 q_vals: [-inf, -3.773, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4607, "number_of_timesteps": 83990, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2664 1 visits [1000.0, 622.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4607 q_vals: [-inf, -3.774, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2665 1 visits [1000.0, 623.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4608 q_vals: [-inf, -3.776, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2666 1 visits [1000.0, 624.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4609 q_vals: [-inf, -3.77, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2667 1 visits [1000.0, 625.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4614 q_vals: [-inf, -3.764, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2668 1 visits [1000.0, 626.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4614 q_vals: [-inf, -3.766, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2669 1 visits [1000.0, 627.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4614 q_vals: [-inf, -3.76, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4617, "number_of_timesteps": 84144, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2670 1 visits [1000.0, 628.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4617 q_vals: [-inf, -3.763, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2671 1 visits [1000.0, 629.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4621 q_vals: [-inf, -3.764, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2672 1 visits [1000.0, 630.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4621 q_vals: [-inf, -3.764, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2673 1 visits [1000.0, 631.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4622 q_vals: [-inf, -3.758, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2674 1 visits [1000.0, 632.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4624 q_vals: [-inf, -3.759, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2675 1 visits [1000.0, 633.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4625 q_vals: [-inf, -3.753, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2676 1 visits [1000.0, 634.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4626 q_vals: [-inf, -3.756, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4628, "number_of_timesteps": 84355, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2677 1 visits [1000.0, 635.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4628 q_vals: [-inf, -3.758, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2678 1 visits [1000.0, 636.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4630 q_vals: [-inf, -3.752, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2679 1 visits [1000.0, 637.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4632 q_vals: [-inf, -3.767, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2680 1 visits [1000.0, 638.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4634 q_vals: [-inf, -3.761, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2681 1 visits [1000.0, 639.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4635 q_vals: [-inf, -3.762, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2682 1 visits [1000.0, 640.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4636 q_vals: [-inf, -3.756, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4638, "number_of_timesteps": 84519, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2683 1 visits [1000.0, 641.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4638 q_vals: [-inf, -3.757, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2684 1 visits [1000.0, 642.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4639 q_vals: [-inf, -3.755, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2685 1 visits [1000.0, 643.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4641 q_vals: [-inf, -3.75, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2686 1 visits [1000.0, 644.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4643 q_vals: [-inf, -3.764, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2687 1 visits [1000.0, 645.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4644 q_vals: [-inf, -3.758, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2688 1 visits [1000.0, 646.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4646 q_vals: [-inf, -3.758, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4648, "number_of_timesteps": 84770, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2689 1 visits [1000.0, 647.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4648 q_vals: [-inf, -3.759, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2690 1 visits [1000.0, 648.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4649 q_vals: [-inf, -3.753, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2691 1 visits [1000.0, 649.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4651 q_vals: [-inf, -3.754, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2692 1 visits [1000.0, 650.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4653 q_vals: [-inf, -3.757, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2693 1 visits [1000.0, 651.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4653 q_vals: [-inf, -3.751, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2694 1 visits [1000.0, 652.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4655 q_vals: [-inf, -3.752, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4659, "number_of_timesteps": 84989, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2695 1 visits [1000.0, 653.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4659 q_vals: [-inf, -3.753, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2696 1 visits [1000.0, 654.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4661 q_vals: [-inf, -3.747, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2697 1 visits [1000.0, 655.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4661 q_vals: [-inf, -3.742, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2698 1 visits [1000.0, 656.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4664 q_vals: [-inf, -3.736, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2699 1 visits [1000.0, 657.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4668 q_vals: [-inf, -3.736, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2700 1 visits [1000.0, 658.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4668 q_vals: [-inf, -3.739, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4669, "number_of_timesteps": 85139, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2701 1 visits [1000.0, 659.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4669 q_vals: [-inf, -3.733, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2702 1 visits [1000.0, 660.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4670 q_vals: [-inf, -3.734, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2703 1 visits [1000.0, 661.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4672 q_vals: [-inf, -3.735, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2704 1 visits [1000.0, 662.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4675 q_vals: [-inf, -3.73, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2705 1 visits [1000.0, 663.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4677 q_vals: [-inf, -3.731, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2706 1 visits [1000.0, 664.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4677 q_vals: [-inf, -3.725, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2707 1 visits [1000.0, 665.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4678 q_vals: [-inf, -3.726, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4680, "number_of_timesteps": 85345, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2708 1 visits [1000.0, 666.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4680 q_vals: [-inf, -3.72, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2709 1 visits [1000.0, 667.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4684 q_vals: [-inf, -3.722, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2710 1 visits [1000.0, 668.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4685 q_vals: [-inf, -3.724, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2711 1 visits [1000.0, 669.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4687 q_vals: [-inf, -3.726, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4690, "number_of_timesteps": 85501, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2712 1 visits [1000.0, 670.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4690 q_vals: [-inf, -3.721, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2713 1 visits [1000.0, 671.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4692 q_vals: [-inf, -3.715, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2714 1 visits [1000.0, 672.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4692 q_vals: [-inf, -3.71, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2715 1 visits [1000.0, 673.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4697 q_vals: [-inf, -3.704, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2716 1 visits [1000.0, 674.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4699 q_vals: [-inf, -3.705, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4701, "number_of_timesteps": 85657, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2717 1 visits [1000.0, 675.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4701 q_vals: [-inf, -3.706, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2718 1 visits [1000.0, 676.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4702 q_vals: [-inf, -3.719, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2719 1 visits [1000.0, 677.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4706 q_vals: [-inf, -3.721, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2720 1 visits [1000.0, 678.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4709 q_vals: [-inf, -3.722, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2721 1 visits [1000.0, 679.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4710 q_vals: [-inf, -3.735, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4711, "number_of_timesteps": 85796, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2722 1 visits [1000.0, 680.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4711 q_vals: [-inf, -3.748, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2723 1 visits [1000.0, 681.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4712 q_vals: [-inf, -3.762, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2724 1 visits [1000.0, 682.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4714 q_vals: [-inf, -3.763, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2725 1 visits [1000.0, 683.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4717 q_vals: [-inf, -3.764, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2726 1 visits [1000.0, 684.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4718 q_vals: [-inf, -3.767, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2727 1 visits [1000.0, 685.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4720 q_vals: [-inf, -3.78, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4723, "number_of_timesteps": 85983, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2728 1 visits [1000.0, 686.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4723 q_vals: [-inf, -3.78, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2729 1 visits [1000.0, 687.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4725 q_vals: [-inf, -3.781, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2730 1 visits [1000.0, 688.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4726 q_vals: [-inf, -3.783, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2731 1 visits [1000.0, 689.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4729 q_vals: [-inf, -3.783, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2732 1 visits [1000.0, 690.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4730 q_vals: [-inf, -3.784, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2733 1 visits [1000.0, 691.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4730 q_vals: [-inf, -3.797, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4734, "number_of_timesteps": 86185, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2734 1 visits [1000.0, 692.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4734 q_vals: [-inf, -3.797, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2735 1 visits [1000.0, 693.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4736 q_vals: [-inf, -3.799, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2736 1 visits [1000.0, 694.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4738 q_vals: [-inf, -3.801, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2737 1 visits [1000.0, 695.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4742 q_vals: [-inf, -3.801, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2738 1 visits [1000.0, 696.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4743 q_vals: [-inf, -3.803, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4744, "number_of_timesteps": 86334, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2739 1 visits [1000.0, 697.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4744 q_vals: [-inf, -3.804, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2740 1 visits [1000.0, 698.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4746 q_vals: [-inf, -3.798, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2741 1 visits [1000.0, 699.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4749 q_vals: [-inf, -3.801, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2742 1 visits [1000.0, 700.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4751 q_vals: [-inf, -3.802, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2743 1 visits [1000.0, 701.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4752 q_vals: [-inf, -3.796, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4754, "number_of_timesteps": 86487, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2744 1 visits [1000.0, 702.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4754 q_vals: [-inf, -3.798, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2745 1 visits [1000.0, 703.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4756 q_vals: [-inf, -3.8, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2746 1 visits [1000.0, 704.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4757 q_vals: [-inf, -3.813, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2747 1 visits [1000.0, 705.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4760 q_vals: [-inf, -3.815, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2748 1 visits [1000.0, 706.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4761 q_vals: [-inf, -3.815, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4764, "number_of_timesteps": 86646, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2749 1 visits [1000.0, 707.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4764 q_vals: [-inf, -3.815, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2750 1 visits [1000.0, 708.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4766 q_vals: [-inf, -3.818, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2751 1 visits [1000.0, 709.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4768 q_vals: [-inf, -3.813, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2752 1 visits [1000.0, 710.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4772 q_vals: [-inf, -3.814, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2753 1 visits [1000.0, 711.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4773 q_vals: [-inf, -3.814, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4775, "number_of_timesteps": 86810, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2754 1 visits [1000.0, 712.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4775 q_vals: [-inf, -3.815, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2755 1 visits [1000.0, 713.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4778 q_vals: [-inf, -3.81, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2756 1 visits [1000.0, 714.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4781 q_vals: [-inf, -3.812, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2757 1 visits [1000.0, 715.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4783 q_vals: [-inf, -3.825, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4785, "number_of_timesteps": 86943, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2758 1 visits [1000.0, 716.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4785 q_vals: [-inf, -3.826, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2759 1 visits [1000.0, 717.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4788 q_vals: [-inf, -3.827, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2760 1 visits [1000.0, 718.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4790 q_vals: [-inf, -3.822, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2761 1 visits [1000.0, 719.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4792 q_vals: [-inf, -3.816, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2762 1 visits [1000.0, 720.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4794 q_vals: [-inf, -3.817, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4797, "number_of_timesteps": 87099, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2763 1 visits [1000.0, 721.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4797 q_vals: [-inf, -3.821, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2764 1 visits [1000.0, 722.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4798 q_vals: [-inf, -3.821, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2765 1 visits [1000.0, 723.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4798 q_vals: [-inf, -3.816, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2766 1 visits [1000.0, 724.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4802 q_vals: [-inf, -3.816, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2767 1 visits [1000.0, 725.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4804 q_vals: [-inf, -3.811, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2768 1 visits [1000.0, 726.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4806 q_vals: [-inf, -3.806, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2769 1 visits [1000.0, 727.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4806 q_vals: [-inf, -3.808, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4809, "number_of_timesteps": 87267, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2770 1 visits [1000.0, 728.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4809 q_vals: [-inf, -3.808, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2771 1 visits [1000.0, 729.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4812 q_vals: [-inf, -3.809, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2772 1 visits [1000.0, 730.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4813 q_vals: [-inf, -3.809, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2773 1 visits [1000.0, 731.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4815 q_vals: [-inf, -3.804, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2774 1 visits [1000.0, 732.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4817 q_vals: [-inf, -3.799, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4819, "number_of_timesteps": 87453, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2775 1 visits [1000.0, 733.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4819 q_vals: [-inf, -3.802, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2776 1 visits [1000.0, 734.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4821 q_vals: [-inf, -3.797, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2777 1 visits [1000.0, 735.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4822 q_vals: [-inf, -3.797, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2778 1 visits [1000.0, 736.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4824 q_vals: [-inf, -3.799, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2779 1 visits [1000.0, 737.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4825 q_vals: [-inf, -3.799, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2780 1 visits [1000.0, 738.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4828 q_vals: [-inf, -3.801, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4829, "number_of_timesteps": 87617, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2781 1 visits [1000.0, 739.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4829 q_vals: [-inf, -3.803, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2782 1 visits [1000.0, 740.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4830 q_vals: [-inf, -3.805, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2783 1 visits [1000.0, 741.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4832 q_vals: [-inf, -3.8, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2784 1 visits [1000.0, 742.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4835 q_vals: [-inf, -3.802, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2785 1 visits [1000.0, 743.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4835 q_vals: [-inf, -3.804, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2786 1 visits [1000.0, 744.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4837 q_vals: [-inf, -3.816, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4840, "number_of_timesteps": 87821, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2787 1 visits [1000.0, 745.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4840 q_vals: [-inf, -3.817, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2788 1 visits [1000.0, 746.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4841 q_vals: [-inf, -3.812, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2789 1 visits [1000.0, 747.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4842 q_vals: [-inf, -3.812, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2790 1 visits [1000.0, 748.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4845 q_vals: [-inf, -3.824, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2791 1 visits [1000.0, 749.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4849 q_vals: [-inf, -3.825, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2792 1 visits [1000.0, 750.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4849 q_vals: [-inf, -3.826, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4851, "number_of_timesteps": 87999, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2793 1 visits [1000.0, 751.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4851 q_vals: [-inf, -3.828, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2794 1 visits [1000.0, 752.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4855 q_vals: [-inf, -3.84, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2795 1 visits [1000.0, 753.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4855 q_vals: [-inf, -3.852, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2796 1 visits [1000.0, 754.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4857 q_vals: [-inf, -3.852, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2797 1 visits [1000.0, 755.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4857 q_vals: [-inf, -3.847, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2798 1 visits [1000.0, 756.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4860 q_vals: [-inf, -3.847, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4862, "number_of_timesteps": 88176, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2799 1 visits [1000.0, 757.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4862 q_vals: [-inf, -3.842, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2800 1 visits [1000.0, 758.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4862 q_vals: [-inf, -3.844, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2801 1 visits [1000.0, 759.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4864 q_vals: [-inf, -3.839, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2802 1 visits [1000.0, 760.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4866 q_vals: [-inf, -3.839, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2803 1 visits [1000.0, 761.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4866 q_vals: [-inf, -3.851, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2804 1 visits [1000.0, 762.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4871 q_vals: [-inf, -3.846, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2805 1 visits [1000.0, 763.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4871 q_vals: [-inf, -3.847, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4873, "number_of_timesteps": 88420, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2806 1 visits [1000.0, 764.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4873 q_vals: [-inf, -3.848, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2807 1 visits [1000.0, 765.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4874 q_vals: [-inf, -3.843, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2808 1 visits [1000.0, 766.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4875 q_vals: [-inf, -3.838, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2809 1 visits [1000.0, 767.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4877 q_vals: [-inf, -3.833, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2810 1 visits [1000.0, 768.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4879 q_vals: [-inf, -3.828, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2811 1 visits [1000.0, 769.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4881 q_vals: [-inf, -3.828, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2812 1 visits [1000.0, 770.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4881 q_vals: [-inf, -3.829, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4883, "number_of_timesteps": 88634, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2813 1 visits [1000.0, 771.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4883 q_vals: [-inf, -3.831, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2814 1 visits [1000.0, 772.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4885 q_vals: [-inf, -3.833, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2815 1 visits [1000.0, 773.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4885 q_vals: [-inf, -3.834, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2816 1 visits [1000.0, 774.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4888 q_vals: [-inf, -3.834, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2817 1 visits [1000.0, 775.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4889 q_vals: [-inf, -3.834, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2818 1 visits [1000.0, 776.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4889 q_vals: [-inf, -3.837, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2819 1 visits [1000.0, 777.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4891 q_vals: [-inf, -3.837, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4894, "number_of_timesteps": 88852, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2820 1 visits [1000.0, 778.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4894 q_vals: [-inf, -3.838, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2821 1 visits [1000.0, 779.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4894 q_vals: [-inf, -3.84, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2822 1 visits [1000.0, 780.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4896 q_vals: [-inf, -3.835, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2823 1 visits [1000.0, 781.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4897 q_vals: [-inf, -3.83, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2824 1 visits [1000.0, 782.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4900 q_vals: [-inf, -3.831, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2825 1 visits [1000.0, 783.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4901 q_vals: [-inf, -3.843, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2826 1 visits [1000.0, 784.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4903 q_vals: [-inf, -3.854, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4906, "number_of_timesteps": 89110, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2827 1 visits [1000.0, 785.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4906 q_vals: [-inf, -3.854, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2828 1 visits [1000.0, 786.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4906 q_vals: [-inf, -3.855, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2829 1 visits [1000.0, 787.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4908 q_vals: [-inf, -3.855, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2830 1 visits [1000.0, 788.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4909 q_vals: [-inf, -3.855, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2831 1 visits [1000.0, 789.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4911 q_vals: [-inf, -3.856, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2832 1 visits [1000.0, 790.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4913 q_vals: [-inf, -3.851, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2833 1 visits [1000.0, 791.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4913 q_vals: [-inf, -3.851, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2834 1 visits [1000.0, 792.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4914 q_vals: [-inf, -3.846, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4917, "number_of_timesteps": 89320, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2835 1 visits [1000.0, 793.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4917 q_vals: [-inf, -3.848, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2836 1 visits [1000.0, 794.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4918 q_vals: [-inf, -3.843, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2837 1 visits [1000.0, 795.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4920 q_vals: [-inf, -3.845, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2838 1 visits [1000.0, 796.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4921 q_vals: [-inf, -3.84, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2839 1 visits [1000.0, 797.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4923 q_vals: [-inf, -3.84, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2840 1 visits [1000.0, 798.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4924 q_vals: [-inf, -3.835, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2841 1 visits [1000.0, 799.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4926 q_vals: [-inf, -3.835, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2842 1 visits [1000.0, 800.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4926 q_vals: [-inf, -3.835, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4930, "number_of_timesteps": 89587, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2843 1 visits [1000.0, 801.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4930 q_vals: [-inf, -3.836, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2844 1 visits [1000.0, 802.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4931 q_vals: [-inf, -3.836, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2845 1 visits [1000.0, 803.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4934 q_vals: [-inf, -3.832, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2846 1 visits [1000.0, 804.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4934 q_vals: [-inf, -3.832, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2847 1 visits [1000.0, 805.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4936 q_vals: [-inf, -3.827, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4941, "number_of_timesteps": 89818, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2848 1 visits [1000.0, 806.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4941 q_vals: [-inf, -3.827, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2849 1 visits [1000.0, 807.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4942 q_vals: [-inf, -3.827, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2850 1 visits [1000.0, 808.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4942 q_vals: [-inf, -3.829, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2851 1 visits [1000.0, 809.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4945 q_vals: [-inf, -3.831, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2852 1 visits [1000.0, 810.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4946 q_vals: [-inf, -3.826, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2853 1 visits [1000.0, 811.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4946 q_vals: [-inf, -3.822, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2854 1 visits [1000.0, 812.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4947 q_vals: [-inf, -3.833, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2855 1 visits [1000.0, 813.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4950 q_vals: [-inf, -3.828, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4951, "number_of_timesteps": 89990, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2856 1 visits [1000.0, 814.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4951 q_vals: [-inf, -3.828, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2857 1 visits [1000.0, 815.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4953 q_vals: [-inf, -3.823, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2858 1 visits [1000.0, 816.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4954 q_vals: [-inf, -3.824, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2859 1 visits [1000.0, 817.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4957 q_vals: [-inf, -3.825, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2860 1 visits [1000.0, 818.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4959 q_vals: [-inf, -3.826, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4961, "number_of_timesteps": 90195, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2861 1 visits [1000.0, 819.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4961 q_vals: [-inf, -3.826, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2862 1 visits [1000.0, 820.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4964 q_vals: [-inf, -3.826, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2863 1 visits [1000.0, 821.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4965 q_vals: [-inf, -3.837, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2864 1 visits [1000.0, 822.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4969 q_vals: [-inf, -3.832, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4972, "number_of_timesteps": 90337, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2865 1 visits [1000.0, 823.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4972 q_vals: [-inf, -3.833, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2866 1 visits [1000.0, 824.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4972 q_vals: [-inf, -3.835, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2867 1 visits [1000.0, 825.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4974 q_vals: [-inf, -3.836, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2868 1 visits [1000.0, 826.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4976 q_vals: [-inf, -3.831, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2869 1 visits [1000.0, 827.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4978 q_vals: [-inf, -3.833, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2870 1 visits [1000.0, 828.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4980 q_vals: [-inf, -3.834, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4983, "number_of_timesteps": 90517, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2871 1 visits [1000.0, 829.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4983 q_vals: [-inf, -3.834, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2872 1 visits [1000.0, 830.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4984 q_vals: [-inf, -3.829, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2873 1 visits [1000.0, 831.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4985 q_vals: [-inf, -3.831, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2874 1 visits [1000.0, 832.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4987 q_vals: [-inf, -3.842, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2875 1 visits [1000.0, 833.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4989 q_vals: [-inf, -3.842, -6.4, -5.293, -6.754, -4.916, -4.288]
q_vals: [-inf, -3.838, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 4994, "number_of_timesteps": 90695, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2877 1 visits [1000.0, 835.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4994 q_vals: [-inf, -3.833, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2878 1 visits [1000.0, 836.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4994 q_vals: [-inf, -3.833, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2879 1 visits [1000.0, 837.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4996 q_vals: [-inf, -3.833, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2880 1 visits [1000.0, 838.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 4999 q_vals: [-inf, -3.829, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2881 1 visits [1000.0, 839.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5000 q_vals: [-inf, -3.839, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2882 1 visits [1000.0, 840.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5003 q_vals: [-inf, -3.85, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2883 1 visits [1000.0, 841.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5003 q_vals: [-inf, -3.851, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5005, "number_of_timesteps": 90880, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2884 1 visits [1000.0, 842.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5005 q_vals: [-inf, -3.851, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2885 1 visits [1000.0, 843.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5008 q_vals: [-inf, -3.862, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2886 1 visits [1000.0, 844.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5010 q_vals: [-inf, -3.862, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2887 1 visits [1000.0, 845.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5010 q_vals: [-inf, -3.863, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2888 1 visits [1000.0, 846.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5012 q_vals: [-inf, -3.859, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2889 1 visits [1000.0, 847.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5013 q_vals: [-inf, -3.86, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2890 1 visits [1000.0, 848.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5014 q_vals: [-inf, -3.856, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5016, "number_of_timesteps": 91086, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2891 1 visits [1000.0, 849.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5016 q_vals: [-inf, -3.856, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2892 1 visits [1000.0, 850.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5020 q_vals: [-inf, -3.856, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2893 1 visits [1000.0, 851.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5020 q_vals: [-inf, -3.858, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2894 1 visits [1000.0, 852.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5022 q_vals: [-inf, -3.859, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2895 1 visits [1000.0, 853.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5024 q_vals: [-inf, -3.859, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5027, "number_of_timesteps": 91247, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2896 1 visits [1000.0, 854.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5027 q_vals: [-inf, -3.859, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2897 1 visits [1000.0, 855.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5027 q_vals: [-inf, -3.869, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2898 1 visits [1000.0, 856.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5031 q_vals: [-inf, -3.866, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2899 1 visits [1000.0, 857.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5034 q_vals: [-inf, -3.866, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2900 1 visits [1000.0, 858.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5035 q_vals: [-inf, -3.867, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5037, "number_of_timesteps": 91427, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2901 1 visits [1000.0, 859.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5037 q_vals: [-inf, -3.862, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2902 1 visits [1000.0, 860.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5039 q_vals: [-inf, -3.873, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2903 1 visits [1000.0, 861.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5040 q_vals: [-inf, -3.873, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2904 1 visits [1000.0, 862.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5042 q_vals: [-inf, -3.868, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2905 1 visits [1000.0, 863.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5046 q_vals: [-inf, -3.868, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5047, "number_of_timesteps": 91589, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2906 1 visits [1000.0, 864.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5047 q_vals: [-inf, -3.868, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2907 1 visits [1000.0, 865.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5048 q_vals: [-inf, -3.869, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2908 1 visits [1000.0, 866.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5052 q_vals: [-inf, -3.869, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2909 1 visits [1000.0, 867.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5054 q_vals: [-inf, -3.88, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5057, "number_of_timesteps": 91724, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2910 1 visits [1000.0, 868.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5057 q_vals: [-inf, -3.88, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2911 1 visits [1000.0, 869.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5060 q_vals: [-inf, -3.881, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2912 1 visits [1000.0, 870.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5063 q_vals: [-inf, -3.882, -6.4, -5.293, -6.754, -4.916, -4.288]
[-inf, -3.882, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5067, "number_of_timesteps": 91836, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2914 1 visits [1000.0, 872.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5067 q_vals: [-inf, -3.877, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2915 1 visits [1000.0, 873.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5069 q_vals: [-inf, -3.887, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2916 1 visits [1000.0, 874.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5072 q_vals: [-inf, -3.883, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2917 1 visits [1000.0, 875.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5073 q_vals: [-inf, -3.879, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2918 1 visits [1000.0, 876.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5076 q_vals: [-inf, -3.874, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5079, "number_of_timesteps": 91997, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2919 1 visits [1000.0, 877.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5079 q_vals: [-inf, -3.874, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2920 1 visits [1000.0, 878.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5080 q_vals: [-inf, -3.875, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2921 1 visits [1000.0, 879.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5081 q_vals: [-inf, -3.875, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2922 1 visits [1000.0, 880.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5086 q_vals: [-inf, -3.876, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2923 1 visits [1000.0, 881.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5087 q_vals: [-inf, -3.886, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5089, "number_of_timesteps": 92125, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2924 1 visits [1000.0, 882.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5089 q_vals: [-inf, -3.886, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2925 1 visits [1000.0, 883.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5093 q_vals: [-inf, -3.882, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2926 1 visits [1000.0, 884.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5094 q_vals: [-inf, -3.882, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2927 1 visits [1000.0, 885.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5096 q_vals: [-inf, -3.878, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2928 1 visits [1000.0, 886.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5098 q_vals: [-inf, -3.873, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5100, "number_of_timesteps": 92265, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2929 1 visits [1000.0, 887.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5100 q_vals: [-inf, -3.876, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2930 1 visits [1000.0, 888.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5101 q_vals: [-inf, -3.886, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2931 1 visits [1000.0, 889.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5105 q_vals: [-inf, -3.886, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2932 1 visits [1000.0, 890.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5106 q_vals: [-inf, -3.884, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2933 1 visits [1000.0, 891.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5107 q_vals: [-inf, -3.886, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5110, "number_of_timesteps": 92415, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2934 1 visits [1000.0, 892.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5110 q_vals: [-inf, -3.886, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2935 1 visits [1000.0, 893.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5111 q_vals: [-inf, -3.886, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2936 1 visits [1000.0, 894.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5114 q_vals: [-inf, -3.887, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2937 1 visits [1000.0, 895.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5114 q_vals: [-inf, -3.887, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2938 1 visits [1000.0, 896.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5117 q_vals: [-inf, -3.887, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2939 1 visits [1000.0, 897.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5119 q_vals: [-inf, -3.883, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5120, "number_of_timesteps": 92593, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2940 1 visits [1000.0, 898.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5120 q_vals: [-inf, -3.884, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2941 1 visits [1000.0, 899.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5121 q_vals: [-inf, -3.88, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2942 1 visits [1000.0, 900.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5122 q_vals: [-inf, -3.88, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2943 1 visits [1000.0, 901.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5125 q_vals: [-inf, -3.88, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2944 1 visits [1000.0, 902.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5126 q_vals: [-inf, -3.876, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2945 1 visits [1000.0, 903.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5127 q_vals: [-inf, -3.876, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5130, "number_of_timesteps": 92787, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2946 1 visits [1000.0, 904.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5130 q_vals: [-inf, -3.876, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2947 1 visits [1000.0, 905.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5130 q_vals: [-inf, -3.877, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2948 1 visits [1000.0, 906.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5133 q_vals: [-inf, -3.872, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2949 1 visits [1000.0, 907.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5135 q_vals: [-inf, -3.875, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2950 1 visits [1000.0, 908.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5136 q_vals: [-inf, -3.87, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2951 1 visits [1000.0, 909.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5137 q_vals: [-inf, -3.871, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2952 1 visits [1000.0, 910.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5138 q_vals: [-inf, -3.874, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2953 1 visits [1000.0, 911.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5139 q_vals: [-inf, -3.874, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5140, "number_of_timesteps": 92968, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2954 1 visits [1000.0, 912.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5140 q_vals: [-inf, -3.883, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2955 1 visits [1000.0, 913.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5142 q_vals: [-inf, -3.884, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2956 1 visits [1000.0, 914.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5143 q_vals: [-inf, -3.883, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2957 1 visits [1000.0, 915.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5145 q_vals: [-inf, -3.883, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2958 1 visits [1000.0, 916.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5146 q_vals: [-inf, -3.879, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2959 1 visits [1000.0, 917.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5146 q_vals: [-inf, -3.878, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2960 1 visits [1000.0, 918.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5147 q_vals: [-inf, -3.874, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2961 1 visits [1000.0, 919.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5147 q_vals: [-inf, -3.87, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2962 1 visits [1000.0, 920.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5148 q_vals: [-inf, -3.87, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2963 1 visits [1000.0, 921.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5149 q_vals: [-inf, -3.866, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5151, "number_of_timesteps": 93316, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2964 1 visits [1000.0, 922.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5151 q_vals: [-inf, -3.866, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2965 1 visits [1000.0, 923.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5153 q_vals: [-inf, -3.867, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2966 1 visits [1000.0, 924.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5153 q_vals: [-inf, -3.867, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2967 1 visits [1000.0, 925.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5154 q_vals: [-inf, -3.863, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2968 1 visits [1000.0, 926.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5157 q_vals: [-inf, -3.859, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2969 1 visits [1000.0, 927.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5157 q_vals: [-inf, -3.86, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5161, "number_of_timesteps": 93577, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2970 1 visits [1000.0, 928.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5161 q_vals: [-inf, -3.856, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2971 1 visits [1000.0, 929.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5162 q_vals: [-inf, -3.855, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2972 1 visits [1000.0, 930.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5163 q_vals: [-inf, -3.865, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2973 1 visits [1000.0, 931.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5166 q_vals: [-inf, -3.865, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2974 1 visits [1000.0, 932.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5167 q_vals: [-inf, -3.875, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2975 1 visits [1000.0, 933.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5169 q_vals: [-inf, -3.87, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2976 1 visits [1000.0, 934.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5170 q_vals: [-inf, -3.866, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5172, "number_of_timesteps": 93770, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2977 1 visits [1000.0, 935.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5172 q_vals: [-inf, -3.866, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2978 1 visits [1000.0, 936.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5173 q_vals: [-inf, -3.862, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2979 1 visits [1000.0, 937.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5175 q_vals: [-inf, -3.863, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2980 1 visits [1000.0, 938.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5175 q_vals: [-inf, -3.863, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2981 1 visits [1000.0, 939.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5175 q_vals: [-inf, -3.864, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2982 1 visits [1000.0, 940.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5179 q_vals: [-inf, -3.867, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2983 1 visits [1000.0, 941.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5180 q_vals: [-inf, -3.867, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2984 1 visits [1000.0, 942.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5181 q_vals: [-inf, -3.877, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2985 1 visits [1000.0, 943.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5181 q_vals: [-inf, -3.873, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5183, "number_of_timesteps": 94010, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2986 1 visits [1000.0, 944.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5183 q_vals: [-inf, -3.869, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2987 1 visits [1000.0, 945.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5185 q_vals: [-inf, -3.878, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2988 1 visits [1000.0, 946.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5185 q_vals: [-inf, -3.888, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2989 1 visits [1000.0, 947.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5188 q_vals: [-inf, -3.889, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2990 1 visits [1000.0, 948.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5189 q_vals: [-inf, -3.884, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2991 1 visits [1000.0, 949.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5190 q_vals: [-inf, -3.885, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2992 1 visits [1000.0, 950.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5191 q_vals: [-inf, -3.885, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5194, "number_of_timesteps": 94259, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2993 1 visits [1000.0, 951.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5194 q_vals: [-inf, -3.894, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2994 1 visits [1000.0, 952.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5195 q_vals: [-inf, -3.89, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2995 1 visits [1000.0, 953.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5197 q_vals: [-inf, -3.887, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2996 1 visits [1000.0, 954.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5198 q_vals: [-inf, -3.887, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2997 1 visits [1000.0, 955.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5198 q_vals: [-inf, -3.896, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 2998 1 visits [1000.0, 956.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5202 q_vals: [-inf, -3.896, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5204, "number_of_timesteps": 94502, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2999 1 visits [1000.0, 957.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5204 q_vals: [-inf, -3.897, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3000 1 visits [1000.0, 958.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5207 q_vals: [-inf, -3.898, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3001 1 visits [1000.0, 959.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5209 q_vals: [-inf, -3.894, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3002 1 visits [1000.0, 960.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5211 q_vals: [-inf, -3.895, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3003 1 visits [1000.0, 961.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5212 q_vals: [-inf, -3.891, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5214, "number_of_timesteps": 94636, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3004 1 visits [1000.0, 962.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5214 q_vals: [-inf, -3.891, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3005 1 visits [1000.0, 963.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5216 q_vals: [-inf, -3.887, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3006 1 visits [1000.0, 964.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5217 q_vals: [-inf, -3.883, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3007 1 visits [1000.0, 965.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5220 q_vals: [-inf, -3.882, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3008 1 visits [1000.0, 966.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5223 q_vals: [-inf, -3.883, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5224, "number_of_timesteps": 94812, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3009 1 visits [1000.0, 967.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5224 q_vals: [-inf, -3.883, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3010 1 visits [1000.0, 968.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5226 q_vals: [-inf, -3.886, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3011 1 visits [1000.0, 969.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5227 q_vals: [-inf, -3.887, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3012 1 visits [1000.0, 970.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5228 q_vals: [-inf, -3.883, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3013 1 visits [1000.0, 971.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5230 q_vals: [-inf, -3.883, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3014 1 visits [1000.0, 972.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5231 q_vals: [-inf, -3.879, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5234, "number_of_timesteps": 94987, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3015 1 visits [1000.0, 973.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5234 q_vals: [-inf, -3.879, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3016 1 visits [1000.0, 974.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5238 q_vals: [-inf, -3.875, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3017 1 visits [1000.0, 975.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5238 q_vals: [-inf, -3.884, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3018 1 visits [1000.0, 976.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5241 q_vals: [-inf, -3.884, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5244, "number_of_timesteps": 95140, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3019 1 visits [1000.0, 977.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5244 q_vals: [-inf, -3.883, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3020 1 visits [1000.0, 978.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5244 q_vals: [-inf, -3.883, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3021 1 visits [1000.0, 979.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5246 q_vals: [-inf, -3.883, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3022 1 visits [1000.0, 980.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5248 q_vals: [-inf, -3.886, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3023 1 visits [1000.0, 981.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5249 q_vals: [-inf, -3.887, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3024 1 visits [1000.0, 982.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5250 q_vals: [-inf, -3.888, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3025 1 visits [1000.0, 983.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5251 q_vals: [-inf, -3.893, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3026 1 visits [1000.0, 984.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5253 q_vals: [-inf, -3.894, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5254, "number_of_timesteps": 95340, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3027 1 visits [1000.0, 985.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5254 q_vals: [-inf, -3.894, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3028 1 visits [1000.0, 986.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5257 q_vals: [-inf, -3.903, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3029 1 visits [1000.0, 987.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5258 q_vals: [-inf, -3.905, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3030 1 visits [1000.0, 988.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5259 q_vals: [-inf, -3.901, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3031 1 visits [1000.0, 989.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5259 q_vals: [-inf, -3.91, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3032 1 visits [1000.0, 990.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5260 q_vals: [-inf, -3.912, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3033 1 visits [1000.0, 991.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5262 q_vals: [-inf, -3.908, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5265, "number_of_timesteps": 95597, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3034 1 visits [1000.0, 992.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5265 q_vals: [-inf, -3.907, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3035 1 visits [1000.0, 993.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5266 q_vals: [-inf, -3.908, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3036 1 visits [1000.0, 994.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5266 q_vals: [-inf, -3.917, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3037 1 visits [1000.0, 995.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5268 q_vals: [-inf, -3.913, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3038 1 visits [1000.0, 996.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5271 q_vals: [-inf, -3.915, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3039 1 visits [1000.0, 997.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5272 q_vals: [-inf, -3.918, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3040 1 visits [1000.0, 998.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5274 q_vals: [-inf, -3.927, -6.4, -5.293, -6.754, -4.916, -4.288]
{"total_number_of_episodes": 5275, "number_of_timesteps": 95806, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3041 1 visits [1000.0, 999.0, 2.0, 5.0, 4.0, 11.0, 289.0]  episode_count: 5275 q_vals: [-inf, -3.926, -6.4, -5.293, -6.754, -4.916, -4.288]
Step 3042 1 visits [1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 5277 q_vals: [-inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 3043 2 visits [1000.0, 1000.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 5277 q_vals: [-inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 3044 3 visits [1000.0, 1000.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 5277 q_vals: [-inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 3045 4 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 5279 q_vals: [-inf, -inf, 0.0, 0.0, -4.042, 0.0, 0.0]
Step 3046 5 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 5281 q_vals: [-inf, -inf, 0.0, 0.0, -4.042, -4.018, 0.0]
Step 3047 6 visits [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 5282 q_vals: [-inf, -inf, 0.0, 0.0, -4.042, -4.018, 0.0]
{"total_number_of_episodes": 5285, "number_of_timesteps": 96047, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.023809523809523826, "biggest_recent_change": 2.142857142857144},
Step 3048 2 visits [1000.0, 1000.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 5285 q_vals: [-inf, -inf, -2.405, 0.0, -4.042, -4.018, 0.0]
Step 3049 3 visits [1000.0, 1000.0, 2.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 5288 q_vals: [-inf, -inf, -2.405, 0.0, -4.042, -4.018, 0.0]
Step 3050 6 visits [1000.0, 1000.0, 2.0, 2.0, 1.0, 1.0, 2.0]  episode_count: 5289 q_vals: [-inf, -inf, -2.405, 0.0, -4.042, -4.018, -2.415]
Step 3051 3 visits [1000.0, 1000.0, 2.0, 3.0, 1.0, 1.0, 2.0]  episode_count: 5291 q_vals: [-inf, -inf, -2.405, 0.0, -4.042, -4.018, -2.415]
{"total_number_of_episodes": 5295, "number_of_timesteps": 96201, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.023809523809523826, "biggest_recent_change": 2.142857142857144},
Step 3052 3 visits [1000.0, 1000.0, 2.0, 4.0, 1.0, 1.0, 2.0]  episode_count: 5295 q_vals: [-inf, -inf, -2.405, -1.105, -4.042, -4.018, -2.415]
Step 3053 3 visits [1000.0, 1000.0, 2.0, 5.0, 1.0, 1.0, 2.0]  episode_count: 5295 q_vals: [-inf, -inf, -2.405, -1.768, -4.042, -4.018, -2.415]
Step 3054 3 visits [1000.0, 1000.0, 2.0, 6.0, 1.0, 1.0, 2.0]  episode_count: 5297 q_vals: [-inf, -inf, -2.405, -1.473, -4.042, -4.018, -2.415]
Step 3055 3 visits [1000.0, 1000.0, 2.0, 7.0, 1.0, 1.0, 2.0]  episode_count: 5302 q_vals: [-inf, -inf, -2.405, -1.902, -4.042, -4.018, -2.415]
Step 3056 2 visits [1000.0, 1000.0, 3.0, 7.0, 1.0, 1.0, 2.0]  episode_count: 5302 q_vals: [-inf, -inf, -2.953, -1.902, -4.042, -4.018, -2.415]
Step 3057 6 visits [1000.0, 1000.0, 3.0, 7.0, 1.0, 1.0, 3.0]  episode_count: 5304 q_vals: [-inf, -inf, -2.953, -1.902, -4.042, -4.018, -3.035]
{"total_number_of_episodes": 5307, "number_of_timesteps": 96364, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.023809523809523826, "biggest_recent_change": 2.142857142857144},
Step 3058 3 visits [1000.0, 1000.0, 3.0, 8.0, 1.0, 1.0, 3.0]  episode_count: 5307 q_vals: [-inf, -inf, -2.953, -2.166, -4.042, -4.018, -3.035]
Step 3059 3 visits [1000.0, 1000.0, 3.0, 9.0, 1.0, 1.0, 3.0]  episode_count: 5309 q_vals: [-inf, -inf, -2.953, -2.415, -4.042, -4.018, -3.035]
Step 3060 3 visits [1000.0, 1000.0, 3.0, 10.0, 1.0, 1.0, 3.0]  episode_count: 5311 q_vals: [-inf, -inf, -2.953, -2.173, -4.042, -4.018, -3.035]
Step 3061 3 visits [1000.0, 1000.0, 3.0, 11.0, 1.0, 1.0, 3.0]  episode_count: 5315 q_vals: [-inf, -inf, -2.953, -2.343, -4.042, -4.018, -3.035]
Step 3062 3 visits [1000.0, 1000.0, 3.0, 12.0, 1.0, 1.0, 3.0]  episode_count: 5316 q_vals: [-inf, -inf, -2.953, -2.148, -4.042, -4.018, -3.035]
{"total_number_of_episodes": 5319, "number_of_timesteps": 96528, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.023809523809523826, "biggest_recent_change": 2.142857142857144},
Step 3063 3 visits [1000.0, 1000.0, 3.0, 13.0, 1.0, 1.0, 3.0]  episode_count: 5319 q_vals: [-inf, -inf, -2.953, -2.336, -4.042, -4.018, -3.035]
Step 3064 3 visits [1000.0, 1000.0, 3.0, 14.0, 1.0, 1.0, 3.0]  episode_count: 5322 q_vals: [-inf, -inf, -2.953, -2.169, -4.042, -4.018, -3.035]
Step 3065 3 visits [1000.0, 1000.0, 3.0, 15.0, 1.0, 1.0, 3.0]  episode_count: 5322 q_vals: [-inf, -inf, -2.953, -3.025, -4.042, -4.018, -3.035]
Step 3066 2 visits [1000.0, 1000.0, 4.0, 15.0, 1.0, 1.0, 3.0]  episode_count: 5327 q_vals: [-inf, -inf, -3.253, -3.025, -4.042, -4.018, -3.035]
{"total_number_of_episodes": 5329, "number_of_timesteps": 96654, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.023809523809523826, "biggest_recent_change": 2.142857142857144},
Step 3067 6 visits [1000.0, 1000.0, 4.0, 15.0, 1.0, 1.0, 4.0]  episode_count: 5329 q_vals: [-inf, -inf, -3.253, -3.025, -4.042, -4.018, -3.317]
Step 3068 5 visits [1000.0, 1000.0, 4.0, 15.0, 1.0, 2.0, 4.0]  episode_count: 5329 q_vals: [-inf, -inf, -3.253, -3.025, -4.042, -2.009, -3.317]
Step 3069 5 visits [1000.0, 1000.0, 4.0, 15.0, 1.0, 3.0, 4.0]  episode_count: 5334 q_vals: [-inf, -inf, -3.253, -3.025, -4.042, -1.339, -3.317]
Step 3070 5 visits [1000.0, 1000.0, 4.0, 15.0, 1.0, 4.0, 4.0]  episode_count: 5336 q_vals: [-inf, -inf, -3.253, -3.025, -4.042, -1.004, -3.317]
Step 3071 5 visits [1000.0, 1000.0, 4.0, 15.0, 1.0, 5.0, 4.0]  episode_count: 5337 q_vals: [-inf, -inf, -3.253, -3.025, -4.042, -1.66, -3.317]
{"total_number_of_episodes": 5341, "number_of_timesteps": 96798, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.023809523809523826, "biggest_recent_change": 2.142857142857144},
Step 3072 5 visits [1000.0, 1000.0, 4.0, 15.0, 1.0, 6.0, 4.0]  episode_count: 5341 q_vals: [-inf, -inf, -3.253, -3.025, -4.042, -2.122, -3.317]
Step 3073 5 visits [1000.0, 1000.0, 4.0, 15.0, 1.0, 7.0, 4.0]  episode_count: 5343 q_vals: [-inf, -inf, -3.253, -3.025, -4.042, -2.511, -3.317]
Step 3074 5 visits [1000.0, 1000.0, 4.0, 15.0, 1.0, 8.0, 4.0]  episode_count: 5344 q_vals: [-inf, -inf, -3.253, -3.025, -4.042, -2.197, -3.317]
Step 3075 5 visits [1000.0, 1000.0, 4.0, 15.0, 1.0, 9.0, 4.0]  episode_count: 5347 q_vals: [-inf, -inf, -3.253, -3.025, -4.042, -2.453, -3.317]
Step 3076 5 visits [1000.0, 1000.0, 4.0, 15.0, 1.0, 10.0, 4.0]  episode_count: 5349 q_vals: [-inf, -inf, -3.253, -3.025, -4.042, -2.855, -3.317]
Step 3077 4 visits [1000.0, 1000.0, 4.0, 15.0, 2.0, 10.0, 4.0]  episode_count: 5350 q_vals: [-inf, -inf, -3.253, -3.025, -2.021, -2.855, -3.317]
{"total_number_of_episodes": 5354, "number_of_timesteps": 96969, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.023809523809523826, "biggest_recent_change": 2.142857142857144},
Step 3078 4 visits [1000.0, 1000.0, 4.0, 15.0, 3.0, 10.0, 4.0]  episode_count: 5354 q_vals: [-inf, -inf, -3.253, -3.025, -2.746, -2.855, -3.317]
Step 3079 4 visits [1000.0, 1000.0, 4.0, 15.0, 4.0, 10.0, 4.0]  episode_count: 5354 q_vals: [-inf, -inf, -3.253, -3.025, -5.81, -2.855, -3.317]
Step 3080 5 visits [1000.0, 1000.0, 4.0, 15.0, 4.0, 11.0, 4.0]  episode_count: 5359 q_vals: [-inf, -inf, -3.253, -3.025, -5.81, -3.057, -3.317]
Step 3081 2 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 11.0, 4.0]  episode_count: 5359 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.057, -3.317]
Step 3082 6 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 11.0, 5.0]  episode_count: 5360 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.057, -2.653]
{"total_number_of_episodes": 5365, "number_of_timesteps": 97133, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.023809523809523826, "biggest_recent_change": 2.142857142857144},
Step 3083 6 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 11.0, 6.0]  episode_count: 5365 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.057, -2.933]
Step 3084 6 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 11.0, 7.0]  episode_count: 5366 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.057, -2.514]
Step 3085 6 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 11.0, 8.0]  episode_count: 5367 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.057, -2.2]
Step 3086 6 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 11.0, 9.0]  episode_count: 5371 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.057, -2.579]
Step 3087 6 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 11.0, 10.0]  episode_count: 5373 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.057, -2.749]
{"total_number_of_episodes": 5375, "number_of_timesteps": 97276, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.023809523809523826, "biggest_recent_change": 2.142857142857144},
Step 3088 6 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 11.0, 11.0]  episode_count: 5375 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.057, -2.898]
Step 3089 6 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 11.0, 12.0]  episode_count: 5377 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.057, -3.017]
Step 3090 6 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 11.0, 13.0]  episode_count: 5379 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.057, -2.785]
Step 3091 6 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 11.0, 14.0]  episode_count: 5381 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.057, -2.958]
Step 3092 6 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 11.0, 15.0]  episode_count: 5383 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.057, -2.761]
{"total_number_of_episodes": 5386, "number_of_timesteps": 97433, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3093 6 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 11.0, 16.0]  episode_count: 5386 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.057, -2.945]
Step 3094 6 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 11.0, 17.0]  episode_count: 5388 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.057, -3.654]
Step 3095 5 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 12.0, 17.0]  episode_count: 5389 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -2.802, -3.654]
Step 3096 5 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 13.0, 17.0]  episode_count: 5392 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -2.989, -3.654]
Step 3097 5 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 14.0, 17.0]  episode_count: 5393 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -2.776, -3.654]
{"total_number_of_episodes": 5397, "number_of_timesteps": 97595, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3098 5 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 15.0, 17.0]  episode_count: 5397 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -2.995, -3.654]
Step 3099 5 visits [1000.0, 1000.0, 5.0, 15.0, 4.0, 16.0, 17.0]  episode_count: 5399 q_vals: [-inf, -inf, -3.532, -3.025, -5.81, -3.123, -3.654]
visits [1000.0, 1000.0, 5.0, 16.0, 4.0, 16.0, 17.0]  episode_count: 5401 q_vals: [-inf, -inf, -3.532, -3.186, -5.81, -3.123, -3.654]
Step 3101 5 visits [1000.0, 1000.0, 5.0, 16.0, 4.0, 17.0, 17.0]  episode_count: 5404 q_vals: [-inf, -inf, -3.532, -3.186, -5.81, -3.397, -3.654]
Step 3102 2 visits [1000.0, 1000.0, 6.0, 16.0, 4.0, 17.0, 17.0]  episode_count: 5406 q_vals: [-inf, -inf, -2.943, -3.186, -5.81, -3.397, -3.654]
{"total_number_of_episodes": 5407, "number_of_timesteps": 97713, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3103 2 visits [1000.0, 1000.0, 7.0, 16.0, 4.0, 17.0, 17.0]  episode_count: 5407 q_vals: [-inf, -inf, -4.666, -3.186, -5.81, -3.397, -3.654]
Step 3104 3 visits [1000.0, 1000.0, 7.0, 17.0, 4.0, 17.0, 17.0]  episode_count: 5411 q_vals: [-inf, -inf, -4.666, -2.999, -5.81, -3.397, -3.654]
Step 3105 3 visits [1000.0, 1000.0, 7.0, 18.0, 4.0, 17.0, 17.0]  episode_count: 5413 q_vals: [-inf, -inf, -4.666, -2.832, -5.81, -3.397, -3.654]
Step 3106 3 visits [1000.0, 1000.0, 7.0, 19.0, 4.0, 17.0, 17.0]  episode_count: 5414 q_vals: [-inf, -inf, -4.666, -2.985, -5.81, -3.397, -3.654]
Step 3107 3 visits [1000.0, 1000.0, 7.0, 20.0, 4.0, 17.0, 17.0]  episode_count: 5415 q_vals: [-inf, -inf, -4.666, -3.064, -5.81, -3.397, -3.654]
{"total_number_of_episodes": 5418, "number_of_timesteps": 97877, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3108 3 visits [1000.0, 1000.0, 7.0, 21.0, 4.0, 17.0, 17.0]  episode_count: 5418 q_vals: [-inf, -inf, -4.666, -3.129, -5.81, -3.397, -3.654]
Step 3109 3 visits [1000.0, 1000.0, 7.0, 22.0, 4.0, 17.0, 17.0]  episode_count: 5420 q_vals: [-inf, -inf, -4.666, -3.21, -5.81, -3.397, -3.654]
Step 3110 3 visits [1000.0, 1000.0, 7.0, 23.0, 4.0, 17.0, 17.0]  episode_count: 5422 q_vals: [-inf, -inf, -4.666, -3.264, -5.81, -3.397, -3.654]
Step 3111 3 visits [1000.0, 1000.0, 7.0, 24.0, 4.0, 17.0, 17.0]  episode_count: 5423 q_vals: [-inf, -inf, -4.666, -3.33, -5.81, -3.397, -3.654]
Step 3112 5 visits [1000.0, 1000.0, 7.0, 24.0, 4.0, 18.0, 17.0]  episode_count: 5425 q_vals: [-inf, -inf, -4.666, -3.33, -5.81, -3.208, -3.654]
Step 3113 5 visits [1000.0, 1000.0, 7.0, 24.0, 4.0, 19.0, 17.0]  episode_count: 5427 q_vals: [-inf, -inf, -4.666, -3.33, -5.81, -3.294, -3.654]
{"total_number_of_episodes": 5429, "number_of_timesteps": 98072, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3114 5 visits [1000.0, 1000.0, 7.0, 24.0, 4.0, 20.0, 17.0]  episode_count: 5429 q_vals: [-inf, -inf, -4.666, -3.33, -5.81, -3.378, -3.654]
Step 3115 3 visits [1000.0, 1000.0, 7.0, 25.0, 4.0, 20.0, 17.0]  episode_count: 5429 q_vals: [-inf, -inf, -4.666, -3.197, -5.81, -3.378, -3.654]
Step 3116 3 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 20.0, 17.0]  episode_count: 5431 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.378, -3.654]
Step 3117 5 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 21.0, 17.0]  episode_count: 5435 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.449, -3.654]
Step 3118 5 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 22.0, 17.0]  episode_count: 5437 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.518, -3.654]
Step 3119 5 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 23.0, 17.0]  episode_count: 5438 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.365, -3.654]
{"total_number_of_episodes": 5440, "number_of_timesteps": 98247, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3120 5 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 24.0, 17.0]  episode_count: 5440 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.511, -3.654]
Step 3121 5 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 25.0, 17.0]  episode_count: 5441 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.562, -3.654]
Step 3122 5 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 26.0, 17.0]  episode_count: 5442 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.425, -3.654]
Step 3123 5 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 27.0, 17.0]  episode_count: 5443 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.481, -3.654]
Step 3124 5 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 28.0, 17.0]  episode_count: 5447 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.537, -3.654]
Step 3125 5 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 17.0]  episode_count: 5447 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.654]
Step 3126 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 18.0]  episode_count: 5449 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.451]
{"total_number_of_episodes": 5450, "number_of_timesteps": 98451, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3127 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 19.0]  episode_count: 5450 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.27]
Step 3128 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 20.0]  episode_count: 5453 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.344]
Step 3129 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 21.0]  episode_count: 5455 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.448]
Step 3130 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 22.0]  episode_count: 5457 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.542]
{"total_number_of_episodes": 5461, "number_of_timesteps": 98619, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3131 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 23.0]  episode_count: 5461 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.388]
Step 3132 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 24.0]  episode_count: 5463 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.478]
Step 3133 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 25.0]  episode_count: 5464 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.339]
Step 3134 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 26.0]  episode_count: 5467 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.21]
Step 3135 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 27.0]  episode_count: 5468 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.281]
{"total_number_of_episodes": 5471, "number_of_timesteps": 98749, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3136 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 28.0]  episode_count: 5471 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.164]
Step 3137 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 29.0]  episode_count: 5472 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.253]
Step 3138 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 30.0]  episode_count: 5473 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.144]
Step 3139 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 31.0]  episode_count: 5474 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.043]
Step 3140 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 32.0]  episode_count: 5478 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -2.948]
Step 3141 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 33.0]  episode_count: 5479 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.027]
{"total_number_of_episodes": 5481, "number_of_timesteps": 98921, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3142 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 34.0]  episode_count: 5481 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.089]
Step 3143 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 35.0]  episode_count: 5483 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.148]
Step 3144 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 36.0]  episode_count: 5483 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.06]
Step 3145 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 37.0]  episode_count: 5486 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.105]
Step 3146 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 38.0]  episode_count: 5487 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.139]
Step 3147 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 39.0]  episode_count: 5487 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.261]
Step 3148 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 40.0]  episode_count: 5490 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.291]
Step 3149 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 41.0]  episode_count: 5490 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.277]
{"total_number_of_episodes": 5491, "number_of_timesteps": 99158, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3150 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 42.0]  episode_count: 5491 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.318]
Step 3151 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 43.0]  episode_count: 5493 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.341]
Step 3152 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 44.0]  episode_count: 5494 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.266]
Step 3153 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 45.0]  episode_count: 5495 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.238]
Step 3154 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 46.0]  episode_count: 5498 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.227]
Step 3155 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 47.0]  episode_count: 5499 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.159]
{"total_number_of_episodes": 5501, "number_of_timesteps": 99401, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3156 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 48.0]  episode_count: 5501 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.215]
Step 3157 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 49.0]  episode_count: 5504 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.237]
Step 3158 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 50.0]  episode_count: 5504 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.267]
Step 3159 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 51.0]  episode_count: 5505 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.29]
Step 3160 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 52.0]  episode_count: 5506 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.227]
Step 3161 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 53.0]  episode_count: 5509 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.166]
Step 3162 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 54.0]  episode_count: 5510 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.214]
{"total_number_of_episodes": 5511, "number_of_timesteps": 99593, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3163 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 55.0]  episode_count: 5511 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.156]
Step 3164 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 56.0]  episode_count: 5513 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.18]
Step 3165 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 57.0]  episode_count: 5515 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.387]
Step 3166 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 58.0]  episode_count: 5518 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.416]
Step 3167 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 59.0]  episode_count: 5519 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.358]
Step 3168 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 60.0]  episode_count: 5519 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.302]
{"total_number_of_episodes": 5523, "number_of_timesteps": 99835, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3169 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 61.0]  episode_count: 5523 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.321]
Step 3170 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 62.0]  episode_count: 5526 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.267]
Step 3171 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 63.0]  episode_count: 5526 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.215]
Step 3172 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 64.0]  episode_count: 5528 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.253]
Step 3173 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 65.0]  episode_count: 5531 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.263]
Step 3174 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 66.0]  episode_count: 5531 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.308]
Step 3175 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 67.0]  episode_count: 5532 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.259]
{"total_number_of_episodes": 5533, "number_of_timesteps": 99989, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3176 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 68.0]  episode_count: 5533 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.211]
Step 3177 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 69.0]  episode_count: 5536 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.164]
Step 3178 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 70.0]  episode_count: 5538 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.119]
Step 3179 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 71.0]  episode_count: 5539 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.075]
Step 3180 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 72.0]  episode_count: 5540 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.033]
Step 3181 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 73.0]  episode_count: 5542 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.044]
{"total_number_of_episodes": 5543, "number_of_timesteps": 100172, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3182 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 74.0]  episode_count: 5543 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.002]
Step 3183 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 75.0]  episode_count: 5546 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.053]
Step 3184 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 76.0]  episode_count: 5546 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.013]
Step 3185 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 77.0]  episode_count: 5547 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.05]
Step 3186 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 78.0]  episode_count: 5550 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.067]
Step 3187 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 79.0]  episode_count: 5551 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.087]
Step 3188 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 80.0]  episode_count: 5552 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.236]
{"total_number_of_episodes": 5555, "number_of_timesteps": 100453, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3189 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 81.0]  episode_count: 5555 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.226]
Step 3190 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 82.0]  episode_count: 5556 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.187]
Step 3191 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 83.0]  episode_count: 5557 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.148]
Step 3192 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 84.0]  episode_count: 5557 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.289]
Step 3193 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 29.0, 85.0]  episode_count: 5559 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.587, -3.427]
Step 3194 5 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 30.0, 85.0]  episode_count: 5560 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.611, -3.427]
Step 3195 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 30.0, 86.0]  episode_count: 5561 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.611, -3.437]
Step 3196 6 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 30.0, 87.0]  episode_count: 5561 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.611, -3.465]
Step 3197 5 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 31.0, 87.0]  episode_count: 5563 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.495, -3.465]
{"total_number_of_episodes": 5565, "number_of_timesteps": 100674, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3198 5 visits [1000.0, 1000.0, 7.0, 26.0, 4.0, 32.0, 87.0]  episode_count: 5565 q_vals: [-inf, -inf, -4.666, -3.651, -5.81, -3.854, -3.465]
Step 3199 3 visits [1000.0, 1000.0, 7.0, 27.0, 4.0, 32.0, 87.0]  episode_count: 5567 q_vals: [-inf, -inf, -4.666, -3.516, -5.81, -3.854, -3.465]
Step 3200 3 visits [1000.0, 1000.0, 7.0, 28.0, 4.0, 32.0, 87.0]  episode_count: 5569 q_vals: [-inf, -inf, -4.666, -3.39, -5.81, -3.854, -3.465]
Step 3201 3 visits [1000.0, 1000.0, 7.0, 29.0, 4.0, 32.0, 87.0]  episode_count: 5572 q_vals: [-inf, -inf, -4.666, -3.273, -5.81, -3.854, -3.465]
Step 3202 3 visits [1000.0, 1000.0, 7.0, 30.0, 4.0, 32.0, 87.0]  episode_count: 5572 q_vals: [-inf, -inf, -4.666, -3.164, -5.81, -3.854, -3.465]
Step 3203 3 visits [1000.0, 1000.0, 7.0, 31.0, 4.0, 32.0, 87.0]  episode_count: 5574 q_vals: [-inf, -inf, -4.666, -3.2, -5.81, -3.854, -3.465]
{"total_number_of_episodes": 5576, "number_of_timesteps": 100908, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3204 3 visits [1000.0, 1000.0, 7.0, 32.0, 4.0, 32.0, 87.0]  episode_count: 5576 q_vals: [-inf, -inf, -4.666, -3.1, -5.81, -3.854, -3.465]
Step 3205 3 visits [1000.0, 1000.0, 7.0, 33.0, 4.0, 32.0, 87.0]  episode_count: 5576 q_vals: [-inf, -inf, -4.666, -3.151, -5.81, -3.854, -3.465]
Step 3206 3 visits [1000.0, 1000.0, 7.0, 34.0, 4.0, 32.0, 87.0]  episode_count: 5578 q_vals: [-inf, -inf, -4.666, -3.183, -5.81, -3.854, -3.465]
Step 3207 3 visits [1000.0, 1000.0, 7.0, 35.0, 4.0, 32.0, 87.0]  episode_count: 5583 q_vals: [-inf, -inf, -4.666, -3.093, -5.81, -3.854, -3.465]
Step 3208 3 visits [1000.0, 1000.0, 7.0, 36.0, 4.0, 32.0, 87.0]  episode_count: 5583 q_vals: [-inf, -inf, -4.666, -3.126, -5.81, -3.854, -3.465]
Step 3209 3 visits [1000.0, 1000.0, 7.0, 37.0, 4.0, 32.0, 87.0]  episode_count: 5583 q_vals: [-inf, -inf, -4.666, -3.447, -5.81, -3.854, -3.465]
{"total_number_of_episodes": 5589, "number_of_timesteps": 101161, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3210 3 visits [1000.0, 1000.0, 7.0, 38.0, 4.0, 32.0, 87.0]  episode_count: 5589 q_vals: [-inf, -inf, -4.666, -3.356, -5.81, -3.854, -3.465]
Step 3211 3 visits [1000.0, 1000.0, 7.0, 39.0, 4.0, 32.0, 87.0]  episode_count: 5590 q_vals: [-inf, -inf, -4.666, -3.414, -5.81, -3.854, -3.465]
Step 3212 3 visits [1000.0, 1000.0, 7.0, 40.0, 4.0, 32.0, 87.0]  episode_count: 5590 q_vals: [-inf, -inf, -4.666, -3.477, -5.81, -3.854, -3.465]
Step 3213 3 visits [1000.0, 1000.0, 7.0, 41.0, 4.0, 32.0, 87.0]  episode_count: 5592 q_vals: [-inf, -inf, -4.666, -3.392, -5.81, -3.854, -3.465]
Step 3214 3 visits [1000.0, 1000.0, 7.0, 42.0, 4.0, 32.0, 87.0]  episode_count: 5595 q_vals: [-inf, -inf, -4.666, -3.429, -5.81, -3.854, -3.465]
Step 3215 3 visits [1000.0, 1000.0, 7.0, 43.0, 4.0, 32.0, 87.0]  episode_count: 5596 q_vals: [-inf, -inf, -4.666, -3.349, -5.81, -3.854, -3.465]
Step 3216 3 visits [1000.0, 1000.0, 7.0, 44.0, 4.0, 32.0, 87.0]  episode_count: 5597 q_vals: [-inf, -inf, -4.666, -3.467, -5.81, -3.854, -3.465]
{"total_number_of_episodes": 5599, "number_of_timesteps": 101325, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3217 3 visits [1000.0, 1000.0, 7.0, 45.0, 4.0, 32.0, 87.0]  episode_count: 5599 q_vals: [-inf, -inf, -4.666, -3.39, -5.81, -3.854, -3.465]
Step 3218 3 visits [1000.0, 1000.0, 7.0, 46.0, 4.0, 32.0, 87.0]  episode_count: 5599 q_vals: [-inf, -inf, -4.666, -3.458, -5.81, -3.854, -3.465]
Step 3219 3 visits [1000.0, 1000.0, 7.0, 47.0, 4.0, 32.0, 87.0]  episode_count: 5602 q_vals: [-inf, -inf, -4.666, -3.471, -5.81, -3.854, -3.465]
Step 3220 3 visits [1000.0, 1000.0, 7.0, 48.0, 4.0, 32.0, 87.0]  episode_count: 5602 q_vals: [-inf, -inf, -4.666, -3.502, -5.81, -3.854, -3.465]
Step 3221 3 visits [1000.0, 1000.0, 7.0, 49.0, 4.0, 32.0, 87.0]  episode_count: 5605 q_vals: [-inf, -inf, -4.666, -3.431, -5.81, -3.854, -3.465]
Step 3222 3 visits [1000.0, 1000.0, 7.0, 50.0, 4.0, 32.0, 87.0]  episode_count: 5607 q_vals: [-inf, -inf, -4.666, -3.446, -5.81, -3.854, -3.465]
Step 3223 3 visits [1000.0, 1000.0, 7.0, 51.0, 4.0, 32.0, 87.0]  episode_count: 5607 q_vals: [-inf, -inf, -4.666, -3.379, -5.81, -3.854, -3.465]
{"total_number_of_episodes": 5609, "number_of_timesteps": 101532, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3224 3 visits [1000.0, 1000.0, 7.0, 52.0, 4.0, 32.0, 87.0]  episode_count: 5609 q_vals: [-inf, -inf, -4.666, -3.396, -5.81, -3.854, -3.465]
Step 3225 3 visits [1000.0, 1000.0, 7.0, 53.0, 4.0, 32.0, 87.0]  episode_count: 5612 q_vals: [-inf, -inf, -4.666, -3.332, -5.81, -3.854, -3.465]
Step 3226 3 visits [1000.0, 1000.0, 7.0, 54.0, 4.0, 32.0, 87.0]  episode_count: 5613 q_vals: [-inf, -inf, -4.666, -3.271, -5.81, -3.854, -3.465]
Step 3227 3 visits [1000.0, 1000.0, 7.0, 55.0, 4.0, 32.0, 87.0]  episode_count: 5616 q_vals: [-inf, -inf, -4.666, -3.484, -5.81, -3.854, -3.465]
Step 3228 3 visits [1000.0, 1000.0, 7.0, 56.0, 4.0, 32.0, 87.0]  episode_count: 5618 q_vals: [-inf, -inf, -4.666, -3.532, -5.81, -3.854, -3.465]
{"total_number_of_episodes": 5619, "number_of_timesteps": 101731, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3229 6 visits [1000.0, 1000.0, 7.0, 56.0, 4.0, 32.0, 88.0]  episode_count: 5619 q_vals: [-inf, -inf, -4.666, -3.532, -5.81, -3.854, -3.478]
Step 3230 3 visits [1000.0, 1000.0, 7.0, 57.0, 4.0, 32.0, 88.0]  episode_count: 5620 q_vals: [-inf, -inf, -4.666, -3.47, -5.81, -3.854, -3.478]
Step 3231 3 visits [1000.0, 1000.0, 7.0, 58.0, 4.0, 32.0, 88.0]  episode_count: 5623 q_vals: [-inf, -inf, -4.666, -3.513, -5.81, -3.854, -3.478]
Step 3232 3 visits [1000.0, 1000.0, 7.0, 59.0, 4.0, 32.0, 88.0]  episode_count: 5625 q_vals: [-inf, -inf, -4.666, -3.525, -5.81, -3.854, -3.478]
Step 3233 3 visits [1000.0, 1000.0, 7.0, 60.0, 4.0, 32.0, 88.0]  episode_count: 5627 q_vals: [-inf, -inf, -4.666, -3.538, -5.81, -3.854, -3.478]
{"total_number_of_episodes": 5630, "number_of_timesteps": 101911, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3234 6 visits [1000.0, 1000.0, 7.0, 60.0, 4.0, 32.0, 89.0]  episode_count: 5630 q_vals: [-inf, -inf, -4.666, -3.538, -5.81, -3.854, -3.607]
Step 3235 3 visits [1000.0, 1000.0, 7.0, 61.0, 4.0, 32.0, 89.0]  episode_count: 5633 q_vals: [-inf, -inf, -4.666, -3.562, -5.81, -3.854, -3.607]
Step 3236 3 visits [1000.0, 1000.0, 7.0, 62.0, 4.0, 32.0, 89.0]  episode_count: 5633 q_vals: [-inf, -inf, -4.666, -3.573, -5.81, -3.854, -3.607]
Step 3237 3 visits [1000.0, 1000.0, 7.0, 63.0, 4.0, 32.0, 89.0]  episode_count: 5637 q_vals: [-inf, -inf, -4.666, -3.584, -5.81, -3.854, -3.607]
Step 3238 3 visits [1000.0, 1000.0, 7.0, 64.0, 4.0, 32.0, 89.0]  episode_count: 5638 q_vals: [-inf, -inf, -4.666, -3.594, -5.81, -3.854, -3.607]
{"total_number_of_episodes": 5640, "number_of_timesteps": 102057, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3239 3 visits [1000.0, 1000.0, 7.0, 65.0, 4.0, 32.0, 89.0]  episode_count: 5640 q_vals: [-inf, -inf, -4.666, -3.638, -5.81, -3.854, -3.607]
Step 3240 3 visits [1000.0, 1000.0, 7.0, 66.0, 4.0, 32.0, 89.0]  episode_count: 5644 q_vals: [-inf, -inf, -4.666, -3.583, -5.81, -3.854, -3.607]
Step 3241 3 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 32.0, 89.0]  episode_count: 5645 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.854, -3.607]
Step 3242 6 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 32.0, 90.0]  episode_count: 5646 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.854, -3.632]
Step 3243 6 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 32.0, 91.0]  episode_count: 5647 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.854, -3.592]
Step 3244 6 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 32.0, 92.0]  episode_count: 5649 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.854, -3.616]
{"total_number_of_episodes": 5651, "number_of_timesteps": 102222, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3245 6 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 32.0, 93.0]  episode_count: 5651 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.854, -3.577]
Step 3246 6 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 32.0, 94.0]  episode_count: 5651 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.854, -3.584]
Step 3247 6 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 32.0, 95.0]  episode_count: 5652 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.854, -3.704]
Step 3248 5 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 33.0, 95.0]  episode_count: 5655 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.738, -3.704]
Step 3249 5 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 34.0, 95.0]  episode_count: 5656 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.628, -3.704]
Step 3250 5 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 35.0, 95.0]  episode_count: 5658 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.524, -3.704]
Step 3251 5 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 36.0, 95.0]  episode_count: 5660 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.514, -3.704]
{"total_number_of_episodes": 5661, "number_of_timesteps": 102410, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3252 5 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 37.0, 95.0]  episode_count: 5661 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.54, -3.704]
Step 3253 5 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 38.0, 95.0]  episode_count: 5663 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.447, -3.704]
Step 3254 5 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 39.0, 95.0]  episode_count: 5665 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.743, -3.704]
Step 3255 5 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 40.0, 95.0]  episode_count: 5666 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.65, -3.704]
Step 3256 5 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 41.0, 95.0]  episode_count: 5667 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.677, -3.704]
Step 3257 5 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 42.0, 95.0]  episode_count: 5670 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.871, -3.704]
{"total_number_of_episodes": 5671, "number_of_timesteps": 102638, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3258 6 visits [1000.0, 1000.0, 7.0, 67.0, 4.0, 42.0, 96.0]  episode_count: 5671 q_vals: [-inf, -inf, -4.666, -3.753, -5.81, -3.871, -3.727]
Step 3259 3 visits [1000.0, 1000.0, 7.0, 68.0, 4.0, 42.0, 96.0]  episode_count: 5671 q_vals: [-inf, -inf, -4.666, -3.698, -5.81, -3.871, -3.727]
Step 3260 3 visits [1000.0, 1000.0, 7.0, 69.0, 4.0, 42.0, 96.0]  episode_count: 5674 q_vals: [-inf, -inf, -4.666, -3.645, -5.81, -3.871, -3.727]
Step 3261 3 visits [1000.0, 1000.0, 7.0, 70.0, 4.0, 42.0, 96.0]  episode_count: 5676 q_vals: [-inf, -inf, -4.666, -3.592, -5.81, -3.871, -3.727]
Step 3262 3 visits [1000.0, 1000.0, 7.0, 71.0, 4.0, 42.0, 96.0]  episode_count: 5676 q_vals: [-inf, -inf, -4.666, -3.601, -5.81, -3.871, -3.727]
Step 3263 3 visits [1000.0, 1000.0, 7.0, 72.0, 4.0, 42.0, 96.0]  episode_count: 5677 q_vals: [-inf, -inf, -4.666, -3.551, -5.81, -3.871, -3.727]
Step 3264 3 visits [1000.0, 1000.0, 7.0, 73.0, 4.0, 42.0, 96.0]  episode_count: 5678 q_vals: [-inf, -inf, -4.666, -3.561, -5.81, -3.871, -3.727]
{"total_number_of_episodes": 5681, "number_of_timesteps": 102850, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3265 3 visits [1000.0, 1000.0, 7.0, 74.0, 4.0, 42.0, 96.0]  episode_count: 5681 q_vals: [-inf, -inf, -4.666, -3.567, -5.81, -3.871, -3.727]
Step 3266 3 visits [1000.0, 1000.0, 7.0, 75.0, 4.0, 42.0, 96.0]  episode_count: 5683 q_vals: [-inf, -inf, -4.666, -3.52, -5.81, -3.871, -3.727]
Step 3267 3 visits [1000.0, 1000.0, 7.0, 76.0, 4.0, 42.0, 96.0]  episode_count: 5683 q_vals: [-inf, -inf, -4.666, -3.53, -5.81, -3.871, -3.727]
Step 3268 3 visits [1000.0, 1000.0, 7.0, 77.0, 4.0, 42.0, 96.0]  episode_count: 5686 q_vals: [-inf, -inf, -4.666, -3.484, -5.81, -3.871, -3.727]
Step 3269 3 visits [1000.0, 1000.0, 7.0, 78.0, 4.0, 42.0, 96.0]  episode_count: 5688 q_vals: [-inf, -inf, -4.666, -3.439, -5.81, -3.871, -3.727]
{"total_number_of_episodes": 5691, "number_of_timesteps": 103048, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3270 3 visits [1000.0, 1000.0, 7.0, 79.0, 4.0, 42.0, 96.0]  episode_count: 5691 q_vals: [-inf, -inf, -4.666, -3.396, -5.81, -3.871, -3.727]
Step 3271 3 visits [1000.0, 1000.0, 7.0, 80.0, 4.0, 42.0, 96.0]  episode_count: 5693 q_vals: [-inf, -inf, -4.666, -3.353, -5.81, -3.871, -3.727]
Step 3272 3 visits [1000.0, 1000.0, 7.0, 81.0, 4.0, 42.0, 96.0]  episode_count: 5696 q_vals: [-inf, -inf, -4.666, -3.37, -5.81, -3.871, -3.727]
Step 3273 3 visits [1000.0, 1000.0, 7.0, 82.0, 4.0, 42.0, 96.0]  episode_count: 5699 q_vals: [-inf, -inf, -4.666, -3.382, -5.81, -3.871, -3.727]
{"total_number_of_episodes": 5702, "number_of_timesteps": 103171, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3274 3 visits [1000.0, 1000.0, 7.0, 83.0, 4.0, 42.0, 96.0]  episode_count: 5702 q_vals: [-inf, -inf, -4.666, -3.401, -5.81, -3.871, -3.727]
Step 3275 3 visits [1000.0, 1000.0, 7.0, 84.0, 4.0, 42.0, 96.0]  episode_count: 5703 q_vals: [-inf, -inf, -4.666, -3.36, -5.81, -3.871, -3.727]
Step 3276 3 visits [1000.0, 1000.0, 7.0, 85.0, 4.0, 42.0, 96.0]  episode_count: 5707 q_vals: [-inf, -inf, -4.666, -3.379, -5.81, -3.871, -3.727]
Step 3277 3 visits [1000.0, 1000.0, 7.0, 86.0, 4.0, 42.0, 96.0]  episode_count: 5710 q_vals: [-inf, -inf, -4.666, -3.394, -5.81, -3.871, -3.727]
Step 3278 3 visits [1000.0, 1000.0, 7.0, 87.0, 4.0, 42.0, 96.0]  episode_count: 5710 q_vals: [-inf, -inf, -4.666, -3.528, -5.81, -3.871, -3.727]
{"total_number_of_episodes": 5716, "number_of_timesteps": 103332, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3279 3 visits [1000.0, 1000.0, 7.0, 88.0, 4.0, 42.0, 96.0]  episode_count: 5716 q_vals: [-inf, -inf, -4.666, -3.541, -5.81, -3.871, -3.727]
Step 3280 3 visits [1000.0, 1000.0, 7.0, 89.0, 4.0, 42.0, 96.0]  episode_count: 5717 q_vals: [-inf, -inf, -4.666, -3.67, -5.81, -3.871, -3.727]
Step 3281 3 visits [1000.0, 1000.0, 7.0, 90.0, 4.0, 42.0, 96.0]  episode_count: 5720 q_vals: [-inf, -inf, -4.666, -3.629, -5.81, -3.871, -3.727]
Step 3282 3 visits [1000.0, 1000.0, 7.0, 91.0, 4.0, 42.0, 96.0]  episode_count: 5722 q_vals: [-inf, -inf, -4.666, -3.754, -5.81, -3.871, -3.727]
Step 3283 6 visits [1000.0, 1000.0, 7.0, 91.0, 4.0, 42.0, 97.0]  episode_count: 5725 q_vals: [-inf, -inf, -4.666, -3.754, -5.81, -3.871, -3.736]
{"total_number_of_episodes": 5728, "number_of_timesteps": 103470, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3284 6 visits [1000.0, 1000.0, 7.0, 91.0, 4.0, 42.0, 98.0]  episode_count: 5728 q_vals: [-inf, -inf, -4.666, -3.754, -5.81, -3.871, -3.745]
Step 3285 6 visits [1000.0, 1000.0, 7.0, 91.0, 4.0, 42.0, 99.0]  episode_count: 5729 q_vals: [-inf, -inf, -4.666, -3.754, -5.81, -3.871, -3.707]
Step 3286 6 visits [1000.0, 1000.0, 7.0, 91.0, 4.0, 42.0, 100.0]  episode_count: 5730 q_vals: [-inf, -inf, -4.666, -3.754, -5.81, -3.871, -3.82]
Step 3287 3 visits [1000.0, 1000.0, 7.0, 92.0, 4.0, 42.0, 100.0]  episode_count: 5735 q_vals: [-inf, -inf, -4.666, -3.713, -5.81, -3.871, -3.82]
Step 3288 3 visits [1000.0, 1000.0, 7.0, 93.0, 4.0, 42.0, 100.0]  episode_count: 5737 q_vals: [-inf, -inf, -4.666, -3.723, -5.81, -3.871, -3.82]
{"total_number_of_episodes": 5738, "number_of_timesteps": 103596, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3289 3 visits [1000.0, 1000.0, 7.0, 94.0, 4.0, 42.0, 100.0]  episode_count: 5738 q_vals: [-inf, -inf, -4.666, -3.683, -5.81, -3.871, -3.82]
Step 3290 3 visits [1000.0, 1000.0, 7.0, 95.0, 4.0, 42.0, 100.0]  episode_count: 5744 q_vals: [-inf, -inf, -4.666, -3.689, -5.81, -3.871, -3.82]
Step 3291 3 visits [1000.0, 1000.0, 7.0, 96.0, 4.0, 42.0, 100.0]  episode_count: 5745 q_vals: [-inf, -inf, -4.666, -3.709, -5.81, -3.871, -3.82]
{"total_number_of_episodes": 5748, "number_of_timesteps": 103703, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3292 3 visits [1000.0, 1000.0, 7.0, 97.0, 4.0, 42.0, 100.0]  episode_count: 5748 q_vals: [-inf, -inf, -4.666, -3.718, -5.81, -3.871, -3.82]
Step 3293 3 visits [1000.0, 1000.0, 7.0, 98.0, 4.0, 42.0, 100.0]  episode_count: 5752 q_vals: [-inf, -inf, -4.666, -3.725, -5.81, -3.871, -3.82]
Step 3294 3 visits [1000.0, 1000.0, 7.0, 99.0, 4.0, 42.0, 100.0]  episode_count: 5754 q_vals: [-inf, -inf, -4.666, -3.734, -5.81, -3.871, -3.82]
{"total_number_of_episodes": 5758, "number_of_timesteps": 103813, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3295 3 visits [1000.0, 1000.0, 7.0, 100.0, 4.0, 42.0, 100.0]  episode_count: 5758 q_vals: [-inf, -inf, -4.666, -3.696, -5.81, -3.871, -3.82]
Step 3296 3 visits [1000.0, 1000.0, 7.0, 101.0, 4.0, 42.0, 100.0]  episode_count: 5760 q_vals: [-inf, -inf, -4.666, -3.706, -5.81, -3.871, -3.82]
Step 3297 3 visits [1000.0, 1000.0, 7.0, 102.0, 4.0, 42.0, 100.0]  episode_count: 5764 q_vals: [-inf, -inf, -4.666, -3.713, -5.81, -3.871, -3.82]
Step 3298 3 visits [1000.0, 1000.0, 7.0, 103.0, 4.0, 42.0, 100.0]  episode_count: 5764 q_vals: [-inf, -inf, -4.666, -3.677, -5.81, -3.871, -3.82]
{"total_number_of_episodes": 5769, "number_of_timesteps": 103932, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3299 3 visits [1000.0, 1000.0, 7.0, 104.0, 4.0, 42.0, 100.0]  episode_count: 5769 q_vals: [-inf, -inf, -4.666, -3.642, -5.81, -3.871, -3.82]
Step 3300 3 visits [1000.0, 1000.0, 7.0, 105.0, 4.0, 42.0, 100.0]  episode_count: 5770 q_vals: [-inf, -inf, -4.666, -3.653, -5.81, -3.871, -3.82]
Step 3301 3 visits [1000.0, 1000.0, 7.0, 106.0, 4.0, 42.0, 100.0]  episode_count: 5773 q_vals: [-inf, -inf, -4.666, -3.619, -5.81, -3.871, -3.82]
Step 3302 3 visits [1000.0, 1000.0, 7.0, 107.0, 4.0, 42.0, 100.0]  episode_count: 5776 q_vals: [-inf, -inf, -4.666, -3.585, -5.81, -3.871, -3.82]
Step 3303 3 visits [1000.0, 1000.0, 7.0, 108.0, 4.0, 42.0, 100.0]  episode_count: 5777 q_vals: [-inf, -inf, -4.666, -3.552, -5.81, -3.871, -3.82]
{"total_number_of_episodes": 5782, "number_of_timesteps": 104090, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3304 3 visits [1000.0, 1000.0, 7.0, 109.0, 4.0, 42.0, 100.0]  episode_count: 5782 q_vals: [-inf, -inf, -4.666, -3.561, -5.81, -3.871, -3.82]
Step 3305 3 visits [1000.0, 1000.0, 7.0, 110.0, 4.0, 42.0, 100.0]  episode_count: 5783 q_vals: [-inf, -inf, -4.666, -3.577, -5.81, -3.871, -3.82]
Step 3306 3 visits [1000.0, 1000.0, 7.0, 111.0, 4.0, 42.0, 100.0]  episode_count: 5787 q_vals: [-inf, -inf, -4.666, -3.544, -5.81, -3.871, -3.82]
Step 3307 3 visits [1000.0, 1000.0, 7.0, 112.0, 4.0, 42.0, 100.0]  episode_count: 5789 q_vals: [-inf, -inf, -4.666, -3.513, -5.81, -3.871, -3.82]
Step 3308 3 visits [1000.0, 1000.0, 7.0, 113.0, 4.0, 42.0, 100.0]  episode_count: 5790 q_vals: [-inf, -inf, -4.666, -3.482, -5.81, -3.871, -3.82]
{"total_number_of_episodes": 5793, "number_of_timesteps": 104221, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3309 3 visits [1000.0, 1000.0, 7.0, 114.0, 4.0, 42.0, 100.0]  episode_count: 5793 q_vals: [-inf, -inf, -4.666, -3.501, -5.81, -3.871, -3.82]
Step 3310 3 visits [1000.0, 1000.0, 7.0, 115.0, 4.0, 42.0, 100.0]  episode_count: 5796 q_vals: [-inf, -inf, -4.666, -3.516, -5.81, -3.871, -3.82]
Step 3311 3 visits [1000.0, 1000.0, 7.0, 116.0, 4.0, 42.0, 100.0]  episode_count: 5797 q_vals: [-inf, -inf, -4.666, -3.527, -5.81, -3.871, -3.82]
Step 3312 3 visits [1000.0, 1000.0, 7.0, 117.0, 4.0, 42.0, 100.0]  episode_count: 5799 q_vals: [-inf, -inf, -4.666, -3.625, -5.81, -3.871, -3.82]
{"total_number_of_episodes": 5804, "number_of_timesteps": 104375, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3313 3 visits [1000.0, 1000.0, 7.0, 118.0, 4.0, 42.0, 100.0]  episode_count: 5804 q_vals: [-inf, -inf, -4.666, -3.636, -5.81, -3.871, -3.82]
Step 3314 3 visits [1000.0, 1000.0, 7.0, 119.0, 4.0, 42.0, 100.0]  episode_count: 5805 q_vals: [-inf, -inf, -4.666, -3.644, -5.81, -3.871, -3.82]
Step 3315 3 visits [1000.0, 1000.0, 7.0, 120.0, 4.0, 42.0, 100.0]  episode_count: 5805 q_vals: [-inf, -inf, -4.666, -3.659, -5.81, -3.871, -3.82]
Step 3316 3 visits [1000.0, 1000.0, 7.0, 121.0, 4.0, 42.0, 100.0]  episode_count: 5810 q_vals: [-inf, -inf, -4.666, -3.628, -5.81, -3.871, -3.82]
Step 3317 3 visits [1000.0, 1000.0, 7.0, 122.0, 4.0, 42.0, 100.0]  episode_count: 5812 q_vals: [-inf, -inf, -4.666, -3.599, -5.81, -3.871, -3.82]
Step 3318 3 visits [1000.0, 1000.0, 7.0, 123.0, 4.0, 42.0, 100.0]  episode_count: 5813 q_vals: [-inf, -inf, -4.666, -3.569, -5.81, -3.871, -3.82]
{"total_number_of_episodes": 5817, "number_of_timesteps": 104545, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3319 3 visits [1000.0, 1000.0, 7.0, 124.0, 4.0, 42.0, 100.0]  episode_count: 5817 q_vals: [-inf, -inf, -4.666, -3.578, -5.81, -3.871, -3.82]
Step 3320 3 visits [1000.0, 1000.0, 7.0, 125.0, 4.0, 42.0, 100.0]  episode_count: 5819 q_vals: [-inf, -inf, -4.666, -3.588, -5.81, -3.871, -3.82]
Step 3321 3 visits [1000.0, 1000.0, 7.0, 126.0, 4.0, 42.0, 100.0]  episode_count: 5819 q_vals: [-inf, -inf, -4.666, -3.606, -5.81, -3.871, -3.82]
Step 3322 3 visits [1000.0, 1000.0, 7.0, 127.0, 4.0, 42.0, 100.0]  episode_count: 5823 q_vals: [-inf, -inf, -4.666, -3.629, -5.81, -3.871, -3.82]
Step 3323 3 visits [1000.0, 1000.0, 7.0, 128.0, 4.0, 42.0, 100.0]  episode_count: 5825 q_vals: [-inf, -inf, -4.666, -3.718, -5.81, -3.871, -3.82]
{"total_number_of_episodes": 5827, "number_of_timesteps": 104690, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3324 5 visits [1000.0, 1000.0, 7.0, 128.0, 4.0, 43.0, 100.0]  episode_count: 5827 q_vals: [-inf, -inf, -4.666, -3.718, -5.81, -3.781, -3.82]
Step 3325 5 visits [1000.0, 1000.0, 7.0, 128.0, 4.0, 44.0, 100.0]  episode_count: 5829 q_vals: [-inf, -inf, -4.666, -3.718, -5.81, -3.817, -3.82]
Step 3326 5 visits [1000.0, 1000.0, 7.0, 128.0, 4.0, 45.0, 100.0]  episode_count: 5831 q_vals: [-inf, -inf, -4.666, -3.718, -5.81, -3.82, -3.82]
Step 3327 5 visits [1000.0, 1000.0, 7.0, 128.0, 4.0, 46.0, 100.0]  episode_count: 5831 q_vals: [-inf, -inf, -4.666, -3.718, -5.81, -3.872, -3.82]
Step 3328 3 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 46.0, 100.0]  episode_count: 5833 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.872, -3.82]
Step 3329 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 47.0, 100.0]  episode_count: 5833 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.79, -3.82]
Step 3330 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 48.0, 100.0]  episode_count: 5835 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.711, -3.82]
Step 3331 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 49.0, 100.0]  episode_count: 5836 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.635, -3.82]
{"total_number_of_episodes": 5838, "number_of_timesteps": 104895, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3332 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 50.0, 100.0]  episode_count: 5838 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.67, -3.82]
Step 3333 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 51.0, 100.0]  episode_count: 5840 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.687, -3.82]
Step 3334 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 52.0, 100.0]  episode_count: 5842 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.676, -3.82]
Step 3335 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 53.0, 100.0]  episode_count: 5845 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.749, -3.82]
Step 3336 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 54.0, 100.0]  episode_count: 5847 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.77, -3.82]
Step 3337 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 55.0, 100.0]  episode_count: 5847 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.8, -3.82]
{"total_number_of_episodes": 5848, "number_of_timesteps": 105090, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3338 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 56.0, 100.0]  episode_count: 5848 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.843, -3.82]
Step 3339 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 57.0, 100.0]  episode_count: 5851 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.775, -3.82]
Step 3340 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 58.0, 100.0]  episode_count: 5853 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.809, -3.82]
Step 3341 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 59.0, 100.0]  episode_count: 5855 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.745, -3.82]
Step 3342 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 60.0, 100.0]  episode_count: 5857 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.77, -3.82]
{"total_number_of_episodes": 5858, "number_of_timesteps": 105265, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3343 5 visits [1000.0, 1000.0, 7.0, 129.0, 4.0, 61.0, 100.0]  episode_count: 5858 q_vals: [-inf, -inf, -4.666, -3.742, -5.81, -3.954, -3.82]
Step 3344 3 visits [1000.0, 1000.0, 7.0, 130.0, 4.0, 61.0, 100.0]  episode_count: 5861 q_vals: [-inf, -inf, -4.666, -3.713, -5.81, -3.954, -3.82]
Step 3345 3 visits [1000.0, 1000.0, 7.0, 131.0, 4.0, 61.0, 100.0]  episode_count: 5864 q_vals: [-inf, -inf, -4.666, -3.799, -5.81, -3.954, -3.82]
Step 3346 6 visits [1000.0, 1000.0, 7.0, 131.0, 4.0, 61.0, 101.0]  episode_count: 5865 q_vals: [-inf, -inf, -4.666, -3.799, -5.81, -3.954, -3.782]
Step 3347 6 visits [1000.0, 1000.0, 7.0, 131.0, 4.0, 61.0, 102.0]  episode_count: 5867 q_vals: [-inf, -inf, -4.666, -3.799, -5.81, -3.954, -3.807]
{"total_number_of_episodes": 5869, "number_of_timesteps": 105431, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3348 6 visits [1000.0, 1000.0, 7.0, 131.0, 4.0, 61.0, 103.0]  episode_count: 5869 q_vals: [-inf, -inf, -4.666, -3.799, -5.81, -3.954, -3.814]
Step 3349 6 visits [1000.0, 1000.0, 7.0, 131.0, 4.0, 61.0, 104.0]  episode_count: 5872 q_vals: [-inf, -inf, -4.666, -3.799, -5.81, -3.954, -3.836]
Step 3350 3 visits [1000.0, 1000.0, 7.0, 132.0, 4.0, 61.0, 104.0]  episode_count: 5874 q_vals: [-inf, -inf, -4.666, -3.771, -5.81, -3.954, -3.836]
Step 3351 3 visits [1000.0, 1000.0, 7.0, 133.0, 4.0, 61.0, 104.0]  episode_count: 5876 q_vals: [-inf, -inf, -4.666, -3.777, -5.81, -3.954, -3.836]
Step 3352 3 visits [1000.0, 1000.0, 7.0, 134.0, 4.0, 61.0, 104.0]  episode_count: 5877 q_vals: [-inf, -inf, -4.666, -3.783, -5.81, -3.954, -3.836]
{"total_number_of_episodes": 5879, "number_of_timesteps": 105569, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3353 3 visits [1000.0, 1000.0, 7.0, 135.0, 4.0, 61.0, 104.0]  episode_count: 5879 q_vals: [-inf, -inf, -4.666, -3.754, -5.81, -3.954, -3.836]
Step 3354 3 visits [1000.0, 1000.0, 7.0, 136.0, 4.0, 61.0, 104.0]  episode_count: 5880 q_vals: [-inf, -inf, -4.666, -3.727, -5.81, -3.954, -3.836]
Step 3355 3 visits [1000.0, 1000.0, 7.0, 137.0, 4.0, 61.0, 104.0]  episode_count: 5881 q_vals: [-inf, -inf, -4.666, -3.735, -5.81, -3.954, -3.836]
Step 3356 3 visits [1000.0, 1000.0, 7.0, 138.0, 4.0, 61.0, 104.0]  episode_count: 5882 q_vals: [-inf, -inf, -4.666, -3.708, -5.81, -3.954, -3.836]
Step 3357 3 visits [1000.0, 1000.0, 7.0, 139.0, 4.0, 61.0, 104.0]  episode_count: 5883 q_vals: [-inf, -inf, -4.666, -3.681, -5.81, -3.954, -3.836]
Step 3358 3 visits [1000.0, 1000.0, 7.0, 140.0, 4.0, 61.0, 104.0]  episode_count: 5885 q_vals: [-inf, -inf, -4.666, -3.687, -5.81, -3.954, -3.836]
Step 3359 3 visits [1000.0, 1000.0, 7.0, 141.0, 4.0, 61.0, 104.0]  episode_count: 5886 q_vals: [-inf, -inf, -4.666, -3.767, -5.81, -3.954, -3.836]
Step 3360 3 visits [1000.0, 1000.0, 7.0, 142.0, 4.0, 61.0, 104.0]  episode_count: 5887 q_vals: [-inf, -inf, -4.666, -3.846, -5.81, -3.954, -3.836]
{"total_number_of_episodes": 5890, "number_of_timesteps": 105772, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3361 6 visits [1000.0, 1000.0, 7.0, 142.0, 4.0, 61.0, 105.0]  episode_count: 5890 q_vals: [-inf, -inf, -4.666, -3.846, -5.81, -3.954, -3.942]
Step 3362 3 visits [1000.0, 1000.0, 7.0, 143.0, 4.0, 61.0, 105.0]  episode_count: 5891 q_vals: [-inf, -inf, -4.666, -3.82, -5.81, -3.954, -3.942]
Step 3363 3 visits [1000.0, 1000.0, 7.0, 144.0, 4.0, 61.0, 105.0]  episode_count: 5891 q_vals: [-inf, -inf, -4.666, -3.83, -5.81, -3.954, -3.942]
Step 3364 3 visits [1000.0, 1000.0, 7.0, 145.0, 4.0, 61.0, 105.0]  episode_count: 5892 q_vals: [-inf, -inf, -4.666, -3.822, -5.81, -3.954, -3.942]
Step 3365 3 visits [1000.0, 1000.0, 7.0, 146.0, 4.0, 61.0, 105.0]  episode_count: 5894 q_vals: [-inf, -inf, -4.666, -3.835, -5.81, -3.954, -3.942]
Step 3366 3 visits [1000.0, 1000.0, 7.0, 147.0, 4.0, 61.0, 105.0]  episode_count: 5895 q_vals: [-inf, -inf, -4.666, -3.809, -5.81, -3.954, -3.942]
Step 3367 3 visits [1000.0, 1000.0, 7.0, 148.0, 4.0, 61.0, 105.0]  episode_count: 5895 q_vals: [-inf, -inf, -4.666, -3.814, -5.81, -3.954, -3.942]
Step 3368 3 visits [1000.0, 1000.0, 7.0, 149.0, 4.0, 61.0, 105.0]  episode_count: 5897 q_vals: [-inf, -inf, -4.666, -3.788, -5.81, -3.954, -3.942]
{"total_number_of_episodes": 5900, "number_of_timesteps": 106107, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3369 3 visits [1000.0, 1000.0, 7.0, 150.0, 4.0, 61.0, 105.0]  episode_count: 5900 q_vals: [-inf, -inf, -4.666, -3.794, -5.81, -3.954, -3.942]
Step 3370 3 visits [1000.0, 1000.0, 7.0, 151.0, 4.0, 61.0, 105.0]  episode_count: 5900 q_vals: [-inf, -inf, -4.666, -3.869, -5.81, -3.954, -3.942]
Step 3371 5 visits [1000.0, 1000.0, 7.0, 151.0, 4.0, 62.0, 105.0]  episode_count: 5900 q_vals: [-inf, -inf, -4.666, -3.869, -5.81, -4.132, -3.942]
Step 3372 3 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 105.0]  episode_count: 5902 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.942]
Step 3373 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 106.0]  episode_count: 5904 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.947]
Step 3374 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 107.0]  episode_count: 5905 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.91]
Step 3375 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 108.0]  episode_count: 5906 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.896]
Step 3376 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 109.0]  episode_count: 5908 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.908]
Step 3377 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 110.0]  episode_count: 5908 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.872]
{"total_number_of_episodes": 5911, "number_of_timesteps": 106384, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3378 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 111.0]  episode_count: 5911 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.837]
Step 3379 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 112.0]  episode_count: 5912 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.937]
Step 3380 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 113.0]  episode_count: 5915 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.943]
Step 3381 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 114.0]  episode_count: 5916 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.908]
Step 3382 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 115.0]  episode_count: 5917 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.874]
Step 3383 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 116.0]  episode_count: 5920 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.841]
{"total_number_of_episodes": 5921, "number_of_timesteps": 106583, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3384 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 117.0]  episode_count: 5921 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.856]
Step 3385 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 118.0]  episode_count: 5924 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.823]
Step 3386 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 119.0]  episode_count: 5926 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.83]
Step 3387 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 120.0]  episode_count: 5927 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.844]
Step 3388 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 121.0]  episode_count: 5930 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.86]
{"total_number_of_episodes": 5932, "number_of_timesteps": 106755, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3389 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 122.0]  episode_count: 5932 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.951]
Step 3390 6 visits [1000.0, 1000.0, 7.0, 152.0, 4.0, 62.0, 123.0]  episode_count: 5935 q_vals: [-inf, -inf, -4.666, -3.942, -5.81, -4.132, -3.965]
Step 3391 3 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 123.0]  episode_count: 5937 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.965]
Step 3392 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 124.0]  episode_count: 5939 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.933]
{"total_number_of_episodes": 5942, "number_of_timesteps": 106876, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3393 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 125.0]  episode_count: 5942 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.901]
Step 3394 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 126.0]  episode_count: 5945 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.87]
Step 3395 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 127.0]  episode_count: 5946 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.84]
Step 3396 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 128.0]  episode_count: 5948 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.846]
Step 3397 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 129.0]  episode_count: 5950 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.86]
{"total_number_of_episodes": 5953, "number_of_timesteps": 107033, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
[-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.83]
Step 3399 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 131.0]  episode_count: 5954 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.839]
Step 3400 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 132.0]  episode_count: 5956 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.81]
Step 3401 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 133.0]  episode_count: 5959 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.817]
Step 3402 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 134.0]  episode_count: 5960 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.824]
Step 3403 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 135.0]  episode_count: 5962 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.831]
{"total_number_of_episodes": 5967, "number_of_timesteps": 107230, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3404 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 136.0]  episode_count: 5967 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.802]
Step 3405 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 137.0]  episode_count: 5967 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.811]
Step 3406 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 138.0]  episode_count: 5969 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.824]
Step 3407 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 139.0]  episode_count: 5970 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.837]
Step 3408 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 140.0]  episode_count: 5971 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.809]
Step 3409 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 141.0]  episode_count: 5973 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.782]
Step 3410 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 142.0]  episode_count: 5975 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.788]
Step 3411 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 143.0]  episode_count: 5976 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.761]
{"total_number_of_episodes": 5977, "number_of_timesteps": 107415, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3412 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 144.0]  episode_count: 5977 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.735]
Step 3413 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 145.0]  episode_count: 5978 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.74]
Step 3414 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 146.0]  episode_count: 5982 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.714]
Step 3415 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 147.0]  episode_count: 5983 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.689]
Step 3416 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 148.0]  episode_count: 5984 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.696]
Step 3417 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 149.0]  episode_count: 5985 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.709]
{"total_number_of_episodes": 5987, "number_of_timesteps": 107620, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3418 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 150.0]  episode_count: 5987 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.685]
Step 3419 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 151.0]  episode_count: 5990 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.695]
Step 3420 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 152.0]  episode_count: 5991 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.671]
Step 3421 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 153.0]  episode_count: 5993 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.647]
Step 3422 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 154.0]  episode_count: 5994 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.623]
Step 3423 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 155.0]  episode_count: 5996 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.6]
Step 3424 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 156.0]  episode_count: 5996 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.577]
{"total_number_of_episodes": 5998, "number_of_timesteps": 107836, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3425 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 157.0]  episode_count: 5998 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.583]
Step 3426 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 158.0]  episode_count: 6001 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.587]
Step 3427 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 159.0]  episode_count: 6002 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.614]
Step 3428 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 160.0]  episode_count: 6002 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.592]
Step 3429 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 161.0]  episode_count: 6003 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.598]
Step 3430 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 162.0]  episode_count: 6006 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.575]
Step 3431 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 163.0]  episode_count: 6006 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.553]
Step 3432 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 164.0]  episode_count: 6007 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.562]
{"total_number_of_episodes": 6009, "number_of_timesteps": 108051, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3433 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 165.0]  episode_count: 6009 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.631]
Step 3434 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 166.0]  episode_count: 6009 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.609]
Step 3435 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 167.0]  episode_count: 6011 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.615]
[1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 168.0]  episode_count: 6013 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.593]
Step 3437 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 169.0]  episode_count: 6015 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.607]
Step 3438 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 170.0]  episode_count: 6015 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.674]
Step 3439 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 171.0]  episode_count: 6016 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.653]
Step 3440 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 172.0]  episode_count: 6018 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.659]
{"total_number_of_episodes": 6020, "number_of_timesteps": 108327, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3441 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 173.0]  episode_count: 6020 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.638]
Step 3442 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 174.0]  episode_count: 6022 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.617]
Step 3443 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 175.0]  episode_count: 6024 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.622]
Step 3444 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 176.0]  episode_count: 6025 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.602]
Step 3445 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 177.0]  episode_count: 6027 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.606]
Step 3446 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 178.0]  episode_count: 6029 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.623]
{"total_number_of_episodes": 6032, "number_of_timesteps": 108572, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3447 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 179.0]  episode_count: 6032 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.64]
Step 3448 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 180.0]  episode_count: 6033 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.644]
Step 3449 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 181.0]  episode_count: 6035 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.648]
Step 3450 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 182.0]  episode_count: 6036 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.628]
Step 3451 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 183.0]  episode_count: 6038 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.608]
Step 3452 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 184.0]  episode_count: 6041 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.588]
{"total_number_of_episodes": 6044, "number_of_timesteps": 108754, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3453 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 185.0]  episode_count: 6044 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.595]
Step 3454 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 186.0]  episode_count: 6045 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.6]
Step 3455 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 187.0]  episode_count: 6049 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.58]
Step 3456 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 188.0]  episode_count: 6050 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.581]
Step 3457 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 189.0]  episode_count: 6052 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.59]
{"total_number_of_episodes": 6056, "number_of_timesteps": 108933, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3458 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 190.0]  episode_count: 6056 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.571]
Step 3459 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 191.0]  episode_count: 6058 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.576]
Step 3460 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 192.0]  episode_count: 6060 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.583]
Step 3461 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 193.0]  episode_count: 6061 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.59]
Step 3462 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 194.0]  episode_count: 6064 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.598]
{"total_number_of_episodes": 6066, "number_of_timesteps": 109075, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3463 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 195.0]  episode_count: 6066 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.656]
Step 3464 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 196.0]  episode_count: 6067 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.638]
Step 3465 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 197.0]  episode_count: 6069 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.645]
Step 3466 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 198.0]  episode_count: 6071 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.626]
Step 3467 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 199.0]  episode_count: 6075 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.635]
{"total_number_of_episodes": 6076, "number_of_timesteps": 109236, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3468 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 200.0]  episode_count: 6076 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.617]
Step 3469 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 201.0]  episode_count: 6080 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.629]
Step 3470 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 202.0]  episode_count: 6081 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.634]
Step 3471 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 203.0]  episode_count: 6085 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.643]
{"total_number_of_episodes": 6087, "number_of_timesteps": 109387, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
 [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.649]
Step 3473 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 205.0]  episode_count: 6089 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.66]
Step 3474 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 206.0]  episode_count: 6089 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.643]
Step 3475 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 207.0]  episode_count: 6092 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.625]
Step 3476 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 208.0]  episode_count: 6092 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.608]
Step 3477 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 209.0]  episode_count: 6094 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.662]
{"total_number_of_episodes": 6097, "number_of_timesteps": 109541, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3478 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 210.0]  episode_count: 6097 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.645]
Step 3479 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 211.0]  episode_count: 6098 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.653]
Step 3480 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 212.0]  episode_count: 6098 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.675]
Step 3481 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 213.0]  episode_count: 6098 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.679]
Step 3482 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 214.0]  episode_count: 6102 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.662]
Step 3483 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 215.0]  episode_count: 6104 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.668]
Step 3484 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 216.0]  episode_count: 6104 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.721]
Step 3485 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 217.0]  episode_count: 6105 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.704]
{"total_number_of_episodes": 6108, "number_of_timesteps": 109805, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3486 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 218.0]  episode_count: 6108 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.711]
Step 3487 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 219.0]  episode_count: 6109 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.717]
Step 3488 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 220.0]  episode_count: 6110 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.7]
Step 3489 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 221.0]  episode_count: 6111 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.704]
Step 3490 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 222.0]  episode_count: 6114 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.709]
Step 3491 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 223.0]  episode_count: 6114 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.725]
Step 3492 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 224.0]  episode_count: 6115 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.708]
Step 3493 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 225.0]  episode_count: 6116 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.712]
Step 3494 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 226.0]  episode_count: 6117 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.695]
{"total_number_of_episodes": 6119, "number_of_timesteps": 110062, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3495 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 227.0]  episode_count: 6119 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.703]
Step 3496 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 228.0]  episode_count: 6122 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.708]
Step 3497 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 229.0]  episode_count: 6123 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.711]
Step 3498 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 230.0]  episode_count: 6126 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.727]
Step 3499 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 231.0]  episode_count: 6128 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.731]
{"total_number_of_episodes": 6129, "number_of_timesteps": 110258, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3500 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 232.0]  episode_count: 6129 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.735]
Step 3501 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 233.0]  episode_count: 6131 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.719]
Step 3502 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 234.0]  episode_count: 6132 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.704]
Step 3503 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 235.0]  episode_count: 6133 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.688]
Step 3504 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 236.0]  episode_count: 6137 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.672]
Step 3505 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 237.0]  episode_count: 6137 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.676]
{"total_number_of_episodes": 6141, "number_of_timesteps": 110470, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3506 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 238.0]  episode_count: 6141 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.661]
Step 3507 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 239.0]  episode_count: 6143 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.665]
Step 3508 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 240.0]  episode_count: 6144 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.65]
Step 3509 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 241.0]  episode_count: 6145 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.656]
Step 3510 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 242.0]  episode_count: 6149 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.67]
Step 3511 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 243.0]  episode_count: 6150 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.716]
{"total_number_of_episodes": 6152, "number_of_timesteps": 110647, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3512 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 244.0]  episode_count: 6152 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.721]
Step 3513 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 245.0]  episode_count: 6152 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.724]
Step 3514 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 246.0]  episode_count: 6156 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.727]
Step 3515 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 247.0]  episode_count: 6158 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.73]
Step 3516 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 248.0]  episode_count: 6158 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.715]
Step 3517 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 249.0]  episode_count: 6160 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.719]
{"total_number_of_episodes": 6162, "number_of_timesteps": 110815, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3518 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 250.0]  episode_count: 6162 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.704]
Step 3519 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 251.0]  episode_count: 6163 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.69]
Step 3520 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 252.0]  episode_count: 6165 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.675]
Step 3521 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 253.0]  episode_count: 6167 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.679]
Step 3522 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 254.0]  episode_count: 6169 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.683]
Step 3523 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 255.0]  episode_count: 6170 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.669]
{"total_number_of_episodes": 6173, "number_of_timesteps": 111039, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3524 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 256.0]  episode_count: 6173 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.654]
Step 3525 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 257.0]  episode_count: 6176 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.661]
Step 3526 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 258.0]  episode_count: 6178 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.647]
Step 3527 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 259.0]  episode_count: 6179 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.651]
Step 3528 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 260.0]  episode_count: 6182 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.637]
Step 3529 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 261.0]  episode_count: 6182 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.623]
{"total_number_of_episodes": 6184, "number_of_timesteps": 111195, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3530 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 262.0]  episode_count: 6184 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.609]
Step 3531 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 263.0]  episode_count: 6187 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.611]
Step 3532 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 264.0]  episode_count: 6187 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.615]
Step 3533 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 265.0]  episode_count: 6189 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.602]
Step 3534 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 266.0]  episode_count: 6191 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.609]
Step 3535 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 267.0]  episode_count: 6191 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.609]
Step 3536 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 268.0]  episode_count: 6191 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.596]
Step 3537 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 269.0]  episode_count: 6192 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.582]
{"total_number_of_episodes": 6194, "number_of_timesteps": 111400, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3538 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 270.0]  episode_count: 6194 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.589]
Step 3539 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 271.0]  episode_count: 6197 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.594]
Step 3540 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 272.0]  episode_count: 6198 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.597]
Step 3541 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 273.0]  episode_count: 6200 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.583]
Step 3542 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 274.0]  episode_count: 6202 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.57]
{"total_number_of_episodes": 6205, "number_of_timesteps": 111640, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3543 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 275.0]  episode_count: 6205 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.576]
Step 3544 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 276.0]  episode_count: 6207 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.563]
Step 3545 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 277.0]  episode_count: 6208 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.55]
Step 3546 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 278.0]  episode_count: 6211 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.554]
Step 3547 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 279.0]  episode_count: 6213 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.561]
Step 3548 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 280.0]  episode_count: 6213 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.548]
{"total_number_of_episodes": 6218, "number_of_timesteps": 111833, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3549 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 281.0]  episode_count: 6218 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.554]
Step 3550 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 282.0]  episode_count: 6219 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.542]
Step 3551 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 283.0]  episode_count: 6222 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.529]
Step 3552 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 284.0]  episode_count: 6225 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.533]
Step 3553 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 285.0]  episode_count: 6226 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.536]
{"total_number_of_episodes": 6228, "number_of_timesteps": 111972, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3554 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 286.0]  episode_count: 6228 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.541]
Step 3555 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 287.0]  episode_count: 6229 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.529]
Step 3556 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 288.0]  episode_count: 6232 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.517]
Step 3557 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 289.0]  episode_count: 6235 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.523]
Step 3558 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 290.0]  episode_count: 6236 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.53]
{"total_number_of_episodes": 6239, "number_of_timesteps": 112136, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3559 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 291.0]  episode_count: 6239 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.517]
Step 3560 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 292.0]  episode_count: 6242 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.505]
Step 3561 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 293.0]  episode_count: 6242 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.545]
Step 3562 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 294.0]  episode_count: 6245 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.533]
Step 3563 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 295.0]  episode_count: 6246 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.536]
Step 3564 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 296.0]  episode_count: 6247 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.539]
Step 3565 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 297.0]  episode_count: 6248 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.527]
{"total_number_of_episodes": 6252, "number_of_timesteps": 112360, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3566 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 298.0]  episode_count: 6252 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.531]
Step 3567 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 299.0]  episode_count: 6253 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.519]
Step 3568 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 300.0]  episode_count: 6253 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.529]
Step 3569 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 301.0]  episode_count: 6255 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.518]
Step 3570 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 302.0]  episode_count: 6259 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.506]
Step 3571 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 303.0]  episode_count: 6260 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.544]
Step 3572 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 304.0]  episode_count: 6260 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.581]
{"total_number_of_episodes": 6262, "number_of_timesteps": 112535, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3573 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 305.0]  episode_count: 6262 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.586]
Step 3574 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 306.0]  episode_count: 6265 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.574]
Step 3575 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 307.0]  episode_count: 6265 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.563]
Step 3576 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 308.0]  episode_count: 6266 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.566]
Step 3577 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 309.0]  episode_count: 6268 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.555]
Step 3578 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 310.0]  episode_count: 6269 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.558]
{"total_number_of_episodes": 6272, "number_of_timesteps": 112755, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3579 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 311.0]  episode_count: 6272 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.546]
Step 3580 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 312.0]  episode_count: 6273 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.583]
Step 3581 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 313.0]  episode_count: 6274 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.572]
Step 3582 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 314.0]  episode_count: 6278 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.56]
Step 3583 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 315.0]  episode_count: 6278 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.566]
Step 3584 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 316.0]  episode_count: 6281 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.554]
Step 3585 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 317.0]  episode_count: 6281 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.561]
{"total_number_of_episodes": 6285, "number_of_timesteps": 112948, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3586 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 318.0]  episode_count: 6285 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.566]
Step 3587 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 319.0]  episode_count: 6288 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.569]
Step 3588 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 320.0]  episode_count: 6288 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.575]
Step 3589 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 321.0]  episode_count: 6292 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.564]
Step 3590 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 322.0]  episode_count: 6294 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.553]
{"total_number_of_episodes": 6296, "number_of_timesteps": 113114, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3591 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 323.0]  episode_count: 6296 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.542]
Step 3592 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 324.0]  episode_count: 6298 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.531]
Step 3593 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 325.0]  episode_count: 6301 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.534]
Step 3594 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 326.0]  episode_count: 6304 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.523]
{"total_number_of_episodes": 6307, "number_of_timesteps": 113269, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3595 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 327.0]  episode_count: 6307 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.513]
Step 3596 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 328.0]  episode_count: 6308 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.548]
Step 3597 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 329.0]  episode_count: 6311 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.537]
Step 3598 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 330.0]  episode_count: 6314 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.526]
Step 3599 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 331.0]  episode_count: 6316 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.516]
{"total_number_of_episodes": 6318, "number_of_timesteps": 113401, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3600 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 332.0]  episode_count: 6318 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.521]
Step 3601 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 333.0]  episode_count: 6320 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.51]
Step 3602 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 334.0]  episode_count: 6324 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.5]
Step 3603 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 335.0]  episode_count: 6326 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.489]
{"total_number_of_episodes": 6329, "number_of_timesteps": 113543, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3604 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 336.0]  episode_count: 6329 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.479]
Step 3605 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 337.0]  episode_count: 6332 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.469]
Step 3606 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 338.0]  episode_count: 6332 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.471]
Step 3607 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 339.0]  episode_count: 6336 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.461]
{"total_number_of_episodes": 6339, "number_of_timesteps": 113672, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3608 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 340.0]  episode_count: 6339 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.47]
Step 3609 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 341.0]  episode_count: 6340 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.475]
Step 3610 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 342.0]  episode_count: 6342 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.509]
Step 3611 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 343.0]  episode_count: 6344 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.516]
Step 3612 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 344.0]  episode_count: 6347 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.506]
{"total_number_of_episodes": 6351, "number_of_timesteps": 113834, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3613 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 345.0]  episode_count: 6351 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.496]
Step 3614 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 346.0]  episode_count: 6351 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.504]
Step 3615 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 347.0]  episode_count: 6354 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.494]
Step 3616 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 348.0]  episode_count: 6357 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.499]
Step 3617 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 349.0]  episode_count: 6358 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.503]
Step 3618 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 350.0]  episode_count: 6359 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.506]
Step 3619 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 351.0]  episode_count: 6360 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.509]
{"total_number_of_episodes": 6361, "number_of_timesteps": 113984, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3620 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 352.0]  episode_count: 6361 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.499]
Step 3621 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 353.0]  episode_count: 6363 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.489]
Step 3622 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 354.0]  episode_count: 6363 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.479]
Step 3623 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 355.0]  episode_count: 6366 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.469]
Step 3624 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 356.0]  episode_count: 6368 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.473]
Step 3625 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 357.0]  episode_count: 6369 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.476]
Step 3626 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 358.0]  episode_count: 6369 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.484]
Step 3627 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 359.0]  episode_count: 6370 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.474]
{"total_number_of_episodes": 6371, "number_of_timesteps": 114223, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3628 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 360.0]  episode_count: 6371 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.479]
Step 3629 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 361.0]  episode_count: 6371 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.469]
Step 3630 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 362.0]  episode_count: 6372 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.476]
Step 3631 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 363.0]  episode_count: 6376 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.489]
Step 3632 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 364.0]  episode_count: 6377 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.479]
Step 3633 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 365.0]  episode_count: 6378 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.47]
{"total_number_of_episodes": 6381, "number_of_timesteps": 114484, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3634 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 366.0]  episode_count: 6381 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.466]
Step 3635 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 367.0]  episode_count: 6383 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.457]
Step 3636 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 368.0]  episode_count: 6384 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.454]
Step 3637 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 369.0]  episode_count: 6386 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.486]
Step 3638 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 370.0]  episode_count: 6388 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.517]
Step 3639 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 371.0]  episode_count: 6390 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.532]
{"total_number_of_episodes": 6391, "number_of_timesteps": 114652, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3640 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 372.0]  episode_count: 6391 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.523]
Step 3641 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 373.0]  episode_count: 6394 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.554]
Step 3642 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 374.0]  episode_count: 6395 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.584]
Step 3643 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 375.0]  episode_count: 6396 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.586]
Step 3644 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 376.0]  episode_count: 6398 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.578]
Step 3645 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 377.0]  episode_count: 6399 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.608]
Step 3646 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 378.0]  episode_count: 6399 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.639]
{"total_number_of_episodes": 6402, "number_of_timesteps": 114843, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3647 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 379.0]  episode_count: 6402 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.641]
Step 3648 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 380.0]  episode_count: 6402 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.644]
Step 3649 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 381.0]  episode_count: 6402 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.635]
Step 3650 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 382.0]  episode_count: 6405 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.638]
Step 3651 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 383.0]  episode_count: 6407 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.64]
Step 3652 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 384.0]  episode_count: 6409 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.631]
Step 3653 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 385.0]  episode_count: 6410 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.636]
{"total_number_of_episodes": 6412, "number_of_timesteps": 115089, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3654 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 386.0]  episode_count: 6412 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.626]
Step 3655 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 387.0]  episode_count: 6413 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.633]
Step 3656 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 388.0]  episode_count: 6414 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.624]
Step 3657 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 389.0]  episode_count: 6416 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.629]
Step 3658 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 390.0]  episode_count: 6418 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.642]
Step 3659 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 391.0]  episode_count: 6418 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.633]
Step 3660 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 392.0]  episode_count: 6419 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.635]
{"total_number_of_episodes": 6422, "number_of_timesteps": 115309, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3661 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 393.0]  episode_count: 6422 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.626]
Step 3662 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 394.0]  episode_count: 6424 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.628]
Step 3663 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 395.0]  episode_count: 6424 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.657]
Step 3664 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 396.0]  episode_count: 6429 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.647]
Step 3665 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 397.0]  episode_count: 6429 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.651]
Step 3666 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 398.0]  episode_count: 6429 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.658]
{"total_number_of_episodes": 6433, "number_of_timesteps": 115511, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3667 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 399.0]  episode_count: 6433 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.649]
Step 3668 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 400.0]  episode_count: 6433 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.64]
Step 3669 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 401.0]  episode_count: 6434 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.642]
Step 3670 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 402.0]  episode_count: 6436 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.633]
Step 3671 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 403.0]  episode_count: 6436 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.624]
Step 3672 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 404.0]  episode_count: 6438 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.626]
Step 3673 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 405.0]  episode_count: 6442 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.628]
{"total_number_of_episodes": 6443, "number_of_timesteps": 115740, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3674 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 406.0]  episode_count: 6443 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.63]
Step 3675 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 407.0]  episode_count: 6443 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.621]
Step 3676 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 408.0]  episode_count: 6447 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.631]
Step 3677 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 409.0]  episode_count: 6449 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.638]
Step 3678 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 410.0]  episode_count: 6451 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.629]
Step 3679 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 411.0]  episode_count: 6452 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.62]
{"total_number_of_episodes": 6453, "number_of_timesteps": 115891, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3680 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 412.0]  episode_count: 6453 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.611]
Step 3681 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 413.0]  episode_count: 6454 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.603]
Step 3682 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 414.0]  episode_count: 6455 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.605]
Step 3683 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 415.0]  episode_count: 6455 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.609]
Step 3684 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 416.0]  episode_count: 6460 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.6]
Step 3685 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 417.0]  episode_count: 6462 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.592]
Step 3686 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 418.0]  episode_count: 6462 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.583]
{"total_number_of_episodes": 6465, "number_of_timesteps": 116140, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3687 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 419.0]  episode_count: 6465 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.575]
Step 3688 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 420.0]  episode_count: 6469 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.566]
Step 3689 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 421.0]  episode_count: 6469 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.558]
Step 3690 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 422.0]  episode_count: 6472 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.56]
Step 3691 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 423.0]  episode_count: 6474 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.563]
Step 3692 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 424.0]  episode_count: 6474 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.59]
{"total_number_of_episodes": 6477, "number_of_timesteps": 116319, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3693 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 425.0]  episode_count: 6477 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.592]
Step 3694 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 426.0]  episode_count: 6480 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.583]
Step 3695 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 427.0]  episode_count: 6480 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.61]
Step 3696 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 428.0]  episode_count: 6481 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.602]
Step 3697 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 429.0]  episode_count: 6482 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.607]
Step 3698 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 430.0]  episode_count: 6484 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.608]
Step 3699 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 431.0]  episode_count: 6486 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.6]
{"total_number_of_episodes": 6488, "number_of_timesteps": 116535, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3700 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 432.0]  episode_count: 6488 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.592]
Step 3701 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 433.0]  episode_count: 6489 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.583]
Step 3702 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 434.0]  episode_count: 6493 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.587]
Step 3703 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 435.0]  episode_count: 6494 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.588]
Step 3704 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 436.0]  episode_count: 6494 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.58]
Step 3705 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 437.0]  episode_count: 6496 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.584]
{"total_number_of_episodes": 6498, "number_of_timesteps": 116720, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3706 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 438.0]  episode_count: 6498 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.575]
Step 3707 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 439.0]  episode_count: 6500 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.577]
Step 3708 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 440.0]  episode_count: 6502 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.583]
Step 3709 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 441.0]  episode_count: 6504 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.574]
Step 3710 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 442.0]  episode_count: 6506 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.578]
{"total_number_of_episodes": 6508, "number_of_timesteps": 116904, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3711 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 443.0]  episode_count: 6508 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.58]
Step 3712 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 444.0]  episode_count: 6508 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.572]
Step 3713 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 445.0]  episode_count: 6511 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.578]
Step 3714 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 446.0]  episode_count: 6513 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.58]
Step 3715 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 447.0]  episode_count: 6514 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.572]
Step 3716 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 448.0]  episode_count: 6517 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.573]
{"total_number_of_episodes": 6518, "number_of_timesteps": 117078, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3717 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 449.0]  episode_count: 6518 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.575]
Step 3718 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 450.0]  episode_count: 6519 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.577]
Step 3719 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 451.0]  episode_count: 6520 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.583]
Step 3720 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 452.0]  episode_count: 6522 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.586]
Step 3721 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 453.0]  episode_count: 6524 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.588]
Step 3722 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 454.0]  episode_count: 6526 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.58]
Step 3723 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 455.0]  episode_count: 6526 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.572]
{"total_number_of_episodes": 6528, "number_of_timesteps": 117276, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3724 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 456.0]  episode_count: 6528 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.574]
Step 3725 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 457.0]  episode_count: 6529 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.566]
Step 3726 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 458.0]  episode_count: 6531 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.568]
Step 3727 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 459.0]  episode_count: 6532 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.569]
Step 3728 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 460.0]  episode_count: 6535 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.573]
{"total_number_of_episodes": 6538, "number_of_timesteps": 117488, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3729 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 461.0]  episode_count: 6538 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.565]
Step 3730 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 462.0]  episode_count: 6539 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.557]
Step 3731 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 463.0]  episode_count: 6541 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.559]
6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 464.0]  episode_count: 6544 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.561]
Step 3733 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 465.0]  episode_count: 6547 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.554]
{"total_number_of_episodes": 6550, "number_of_timesteps": 117640, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3734 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 466.0]  episode_count: 6550 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.546]
Step 3735 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 467.0]  episode_count: 6553 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.539]
Step 3736 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 468.0]  episode_count: 6555 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.54]
Step 3737 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 469.0]  episode_count: 6559 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.533]
{"total_number_of_episodes": 6561, "number_of_timesteps": 117757, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3738 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 470.0]  episode_count: 6561 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.525]
Step 3739 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 471.0]  episode_count: 6563 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.527]
Step 3740 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 472.0]  episode_count: 6568 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.52]
Step 3741 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 473.0]  episode_count: 6570 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.512]
{"total_number_of_episodes": 6572, "number_of_timesteps": 117873, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3742 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 474.0]  episode_count: 6572 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.505]
Step 3743 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 475.0]  episode_count: 6576 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.497]
Step 3744 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 476.0]  episode_count: 6578 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.49]
{"total_number_of_episodes": 6582, "number_of_timesteps": 117985, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3745 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 477.0]  episode_count: 6582 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.492]
Step 3746 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 478.0]  episode_count: 6584 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.495]
Step 3747 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 479.0]  episode_count: 6587 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.487]
Step 3748 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 480.0]  episode_count: 6590 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.511]
{"total_number_of_episodes": 6594, "number_of_timesteps": 118116, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3749 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 481.0]  episode_count: 6594 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.504]
Step 3750 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 482.0]  episode_count: 6596 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.506]
Step 3751 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 483.0]  episode_count: 6598 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.509]
Step 3752 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 484.0]  episode_count: 6600 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.502]
Step 3753 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 485.0]  episode_count: 6603 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.495]
{"total_number_of_episodes": 6605, "number_of_timesteps": 118248, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3754 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 486.0]  episode_count: 6605 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.505]
Step 3755 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 487.0]  episode_count: 6608 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.498]
Step 3756 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 488.0]  episode_count: 6610 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.501]
Step 3757 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 489.0]  episode_count: 6611 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.503]
{"total_number_of_episodes": 6615, "number_of_timesteps": 118373, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3758 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 490.0]  episode_count: 6615 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.496]
Step 3759 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 491.0]  episode_count: 6616 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.501]
Step 3760 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 492.0]  episode_count: 6617 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.494]
Step 3761 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 493.0]  episode_count: 6620 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.487]
Step 3762 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 494.0]  episode_count: 6622 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.493]
Step 3763 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 495.0]  episode_count: 6623 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.49]
{"total_number_of_episodes": 6625, "number_of_timesteps": 118504, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3764 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 496.0]  episode_count: 6625 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.483]
Step 3765 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 497.0]  episode_count: 6627 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.506]
Step 3766 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 498.0]  episode_count: 6628 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.499]
Step 3767 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 499.0]  episode_count: 6630 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.492]
Step 3768 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 500.0]  episode_count: 6631 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.515]
Step 3769 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 501.0]  episode_count: 6633 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.538]
Step 3770 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 502.0]  episode_count: 6633 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.561]
{"total_number_of_episodes": 6637, "number_of_timesteps": 118761, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3771 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 503.0]  episode_count: 6637 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.563]
Step 3772 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 504.0]  episode_count: 6638 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.556]
Step 3773 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 505.0]  episode_count: 6638 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.578]
Step 3774 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 506.0]  episode_count: 6641 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.581]
Step 3775 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 507.0]  episode_count: 6644 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.585]
Step 3776 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 508.0]  episode_count: 6645 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.602]
Step 3777 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 509.0]  episode_count: 6645 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.594]
Step 3778 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 510.0]  episode_count: 6645 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.587]
{"total_number_of_episodes": 6651, "number_of_timesteps": 119040, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3779 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 511.0]  episode_count: 6651 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.58]
Step 3780 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 512.0]  episode_count: 6652 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.573]
Step 3781 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 513.0]  episode_count: 6652 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.566]
Step 3782 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 514.0]  episode_count: 6653 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.568]
Step 3783 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 515.0]  episode_count: 6655 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.571]
Step 3784 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 516.0]  episode_count: 6657 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.564]
Step 3785 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 517.0]  episode_count: 6657 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.567]
Step 3786 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 518.0]  episode_count: 6659 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.561]
{"total_number_of_episodes": 6663, "number_of_timesteps": 119305, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3787 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 519.0]  episode_count: 6663 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.554]
Step 3788 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 520.0]  episode_count: 6664 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.576]
Step 3789 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 521.0]  episode_count: 6666 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.578]
Step 3790 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 522.0]  episode_count: 6668 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.583]
Step 3791 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 523.0]  episode_count: 6669 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.605]
Step 3792 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 524.0]  episode_count: 6670 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.608]
Step 3793 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 525.0]  episode_count: 6671 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.63]
{"total_number_of_episodes": 6674, "number_of_timesteps": 119486, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3794 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 526.0]  episode_count: 6674 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.623]
Step 3795 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 527.0]  episode_count: 6675 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.616]
Step 3796 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 528.0]  episode_count: 6676 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.618]
Step 3797 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 529.0]  episode_count: 6678 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.62]
Step 3798 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 530.0]  episode_count: 6679 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.614]
Step 3799 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 531.0]  episode_count: 6680 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.608]
Step 3800 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 532.0]  episode_count: 6681 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.611]
Step 3801 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 533.0]  episode_count: 6683 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.614]
{"total_number_of_episodes": 6685, "number_of_timesteps": 119732, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3802 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 534.0]  episode_count: 6685 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.607]
Step 3803 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 535.0]  episode_count: 6687 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.6]
Step 3804 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 536.0]  episode_count: 6690 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.603]
[-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.607]
{"total_number_of_episodes": 6695, "number_of_timesteps": 119912, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3806 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 538.0]  episode_count: 6695 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.609]
Step 3807 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 539.0]  episode_count: 6696 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.613]
Step 3808 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 540.0]  episode_count: 6701 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.615]
Step 3809 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 541.0]  episode_count: 6702 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.62]
Step 3810 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 542.0]  episode_count: 6703 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.622]
{"total_number_of_episodes": 6707, "number_of_timesteps": 120064, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3811 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 543.0]  episode_count: 6707 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.626]
Step 3812 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 544.0]  episode_count: 6707 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.62]
Step 3813 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 545.0]  episode_count: 6709 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.613]
Step 3814 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 546.0]  episode_count: 6713 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.606]
Step 3815 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 547.0]  episode_count: 6714 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.6]
Step 3816 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 548.0]  episode_count: 6716 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.603]
{"total_number_of_episodes": 6719, "number_of_timesteps": 120251, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3817 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 549.0]  episode_count: 6719 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.606]
Step 3818 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 550.0]  episode_count: 6721 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.6]
Step 3819 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 551.0]  episode_count: 6723 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.603]
Step 3820 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 552.0]  episode_count: 6727 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.596]
Step 3821 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 553.0]  episode_count: 6728 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.59]
{"total_number_of_episodes": 6732, "number_of_timesteps": 120402, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3822 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 554.0]  episode_count: 6732 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.592]
Step 3823 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 555.0]  episode_count: 6734 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.594]
Step 3824 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 556.0]  episode_count: 6737 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.588]
Step 3825 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 557.0]  episode_count: 6739 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.608]
{"total_number_of_episodes": 6742, "number_of_timesteps": 120519, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3826 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 558.0]  episode_count: 6742 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.611]
Step 3827 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 559.0]  episode_count: 6744 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.605]
Step 3828 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 560.0]  episode_count: 6748 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.607]
Step 3829 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 561.0]  episode_count: 6749 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.61]
{"total_number_of_episodes": 6752, "number_of_timesteps": 120635, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3830 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 562.0]  episode_count: 6752 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.603]
Step 3831 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 563.0]  episode_count: 6754 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.597]
Step 3832 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 564.0]  episode_count: 6757 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.6]
Step 3833 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 565.0]  episode_count: 6760 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.602]
{"total_number_of_episodes": 6763, "number_of_timesteps": 120762, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3834 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 566.0]  episode_count: 6763 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.605]
Step 3835 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 567.0]  episode_count: 6763 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.607]
Step 3836 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 568.0]  episode_count: 6765 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.601]
Step 3837 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 569.0]  episode_count: 6769 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.603]
Step 3838 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 570.0]  episode_count: 6772 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.606]
{"total_number_of_episodes": 6774, "number_of_timesteps": 120902, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3839 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 571.0]  episode_count: 6774 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.6]
Step 3840 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 572.0]  episode_count: 6777 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.603]
Step 3841 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 573.0]  episode_count: 6780 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.605]
Step 3842 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 574.0]  episode_count: 6782 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.612]
Step 3843 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 575.0]  episode_count: 6783 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.614]
{"total_number_of_episodes": 6785, "number_of_timesteps": 121024, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3844 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 576.0]  episode_count: 6785 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.617]
Step 3845 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 577.0]  episode_count: 6789 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.61]
Step 3846 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 578.0]  episode_count: 6791 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.604]
{"total_number_of_episodes": 6795, "number_of_timesteps": 121156, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3847 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 579.0]  episode_count: 6795 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.608]
Step 3848 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 580.0]  episode_count: 6796 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.602]
Step 3849 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 581.0]  episode_count: 6799 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.596]
Step 3850 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 582.0]  episode_count: 6803 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.599]
{"total_number_of_episodes": 6805, "number_of_timesteps": 121272, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3851 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 583.0]  episode_count: 6805 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.601]
Step 3852 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 584.0]  episode_count: 6805 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.605]
Step 3853 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 585.0]  episode_count: 6810 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.608]
Step 3854 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 586.0]  episode_count: 6811 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.602]
{"total_number_of_episodes": 6815, "number_of_timesteps": 121402, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3855 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 587.0]  episode_count: 6815 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.605]
Step 3856 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 588.0]  episode_count: 6817 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.599]
Step 3857 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 589.0]  episode_count: 6819 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.593]
Step 3858 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 590.0]  episode_count: 6821 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.587]
Step 3859 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 591.0]  episode_count: 6822 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.581]
{"total_number_of_episodes": 6827, "number_of_timesteps": 121563, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3860 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 592.0]  episode_count: 6827 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.575]
Step 3861 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 593.0]  episode_count: 6828 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.569]
Step 3862 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 594.0]  episode_count: 6831 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.572]
Step 3863 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 595.0]  episode_count: 6834 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.575]
Step 3864 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 596.0]  episode_count: 6834 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.594]
{"total_number_of_episodes": 6839, "number_of_timesteps": 121714, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3865 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 597.0]  episode_count: 6839 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.597]
Step 3866 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 598.0]  episode_count: 6841 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.591]
Step 3867 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 599.0]  episode_count: 6842 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.593]
Step 3868 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 600.0]  episode_count: 6845 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.612]
Step 3869 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 601.0]  episode_count: 6847 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.606]
{"total_number_of_episodes": 6849, "number_of_timesteps": 121848, "per_episode_reward": 10.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 3870 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 602.0]  episode_count: 6849 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.6]
Step 3871 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 603.0]  episode_count: 6852 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.604]
Step 3872 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 604.0]  episode_count: 6854 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.598]
Step 3873 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 605.0]  episode_count: 6856 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.602]
Step 3874 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 606.0]  episode_count: 6856 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.604]
{"total_number_of_episodes": 6859, "number_of_timesteps": 121989, "per_episode_reward": 10.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 3875 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 607.0]  episode_count: 6859 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.607]
Step 3876 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 608.0]  episode_count: 6861 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.609]
Step 3877 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 609.0]  episode_count: 6862 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.614]
Step 3878 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 610.0]  episode_count: 6863 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.608]
Step 3879 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 611.0]  episode_count: 6865 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.612]
Step 3880 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 612.0]  episode_count: 6866 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.606]
Step 3881 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 613.0]  episode_count: 6867 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.6]
Step 3882 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 614.0]  episode_count: 6868 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.605]
{"total_number_of_episodes": 6871, "number_of_timesteps": 122236, "per_episode_reward": 10.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 3883 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 615.0]  episode_count: 6871 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.623]
Step 3884 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 616.0]  episode_count: 6873 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.637]
Step 3885 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 617.0]  episode_count: 6875 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.639]
Step 3886 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 618.0]  episode_count: 6876 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.633]
Step 3887 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 619.0]  episode_count: 6878 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.627]
Step 3888 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 620.0]  episode_count: 6879 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.632]
{"total_number_of_episodes": 6881, "number_of_timesteps": 122432, "per_episode_reward": 10.64, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 3889 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 621.0]  episode_count: 6881 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.626]
Step 3890 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 622.0]  episode_count: 6883 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.628]
Step 3891 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 623.0]  episode_count: 6885 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.635]
Step 3892 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 624.0]  episode_count: 6885 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.629]
Step 3893 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 625.0]  episode_count: 6886 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.623]
Step 3894 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 626.0]  episode_count: 6888 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.627]
{"total_number_of_episodes": 6892, "number_of_timesteps": 122654, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 3895 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 627.0]  episode_count: 6892 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.621]
Step 3896 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 628.0]  episode_count: 6892 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.623]
Step 3897 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 629.0]  episode_count: 6897 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.628]
Step 3898 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 630.0]  episode_count: 6897 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.63]
Step 3899 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 631.0]  episode_count: 6898 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.634]
Step 3900 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 632.0]  episode_count: 6900 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.636]
{"total_number_of_episodes": 6903, "number_of_timesteps": 122829, "per_episode_reward": 10.64, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 3901 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 633.0]  episode_count: 6903 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.631]
Step 3902 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 634.0]  episode_count: 6905 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.633]
Step 3903 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 635.0]  episode_count: 6905 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.627]
Step 3904 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 636.0]  episode_count: 6909 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.63]
Step 3905 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 637.0]  episode_count: 6910 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.635]
Step 3906 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 638.0]  episode_count: 6912 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.638]
{"total_number_of_episodes": 6913, "number_of_timesteps": 122991, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 3907 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 639.0]  episode_count: 6913 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.632]
Step 3908 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 640.0]  episode_count: 6915 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.634]
Step 3909 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 641.0]  episode_count: 6917 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.628]
Step 3910 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 642.0]  episode_count: 6918 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.632]
Step 3911 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 643.0]  episode_count: 6920 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.636]
Step 3912 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 644.0]  episode_count: 6920 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.639]
{"total_number_of_episodes": 6925, "number_of_timesteps": 123188, "per_episode_reward": 10.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 3913 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 645.0]  episode_count: 6925 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.634]
Step 3914 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 646.0]  episode_count: 6926 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.628]
Step 3915 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 647.0]  episode_count: 6927 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.622]
Step 3916 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 648.0]  episode_count: 6928 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.625]
Step 3917 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 649.0]  episode_count: 6931 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.627]
Step 3918 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 650.0]  episode_count: 6932 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.621]
{"total_number_of_episodes": 6935, "number_of_timesteps": 123401, "per_episode_reward": 10.64, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 3919 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 651.0]  episode_count: 6935 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.616]
Step 3920 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 652.0]  episode_count: 6936 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.618]
Step 3921 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 653.0]  episode_count: 6938 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.613]
Step 3922 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 654.0]  episode_count: 6941 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.617]
Step 3923 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 655.0]  episode_count: 6943 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.62]
Step 3924 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 656.0]  episode_count: 6944 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.614]
{"total_number_of_episodes": 6947, "number_of_timesteps": 123579, "per_episode_reward": 10.64, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 3925 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 657.0]  episode_count: 6947 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.618]
Step 3926 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 658.0]  episode_count: 6948 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.613]
Step 3927 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 659.0]  episode_count: 6951 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.615]
Step 3928 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 660.0]  episode_count: 6953 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.617]
Step 3929 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 661.0]  episode_count: 6954 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.619]
Step 3930 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 662.0]  episode_count: 6954 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.613]
{"total_number_of_episodes": 6959, "number_of_timesteps": 123773, "per_episode_reward": 10.64, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 3931 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 663.0]  episode_count: 6959 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.619]
Step 3932 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 664.0]  episode_count: 6960 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.613]
Step 3933 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 665.0]  episode_count: 6961 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.608]
Step 3934 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 666.0]  episode_count: 6964 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.612]
Step 3935 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 667.0]  episode_count: 6965 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.614]
Step 3936 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 668.0]  episode_count: 6965 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.631]
{"total_number_of_episodes": 6969, "number_of_timesteps": 123942, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 3937 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 669.0]  episode_count: 6969 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.634]
Step 3938 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 670.0]  episode_count: 6971 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.629]
Step 3939 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 671.0]  episode_count: 6972 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.634]
Step 3940 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 672.0]  episode_count: 6973 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.628]
Step 3941 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 673.0]  episode_count: 6974 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.623]
Step 3942 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 674.0]  episode_count: 6976 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.618]
Step 3943 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 675.0]  episode_count: 6978 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.619]
{"total_number_of_episodes": 6979, "number_of_timesteps": 124138, "per_episode_reward": 10.57, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 3944 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 676.0]  episode_count: 6979 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.623]
Step 3945 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 677.0]  episode_count: 6982 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.618]
Step 3946 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 678.0]  episode_count: 6982 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.621]
Step 3947 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 679.0]  episode_count: 6984 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.638]
Step 3948 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 680.0]  episode_count: 6984 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.632]
Step 3949 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 681.0]  episode_count: 6985 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.627]
Step 3950 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 682.0]  episode_count: 6985 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.63]
Step 3951 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 683.0]  episode_count: 6988 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.634]
{"total_number_of_episodes": 6989, "number_of_timesteps": 124347, "per_episode_reward": 10.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 3952 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 684.0]  episode_count: 6989 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.635]
Step 3953 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 685.0]  episode_count: 6989 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.644]
Step 3954 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 686.0]  episode_count: 6993 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.638]
Step 3955 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 687.0]  episode_count: 6994 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.655]
Step 3956 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 688.0]  episode_count: 6997 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.649]
{"total_number_of_episodes": 6999, "number_of_timesteps": 124568, "per_episode_reward": 10.57, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 3957 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 689.0]  episode_count: 6999 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.644]
Step 3958 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 690.0]  episode_count: 7001 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.646]
Step 3959 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 691.0]  episode_count: 7003 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.641]
Step 3960 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 692.0]  episode_count: 7005 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.643]
{"total_number_of_episodes": 7009, "number_of_timesteps": 124715, "per_episode_reward": 10.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 3961 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 693.0]  episode_count: 7009 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.637]
Step 3962 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 694.0]  episode_count: 7010 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.632]
Step 3963 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 695.0]  episode_count: 7012 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.627]
Step 3964 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 696.0]  episode_count: 7014 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.628]
Step 3965 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 697.0]  episode_count: 7015 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.623]
Step 3966 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 698.0]  episode_count: 7015 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.627]
Step 3967 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 699.0]  episode_count: 7018 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.628]
{"total_number_of_episodes": 7019, "number_of_timesteps": 124871, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 3968 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 700.0]  episode_count: 7019 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.629]
Step 3969 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 701.0]  episode_count: 7020 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.631]
Step 3970 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 702.0]  episode_count: 7023 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.634]
Step 3971 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 703.0]  episode_count: 7024 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.636]
Step 3972 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 704.0]  episode_count: 7025 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.637]
Step 3973 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 705.0]  episode_count: 7026 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.632]
Step 3974 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 706.0]  episode_count: 7027 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.636]
{"total_number_of_episodes": 7030, "number_of_timesteps": 125136, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 3975 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 707.0]  episode_count: 7030 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.631]
Step 3976 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 708.0]  episode_count: 7032 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.626]
Step 3977 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 709.0]  episode_count: 7032 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.628]
Step 3978 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 710.0]  episode_count: 7036 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.634]
Step 3979 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 711.0]  episode_count: 7038 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.635]
Step 3980 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 712.0]  episode_count: 7039 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.637]
Step 3981 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 713.0]  episode_count: 7039 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.64]
{"total_number_of_episodes": 7041, "number_of_timesteps": 125328, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 3982 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 714.0]  episode_count: 7041 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.642]
Step 3983 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 715.0]  episode_count: 7043 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.637]
Step 3984 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 716.0]  episode_count: 7044 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.639]
Step 3985 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 717.0]  episode_count: 7046 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.641]
Step 3986 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 718.0]  episode_count: 7048 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.636]
Step 3987 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 719.0]  episode_count: 7050 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.637]
{"total_number_of_episodes": 7051, "number_of_timesteps": 125534, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 3988 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 720.0]  episode_count: 7051 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.632]
Step 3989 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 721.0]  episode_count: 7053 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.634]
Step 3990 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 722.0]  episode_count: 7056 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.638]
Step 3991 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 723.0]  episode_count: 7057 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.633]
Step 3992 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 724.0]  episode_count: 7059 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.628]
Step 3993 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 725.0]  episode_count: 7059 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.629]
{"total_number_of_episodes": 7061, "number_of_timesteps": 125710, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 3994 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 726.0]  episode_count: 7061 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.624]
Step 3995 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 727.0]  episode_count: 7064 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.625]
Step 3996 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 728.0]  episode_count: 7065 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.62]
Step 3997 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 729.0]  episode_count: 7068 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.615]
Step 3998 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 730.0]  episode_count: 7068 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.616]
Step 3999 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 731.0]  episode_count: 7069 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.611]
{"total_number_of_episodes": 7073, "number_of_timesteps": 125936, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 4000 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 732.0]  episode_count: 7073 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.613]
Step 4001 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 733.0]  episode_count: 7074 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.616]
Step 4002 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 734.0]  episode_count: 7076 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.611]
Step 4003 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 735.0]  episode_count: 7079 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.614]
Step 4004 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 736.0]  episode_count: 7080 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.609]
Step 4005 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 737.0]  episode_count: 7081 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.61]
Step 4006 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 738.0]  episode_count: 7081 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.605]
{"total_number_of_episodes": 7084, "number_of_timesteps": 126137, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 4007 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 739.0]  episode_count: 7084 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.607]
Step 4008 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 740.0]  episode_count: 7086 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.608]
Step 4009 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 741.0]  episode_count: 7087 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.615]
Step 4010 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 742.0]  episode_count: 7089 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.616]
Step 4011 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 743.0]  episode_count: 7090 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.611]
Step 4012 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 744.0]  episode_count: 7092 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.606]
Step 4013 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 745.0]  episode_count: 7093 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.622]
{"total_number_of_episodes": 7096, "number_of_timesteps": 126382, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 4014 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 746.0]  episode_count: 7096 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.617]
Step 4015 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 747.0]  episode_count: 7097 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.612]
Step 4016 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 748.0]  episode_count: 7099 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.614]
Step 4017 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 749.0]  episode_count: 7101 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.629]
Step 4018 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 750.0]  episode_count: 7102 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.624]
Step 4019 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 751.0]  episode_count: 7103 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.625]
{"total_number_of_episodes": 7106, "number_of_timesteps": 126570, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 4020 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 752.0]  episode_count: 7106 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.628]
Step 4021 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 753.0]  episode_count: 7108 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.624]
Step 4022 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 754.0]  episode_count: 7110 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.625]
Step 4023 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 755.0]  episode_count: 7112 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.627]
Step 4024 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 756.0]  episode_count: 7113 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.622]
{"total_number_of_episodes": 7116, "number_of_timesteps": 126731, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 4025 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 757.0]  episode_count: 7116 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.617]
Step 4026 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 758.0]  episode_count: 7117 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.613]
Step 4027 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 759.0]  episode_count: 7117 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.608]
Step 4028 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 760.0]  episode_count: 7119 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.61]
Step 4029 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 761.0]  episode_count: 7120 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.612]
Step 4030 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 762.0]  episode_count: 7124 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.62]
Step 4031 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 763.0]  episode_count: 7124 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.621]
Step 4032 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 764.0]  episode_count: 7125 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.617]
{"total_number_of_episodes": 7128, "number_of_timesteps": 126979, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4033 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 765.0]  episode_count: 7128 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.62]
Step 4034 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 766.0]  episode_count: 7130 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.615]
Step 4035 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 767.0]  episode_count: 7130 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.617]
Step 4036 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 768.0]  episode_count: 7134 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.618]
Step 4037 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 769.0]  episode_count: 7135 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.633]
{"total_number_of_episodes": 7138, "number_of_timesteps": 127154, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4038 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 770.0]  episode_count: 7138 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.634]
Step 4039 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 771.0]  episode_count: 7138 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.629]
Step 4040 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 772.0]  episode_count: 7140 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.644]
Step 4041 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 773.0]  episode_count: 7143 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.639]
Step 4042 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 774.0]  episode_count: 7146 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.642]
Step 4043 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 775.0]  episode_count: 7147 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.643]
{"total_number_of_episodes": 7150, "number_of_timesteps": 127338, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4044 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 776.0]  episode_count: 7150 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.638]
Step 4045 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 777.0]  episode_count: 7152 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.639]
Step 4046 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 778.0]  episode_count: 7155 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.641]
Step 4047 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 779.0]  episode_count: 7156 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.642]
Step 4048 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 780.0]  episode_count: 7158 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.643]
Step 4049 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 781.0]  episode_count: 7158 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.644]
{"total_number_of_episodes": 7160, "number_of_timesteps": 127490, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4050 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 782.0]  episode_count: 7160 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.647]
Step 4051 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 783.0]  episode_count: 7163 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.648]
Step 4052 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 784.0]  episode_count: 7164 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.643]
Step 4053 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 785.0]  episode_count: 7165 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.638]
Step 4054 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 786.0]  episode_count: 7165 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.653]
Step 4055 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 787.0]  episode_count: 7167 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.655]
Step 4056 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 788.0]  episode_count: 7169 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.651]
{"total_number_of_episodes": 7171, "number_of_timesteps": 127722, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4057 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 789.0]  episode_count: 7171 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.646]
Step 4058 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 790.0]  episode_count: 7171 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.647]
Step 4059 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 791.0]  episode_count: 7171 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.649]
Step 4060 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 792.0]  episode_count: 7174 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.663]
Step 4061 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 793.0]  episode_count: 7175 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.665]
Step 4062 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 794.0]  episode_count: 7175 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.66]
Step 4063 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 795.0]  episode_count: 7176 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.663]
Step 4064 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 796.0]  episode_count: 7177 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.664]
Step 4065 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 797.0]  episode_count: 7178 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.662]
Step 4066 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 798.0]  episode_count: 7180 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.676]
Step 4067 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 799.0]  episode_count: 7180 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.671]
{"total_number_of_episodes": 7184, "number_of_timesteps": 128042, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4068 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 800.0]  episode_count: 7184 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.667]
Step 4069 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 801.0]  episode_count: 7184 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.662]
Step 4070 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 802.0]  episode_count: 7186 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.658]
Step 4071 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 803.0]  episode_count: 7188 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.659]
Step 4072 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 804.0]  episode_count: 7190 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.66]
Step 4073 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 805.0]  episode_count: 7191 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.656]
Step 4074 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 806.0]  episode_count: 7193 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.658]
{"total_number_of_episodes": 7196, "number_of_timesteps": 128308, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4075 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 807.0]  episode_count: 7196 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.654]
Step 4076 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 808.0]  episode_count: 7197 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.655]
Step 4077 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 809.0]  episode_count: 7198 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.669]
Step 4078 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 810.0]  episode_count: 7202 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.67]
Step 4079 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 811.0]  episode_count: 7203 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.672]
{"total_number_of_episodes": 7206, "number_of_timesteps": 128468, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4080 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 812.0]  episode_count: 7206 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.667]
Step 4081 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 813.0]  episode_count: 7209 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.668]
Step 4082 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 814.0]  episode_count: 7209 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.669]
Step 4083 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 815.0]  episode_count: 7213 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.664]
Step 4084 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 816.0]  episode_count: 7215 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.66]
{"total_number_of_episodes": 7217, "number_of_timesteps": 128616, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4085 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 817.0]  episode_count: 7217 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.655]
Step 4086 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 818.0]  episode_count: 7220 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.657]
Step 4087 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 819.0]  episode_count: 7220 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.652]
Step 4088 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 820.0]  episode_count: 7223 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.648]
Step 4089 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 821.0]  episode_count: 7224 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.649]
Step 4090 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 822.0]  episode_count: 7226 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.644]
{"total_number_of_episodes": 7228, "number_of_timesteps": 128798, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4091 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 823.0]  episode_count: 7228 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.645]
Step 4092 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 824.0]  episode_count: 7229 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.641]
Step 4093 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 825.0]  episode_count: 7231 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.636]
Step 4094 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 826.0]  episode_count: 7232 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.632]
Step 4095 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 827.0]  episode_count: 7234 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.633]
Step 4096 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 828.0]  episode_count: 7235 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.635]
Step 4097 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 829.0]  episode_count: 7236 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.636]
{"total_number_of_episodes": 7239, "number_of_timesteps": 128993, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
[-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.637]
Step 4099 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 831.0]  episode_count: 7239 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.638]
Step 4100 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 832.0]  episode_count: 7243 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.634]
Step 4101 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 833.0]  episode_count: 7244 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.63]
Step 4102 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 834.0]  episode_count: 7245 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.643]
{"total_number_of_episodes": 7249, "number_of_timesteps": 129191, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4103 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 835.0]  episode_count: 7249 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.639]
Step 4104 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 836.0]  episode_count: 7251 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.642]
Step 4105 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 837.0]  episode_count: 7252 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.638]
Step 4106 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 838.0]  episode_count: 7255 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.639]
Step 4107 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 839.0]  episode_count: 7256 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.641]
Step 4108 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 840.0]  episode_count: 7258 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.644]
{"total_number_of_episodes": 7259, "number_of_timesteps": 129347, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4109 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 841.0]  episode_count: 7259 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.646]
Step 4110 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 842.0]  episode_count: 7260 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.647]
Step 4111 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 843.0]  episode_count: 7261 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.649]
Step 4112 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 844.0]  episode_count: 7263 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.653]
Step 4113 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 845.0]  episode_count: 7264 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.648]
Step 4114 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 846.0]  episode_count: 7266 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.644]
{"total_number_of_episodes": 7269, "number_of_timesteps": 129573, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4115 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 847.0]  episode_count: 7269 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.646]
Step 4116 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 848.0]  episode_count: 7269 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.649]
Step 4117 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 849.0]  episode_count: 7271 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.65]
Step 4118 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 850.0]  episode_count: 7273 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.646]
Step 4119 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 851.0]  episode_count: 7274 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.641]
Step 4120 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 852.0]  episode_count: 7276 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.642]
Step 4121 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 853.0]  episode_count: 7277 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.643]
Step 4122 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 854.0]  episode_count: 7278 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.639]
{"total_number_of_episodes": 7280, "number_of_timesteps": 129793, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4123 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 855.0]  episode_count: 7280 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.635]
Step 4124 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 856.0]  episode_count: 7282 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.631]
Step 4125 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 857.0]  episode_count: 7282 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.633]
Step 4126 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 858.0]  episode_count: 7282 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.629]
Step 4127 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 859.0]  episode_count: 7287 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.63]
Step 4128 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 860.0]  episode_count: 7288 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.626]
Step 4129 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 861.0]  episode_count: 7289 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.639]
{"total_number_of_episodes": 7293, "number_of_timesteps": 130058, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4130 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 862.0]  episode_count: 7293 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.635]
Step 4131 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 863.0]  episode_count: 7295 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.63]
Step 4132 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 864.0]  episode_count: 7295 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.626]
Step 4133 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 865.0]  episode_count: 7297 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.622]
Step 4134 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 866.0]  episode_count: 7301 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.618]
Step 4135 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 867.0]  episode_count: 7301 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.614]
Step 4136 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 868.0]  episode_count: 7301 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.617]
{"total_number_of_episodes": 7303, "number_of_timesteps": 130208, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4137 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 869.0]  episode_count: 7303 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.618]
Step 4138 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 870.0]  episode_count: 7305 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.62]
Step 4139 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 871.0]  episode_count: 7308 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.621]
Step 4140 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 872.0]  episode_count: 7308 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.617]
Step 4141 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 873.0]  episode_count: 7311 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.612]
Step 4142 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 874.0]  episode_count: 7312 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.625]
{"total_number_of_episodes": 7313, "number_of_timesteps": 130428, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4143 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 875.0]  episode_count: 7313 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.638]
Step 4144 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 876.0]  episode_count: 7314 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.64]
Step 4145 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 877.0]  episode_count: 7317 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.64]
Step 4146 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 878.0]  episode_count: 7319 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.636]
Step 4147 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 879.0]  episode_count: 7320 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.649]
{"total_number_of_episodes": 7323, "number_of_timesteps": 130598, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4148 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 880.0]  episode_count: 7323 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.645]
Step 4149 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 881.0]  episode_count: 7324 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.646]
Step 4150 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 882.0]  episode_count: 7327 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.649]
Step 4151 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 883.0]  episode_count: 7328 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.661]
Step 4152 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 884.0]  episode_count: 7332 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.657]
Step 4153 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 885.0]  episode_count: 7332 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.67]
{"total_number_of_episodes": 7334, "number_of_timesteps": 130785, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4154 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 886.0]  episode_count: 7334 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.672]
Step 4155 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 887.0]  episode_count: 7337 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.673]
Step 4156 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 888.0]  episode_count: 7339 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.675]
Step 4157 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 889.0]  episode_count: 7340 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.671]
Step 4158 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 890.0]  episode_count: 7342 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.667]
Step 4159 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 891.0]  episode_count: 7342 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.668]
{"total_number_of_episodes": 7345, "number_of_timesteps": 130976, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4160 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 892.0]  episode_count: 7345 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.664]
Step 4161 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 893.0]  episode_count: 7347 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.659]
Step 4162 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 894.0]  episode_count: 7347 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.655]
Step 4163 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 895.0]  episode_count: 7352 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.651]
Step 4164 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 896.0]  episode_count: 7352 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.653]
Step 4165 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 897.0]  episode_count: 7354 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.654]
{"total_number_of_episodes": 7356, "number_of_timesteps": 131168, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4166 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 898.0]  episode_count: 7356 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.649]
Step 4167 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 899.0]  episode_count: 7357 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.65]
Step 4168 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 900.0]  episode_count: 7359 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.646]
Step 4169 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 901.0]  episode_count: 7360 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.642]
Step 4170 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 902.0]  episode_count: 7363 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.645]
Step 4171 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 903.0]  episode_count: 7365 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.646]
{"total_number_of_episodes": 7367, "number_of_timesteps": 131370, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4172 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 904.0]  episode_count: 7367 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.648]
Step 4173 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 905.0]  episode_count: 7370 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.661]
Step 4174 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 906.0]  episode_count: 7372 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.662]
Step 4175 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 907.0]  episode_count: 7374 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.658]
{"total_number_of_episodes": 7377, "number_of_timesteps": 131492, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4176 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 908.0]  episode_count: 7377 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.67]
Step 4177 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 909.0]  episode_count: 7379 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.666]
Step 4178 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 910.0]  episode_count: 7379 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.662]
Step 4179 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 911.0]  episode_count: 7381 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.665]
Step 4180 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 912.0]  episode_count: 7386 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.661]
{"total_number_of_episodes": 7387, "number_of_timesteps": 131655, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4181 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 913.0]  episode_count: 7387 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.662]
Step 4182 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 914.0]  episode_count: 7387 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.675]
Step 4183 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 915.0]  episode_count: 7389 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.671]
Step 4184 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 916.0]  episode_count: 7391 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.673]
Step 4185 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 917.0]  episode_count: 7392 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.674]
Step 4186 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 918.0]  episode_count: 7394 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.675]
Step 4187 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 919.0]  episode_count: 7396 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.677]
{"total_number_of_episodes": 7398, "number_of_timesteps": 131866, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4188 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 920.0]  episode_count: 7398 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.678]
Step 4189 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 921.0]  episode_count: 7401 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.679]
Step 4190 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 922.0]  episode_count: 7401 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.681]
Step 4191 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 923.0]  episode_count: 7404 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.677]
Step 4192 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 924.0]  episode_count: 7407 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.68]
{"total_number_of_episodes": 7409, "number_of_timesteps": 132033, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4193 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 925.0]  episode_count: 7409 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.681]
Step 4194 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 926.0]  episode_count: 7409 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.693]
Step 4195 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 927.0]  episode_count: 7412 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.689]
Step 4196 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 928.0]  episode_count: 7414 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.685]
Step 4197 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 929.0]  episode_count: 7416 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.681]
Step 4198 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 930.0]  episode_count: 7417 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.682]
{"total_number_of_episodes": 7419, "number_of_timesteps": 132195, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4199 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 931.0]  episode_count: 7419 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.678]
Step 4200 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 932.0]  episode_count: 7421 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.674]
Step 4201 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 933.0]  episode_count: 7423 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.67]
Step 4202 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 934.0]  episode_count: 7425 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.667]
Step 4203 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 935.0]  episode_count: 7428 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.667]
{"total_number_of_episodes": 7430, "number_of_timesteps": 132364, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4204 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 936.0]  episode_count: 7430 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.668]
Step 4205 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 937.0]  episode_count: 7433 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.68]
Step 4206 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 938.0]  episode_count: 7436 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.676]
Step 4207 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 939.0]  episode_count: 7437 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.677]
Step 4208 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 940.0]  episode_count: 7439 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.679]
{"total_number_of_episodes": 7441, "number_of_timesteps": 132491, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4209 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 941.0]  episode_count: 7441 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.68]
Step 4210 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 942.0]  episode_count: 7444 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.682]
Step 4211 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 943.0]  episode_count: 7444 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.682]
Step 4212 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 944.0]  episode_count: 7446 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.678]
Step 4213 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 945.0]  episode_count: 7449 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.68]
{"total_number_of_episodes": 7451, "number_of_timesteps": 132656, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4214 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 946.0]  episode_count: 7451 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.682]
Step 4215 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 947.0]  episode_count: 7453 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.683]
Step 4216 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 948.0]  episode_count: 7454 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.684]
Step 4217 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 949.0]  episode_count: 7456 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.686]
Step 4218 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 950.0]  episode_count: 7459 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.687]
{"total_number_of_episodes": 7462, "number_of_timesteps": 132830, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4219 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 951.0]  episode_count: 7462 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.688]
Step 4220 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 952.0]  episode_count: 7462 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.689]
Step 4221 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 953.0]  episode_count: 7465 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.69]
Step 4222 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 954.0]  episode_count: 7469 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.691]
Step 4223 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 955.0]  episode_count: 7470 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.688]
{"total_number_of_episodes": 7475, "number_of_timesteps": 132989, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4224 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 956.0]  episode_count: 7475 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.684]
Step 4225 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 957.0]  episode_count: 7475 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.68]
Step 4226 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 958.0]  episode_count: 7475 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.681]
Step 4227 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 959.0]  episode_count: 7477 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.677]
Step 4228 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 960.0]  episode_count: 7480 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.673]
Step 4229 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 961.0]  episode_count: 7480 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.67]
Step 4230 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 962.0]  episode_count: 7481 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.681]
Step 4231 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 963.0]  episode_count: 7484 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.682]
{"total_number_of_episodes": 7485, "number_of_timesteps": 133164, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4232 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 964.0]  episode_count: 7485 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.683]
Step 4233 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 965.0]  episode_count: 7487 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.68]
Step 4234 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 966.0]  episode_count: 7490 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.676]
Step 4235 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 967.0]  episode_count: 7490 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.672]
Step 4236 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 968.0]  episode_count: 7491 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.668]
Step 4237 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 969.0]  episode_count: 7493 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.67]
{"total_number_of_episodes": 7495, "number_of_timesteps": 133365, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4238 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 970.0]  episode_count: 7495 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.671]
Step 4239 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 971.0]  episode_count: 7496 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.674]
Step 4240 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 972.0]  episode_count: 7500 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.679]
Step 4241 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 973.0]  episode_count: 7500 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.678]
Step 4242 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 974.0]  episode_count: 7501 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.674]
Step 4243 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 975.0]  episode_count: 7503 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.671]
{"total_number_of_episodes": 7506, "number_of_timesteps": 133586, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4244 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 976.0]  episode_count: 7506 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.667]

Step 4246 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 978.0]  episode_count: 7508 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.664]
Step 4247 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 979.0]  episode_count: 7511 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.66]
Step 4248 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 980.0]  episode_count: 7512 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.661]
Step 4249 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 981.0]  episode_count: 7514 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.657]
Step 4250 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 982.0]  episode_count: 7514 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.669]
{"total_number_of_episodes": 7517, "number_of_timesteps": 133790, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4251 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 983.0]  episode_count: 7517 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.67]
Step 4252 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 984.0]  episode_count: 7518 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.673]
Step 4253 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 985.0]  episode_count: 7521 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.673]
Step 4254 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 986.0]  episode_count: 7522 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.674]
Step 4255 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 987.0]  episode_count: 7522 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.686]
Step 4256 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 988.0]  episode_count: 7526 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.687]
{"total_number_of_episodes": 7527, "number_of_timesteps": 133985, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4257 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 989.0]  episode_count: 7527 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.687]
Step 4258 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 990.0]  episode_count: 7528 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.699]
Step 4259 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 991.0]  episode_count: 7530 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.7]
Step 4260 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 992.0]  episode_count: 7533 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.703]
Step 4261 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 993.0]  episode_count: 7533 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.699]
Step 4262 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 994.0]  episode_count: 7534 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.695]
Step 4263 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 995.0]  episode_count: 7535 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.691]
Step 4264 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 996.0]  episode_count: 7536 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.703]
{"total_number_of_episodes": 7540, "number_of_timesteps": 134230, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4265 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 997.0]  episode_count: 7540 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.704]
Step 4266 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 998.0]  episode_count: 7541 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.705]
Step 4267 6 visits [1000.0, 1000.0, 7.0, 153.0, 4.0, 62.0, 999.0]  episode_count: 7543 q_vals: [-inf, -inf, -4.666, -3.952, -5.81, -4.132, -3.703]
Step 4268 6 visits [1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 1000.0]  episode_count: 7546 q_vals: [-inf, -inf, 0.0, 0.0, 0.0, 0.0, -inf]
{"total_number_of_episodes": 7551, "number_of_timesteps": 134435, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 7561, "number_of_timesteps": 134585, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 7573, "number_of_timesteps": 134867, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 7583, "number_of_timesteps": 135073, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 7593, "number_of_timesteps": 135332, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 7603, "number_of_timesteps": 135505, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 7615, "number_of_timesteps": 135710, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},

{"total_number_of_episodes": 7626, "number_of_timesteps": 135862, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 7638, "number_of_timesteps": 136016, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 7649, "number_of_timesteps": 136207, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7659, "number_of_timesteps": 136378, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7670, "number_of_timesteps": 136598, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7680, "number_of_timesteps": 136812, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7690, "number_of_timesteps": 137050, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7700, "number_of_timesteps": 137200, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7711, "number_of_timesteps": 137420, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7722, "number_of_timesteps": 137676, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7732, "number_of_timesteps": 137897, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7743, "number_of_timesteps": 138125, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7753, "number_of_timesteps": 138326, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7764, "number_of_timesteps": 138539, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7775, "number_of_timesteps": 138741, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7787, "number_of_timesteps": 138886, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7797, "number_of_timesteps": 139018, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7810, "number_of_timesteps": 139185, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7821, "number_of_timesteps": 139331, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7831, "number_of_timesteps": 139468, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7845, "number_of_timesteps": 139783, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7856, "number_of_timesteps": 139993, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7866, "number_of_timesteps": 140198, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7876, "number_of_timesteps": 140365, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7886, "number_of_timesteps": 140519, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7897, "number_of_timesteps": 140715, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7909, "number_of_timesteps": 140914, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7921, "number_of_timesteps": 141069, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7931, "number_of_timesteps": 141183, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7942, "number_of_timesteps": 141306, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7952, "number_of_timesteps": 141437, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7962, "number_of_timesteps": 141554, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7974, "number_of_timesteps": 141715, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7985, "number_of_timesteps": 141855, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7996, "number_of_timesteps": 141992, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8008, "number_of_timesteps": 142159, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8022, "number_of_timesteps": 142359, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8032, "number_of_timesteps": 142481, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8042, "number_of_timesteps": 142597, "per_episode_reward": 8.5, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8054, "number_of_timesteps": 142735, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8064, "number_of_timesteps": 142856, "per_episode_reward": 8.5, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8076, "number_of_timesteps": 143013, "per_episode_reward": 8.5, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8087, "number_of_timesteps": 143149, "per_episode_reward": 8.5, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8099, "number_of_timesteps": 143316, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8109, "number_of_timesteps": 143437, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8121, "number_of_timesteps": 143636, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8131, "number_of_timesteps": 143765, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8141, "number_of_timesteps": 143913, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8151, "number_of_timesteps": 144063, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8164, "number_of_timesteps": 144297, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8176, "number_of_timesteps": 144482, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8186, "number_of_timesteps": 144600, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8196, "number_of_timesteps": 144724, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8207, "number_of_timesteps": 144868, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8218, "number_of_timesteps": 145051, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8229, "number_of_timesteps": 145371, "per_episode_reward": 8.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8240, "number_of_timesteps": 145646, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8251, "number_of_timesteps": 145872, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8262, "number_of_timesteps": 146064, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8272, "number_of_timesteps": 146279, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8282, "number_of_timesteps": 146451, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8292, "number_of_timesteps": 146594, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8303, "number_of_timesteps": 146746, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8315, "number_of_timesteps": 146885, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8326, "number_of_timesteps": 147035, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8338, "number_of_timesteps": 147175, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8348, "number_of_timesteps": 147309, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8358, "number_of_timesteps": 147456, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8369, "number_of_timesteps": 147664, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8380, "number_of_timesteps": 147847, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8390, "number_of_timesteps": 147976, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8400, "number_of_timesteps": 148096, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8411, "number_of_timesteps": 148246, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8421, "number_of_timesteps": 148389, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8431, "number_of_timesteps": 148528, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8441, "number_of_timesteps": 148675, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8452, "number_of_timesteps": 148816, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8463, "number_of_timesteps": 148941, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8473, "number_of_timesteps": 149070, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8485, "number_of_timesteps": 149258, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8496, "number_of_timesteps": 149414, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8508, "number_of_timesteps": 149661, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8519, "number_of_timesteps": 149802, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8530, "number_of_timesteps": 149952, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8540, "number_of_timesteps": 150164, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8551, "number_of_timesteps": 150347, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8561, "number_of_timesteps": 150520, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8571, "number_of_timesteps": 150719, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8582, "number_of_timesteps": 150933, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8593, "number_of_timesteps": 151129, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8604, "number_of_timesteps": 151335, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8616, "number_of_timesteps": 151514, "per_episode_reward": 8.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8626, "number_of_timesteps": 151627, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8636, "number_of_timesteps": 151767, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8646, "number_of_timesteps": 151902, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8658, "number_of_timesteps": 152075, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8668, "number_of_timesteps": 152348, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8679, "number_of_timesteps": 152594, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8689, "number_of_timesteps": 152776, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8699, "number_of_timesteps": 152990, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8711, "number_of_timesteps": 153215, "per_episode_reward": 8.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8722, "number_of_timesteps": 153426, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8733, "number_of_timesteps": 153675, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8744, "number_of_timesteps": 153890, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8755, "number_of_timesteps": 154182, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8766, "number_of_timesteps": 154402, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8776, "number_of_timesteps": 154614, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8787, "number_of_timesteps": 154832, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8798, "number_of_timesteps": 155070, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8809, "number_of_timesteps": 155273, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8819, "number_of_timesteps": 155455, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8829, "number_of_timesteps": 155649, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8839, "number_of_timesteps": 155934, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8849, "number_of_timesteps": 156084, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8860, "number_of_timesteps": 156263, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8870, "number_of_timesteps": 156416, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8880, "number_of_timesteps": 156553, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8892, "number_of_timesteps": 156740, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8904, "number_of_timesteps": 156937, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8915, "number_of_timesteps": 157181, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8927, "number_of_timesteps": 157372, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8939, "number_of_timesteps": 157586, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8950, "number_of_timesteps": 157761, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8960, "number_of_timesteps": 157964, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8972, "number_of_timesteps": 158164, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8982, "number_of_timesteps": 158331, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8993, "number_of_timesteps": 158549, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9003, "number_of_timesteps": 158814, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9013, "number_of_timesteps": 159043, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9023, "number_of_timesteps": 159229, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9035, "number_of_timesteps": 159408, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9045, "number_of_timesteps": 159677, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9055, "number_of_timesteps": 159883, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9067, "number_of_timesteps": 160125, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9077, "number_of_timesteps": 160334, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9090, "number_of_timesteps": 160512, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9101, "number_of_timesteps": 160676, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9112, "number_of_timesteps": 160859, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9123, "number_of_timesteps": 161121, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9133, "number_of_timesteps": 161337, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9144, "number_of_timesteps": 161672, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9155, "number_of_timesteps": 161896, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9166, "number_of_timesteps": 162094, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9176, "number_of_timesteps": 162333, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9186, "number_of_timesteps": 162505, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9198, "number_of_timesteps": 162761, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9209, "number_of_timesteps": 162967, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9220, "number_of_timesteps": 163197, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9231, "number_of_timesteps": 163422, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9242, "number_of_timesteps": 163658, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9252, "number_of_timesteps": 163846, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9262, "number_of_timesteps": 164030, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9274, "number_of_timesteps": 164288, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9284, "number_of_timesteps": 164474, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9295, "number_of_timesteps": 164673, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9305, "number_of_timesteps": 164886, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9317, "number_of_timesteps": 165178, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9327, "number_of_timesteps": 165383, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9338, "number_of_timesteps": 165621, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9349, "number_of_timesteps": 165896, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9359, "number_of_timesteps": 166209, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9369, "number_of_timesteps": 166438, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9379, "number_of_timesteps": 166769, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9389, "number_of_timesteps": 166980, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9402, "number_of_timesteps": 167219, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9412, "number_of_timesteps": 167406, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9424, "number_of_timesteps": 167616, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9434, "number_of_timesteps": 167789, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9444, "number_of_timesteps": 167985, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9455, "number_of_timesteps": 168293, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9466, "number_of_timesteps": 168550, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9476, "number_of_timesteps": 168822, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9487, "number_of_timesteps": 169085, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9498, "number_of_timesteps": 169384, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9509, "number_of_timesteps": 169670, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9519, "number_of_timesteps": 169898, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9530, "number_of_timesteps": 170131, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9541, "number_of_timesteps": 170467, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9551, "number_of_timesteps": 170701, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9561, "number_of_timesteps": 170894, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9571, "number_of_timesteps": 171109, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9581, "number_of_timesteps": 171345, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9591, "number_of_timesteps": 171610, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9602, "number_of_timesteps": 171890, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9612, "number_of_timesteps": 172128, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9622, "number_of_timesteps": 172471, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9632, "number_of_timesteps": 172723, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9642, "number_of_timesteps": 172951, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9652, "number_of_timesteps": 173194, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9662, "number_of_timesteps": 173374, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9672, "number_of_timesteps": 173597, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9684, "number_of_timesteps": 173824, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9697, "number_of_timesteps": 174075, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9707, "number_of_timesteps": 174332, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9717, "number_of_timesteps": 174586, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9728, "number_of_timesteps": 174958, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9739, "number_of_timesteps": 175256, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9750, "number_of_timesteps": 175546, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9761, "number_of_timesteps": 175784, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9771, "number_of_timesteps": 176192, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9782, "number_of_timesteps": 176501, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9792, "number_of_timesteps": 176856, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9802, "number_of_timesteps": 177094, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9813, "number_of_timesteps": 177465, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9823, "number_of_timesteps": 177728, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9833, "number_of_timesteps": 177905, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9843, "number_of_timesteps": 178157, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9853, "number_of_timesteps": 178413, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9863, "number_of_timesteps": 178701, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9873, "number_of_timesteps": 178994, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9884, "number_of_timesteps": 179359, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9894, "number_of_timesteps": 179554, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9904, "number_of_timesteps": 179802, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9914, "number_of_timesteps": 180109, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9926, "number_of_timesteps": 180412, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9936, "number_of_timesteps": 180691, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9946, "number_of_timesteps": 181080, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9957, "number_of_timesteps": 181427, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9968, "number_of_timesteps": 181823, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9979, "number_of_timesteps": 182189, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9989, "number_of_timesteps": 182493, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9999, "number_of_timesteps": 182749, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10010, "number_of_timesteps": 183033, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10020, "number_of_timesteps": 183361, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10030, "number_of_timesteps": 183644, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10040, "number_of_timesteps": 183990, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10050, "number_of_timesteps": 184323, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10061, "number_of_timesteps": 184711, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10072, "number_of_timesteps": 185117, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10082, "number_of_timesteps": 185365, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10092, "number_of_timesteps": 185659, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10102, "number_of_timesteps": 185952, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10112, "number_of_timesteps": 186216, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10122, "number_of_timesteps": 186376, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10135, "number_of_timesteps": 186686, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10145, "number_of_timesteps": 186962, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10155, "number_of_timesteps": 187271, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10165, "number_of_timesteps": 187648, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10175, "number_of_timesteps": 188025, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10185, "number_of_timesteps": 188247, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10196, "number_of_timesteps": 188643, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10206, "number_of_timesteps": 189122, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10218, "number_of_timesteps": 189497, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10229, "number_of_timesteps": 189902, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10239, "number_of_timesteps": 190242, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10249, "number_of_timesteps": 190699, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10260, "number_of_timesteps": 191035, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10271, "number_of_timesteps": 191488, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10282, "number_of_timesteps": 191768, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10292, "number_of_timesteps": 192144, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10302, "number_of_timesteps": 192511, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10312, "number_of_timesteps": 192993, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10323, "number_of_timesteps": 193421, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10333, "number_of_timesteps": 193829, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10343, "number_of_timesteps": 194155, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10353, "number_of_timesteps": 194511, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10363, "number_of_timesteps": 194989, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10375, "number_of_timesteps": 195480, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10386, "number_of_timesteps": 195970, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10396, "number_of_timesteps": 196434, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10406, "number_of_timesteps": 196704, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10416, "number_of_timesteps": 197374, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10426, "number_of_timesteps": 198112, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10436, "number_of_timesteps": 198571, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10447, "number_of_timesteps": 199176, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10457, "number_of_timesteps": 199592, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10467, "number_of_timesteps": 200141, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10477, "number_of_timesteps": 200727, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10487, "number_of_timesteps": 201206, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10497, "number_of_timesteps": 201661, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10507, "number_of_timesteps": 202357, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10517, "number_of_timesteps": 203154, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10527, "number_of_timesteps": 203669, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10537, "number_of_timesteps": 204274, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10547, "number_of_timesteps": 204928, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10557, "number_of_timesteps": 205827, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10567, "number_of_timesteps": 206595, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10577, "number_of_timesteps": 207004, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10589, "number_of_timesteps": 207629, "per_episode_reward": 8.64, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10601, "number_of_timesteps": 208049, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10611, "number_of_timesteps": 208894, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10621, "number_of_timesteps": 209773, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10631, "number_of_timesteps": 210438, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10641, "number_of_timesteps": 211127, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10652, "number_of_timesteps": 212191, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10662, "number_of_timesteps": 212512, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10672, "number_of_timesteps": 213753, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10682, "number_of_timesteps": 214841, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10692, "number_of_timesteps": 216373, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10703, "number_of_timesteps": 217993, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10714, "number_of_timesteps": 219329, "per_episode_reward": 8.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10724, "number_of_timesteps": 221024, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10734, "number_of_timesteps": 222880, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10744, "number_of_timesteps": 224200, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10754, "number_of_timesteps": 225633, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10764, "number_of_timesteps": 226510, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10774, "number_of_timesteps": 228167, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10784, "number_of_timesteps": 229606, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10794, "number_of_timesteps": 231077, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 10804, "number_of_timesteps": 231903, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10814, "number_of_timesteps": 233018, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10824, "number_of_timesteps": 233849, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10836, "number_of_timesteps": 234739, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10846, "number_of_timesteps": 235179, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10856, "number_of_timesteps": 235770, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10866, "number_of_timesteps": 236093, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10877, "number_of_timesteps": 236481, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10887, "number_of_timesteps": 236836, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10898, "number_of_timesteps": 237227, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10908, "number_of_timesteps": 237531, "per_episode_reward": 8.93, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10918, "number_of_timesteps": 237887, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 10929, "number_of_timesteps": 238225, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10939, "number_of_timesteps": 238479, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10950, "number_of_timesteps": 239182, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10961, "number_of_timesteps": 239544, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10973, "number_of_timesteps": 240278, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10983, "number_of_timesteps": 240758, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 10993, "number_of_timesteps": 241253, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 11003, "number_of_timesteps": 241523, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 11014, "number_of_timesteps": 242136, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 11024, "number_of_timesteps": 242604, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11035, "number_of_timesteps": 242894, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11045, "number_of_timesteps": 243474, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11055, "number_of_timesteps": 243851, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11065, "number_of_timesteps": 244259, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11075, "number_of_timesteps": 244585, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11086, "number_of_timesteps": 244915, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11097, "number_of_timesteps": 245276, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11107, "number_of_timesteps": 245475, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11118, "number_of_timesteps": 245873, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11128, "number_of_timesteps": 246671, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11138, "number_of_timesteps": 247556, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11148, "number_of_timesteps": 247901, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11158, "number_of_timesteps": 248358, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11168, "number_of_timesteps": 249103, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11178, "number_of_timesteps": 250130, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11188, "number_of_timesteps": 251092, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11198, "number_of_timesteps": 251487, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11208, "number_of_timesteps": 252563, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11219, "number_of_timesteps": 253580, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11231, "number_of_timesteps": 254262, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11241, "number_of_timesteps": 254986, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11251, "number_of_timesteps": 255430, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11261, "number_of_timesteps": 256432, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11271, "number_of_timesteps": 256913, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11281, "number_of_timesteps": 257134, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11291, "number_of_timesteps": 257388, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11301, "number_of_timesteps": 257821, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11311, "number_of_timesteps": 258964, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11321, "number_of_timesteps": 260409, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11331, "number_of_timesteps": 262185, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11341, "number_of_timesteps": 263956, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11351, "number_of_timesteps": 266054, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11362, "number_of_timesteps": 267691, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11372, "number_of_timesteps": 268325, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11382, "number_of_timesteps": 269426, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11392, "number_of_timesteps": 270678, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11402, "number_of_timesteps": 271574, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11412, "number_of_timesteps": 272805, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 11422, "number_of_timesteps": 274002, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11432, "number_of_timesteps": 275311, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11442, "number_of_timesteps": 276420, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11452, "number_of_timesteps": 277487, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11462, "number_of_timesteps": 278765, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11472, "number_of_timesteps": 280252, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11482, "number_of_timesteps": 281165, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11493, "number_of_timesteps": 282388, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11503, "number_of_timesteps": 283618, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11513, "number_of_timesteps": 284549, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11523, "number_of_timesteps": 285876, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11533, "number_of_timesteps": 287230, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11543, "number_of_timesteps": 288561, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11553, "number_of_timesteps": 289791, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11563, "number_of_timesteps": 290786, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11573, "number_of_timesteps": 291586, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11583, "number_of_timesteps": 292092, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11593, "number_of_timesteps": 293194, "per_episode_reward": 9.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11603, "number_of_timesteps": 295170, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11614, "number_of_timesteps": 296849, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11624, "number_of_timesteps": 298962, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},

{"total_number_of_episodes": 11634, "number_of_timesteps": 301916, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11644, "number_of_timesteps": 303431, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11654, "number_of_timesteps": 304398, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11664, "number_of_timesteps": 305302, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11674, "number_of_timesteps": 306506, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11684, "number_of_timesteps": 308384, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11694, "number_of_timesteps": 309861, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11704, "number_of_timesteps": 310168, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11716, "number_of_timesteps": 310742, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11726, "number_of_timesteps": 311423, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11736, "number_of_timesteps": 311749, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11747, "number_of_timesteps": 312247, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11757, "number_of_timesteps": 312584, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11767, "number_of_timesteps": 313266, "per_episode_reward": 9.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11777, "number_of_timesteps": 315453, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11787, "number_of_timesteps": 317185, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11797, "number_of_timesteps": 319323, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11807, "number_of_timesteps": 320891, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11818, "number_of_timesteps": 322848, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11828, "number_of_timesteps": 324034, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11838, "number_of_timesteps": 325351, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 11848, "number_of_timesteps": 327374, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11858, "number_of_timesteps": 329665, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11868, "number_of_timesteps": 331277, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11878, "number_of_timesteps": 333589, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11888, "number_of_timesteps": 335934, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11898, "number_of_timesteps": 338096, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11908, "number_of_timesteps": 340357, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11918, "number_of_timesteps": 342698, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11928, "number_of_timesteps": 345381, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11938, "number_of_timesteps": 347572, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11948, "number_of_timesteps": 349485, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 11958, "number_of_timesteps": 352309, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 11968, "number_of_timesteps": 354741, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 11978, "number_of_timesteps": 357045, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 11988, "number_of_timesteps": 360472, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 11998, "number_of_timesteps": 364351, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12008, "number_of_timesteps": 368266, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12018, "number_of_timesteps": 372397, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12028, "number_of_timesteps": 376006, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 12038, "number_of_timesteps": 379784, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12049, "number_of_timesteps": 383028, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12059, "number_of_timesteps": 386235, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12070, "number_of_timesteps": 387982, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12080, "number_of_timesteps": 388447, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12091, "number_of_timesteps": 388649, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12101, "number_of_timesteps": 388866, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12112, "number_of_timesteps": 389052, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12124, "number_of_timesteps": 389239, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12134, "number_of_timesteps": 389404, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12144, "number_of_timesteps": 389718, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 12155, "number_of_timesteps": 390011, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12165, "number_of_timesteps": 390870, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12175, "number_of_timesteps": 391791, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12185, "number_of_timesteps": 392416, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12195, "number_of_timesteps": 392942, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12205, "number_of_timesteps": 393889, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12216, "number_of_timesteps": 395575, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12226, "number_of_timesteps": 396758, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12237, "number_of_timesteps": 397626, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12248, "number_of_timesteps": 399383, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12258, "number_of_timesteps": 400664, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12269, "number_of_timesteps": 402158, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12279, "number_of_timesteps": 403252, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12289, "number_of_timesteps": 404170, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12300, "number_of_timesteps": 404585, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12312, "number_of_timesteps": 405746, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12322, "number_of_timesteps": 406037, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12332, "number_of_timesteps": 406759, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12342, "number_of_timesteps": 407612, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12352, "number_of_timesteps": 410079, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12362, "number_of_timesteps": 411943, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12372, "number_of_timesteps": 413328, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12382, "number_of_timesteps": 414839, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12392, "number_of_timesteps": 416554, "per_episode_reward": 9.64, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12402, "number_of_timesteps": 417932, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12412, "number_of_timesteps": 420468, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12422, "number_of_timesteps": 423762, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12432, "number_of_timesteps": 426760, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12442, "number_of_timesteps": 428682, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12452, "number_of_timesteps": 432688, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12463, "number_of_timesteps": 436039, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12473, "number_of_timesteps": 439009, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12483, "number_of_timesteps": 442993, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12493, "number_of_timesteps": 445225, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12503, "number_of_timesteps": 446142, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12513, "number_of_timesteps": 449687, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12523, "number_of_timesteps": 453807, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12533, "number_of_timesteps": 458508, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12543, "number_of_timesteps": 463508, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12553, "number_of_timesteps": 468093, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12563, "number_of_timesteps": 470645, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12573, "number_of_timesteps": 475645, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12583, "number_of_timesteps": 480645, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12593, "number_of_timesteps": 485591, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12603, "number_of_timesteps": 490591, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12613, "number_of_timesteps": 495591, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12623, "number_of_timesteps": 500455, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12633, "number_of_timesteps": 505455, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12643, "number_of_timesteps": 510455, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12653, "number_of_timesteps": 515455, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12663, "number_of_timesteps": 520419, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12673, "number_of_timesteps": 525419, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12683, "number_of_timesteps": 530350, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12693, "number_of_timesteps": 535350, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12704, "number_of_timesteps": 540850, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12714, "number_of_timesteps": 545850, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12724, "number_of_timesteps": 550677, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12734, "number_of_timesteps": 555332, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 12744, "number_of_timesteps": 560332, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12754, "number_of_timesteps": 565137, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12764, "number_of_timesteps": 570137, "per_episode_reward": 9.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12774, "number_of_timesteps": 575120, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12784, "number_of_timesteps": 580120, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12794, "number_of_timesteps": 585120, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12804, "number_of_timesteps": 590120, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},

{"total_number_of_episodes": 12814, "number_of_timesteps": 595120, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12824, "number_of_timesteps": 600097, "per_episode_reward": 9.93, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},

{"total_number_of_episodes": 12834, "number_of_timesteps": 605097, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12844, "number_of_timesteps": 609823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12854, "number_of_timesteps": 614823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12864, "number_of_timesteps": 619823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12874, "number_of_timesteps": 624823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12884, "number_of_timesteps": 629823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12894, "number_of_timesteps": 634823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12904, "number_of_timesteps": 639823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12914, "number_of_timesteps": 644823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12924, "number_of_timesteps": 649823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12934, "number_of_timesteps": 654823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12944, "number_of_timesteps": 659823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12954, "number_of_timesteps": 664823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12964, "number_of_timesteps": 669823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12974, "number_of_timesteps": 674823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12984, "number_of_timesteps": 679605, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12994, "number_of_timesteps": 684605, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13004, "number_of_timesteps": 689605, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13014, "number_of_timesteps": 694605, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13024, "number_of_timesteps": 699605, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13034, "number_of_timesteps": 704605, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13044, "number_of_timesteps": 709566, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13054, "number_of_timesteps": 714367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13064, "number_of_timesteps": 719367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13074, "number_of_timesteps": 724367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13084, "number_of_timesteps": 729367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13094, "number_of_timesteps": 734367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13104, "number_of_timesteps": 739367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13114, "number_of_timesteps": 744367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13124, "number_of_timesteps": 749367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13134, "number_of_timesteps": 754367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13144, "number_of_timesteps": 759367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13154, "number_of_timesteps": 764367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13164, "number_of_timesteps": 769367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13174, "number_of_timesteps": 774367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13184, "number_of_timesteps": 779367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13194, "number_of_timesteps": 784367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13204, "number_of_timesteps": 789367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13214, "number_of_timesteps": 794367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13224, "number_of_timesteps": 799367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13234, "number_of_timesteps": 804367, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13244, "number_of_timesteps": 809367, "per_episode_reward": 10.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13254, "number_of_timesteps": 814367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13264, "number_of_timesteps": 819367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13274, "number_of_timesteps": 824367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13284, "number_of_timesteps": 829367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13294, "number_of_timesteps": 834367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13304, "number_of_timesteps": 839367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13314, "number_of_timesteps": 844367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13324, "number_of_timesteps": 849367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13334, "number_of_timesteps": 854367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 13344, "number_of_timesteps": 859367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13354, "number_of_timesteps": 864367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13364, "number_of_timesteps": 869367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13374, "number_of_timesteps": 874367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13384, "number_of_timesteps": 879367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13394, "number_of_timesteps": 884367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13404, "number_of_timesteps": 889367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13414, "number_of_timesteps": 894367, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13424, "number_of_timesteps": 899036, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13434, "number_of_timesteps": 904036, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13444, "number_of_timesteps": 909036, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13454, "number_of_timesteps": 914036, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13464, "number_of_timesteps": 919036, "per_episode_reward": 10.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13474, "number_of_timesteps": 924036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13484, "number_of_timesteps": 929036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13494, "number_of_timesteps": 934036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13504, "number_of_timesteps": 939036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13514, "number_of_timesteps": 944036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13524, "number_of_timesteps": 949036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13534, "number_of_timesteps": 954036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13544, "number_of_timesteps": 959036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13554, "number_of_timesteps": 964036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13564, "number_of_timesteps": 969036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13574, "number_of_timesteps": 974036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13584, "number_of_timesteps": 979036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13594, "number_of_timesteps": 984036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13604, "number_of_timesteps": 989036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13614, "number_of_timesteps": 994036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13624, "number_of_timesteps": 999036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13634, "number_of_timesteps": 1004036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13644, "number_of_timesteps": 1009036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13654, "number_of_timesteps": 1014036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13664, "number_of_timesteps": 1019036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13674, "number_of_timesteps": 1024036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13684, "number_of_timesteps": 1029036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13694, "number_of_timesteps": 1034036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13704, "number_of_timesteps": 1039036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13714, "number_of_timesteps": 1044036, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13724, "number_of_timesteps": 1049036, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 13734, "number_of_timesteps": 1054036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13744, "number_of_timesteps": 1059036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13754, "number_of_timesteps": 1064036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13764, "number_of_timesteps": 1069036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13774, "number_of_timesteps": 1074036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13784, "number_of_timesteps": 1079036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13794, "number_of_timesteps": 1084036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13804, "number_of_timesteps": 1089036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13814, "number_of_timesteps": 1094036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 13824, "number_of_timesteps": 1099036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13834, "number_of_timesteps": 1104036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13844, "number_of_timesteps": 1109036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13854, "number_of_timesteps": 1114036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13864, "number_of_timesteps": 1119036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13874, "number_of_timesteps": 1124036, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13884, "number_of_timesteps": 1129036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13894, "number_of_timesteps": 1134036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13904, "number_of_timesteps": 1139036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13914, "number_of_timesteps": 1144036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13924, "number_of_timesteps": 1149036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13934, "number_of_timesteps": 1154036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13944, "number_of_timesteps": 1159036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13954, "number_of_timesteps": 1164036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13964, "number_of_timesteps": 1169036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 13974, "number_of_timesteps": 1174036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13984, "number_of_timesteps": 1179036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13994, "number_of_timesteps": 1184036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14004, "number_of_timesteps": 1189036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14014, "number_of_timesteps": 1194036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14024, "number_of_timesteps": 1199036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14034, "number_of_timesteps": 1204036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14044, "number_of_timesteps": 1209036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14054, "number_of_timesteps": 1214036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14064, "number_of_timesteps": 1219036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14074, "number_of_timesteps": 1224036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14084, "number_of_timesteps": 1229036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14094, "number_of_timesteps": 1234036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14104, "number_of_timesteps": 1239036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14114, "number_of_timesteps": 1244036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14124, "number_of_timesteps": 1249036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14134, "number_of_timesteps": 1254036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 14144, "number_of_timesteps": 1259036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14154, "number_of_timesteps": 1264036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14164, "number_of_timesteps": 1269036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14174, "number_of_timesteps": 1274036, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14184, "number_of_timesteps": 1278999, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14194, "number_of_timesteps": 1283999, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14204, "number_of_timesteps": 1288999, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14214, "number_of_timesteps": 1293999, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14224, "number_of_timesteps": 1298999, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14234, "number_of_timesteps": 1303999, "per_episode_reward": 10.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14244, "number_of_timesteps": 1308999, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14254, "number_of_timesteps": 1313999, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14264, "number_of_timesteps": 1318999, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14274, "number_of_timesteps": 1323999, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14284, "number_of_timesteps": 1328999, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14294, "number_of_timesteps": 1333999, "per_episode_reward": 10.93, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14304, "number_of_timesteps": 1338999, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14314, "number_of_timesteps": 1343999, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14324, "number_of_timesteps": 1348999, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14334, "number_of_timesteps": 1353999, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14344, "number_of_timesteps": 1358999, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14354, "number_of_timesteps": 1363999, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14364, "number_of_timesteps": 1368999, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14374, "number_of_timesteps": 1373999, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14384, "number_of_timesteps": 1378683, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14394, "number_of_timesteps": 1383683, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14404, "number_of_timesteps": 1388683, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14414, "number_of_timesteps": 1393683, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14424, "number_of_timesteps": 1398683, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14434, "number_of_timesteps": 1403683, "per_episode_reward": 11.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 14444, "number_of_timesteps": 1408683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14454, "number_of_timesteps": 1413683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14464, "number_of_timesteps": 1418683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14474, "number_of_timesteps": 1423683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14484, "number_of_timesteps": 1428683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14494, "number_of_timesteps": 1433683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14504, "number_of_timesteps": 1438683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14514, "number_of_timesteps": 1443683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14524, "number_of_timesteps": 1448683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14534, "number_of_timesteps": 1453683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14544, "number_of_timesteps": 1458683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14554, "number_of_timesteps": 1463683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 14564, "number_of_timesteps": 1468683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14574, "number_of_timesteps": 1473683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14584, "number_of_timesteps": 1478683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14594, "number_of_timesteps": 1483683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 14604, "number_of_timesteps": 1488683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14614, "number_of_timesteps": 1493683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14624, "number_of_timesteps": 1498683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14634, "number_of_timesteps": 1503683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14644, "number_of_timesteps": 1508683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14654, "number_of_timesteps": 1513683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14664, "number_of_timesteps": 1518683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14674, "number_of_timesteps": 1523683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14684, "number_of_timesteps": 1528683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14694, "number_of_timesteps": 1533683, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14704, "number_of_timesteps": 1538683, "per_episode_reward": 11.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14714, "number_of_timesteps": 1543683, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14724, "number_of_timesteps": 1548683, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14734, "number_of_timesteps": 1553683, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14744, "number_of_timesteps": 1558683, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14754, "number_of_timesteps": 1563683, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14764, "number_of_timesteps": 1568683, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14774, "number_of_timesteps": 1573683, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14784, "number_of_timesteps": 1578683, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14794, "number_of_timesteps": 1583683, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14804, "number_of_timesteps": 1588683, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14814, "number_of_timesteps": 1593683, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14824, "number_of_timesteps": 1598683, "per_episode_reward": 11.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14834, "number_of_timesteps": 1603683, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14844, "number_of_timesteps": 1608683, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14854, "number_of_timesteps": 1613683, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14864, "number_of_timesteps": 1618683, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14874, "number_of_timesteps": 1623683, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14884, "number_of_timesteps": 1628683, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14894, "number_of_timesteps": 1633683, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14904, "number_of_timesteps": 1638683, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14914, "number_of_timesteps": 1643683, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14924, "number_of_timesteps": 1648683, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14934, "number_of_timesteps": 1653683, "per_episode_reward": 11.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14944, "number_of_timesteps": 1658683, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14954, "number_of_timesteps": 1663683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14964, "number_of_timesteps": 1668683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14974, "number_of_timesteps": 1673683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14984, "number_of_timesteps": 1678683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14994, "number_of_timesteps": 1683683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15004, "number_of_timesteps": 1688683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15014, "number_of_timesteps": 1693683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15024, "number_of_timesteps": 1698683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15034, "number_of_timesteps": 1703683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15044, "number_of_timesteps": 1708683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15054, "number_of_timesteps": 1713683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15064, "number_of_timesteps": 1718683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 15074, "number_of_timesteps": 1723683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15084, "number_of_timesteps": 1728683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15094, "number_of_timesteps": 1733683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15104, "number_of_timesteps": 1738683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15114, "number_of_timesteps": 1743683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15124, "number_of_timesteps": 1748683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15134, "number_of_timesteps": 1753683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15144, "number_of_timesteps": 1758683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15154, "number_of_timesteps": 1763683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15164, "number_of_timesteps": 1768683, "per_episode_reward": 11.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15174, "number_of_timesteps": 1773683, "per_episode_reward": 11.64, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15184, "number_of_timesteps": 1778683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15194, "number_of_timesteps": 1783683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 15204, "number_of_timesteps": 1788683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15214, "number_of_timesteps": 1793683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15224, "number_of_timesteps": 1798683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15234, "number_of_timesteps": 1803683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15244, "number_of_timesteps": 1808683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15254, "number_of_timesteps": 1813683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 15264, "number_of_timesteps": 1818683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15274, "number_of_timesteps": 1823683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15284, "number_of_timesteps": 1828683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15294, "number_of_timesteps": 1833683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15304, "number_of_timesteps": 1838683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15314, "number_of_timesteps": 1843683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15324, "number_of_timesteps": 1848683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15334, "number_of_timesteps": 1853683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15344, "number_of_timesteps": 1858683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15354, "number_of_timesteps": 1863683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 15364, "number_of_timesteps": 1868683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15374, "number_of_timesteps": 1873683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15384, "number_of_timesteps": 1878683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15394, "number_of_timesteps": 1883683, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15404, "number_of_timesteps": 1888683, "per_episode_reward": 11.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15414, "number_of_timesteps": 1893683, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15424, "number_of_timesteps": 1898683, "per_episode_reward": 11.93, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15434, "number_of_timesteps": 1903683, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15444, "number_of_timesteps": 1908683, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15454, "number_of_timesteps": 1913683, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15464, "number_of_timesteps": 1918683, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15474, "number_of_timesteps": 1923683, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15484, "number_of_timesteps": 1928683, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15494, "number_of_timesteps": 1933683, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15504, "number_of_timesteps": 1938683, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15514, "number_of_timesteps": 1943683, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15524, "number_of_timesteps": 1948683, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15534, "number_of_timesteps": 1953683, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15544, "number_of_timesteps": 1958683, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15554, "number_of_timesteps": 1963683, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15564, "number_of_timesteps": 1968683, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15574, "number_of_timesteps": 1973683, "per_episode_reward": 12.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15584, "number_of_timesteps": 1978236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15594, "number_of_timesteps": 1983236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15604, "number_of_timesteps": 1988236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15614, "number_of_timesteps": 1993236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15624, "number_of_timesteps": 1998236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 15634, "number_of_timesteps": 2003236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15644, "number_of_timesteps": 2008236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15654, "number_of_timesteps": 2013236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 15664, "number_of_timesteps": 2018236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15674, "number_of_timesteps": 2023236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15684, "number_of_timesteps": 2028236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15694, "number_of_timesteps": 2033236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15704, "number_of_timesteps": 2038236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15714, "number_of_timesteps": 2043236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15724, "number_of_timesteps": 2048236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15734, "number_of_timesteps": 2053236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15744, "number_of_timesteps": 2058236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15754, "number_of_timesteps": 2063236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15764, "number_of_timesteps": 2068236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15774, "number_of_timesteps": 2073236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15784, "number_of_timesteps": 2078236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15794, "number_of_timesteps": 2083236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15804, "number_of_timesteps": 2088236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15814, "number_of_timesteps": 2093236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 15824, "number_of_timesteps": 2098236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15834, "number_of_timesteps": 2103236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15844, "number_of_timesteps": 2108236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15854, "number_of_timesteps": 2113236, "per_episode_reward": 12.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15864, "number_of_timesteps": 2118236, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 15874, "number_of_timesteps": 2123236, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 15884, "number_of_timesteps": 2128236, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 15894, "number_of_timesteps": 2133236, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 15904, "number_of_timesteps": 2138236, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},

{"total_number_of_episodes": 15914, "number_of_timesteps": 2143236, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 15924, "number_of_timesteps": 2148236, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 15934, "number_of_timesteps": 2153236, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 15944, "number_of_timesteps": 2158236, "per_episode_reward": 12.36, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 15954, "number_of_timesteps": 2163236, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15964, "number_of_timesteps": 2168236, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15974, "number_of_timesteps": 2173236, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15984, "number_of_timesteps": 2178236, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 15994, "number_of_timesteps": 2183236, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16004, "number_of_timesteps": 2188236, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16014, "number_of_timesteps": 2193236, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16024, "number_of_timesteps": 2198236, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16034, "number_of_timesteps": 2203236, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},

{"total_number_of_episodes": 16044, "number_of_timesteps": 2208236, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16054, "number_of_timesteps": 2213236, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16064, "number_of_timesteps": 2218236, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16074, "number_of_timesteps": 2223236, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16084, "number_of_timesteps": 2228236, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16094, "number_of_timesteps": 2233236, "per_episode_reward": 12.64, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16104, "number_of_timesteps": 2238236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16114, "number_of_timesteps": 2243236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16124, "number_of_timesteps": 2248236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16134, "number_of_timesteps": 2253236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16144, "number_of_timesteps": 2258236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16154, "number_of_timesteps": 2263236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16164, "number_of_timesteps": 2268236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16174, "number_of_timesteps": 2273236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16184, "number_of_timesteps": 2278236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16194, "number_of_timesteps": 2283236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16204, "number_of_timesteps": 2288236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16214, "number_of_timesteps": 2293236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16224, "number_of_timesteps": 2298236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16234, "number_of_timesteps": 2303236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16244, "number_of_timesteps": 2308236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16254, "number_of_timesteps": 2313236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},

{"total_number_of_episodes": 16264, "number_of_timesteps": 2318236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16274, "number_of_timesteps": 2323236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16284, "number_of_timesteps": 2328236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16294, "number_of_timesteps": 2333236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16304, "number_of_timesteps": 2338236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16314, "number_of_timesteps": 2343236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16324, "number_of_timesteps": 2348236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16334, "number_of_timesteps": 2353236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16344, "number_of_timesteps": 2358236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16354, "number_of_timesteps": 2363236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16364, "number_of_timesteps": 2368236, "per_episode_reward": 12.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16374, "number_of_timesteps": 2373236, "per_episode_reward": 12.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 16384, "number_of_timesteps": 2378236, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 16394, "number_of_timesteps": 2383236, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},

{"total_number_of_episodes": 16404, "number_of_timesteps": 2388236, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 16414, "number_of_timesteps": 2393236, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 16424, "number_of_timesteps": 2398236, "per_episode_reward": 12.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 16434, "number_of_timesteps": 2403236, "per_episode_reward": 12.93, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 16444, "number_of_timesteps": 2408236, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16454, "number_of_timesteps": 2413236, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.004761904761904764, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16464, "number_of_timesteps": 2418236, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.003968253968253954, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16474, "number_of_timesteps": 2423236, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16484, "number_of_timesteps": 2428236, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16494, "number_of_timesteps": 2433236, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16504, "number_of_timesteps": 2438236, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16514, "number_of_timesteps": 2443236, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16524, "number_of_timesteps": 2448236, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16534, "number_of_timesteps": 2453236, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16544, "number_of_timesteps": 2458236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 16554, "number_of_timesteps": 2463236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 16564, "number_of_timesteps": 2468236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 16574, "number_of_timesteps": 2473236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 16584, "number_of_timesteps": 2478236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 16594, "number_of_timesteps": 2483236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 16604, "number_of_timesteps": 2488236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 16614, "number_of_timesteps": 2493236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 16624, "number_of_timesteps": 2498236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 16634, "number_of_timesteps": 2503236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16644, "number_of_timesteps": 2508236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16654, "number_of_timesteps": 2513236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16664, "number_of_timesteps": 2518236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16674, "number_of_timesteps": 2523236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16684, "number_of_timesteps": 2528236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16694, "number_of_timesteps": 2533236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16704, "number_of_timesteps": 2538236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16714, "number_of_timesteps": 2543236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16724, "number_of_timesteps": 2548236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16734, "number_of_timesteps": 2553236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16744, "number_of_timesteps": 2558236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16754, "number_of_timesteps": 2563236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16764, "number_of_timesteps": 2568236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16774, "number_of_timesteps": 2573236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16784, "number_of_timesteps": 2578236, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16794, "number_of_timesteps": 2583236, "per_episode_reward": 13.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16804, "number_of_timesteps": 2588236, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16814, "number_of_timesteps": 2593236, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16824, "number_of_timesteps": 2598236, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16834, "number_of_timesteps": 2603236, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16844, "number_of_timesteps": 2608236, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16854, "number_of_timesteps": 2613236, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16864, "number_of_timesteps": 2618236, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16874, "number_of_timesteps": 2623236, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16884, "number_of_timesteps": 2628236, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16894, "number_of_timesteps": 2633236, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 16904, "number_of_timesteps": 2638236, "per_episode_reward": 13.64, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},

{"total_number_of_episodes": 16914, "number_of_timesteps": 2643236, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16924, "number_of_timesteps": 2648236, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16934, "number_of_timesteps": 2653236, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16944, "number_of_timesteps": 2658236, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16954, "number_of_timesteps": 2663236, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16964, "number_of_timesteps": 2668236, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16974, "number_of_timesteps": 2673236, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16984, "number_of_timesteps": 2678236, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16994, "number_of_timesteps": 2683236, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17004, "number_of_timesteps": 2688236, "per_episode_reward": 13.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17014, "number_of_timesteps": 2693236, "per_episode_reward": 13.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},

{"total_number_of_episodes": 17024, "number_of_timesteps": 2698236, "per_episode_reward": 13.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17034, "number_of_timesteps": 2703236, "per_episode_reward": 13.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},

{"total_number_of_episodes": 17044, "number_of_timesteps": 2708236, "per_episode_reward": 13.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17054, "number_of_timesteps": 2713236, "per_episode_reward": 13.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17064, "number_of_timesteps": 2718236, "per_episode_reward": 13.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17074, "number_of_timesteps": 2723236, "per_episode_reward": 13.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17084, "number_of_timesteps": 2728236, "per_episode_reward": 13.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17094, "number_of_timesteps": 2733236, "per_episode_reward": 13.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17104, "number_of_timesteps": 2738236, "per_episode_reward": 13.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17114, "number_of_timesteps": 2743236, "per_episode_reward": 13.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17124, "number_of_timesteps": 2748236, "per_episode_reward": 13.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17134, "number_of_timesteps": 2753236, "per_episode_reward": 13.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17144, "number_of_timesteps": 2758236, "per_episode_reward": 13.93, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17154, "number_of_timesteps": 2763236, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17164, "number_of_timesteps": 2768236, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17174, "number_of_timesteps": 2773236, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17184, "number_of_timesteps": 2778236, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17194, "number_of_timesteps": 2783236, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17204, "number_of_timesteps": 2788236, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17214, "number_of_timesteps": 2793236, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17224, "number_of_timesteps": 2798236, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17234, "number_of_timesteps": 2803236, "per_episode_reward": 14.07, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17244, "number_of_timesteps": 2808236, "per_episode_reward": 14.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17254, "number_of_timesteps": 2813236, "per_episode_reward": 14.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17264, "number_of_timesteps": 2818236, "per_episode_reward": 14.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17274, "number_of_timesteps": 2823236, "per_episode_reward": 14.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17284, "number_of_timesteps": 2828236, "per_episode_reward": 14.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 17294, "number_of_timesteps": 2833236, "per_episode_reward": 14.21, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17304, "number_of_timesteps": 2838236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17314, "number_of_timesteps": 2843236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17324, "number_of_timesteps": 2848236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17334, "number_of_timesteps": 2853236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17344, "number_of_timesteps": 2858236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17354, "number_of_timesteps": 2863236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17364, "number_of_timesteps": 2868236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17374, "number_of_timesteps": 2873236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17384, "number_of_timesteps": 2878236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17394, "number_of_timesteps": 2883236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17404, "number_of_timesteps": 2888236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17414, "number_of_timesteps": 2893236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17424, "number_of_timesteps": 2898236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17434, "number_of_timesteps": 2903236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17444, "number_of_timesteps": 2908236, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17454, "number_of_timesteps": 2913236, "per_episode_reward": 14.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},

{"total_number_of_episodes": 17464, "number_of_timesteps": 2918236, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 17474, "number_of_timesteps": 2923236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 17484, "number_of_timesteps": 2928236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 17494, "number_of_timesteps": 2933236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 17504, "number_of_timesteps": 2938236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 17514, "number_of_timesteps": 2943236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},

{"total_number_of_episodes": 17524, "number_of_timesteps": 2948236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 17534, "number_of_timesteps": 2953236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 17544, "number_of_timesteps": 2958236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 17554, "number_of_timesteps": 2963236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17564, "number_of_timesteps": 2968236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17574, "number_of_timesteps": 2973236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17584, "number_of_timesteps": 2978236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17594, "number_of_timesteps": 2983236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17604, "number_of_timesteps": 2988236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17614, "number_of_timesteps": 2993236, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17624, "number_of_timesteps": 2998236, "per_episode_reward": 14.64, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17634, "number_of_timesteps": 3003236, "per_episode_reward": 14.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17644, "number_of_timesteps": 3008236, "per_episode_reward": 14.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17654, "number_of_timesteps": 3013236, "per_episode_reward": 14.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17664, "number_of_timesteps": 3018236, "per_episode_reward": 14.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17674, "number_of_timesteps": 3023236, "per_episode_reward": 14.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17684, "number_of_timesteps": 3028236, "per_episode_reward": 14.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17694, "number_of_timesteps": 3033236, "per_episode_reward": 14.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17704, "number_of_timesteps": 3038236, "per_episode_reward": 14.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17714, "number_of_timesteps": 3043236, "per_episode_reward": 14.79, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17724, "number_of_timesteps": 3048236, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17734, "number_of_timesteps": 3053236, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17744, "number_of_timesteps": 3058236, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17754, "number_of_timesteps": 3063236, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17764, "number_of_timesteps": 3068236, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17774, "number_of_timesteps": 3073236, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17784, "number_of_timesteps": 3078236, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17794, "number_of_timesteps": 3083236, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17804, "number_of_timesteps": 3088236, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17814, "number_of_timesteps": 3093236, "per_episode_reward": 14.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17824, "number_of_timesteps": 3098236, "per_episode_reward": 14.93, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17834, "number_of_timesteps": 3103236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17844, "number_of_timesteps": 3108236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17854, "number_of_timesteps": 3113236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17864, "number_of_timesteps": 3118236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17874, "number_of_timesteps": 3123236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17884, "number_of_timesteps": 3128236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17894, "number_of_timesteps": 3133236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17904, "number_of_timesteps": 3138236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17914, "number_of_timesteps": 3143236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17924, "number_of_timesteps": 3148236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17934, "number_of_timesteps": 3153236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17944, "number_of_timesteps": 3158236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17954, "number_of_timesteps": 3163236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17964, "number_of_timesteps": 3168236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17974, "number_of_timesteps": 3173236, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17984, "number_of_timesteps": 3178236, "per_episode_reward": 15.07, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17994, "number_of_timesteps": 3183236, "per_episode_reward": 15.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18004, "number_of_timesteps": 3188236, "per_episode_reward": 15.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18014, "number_of_timesteps": 3193236, "per_episode_reward": 15.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18024, "number_of_timesteps": 3198236, "per_episode_reward": 15.21, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18034, "number_of_timesteps": 3203236, "per_episode_reward": 15.29, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18044, "number_of_timesteps": 3208236, "per_episode_reward": 15.29, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18054, "number_of_timesteps": 3213236, "per_episode_reward": 15.29, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18064, "number_of_timesteps": 3218236, "per_episode_reward": 15.29, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18074, "number_of_timesteps": 3223236, "per_episode_reward": 15.29, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18084, "number_of_timesteps": 3228236, "per_episode_reward": 15.36, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18094, "number_of_timesteps": 3233236, "per_episode_reward": 15.43, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18104, "number_of_timesteps": 3238236, "per_episode_reward": 15.43, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18114, "number_of_timesteps": 3243236, "per_episode_reward": 15.43, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18124, "number_of_timesteps": 3248236, "per_episode_reward": 15.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18134, "number_of_timesteps": 3253236, "per_episode_reward": 15.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18144, "number_of_timesteps": 3258236, "per_episode_reward": 15.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18154, "number_of_timesteps": 3263236, "per_episode_reward": 15.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18164, "number_of_timesteps": 3268236, "per_episode_reward": 15.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18174, "number_of_timesteps": 3273236, "per_episode_reward": 15.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18184, "number_of_timesteps": 3278236, "per_episode_reward": 15.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18194, "number_of_timesteps": 3283236, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18204, "number_of_timesteps": 3288236, "per_episode_reward": 15.64, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18214, "number_of_timesteps": 3293236, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18224, "number_of_timesteps": 3298236, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18234, "number_of_timesteps": 3303236, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18244, "number_of_timesteps": 3308236, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18254, "number_of_timesteps": 3313236, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18264, "number_of_timesteps": 3318236, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18274, "number_of_timesteps": 3323236, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18284, "number_of_timesteps": 3328236, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18294, "number_of_timesteps": 3333236, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18304, "number_of_timesteps": 3338236, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18314, "number_of_timesteps": 3343236, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18324, "number_of_timesteps": 3348236, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18334, "number_of_timesteps": 3353236, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18344, "number_of_timesteps": 3358236, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18354, "number_of_timesteps": 3363236, "per_episode_reward": 15.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18364, "number_of_timesteps": 3368236, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18374, "number_of_timesteps": 3373236, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18384, "number_of_timesteps": 3378236, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18394, "number_of_timesteps": 3383236, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18404, "number_of_timesteps": 3388236, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18414, "number_of_timesteps": 3393236, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18424, "number_of_timesteps": 3398236, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18434, "number_of_timesteps": 3403236, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18444, "number_of_timesteps": 3408236, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18454, "number_of_timesteps": 3413236, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18464, "number_of_timesteps": 3418236, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18474, "number_of_timesteps": 3423236, "per_episode_reward": 15.93, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18484, "number_of_timesteps": 3428236, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18494, "number_of_timesteps": 3433236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18504, "number_of_timesteps": 3438236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18514, "number_of_timesteps": 3443236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18524, "number_of_timesteps": 3448236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18534, "number_of_timesteps": 3453236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18544, "number_of_timesteps": 3458236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18554, "number_of_timesteps": 3463236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18564, "number_of_timesteps": 3468236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18574, "number_of_timesteps": 3473236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18584, "number_of_timesteps": 3478236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18594, "number_of_timesteps": 3483236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18604, "number_of_timesteps": 3488236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18614, "number_of_timesteps": 3493236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18624, "number_of_timesteps": 3498236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18634, "number_of_timesteps": 3503236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18644, "number_of_timesteps": 3508236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18654, "number_of_timesteps": 3513236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18664, "number_of_timesteps": 3518236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18674, "number_of_timesteps": 3523236, "per_episode_reward": 16.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18684, "number_of_timesteps": 3528236, "per_episode_reward": 16.21, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18694, "number_of_timesteps": 3533236, "per_episode_reward": 16.36, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18704, "number_of_timesteps": 3538236, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18714, "number_of_timesteps": 3543236, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18724, "number_of_timesteps": 3548236, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18734, "number_of_timesteps": 3553236, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18744, "number_of_timesteps": 3558236, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 18754, "number_of_timesteps": 3563236, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 18764, "number_of_timesteps": 3568236, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 18774, "number_of_timesteps": 3573236, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.1428571428571459},

{"total_number_of_episodes": 18784, "number_of_timesteps": 3578236, "per_episode_reward": 16.64, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 18794, "number_of_timesteps": 3583236, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 18804, "number_of_timesteps": 3588236, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 18814, "number_of_timesteps": 3593236, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 18824, "number_of_timesteps": 3598236, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 18834, "number_of_timesteps": 3603236, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18844, "number_of_timesteps": 3608236, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},

{"total_number_of_episodes": 18854, "number_of_timesteps": 3613236, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18864, "number_of_timesteps": 3618236, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18874, "number_of_timesteps": 3623236, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18884, "number_of_timesteps": 3628236, "per_episode_reward": 16.79, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.0714285714285694},
{"total_number_of_episodes": 18894, "number_of_timesteps": 3633236, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18904, "number_of_timesteps": 3638236, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18914, "number_of_timesteps": 3643236, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18924, "number_of_timesteps": 3648236, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18934, "number_of_timesteps": 3653236, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18944, "number_of_timesteps": 3658236, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18954, "number_of_timesteps": 3663236, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18964, "number_of_timesteps": 3668236, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},

{"total_number_of_episodes": 18974, "number_of_timesteps": 3673236, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 18984, "number_of_timesteps": 3678236, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18994, "number_of_timesteps": 3683236, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19004, "number_of_timesteps": 3688236, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19014, "number_of_timesteps": 3693236, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19024, "number_of_timesteps": 3698236, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19034, "number_of_timesteps": 3703236, "per_episode_reward": 17.07, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19044, "number_of_timesteps": 3708236, "per_episode_reward": 17.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},

{"total_number_of_episodes": 19054, "number_of_timesteps": 3713236, "per_episode_reward": 17.29, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},

{"total_number_of_episodes": 19064, "number_of_timesteps": 3718236, "per_episode_reward": 17.36, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19074, "number_of_timesteps": 3723236, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19084, "number_of_timesteps": 3728236, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19094, "number_of_timesteps": 3733236, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19104, "number_of_timesteps": 3738236, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19114, "number_of_timesteps": 3743236, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19124, "number_of_timesteps": 3748236, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.003968253968253935, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19134, "number_of_timesteps": 3753236, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19144, "number_of_timesteps": 3758236, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19154, "number_of_timesteps": 3763236, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.0714285714285694},
{"total_number_of_episodes": 19164, "number_of_timesteps": 3768236, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19174, "number_of_timesteps": 3773236, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19184, "number_of_timesteps": 3778236, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19194, "number_of_timesteps": 3783236, "per_episode_reward": 17.57, "episode_reward_trend_value": 0.0015873015873016211, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19204, "number_of_timesteps": 3788236, "per_episode_reward": 17.57, "episode_reward_trend_value": 0.0015873015873016211, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19214, "number_of_timesteps": 3793236, "per_episode_reward": 17.57, "episode_reward_trend_value": 0.0015873015873016211, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19224, "number_of_timesteps": 3798236, "per_episode_reward": 17.57, "episode_reward_trend_value": 0.0015873015873016211, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19234, "number_of_timesteps": 3803236, "per_episode_reward": 17.64, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19244, "number_of_timesteps": 3808236, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19254, "number_of_timesteps": 3813236, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19264, "number_of_timesteps": 3818236, "per_episode_reward": 17.79, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19274, "number_of_timesteps": 3823236, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19284, "number_of_timesteps": 3828236, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19294, "number_of_timesteps": 3833236, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19304, "number_of_timesteps": 3838236, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19314, "number_of_timesteps": 3843236, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19324, "number_of_timesteps": 3848236, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19334, "number_of_timesteps": 3853236, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19344, "number_of_timesteps": 3858236, "per_episode_reward": 18.07, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19354, "number_of_timesteps": 3863236, "per_episode_reward": 18.14, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19364, "number_of_timesteps": 3868236, "per_episode_reward": 18.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19374, "number_of_timesteps": 3873236, "per_episode_reward": 18.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19384, "number_of_timesteps": 3878236, "per_episode_reward": 18.36, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19394, "number_of_timesteps": 3883236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19404, "number_of_timesteps": 3888236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19414, "number_of_timesteps": 3893236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19424, "number_of_timesteps": 3898236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19434, "number_of_timesteps": 3903236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.003968253968253935, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19444, "number_of_timesteps": 3908236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19454, "number_of_timesteps": 3913236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19464, "number_of_timesteps": 3918236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 19474, "number_of_timesteps": 3923236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.0714285714285694},
{"total_number_of_episodes": 19484, "number_of_timesteps": 3928236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19494, "number_of_timesteps": 3933236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19504, "number_of_timesteps": 3938236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19514, "number_of_timesteps": 3943236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19524, "number_of_timesteps": 3948236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19534, "number_of_timesteps": 3953236, "per_episode_reward": 18.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19544, "number_of_timesteps": 3958236, "per_episode_reward": 18.57, "episode_reward_trend_value": 0.0015873015873016211, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 19554, "number_of_timesteps": 3963236, "per_episode_reward": 18.64, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 19564, "number_of_timesteps": 3968236, "per_episode_reward": 18.79, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 19574, "number_of_timesteps": 3973236, "per_episode_reward": 18.86, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 19584, "number_of_timesteps": 3978236, "per_episode_reward": 18.86, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 19594, "number_of_timesteps": 3983236, "per_episode_reward": 18.86, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 19604, "number_of_timesteps": 3988236, "per_episode_reward": 18.86, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 19614, "number_of_timesteps": 3993236, "per_episode_reward": 18.86, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 19624, "number_of_timesteps": 3998236, "per_episode_reward": 18.86, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 19634, "number_of_timesteps": 4003236, "per_episode_reward": 18.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19644, "number_of_timesteps": 4008236, "per_episode_reward": 18.93, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19654, "number_of_timesteps": 4013236, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19664, "number_of_timesteps": 4018236, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19674, "number_of_timesteps": 4023236, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19684, "number_of_timesteps": 4028236, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19694, "number_of_timesteps": 4033236, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19704, "number_of_timesteps": 4038236, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19714, "number_of_timesteps": 4043236, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19724, "number_of_timesteps": 4048236, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19734, "number_of_timesteps": 4053236, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19744, "number_of_timesteps": 4058236, "per_episode_reward": 19.07, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19754, "number_of_timesteps": 4063236, "per_episode_reward": 19.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19764, "number_of_timesteps": 4068236, "per_episode_reward": 19.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19774, "number_of_timesteps": 4073236, "per_episode_reward": 19.29, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19784, "number_of_timesteps": 4078236, "per_episode_reward": 19.29, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19794, "number_of_timesteps": 4083236, "per_episode_reward": 19.36, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19804, "number_of_timesteps": 4088236, "per_episode_reward": 19.43, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19814, "number_of_timesteps": 4093236, "per_episode_reward": 19.43, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19824, "number_of_timesteps": 4098236, "per_episode_reward": 19.43, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19834, "number_of_timesteps": 4103236, "per_episode_reward": 19.43, "episode_reward_trend_value": 0.003968253968253935, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19844, "number_of_timesteps": 4108236, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19854, "number_of_timesteps": 4113236, "per_episode_reward": 19.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19864, "number_of_timesteps": 4118236, "per_episode_reward": 19.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19874, "number_of_timesteps": 4123236, "per_episode_reward": 19.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19884, "number_of_timesteps": 4128236, "per_episode_reward": 19.57, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19894, "number_of_timesteps": 4133236, "per_episode_reward": 19.57, "episode_reward_trend_value": 0.0015873015873016211, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19904, "number_of_timesteps": 4138236, "per_episode_reward": 19.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19914, "number_of_timesteps": 4143236, "per_episode_reward": 19.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19924, "number_of_timesteps": 4148236, "per_episode_reward": 19.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19934, "number_of_timesteps": 4153236, "per_episode_reward": 19.79, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19944, "number_of_timesteps": 4158236, "per_episode_reward": 19.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19954, "number_of_timesteps": 4163236, "per_episode_reward": 19.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19964, "number_of_timesteps": 4168236, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19974, "number_of_timesteps": 4173236, "per_episode_reward": 20.14, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19984, "number_of_timesteps": 4178236, "per_episode_reward": 20.14, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 19994, "number_of_timesteps": 4183236, "per_episode_reward": 20.14, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20004, "number_of_timesteps": 4188236, "per_episode_reward": 20.14, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20014, "number_of_timesteps": 4193236, "per_episode_reward": 20.21, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20024, "number_of_timesteps": 4198236, "per_episode_reward": 20.29, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20034, "number_of_timesteps": 4203236, "per_episode_reward": 20.29, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20044, "number_of_timesteps": 4208236, "per_episode_reward": 20.29, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20054, "number_of_timesteps": 4213236, "per_episode_reward": 20.29, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20064, "number_of_timesteps": 4218236, "per_episode_reward": 20.29, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20074, "number_of_timesteps": 4223236, "per_episode_reward": 20.29, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20084, "number_of_timesteps": 4228236, "per_episode_reward": 20.29, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20094, "number_of_timesteps": 4233236, "per_episode_reward": 20.29, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20104, "number_of_timesteps": 4238236, "per_episode_reward": 20.43, "episode_reward_trend_value": 0.0023809523809523525, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20114, "number_of_timesteps": 4243236, "per_episode_reward": 20.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20124, "number_of_timesteps": 4248236, "per_episode_reward": 20.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20134, "number_of_timesteps": 4253236, "per_episode_reward": 20.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20144, "number_of_timesteps": 4258236, "per_episode_reward": 20.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20154, "number_of_timesteps": 4263236, "per_episode_reward": 20.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20164, "number_of_timesteps": 4268236, "per_episode_reward": 20.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20174, "number_of_timesteps": 4273236, "per_episode_reward": 20.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20184, "number_of_timesteps": 4278236, "per_episode_reward": 20.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20194, "number_of_timesteps": 4283236, "per_episode_reward": 20.64, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20204, "number_of_timesteps": 4288236, "per_episode_reward": 20.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20214, "number_of_timesteps": 4293236, "per_episode_reward": 20.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20224, "number_of_timesteps": 4298236, "per_episode_reward": 20.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20234, "number_of_timesteps": 4303236, "per_episode_reward": 20.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20244, "number_of_timesteps": 4308236, "per_episode_reward": 20.93, "episode_reward_trend_value": 0.003968253968253935, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20254, "number_of_timesteps": 4313236, "per_episode_reward": 21.0, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20264, "number_of_timesteps": 4318236, "per_episode_reward": 21.0, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20274, "number_of_timesteps": 4323236, "per_episode_reward": 21.0, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20284, "number_of_timesteps": 4328236, "per_episode_reward": 21.14, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20294, "number_of_timesteps": 4333236, "per_episode_reward": 21.29, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20304, "number_of_timesteps": 4338236, "per_episode_reward": 21.29, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20314, "number_of_timesteps": 4343236, "per_episode_reward": 21.29, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20324, "number_of_timesteps": 4348236, "per_episode_reward": 21.29, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20334, "number_of_timesteps": 4353236, "per_episode_reward": 21.29, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20344, "number_of_timesteps": 4358236, "per_episode_reward": 21.29, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20354, "number_of_timesteps": 4363236, "per_episode_reward": 21.29, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20364, "number_of_timesteps": 4368236, "per_episode_reward": 21.36, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20374, "number_of_timesteps": 4373236, "per_episode_reward": 21.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20384, "number_of_timesteps": 4378236, "per_episode_reward": 21.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20394, "number_of_timesteps": 4383236, "per_episode_reward": 21.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20404, "number_of_timesteps": 4388236, "per_episode_reward": 21.64, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.1428571428571459},

{"total_number_of_episodes": 20414, "number_of_timesteps": 4393236, "per_episode_reward": 21.71, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20424, "number_of_timesteps": 4398236, "per_episode_reward": 21.79, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20434, "number_of_timesteps": 4403236, "per_episode_reward": 21.86, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20444, "number_of_timesteps": 4408236, "per_episode_reward": 21.86, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20454, "number_of_timesteps": 4413236, "per_episode_reward": 21.86, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20464, "number_of_timesteps": 4418236, "per_episode_reward": 21.86, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20474, "number_of_timesteps": 4423236, "per_episode_reward": 21.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20484, "number_of_timesteps": 4428236, "per_episode_reward": 21.86, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20494, "number_of_timesteps": 4433236, "per_episode_reward": 21.86, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20504, "number_of_timesteps": 4438236, "per_episode_reward": 21.86, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20514, "number_of_timesteps": 4443236, "per_episode_reward": 21.86, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},

{"total_number_of_episodes": 20524, "number_of_timesteps": 4448236, "per_episode_reward": 21.93, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.0714285714285694},

{"total_number_of_episodes": 20534, "number_of_timesteps": 4453236, "per_episode_reward": 22.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},

{"total_number_of_episodes": 20544, "number_of_timesteps": 4458236, "per_episode_reward": 22.07, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20554, "number_of_timesteps": 4463236, "per_episode_reward": 22.29, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20564, "number_of_timesteps": 4468236, "per_episode_reward": 22.29, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20574, "number_of_timesteps": 4473236, "per_episode_reward": 22.36, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20584, "number_of_timesteps": 4478236, "per_episode_reward": 22.43, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20594, "number_of_timesteps": 4483236, "per_episode_reward": 22.43, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20604, "number_of_timesteps": 4488236, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.0071428571428571366, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20614, "number_of_timesteps": 4493236, "per_episode_reward": 22.57, "episode_reward_trend_value": 0.007142857142857177, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20624, "number_of_timesteps": 4498236, "per_episode_reward": 22.57, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20634, "number_of_timesteps": 4503236, "per_episode_reward": 22.57, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20644, "number_of_timesteps": 4508236, "per_episode_reward": 22.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20654, "number_of_timesteps": 4513236, "per_episode_reward": 22.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20664, "number_of_timesteps": 4518236, "per_episode_reward": 22.57, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20674, "number_of_timesteps": 4523236, "per_episode_reward": 22.79, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.21428571428571175},
{"total_number_of_episodes": 20684, "number_of_timesteps": 4528236, "per_episode_reward": 23.0, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 20694, "number_of_timesteps": 4533236, "per_episode_reward": 23.0, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 20704, "number_of_timesteps": 4538236, "per_episode_reward": 23.0, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 20714, "number_of_timesteps": 4543236, "per_episode_reward": 23.0, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 20724, "number_of_timesteps": 4548236, "per_episode_reward": 23.0, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 20734, "number_of_timesteps": 4553236, "per_episode_reward": 23.14, "episode_reward_trend_value": 0.006349206349206327, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 20744, "number_of_timesteps": 4558236, "per_episode_reward": 23.29, "episode_reward_trend_value": 0.007936507936507908, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 20754, "number_of_timesteps": 4563236, "per_episode_reward": 23.36, "episode_reward_trend_value": 0.008730158730158718, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 20764, "number_of_timesteps": 4568236, "per_episode_reward": 23.43, "episode_reward_trend_value": 0.0071428571428571366, "biggest_recent_change": 0.2142857142857153},
{"total_number_of_episodes": 20774, "number_of_timesteps": 4573236, "per_episode_reward": 23.43, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20784, "number_of_timesteps": 4578236, "per_episode_reward": 23.43, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20794, "number_of_timesteps": 4583236, "per_episode_reward": 23.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20804, "number_of_timesteps": 4588236, "per_episode_reward": 23.64, "episode_reward_trend_value": 0.0071428571428571366, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20814, "number_of_timesteps": 4593236, "per_episode_reward": 23.71, "episode_reward_trend_value": 0.007936507936507946, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20824, "number_of_timesteps": 4598236, "per_episode_reward": 23.79, "episode_reward_trend_value": 0.0071428571428571366, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20834, "number_of_timesteps": 4603236, "per_episode_reward": 23.86, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20844, "number_of_timesteps": 4608236, "per_episode_reward": 24.0, "episode_reward_trend_value": 0.0071428571428571366, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20854, "number_of_timesteps": 4613236, "per_episode_reward": 24.07, "episode_reward_trend_value": 0.007142857142857177, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20864, "number_of_timesteps": 4618236, "per_episode_reward": 24.14, "episode_reward_trend_value": 0.007936507936507946, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20874, "number_of_timesteps": 4623236, "per_episode_reward": 24.14, "episode_reward_trend_value": 0.007936507936507946, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20884, "number_of_timesteps": 4628236, "per_episode_reward": 24.14, "episode_reward_trend_value": 0.0071428571428571366, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20894, "number_of_timesteps": 4633236, "per_episode_reward": 24.14, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20904, "number_of_timesteps": 4638236, "per_episode_reward": 24.14, "episode_reward_trend_value": 0.004761904761904745, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20914, "number_of_timesteps": 4643236, "per_episode_reward": 24.14, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20924, "number_of_timesteps": 4648236, "per_episode_reward": 24.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20934, "number_of_timesteps": 4653236, "per_episode_reward": 24.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20944, "number_of_timesteps": 4658236, "per_episode_reward": 24.21, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20954, "number_of_timesteps": 4663236, "per_episode_reward": 24.29, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 20964, "number_of_timesteps": 4668236, "per_episode_reward": 24.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.14285714285714235},

{"total_number_of_episodes": 20974, "number_of_timesteps": 4673236, "per_episode_reward": 24.57, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.1428571428571459},
{"total_number_of_episodes": 20984, "number_of_timesteps": 4678236, "per_episode_reward": 24.71, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.1428571428571459},
exited at update_barrier.wait(): 4, error = 
None
{"total_number_of_episodes": 20994, "number_of_timesteps": 4683236, "per_episode_reward": 24.71, "episode_reward_trend_value": 0.006349206349206366, "biggest_recent_change": 0.1428571428571459},
exited at update_barrier.wait(): 1, error = 
None
exited at update_barrier.wait(): 0, error = 
None
exited at all_updated_barrier.wait(): 5, error = 
None
exited at all_updated_barrier.wait(): 3, error = 
None
exited at all_updated_barrier.wait(): 2, error = 
None
[done calling async_.run_async()]
final_eval: {'number_of_steps': 125000, 'number_of_episodes': None, 'mean': 500.0, 'median': 500.0, 'stdev': 0.0}
logs/comparisons/cartpole__atk=none__def=ucb.log fitness_value = 155.21428571428572
