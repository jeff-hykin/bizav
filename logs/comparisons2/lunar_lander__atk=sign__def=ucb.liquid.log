config = {
    "evaluation": {
        "enabled": True, 
        "number_of_episodes_before_eval": 130, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": 125000, 
            "number_of_episodes": None, 
        }, 
    }, 
    "verbose": True, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "expected_number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": {
        0: 0.1, 
        1: 0.08, 
        2: 0.063, 
        3: 0.05, 
        4: 0.04, 
        5: 0.032, 
        6: 0.025, 
        7: 0.02, 
        8: 0.016, 
        9: 0.012, 
        10: 0.01, 
        11: 0.008, 
        12: 0.0063, 
        13: 0.005, 
        14: 0.004, 
        15: 0.0032, 
        16: 0.0025, 
        17: 0.002, 
        18: 0.0016, 
        19: 0.0012, 
        20: 0.001, 
        21: 0.0008, 
        22: 0.00063, 
        23: 0.0005, 
        24: 0.0004, 
        25: 0.00032, 
        26: 0.00025, 
        27: 0.0002, 
        28: 0.00016, 
        29: 0.00012, 
        30: 1e-05, 
        31: 8e-06, 
        32: 6.3e-06, 
        33: 5e-06, 
        34: 4e-06, 
        35: 3.2e-06, 
        36: 2.5e-06, 
        37: 2e-06, 
        38: 1.6e-06, 
        39: 1.2e-06, 
    }, 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": {0: 0, }, 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0, 
        "min_number_of_episodes": 30, 
        "thresholds": {}, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": {0: 0, 1: 1, 2: 2, }, }, 
            "sequential_options": {
                "t_max": {0: 3, 1: 5, 2: 10, 3: 20, 4: 30, 5: 50, }, 
                "hidden_size": {0: 16, 1: 32, 2: 64, 3: 128, }, 
                "learning_rate": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
                "beta": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
                "beta": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 40000, }, 
    "env_config": {
        "env_name": "LunarLander-v2", 
        "learning_rate": 0.0009, 
        "beta": 2e-05, 
        "t_max": 10, 
        "activation": 1, 
        "hidden_size": 128, 
        "permaban_threshold": 1000, 
        "variance_scaling_factor": 1, 
    }, 
}
args = {
    "processes": 10, 
    "env": "LunarLander-v2", 
    "seed": 2620171648, 
    "outdir": "results", 
    "t_max": 10, 
    "beta": 2e-05, 
    "profile": False, 
    "steps": 40000, 
    "max_frames": (108000, ), 
    "lr": 0.0009, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 1000, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 128, 
    "activation": 1, 
}
[starting train_a3c()]
[starting train_agent_async()]
[about to call async_.run_async()]
[starting run_func()]
[starting train_loop()]
{ "step": 0, "visits": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 0, "q_vals": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 1, "visits": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 0, "q_vals": [-5.011, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 2, "visits": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 0, "q_vals": [-5.011, -7.901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 3, "visits": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 0, "q_vals": [-5.011, -7.901, -7.901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 4, "visits": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 0, "q_vals": [-5.011, -7.901, -7.901, -7.901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 5, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 0, "q_vals": [-5.011, -7.901, -7.901, -7.901, -6.542, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 6, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 0, "q_vals": [-5.011, -7.901, -7.901, -7.901, -6.542, -1.613, 0.0, 0.0, 0.0, 0.0] }
{ "step": 7, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0] , "episode_count": 2, "q_vals": [-5.011, -7.901, -7.901, -7.901, -6.542, -1.613, -7.901, 0.0, 0.0, 0.0] }
{ "step": 8, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0] , "episode_count": 4, "q_vals": [-5.011, -7.901, -7.901, -7.901, -6.542, -1.613, -7.901, 0.0, 0.0, 0.0] }
{ "step": 9, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0] , "episode_count": 5, "q_vals": [-5.011, -7.901, -7.901, -7.901, -6.542, -1.613, -7.901, 0.0, -7.901, 0.0] }
{ "step": 10, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 6, "q_vals": [-5.011, -7.901, -7.901, -7.901, -6.542, -1.613, -7.901, 0.0, -7.901, -7.901] }
{ "step": 11, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0] , "episode_count": 7, "q_vals": [-5.011, -7.901, -7.901, -7.901, -6.542, -1.613, -7.901, -2.042, -7.901, -7.901] }
{ "step": 12, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0] , "episode_count": 9, "q_vals": [-5.011, -7.901, -7.901, -7.901, -6.542, -3.668, -7.901, -2.042, -7.901, -7.901] }
{ "step": 13, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 10, "q_vals": [-5.011, -7.901, -7.901, -7.901, -6.542, -3.668, -7.901, -7.945, -7.901, -7.901] }
{ "step": 14, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 10, "q_vals": [-5.011, -7.901, -7.901, -7.901, -6.542, -5.079, -7.901, -7.945, -7.901, -7.901] }
{ "step": 15, "visits": [2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 10, "q_vals": [-6.456, -7.901, -7.901, -7.901, -6.542, -5.079, -7.901, -7.945, -7.901, -7.901] }
{ "step": 16, "visits": [2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 10, "q_vals": [-6.456, -7.901, -7.901, -7.901, -6.542, -6.751, -7.901, -7.945, -7.901, -7.901] }
{ "step": 17, "visits": [2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 13, "q_vals": [-6.456, -7.901, -7.901, -7.901, -7.222, -6.751, -7.901, -7.945, -7.901, -7.901] }
{ "step": 18, "visits": [3.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 15, "q_vals": [-10.888, -7.901, -7.901, -7.901, -7.222, -6.751, -7.901, -7.945, -7.901, -7.901] }
{ "step": 19, "visits": [3.0, 1.0, 1.0, 1.0, 2.0, 5.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 15, "q_vals": [-10.888, -7.901, -7.901, -7.901, -7.222, -8.679, -7.901, -7.945, -7.901, -7.901] }
{ "step": 20, "visits": [3.0, 1.0, 1.0, 1.0, 3.0, 5.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 15, "q_vals": [-10.888, -7.901, -7.901, -7.901, -7.448, -8.679, -7.901, -7.945, -7.901, -7.901] }
{ "step": 21, "visits": [3.0, 1.0, 1.0, 1.0, 3.0, 5.0, 2.0, 3.0, 1.0, 1.0] , "episode_count": 17, "q_vals": [-10.888, -7.901, -7.901, -7.901, -7.448, -8.679, -13.827, -7.945, -7.901, -7.901] }
{ "step": 22, "visits": [3.0, 2.0, 1.0, 1.0, 3.0, 5.0, 2.0, 3.0, 1.0, 1.0] , "episode_count": 17, "q_vals": [-10.888, -5.212, -7.901, -7.901, -7.448, -8.679, -13.827, -7.945, -7.901, -7.901] }
{ "step": 23, "visits": [3.0, 3.0, 1.0, 1.0, 3.0, 5.0, 2.0, 3.0, 1.0, 1.0] , "episode_count": 19, "q_vals": [-10.888, -5.583, -7.901, -7.901, -7.448, -8.679, -13.827, -7.945, -7.901, -7.901] }
{ "step": 24, "visits": [3.0, 4.0, 1.0, 1.0, 3.0, 5.0, 2.0, 3.0, 1.0, 1.0] , "episode_count": 20, "q_vals": [-10.888, -6.162, -7.901, -7.901, -7.448, -8.679, -13.827, -7.945, -7.901, -7.901] }
{ "step": 25, "visits": [3.0, 5.0, 1.0, 1.0, 3.0, 5.0, 2.0, 3.0, 1.0, 1.0] , "episode_count": 20, "q_vals": [-10.888, -6.51, -7.901, -7.901, -7.448, -8.679, -13.827, -7.945, -7.901, -7.901] }
{ "step": 26, "visits": [3.0, 6.0, 1.0, 1.0, 3.0, 5.0, 2.0, 3.0, 1.0, 1.0] , "episode_count": 21, "q_vals": [-10.888, -6.742, -7.901, -7.901, -7.448, -8.679, -13.827, -7.945, -7.901, -7.901] }
{ "step": 27, "visits": [3.0, 7.0, 1.0, 1.0, 3.0, 5.0, 2.0, 3.0, 1.0, 1.0] , "episode_count": 21, "q_vals": [-10.888, -6.908, -7.901, -7.901, -7.448, -8.679, -13.827, -7.945, -7.901, -7.901] }
{ "step": 28, "visits": [3.0, 7.0, 1.0, 2.0, 3.0, 5.0, 2.0, 3.0, 1.0, 1.0] , "episode_count": 23, "q_vals": [-10.888, -6.908, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.901] }
{ "step": 29, "visits": [3.0, 7.0, 1.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 1.0] , "episode_count": 24, "q_vals": [-10.888, -6.908, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.901] }
{ "step": 30, "visits": [3.0, 7.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 1.0] , "episode_count": 25, "q_vals": [-10.888, -6.908, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.901] }
{ "step": 31, "visits": [3.0, 7.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 2.0] , "episode_count": 27, "q_vals": [-10.888, -6.908, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -5.699] }
{ "step": 32, "visits": [3.0, 7.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 3.0] , "episode_count": 27, "q_vals": [-10.888, -6.908, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -3.8] }
{ "step": 33, "visits": [3.0, 7.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 27, "q_vals": [-10.888, -6.908, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.788] }
{ "step": 34, "visits": [3.0, 8.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 29, "q_vals": [-10.888, -6.926, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.788] }
{ "step": 35, "visits": [3.0, 9.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 29, "q_vals": [-10.888, -6.608, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.788] }
{ "step": 36, "visits": [3.0, 10.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 29, "q_vals": [-10.888, -6.737, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.788] }
{ "step": 37, "visits": [3.0, 11.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 29, "q_vals": [-10.888, -6.125, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.788] }
{"total_number_of_episodes": 33, "number_of_timesteps": 3239, "per_episode_reward": -152.41, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{ "step": 38, "visits": [3.0, 12.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 33, "q_vals": [-10.888, -6.273, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.788] }
{ "step": 39, "visits": [3.0, 13.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 34, "q_vals": [-10.888, -6.398, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.788] }
{ "step": 40, "visits": [3.0, 14.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 34, "q_vals": [-10.888, -6.505, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.788] }
{ "step": 41, "visits": [3.0, 15.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 35, "q_vals": [-10.888, -6.598, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.788] }
{ "step": 42, "visits": [3.0, 16.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 37, "q_vals": [-10.888, -6.68, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.788] }
{ "step": 43, "visits": [3.0, 17.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 37, "q_vals": [-10.888, -6.752, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.788] }
{ "step": 44, "visits": [3.0, 18.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 38, "q_vals": [-10.888, -6.816, -7.901, -13.827, -7.448, -8.679, -13.827, -7.945, -7.901, -7.788] }
{ "step": 45, "visits": [3.0, 18.0, 2.0, 2.0, 4.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 39, "q_vals": [-10.888, -6.816, -7.901, -13.827, -10.524, -8.679, -13.827, -7.945, -7.901, -7.788] }
{ "step": 46, "visits": [3.0, 19.0, 2.0, 2.0, 4.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 40, "q_vals": [-10.888, -6.689, -7.901, -13.827, -10.524, -8.679, -13.827, -7.945, -7.901, -7.788] }
{ "step": 47, "visits": [3.0, 20.0, 2.0, 2.0, 4.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 41, "q_vals": [-10.888, -6.566, -7.901, -13.827, -10.524, -8.679, -13.827, -7.945, -7.901, -7.788] }
{"total_number_of_episodes": 43, "number_of_timesteps": 4232, "per_episode_reward": -187.75, "episode_reward_trend_value": -3.5338642736342196, "biggest_recent_change": NaN},
{ "step": 48, "visits": [3.0, 21.0, 2.0, 2.0, 4.0, 5.0, 2.0, 3.0, 2.0, 4.0] , "episode_count": 43, "q_vals": [-10.888, -7.194, -7.901, -13.827, -10.524, -8.679, -13.827, -7.945, -7.901, -7.788] }
{ "step": 49, "visits": [3.0, 21.0, 2.0, 2.0, 4.0, 5.0, 2.0, 3.0, 3.0, 4.0] , "episode_count": 44, "q_vals": [-10.888, -7.194, -7.901, -13.827, -10.524, -8.679, -13.827, -7.945, -5.267, -7.788] }
{ "step": 50, "visits": [3.0, 21.0, 2.0, 2.0, 4.0, 5.0, 2.0, 3.0, 4.0, 4.0] , "episode_count": 46, "q_vals": [-10.888, -7.194, -7.901, -13.827, -10.524, -8.679, -13.827, -7.945, -8.889, -7.788] }
{ "step": 51, "visits": [3.0, 21.0, 3.0, 2.0, 4.0, 5.0, 2.0, 3.0, 4.0, 4.0] , "episode_count": 46, "q_vals": [-10.888, -7.194, -7.901, -13.827, -10.524, -8.679, -13.827, -7.945, -8.889, -7.788] }
{ "step": 52, "visits": [3.0, 21.0, 4.0, 2.0, 4.0, 5.0, 2.0, 3.0, 4.0, 4.0] , "episode_count": 46, "q_vals": [-10.888, -7.194, -7.901, -13.827, -10.524, -8.679, -13.827, -7.945, -8.889, -7.788] }
{ "step": 53, "visits": [3.0, 22.0, 4.0, 2.0, 4.0, 5.0, 2.0, 3.0, 4.0, 4.0] , "episode_count": 46, "q_vals": [-10.888, -7.226, -7.901, -13.827, -10.524, -8.679, -13.827, -7.945, -8.889, -7.788] }
{ "step": 54, "visits": [3.0, 22.0, 4.0, 2.0, 4.0, 5.0, 2.0, 3.0, 4.0, 5.0] , "episode_count": 48, "q_vals": [-10.888, -7.226, -7.901, -13.827, -10.524, -8.679, -13.827, -7.945, -8.889, -10.181] }
{ "step": 55, "visits": [3.0, 22.0, 4.0, 2.0, 4.0, 5.0, 2.0, 4.0, 4.0, 5.0] , "episode_count": 49, "q_vals": [-10.888, -7.226, -7.901, -13.827, -10.524, -8.679, -13.827, -7.704, -8.889, -10.181] }
{ "step": 56, "visits": [3.0, 22.0, 4.0, 2.0, 4.0, 5.0, 2.0, 5.0, 4.0, 5.0] , "episode_count": 49, "q_vals": [-10.888, -7.226, -7.901, -13.827, -10.524, -8.679, -13.827, -7.744, -8.889, -10.181] }
{ "step": 57, "visits": [3.0, 23.0, 4.0, 2.0, 4.0, 5.0, 2.0, 5.0, 4.0, 5.0] , "episode_count": 49, "q_vals": [-10.888, -7.255, -7.901, -13.827, -10.524, -8.679, -13.827, -7.744, -8.889, -10.181] }
{ "step": 58, "visits": [3.0, 24.0, 4.0, 2.0, 4.0, 5.0, 2.0, 5.0, 4.0, 5.0] , "episode_count": 50, "q_vals": [-10.888, -7.282, -7.901, -13.827, -10.524, -8.679, -13.827, -7.744, -8.889, -10.181] }
{ "step": 59, "visits": [3.0, 24.0, 4.0, 2.0, 4.0, 5.0, 2.0, 6.0, 4.0, 5.0] , "episode_count": 52, "q_vals": [-10.888, -7.282, -7.901, -13.827, -10.524, -8.679, -13.827, -7.61, -8.889, -10.181] }
{"total_number_of_episodes": 54, "number_of_timesteps": 5364, "per_episode_reward": -192.77, "episode_reward_trend_value": -2.0181290057619536, "biggest_recent_change": NaN},
{ "step": 60, "visits": [3.0, 24.0, 4.0, 2.0, 4.0, 5.0, 2.0, 7.0, 4.0, 5.0] , "episode_count": 54, "q_vals": [-10.888, -7.282, -7.901, -13.827, -10.524, -8.679, -13.827, -7.651, -8.889, -10.181] }
{ "step": 61, "visits": [3.0, 25.0, 4.0, 2.0, 4.0, 5.0, 2.0, 7.0, 4.0, 5.0] , "episode_count": 55, "q_vals": [-10.888, -7.781, -7.901, -13.827, -10.524, -8.679, -13.827, -7.651, -8.889, -10.181] }
{ "step": 62, "visits": [3.0, 25.0, 4.0, 2.0, 4.0, 5.0, 2.0, 8.0, 4.0, 5.0] , "episode_count": 56, "q_vals": [-10.888, -7.781, -7.901, -13.827, -10.524, -8.679, -13.827, -6.695, -8.889, -10.181] }
{ "step": 63, "visits": [3.0, 25.0, 4.0, 2.0, 4.0, 5.0, 2.0, 9.0, 4.0, 5.0] , "episode_count": 56, "q_vals": [-10.888, -7.781, -7.901, -13.827, -10.524, -8.679, -13.827, -8.146, -8.889, -10.181] }
{ "step": 64, "visits": [3.0, 25.0, 5.0, 2.0, 4.0, 5.0, 2.0, 9.0, 4.0, 5.0] , "episode_count": 57, "q_vals": [-10.888, -7.781, -7.901, -13.827, -10.524, -8.679, -13.827, -8.146, -8.889, -10.181] }
{ "step": 65, "visits": [3.0, 25.0, 6.0, 2.0, 4.0, 5.0, 2.0, 9.0, 4.0, 5.0] , "episode_count": 58, "q_vals": [-10.888, -7.781, -7.901, -13.827, -10.524, -8.679, -13.827, -8.146, -8.889, -10.181] }
{ "step": 66, "visits": [3.0, 25.0, 7.0, 2.0, 4.0, 5.0, 2.0, 9.0, 4.0, 5.0] , "episode_count": 58, "q_vals": [-10.888, -7.781, -7.901, -13.827, -10.524, -8.679, -13.827, -8.146, -8.889, -10.181] }
{ "step": 67, "visits": [3.0, 25.0, 8.0, 2.0, 4.0, 5.0, 2.0, 9.0, 4.0, 5.0] , "episode_count": 58, "q_vals": [-10.888, -7.781, -9.383, -13.827, -10.524, -8.679, -13.827, -8.146, -8.889, -10.181] }
{ "step": 68, "visits": [3.0, 26.0, 8.0, 2.0, 4.0, 5.0, 2.0, 9.0, 4.0, 5.0] , "episode_count": 59, "q_vals": [-10.888, -8.242, -9.383, -13.827, -10.524, -8.679, -13.827, -8.146, -8.889, -10.181] }
{ "step": 69, "visits": [3.0, 26.0, 8.0, 2.0, 4.0, 5.0, 2.0, 10.0, 4.0, 5.0] , "episode_count": 62, "q_vals": [-10.888, -8.242, -9.383, -13.827, -10.524, -8.679, -13.827, -8.121, -8.889, -10.181] }
{ "step": 70, "visits": [3.0, 26.0, 8.0, 2.0, 4.0, 5.0, 2.0, 11.0, 4.0, 5.0] , "episode_count": 63, "q_vals": [-10.888, -8.242, -9.383, -13.827, -10.524, -8.679, -13.827, -7.383, -8.889, -10.181] }
{"total_number_of_episodes": 64, "number_of_timesteps": 6395, "per_episode_reward": -197.87, "episode_reward_trend_value": -1.5154353217094345, "biggest_recent_change": NaN},
{ "step": 71, "visits": [3.0, 26.0, 8.0, 2.0, 4.0, 5.0, 2.0, 12.0, 4.0, 5.0] , "episode_count": 64, "q_vals": [-10.888, -8.242, -9.383, -13.827, -10.524, -8.679, -13.827, -8.414, -8.889, -10.181] }
{ "step": 72, "visits": [3.0, 26.0, 8.0, 2.0, 4.0, 6.0, 2.0, 12.0, 4.0, 5.0] , "episode_count": 65, "q_vals": [-10.888, -8.242, -9.383, -13.827, -10.524, -8.55, -13.827, -8.414, -8.889, -10.181] }
{ "step": 73, "visits": [3.0, 26.0, 8.0, 2.0, 4.0, 7.0, 2.0, 12.0, 4.0, 5.0] , "episode_count": 66, "q_vals": [-10.888, -8.242, -9.383, -13.827, -10.524, -8.457, -13.827, -8.414, -8.889, -10.181] }
{ "step": 74, "visits": [3.0, 26.0, 8.0, 2.0, 4.0, 8.0, 2.0, 12.0, 4.0, 5.0] , "episode_count": 66, "q_vals": [-10.888, -8.242, -9.383, -13.827, -10.524, -8.388, -13.827, -8.414, -8.889, -10.181] }
{ "step": 75, "visits": [3.0, 26.0, 8.0, 2.0, 4.0, 9.0, 2.0, 12.0, 4.0, 5.0] , "episode_count": 67, "q_vals": [-10.888, -8.242, -9.383, -13.827, -10.524, -8.333, -13.827, -8.414, -8.889, -10.181] }
{ "step": 76, "visits": [3.0, 26.0, 8.0, 2.0, 4.0, 10.0, 2.0, 12.0, 4.0, 5.0] , "episode_count": 68, "q_vals": [-10.888, -8.242, -9.383, -13.827, -10.524, -8.29, -13.827, -8.414, -8.889, -10.181] }
{ "step": 77, "visits": [3.0, 26.0, 8.0, 2.0, 4.0, 11.0, 2.0, 12.0, 4.0, 5.0] , "episode_count": 68, "q_vals": [-10.888, -8.242, -9.383, -13.827, -10.524, -8.255, -13.827, -8.414, -8.889, -10.181] }
{ "step": 78, "visits": [3.0, 26.0, 8.0, 2.0, 4.0, 12.0, 2.0, 12.0, 4.0, 5.0] , "episode_count": 68, "q_vals": [-10.888, -8.242, -9.383, -13.827, -10.524, -8.576, -13.827, -8.414, -8.889, -10.181] }
{ "step": 79, "visits": [3.0, 26.0, 8.0, 2.0, 4.0, 12.0, 2.0, 13.0, 4.0, 5.0] , "episode_count": 69, "q_vals": [-10.888, -8.242, -9.383, -13.827, -10.524, -8.576, -13.827, -8.374, -8.889, -10.181] }
{ "step": 80, "visits": [3.0, 26.0, 8.0, 2.0, 4.0, 12.0, 2.0, 14.0, 4.0, 5.0] , "episode_count": 70, "q_vals": [-10.888, -8.242, -9.383, -13.827, -10.524, -8.576, -13.827, -8.341, -8.889, -10.181] }
{ "step": 81, "visits": [3.0, 26.0, 8.0, 2.0, 4.0, 12.0, 2.0, 15.0, 4.0, 5.0] , "episode_count": 72, "q_vals": [-10.888, -8.242, -9.383, -13.827, -10.524, -8.576, -13.827, -9.102, -8.889, -10.181] }
{ "step": 82, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 12.0, 2.0, 15.0, 4.0, 5.0] , "episode_count": 73, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -8.576, -13.827, -9.102, -8.889, -10.181] }
{"total_number_of_episodes": 74, "number_of_timesteps": 7401, "per_episode_reward": -198.75, "episode_reward_trend_value": -1.1585667078676125, "biggest_recent_change": NaN},
{ "step": 83, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 12.0, 2.0, 15.0, 5.0, 5.0] , "episode_count": 74, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -8.576, -13.827, -9.102, -8.691, -10.181] }
{ "step": 84, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 12.0, 2.0, 15.0, 6.0, 5.0] , "episode_count": 75, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -8.576, -13.827, -9.102, -8.56, -10.181] }
{ "step": 85, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 12.0, 2.0, 15.0, 7.0, 5.0] , "episode_count": 75, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -8.576, -13.827, -9.102, -8.466, -10.181] }
{ "step": 86, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 12.0, 2.0, 15.0, 8.0, 5.0] , "episode_count": 75, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -8.576, -13.827, -9.102, -7.407, -10.181] }
{ "step": 87, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 12.0, 2.0, 15.0, 9.0, 5.0] , "episode_count": 77, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -8.576, -13.827, -9.102, -7.462, -10.181] }
{ "step": 88, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 12.0, 2.0, 15.0, 10.0, 5.0] , "episode_count": 77, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -8.576, -13.827, -9.102, -7.506, -10.181] }
{ "step": 89, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 12.0, 2.0, 15.0, 11.0, 5.0] , "episode_count": 77, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -8.576, -13.827, -9.102, -8.62, -10.181] }
{ "step": 90, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 13.0, 2.0, 15.0, 11.0, 5.0] , "episode_count": 77, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -8.524, -13.827, -9.102, -8.62, -10.181] }
{ "step": 91, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 11.0, 5.0] , "episode_count": 79, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -8.62, -10.181] }
{ "step": 92, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 12.0, 5.0] , "episode_count": 81, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -8.56, -10.181] }
{ "step": 93, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 13.0, 5.0] , "episode_count": 81, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -8.509, -10.181] }
{ "step": 94, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 14.0, 5.0] , "episode_count": 82, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -8.466, -10.181] }
{ "step": 95, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 15.0, 5.0] , "episode_count": 83, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -8.428, -10.181] }
{"total_number_of_episodes": 85, "number_of_timesteps": 8678, "per_episode_reward": -215.21, "episode_reward_trend_value": -1.2559789362930995, "biggest_recent_change": NaN},
{ "step": 96, "visits": [3.0, 27.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 85, "q_vals": [-10.888, -8.668, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 97, "visits": [3.0, 28.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 85, "q_vals": [-10.888, -8.64, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 98, "visits": [3.0, 29.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 85, "q_vals": [-10.888, -8.492, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 99, "visits": [3.0, 30.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 85, "q_vals": [-10.888, -8.472, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 100, "visits": [3.0, 31.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 85, "q_vals": [-10.888, -8.345, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 101, "visits": [3.0, 32.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 87, "q_vals": [-10.888, -8.331, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 102, "visits": [3.0, 33.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 88, "q_vals": [-10.888, -8.078, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 103, "visits": [3.0, 34.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 89, "q_vals": [-10.888, -8.073, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 104, "visits": [3.0, 35.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 90, "q_vals": [-10.888, -8.407, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 105, "visits": [3.0, 36.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 92, "q_vals": [-10.888, -8.393, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 106, "visits": [3.0, 37.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 93, "q_vals": [-10.888, -8.379, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 107, "visits": [3.0, 38.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 93, "q_vals": [-10.888, -8.679, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 108, "visits": [3.0, 39.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 93, "q_vals": [-10.888, -8.659, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 109, "visits": [3.0, 40.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 94, "q_vals": [-10.888, -8.64, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{"total_number_of_episodes": 95, "number_of_timesteps": 9652, "per_episode_reward": -204.61, "episode_reward_trend_value": -0.8700921971938385, "biggest_recent_change": NaN},
{ "step": 110, "visits": [3.0, 41.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 95, "q_vals": [-10.888, -8.622, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 111, "visits": [3.0, 42.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 95, "q_vals": [-10.888, -8.605, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 112, "visits": [3.0, 43.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 96, "q_vals": [-10.888, -8.588, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 113, "visits": [3.0, 44.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 100, "q_vals": [-10.888, -8.393, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 114, "visits": [3.0, 45.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 100, "q_vals": [-10.888, -8.382, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 115, "visits": [3.0, 46.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 100, "q_vals": [-10.888, -8.2, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 116, "visits": [3.0, 47.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 100, "q_vals": [-10.888, -8.194, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 117, "visits": [3.0, 48.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 102, "q_vals": [-10.888, -8.188, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 118, "visits": [3.0, 49.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 102, "q_vals": [-10.888, -8.182, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 119, "visits": [3.0, 50.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 103, "q_vals": [-10.888, -8.176, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{"total_number_of_episodes": 105, "number_of_timesteps": 10668, "per_episode_reward": -210.6, "episode_reward_trend_value": -0.8312653016570095, "biggest_recent_change": NaN},
{ "step": 120, "visits": [3.0, 51.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 105, "q_vals": [-10.888, -8.171, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 121, "visits": [3.0, 52.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 106, "q_vals": [-10.888, -8.389, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 122, "visits": [3.0, 53.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 106, "q_vals": [-10.888, -8.38, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 123, "visits": [3.0, 54.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 107, "q_vals": [-10.888, -8.371, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 124, "visits": [3.0, 55.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 107, "q_vals": [-10.888, -8.363, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 125, "visits": [3.0, 56.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 107, "q_vals": [-10.888, -8.354, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 126, "visits": [3.0, 57.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 109, "q_vals": [-10.888, -8.554, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 127, "visits": [3.0, 58.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 109, "q_vals": [-10.888, -8.543, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 128, "visits": [3.0, 59.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 110, "q_vals": [-10.888, -8.532, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 129, "visits": [3.0, 60.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 110, "q_vals": [-10.888, -8.522, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 130, "visits": [3.0, 61.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 110, "q_vals": [-10.888, -8.512, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 131, "visits": [3.0, 62.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 111, "q_vals": [-10.888, -8.502, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 132, "visits": [3.0, 63.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 111, "q_vals": [-10.888, -8.492, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 133, "visits": [3.0, 64.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 113, "q_vals": [-10.888, -8.483, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 134, "visits": [3.0, 65.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 114, "q_vals": [-10.888, -8.474, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{"total_number_of_episodes": 115, "number_of_timesteps": 11880, "per_episode_reward": -206.9, "episode_reward_trend_value": -0.6811011059313448, "biggest_recent_change": NaN},
{ "step": 135, "visits": [3.0, 66.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 115, "q_vals": [-10.888, -8.465, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 136, "visits": [3.0, 67.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 117, "q_vals": [-10.888, -8.457, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 137, "visits": [3.0, 68.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 117, "q_vals": [-10.888, -8.449, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 138, "visits": [3.0, 69.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 118, "q_vals": [-10.888, -8.441, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 139, "visits": [3.0, 70.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 119, "q_vals": [-10.888, -8.433, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 140, "visits": [3.0, 71.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 120, "q_vals": [-10.888, -8.426, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 141, "visits": [3.0, 72.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 121, "q_vals": [-10.888, -8.418, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 142, "visits": [3.0, 73.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 121, "q_vals": [-10.888, -8.411, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 143, "visits": [3.0, 74.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 121, "q_vals": [-10.888, -8.401, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 144, "visits": [3.0, 75.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 121, "q_vals": [-10.888, -8.395, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 145, "visits": [3.0, 76.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 121, "q_vals": [-10.888, -8.388, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 146, "visits": [3.0, 77.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 121, "q_vals": [-10.888, -8.536, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 147, "visits": [3.0, 78.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 124, "q_vals": [-10.888, -8.528, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{"total_number_of_episodes": 126, "number_of_timesteps": 13053, "per_episode_reward": -200.79, "episode_reward_trend_value": -0.5376120170733032, "biggest_recent_change": 35.338642736342194},
{ "step": 148, "visits": [3.0, 79.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 126, "q_vals": [-10.888, -8.67, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 149, "visits": [3.0, 80.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 127, "q_vals": [-10.888, -8.66, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 150, "visits": [3.0, 81.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 128, "q_vals": [-10.888, -8.647, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 151, "visits": [3.0, 82.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 129, "q_vals": [-10.888, -8.637, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 152, "visits": [3.0, 83.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 129, "q_vals": [-10.888, -8.629, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 153, "visits": [3.0, 84.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 129, "q_vals": [-10.888, -8.608, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 154, "visits": [3.0, 85.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 130, "q_vals": [-10.888, -8.57, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 155, "visits": [3.0, 86.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 130, "q_vals": [-10.888, -8.562, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 156, "visits": [3.0, 87.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 131, "q_vals": [-10.888, -8.554, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 157, "visits": [3.0, 88.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 134, "q_vals": [-10.888, -8.547, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{"total_number_of_episodes": 136, "number_of_timesteps": 14078, "per_episode_reward": -194.87, "episode_reward_trend_value": -0.07913479733416864, "biggest_recent_change": 16.456278499950486},
{ "step": 158, "visits": [3.0, 89.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 136, "q_vals": [-10.888, -8.673, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 159, "visits": [3.0, 90.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 136, "q_vals": [-10.888, -8.664, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 160, "visits": [3.0, 91.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 136, "q_vals": [-10.888, -8.656, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 161, "visits": [3.0, 92.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 137, "q_vals": [-10.888, -8.648, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 162, "visits": [3.0, 93.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 137, "q_vals": [-10.888, -8.64, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 163, "visits": [3.0, 94.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 137, "q_vals": [-10.888, -8.619, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 164, "visits": [3.0, 95.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 137, "q_vals": [-10.888, -8.612, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 165, "visits": [3.0, 96.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 137, "q_vals": [-10.888, -8.604, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 166, "visits": [3.0, 97.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 140, "q_vals": [-10.888, -8.597, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 167, "visits": [3.0, 98.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 140, "q_vals": [-10.888, -8.59, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 168, "visits": [3.0, 99.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 142, "q_vals": [-10.888, -8.556, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 169, "visits": [3.0, 100.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 145, "q_vals": [-10.888, -8.549, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{"total_number_of_episodes": 146, "number_of_timesteps": 16098, "per_episode_reward": -187.31, "episode_reward_trend_value": 0.06063445673756923, "biggest_recent_change": 16.456278499950486},
{ "step": 170, "visits": [3.0, 101.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 146, "q_vals": [-10.888, -8.66, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 171, "visits": [3.0, 102.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 146, "q_vals": [-10.888, -8.653, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 172, "visits": [3.0, 103.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 146, "q_vals": [-10.888, -8.645, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 173, "visits": [3.0, 104.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 146, "q_vals": [-10.888, -8.638, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 174, "visits": [3.0, 105.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 146, "q_vals": [-10.888, -8.631, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 175, "visits": [3.0, 106.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 146, "q_vals": [-10.888, -8.55, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 176, "visits": [3.0, 107.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 146, "q_vals": [-10.888, -8.544, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 177, "visits": [3.0, 108.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 147, "q_vals": [-10.888, -8.525, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 178, "visits": [3.0, 109.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 150, "q_vals": [-10.888, -8.519, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 179, "visits": [3.0, 110.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 152, "q_vals": [-10.888, -8.513, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 180, "visits": [3.0, 111.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 153, "q_vals": [-10.888, -8.507, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 181, "visits": [3.0, 112.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 154, "q_vals": [-10.888, -8.501, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 182, "visits": [3.0, 113.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 155, "q_vals": [-10.888, -8.496, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{"total_number_of_episodes": 156, "number_of_timesteps": 17283, "per_episode_reward": -189.62, "episode_reward_trend_value": 0.09168320474456884, "biggest_recent_change": 16.456278499950486},
{ "step": 183, "visits": [3.0, 114.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 156, "q_vals": [-10.888, -8.491, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 184, "visits": [3.0, 115.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 156, "q_vals": [-10.888, -8.486, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 185, "visits": [3.0, 116.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 157, "q_vals": [-10.888, -8.48, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 186, "visits": [3.0, 117.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 158, "q_vals": [-10.888, -8.577, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 187, "visits": [3.0, 118.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 159, "q_vals": [-10.888, -8.571, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 188, "visits": [3.0, 119.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 160, "q_vals": [-10.888, -8.499, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 189, "visits": [3.0, 120.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 162, "q_vals": [-10.888, -8.494, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 190, "visits": [3.0, 121.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 163, "q_vals": [-10.888, -8.587, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 191, "visits": [3.0, 122.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 163, "q_vals": [-10.888, -8.678, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 192, "visits": [3.0, 123.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 164, "q_vals": [-10.888, -8.672, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 193, "visits": [3.0, 124.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 165, "q_vals": [-10.888, -8.666, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{"total_number_of_episodes": 167, "number_of_timesteps": 18255, "per_episode_reward": -180.4, "episode_reward_trend_value": 0.203885844076594, "biggest_recent_change": 16.456278499950486},
{ "step": 194, "visits": [3.0, 125.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 167, "q_vals": [-10.888, -8.66, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 195, "visits": [3.0, 126.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 169, "q_vals": [-10.888, -8.654, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 196, "visits": [3.0, 127.0, 8.0, 2.0, 4.0, 14.0, 2.0, 15.0, 16.0, 5.0] , "episode_count": 170, "q_vals": [-10.888, -8.741, -9.383, -13.827, -10.524, -9.326, -13.827, -9.102, -9.136, -10.181] }
{ "step": 197, "visits": [3.0, 127.0, 8.0, 2.0, 4.0, 14.0, 2.0, 16.0, 16.0, 5.0] , "episode_count": 171, "q_vals": [-10.888, -8.741, -9.383, -13.827, -10.524, -9.326, -13.827, -8.533, -9.136, -10.181] }
{ "step": 198, "visits": [3.0, 127.0, 8.0, 2.0, 4.0, 14.0, 2.0, 17.0, 16.0, 5.0] , "episode_count": 172, "q_vals": [-10.888, -8.741, -9.383, -13.827, -10.524, -9.326, -13.827, -8.496, -9.136, -10.181] }
{ "step": 199, "visits": [3.0, 127.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 16.0, 5.0] , "episode_count": 172, "q_vals": [-10.888, -8.741, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.136, -10.181] }
{ "step": 200, "visits": [3.0, 128.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 16.0, 5.0] , "episode_count": 172, "q_vals": [-10.888, -8.734, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.136, -10.181] }
{ "step": 201, "visits": [3.0, 129.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 16.0, 5.0] , "episode_count": 173, "q_vals": [-10.888, -8.728, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.136, -10.181] }
{ "step": 202, "visits": [3.0, 130.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 16.0, 5.0] , "episode_count": 175, "q_vals": [-10.888, -8.721, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.136, -10.181] }
{ "step": 203, "visits": [3.0, 131.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 16.0, 5.0] , "episode_count": 175, "q_vals": [-10.888, -8.655, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.136, -10.181] }
{"total_number_of_episodes": 177, "number_of_timesteps": 19121, "per_episode_reward": -172.52, "episode_reward_trend_value": 0.47432929926685824, "biggest_recent_change": 10.593414983024672},
{ "step": 204, "visits": [3.0, 132.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 16.0, 5.0] , "episode_count": 177, "q_vals": [-10.888, -8.739, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.136, -10.181] }
{ "step": 205, "visits": [3.0, 133.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 16.0, 5.0] , "episode_count": 179, "q_vals": [-10.888, -8.673, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.136, -10.181] }
{ "step": 206, "visits": [3.0, 134.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 16.0, 5.0] , "episode_count": 180, "q_vals": [-10.888, -8.756, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.136, -10.181] }
{ "step": 207, "visits": [3.0, 135.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 16.0, 5.0] , "episode_count": 180, "q_vals": [-10.888, -8.75, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.136, -10.181] }
{ "step": 208, "visits": [3.0, 136.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 16.0, 5.0] , "episode_count": 181, "q_vals": [-10.888, -8.743, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.136, -10.181] }
{ "step": 209, "visits": [3.0, 137.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 16.0, 5.0] , "episode_count": 183, "q_vals": [-10.888, -8.731, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.136, -10.181] }
{ "step": 210, "visits": [3.0, 138.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 16.0, 5.0] , "episode_count": 183, "q_vals": [-10.888, -8.725, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.136, -10.181] }
{ "step": 211, "visits": [3.0, 139.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 16.0, 5.0] , "episode_count": 183, "q_vals": [-10.888, -8.805, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.136, -10.181] }
{ "step": 212, "visits": [3.0, 139.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 17.0, 5.0] , "episode_count": 184, "q_vals": [-10.888, -8.805, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.046, -10.181] }
{ "step": 213, "visits": [3.0, 139.0, 8.0, 2.0, 4.0, 14.0, 2.0, 18.0, 18.0, 5.0] , "episode_count": 185, "q_vals": [-10.888, -8.805, -9.383, -13.827, -10.524, -9.326, -13.827, -9.121, -9.641, -10.181] }
{ "step": 214, "visits": [3.0, 139.0, 9.0, 2.0, 4.0, 14.0, 2.0, 18.0, 18.0, 5.0] , "episode_count": 185, "q_vals": [-10.888, -8.805, -9.218, -13.827, -10.524, -9.326, -13.827, -9.121, -9.641, -10.181] }
{ "step": 215, "visits": [3.0, 139.0, 10.0, 2.0, 4.0, 14.0, 2.0, 18.0, 18.0, 5.0] , "episode_count": 186, "q_vals": [-10.888, -8.805, -8.802, -13.827, -10.524, -9.326, -13.827, -9.121, -9.641, -10.181] }
{"total_number_of_episodes": 188, "number_of_timesteps": 20268, "per_episode_reward": -171.03, "episode_reward_trend_value": 0.3731576928307567, "biggest_recent_change": 9.218628876460798},
{ "step": 216, "visits": [3.0, 139.0, 11.0, 2.0, 4.0, 14.0, 2.0, 18.0, 18.0, 5.0] , "episode_count": 188, "q_vals": [-10.888, -8.805, -8.525, -13.827, -10.524, -9.326, -13.827, -9.121, -9.641, -10.181] }
{ "step": 217, "visits": [3.0, 139.0, 12.0, 2.0, 4.0, 14.0, 2.0, 18.0, 18.0, 5.0] , "episode_count": 188, "q_vals": [-10.888, -8.805, -9.461, -13.827, -10.524, -9.326, -13.827, -9.121, -9.641, -10.181] }
{ "step": 218, "visits": [3.0, 139.0, 12.0, 2.0, 4.0, 14.0, 2.0, 19.0, 18.0, 5.0] , "episode_count": 190, "q_vals": [-10.888, -8.805, -9.461, -13.827, -10.524, -9.326, -13.827, -9.057, -9.641, -10.181] }
{ "step": 219, "visits": [3.0, 139.0, 12.0, 2.0, 4.0, 14.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 191, "q_vals": [-10.888, -8.805, -9.461, -13.827, -10.524, -9.326, -13.827, -9.592, -9.641, -10.181] }
{ "step": 220, "visits": [3.0, 140.0, 12.0, 2.0, 4.0, 14.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 193, "q_vals": [-10.888, -8.798, -9.461, -13.827, -10.524, -9.326, -13.827, -9.592, -9.641, -10.181] }
{ "step": 221, "visits": [3.0, 141.0, 12.0, 2.0, 4.0, 14.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 193, "q_vals": [-10.888, -8.792, -9.461, -13.827, -10.524, -9.326, -13.827, -9.592, -9.641, -10.181] }
{ "step": 222, "visits": [3.0, 142.0, 12.0, 2.0, 4.0, 14.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 193, "q_vals": [-10.888, -8.786, -9.461, -13.827, -10.524, -9.326, -13.827, -9.592, -9.641, -10.181] }
{ "step": 223, "visits": [3.0, 143.0, 12.0, 2.0, 4.0, 14.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 193, "q_vals": [-10.888, -8.779, -9.461, -13.827, -10.524, -9.326, -13.827, -9.592, -9.641, -10.181] }
{ "step": 224, "visits": [3.0, 144.0, 12.0, 2.0, 4.0, 14.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 194, "q_vals": [-10.888, -8.856, -9.461, -13.827, -10.524, -9.326, -13.827, -9.592, -9.641, -10.181] }
{ "step": 225, "visits": [3.0, 145.0, 12.0, 2.0, 4.0, 14.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 196, "q_vals": [-10.888, -8.849, -9.461, -13.827, -10.524, -9.326, -13.827, -9.592, -9.641, -10.181] }
{"total_number_of_episodes": 198, "number_of_timesteps": 21347, "per_episode_reward": -173.46, "episode_reward_trend_value": 0.4126138703474137, "biggest_recent_change": 9.218628876460798},
{ "step": 226, "visits": [3.0, 146.0, 12.0, 2.0, 4.0, 14.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 198, "q_vals": [-10.888, -8.843, -9.461, -13.827, -10.524, -9.326, -13.827, -9.592, -9.641, -10.181] }
{ "step": 227, "visits": [3.0, 147.0, 12.0, 2.0, 4.0, 14.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 198, "q_vals": [-10.888, -8.917, -9.461, -13.827, -10.524, -9.326, -13.827, -9.592, -9.641, -10.181] }
{ "step": 228, "visits": [3.0, 147.0, 12.0, 2.0, 4.0, 15.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 199, "q_vals": [-10.888, -8.917, -9.461, -13.827, -10.524, -9.072, -13.827, -9.592, -9.641, -10.181] }
{ "step": 229, "visits": [3.0, 147.0, 12.0, 2.0, 4.0, 16.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 201, "q_vals": [-10.888, -8.917, -9.461, -13.827, -10.524, -8.999, -13.827, -9.592, -9.641, -10.181] }
{ "step": 230, "visits": [3.0, 147.0, 12.0, 2.0, 4.0, 17.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 202, "q_vals": [-10.888, -8.917, -9.461, -13.827, -10.524, -8.69, -13.827, -9.592, -9.641, -10.181] }
{ "step": 231, "visits": [3.0, 147.0, 12.0, 2.0, 4.0, 18.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 202, "q_vals": [-10.888, -8.917, -9.461, -13.827, -10.524, -8.646, -13.827, -9.592, -9.641, -10.181] }
{ "step": 232, "visits": [3.0, 147.0, 12.0, 2.0, 4.0, 19.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 202, "q_vals": [-10.888, -8.917, -9.461, -13.827, -10.524, -8.607, -13.827, -9.592, -9.641, -10.181] }
{ "step": 233, "visits": [3.0, 147.0, 12.0, 2.0, 4.0, 20.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 203, "q_vals": [-10.888, -8.917, -9.461, -13.827, -10.524, -8.572, -13.827, -9.592, -9.641, -10.181] }
{ "step": 234, "visits": [3.0, 147.0, 12.0, 2.0, 4.0, 21.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 203, "q_vals": [-10.888, -8.917, -9.461, -13.827, -10.524, -8.163, -13.827, -9.592, -9.641, -10.181] }
{ "step": 235, "visits": [3.0, 147.0, 12.0, 2.0, 4.0, 22.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 205, "q_vals": [-10.888, -8.917, -9.461, -13.827, -10.524, -8.152, -13.827, -9.592, -9.641, -10.181] }
{ "step": 236, "visits": [3.0, 147.0, 12.0, 2.0, 4.0, 23.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 205, "q_vals": [-10.888, -8.917, -9.461, -13.827, -10.524, -8.656, -13.827, -9.592, -9.641, -10.181] }
{ "step": 237, "visits": [3.0, 147.0, 12.0, 2.0, 4.0, 24.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 207, "q_vals": [starting run_func()] }
[starting train_loop()]
[-10.888, -8.917, -9.461, -13.827, -10.524, -9.118, -13.827, -9.592, -9.641, -10.181]
{"total_number_of_episodes": 208, "number_of_timesteps": 22373, "per_episode_reward": -182.33, "episode_reward_trend_value": 0.2729808100803192, "biggest_recent_change": 9.218628876460798},
{ "step": 238, "visits": [3.0, 147.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 208, "q_vals": [-10.888, -8.917, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 239, "visits": [3.0, 148.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 208, "q_vals": [-10.888, -8.908, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 240, "visits": [3.0, 149.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 208, "q_vals": [-10.888, -8.901, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 241, "visits": [3.0, 150.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 209, "q_vals": [-10.888, -8.842, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 242, "visits": [3.0, 151.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 211, "q_vals": [-10.888, -8.783, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 243, "visits": [3.0, 152.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 212, "q_vals": [-10.888, -8.778, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 244, "visits": [3.0, 153.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 213, "q_vals": [-10.888, -8.787, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 245, "visits": [3.0, 154.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 213, "q_vals": [-10.888, -8.781, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 246, "visits": [3.0, 155.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 213, "q_vals": [-10.888, -8.775, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 247, "visits": [3.0, 156.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 214, "q_vals": [-10.888, -8.77, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 248, "visits": [3.0, 157.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 214, "q_vals": [-10.888, -8.84, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 249, "visits": [3.0, 158.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 215, "q_vals": [-10.888, -8.834, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 250, "visits": [3.0, 159.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 217, "q_vals": [-10.888, -8.828, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 251, "visits": [3.0, 160.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 217, "q_vals": [-10.888, -8.822, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{"total_number_of_episodes": 219, "number_of_timesteps": 23685, "per_episode_reward": -194.27, "episode_reward_trend_value": 0.07244476641954678, "biggest_recent_change": 11.945236991559227},
{ "step": 252, "visits": [3.0, 161.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 219, "q_vals": [-10.888, -8.806, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 253, "visits": [3.0, 162.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 219, "q_vals": [-10.888, -8.772, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 254, "visits": [3.0, 163.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 220, "q_vals": [-10.888, -8.839, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 255, "visits": [3.0, 164.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 220, "q_vals": [-10.888, -8.905, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 256, "visits": [3.0, 165.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 221, "q_vals": [-10.888, -8.899, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 257, "visits": [3.0, 166.0, 12.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 222, "q_vals": [-10.888, -8.965, -9.461, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 258, "visits": [3.0, 166.0, 13.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 222, "q_vals": [-10.888, -8.965, -9.341, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 259, "visits": [3.0, 166.0, 14.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 223, "q_vals": [-10.888, -8.965, -9.238, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 260, "visits": [3.0, 166.0, 15.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 223, "q_vals": [-10.888, -8.965, -9.149, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 261, "visits": [3.0, 166.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 225, "q_vals": [-10.888, -8.965, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 262, "visits": [3.0, 167.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 227, "q_vals": [-10.888, -8.958, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 263, "visits": [3.0, 168.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 227, "q_vals": [-10.888, -8.942, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 264, "visits": [3.0, 169.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 228, "q_vals": [-10.888, -8.936, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 265, "visits": [3.0, 170.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 228, "q_vals": [-10.888, -9.0, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{"total_number_of_episodes": 230, "number_of_timesteps": 24917, "per_episode_reward": -202.8, "episode_reward_trend_value": -0.08811676716277235, "biggest_recent_change": 11.945236991559227},
{ "step": 266, "visits": [3.0, 171.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 230, "q_vals": [-10.888, -8.993, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 267, "visits": [3.0, 172.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 230, "q_vals": [-10.888, -8.987, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 268, "visits": [3.0, 173.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 230, "q_vals": [-10.888, -8.981, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 269, "visits": [3.0, 174.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 230, "q_vals": [-10.888, -9.042, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 270, "visits": [3.0, 175.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 230, "q_vals": [-10.888, -9.036, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 271, "visits": [3.0, 176.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 231, "q_vals": [-10.888, -8.994, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 272, "visits": [3.0, 177.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 232, "q_vals": [-10.888, -8.988, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 273, "visits": [3.0, 178.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 232, "q_vals": [-10.888, -8.982, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 274, "visits": [3.0, 179.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 233, "q_vals": [-10.888, -9.042, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 275, "visits": [3.0, 180.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 234, "q_vals": [-10.888, -9.036, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 276, "visits": [3.0, 181.0, 16.0, 2.0, 4.0, 25.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 235, "q_vals": [-10.888, -9.095, -9.812, -13.827, -10.524, -9.359, -13.827, -9.592, -9.641, -10.181] }
{ "step": 277, "visits": [3.0, 181.0, 16.0, 2.0, 4.0, 26.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 236, "q_vals": [-10.888, -9.095, -9.812, -13.827, -10.524, -9.303, -13.827, -9.592, -9.641, -10.181] }
{ "step": 278, "visits": [3.0, 181.0, 16.0, 2.0, 4.0, 27.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 237, "q_vals": [-10.888, -9.095, -9.812, -13.827, -10.524, -9.251, -13.827, -9.592, -9.641, -10.181] }
{ "step": 279, "visits": [3.0, 181.0, 16.0, 2.0, 4.0, 28.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 237, "q_vals": [-10.888, -9.095, -9.812, -13.827, -10.524, -9.626, -13.827, -9.592, -9.641, -10.181] }
{ "step": 280, "visits": [3.0, 182.0, 16.0, 2.0, 4.0, 28.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 239, "q_vals": [-10.888, -9.154, -9.812, -13.827, -10.524, -9.626, -13.827, -9.592, -9.641, -10.181] }
{"total_number_of_episodes": 240, "number_of_timesteps": 26572, "per_episode_reward": -211.25, "episode_reward_trend_value": -0.26593250607566415, "biggest_recent_change": 11.945236991559227},
{ "step": 281, "visits": [3.0, 183.0, 16.0, 2.0, 4.0, 28.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 240, "q_vals": [-10.888, -9.212, -9.812, -13.827, -10.524, -9.626, -13.827, -9.592, -9.641, -10.181] }
{ "step": 282, "visits": [3.0, 184.0, 16.0, 2.0, 4.0, 28.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 240, "q_vals": [-10.888, -9.161, -9.812, -13.827, -10.524, -9.626, -13.827, -9.592, -9.641, -10.181] }
{ "step": 283, "visits": [3.0, 185.0, 16.0, 2.0, 4.0, 28.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 242, "q_vals": [-10.888, -9.155, -9.812, -13.827, -10.524, -9.626, -13.827, -9.592, -9.641, -10.181] }
{ "step": 284, "visits": [3.0, 186.0, 16.0, 2.0, 4.0, 28.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 242, "q_vals": [-10.888, -9.148, -9.812, -13.827, -10.524, -9.626, -13.827, -9.592, -9.641, -10.181] }
{ "step": 285, "visits": [3.0, 187.0, 16.0, 2.0, 4.0, 28.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 242, "q_vals": [-10.888, -9.205, -9.812, -13.827, -10.524, -9.626, -13.827, -9.592, -9.641, -10.181] }
{ "step": 286, "visits": [3.0, 188.0, 16.0, 2.0, 4.0, 28.0, 2.0, 20.0, 18.0, 5.0] , "episode_count": 242, "q_vals": [-10.888, -9.261, -9.812, -13.827, -10.524, -9.626, -13.827, -9.592, -9.641, -10.181] }
{ "step": 287, "visits": [3.0, 188.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 18.0, 5.0] , "episode_count": 242, "q_vals": [-10.888, -9.261, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.641, -10.181] }
{ "step": 288, "visits": [3.0, 188.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 19.0, 5.0] , "episode_count": 245, "q_vals": [-10.888, -9.261, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.55, -10.181] }
{ "step": 289, "visits": [3.0, 188.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 20.0, 5.0] , "episode_count": 245, "q_vals": [-10.888, -9.261, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.467, -10.181] }
{ "step": 290, "visits": [3.0, 188.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 246, "q_vals": [-10.888, -9.261, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 291, "visits": [3.0, 189.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 247, "q_vals": [-10.888, -9.254, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 292, "visits": [3.0, 190.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 249, "q_vals": [-10.888, -9.246, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{"total_number_of_episodes": 250, "number_of_timesteps": 27719, "per_episode_reward": -215.67, "episode_reward_trend_value": -0.2894565120192141, "biggest_recent_change": 11.945236991559227},
{ "step": 293, "visits": [3.0, 191.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 250, "q_vals": [-10.888, -9.198, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 294, "visits": [3.0, 192.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 251, "q_vals": [-10.888, -9.166, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 295, "visits": [3.0, 193.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 252, "q_vals": [-10.888, -9.149, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 296, "visits": [3.0, 194.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 252, "q_vals": [-10.888, -9.198, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 297, "visits": [3.0, 195.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 253, "q_vals": [-10.888, -9.252, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 298, "visits": [3.0, 196.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 254, "q_vals": [-10.888, -9.205, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 299, "visits": [3.0, 197.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 255, "q_vals": [-10.888, -9.198, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 300, "visits": [3.0, 198.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 256, "q_vals": [-10.888, -9.152, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 301, "visits": [3.0, 199.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 256, "q_vals": [-10.888, -9.145, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 302, "visits": [3.0, 200.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 256, "q_vals": [-10.888, -9.139, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 303, "visits": [3.0, 201.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 257, "q_vals": [starting run_func()] }
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[-10.888, -9.133, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181]
{ "step": 304, "visits": [3.0, 202.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 258, "q_vals": [-10.888, -9.186, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 305, "visits": [3.0, 203.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 259, "q_vals": [-10.888, -9.166, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{"total_number_of_episodes": 260, "number_of_timesteps": 28830, "per_episode_reward": -216.05, "episode_reward_trend_value": -0.39614917152382373, "biggest_recent_change": 11.945236991559227},
{ "step": 306, "visits": [3.0, 204.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 260, "q_vals": [-10.888, -9.136, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 307, "visits": [3.0, 205.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 263, "q_vals": [-10.888, -9.187, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 308, "visits": [3.0, 206.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 263, "q_vals": [-10.888, -9.176, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 309, "visits": [3.0, 207.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 263, "q_vals": [-10.888, -9.169, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 310, "visits": [3.0, 208.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 264, "q_vals": [-10.888, -9.145, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 311, "visits": [3.0, 209.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 264, "q_vals": [-10.888, -9.196, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 312, "visits": [3.0, 210.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 265, "q_vals": [-10.888, -9.231, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 313, "visits": [3.0, 211.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 5.0] , "episode_count": 266, "q_vals": [-10.888, -9.281, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.181] }
{ "step": 314, "visits": [3.0, 211.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 6.0] , "episode_count": 267, "q_vals": [-10.888, -9.281, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -9.801] }
{ "step": 315, "visits": [3.0, 211.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 7.0] , "episode_count": 269, "q_vals": [-10.888, -9.281, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -9.144] }
{ "step": 316, "visits": [3.0, 211.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 269, "q_vals": [-10.888, -9.281, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{"total_number_of_episodes": 272, "number_of_timesteps": 30135, "per_episode_reward": -209.07, "episode_reward_trend_value": -0.4061751450996957, "biggest_recent_change": 11.945236991559227},
{ "step": 317, "visits": [3.0, 212.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 272, "q_vals": [-10.888, -9.274, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 318, "visits": [3.0, 213.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 273, "q_vals": [-10.888, -9.268, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 319, "visits": [3.0, 214.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 274, "q_vals": [-10.888, -9.273, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 320, "visits": [3.0, 215.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 274, "q_vals": [-10.888, -9.267, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 321, "visits": [3.0, 216.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 275, "q_vals": [-10.888, -9.224, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 322, "visits": [3.0, 217.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 275, "q_vals": [-10.888, -9.218, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 323, "visits": [3.0, 218.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 275, "q_vals": [-10.888, -9.212, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 324, "visits": [3.0, 219.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 275, "q_vals": [-10.888, -9.206, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 325, "visits": [3.0, 220.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 275, "q_vals": [-10.888, -9.2, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 326, "visits": [3.0, 221.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 276, "q_vals": [-10.888, -9.248, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 327, "visits": [3.0, 222.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 278, "q_vals": [-10.888, -9.239, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 328, "visits": [3.0, 223.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 278, "q_vals": [-10.888, -9.205, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 329, "visits": [3.0, 224.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 280, "q_vals": [-10.888, -9.199, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{"total_number_of_episodes": 282, "number_of_timesteps": 31163, "per_episode_reward": -203.71, "episode_reward_trend_value": -0.3630695947004395, "biggest_recent_change": 11.945236991559227},
{ "step": 330, "visits": [3.0, 225.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 282, "q_vals": [-10.888, -9.193, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 331, "visits": [3.0, 226.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 282, "q_vals": [-10.888, -9.187, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 332, "visits": [3.0, 227.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 282, "q_vals": [-10.888, -9.182, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 333, "visits": [3.0, 228.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 282, "q_vals": [-10.888, -9.141, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 334, "visits": [3.0, 229.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 283, "q_vals": [-10.888, -9.132, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 335, "visits": [3.0, 230.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 283, "q_vals": [-10.888, -9.159, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 336, "visits": [3.0, 231.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 283, "q_vals": [-10.888, -9.147, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 337, "visits": [3.0, 232.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 285, "q_vals": [-10.888, -9.185, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 338, "visits": [3.0, 233.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 285, "q_vals": [-10.888, -9.23, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 339, "visits": [3.0, 234.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 286, "q_vals": [-10.888, -9.224, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 340, "visits": [3.0, 235.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 286, "q_vals": [-10.888, -9.219, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 341, "visits": [3.0, 236.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 287, "q_vals": [-10.888, -9.263, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 342, "visits": [3.0, 237.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 287, "q_vals": [-10.888, -9.257, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 343, "visits": [3.0, 238.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 288, "q_vals": [-10.888, -9.252, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 344, "visits": [3.0, 239.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 290, "q_vals": [-10.888, -9.296, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 345, "visits": [3.0, 240.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 290, "q_vals": [-10.888, -9.257, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 346, "visits": [3.0, 241.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 290, "q_vals": [-10.888, -9.301, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 347, "visits": [3.0, 242.0, 16.0, 2.0, 4.0, 28.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 291, "q_vals": [-10.888, -9.344, -9.812, -13.827, -10.524, -9.626, -13.827, -10.075, -9.957, -10.47] }
{ "step": 348, "visits": [3.0, 242.0, 16.0, 2.0, 4.0, 29.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 291, "q_vals": [-10.888, -9.344, -9.812, -13.827, -10.524, -9.567, -13.827, -10.075, -9.957, -10.47] }
{"total_number_of_episodes": 292, "number_of_timesteps": 32582, "per_episode_reward": -205.01, "episode_reward_trend_value": -0.35053489762418527, "biggest_recent_change": 11.945236991559227},
{ "step": 349, "visits": [3.0, 242.0, 16.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 292, "q_vals": [-10.888, -9.344, -9.812, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 350, "visits": [3.0, 243.0, 16.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 292, "q_vals": [-10.888, -9.305, -9.812, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 351, "visits": [3.0, 244.0, 16.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 293, "q_vals": [-10.888, -9.348, -9.812, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 352, "visits": [3.0, 245.0, 16.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 294, "q_vals": [-10.888, -9.391, -9.812, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 353, "visits": [3.0, 245.0, 17.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 296, "q_vals": [-10.888, -9.391, -9.614, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 354, "visits": [3.0, 245.0, 18.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 299, "q_vals": [-10.888, -9.391, -9.518, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 355, "visits": [3.0, 245.0, 19.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 299, "q_vals": [-10.888, -9.391, -9.433, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 356, "visits": [3.0, 245.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 299, "q_vals": [-10.888, -9.391, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 357, "visits": [3.0, 246.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 300, "q_vals": [-10.888, -9.384, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 358, "visits": [3.0, 247.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 301, "q_vals": [-10.888, -9.378, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 359, "visits": [3.0, 248.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 301, "q_vals": [-10.888, -9.341, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 360, "visits": [3.0, 249.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 301, "q_vals": [-10.888, -9.335, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{"total_number_of_episodes": 302, "number_of_timesteps": 34068, "per_episode_reward": -212.37, "episode_reward_trend_value": -0.33374822787816166, "biggest_recent_change": 11.945236991559227},
{ "step": 361, "visits": [3.0, 250.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 302, "q_vals": [-10.888, -9.298, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 362, "visits": [3.0, 251.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 305, "q_vals": [-10.888, -9.275, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 363, "visits": [3.0, 252.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 306, "q_vals": [-10.888, -9.27, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 364, "visits": [3.0, 253.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 308, "q_vals": [-10.888, -9.233, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 365, "visits": [3.0, 254.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 308, "q_vals": [-10.888, -9.274, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 366, "visits": [3.0, 255.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 308, "q_vals": [-10.888, -9.269, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 367, "visits": [3.0, 256.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 309, "q_vals": [-10.888, -9.264, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 368, "visits": [3.0, 257.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 309, "q_vals": [-10.888, -9.304, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 369, "visits": [3.0, 258.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 309, "q_vals": [-10.888, -9.299, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 370, "visits": [3.0, 259.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 309, "q_vals": [-10.888, -9.339, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 371, "visits": [3.0, 260.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 309, "q_vals": [-10.888, -9.334, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 372, "visits": [3.0, 261.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 310, "q_vals": [-10.888, -9.374, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 373, "visits": [3.0, 262.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 311, "q_vals": [-10.888, -9.413, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 374, "visits": [3.0, 263.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 311, "q_vals": [-10.888, -9.408, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 375, "visits": [3.0, 264.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 311, "q_vals": [-10.888, -9.402, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{"total_number_of_episodes": 314, "number_of_timesteps": 35411, "per_episode_reward": -215.25, "episode_reward_trend_value": -0.23311710602053587, "biggest_recent_change": 8.52623098222881},
{ "step": 376, "visits": [3.0, 265.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 314, "q_vals": [-10.888, -9.396, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 377, "visits": [3.0, 266.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 316, "q_vals": [-10.888, -9.391, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 378, "visits": [3.0, 267.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 316, "q_vals": [-10.888, -9.385, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 379, "visits": [3.0, 268.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 317, "q_vals": [-10.888, -9.38, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 380, "visits": [3.0, 269.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 317, "q_vals": [-10.888, -9.374, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 381, "visits": [3.0, 270.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 317, "q_vals": [-10.888, -9.36, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 382, "visits": [3.0, 271.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 317, "q_vals": [-10.888, -9.354, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 383, "visits": [3.0, 272.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 318, "q_vals": [-10.888, -9.393, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 384, "visits": [3.0, 273.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 318, "q_vals": [-10.888, -9.358, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 385, "visits": [3.0, 274.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 318, "q_vals": [-10.888, -9.353, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 386, "visits": [3.0, 275.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 319, "q_vals": [-10.888, -9.391, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 387, "visits": [3.0, 276.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 319, "q_vals": [-10.888, -9.428, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 388, "visits": [3.0, 277.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 320, "q_vals": [-10.888, -9.423, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 389, "visits": [3.0, 278.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 320, "q_vals": [-10.888, -9.417, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 390, "visits": [3.0, 279.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 321, "q_vals": [-10.888, -9.412, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 391, "visits": [3.0, 280.0, 20.0, 2.0, 4.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 323, "q_vals": [-10.888, -9.449, -9.949, -13.827, -10.524, -9.907, -13.827, -10.075, -9.957, -10.47] }
{"total_number_of_episodes": 324, "number_of_timesteps": 36994, "per_episode_reward": -218.17, "episode_reward_trend_value": -0.1707570280518979, "biggest_recent_change": 8.44812101460073},
{ "step": 392, "visits": [3.0, 280.0, 20.0, 2.0, 5.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 324, "q_vals": [-10.888, -9.449, -9.949, -13.827, -8.42, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 393, "visits": [3.0, 280.0, 20.0, 2.0, 6.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 325, "q_vals": [-10.888, -9.449, -9.949, -13.827, -7.016, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 394, "visits": [3.0, 280.0, 20.0, 2.0, 7.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 326, "q_vals": [-10.888, -9.449, -9.949, -13.827, -7.143, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 395, "visits": [3.0, 280.0, 20.0, 2.0, 8.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 326, "q_vals": [-10.888, -9.449, -9.949, -13.827, -8.719, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 396, "visits": [3.0, 280.0, 20.0, 2.0, 9.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 326, "q_vals": [-10.888, -9.449, -9.949, -13.827, -9.945, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 397, "visits": [3.0, 280.0, 20.0, 2.0, 10.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 327, "q_vals": [-10.888, -9.449, -9.949, -13.827, -9.342, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 398, "visits": [3.0, 280.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 327, "q_vals": [-10.888, -9.449, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 399, "visits": [3.0, 281.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 328, "q_vals": [-10.888, -9.443, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 400, "visits": [3.0, 282.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 329, "q_vals": [-10.888, -9.438, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 401, "visits": [3.0, 283.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 330, "q_vals": [-10.888, -9.432, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 402, "visits": [3.0, 284.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 331, "q_vals": [-10.888, -9.427, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 403, "visits": [3.0, 285.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 331, "q_vals": [-10.888, -9.422, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 404, "visits": [3.0, 286.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 331, "q_vals": [-10.888, -9.458, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 405, "visits": [3.0, 287.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 332, "q_vals": [-10.888, -9.452, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 406, "visits": [3.0, 288.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 332, "q_vals": [-10.888, -9.447, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 407, "visits": [3.0, 289.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 333, "q_vals": [-10.888, -9.442, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 408, "visits": [3.0, 290.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 333, "q_vals": [-10.888, -9.436, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{"total_number_of_episodes": 334, "number_of_timesteps": 38545, "per_episode_reward": -222.06, "episode_reward_trend_value": -0.1201085110209735, "biggest_recent_change": 7.355692505413288},
{ "step": 409, "visits": [3.0, 291.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 334, "q_vals": [-10.888, -9.472, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 410, "visits": [3.0, 292.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 335, "q_vals": [-10.888, -9.466, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 411, "visits": [3.0, 293.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 335, "q_vals": [-10.888, -9.461, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 412, "visits": [3.0, 294.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 336, "q_vals": [-10.888, -9.456, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 413, "visits": [3.0, 295.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 336, "q_vals": [-10.888, -9.45, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 414, "visits": [3.0, 296.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 336, "q_vals": [-10.888, -9.445, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 415, "visits": [3.0, 297.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 338, "q_vals": [-10.888, -9.44, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 416, "visits": [3.0, 298.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 338, "q_vals": [-10.888, -9.435, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 417, "visits": [3.0, 299.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 340, "q_vals": [-10.888, -9.43, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 418, "visits": [3.0, 300.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 342, "q_vals": [-10.888, -9.425, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 419, "visits": [3.0, 301.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 342, "q_vals": [-10.888, -9.459, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 420, "visits": [3.0, 302.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 343, "q_vals": [-10.888, -9.454, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 421, "visits": [3.0, 303.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 343, "q_vals": [-10.888, -9.449, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 422, "visits": [3.0, 304.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 343, "q_vals": [-10.888, -9.483, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{"total_number_of_episodes": 344, "number_of_timesteps": 40053, "per_episode_reward": -225.82, "episode_reward_trend_value": -0.11273815869830532, "biggest_recent_change": 7.355692505413288},
{ "step": 423, "visits": [3.0, 305.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 344, "q_vals": [-10.888, -9.516, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 424, "visits": [3.0, 306.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 344, "q_vals": [-10.888, -9.511, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 425, "visits": [3.0, 307.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 344, "q_vals": [-10.888, -9.506, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 426, "visits": [3.0, 308.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 347, "q_vals": [-10.888, -9.475, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 427, "visits": [3.0, 309.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 349, "q_vals": [-10.888, -9.47, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 428, "visits": [3.0, 310.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 350, "q_vals": [-10.888, -9.503, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 429, "visits": [3.0, 311.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 350, "q_vals": [-10.888, -9.498, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 430, "visits": [3.0, 312.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 350, "q_vals": [-10.888, -9.531, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 431, "visits": [3.0, 313.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 350, "q_vals": [-10.888, -9.525, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 432, "visits": [3.0, 314.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 350, "q_vals": [-10.888, -9.52, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 433, "visits": [3.0, 315.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 350, "q_vals": [-10.888, -9.515, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 434, "visits": [3.0, 316.0, 20.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 351, "q_vals": [-10.888, -9.548, -9.949, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 435, "visits": [3.0, 316.0, 21.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 352, "q_vals": [-10.888, -9.548, -9.852, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 436, "visits": [3.0, 316.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 353, "q_vals": [-10.888, -9.548, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{"total_number_of_episodes": 354, "number_of_timesteps": 41139, "per_episode_reward": -230.28, "episode_reward_trend_value": -0.1580476981961384, "biggest_recent_change": 7.355692505413288},
{ "step": 437, "visits": [3.0, 317.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 354, "q_vals": [-10.888, -9.542, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 438, "visits": [3.0, 318.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 355, "q_vals": [-10.888, -9.537, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 439, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 21.0, 8.0] , "episode_count": 356, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.957, -10.47] }
{ "step": 440, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 22.0, 8.0] , "episode_count": 356, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.864, -10.47] }
{ "step": 441, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 23.0, 8.0] , "episode_count": 356, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.778, -10.47] }
{ "step": 442, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 24.0, 8.0] , "episode_count": 359, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.371, -10.47] }
{ "step": 443, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 25.0, 8.0] , "episode_count": 360, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.786, -10.47] }
{ "step": 444, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 26.0, 8.0] , "episode_count": 360, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.714, -10.47] }
{ "step": 445, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 27.0, 8.0] , "episode_count": 360, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.646, -10.47] }
{ "step": 446, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 28.0, 8.0] , "episode_count": 362, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.302, -10.47] }
{ "step": 447, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 29.0, 8.0] , "episode_count": 362, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.254, -10.47] }
{ "step": 448, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 30.0, 8.0] , "episode_count": 362, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.209, -10.47] }
{ "step": 449, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 31.0, 8.0] , "episode_count": 363, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.166, -10.47] }
{ "step": 450, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 32.0, 8.0] , "episode_count": 363, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.127, -10.47] }
{"total_number_of_episodes": 366, "number_of_timesteps": 42884, "per_episode_reward": -240.85, "episode_reward_trend_value": -0.3530201492785191, "biggest_recent_change": 10.566225752069442},
{ "step": 451, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 33.0, 8.0] , "episode_count": 366, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -8.85, -10.47] }
{ "step": 452, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 34.0, 8.0] , "episode_count": 366, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -8.822, -10.47] }
{ "step": 453, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 35.0, 8.0] , "episode_count": 367, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.135, -10.47] }
{ "step": 454, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 36.0, 8.0] , "episode_count": 369, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.1, -10.47] }
{ "step": 455, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 37.0, 8.0] , "episode_count": 369, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.068, -10.47] }
{ "step": 456, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 38.0, 8.0] , "episode_count": 370, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.349, -10.47] }
{ "step": 457, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 39.0, 8.0] , "episode_count": 370, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.312, -10.47] }
{ "step": 458, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 40.0, 8.0] , "episode_count": 370, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.277, -10.47] }
{ "step": 459, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 41.0, 8.0] , "episode_count": 370, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.243, -10.47] }
{ "step": 460, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 42.0, 8.0] , "episode_count": 372, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.493, -10.47] }
{ "step": 461, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 43.0, 8.0] , "episode_count": 372, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.732, -10.47] }
{ "step": 462, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 44.0, 8.0] , "episode_count": 372, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.69, -10.47] }
{ "step": 463, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 45.0, 8.0] , "episode_count": 375, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.651, -10.47] }
{ "step": 464, "visits": [3.0, 319.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 375, "q_vals": [-10.888, -9.569, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 465, "visits": [3.0, 320.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 375, "q_vals": [-10.888, -9.564, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{"total_number_of_episodes": 377, "number_of_timesteps": 44339, "per_episode_reward": -252.08, "episode_reward_trend_value": -0.5374415719979571, "biggest_recent_change": 11.23045810504081},
{ "step": 466, "visits": [3.0, 321.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 377, "q_vals": [-10.888, -9.534, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 467, "visits": [3.0, 322.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 377, "q_vals": [-10.888, -9.529, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 468, "visits": [3.0, 323.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 377, "q_vals": [-10.888, -9.5, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 469, "visits": [3.0, 324.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 378, "q_vals": [-10.888, -9.495, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 470, "visits": [3.0, 325.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 378, "q_vals": [-10.888, -9.526, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 471, "visits": [3.0, 326.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 380, "q_vals": [-10.888, -9.497, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 472, "visits": [3.0, 327.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 381, "q_vals": [-10.888, -9.492, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 473, "visits": [3.0, 328.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 382, "q_vals": [-10.888, -9.463, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 474, "visits": [3.0, 329.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 383, "q_vals": [-10.888, -9.459, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 475, "visits": [3.0, 330.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 383, "q_vals": [-10.888, -9.454, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 476, "visits": [3.0, 331.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 384, "q_vals": [-10.888, -9.449, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 477, "visits": [3.0, 332.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 385, "q_vals": [-10.888, -9.444, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 478, "visits": [3.0, 333.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 386, "q_vals": [-10.888, -9.44, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{"total_number_of_episodes": 387, "number_of_timesteps": 45564, "per_episode_reward": -259.08, "episode_reward_trend_value": -0.6008271400389147, "biggest_recent_change": 11.23045810504081},
{ "step": 479, "visits": [3.0, 334.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 387, "q_vals": [-10.888, -9.435, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 480, "visits": [3.0, 335.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 387, "q_vals": [-10.888, -9.426, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 481, "visits": [3.0, 336.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 387, "q_vals": [-10.888, -9.422, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 482, "visits": [3.0, 337.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 387, "q_vals": [-10.888, -9.417, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 483, "visits": [3.0, 338.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 389, "q_vals": [-10.888, -9.448, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 484, "visits": [3.0, 339.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 390, "q_vals": [-10.888, -9.443, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 485, "visits": [3.0, 340.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 392, "q_vals": [-10.888, -9.439, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 486, "visits": [3.0, 341.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 392, "q_vals": [-10.888, -9.434, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 487, "visits": [3.0, 342.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 392, "q_vals": [-10.888, -9.465, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 488, "visits": [3.0, 343.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 393, "q_vals": [-10.888, -9.46, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 489, "visits": [3.0, 344.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 394, "q_vals": [-10.888, -9.49, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 490, "visits": [3.0, 345.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 394, "q_vals": [-10.888, -9.52, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 491, "visits": [3.0, 346.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 395, "q_vals": [-10.888, -9.492, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 492, "visits": [3.0, 347.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 395, "q_vals": [-10.888, -9.488, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 493, "visits": [3.0, 348.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 396, "q_vals": [-10.888, -9.483, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{"total_number_of_episodes": 397, "number_of_timesteps": 46845, "per_episode_reward": -263.05, "episode_reward_trend_value": -0.5631512404464404, "biggest_recent_change": 11.23045810504081},
{ "step": 494, "visits": [3.0, 349.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 397, "q_vals": [-10.888, -9.512, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 495, "visits": [3.0, 350.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 397, "q_vals": [-10.888, -9.508, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 496, "visits": [3.0, 351.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 398, "q_vals": [-10.888, -9.503, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 497, "visits": [3.0, 352.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 399, "q_vals": [-10.888, -9.499, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 498, "visits": [3.0, 353.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 400, "q_vals": [-10.888, -9.494, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 499, "visits": [3.0, 354.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 400, "q_vals": [-10.888, -9.523, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 500, "visits": [3.0, 355.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 401, "q_vals": [-10.888, -9.519, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 501, "visits": [3.0, 356.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 402, "q_vals": [-10.888, -9.492, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 502, "visits": [3.0, 357.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 404, "q_vals": [-10.888, -9.487, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 503, "visits": [3.0, 358.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 404, "q_vals": [-10.888, -9.483, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 504, "visits": [3.0, 359.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 405, "q_vals": [-10.888, -9.479, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 505, "visits": [3.0, 360.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 405, "q_vals": [-10.888, -9.452, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 506, "visits": [3.0, 361.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 405, "q_vals": [-10.888, -9.448, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{"total_number_of_episodes": 407, "number_of_timesteps": 48263, "per_episode_reward": -263.96, "episode_reward_trend_value": -0.5411317118044002, "biggest_recent_change": 11.23045810504081},
{ "step": 507, "visits": [3.0, 362.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 407, "q_vals": [-10.888, -9.476, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 508, "visits": [3.0, 363.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 408, "q_vals": [-10.888, -9.472, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 509, "visits": [3.0, 364.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 409, "q_vals": [-10.888, -9.5, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 510, "visits": [3.0, 365.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 409, "q_vals": [-10.888, -9.496, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 511, "visits": [3.0, 366.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 409, "q_vals": [-10.888, -9.492, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 512, "visits": [3.0, 367.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 409, "q_vals": [-10.888, -9.487, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 513, "visits": [3.0, 368.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 409, "q_vals": [-10.888, -9.483, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 514, "visits": [3.0, 369.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 409, "q_vals": [-10.888, -9.479, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 515, "visits": [3.0, 370.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 410, "q_vals": [-10.888, -9.474, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 516, "visits": [3.0, 371.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 412, "q_vals": [-10.888, -9.449, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 517, "visits": [3.0, 372.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 414, "q_vals": [-10.888, -9.445, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 518, "visits": [3.0, 373.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 416, "q_vals": [-10.888, -9.441, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 519, "visits": [3.0, 374.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 416, "q_vals": [-10.888, -9.436, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{"total_number_of_episodes": 417, "number_of_timesteps": 49586, "per_episode_reward": -268.73, "episode_reward_trend_value": -0.5617881838876233, "biggest_recent_change": 11.23045810504081},
{ "step": 520, "visits": [3.0, 375.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 417, "q_vals": [-10.888, -9.432, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 521, "visits": [3.0, 376.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 417, "q_vals": [-10.888, -9.428, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 522, "visits": [3.0, 377.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 418, "q_vals": [-10.888, -9.456, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 523, "visits": [3.0, 378.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 419, "q_vals": [-10.888, -9.451, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 524, "visits": [3.0, 379.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 419, "q_vals": [-10.888, -9.447, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 525, "visits": [3.0, 380.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 419, "q_vals": [-10.888, -9.475, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 526, "visits": [3.0, 381.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 419, "q_vals": [-10.888, -9.47, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 527, "visits": [3.0, 382.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 421, "q_vals": [-10.888, -9.466, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 528, "visits": [3.0, 383.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 422, "q_vals": [-10.888, -9.462, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 529, "visits": [3.0, 384.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 422, "q_vals": [-10.888, -9.458, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 530, "visits": [3.0, 385.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 422, "q_vals": [-10.888, -9.434, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 531, "visits": [3.0, 386.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 426, "q_vals": [-10.888, -9.43, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 532, "visits": [3.0, 387.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 426, "q_vals": [-10.888, -9.426, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 533, "visits": [3.0, 388.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 426, "q_vals": [-10.888, -9.422, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{"total_number_of_episodes": 427, "number_of_timesteps": 50904, "per_episode_reward": -275.0, "episode_reward_trend_value": -0.5882976565610205, "biggest_recent_change": 11.23045810504081},
{ "step": 534, "visits": [3.0, 389.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 427, "q_vals": [-10.888, -9.448, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 535, "visits": [3.0, 390.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 427, "q_vals": [-10.888, -9.475, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 536, "visits": [3.0, 391.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 428, "q_vals": [-10.888, -9.471, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 537, "visits": [3.0, 392.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 429, "q_vals": [-10.888, -9.467, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 538, "visits": [3.0, 393.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 430, "q_vals": [-10.888, -9.463, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 539, "visits": [3.0, 394.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 431, "q_vals": [-10.888, -9.459, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 540, "visits": [3.0, 395.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 432, "q_vals": [-10.888, -9.455, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 541, "visits": [3.0, 396.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 433, "q_vals": [-10.888, -9.451, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 542, "visits": [3.0, 397.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 433, "q_vals": [-10.888, -9.447, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 543, "visits": [3.0, 398.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 434, "q_vals": [-10.888, -9.443, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 544, "visits": [3.0, 399.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 434, "q_vals": [-10.888, -9.419, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 545, "visits": [3.0, 400.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 435, "q_vals": [-10.888, -9.416, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{"total_number_of_episodes": 437, "number_of_timesteps": 52137, "per_episode_reward": -284.75, "episode_reward_trend_value": -0.6548545631521999, "biggest_recent_change": 11.23045810504081},
{ "step": 546, "visits": [3.0, 401.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 437, "q_vals": [-10.888, -9.412, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 547, "visits": [3.0, 402.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 439, "q_vals": [-10.888, -9.408, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 548, "visits": [3.0, 403.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 439, "q_vals": [-10.888, -9.404, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 549, "visits": [3.0, 404.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 441, "q_vals": [-10.888, -9.43, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 550, "visits": [3.0, 405.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 442, "q_vals": [-10.888, -9.426, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 551, "visits": [3.0, 406.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 442, "q_vals": [-10.888, -9.452, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 552, "visits": [3.0, 407.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 443, "q_vals": [-10.888, -9.448, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 553, "visits": [3.0, 408.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 443, "q_vals": [-10.888, -9.444, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 554, "visits": [3.0, 409.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 443, "q_vals": [-10.888, -9.44, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 555, "visits": [3.0, 410.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 444, "q_vals": [-10.888, -9.417, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 556, "visits": [3.0, 411.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 444, "q_vals": [-10.888, -9.414, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 557, "visits": [3.0, 412.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 446, "q_vals": [-10.888, -9.41, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{"total_number_of_episodes": 447, "number_of_timesteps": 53164, "per_episode_reward": -289.92, "episode_reward_trend_value": -0.6626512595465022, "biggest_recent_change": 11.23045810504081},
{ "step": 558, "visits": [3.0, 413.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 447, "q_vals": [-10.888, -9.406, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 559, "visits": [3.0, 414.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 447, "q_vals": [-10.888, -9.383, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 560, "visits": [3.0, 415.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 450, "q_vals": [-10.888, -9.38, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 561, "visits": [3.0, 416.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 450, "q_vals": [-10.888, -9.405, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 562, "visits": [3.0, 417.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 450, "q_vals": [-10.888, -9.401, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 563, "visits": [3.0, 418.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 452, "q_vals": [-10.888, -9.398, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 564, "visits": [3.0, 419.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 452, "q_vals": [-10.888, -9.393, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 565, "visits": [3.0, 420.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 454, "q_vals": [-10.888, -9.39, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
[3.0, 421.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0]  episode_count: 455 q_vals: [-10.888, -9.386, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47]
{ "step": 567, "visits": [3.0, 422.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 456, "q_vals": [-10.888, -9.383, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{"total_number_of_episodes": 457, "number_of_timesteps": 54265, "per_episode_reward": -298.02, "episode_reward_trend_value": -0.6352244081529158, "biggest_recent_change": 11.23045810504081},
{ "step": 568, "visits": [3.0, 423.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 457, "q_vals": [-10.888, -9.389, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 569, "visits": [3.0, 424.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 457, "q_vals": [-10.888, -9.385, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 570, "visits": [3.0, 425.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 457, "q_vals": [-10.888, -9.382, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 571, "visits": [3.0, 426.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 457, "q_vals": [-10.888, -9.378, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 572, "visits": [3.0, 427.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 457, "q_vals": [-10.888, -9.375, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 573, "visits": [3.0, 428.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 461, "q_vals": [-10.888, -9.371, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 574, "visits": [3.0, 429.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 463, "q_vals": [-10.888, -9.396, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 575, "visits": [3.0, 430.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 464, "q_vals": [-10.888, -9.42, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 576, "visits": [3.0, 431.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 465, "q_vals": [-10.888, -9.444, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 577, "visits": [3.0, 432.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 465, "q_vals": [-10.888, -9.44, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 578, "visits": [3.0, 433.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 465, "q_vals": [-10.888, -9.464, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 579, "visits": [3.0, 434.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 465, "q_vals": [-10.888, -9.46, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 580, "visits": [3.0, 435.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 466, "q_vals": [-10.888, -9.484, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{"total_number_of_episodes": 467, "number_of_timesteps": 55421, "per_episode_reward": -306.95, "episode_reward_trend_value": -0.6097513926433856, "biggest_recent_change": 9.750042634499493},
{ "step": 581, "visits": [3.0, 436.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 467, "q_vals": [-10.888, -9.508, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 582, "visits": [3.0, 437.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 470, "q_vals": [-10.888, -9.504, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 583, "visits": [3.0, 438.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 470, "q_vals": [-10.888, -9.527, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 584, "visits": [3.0, 439.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 471, "q_vals": [-10.888, -9.524, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 585, "visits": [3.0, 440.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 472, "q_vals": [-10.888, -9.547, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 586, "visits": [3.0, 441.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 473, "q_vals": [-10.888, -9.543, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 587, "visits": [3.0, 442.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 473, "q_vals": [-10.888, -9.539, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 588, "visits": [3.0, 443.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 473, "q_vals": [-10.888, -9.536, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 589, "visits": [3.0, 444.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 473, "q_vals": [-10.888, -9.532, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 590, "visits": [3.0, 445.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 475, "q_vals": [-10.888, -9.555, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 591, "visits": [4.0, 445.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 475, "q_vals": [-10.142, -9.555, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{"total_number_of_episodes": 479, "number_of_timesteps": 56645, "per_episode_reward": -320.62, "episode_reward_trend_value": -0.6837748793335113, "biggest_recent_change": 13.670675496795866},
{ "step": 592, "visits": [5.0, 445.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 479, "q_vals": [-12.064, -9.555, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 593, "visits": [5.0, 446.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 479, "q_vals": [-12.064, -9.551, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 594, "visits": [5.0, 447.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 479, "q_vals": [-12.064, -9.548, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 595, "visits": [5.0, 448.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 481, "q_vals": [-12.064, -9.544, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 596, "visits": [5.0, 449.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 481, "q_vals": [-12.064, -9.54, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 597, "visits": [5.0, 450.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 482, "q_vals": [-12.064, -9.537, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
[-12.064, -9.533, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47]
{ "step": 599, "visits": [5.0, 452.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 483, "q_vals": [-12.064, -9.529, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 600, "visits": [5.0, 453.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 484, "q_vals": [-12.064, -9.552, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 601, "visits": [5.0, 454.0, 22.0, 2.0, 11.0, 30.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 484, "q_vals": [-12.064, -9.574, -10.302, -13.827, -10.288, -9.907, -13.827, -10.075, -9.87, -10.47] }
{ "step": 602, "visits": [5.0, 454.0, 22.0, 2.0, 11.0, 31.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 486, "q_vals": [-12.064, -9.574, -10.302, -13.827, -10.288, -9.842, -13.827, -10.075, -9.87, -10.47] }
{ "step": 603, "visits": [5.0, 454.0, 22.0, 2.0, 11.0, 32.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 487, "q_vals": [-12.064, -9.574, -10.302, -13.827, -10.288, -9.781, -13.827, -10.075, -9.87, -10.47] }
{ "step": 604, "visits": [5.0, 454.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 488, "q_vals": [-12.064, -9.574, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 605, "visits": [5.0, 455.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 488, "q_vals": [-12.064, -9.571, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{"total_number_of_episodes": 490, "number_of_timesteps": 57926, "per_episode_reward": -325.39, "episode_reward_trend_value": -0.6926971417670751, "biggest_recent_change": 13.670675496795866},
{ "step": 606, "visits": [5.0, 456.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 490, "q_vals": [-12.064, -9.567, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 607, "visits": [5.0, 457.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 491, "q_vals": [-12.064, -9.589, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 608, "visits": [5.0, 458.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 491, "q_vals": [-12.064, -9.586, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 609, "visits": [5.0, 459.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 492, "q_vals": [-12.064, -9.582, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 610, "visits": [5.0, 460.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 492, "q_vals": [-12.064, -9.604, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 611, "visits": [5.0, 461.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 493, "q_vals": [-12.064, -9.6, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 612, "visits": [5.0, 462.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 493, "q_vals": [-12.064, -9.597, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 613, "visits": [5.0, 463.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 494, "q_vals": [-12.064, -9.576, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 614, "visits": [5.0, 464.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 495, "q_vals": [-12.064, -9.572, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 615, "visits": [5.0, 465.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 495, "q_vals": [-12.064, -9.569, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 616, "visits": [5.0, 466.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 496, "q_vals": [-12.064, -9.565, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 617, "visits": [5.0, 467.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 496, "q_vals": [-12.064, -9.562, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 618, "visits": [5.0, 468.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 497, "q_vals": [-12.064, -9.583, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 619, "visits": [5.0, 469.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 498, "q_vals": [-12.064, -9.58, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 620, "visits": [5.0, 470.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 499, "q_vals": [-12.064, -9.576, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{"total_number_of_episodes": 500, "number_of_timesteps": 59103, "per_episode_reward": -328.02, "episode_reward_trend_value": -0.711842102118654, "biggest_recent_change": 13.670675496795866},
{ "step": 621, "visits": [5.0, 471.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 500, "q_vals": [-12.064, -9.573, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 622, "visits": [5.0, 472.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 502, "q_vals": [-12.064, -9.569, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 623, "visits": [5.0, 473.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 503, "q_vals": [-12.064, -9.566, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 624, "visits": [5.0, 474.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 503, "q_vals": [-12.064, -9.562, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 625, "visits": [5.0, 475.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 503, "q_vals": [-12.064, -9.559, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 626, "visits": [5.0, 476.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 504, "q_vals": [-12.064, -9.58, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 627, "visits": [5.0, 477.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 506, "q_vals": [-12.064, -9.56, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 628, "visits": [5.0, 478.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 506, "q_vals": [-12.064, -9.581, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 629, "visits": [5.0, 479.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 506, "q_vals": [-12.064, -9.603, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{ "step": 630, "visits": [5.0, 480.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 46.0, 8.0] , "episode_count": 507, "q_vals": [-12.064, -9.624, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.87, -10.47] }
{"total_number_of_episodes": 510, "number_of_timesteps": 60391, "per_episode_reward": -334.29, "episode_reward_trend_value": -0.7284623543154187, "biggest_recent_change": 13.670675496795866},
[5.0, 480.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 47.0, 8.0]  episode_count: 510 q_vals: [-12.064, -9.624, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.66, -10.47]
{ "step": 632, "visits": [5.0, 480.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 48.0, 8.0] , "episode_count": 510, "q_vals": [-12.064, -9.624, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.624, -10.47] }
{ "step": 633, "visits": [5.0, 480.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 49.0, 8.0] , "episode_count": 511, "q_vals": [-12.064, -9.624, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -9.83, -10.47] }
{ "step": 634, "visits": [5.0, 480.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 50.0, 8.0] , "episode_count": 512, "q_vals": [-12.064, -9.624, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -10.029, -10.47] }
{ "step": 635, "visits": [5.0, 481.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 50.0, 8.0] , "episode_count": 514, "q_vals": [-12.064, -9.62, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -10.029, -10.47] }
{ "step": 636, "visits": [5.0, 482.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 50.0, 8.0] , "episode_count": 514, "q_vals": [-12.064, -9.609, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -10.029, -10.47] }
{ "step": 637, "visits": [5.0, 483.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 50.0, 8.0] , "episode_count": 515, "q_vals": [-12.064, -9.63, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -10.029, -10.47] }
{ "step": 638, "visits": [5.0, 484.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 50.0, 8.0] , "episode_count": 515, "q_vals": [-12.064, -9.626, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -10.029, -10.47] }
{ "step": 639, "visits": [5.0, 485.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 50.0, 8.0] , "episode_count": 516, "q_vals": [-12.064, -9.623, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -10.029, -10.47] }
{ "step": 640, "visits": [5.0, 486.0, 22.0, 2.0, 11.0, 33.0, 2.0, 21.0, 50.0, 8.0] , "episode_count": 516, "q_vals": [-12.064, -9.643, -10.302, -13.827, -10.288, -10.083, -13.827, -10.075, -10.029, -10.47] }
{ "step": 641, "visits": [5.0, 486.0, 22.0, 2.0, 11.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 518, "q_vals": [-12.064, -9.643, -10.302, -13.827, -10.288, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 642, "visits": [5.0, 486.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 519, "q_vals": [-12.064, -9.643, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{"total_number_of_episodes": 520, "number_of_timesteps": 61427, "per_episode_reward": -342.03, "episode_reward_trend_value": -0.7447384590285828, "biggest_recent_change": 13.670675496795866},
{ "step": 643, "visits": [5.0, 487.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 520, "q_vals": [-12.064, -9.664, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 644, "visits": [5.0, 488.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 520, "q_vals": [-12.064, -9.661, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 645, "visits": [5.0, 489.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 520, "q_vals": [-12.064, -9.657, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 646, "visits": [5.0, 490.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 521, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 647, "visits": [5.0, 491.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 523, "q_vals": [-12.064, -9.658, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 648, "visits": [5.0, 492.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 524, "q_vals": [-12.064, -9.654, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 649, "visits": [5.0, 493.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 524, "q_vals": [-12.064, -9.651, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 650, "visits": [5.0, 494.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 524, "q_vals": [-12.064, -9.647, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 651, "visits": [5.0, 495.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 524, "q_vals": [-12.064, -9.644, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 652, "visits": [5.0, 496.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 524, "q_vals": [-12.064, -9.64, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 653, "visits": [5.0, 497.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 525, "q_vals": [-12.064, -9.621, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 654, "visits": [5.0, 498.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 527, "q_vals": [-12.064, -9.617, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 655, "visits": [5.0, 499.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 529, "q_vals": [-12.064, -9.598, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 656, "visits": [5.0, 500.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 529, "q_vals": [-12.064, -9.595, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{"total_number_of_episodes": 530, "number_of_timesteps": 62704, "per_episode_reward": -351.11, "episode_reward_trend_value": -0.7373170998314391, "biggest_recent_change": 13.670675496795866},
{ "step": 657, "visits": [5.0, 501.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 530, "q_vals": [-12.064, -9.615, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 658, "visits": [5.0, 502.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 531, "q_vals": [-12.064, -9.635, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 659, "visits": [5.0, 503.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 532, "q_vals": [-12.064, -9.632, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 660, "visits": [5.0, 504.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 533, "q_vals": [-12.064, -9.628, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 661, "visits": [5.0, 505.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 533, "q_vals": [-12.064, -9.625, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 662, "visits": [5.0, 506.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 533, "q_vals": [-12.064, -9.621, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 663, "visits": [5.0, 507.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 533, "q_vals": [-12.064, -9.641, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 664, "visits": [5.0, 508.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 534, "q_vals": [-12.064, -9.638, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 665, "visits": [5.0, 509.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 534, "q_vals": [-12.064, -9.635, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 666, "visits": [5.0, 510.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 534, "q_vals": [-12.064, -9.631, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 667, "visits": [5.0, 511.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 534, "q_vals": [-12.064, -9.651, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 668, "visits": [5.0, 512.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 535, "q_vals": [-12.064, -9.648, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 669, "visits": [5.0, 513.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 535, "q_vals": [-12.064, -9.629, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 670, "visits": [5.0, 514.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 538, "q_vals": [-12.064, -9.648, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 671, "visits": [5.0, 515.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 539, "q_vals": [-12.064, -9.668, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 672, "visits": [5.0, 516.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 539, "q_vals": [-12.064, -9.665, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{"total_number_of_episodes": 540, "number_of_timesteps": 64158, "per_episode_reward": -355.79, "episode_reward_trend_value": -0.7319401408570122, "biggest_recent_change": 13.670675496795866},
{ "step": 673, "visits": [5.0, 517.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 540, "q_vals": [-12.064, -9.661, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 674, "visits": [5.0, 518.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 540, "q_vals": [-12.064, -9.643, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 675, "visits": [5.0, 519.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 541, "q_vals": [-12.064, -9.639, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 676, "visits": [5.0, 520.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 541, "q_vals": [-12.064, -9.636, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 677, "visits": [5.0, 521.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 542, "q_vals": [-12.064, -9.633, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 678, "visits": [5.0, 522.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 544, "q_vals": [-12.064, -9.629, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 679, "visits": [5.0, 523.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 545, "q_vals": [-12.064, -9.626, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 680, "visits": [5.0, 524.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 546, "q_vals": [-12.064, -9.623, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 681, "visits": [5.0, 525.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 548, "q_vals": [-12.064, -9.642, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 682, "visits": [5.0, 526.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 549, "q_vals": [-12.064, -9.639, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 683, "visits": [5.0, 527.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 549, "q_vals": [-12.064, -9.635, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 684, "visits": [5.0, 528.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 549, "q_vals": [-12.064, -9.632, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{"total_number_of_episodes": 550, "number_of_timesteps": 65476, "per_episode_reward": -361.39, "episode_reward_trend_value": -0.7041862778748762, "biggest_recent_change": 13.670675496795866},
{ "step": 685, "visits": [5.0, 529.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 550, "q_vals": [-12.064, -9.614, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 686, "visits": [5.0, 530.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 550, "q_vals": [-12.064, -9.633, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 687, "visits": [5.0, 531.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 550, "q_vals": [-12.064, -9.63, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 688, "visits": [5.0, 532.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 551, "q_vals": [-12.064, -9.612, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 689, "visits": [5.0, 533.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 551, "q_vals": [-12.064, -9.608, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 690, "visits": [5.0, 534.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 555, "q_vals": [-12.064, -9.605, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 691, "visits": [5.0, 535.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 556, "q_vals": [-12.064, -9.602, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 692, "visits": [5.0, 536.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 557, "q_vals": [-12.064, -9.599, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 693, "visits": [5.0, 537.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 557, "q_vals": [-12.064, -9.596, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 694, "visits": [5.0, 538.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 557, "q_vals": [-12.064, -9.578, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 695, "visits": [5.0, 539.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 558, "q_vals": [-12.064, -9.568, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 696, "visits": [5.0, 540.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 558, "q_vals": [-12.064, -9.564, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 697, "visits": [5.0, 541.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 558, "q_vals": [-12.064, -9.561, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{"total_number_of_episodes": 560, "number_of_timesteps": 66651, "per_episode_reward": -366.27, "episode_reward_trend_value": -0.6591234882926762, "biggest_recent_change": 13.670675496795866},
{ "step": 698, "visits": [5.0, 542.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 560, "q_vals": [-12.064, -9.558, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 699, "visits": [5.0, 543.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 562, "q_vals": [-12.064, -9.555, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 700, "visits": [5.0, 544.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 562, "q_vals": [-12.064, -9.574, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 701, "visits": [5.0, 545.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 562, "q_vals": [-12.064, -9.571, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 702, "visits": [5.0, 546.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 562, "q_vals": [-12.064, -9.568, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 703, "visits": [5.0, 547.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 563, "q_vals": [-12.064, -9.586, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 704, "visits": [5.0, 548.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 564, "q_vals": [-12.064, -9.569, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 705, "visits": [5.0, 549.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 567, "q_vals": [-12.064, -9.588, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 706, "visits": [5.0, 550.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 568, "q_vals": [-12.064, -9.57, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 707, "visits": [5.0, 551.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 568, "q_vals": [-12.064, -9.589, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{"total_number_of_episodes": 570, "number_of_timesteps": 67827, "per_episode_reward": -370.77, "episode_reward_trend_value": -0.5572009338560487, "biggest_recent_change": 9.082120306756565},
{ "step": 708, "visits": [5.0, 552.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 570, "q_vals": [-12.064, -9.586, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 709, "visits": [5.0, 553.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 570, "q_vals": [-12.064, -9.604, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 710, "visits": [5.0, 554.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 570, "q_vals": [-12.064, -9.601, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 711, "visits": [5.0, 555.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 570, "q_vals": [-12.064, -9.598, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 712, "visits": [5.0, 556.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 571, "q_vals": [-12.064, -9.616, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 713, "visits": [5.0, 557.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 571, "q_vals": [-12.064, -9.613, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 714, "visits": [5.0, 558.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 572, "q_vals": [-12.064, -9.631, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 715, "visits": [5.0, 559.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 572, "q_vals": [-12.064, -9.628, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 716, "visits": [5.0, 560.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 573, "q_vals": [-12.064, -9.625, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 717, "visits": [5.0, 561.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 575, "q_vals": [-12.064, -9.622, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 718, "visits": [5.0, 562.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 576, "q_vals": [-12.064, -9.619, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 719, "visits": [5.0, 563.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 578, "q_vals": [-12.064, -9.637, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 720, "visits": [5.0, 564.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 579, "q_vals": [-12.064, -9.634, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{"total_number_of_episodes": 580, "number_of_timesteps": 69083, "per_episode_reward": -377.47, "episode_reward_trend_value": -0.5786077634122143, "biggest_recent_change": 9.082120306756565},
{ "step": 721, "visits": [5.0, 565.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 580, "q_vals": [-12.064, -9.631, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 722, "visits": [5.0, 566.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 580, "q_vals": [-12.064, -9.628, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 723, "visits": [5.0, 567.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 580, "q_vals": [-12.064, -9.625, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 724, "visits": [5.0, 568.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 580, "q_vals": [-12.064, -9.608, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 725, "visits": [5.0, 569.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 580, "q_vals": [-12.064, -9.605, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 726, "visits": [5.0, 570.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 582, "q_vals": [-12.064, -9.602, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 727, "visits": [5.0, 571.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 584, "q_vals": [-12.064, -9.619, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 728, "visits": [5.0, 572.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 584, "q_vals": [-12.064, -9.637, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 729, "visits": [5.0, 573.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 585, "q_vals": [-12.064, -9.634, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 730, "visits": [5.0, 574.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 586, "q_vals": [-12.064, -9.652, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 731, "visits": [5.0, 575.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 586, "q_vals": [-12.064, -9.649, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 732, "visits": [5.0, 576.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 586, "q_vals": [-12.064, -9.646, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 733, "visits": [5.0, 577.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 586, "q_vals": [-12.064, -9.643, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 734, "visits": [5.0, 578.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 588, "q_vals": [-12.064, -9.66, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{ "step": 735, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 8.0] , "episode_count": 589, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.47] }
{"total_number_of_episodes": 590, "number_of_timesteps": 70210, "per_episode_reward": -384.22, "episode_reward_trend_value": -0.6243877391750863, "biggest_recent_change": 9.082120306756565},
{ "step": 736, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 9.0] , "episode_count": 590, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -9.307] }
{ "step": 737, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 10.0] , "episode_count": 590, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -9.167] }
{ "step": 738, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 11.0] , "episode_count": 593, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -9.051] }
{ "step": 739, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 12.0] , "episode_count": 594, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -8.956] }
{ "step": 740, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 13.0] , "episode_count": 594, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -8.875] }
{ "step": 741, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 14.0] , "episode_count": 596, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -8.805] }
{ "step": 742, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 15.0] , "episode_count": 597, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -8.745] }
{ "step": 743, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 16.0] , "episode_count": 597, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -8.198] }
{ "step": 744, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 17.0] , "episode_count": 597, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -8.878] }
{ "step": 745, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 18.0] , "episode_count": 599, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -8.824] }
{ "step": 746, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 19.0] , "episode_count": 599, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -8.775] }
{"total_number_of_episodes": 600, "number_of_timesteps": 71351, "per_episode_reward": -391.52, "episode_reward_trend_value": -0.6358579831544129, "biggest_recent_change": 9.082120306756565},
{ "step": 747, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 20.0] , "episode_count": 600, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -9.324] }
{ "step": 748, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 21.0] , "episode_count": 600, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -9.256] }
{ "step": 749, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 22.0] , "episode_count": 601, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -9.733] }
{ "step": 750, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 23.0] , "episode_count": 603, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -9.654] }
{ "step": 751, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 24.0] , "episode_count": 604, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -9.581] }
{ "step": 752, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 25.0] , "episode_count": 605, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -9.514] }
{ "step": 753, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 26.0] , "episode_count": 607, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -9.452] }
{ "step": 754, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 27.0] , "episode_count": 607, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -9.394] }
{ "step": 755, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 28.0] , "episode_count": 607, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -9.764] }
{ "step": 756, "visits": [5.0, 579.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 608, "q_vals": [-12.064, -9.678, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 757, "visits": [5.0, 580.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 609, "q_vals": [-12.064, -9.675, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{"total_number_of_episodes": 610, "number_of_timesteps": 72541, "per_episode_reward": -399.36, "episode_reward_trend_value": -0.6370232322917995, "biggest_recent_change": 9.082120306756565},
{ "step": 758, "visits": [5.0, 581.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 610, "q_vals": [-12.064, -9.658, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 759, "visits": [5.0, 582.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 610, "q_vals": [-12.064, -9.675, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 760, "visits": [5.0, 583.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 610, "q_vals": [-12.064, -9.692, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 761, "visits": [5.0, 584.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 612, "q_vals": [-12.064, -9.676, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 762, "visits": [5.0, 585.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 612, "q_vals": [-12.064, -9.693, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 763, "visits": [5.0, 586.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 612, "q_vals": [-12.064, -9.69, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 764, "visits": [5.0, 587.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 613, "q_vals": [-12.064, -9.687, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 765, "visits": [5.0, 588.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 614, "q_vals": [-12.064, -9.704, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 766, "visits": [5.0, 589.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 615, "q_vals": [-12.064, -9.701, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 767, "visits": [5.0, 590.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 616, "q_vals": [-12.064, -9.706, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 768, "visits": [5.0, 591.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 616, "q_vals": [-12.064, -9.703, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 769, "visits": [5.0, 592.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 617, "q_vals": [-12.064, -9.7, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 770, "visits": [5.0, 593.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 617, "q_vals": [-12.064, -9.697, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 771, "visits": [5.0, 594.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 618, "q_vals": [-12.064, -9.694, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 772, "visits": [5.0, 595.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 619, "q_vals": [-12.064, -9.711, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 773, "visits": [5.0, 596.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 619, "q_vals": [-12.064, -9.708, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{"total_number_of_episodes": 621, "number_of_timesteps": 73952, "per_episode_reward": -402.47, "episode_reward_trend_value": -0.5706725860853611, "biggest_recent_change": 7.845328868972842},
{ "step": 774, "visits": [5.0, 597.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 621, "q_vals": [-12.064, -9.725, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 775, "visits": [5.0, 598.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 29.0] , "episode_count": 621, "q_vals": [-12.064, -9.742, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.109] }
{ "step": 776, "visits": [5.0, 598.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 30.0] , "episode_count": 622, "q_vals": [-12.064, -9.742, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.035] }
{ "step": 777, "visits": [5.0, 598.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 31.0] , "episode_count": 623, "q_vals": [-12.064, -9.742, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -9.966] }
{ "step": 778, "visits": [5.0, 598.0, 22.0, 2.0, 12.0, 33.0, 2.0, 22.0, 50.0, 32.0] , "episode_count": 623, "q_vals": [-12.064, -9.742, -10.302, -13.827, -11.077, -10.083, -13.827, -10.515, -10.029, -10.272] }
{ "step": 779, "visits": [5.0, 598.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 50.0, 32.0] , "episode_count": 624, "q_vals": [-12.064, -9.742, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.029, -10.272] }
{ "step": 780, "visits": [5.0, 599.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 50.0, 32.0] , "episode_count": 624, "q_vals": [-12.064, -9.739, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.029, -10.272] }
{ "step": 781, "visits": [5.0, 600.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 50.0, 32.0] , "episode_count": 625, "q_vals": [-12.064, -9.735, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.029, -10.272] }
{ "step": 782, "visits": [5.0, 601.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 50.0, 32.0] , "episode_count": 627, "q_vals": [-12.064, -9.752, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.029, -10.272] }
{ "step": 783, "visits": [5.0, 602.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 50.0, 32.0] , "episode_count": 629, "q_vals": [-12.064, -9.749, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.029, -10.272] }
{ "step": 784, "visits": [5.0, 603.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 50.0, 32.0] , "episode_count": 629, "q_vals": [-12.064, -9.746, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.029, -10.272] }
{"total_number_of_episodes": 632, "number_of_timesteps": 75398, "per_episode_reward": -411.31, "episode_reward_trend_value": -0.6168947934818327, "biggest_recent_change": 8.839344067230286},
{ "step": 785, "visits": [5.0, 604.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 50.0, 32.0] , "episode_count": 632, "q_vals": [-12.064, -9.763, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.029, -10.272] }
{ "step": 786, "visits": [5.0, 605.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 50.0, 32.0] , "episode_count": 632, "q_vals": [-12.064, -9.76, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.029, -10.272] }
{ "step": 787, "visits": [5.0, 606.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 50.0, 32.0] , "episode_count": 633, "q_vals": [-12.064, -9.756, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.029, -10.272] }
{ "step": 788, "visits": [5.0, 607.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 50.0, 32.0] , "episode_count": 633, "q_vals": [-12.064, -9.753, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.029, -10.272] }
{ "step": 789, "visits": [5.0, 608.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 50.0, 32.0] , "episode_count": 633, "q_vals": [-12.064, -9.77, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.029, -10.272] }
{ "step": 790, "visits": [5.0, 608.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 51.0, 32.0] , "episode_count": 633, "q_vals": [-12.064, -9.77, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -9.987, -10.272] }
{ "step": 791, "visits": [5.0, 608.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 52.0, 32.0] , "episode_count": 634, "q_vals": [-12.064, -9.77, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -9.947, -10.272] }
{ "step": 792, "visits": [5.0, 608.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 53.0, 32.0] , "episode_count": 634, "q_vals": [-12.064, -9.77, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -9.908, -10.272] }
{ "step": 793, "visits": [5.0, 608.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 54.0, 32.0] , "episode_count": 636, "q_vals": [-12.064, -9.77, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -9.871, -10.272] }
{ "step": 794, "visits": [5.0, 608.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 55.0, 32.0] , "episode_count": 636, "q_vals": [-12.064, -9.77, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -9.835, -10.272] }
{ "step": 795, "visits": [5.0, 608.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 638, "q_vals": [-12.064, -9.77, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 796, "visits": [5.0, 609.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 638, "q_vals": [-12.064, -9.767, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 797, "visits": [5.0, 610.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 638, "q_vals": [-12.064, -9.764, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 798, "visits": [5.0, 611.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 640, "q_vals": [-12.064, -9.761, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 799, "visits": [5.0, 612.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 641, "q_vals": [-12.064, -9.758, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 800, "visits": [5.0, 613.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 641, "q_vals": [-12.064, -9.755, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 801, "visits": [5.0, 614.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 641, "q_vals": [-12.064, -9.752, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{"total_number_of_episodes": 645, "number_of_timesteps": 76966, "per_episode_reward": -426.21, "episode_reward_trend_value": -0.7202408230748365, "biggest_recent_change": 14.901104121624769},
{ "step": 802, "visits": [5.0, 615.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 645, "q_vals": [-12.064, -9.749, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 803, "visits": [5.0, 616.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 645, "q_vals": [-12.064, -9.746, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 804, "visits": [5.0, 617.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 646, "q_vals": [-12.064, -9.743, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 805, "visits": [5.0, 618.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 646, "q_vals": [-12.064, -9.74, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 806, "visits": [5.0, 619.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 647, "q_vals": [-12.064, -9.756, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 807, "visits": [5.0, 620.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 649, "q_vals": [-12.064, -9.753, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 808, "visits": [5.0, 621.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 651, "q_vals": [-12.064, -9.75, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 809, "visits": [5.0, 622.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 651, "q_vals": [-12.064, -9.747, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 810, "visits": [5.0, 623.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 653, "q_vals": [-12.064, -9.744, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 811, "visits": [5.0, 624.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 654, "q_vals": [-12.064, -9.741, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 812, "visits": [5.0, 625.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 654, "q_vals": [-12.064, -9.738, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{"total_number_of_episodes": 655, "number_of_timesteps": 77886, "per_episode_reward": -425.01, "episode_reward_trend_value": -0.6526019428816324, "biggest_recent_change": 14.901104121624769},
{ "step": 813, "visits": [5.0, 626.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 655, "q_vals": [-12.064, -9.735, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 814, "visits": [5.0, 627.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 655, "q_vals": [-12.064, -9.732, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 815, "visits": [5.0, 628.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 655, "q_vals": [-12.064, -9.729, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 816, "visits": [5.0, 629.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 655, "q_vals": [-12.064, -9.726, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 817, "visits": [5.0, 630.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 656, "q_vals": [-12.064, -9.723, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 818, "visits": [5.0, 631.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 658, "q_vals": [-12.064, -9.721, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 819, "visits": [5.0, 632.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 659, "q_vals": [-12.064, -9.736, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 820, "visits": [5.0, 633.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 661, "q_vals": [-12.064, -9.733, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 821, "visits": [5.0, 634.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 661, "q_vals": [-12.064, -9.749, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 822, "visits": [5.0, 635.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 661, "q_vals": [-12.064, -9.765, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 823, "visits": [5.0, 636.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 661, "q_vals": [-12.064, -9.762, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 824, "visits": [5.0, 637.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 56.0, 32.0] , "episode_count": 662, "q_vals": [-12.064, -9.778, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.013, -10.272] }
{ "step": 825, "visits": [5.0, 637.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 662, "q_vals": [-12.064, -9.778, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 826, "visits": [5.0, 638.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 664, "q_vals": [-12.064, -9.775, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 666, "number_of_timesteps": 79229, "per_episode_reward": -432.02, "episode_reward_trend_value": -0.6805285357325248, "biggest_recent_change": 14.901104121624769},
{ "step": 827, "visits": [5.0, 639.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 666, "q_vals": [-12.064, -9.772, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 828, "visits": [5.0, 640.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 668, "q_vals": [-12.064, -9.788, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 829, "visits": [5.0, 641.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 668, "q_vals": [-12.064, -9.785, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 830, "visits": [5.0, 642.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 668, "q_vals": [-12.064, -9.8, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 831, "visits": [5.0, 643.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 668, "q_vals": [-12.064, -9.816, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 832, "visits": [5.0, 644.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 671, "q_vals": [-12.064, -9.831, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 833, "visits": [5.0, 645.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 672, "q_vals": [-12.064, -9.828, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 834, "visits": [5.0, 646.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 672, "q_vals": [-12.064, -9.825, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 835, "visits": [5.0, 647.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 672, "q_vals": [-12.064, -9.822, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 836, "visits": [5.0, 648.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 673, "q_vals": [-12.064, -9.819, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 676, "number_of_timesteps": 80278, "per_episode_reward": -437.8, "episode_reward_trend_value": -0.6703489515417769, "biggest_recent_change": 14.901104121624769},
{ "step": 837, "visits": [5.0, 649.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 676, "q_vals": [-12.064, -9.816, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 838, "visits": [5.0, 650.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 677, "q_vals": [-12.064, -9.813, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 839, "visits": [5.0, 651.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 677, "q_vals": [-12.064, -9.81, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 840, "visits": [5.0, 652.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 677, "q_vals": [-12.064, -9.807, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 841, "visits": [5.0, 653.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 677, "q_vals": [-12.064, -9.792, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 842, "visits": [5.0, 654.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 678, "q_vals": [-12.064, -9.789, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 843, "visits": [5.0, 655.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 678, "q_vals": [-12.064, -9.787, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 844, "visits": [5.0, 656.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 679, "q_vals": [-12.064, -9.772, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 845, "visits": [5.0, 657.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 682, "q_vals": [-12.064, -9.769, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 846, "visits": [5.0, 658.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 682, "q_vals": [-12.064, -9.766, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 847, "visits": [5.0, 659.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 685, "q_vals": [-12.064, -9.763, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 686, "number_of_timesteps": 81382, "per_episode_reward": -443.95, "episode_reward_trend_value": -0.6637554792653083, "biggest_recent_change": 14.901104121624769},
{ "step": 848, "visits": [5.0, 660.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 686, "q_vals": [-12.064, -9.778, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 849, "visits": [5.0, 661.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 687, "q_vals": [-12.064, -9.793, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 850, "visits": [5.0, 662.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 687, "q_vals": [-12.064, -9.79, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 851, "visits": [5.0, 663.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 689, "q_vals": [-12.064, -9.788, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 852, "visits": [5.0, 664.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 689, "q_vals": [-12.064, -9.785, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 853, "visits": [5.0, 665.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 690, "q_vals": [-12.064, -9.782, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 854, "visits": [5.0, 666.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 690, "q_vals": [-12.064, -9.779, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 855, "visits": [5.0, 667.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 690, "q_vals": [-12.064, -9.794, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 856, "visits": [5.0, 668.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 690, "q_vals": [-12.064, -9.791, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 857, "visits": [5.0, 669.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 691, "q_vals": [-12.064, -9.788, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 858, "visits": [5.0, 670.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 692, "q_vals": [-12.064, -9.786, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 859, "visits": [5.0, 671.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 693, "q_vals": [-12.064, -9.783, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 697, "number_of_timesteps": 82533, "per_episode_reward": -446.33, "episode_reward_trend_value": -0.6090694403235236, "biggest_recent_change": 14.901104121624769},
[5.0, 672.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0]  episode_count: 697 q_vals: [-12.064, -9.78, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272]
{ "step": 861, "visits": [5.0, 673.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 697, "q_vals": [-12.064, -9.777, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 862, "visits": [5.0, 674.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 697, "q_vals": [-12.064, -9.774, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 863, "visits": [5.0, 675.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 697, "q_vals": [-12.064, -9.772, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 864, "visits": [5.0, 676.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 697, "q_vals": [-12.064, -9.786, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 865, "visits": [5.0, 677.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 698, "q_vals": [-12.064, -9.784, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 866, "visits": [5.0, 678.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 698, "q_vals": [-12.064, -9.798, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 867, "visits": [5.0, 679.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 699, "q_vals": [-12.064, -9.796, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 868, "visits": [5.0, 680.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 700, "q_vals": [-12.064, -9.793, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 869, "visits": [5.0, 681.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 703, "q_vals": [-12.064, -9.79, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 870, "visits": [5.0, 682.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 703, "q_vals": [-12.064, -9.787, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 871, "visits": [5.0, 683.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 703, "q_vals": [-12.064, -9.802, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 872, "visits": [5.0, 684.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 703, "q_vals": [-12.064, -9.799, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 873, "visits": [5.0, 685.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 704, "q_vals": [-12.064, -9.796, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 874, "visits": [5.0, 686.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 704, "q_vals": [-12.064, -9.793, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 875, "visits": [5.0, 687.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 704, "q_vals": [-12.064, -9.791, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 876, "visits": [5.0, 688.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 704, "q_vals": [-12.064, -9.788, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 877, "visits": [5.0, 689.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 706, "q_vals": [-12.064, -9.785, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 707, "number_of_timesteps": 83901, "per_episode_reward": -449.09, "episode_reward_trend_value": -0.5524846503054006, "biggest_recent_change": 14.901104121624769},
{ "step": 878, "visits": [5.0, 690.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 707, "q_vals": [-12.064, -9.783, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 879, "visits": [5.0, 691.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 709, "q_vals": [-12.064, -9.78, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 880, "visits": [5.0, 692.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 709, "q_vals": [-12.064, -9.777, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 881, "visits": [5.0, 693.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 710, "q_vals": [-12.064, -9.774, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 882, "visits": [5.0, 694.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 710, "q_vals": [-12.064, -9.772, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 883, "visits": [5.0, 695.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 710, "q_vals": [-12.064, -9.769, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 884, "visits": [5.0, 696.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 710, "q_vals": [-12.064, -9.766, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 885, "visits": [5.0, 697.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 711, "q_vals": [-12.064, -9.764, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 886, "visits": [5.0, 698.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 711, "q_vals": [-12.064, -9.778, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 887, "visits": [5.0, 699.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 712, "q_vals": [-12.064, -9.775, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 888, "visits": [5.0, 700.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 715, "q_vals": [-12.064, -9.773, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 717, "number_of_timesteps": 85143, "per_episode_reward": -452.44, "episode_reward_trend_value": -0.5551645876413368, "biggest_recent_change": 14.901104121624769},
{ "step": 889, "visits": [5.0, 701.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 717, "q_vals": [-12.064, -9.77, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 890, "visits": [5.0, 702.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 718, "q_vals": [-12.064, -9.784, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 891, "visits": [5.0, 703.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 719, "q_vals": [-12.064, -9.781, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
[-12.064, -9.779, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272]
{ "step": 893, "visits": [5.0, 705.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 719, "q_vals": [-12.064, -9.776, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 894, "visits": [5.0, 706.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 719, "q_vals": [-12.064, -9.773, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 895, "visits": [5.0, 707.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 719, "q_vals": [-12.064, -9.771, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 896, "visits": [5.0, 708.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 719, "q_vals": [-12.064, -9.757, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 897, "visits": [5.0, 709.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 719, "q_vals": [-12.064, -9.754, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 898, "visits": [5.0, 710.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 721, "q_vals": [-12.064, -9.752, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 899, "visits": [5.0, 711.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 722, "q_vals": [-12.064, -9.749, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 900, "visits": [5.0, 712.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 722, "q_vals": [-12.064, -9.747, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 901, "visits": [5.0, 713.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 722, "q_vals": [-12.064, -9.744, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 902, "visits": [5.0, 714.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 723, "q_vals": [-12.064, -9.741, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 903, "visits": [5.0, 715.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 723, "q_vals": [-12.064, -9.739, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 904, "visits": [5.0, 716.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 724, "q_vals": [-12.064, -9.736, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 905, "visits": [5.0, 717.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 725, "q_vals": [-12.064, -9.75, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 906, "visits": [5.0, 718.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 725, "q_vals": [-12.064, -9.764, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 907, "visits": [5.0, 719.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 726, "q_vals": [-12.064, -9.762, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 727, "number_of_timesteps": 86691, "per_episode_reward": -455.72, "episode_reward_trend_value": -0.4933952454480612, "biggest_recent_change": 14.901104121624769},
{ "step": 908, "visits": [5.0, 720.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 727, "q_vals": [-12.064, -9.759, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 909, "visits": [5.0, 721.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 727, "q_vals": [-12.064, -9.756, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 910, "visits": [5.0, 722.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 727, "q_vals": [-12.064, -9.754, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 911, "visits": [5.0, 723.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 728, "q_vals": [-12.064, -9.751, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 912, "visits": [5.0, 724.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 729, "q_vals": [-12.064, -9.749, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 913, "visits": [5.0, 725.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 729, "q_vals": [-12.064, -9.746, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 914, "visits": [5.0, 726.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 730, "q_vals": [-12.064, -9.76, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 915, "visits": [5.0, 727.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 731, "q_vals": [-12.064, -9.757, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 916, "visits": [5.0, 728.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 733, "q_vals": [-12.064, -9.771, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 917, "visits": [5.0, 729.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 733, "q_vals": [-12.064, -9.769, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 918, "visits": [5.0, 730.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 734, "q_vals": [-12.064, -9.766, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 919, "visits": [5.0, 731.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 735, "q_vals": [-12.064, -9.763, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 920, "visits": [5.0, 732.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 736, "q_vals": [-12.064, -9.761, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 737, "number_of_timesteps": 88114, "per_episode_reward": -458.18, "episode_reward_trend_value": -0.35517153446052074, "biggest_recent_change": 7.011038954079709},
{ "step": 921, "visits": [5.0, 733.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 737, "q_vals": [-12.064, -9.775, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 922, "visits": [5.0, 734.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 738, "q_vals": [-12.064, -9.772, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 923, "visits": [5.0, 735.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 738, "q_vals": [-12.064, -9.769, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
[-12.064, -9.783, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272]
{ "step": 925, "visits": [5.0, 737.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 739, "q_vals": [-12.064, -9.78, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 926, "visits": [5.0, 738.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 739, "q_vals": [-12.064, -9.778, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 927, "visits": [5.0, 739.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 740, "q_vals": [-12.064, -9.775, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 928, "visits": [5.0, 740.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 741, "q_vals": [-12.064, -9.789, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 929, "visits": [5.0, 741.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 741, "q_vals": [-12.064, -9.786, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 930, "visits": [5.0, 742.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 741, "q_vals": [-12.064, -9.784, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 931, "visits": [5.0, 743.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 741, "q_vals": [-12.064, -9.781, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 932, "visits": [5.0, 744.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 743, "q_vals": [-12.064, -9.779, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 933, "visits": [5.0, 745.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 743, "q_vals": [-12.064, -9.792, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 934, "visits": [5.0, 746.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 745, "q_vals": [-12.064, -9.79, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 935, "visits": [5.0, 747.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 745, "q_vals": [-12.064, -9.776, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 936, "visits": [5.0, 748.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 745, "q_vals": [-12.064, -9.79, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 937, "visits": [5.0, 749.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 746, "q_vals": [-12.064, -9.803, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 938, "visits": [5.0, 750.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 746, "q_vals": [-12.064, -9.801, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 748, "number_of_timesteps": 89680, "per_episode_reward": -461.73, "episode_reward_trend_value": -0.408018222811267, "biggest_recent_change": 7.011038954079709},
{ "step": 939, "visits": [5.0, 751.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 748, "q_vals": [-12.064, -9.814, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 940, "visits": [5.0, 752.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 748, "q_vals": [-12.064, -9.827, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 941, "visits": [5.0, 753.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 750, "q_vals": [-12.064, -9.824, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 942, "visits": [5.0, 754.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 751, "q_vals": [-12.064, -9.811, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 943, "visits": [5.0, 755.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 751, "q_vals": [-12.064, -9.809, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 944, "visits": [5.0, 756.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 752, "q_vals": [-12.064, -9.806, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 945, "visits": [5.0, 757.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 752, "q_vals": [-12.064, -9.804, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 946, "visits": [5.0, 758.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 753, "q_vals": [-12.064, -9.801, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 947, "visits": [5.0, 759.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 753, "q_vals": [-12.064, -9.799, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 948, "visits": [5.0, 760.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 754, "q_vals": [-12.064, -9.796, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 949, "visits": [5.0, 761.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 756, "q_vals": [-12.064, -9.809, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 950, "visits": [5.0, 762.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 756, "q_vals": [-12.064, -9.807, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 951, "visits": [5.0, 763.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 756, "q_vals": [-12.064, -9.804, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 758, "number_of_timesteps": 91082, "per_episode_reward": -460.15, "episode_reward_trend_value": -0.3125126450123553, "biggest_recent_change": 6.156510192007715},
{ "step": 952, "visits": [5.0, 764.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 758, "q_vals": [-12.064, -9.802, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 953, "visits": [5.0, 765.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 758, "q_vals": [-12.064, -9.799, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 954, "visits": [5.0, 766.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 759, "q_vals": [-12.064, -9.797, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 955, "visits": [5.0, 767.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 759, "q_vals": [-12.064, -9.784, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 956, "visits": [5.0, 768.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 760, "q_vals": [-12.064, -9.782, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
[-12.064, -9.795, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272]
{ "step": 958, "visits": [5.0, 770.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 761, "q_vals": [-12.064, -9.792, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 959, "visits": [5.0, 771.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 761, "q_vals": [-12.064, -9.79, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 960, "visits": [5.0, 772.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 761, "q_vals": [-12.064, -9.787, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 961, "visits": [5.0, 773.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 763, "q_vals": [-12.064, -9.785, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 962, "visits": [5.0, 774.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 764, "q_vals": [-12.064, -9.783, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 963, "visits": [5.0, 775.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 764, "q_vals": [-12.064, -9.78, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 964, "visits": [5.0, 776.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 766, "q_vals": [-12.064, -9.793, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 965, "visits": [5.0, 777.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 767, "q_vals": [-12.064, -9.79, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 769, "number_of_timesteps": 92776, "per_episode_reward": -461.7, "episode_reward_trend_value": -0.2656082257121492, "biggest_recent_change": 6.156510192007715},
{ "step": 966, "visits": [5.0, 778.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 769, "q_vals": [-12.064, -9.803, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 967, "visits": [5.0, 779.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 770, "q_vals": [-12.064, -9.816, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 968, "visits": [5.0, 780.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 771, "q_vals": [-12.064, -9.829, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 969, "visits": [5.0, 781.0, 22.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 771, "q_vals": [-12.064, -9.842, -10.302, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 970, "visits": [5.0, 781.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 772, "q_vals": [-12.064, -9.842, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 971, "visits": [5.0, 782.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 773, "q_vals": [-12.064, -9.839, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 972, "visits": [5.0, 783.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 774, "q_vals": [-12.064, -9.837, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 973, "visits": [5.0, 784.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 776, "q_vals": [-12.064, -9.849, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 974, "visits": [5.0, 785.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 776, "q_vals": [-12.064, -9.847, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 975, "visits": [5.0, 786.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 778, "q_vals": [-12.064, -9.844, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 780, "number_of_timesteps": 93800, "per_episode_reward": -461.56, "episode_reward_trend_value": -0.19562201645307228, "biggest_recent_change": 3.550938380963885},
{ "step": 976, "visits": [5.0, 787.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 780, "q_vals": [-12.064, -9.842, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 977, "visits": [5.0, 788.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 780, "q_vals": [-12.064, -9.839, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 978, "visits": [5.0, 789.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 780, "q_vals": [-12.064, -9.837, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 979, "visits": [5.0, 790.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 781, "q_vals": [-12.064, -9.834, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 980, "visits": [5.0, 791.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 781, "q_vals": [-12.064, -9.832, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 981, "visits": [5.0, 792.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 784, "q_vals": [-12.064, -9.83, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 982, "visits": [5.0, 793.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 784, "q_vals": [-12.064, -9.827, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 983, "visits": [5.0, 794.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 784, "q_vals": [-12.064, -9.825, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 984, "visits": [5.0, 795.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 785, "q_vals": [-12.064, -9.822, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 985, "visits": [5.0, 796.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 786, "q_vals": [-12.064, -9.82, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 986, "visits": [5.0, 797.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 786, "q_vals": [-12.064, -9.817, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 987, "visits": [5.0, 798.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 787, "q_vals": [-12.064, -9.83, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 988, "visits": [5.0, 799.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 787, "q_vals": [-12.064, -9.827, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 989, "visits": [5.0, 800.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 787, "q_vals": [-12.064, -9.825, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 990, "visits": [5.0, 801.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 788, "q_vals": [-12.064, -9.823, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 991, "visits": [5.0, 802.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 788, "q_vals": [-12.064, -9.82, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 790, "number_of_timesteps": 94883, "per_episode_reward": -464.04, "episode_reward_trend_value": -0.19671319867196138, "biggest_recent_change": 3.550938380963885},
{ "step": 992, "visits": [5.0, 803.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 790, "q_vals": [-12.064, -9.818, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 993, "visits": [5.0, 804.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 790, "q_vals": [-12.064, -9.806, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 994, "visits": [5.0, 805.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 791, "q_vals": [-12.064, -9.818, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 995, "visits": [5.0, 806.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 791, "q_vals": [-12.064, -9.816, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 996, "visits": [5.0, 807.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 792, "q_vals": [-12.064, -9.813, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 997, "visits": [5.0, 808.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 796, "q_vals": [-12.064, -9.811, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 998, "visits": [5.0, 809.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 796, "q_vals": [-12.064, -9.823, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 999, "visits": [5.0, 810.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 796, "q_vals": [-12.064, -9.821, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1000, "visits": [5.0, 811.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 796, "q_vals": [-12.064, -9.818, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1001, "visits": [5.0, 812.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 796, "q_vals": [-12.064, -9.816, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1002, "visits": [5.0, 813.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 798, "q_vals": [-12.064, -9.828, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1003, "visits": [5.0, 814.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 799, "q_vals": [-12.064, -9.826, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1004, "visits": [5.0, 815.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 799, "q_vals": [-12.064, -9.824, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 802, "number_of_timesteps": 96269, "per_episode_reward": -467.98, "episode_reward_trend_value": -0.2099531069026827, "biggest_recent_change": 3.944289508106692},
{ "step": 1005, "visits": [5.0, 816.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 802, "q_vals": [-12.064, -9.821, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1006, "visits": [5.0, 817.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 804, "q_vals": [-12.064, -9.819, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1007, "visits": [5.0, 818.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 805, "q_vals": [-12.064, -9.831, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1008, "visits": [5.0, 819.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 805, "q_vals": [-12.064, -9.819, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1009, "visits": [5.0, 820.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 805, "q_vals": [-12.064, -9.817, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1010, "visits": [5.0, 821.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 805, "q_vals": [-12.064, -9.814, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1011, "visits": [5.0, 822.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 806, "q_vals": [-12.064, -9.812, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1012, "visits": [5.0, 823.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 806, "q_vals": [-12.064, -9.81, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1013, "visits": [5.0, 824.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 806, "q_vals": [-12.064, -9.822, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1014, "visits": [5.0, 825.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 808, "q_vals": [-12.064, -9.819, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1015, "visits": [5.0, 826.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 810, "q_vals": [-12.064, -9.817, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1016, "visits": [5.0, 827.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 810, "q_vals": [-12.064, -9.829, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1017, "visits": [5.0, 828.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 811, "q_vals": [-12.064, -9.827, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 813, "number_of_timesteps": 97647, "per_episode_reward": -471.19, "episode_reward_trend_value": -0.20833404277460216, "biggest_recent_change": 3.944289508106692},
{ "step": 1018, "visits": [5.0, 829.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 813, "q_vals": [-12.064, -9.839, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1019, "visits": [5.0, 830.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 813, "q_vals": [-12.064, -9.851, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1020, "visits": [5.0, 831.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 814, "q_vals": [-12.064, -9.848, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1021, "visits": [5.0, 832.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 815, "q_vals": [-12.064, -9.846, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1022, "visits": [5.0, 833.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 815, "q_vals": [-12.064, -9.844, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1023, "visits": [5.0, 834.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 816, "q_vals": [-12.064, -9.841, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1024, "visits": [5.0, 835.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 817, "q_vals": [-12.064, -9.839, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1025, "visits": [5.0, 836.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 817, "q_vals": [-12.064, -9.851, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1026, "visits": [5.0, 837.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 817, "q_vals": [-12.064, -9.849, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1027, "visits": [5.0, 838.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 818, "q_vals": [-12.064, -9.86, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1028, "visits": [5.0, 839.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 819, "q_vals": [-12.064, -9.849, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1029, "visits": [5.0, 840.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 819, "q_vals": [-12.064, -9.846, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1030, "visits": [5.0, 841.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 821, "q_vals": [-12.064, -9.844, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1031, "visits": [5.0, 842.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 822, "q_vals": [-12.064, -9.832, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1032, "visits": [5.0, 843.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 822, "q_vals": [-12.064, -9.83, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 823, "number_of_timesteps": 98837, "per_episode_reward": -472.56, "episode_reward_trend_value": -0.18714836064577361, "biggest_recent_change": 3.944289508106692},
{ "step": 1033, "visits": [5.0, 844.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 823, "q_vals": [-12.064, -9.828, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1034, "visits": [5.0, 845.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 824, "q_vals": [-12.064, -9.839, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1035, "visits": [5.0, 846.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 824, "q_vals": [-12.064, -9.828, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1036, "visits": [5.0, 847.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 826, "q_vals": [-12.064, -9.826, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1037, "visits": [5.0, 848.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 826, "q_vals": [-12.064, -9.814, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1038, "visits": [5.0, 849.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 826, "q_vals": [-12.064, -9.812, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1039, "visits": [5.0, 850.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 827, "q_vals": [-12.064, -9.823, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1040, "visits": [5.0, 851.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 828, "q_vals": [-12.064, -9.821, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1041, "visits": [5.0, 852.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 828, "q_vals": [-12.064, -9.819, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1042, "visits": [5.0, 853.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 828, "q_vals": [-12.064, -9.831, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1043, "visits": [5.0, 854.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 828, "q_vals": [-12.064, -9.828, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1044, "visits": [5.0, 855.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 829, "q_vals": [-12.064, -9.826, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1045, "visits": [5.0, 856.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 831, "q_vals": [-12.064, -9.824, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1046, "visits": [5.0, 857.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 832, "q_vals": [-12.064, -9.822, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 833, "number_of_timesteps": 100119, "per_episode_reward": -474.42, "episode_reward_trend_value": -0.180497901907565, "biggest_recent_change": 3.944289508106692},
{ "step": 1047, "visits": [5.0, 858.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 833, "q_vals": [-12.064, -9.833, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1048, "visits": [5.0, 859.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 835, "q_vals": [-12.064, -9.831, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1049, "visits": [5.0, 860.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 836, "q_vals": [-12.064, -9.829, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1050, "visits": [5.0, 861.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 836, "q_vals": [-12.064, -9.826, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1051, "visits": [5.0, 862.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 837, "q_vals": [-12.064, -9.824, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1052, "visits": [5.0, 863.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 837, "q_vals": [-12.064, -9.813, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1053, "visits": [5.0, 864.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 837, "q_vals": [-12.064, -9.824, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1054, "visits": [5.0, 865.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 837, "q_vals": [-12.064, -9.822, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1055, "visits": [5.0, 866.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 838, "q_vals": [-12.064, -9.82, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1056, "visits": [5.0, 867.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 839, "q_vals": [-12.064, -9.818, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1057, "visits": [5.0, 868.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 840, "q_vals": [-12.064, -9.815, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1058, "visits": [5.0, 869.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 842, "q_vals": [-12.064, -9.804, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1059, "visits": [5.0, 870.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 842, "q_vals": [-12.064, -9.802, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1060, "visits": [5.0, 871.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 842, "q_vals": [-12.064, -9.8, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 844, "number_of_timesteps": 101687, "per_episode_reward": -475.18, "episode_reward_trend_value": -0.14947600743985404, "biggest_recent_change": 3.944289508106692},
{ "step": 1061, "visits": [5.0, 872.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 844, "q_vals": [-12.064, -9.798, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1062, "visits": [5.0, 873.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 845, "q_vals": [-12.064, -9.809, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1063, "visits": [5.0, 874.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 847, "q_vals": [-12.064, -9.82, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1064, "visits": [5.0, 875.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 847, "q_vals": [-12.064, -9.832, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1065, "visits": [5.0, 876.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 847, "q_vals": [-12.064, -9.83, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1066, "visits": [5.0, 877.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 849, "q_vals": [-12.064, -9.827, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1067, "visits": [5.0, 878.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 849, "q_vals": [-12.064, -9.816, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1068, "visits": [5.0, 879.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 849, "q_vals": [-12.064, -9.814, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1069, "visits": [5.0, 880.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 850, "q_vals": [-12.064, -9.812, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1070, "visits": [5.0, 881.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 852, "q_vals": [-12.064, -9.81, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1071, "visits": [5.0, 882.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 853, "q_vals": [-12.064, -9.821, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 854, "number_of_timesteps": 102762, "per_episode_reward": -474.58, "episode_reward_trend_value": -0.16043567125248426, "biggest_recent_change": 3.944289508106692},
{ "step": 1072, "visits": [5.0, 883.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 854, "q_vals": [-12.064, -9.819, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1073, "visits": [5.0, 884.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 855, "q_vals": [-12.064, -9.817, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1074, "visits": [5.0, 885.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 855, "q_vals": [-12.064, -9.814, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1075, "visits": [5.0, 886.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 856, "q_vals": [-12.064, -9.826, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1076, "visits": [5.0, 887.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 857, "q_vals": [-12.064, -9.837, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1077, "visits": [5.0, 888.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 858, "q_vals": [-12.064, -9.835, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1078, "visits": [5.0, 889.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 858, "q_vals": [-12.064, -9.832, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1079, "visits": [5.0, 890.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 859, "q_vals": [-12.064, -9.844, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1080, "visits": [5.0, 891.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 859, "q_vals": [-12.064, -9.855, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1081, "visits": [5.0, 892.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 860, "q_vals": [-12.064, -9.853, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1082, "visits": [5.0, 893.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 861, "q_vals": [-12.064, -9.864, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1083, "visits": [5.0, 894.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 862, "q_vals": [-12.064, -9.875, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1084, "visits": [5.0, 895.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 862, "q_vals": [-12.064, -9.872, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1085, "visits": [5.0, 896.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 863, "q_vals": [-12.064, -9.87, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{"total_number_of_episodes": 864, "number_of_timesteps": 104000, "per_episode_reward": -475.43, "episode_reward_trend_value": -0.15256156436244434, "biggest_recent_change": 3.944289508106692},
{ "step": 1086, "visits": [5.0, 897.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 864, "q_vals": [-12.064, -9.868, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1087, "visits": [5.0, 898.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 867, "q_vals": [-12.064, -9.879, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1088, "visits": [5.0, 899.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 867, "q_vals": [-12.064, -9.89, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1089, "visits": [5.0, 900.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 869, "q_vals": [-12.064, -9.888, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1090, "visits": [5.0, 901.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 870, "q_vals": [-12.064, -9.886, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1091, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 32.0] , "episode_count": 870, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.272] }
{ "step": 1092, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 33.0] , "episode_count": 870, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -9.961] }
{ "step": 1093, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 34.0] , "episode_count": 871, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.249] }
{ "step": 1094, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 35.0] , "episode_count": 872, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.182] }
{ "step": 1095, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 36.0] , "episode_count": 872, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.118] }
{ "step": 1096, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 37.0] , "episode_count": 873, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.058] }
{"total_number_of_episodes": 875, "number_of_timesteps": 105162, "per_episode_reward": -477.01, "episode_reward_trend_value": -0.17169661159559457, "biggest_recent_change": 3.944289508106692},
{ "step": 1097, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 38.0] , "episode_count": 875, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.002] }
{ "step": 1098, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 39.0] , "episode_count": 876, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -9.948] }
{ "step": 1099, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 40.0] , "episode_count": 878, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -9.897] }
{ "step": 1100, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 41.0] , "episode_count": 878, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -9.848] }
{ "step": 1101, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 42.0] , "episode_count": 878, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -9.802] }
{ "step": 1102, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 43.0] , "episode_count": 878, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -9.757] }
{ "step": 1103, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 44.0] , "episode_count": 878, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -9.715] }
{ "step": 1104, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 45.0] , "episode_count": 879, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -9.938] }
{ "step": 1105, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 46.0] , "episode_count": 879, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -9.894] }
{ "step": 1106, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 47.0] , "episode_count": 880, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.104] }
{ "step": 1107, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 48.0] , "episode_count": 882, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.058] }
{ "step": 1108, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 49.0] , "episode_count": 884, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.014] }
{"total_number_of_episodes": 886, "number_of_timesteps": 106515, "per_episode_reward": -477.3, "episode_reward_trend_value": -0.1473927663564224, "biggest_recent_change": 3.944289508106692},
{ "step": 1109, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 50.0] , "episode_count": 886, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -9.972] }
{ "step": 1110, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 51.0] , "episode_count": 887, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -9.931] }
{ "step": 1111, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 52.0] , "episode_count": 887, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.12] }
{ "step": 1112, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 53.0] , "episode_count": 887, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.078] }
{ "step": 1113, "visits": [5.0, 902.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 54.0] , "episode_count": 888, "q_vals": [-12.064, -9.897, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.257] }
{ "step": 1114, "visits": [5.0, 903.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 54.0] , "episode_count": 888, "q_vals": [-12.064, -9.894, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.257] }
{ "step": 1115, "visits": [5.0, 904.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 54.0] , "episode_count": 888, "q_vals": [-12.064, -9.892, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.257] }
{ "step": 1116, "visits": [5.0, 905.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 54.0] , "episode_count": 890, "q_vals": [-12.064, -9.903, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.257] }
{ "step": 1117, "visits": [5.0, 906.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 54.0] , "episode_count": 891, "q_vals": [-12.064, -9.914, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.257] }
{ "step": 1118, "visits": [5.0, 907.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 54.0] , "episode_count": 892, "q_vals": [-12.064, -9.912, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.257] }
{ "step": 1119, "visits": [5.0, 908.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 57.0, 54.0] , "episode_count": 893, "q_vals": [-12.064, -9.923, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.183, -10.257] }
{ "step": 1120, "visits": [5.0, 908.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 58.0, 54.0] , "episode_count": 893, "q_vals": [-12.064, -9.923, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.144, -10.257] }
{ "step": 1121, "visits": [5.0, 908.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 59.0, 54.0] , "episode_count": 894, "q_vals": [-12.064, -9.923, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.106, -10.257] }
{ "step": 1122, "visits": [5.0, 908.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 894, "q_vals": [-12.064, -9.923, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1123, "visits": [5.0, 909.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 894, "q_vals": [-12.064, -9.92, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1124, "visits": [5.0, 910.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 894, "q_vals": [-12.064, -9.931, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1125, "visits": [5.0, 911.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 895, "q_vals": [-12.064, -9.929, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{"total_number_of_episodes": 896, "number_of_timesteps": 107636, "per_episode_reward": -478.96, "episode_reward_trend_value": -0.1220155613953106, "biggest_recent_change": 3.2060407368841197},
{ "step": 1126, "visits": [5.0, 912.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 896, "q_vals": [-12.064, -9.927, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1127, "visits": [5.0, 913.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 898, "q_vals": [-12.064, -9.924, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1128, "visits": [5.0, 914.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 898, "q_vals": [-12.064, -9.922, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1129, "visits": [5.0, 915.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 898, "q_vals": [-12.064, -9.933, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1130, "visits": [5.0, 916.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 899, "q_vals": [-12.064, -9.931, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1131, "visits": [5.0, 917.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 900, "q_vals": [-12.064, -9.929, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1132, "visits": [5.0, 918.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 901, "q_vals": [-12.064, -9.926, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1133, "visits": [5.0, 919.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 902, "q_vals": [-12.064, -9.937, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1134, "visits": [5.0, 920.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 903, "q_vals": [-12.064, -9.935, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1135, "visits": [5.0, 921.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 904, "q_vals": [-12.064, -9.933, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1136, "visits": [5.0, 922.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 905, "q_vals": [-12.064, -9.93, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1137, "visits": [5.0, 923.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 905, "q_vals": [-12.064, -9.928, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{"total_number_of_episodes": 907, "number_of_timesteps": 109240, "per_episode_reward": -483.18, "episode_reward_trend_value": -0.13327826218197616, "biggest_recent_change": 4.219683807684021},
{ "step": 1138, "visits": [5.0, 924.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 907, "q_vals": [-12.064, -9.939, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1139, "visits": [5.0, 925.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 907, "q_vals": [-12.064, -9.949, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1140, "visits": [5.0, 926.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 907, "q_vals": [-12.064, -9.947, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1141, "visits": [5.0, 927.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 907, "q_vals": [-12.064, -9.945, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1142, "visits": [5.0, 928.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 909, "q_vals": [-12.064, -9.956, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1143, "visits": [5.0, 929.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 911, "q_vals": [-12.064, -9.953, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1144, "visits": [5.0, 930.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 912, "q_vals": [-12.064, -9.943, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1145, "visits": [5.0, 931.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 912, "q_vals": [-12.064, -9.941, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1146, "visits": [5.0, 932.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 912, "q_vals": [-12.064, -9.93, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1147, "visits": [5.0, 933.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 913, "q_vals": [-12.064, -9.928, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1148, "visits": [5.0, 934.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 913, "q_vals": [-12.064, -9.926, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1149, "visits": [5.0, 935.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 913, "q_vals": [-12.064, -9.923, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1150, "visits": [5.0, 936.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 914, "q_vals": [-12.064, -9.921, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{"total_number_of_episodes": 917, "number_of_timesteps": 110299, "per_episode_reward": -484.1, "episode_reward_trend_value": -0.12815935215917812, "biggest_recent_change": 4.219683807684021},
{ "step": 1151, "visits": [5.0, 937.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 917, "q_vals": [-12.064, -9.919, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1152, "visits": [5.0, 938.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 919, "q_vals": [-12.064, -9.917, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1153, "visits": [5.0, 939.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 919, "q_vals": [-12.064, -9.915, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1154, "visits": [5.0, 940.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 921, "q_vals": [-12.064, -9.925, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1155, "visits": [5.0, 941.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 921, "q_vals": [-12.064, -9.923, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1156, "visits": [5.0, 942.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 921, "q_vals": [-12.064, -9.921, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1157, "visits": [5.0, 943.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 922, "q_vals": [-12.064, -9.931, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1158, "visits": [5.0, 944.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 922, "q_vals": [-12.064, -9.929, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1159, "visits": [5.0, 945.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 922, "q_vals": [-12.064, -9.927, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1160, "visits": [5.0, 946.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 925, "q_vals": [-12.064, -9.925, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1161, "visits": [5.0, 947.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 925, "q_vals": [-12.064, -9.923, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1162, "visits": [5.0, 948.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 926, "q_vals": [-12.064, -9.921, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1163, "visits": [5.0, 949.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 926, "q_vals": [-12.064, -9.931, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1164, "visits": [5.0, 950.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 926, "q_vals": [-12.064, -9.929, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{"total_number_of_episodes": 927, "number_of_timesteps": 111534, "per_episode_reward": -489.67, "episode_reward_trend_value": -0.1694454134379056, "biggest_recent_change": 5.578174361392826},
{ "step": 1165, "visits": [5.0, 951.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 927, "q_vals": [-12.064, -9.927, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1166, "visits": [5.0, 952.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 927, "q_vals": [-12.064, -9.925, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1167, "visits": [5.0, 953.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 928, "q_vals": [-12.064, -9.922, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1168, "visits": [5.0, 954.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 929, "q_vals": [-12.064, -9.92, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1169, "visits": [5.0, 955.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 930, "q_vals": [-12.064, -9.931, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1170, "visits": [5.0, 956.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 930, "q_vals": [-12.064, -9.929, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1171, "visits": [5.0, 957.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 931, "q_vals": [-12.064, -9.918, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1172, "visits": [5.0, 958.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 933, "q_vals": [-12.064, -9.916, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1173, "visits": [5.0, 959.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 933, "q_vals": [-12.064, -9.914, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1174, "visits": [5.0, 960.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 934, "q_vals": [-12.064, -9.912, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1175, "visits": [5.0, 961.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 935, "q_vals": [-12.064, -9.922, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1176, "visits": [5.0, 962.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 935, "q_vals": [-12.064, -9.92, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1177, "visits": [5.0, 963.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 935, "q_vals": [-12.064, -9.918, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1178, "visits": [5.0, 964.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 935, "q_vals": [-12.064, -9.928, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1179, "visits": [5.0, 965.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 936, "q_vals": [-12.064, -9.926, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1180, "visits": [5.0, 966.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 936, "q_vals": [-12.064, -9.924, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1181, "visits": [5.0, 967.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 936, "q_vals": [-12.064, -9.934, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{"total_number_of_episodes": 937, "number_of_timesteps": 112881, "per_episode_reward": -490.64, "episode_reward_trend_value": -0.17178394173545572, "biggest_recent_change": 5.578174361392826},
{ "step": 1182, "visits": [5.0, 968.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 937, "q_vals": [-12.064, -9.932, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1183, "visits": [5.0, 969.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 939, "q_vals": [-12.064, -9.93, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1184, "visits": [5.0, 970.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 940, "q_vals": [-12.064, -9.928, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1185, "visits": [5.0, 971.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 940, "q_vals": [-12.064, -9.926, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1186, "visits": [5.0, 972.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 940, "q_vals": [-12.064, -9.924, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1187, "visits": [5.0, 973.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 942, "q_vals": [-12.064, -9.922, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1188, "visits": [5.0, 974.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 943, "q_vals": [-12.064, -9.932, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1189, "visits": [5.0, 975.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 943, "q_vals": [-12.064, -9.942, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1190, "visits": [5.0, 976.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 943, "q_vals": [-12.064, -9.94, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1191, "visits": [5.0, 977.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 944, "q_vals": [-12.064, -9.95, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1192, "visits": [5.0, 978.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 945, "q_vals": [-12.064, -9.948, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1193, "visits": [5.0, 979.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 946, "q_vals": [-12.064, -9.945, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{"total_number_of_episodes": 948, "number_of_timesteps": 114624, "per_episode_reward": -493.49, "episode_reward_trend_value": -0.21006416190493646, "biggest_recent_change": 5.578174361392826},
{ "step": 1194, "visits": [5.0, 980.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 948, "q_vals": [-12.064, -9.943, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1195, "visits": [5.0, 981.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 949, "q_vals": [-12.064, -9.933, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1196, "visits": [5.0, 982.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 952, "q_vals": [-12.064, -9.931, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1197, "visits": [5.0, 983.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 952, "q_vals": [-12.064, -9.929, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1198, "visits": [5.0, 984.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 952, "q_vals": [-12.064, -9.927, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1199, "visits": [5.0, 985.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 952, "q_vals": [-12.064, -9.937, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1200, "visits": [5.0, 986.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 952, "q_vals": [-12.064, -9.935, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1201, "visits": [5.0, 987.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 954, "q_vals": [-12.064, -9.945, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1202, "visits": [5.0, 988.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 955, "q_vals": [-12.064, -9.943, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1203, "visits": [5.0, 989.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 956, "q_vals": [-12.064, -9.953, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{"total_number_of_episodes": 958, "number_of_timesteps": 115661, "per_episode_reward": -495.08, "episode_reward_trend_value": -0.21827740080142094, "biggest_recent_change": 5.578174361392826},
{ "step": 1204, "visits": [5.0, 990.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 958, "q_vals": [-12.064, -9.951, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1205, "visits": [5.0, 991.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 958, "q_vals": [-12.064, -9.949, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1206, "visits": [5.0, 992.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 959, "q_vals": [-12.064, -9.958, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1207, "visits": [5.0, 993.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 960, "q_vals": [-12.064, -9.956, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1208, "visits": [5.0, 994.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 960, "q_vals": [-12.064, -9.954, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1209, "visits": [5.0, 995.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 962, "q_vals": [-12.064, -9.952, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1210, "visits": [5.0, 996.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 963, "q_vals": [-12.064, -9.942, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1211, "visits": [5.0, 997.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 963, "q_vals": [-12.064, -9.952, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1212, "visits": [5.0, 998.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 963, "q_vals": [-12.064, -9.95, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1213, "visits": [5.0, 999.0, 23.0, 2.0, 12.0, 34.0, 2.0, 22.0, 60.0, 54.0] , "episode_count": 964, "q_vals": [-12.064, -9.96, -10.713, -13.827, -11.077, -10.368, -13.827, -10.515, -10.267, -10.257] }
{ "step": 1214, "visits": [0.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 965, "q_vals": [0.0, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 1215, "visits": [1.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 966, "q_vals": [-8.75, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 1216, "visits": [1.0, 1000.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 967, "q_vals": [-8.75, -inf, -8.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{"total_number_of_episodes": 969, "number_of_timesteps": 116851, "per_episode_reward": -446.83, "episode_reward_trend_value": 0.3353870911765303, "biggest_recent_change": 48.2498986683413},
{ "step": 1217, "visits": [1.0, 1000.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 969, "q_vals": [-8.75, -inf, -8.75, -8.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 1218, "visits": [1.0, 1000.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 970, "q_vals": [-8.75, -inf, -8.75, -8.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 1219, "visits": [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 972, "q_vals": [-8.75, -inf, -8.75, -8.75, 0.0, -8.75, 0.0, 0.0, 0.0, 0.0] }
{ "step": 1220, "visits": [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0] , "episode_count": 973, "q_vals": [-8.75, -inf, -8.75, -8.75, 0.0, -8.75, -21.875, 0.0, 0.0, 0.0] }
{ "step": 1221, "visits": [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0] , "episode_count": 973, "q_vals": [-8.75, -inf, -8.75, -8.75, 0.0, -8.75, -21.875, 0.0, 0.0, 0.0] }
{ "step": 1222, "visits": [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0] , "episode_count": 973, "q_vals": [-8.75, -inf, -8.75, -8.75, 0.0, -8.75, -21.875, 0.0, -21.875, 0.0] }
{ "step": 1223, "visits": [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 973, "q_vals": [-8.75, -inf, -8.75, -8.75, 0.0, -8.75, -21.875, 0.0, -21.875, 0.0] }
{ "step": 1224, "visits": [1.0, 1000.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 975, "q_vals": [-8.75, -inf, -8.75, -8.75, -4.375, -8.75, -21.875, 0.0, -21.875, 0.0] }
{ "step": 1225, "visits": [1.0, 1000.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0] , "episode_count": 975, "q_vals": [-8.75, -inf, -8.75, -8.75, -4.375, -8.75, -21.875, -4.375, -21.875, 0.0] }
{ "step": 1226, "visits": [1.0, 1000.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0] , "episode_count": 975, "q_vals": [-8.75, -inf, -8.75, -8.75, -4.375, -8.75, -21.875, -4.375, -21.875, -10.938] }
{ "step": 1227, "visits": [1.0, 1000.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0] , "episode_count": 975, "q_vals": [-8.75, -inf, -8.75, -8.75, -10.208, -8.75, -21.875, -4.375, -21.875, -10.938] }
{ "step": 1228, "visits": [1.0, 1000.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 978, "q_vals": [-8.75, -inf, -8.75, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 979, "number_of_timesteps": 117872, "per_episode_reward": -448.96, "episode_reward_trend_value": 0.31489410440426835, "biggest_recent_change": 48.2498986683413},
{ "step": 1229, "visits": [1.0, 1000.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 979, "q_vals": [-8.75, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1230, "visits": [2.0, 1000.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 980, "q_vals": [-4.375, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1231, "visits": [3.0, 1000.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 980, "q_vals": [-2.917, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1232, "visits": [4.0, 1000.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 981, "q_vals": [-4.375, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1233, "visits": [5.0, 1000.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 981, "q_vals": [-5.25, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1234, "visits": [6.0, 1000.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 981, "q_vals": [-4.375, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1235, "visits": [7.0, 1000.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 982, "q_vals": [-5.0, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1236, "visits": [8.0, 1000.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 983, "q_vals": [-5.469, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1237, "visits": [9.0, 1000.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 985, "q_vals": [-7.292, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1238, "visits": [10.0, 1000.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 987, "q_vals": [-7.438, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1239, "visits": [11.0, 1000.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 988, "q_vals": [-7.557, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 989, "number_of_timesteps": 118968, "per_episode_reward": -450.83, "episode_reward_trend_value": 0.3126412124076997, "biggest_recent_change": 48.2498986683413},
{ "step": 1240, "visits": [11.0, 1000.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 989, "q_vals": [-7.557, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1241, "visits": [11.0, 1000.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 989, "q_vals": [-7.557, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1242, "visits": [12.0, 1000.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 989, "q_vals": [-7.656, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1243, "visits": [13.0, 1000.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 989, "q_vals": [-8.75, -inf, -15.312, -8.75, -10.208, -8.75, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1244, "visits": [13.0, 1000.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 989, "q_vals": [-8.75, -inf, -15.312, -8.75, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1245, "visits": [13.0, 1000.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 992, "q_vals": [-8.75, -inf, -15.312, -8.75, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1246, "visits": [13.0, 1000.0, 2.0, 4.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 993, "q_vals": [-8.75, -inf, -15.312, -6.563, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1247, "visits": [13.0, 1000.0, 2.0, 5.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 993, "q_vals": [-8.75, -inf, -15.312, -7.0, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1248, "visits": [13.0, 1000.0, 2.0, 6.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 995, "q_vals": [-8.75, -inf, -15.312, -7.292, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1249, "visits": [13.0, 1000.0, 2.0, 7.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 995, "q_vals": [-8.75, -inf, -15.312, -7.5, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
[-8.75, -inf, -15.312, -7.656, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938]
{ "step": 1251, "visits": [13.0, 1000.0, 2.0, 9.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 996, "q_vals": [-8.75, -inf, -15.312, -6.806, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1252, "visits": [13.0, 1000.0, 2.0, 10.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 998, "q_vals": [-8.75, -inf, -15.312, -7.0, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 999, "number_of_timesteps": 120268, "per_episode_reward": -453.03, "episode_reward_trend_value": 0.3350744057212713, "biggest_recent_change": 48.2498986683413},
{ "step": 1253, "visits": [13.0, 1000.0, 2.0, 11.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 999, "q_vals": [-8.75, -inf, -15.312, -8.352, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1254, "visits": [13.0, 1000.0, 2.0, 12.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 999, "q_vals": [-8.75, -inf, -15.312, -8.385, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1255, "visits": [13.0, 1000.0, 2.0, 13.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1000, "q_vals": [-8.75, -inf, -15.312, -8.413, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1256, "visits": [13.0, 1000.0, 2.0, 14.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1001, "q_vals": [-8.75, -inf, -15.312, -8.438, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1257, "visits": [13.0, 1000.0, 2.0, 15.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1002, "q_vals": [-8.75, -inf, -15.312, -8.458, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1258, "visits": [13.0, 1000.0, 2.0, 16.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1004, "q_vals": [-8.75, -inf, -15.312, -8.477, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1259, "visits": [13.0, 1000.0, 2.0, 17.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1004, "q_vals": [-8.75, -inf, -15.312, -8.493, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1260, "visits": [13.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1004, "q_vals": [-8.75, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1261, "visits": [14.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1005, "q_vals": [-8.75, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1262, "visits": [15.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1006, "q_vals": [-8.75, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1263, "visits": [16.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1007, "q_vals": [-8.75, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1264, "visits": [17.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1007, "q_vals": [-8.75, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1009, "number_of_timesteps": 121381, "per_episode_reward": -455.37, "episode_reward_trend_value": 0.3191864198246094, "biggest_recent_change": 48.2498986683413},
{ "step": 1265, "visits": [18.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1009, "q_vals": [-8.75, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1266, "visits": [19.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1010, "q_vals": [-8.289, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1267, "visits": [20.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1011, "q_vals": [-7.875, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1268, "visits": [21.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1011, "q_vals": [-7.917, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1269, "visits": [22.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1011, "q_vals": [-7.955, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1270, "visits": [23.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1011, "q_vals": [-7.609, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1271, "visits": [24.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1011, "q_vals": [-7.656, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1272, "visits": [25.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1012, "q_vals": [-7.7, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1273, "visits": [26.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1014, "q_vals": [-7.74, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1274, "visits": [27.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1014, "q_vals": [-7.778, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1275, "visits": [28.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1018, "q_vals": [-7.813, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1276, "visits": [29.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1018, "q_vals": [-7.845, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1277, "visits": [30.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1018, "q_vals": [-7.875, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1278, "visits": [31.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1018, "q_vals": [-7.903, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1279, "visits": [32.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1018, "q_vals": [-7.656, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1019, "number_of_timesteps": 122691, "per_episode_reward": -457.76, "episode_reward_trend_value": 0.35454982126887935, "biggest_recent_change": 48.2498986683413},
{ "step": 1280, "visits": [33.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1019, "q_vals": [-7.689, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1281, "visits": [34.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1019, "q_vals": [-7.721, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1282, "visits": [35.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1021, "q_vals": [-7.75, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1283, "visits": [36.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1022, "q_vals": [-7.535, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1284, "visits": [37.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1023, "q_vals": [-7.568, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1285, "visits": [38.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1023, "q_vals": [-7.599, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1286, "visits": [39.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1024, "q_vals": [-7.404, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1287, "visits": [40.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1025, "q_vals": [-7.438, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1288, "visits": [41.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1026, "q_vals": [-7.47, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1289, "visits": [42.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1026, "q_vals": [-7.292, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1290, "visits": [43.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1027, "q_vals": [-7.326, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1291, "visits": [44.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1028, "q_vals": [-7.358, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1029, "number_of_timesteps": 123969, "per_episode_reward": -458.85, "episode_reward_trend_value": 0.35321781894174303, "biggest_recent_change": 48.2498986683413},
{ "step": 1292, "visits": [45.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1029, "q_vals": [-7.389, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1293, "visits": [46.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1031, "q_vals": [-7.418, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1294, "visits": [47.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1033, "q_vals": [-7.261, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1295, "visits": [48.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1034, "q_vals": [-7.292, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1296, "visits": [49.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1034, "q_vals": [-7.589, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1297, "visits": [50.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1034, "q_vals": [-7.613, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1298, "visits": [51.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1035, "q_vals": [-7.635, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1299, "visits": [52.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1036, "q_vals": [-7.656, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1300, "visits": [53.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1036, "q_vals": [-7.677, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1301, "visits": [54.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1037, "q_vals": [-7.697, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1040, "number_of_timesteps": 125118, "per_episode_reward": -460.2, "episode_reward_trend_value": 0.3699306673561592, "biggest_recent_change": 48.2498986683413},
{ "step": 1302, "visits": [55.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1040, "q_vals": [-7.557, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1303, "visits": [56.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1041, "q_vals": [-7.578, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1304, "visits": [57.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1041, "q_vals": [-7.445, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1305, "visits": [58.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1042, "q_vals": [-7.468, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1306, "visits": [59.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1043, "q_vals": [-7.489, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1307, "visits": [60.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1043, "q_vals": [-7.729, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1308, "visits": [61.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1044, "q_vals": [-7.746, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1309, "visits": [62.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1046, "q_vals": [-7.762, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1310, "visits": [63.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1048, "q_vals": [-7.639, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1311, "visits": [64.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1048, "q_vals": [-7.656, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1312, "visits": [65.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1049, "q_vals": [-7.673, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1050, "number_of_timesteps": 126171, "per_episode_reward": -464.13, "episode_reward_trend_value": 0.34382953968428626, "biggest_recent_change": 48.2498986683413},
{ "step": 1313, "visits": [66.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1050, "q_vals": [-7.689, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1314, "visits": [67.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1050, "q_vals": [-7.575, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1315, "visits": [68.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1051, "q_vals": [-7.592, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1316, "visits": [69.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1051, "q_vals": [-7.609, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1317, "visits": [70.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1052, "q_vals": [-7.625, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1318, "visits": [71.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1053, "q_vals": [-7.641, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1319, "visits": [72.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1054, "q_vals": [-7.656, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1320, "visits": [73.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1054, "q_vals": [-7.671, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1321, "visits": [74.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1055, "q_vals": [-7.686, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1322, "visits": [75.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1057, "q_vals": [-7.7, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1323, "visits": [76.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1058, "q_vals": [-7.714, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1324, "visits": [77.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1058, "q_vals": [-7.727, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1060, "number_of_timesteps": 127233, "per_episode_reward": -464.94, "episode_reward_trend_value": -0.2012512515660856, "biggest_recent_change": 3.936542878028945},
{ "step": 1325, "visits": [78.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1060, "q_vals": [-7.74, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1326, "visits": [79.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1060, "q_vals": [-7.753, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1327, "visits": [80.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1060, "q_vals": [-7.766, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1328, "visits": [81.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1060, "q_vals": [-7.778, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1329, "visits": [82.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1062, "q_vals": [-7.95, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1330, "visits": [83.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1063, "q_vals": [-7.959, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1331, "visits": [84.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1063, "q_vals": [-7.969, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1332, "visits": [85.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1064, "q_vals": [-7.875, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1333, "visits": [86.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1065, "q_vals": [-7.783, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1334, "visits": [87.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1067, "q_vals": [-7.795, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1335, "visits": [88.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1067, "q_vals": [-7.706, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1336, "visits": [89.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1067, "q_vals": [-7.718, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1337, "visits": [90.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1068, "q_vals": [-7.632, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1338, "visits": [91.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1069, "q_vals": [-7.644, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1070, "number_of_timesteps": 128537, "per_episode_reward": -465.56, "episode_reward_trend_value": -0.18445492649628806, "biggest_recent_change": 3.936542878028945},
{ "step": 1339, "visits": [92.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1070, "q_vals": [-7.561, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1340, "visits": [93.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1070, "q_vals": [-7.715, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1341, "visits": [94.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1072, "q_vals": [-7.633, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1342, "visits": [95.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1075, "q_vals": [-7.645, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1343, "visits": [96.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1075, "q_vals": [-7.656, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1344, "visits": [97.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1076, "q_vals": [-7.668, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1345, "visits": [98.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1077, "q_vals": [-7.679, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1346, "visits": [99.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1077, "q_vals": [-7.689, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1347, "visits": [100.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1078, "q_vals": [-7.7, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1348, "visits": [101.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1079, "q_vals": [-7.71, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1349, "visits": [102.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1079, "q_vals": [-7.721, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1080, "number_of_timesteps": 129532, "per_episode_reward": -466.55, "episode_reward_trend_value": -0.17471505306433843, "biggest_recent_change": 3.936542878028945},
{ "step": 1350, "visits": [103.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1080, "q_vals": [-7.731, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1351, "visits": [104.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1080, "q_vals": [-7.74, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1352, "visits": [105.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1080, "q_vals": [-7.75, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1353, "visits": [106.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1081, "q_vals": [-7.883, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1354, "visits": [107.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1082, "q_vals": [-7.891, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1355, "visits": [108.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1082, "q_vals": [-7.899, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1356, "visits": [109.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1083, "q_vals": [-7.907, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1357, "visits": [110.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1084, "q_vals": [-7.915, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1358, "visits": [111.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1084, "q_vals": [-7.922, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1359, "visits": [112.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1084, "q_vals": [-7.93, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1360, "visits": [113.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1084, "q_vals": [-7.937, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1361, "visits": [114.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1085, "q_vals": [-7.944, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1362, "visits": [115.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1087, "q_vals": [-7.875, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1363, "visits": [116.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1088, "q_vals": [-7.883, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1364, "visits": [117.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1089, "q_vals": [-7.89, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1092, "number_of_timesteps": 131166, "per_episode_reward": -467.91, "episode_reward_trend_value": -0.1654236454198686, "biggest_recent_change": 3.936542878028945},
{ "step": 1365, "visits": [118.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1092, "q_vals": [-7.823, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1366, "visits": [119.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1092, "q_vals": [-7.831, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1367, "visits": [120.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1093, "q_vals": [-7.839, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1368, "visits": [121.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1093, "q_vals": [-7.846, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1369, "visits": [122.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1093, "q_vals": [-7.853, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1370, "visits": [123.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1094, "q_vals": [-7.861, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1371, "visits": [124.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1094, "q_vals": [-7.868, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1372, "visits": [125.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1094, "q_vals": [-7.98, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1373, "visits": [126.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1097, "q_vals": [-7.986, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1374, "visits": [127.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1099, "q_vals": [-7.992, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1375, "visits": [128.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1100, "q_vals": [-7.93, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1376, "visits": [129.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1100, "q_vals": [-7.936, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1377, "visits": [130.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1101, "q_vals": [-7.942, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1378, "visits": [131.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1101, "q_vals": [-7.948, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1379, "visits": [132.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1101, "q_vals": [-7.955, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1380, "visits": [133.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1101, "q_vals": [-7.961, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1103, "number_of_timesteps": 132394, "per_episode_reward": -468.08, "episode_reward_trend_value": -0.14125700477543748, "biggest_recent_change": 3.936542878028945},
{ "step": 1381, "visits": [134.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1103, "q_vals": [-7.901, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1382, "visits": [135.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1104, "q_vals": [-7.907, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1383, "visits": [136.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1105, "q_vals": [-7.914, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1384, "visits": [137.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1107, "q_vals": [-7.92, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1385, "visits": [138.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1107, "q_vals": [-7.862, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1386, "visits": [139.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1108, "q_vals": [-7.869, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1387, "visits": [140.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1110, "q_vals": [-7.875, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1388, "visits": [141.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1110, "q_vals": [-7.819, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1389, "visits": [142.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1111, "q_vals": [-7.826, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1390, "visits": [143.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1111, "q_vals": [-7.832, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1391, "visits": [144.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1111, "q_vals": [-7.839, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1392, "visits": [145.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1112, "q_vals": [-7.845, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1113, "number_of_timesteps": 133658, "per_episode_reward": -467.77, "episode_reward_trend_value": -0.11111987373143772, "biggest_recent_change": 3.936542878028945},
{ "step": 1393, "visits": [146.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1113, "q_vals": [-7.791, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1394, "visits": [147.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1113, "q_vals": [-7.798, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1395, "visits": [148.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1115, "q_vals": [-7.804, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1396, "visits": [149.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1116, "q_vals": [-7.752, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1397, "visits": [150.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1116, "q_vals": [-7.758, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1398, "visits": [151.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1117, "q_vals": [-7.765, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1399, "visits": [152.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1118, "q_vals": [-7.771, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1400, "visits": [153.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1119, "q_vals": [-7.864, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1401, "visits": [154.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1120, "q_vals": [-7.869, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1402, "visits": [155.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1120, "q_vals": [-7.96, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1403, "visits": [156.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1120, "q_vals": [-7.909, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1404, "visits": [157.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1122, "q_vals": [-7.914, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1124, "number_of_timesteps": 135012, "per_episode_reward": -469.08, "episode_reward_trend_value": -0.11358427275048308, "biggest_recent_change": 3.936542878028945},
{ "step": 1405, "visits": [158.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1124, "q_vals": [-7.919, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1406, "visits": [159.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1124, "q_vals": [-7.925, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1407, "visits": [160.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1124, "q_vals": [-7.875, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1408, "visits": [161.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1126, "q_vals": [-7.88, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1409, "visits": [162.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1126, "q_vals": [-7.967, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1410, "visits": [163.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1126, "q_vals": [-7.972, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1411, "visits": [164.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1126, "q_vals": [-7.976, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1412, "visits": [165.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1127, "q_vals": [-7.928, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1413, "visits": [166.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1127, "q_vals": [-8.012, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1414, "visits": [167.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1128, "q_vals": [-7.964, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1415, "visits": [168.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1129, "q_vals": [-7.969, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1416, "visits": [169.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1129, "q_vals": [-8.051, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1417, "visits": [170.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1131, "q_vals": [-8.055, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1418, "visits": [171.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1131, "q_vals": [-8.059, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1419, "visits": [172.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1133, "q_vals": [-8.012, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1134, "number_of_timesteps": 136356, "per_episode_reward": -470.71, "episode_reward_trend_value": -0.1167996522210697, "biggest_recent_change": 3.936542878028945},
{ "step": 1420, "visits": [173.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1134, "q_vals": [-8.017, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1421, "visits": [174.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1135, "q_vals": [-8.096, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1422, "visits": [175.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1135, "q_vals": [-8.1, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1423, "visits": [176.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1135, "q_vals": [-8.178, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1424, "visits": [177.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1136, "q_vals": [-8.132, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1425, "visits": [178.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1136, "q_vals": [-8.086, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1426, "visits": [179.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1138, "q_vals": [-8.09, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1427, "visits": [180.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1138, "q_vals": [-8.094, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1428, "visits": [181.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1139, "q_vals": [-8.09, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1429, "visits": [182.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1140, "q_vals": [-8.094, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1430, "visits": [183.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1140, "q_vals": [-8.098, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1431, "visits": [184.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1140, "q_vals": [-8.101, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1432, "visits": [185.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1142, "q_vals": [-8.105, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1433, "visits": [186.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1143, "q_vals": [-8.108, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1145, "number_of_timesteps": 137723, "per_episode_reward": -473.95, "episode_reward_trend_value": -0.10903374441070735, "biggest_recent_change": 3.2376111750963332},
{ "step": 1434, "visits": [187.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1145, "q_vals": [-8.112, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1435, "visits": [188.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1145, "q_vals": [-8.115, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1436, "visits": [189.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1146, "q_vals": [-8.118, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1437, "visits": [190.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1146, "q_vals": [-8.122, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1438, "visits": [191.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1148, "q_vals": [-8.079, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1439, "visits": [192.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1148, "q_vals": [-8.083, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1440, "visits": [193.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1150, "q_vals": [-8.086, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1441, "visits": [194.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1150, "q_vals": [-8.09, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1442, "visits": [195.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1151, "q_vals": [-8.093, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1443, "visits": [196.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1153, "q_vals": [-8.096, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1155, "number_of_timesteps": 138895, "per_episode_reward": -475.76, "episode_reward_trend_value": -0.12024290986106127, "biggest_recent_change": 3.2376111750963332},
{ "step": 1444, "visits": [197.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1155, "q_vals": [-8.1, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1445, "visits": [198.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1155, "q_vals": [-8.169, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1446, "visits": [199.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1155, "q_vals": [-8.172, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
[200.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0]  episode_count: 1157 q_vals: [-8.241, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938]
{ "step": 1448, "visits": [201.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1157, "q_vals": [-8.243, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1449, "visits": [202.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1158, "q_vals": [-8.246, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1450, "visits": [203.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1159, "q_vals": [-8.248, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1451, "visits": [204.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1161, "q_vals": [-8.251, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1452, "visits": [205.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1161, "q_vals": [-8.21, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1453, "visits": [206.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1163, "q_vals": [-8.213, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1454, "visits": [207.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1164, "q_vals": [-8.173, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1455, "visits": [208.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1164, "q_vals": [-8.176, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1166, "number_of_timesteps": 139981, "per_episode_reward": -475.91, "episode_reward_trend_value": -0.11494539742635967, "biggest_recent_change": 3.2376111750963332},
{ "step": 1456, "visits": [209.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1166, "q_vals": [-8.179, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1457, "visits": [210.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1168, "q_vals": [-8.244, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1458, "visits": [211.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1168, "q_vals": [-8.205, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1459, "visits": [212.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1171, "q_vals": [-8.208, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1460, "visits": [213.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1173, "q_vals": [-8.21, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1461, "visits": [214.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1173, "q_vals": [-8.172, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1462, "visits": [215.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1173, "q_vals": [-8.235, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1463, "visits": [216.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1173, "q_vals": [-8.238, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1464, "visits": [217.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1174, "q_vals": [-8.2, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1176, "number_of_timesteps": 140770, "per_episode_reward": -477.68, "episode_reward_trend_value": -0.12363560549008652, "biggest_recent_change": 3.2376111750963332},
{ "step": 1465, "visits": [218.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1176, "q_vals": [-8.263, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1466, "visits": [219.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1179, "q_vals": [-8.265, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1467, "visits": [220.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1180, "q_vals": [-8.267, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1468, "visits": [221.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1181, "q_vals": [-8.269, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1469, "visits": [222.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1182, "q_vals": [-8.271, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1470, "visits": [223.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1183, "q_vals": [-8.274, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1471, "visits": [224.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1183, "q_vals": [-8.237, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1472, "visits": [225.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1183, "q_vals": [-8.239, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1473, "visits": [226.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1184, "q_vals": [-8.241, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1474, "visits": [227.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1185, "q_vals": [-8.301, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1188, "number_of_timesteps": 141751, "per_episode_reward": -480.09, "episode_reward_trend_value": -0.13531766230149617, "biggest_recent_change": 3.2376111750963332},
{ "step": 1475, "visits": [228.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1188, "q_vals": [-8.265, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1476, "visits": [229.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1192, "q_vals": [-8.267, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1477, "visits": [230.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1193, "q_vals": [-8.231, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1478, "visits": [231.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1193, "q_vals": [-8.233, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
[-8.292, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938]
{ "step": 1480, "visits": [233.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1193, "q_vals": [-8.294, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1481, "visits": [234.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1194, "q_vals": [-8.296, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1482, "visits": [235.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1196, "q_vals": [-8.298, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1200, "number_of_timesteps": 142671, "per_episode_reward": -481.39, "episode_reward_trend_value": -0.14784326085084684, "biggest_recent_change": 3.2376111750963332},
{ "step": 1483, "visits": [236.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1200, "q_vals": [-8.3, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1484, "visits": [237.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1203, "q_vals": [-8.302, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1485, "visits": [238.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1203, "q_vals": [-8.304, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1486, "visits": [239.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1203, "q_vals": [-8.305, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1487, "visits": [240.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1203, "q_vals": [-8.307, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1488, "visits": [241.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1204, "q_vals": [-8.273, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1489, "visits": [242.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1204, "q_vals": [-8.239, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1490, "visits": [243.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1209, "q_vals": [-8.205, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1210, "number_of_timesteps": 143376, "per_episode_reward": -481.41, "episode_reward_trend_value": -0.1515766375199405, "biggest_recent_change": 3.2376111750963332},
{ "step": 1491, "visits": [244.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1210, "q_vals": [-8.207, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1492, "visits": [245.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1211, "q_vals": [-8.263, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1493, "visits": [246.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1213, "q_vals": [-8.265, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1494, "visits": [247.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1214, "q_vals": [-8.267, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1495, "visits": [248.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1214, "q_vals": [-8.322, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1496, "visits": [249.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1215, "q_vals": [-8.323, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1497, "visits": [250.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1216, "q_vals": [-8.29, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1498, "visits": [251.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1218, "q_vals": [-8.292, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1499, "visits": [252.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1219, "q_vals": [-8.294, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1220, "number_of_timesteps": 144119, "per_episode_reward": -481.43, "episode_reward_trend_value": -0.13728857078216125, "biggest_recent_change": 3.2376111750963332},
{ "step": 1500, "visits": [253.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1220, "q_vals": [-8.261, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1501, "visits": [254.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1222, "q_vals": [-8.228, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1502, "visits": [255.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1222, "q_vals": [-8.196, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1503, "visits": [256.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1224, "q_vals": [-8.164, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1504, "visits": [257.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1225, "q_vals": [-8.166, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1505, "visits": [258.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1226, "q_vals": [-8.169, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1506, "visits": [259.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1227, "q_vals": [-8.137, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1507, "visits": [260.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1229, "q_vals": [-8.139, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1230, "number_of_timesteps": 144897, "per_episode_reward": -481.52, "episode_reward_trend_value": -0.12012291703663829, "biggest_recent_change": 3.2376111750963332},
{ "step": 1508, "visits": [261.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1230, "q_vals": [-8.192, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1509, "visits": [262.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1232, "q_vals": [-8.194, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1510, "visits": [263.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1233, "q_vals": [-8.196, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
[264.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0]  episode_count: 1233 q_vals: [-8.198, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938]
{ "step": 1512, "visits": [265.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1235, "q_vals": [-8.167, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1513, "visits": [266.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1236, "q_vals": [-8.219, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1514, "visits": [267.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1238, "q_vals": [-8.221, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1515, "visits": [268.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1238, "q_vals": [-8.223, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1516, "visits": [269.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1238, "q_vals": [-8.225, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1240, "number_of_timesteps": 145655, "per_episode_reward": -480.49, "episode_reward_trend_value": -0.07271107190411562, "biggest_recent_change": 2.4158548344871633},
{ "step": 1517, "visits": [270.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1240, "q_vals": [-8.227, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1518, "visits": [271.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1243, "q_vals": [-8.229, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1519, "visits": [272.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1244, "q_vals": [-8.199, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1520, "visits": [273.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1246, "q_vals": [-8.169, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1521, "visits": [274.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1246, "q_vals": [-8.171, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1522, "visits": [275.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1247, "q_vals": [-8.173, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1523, "visits": [276.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1248, "q_vals": [-8.143, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1250, "number_of_timesteps": 146421, "per_episode_reward": -481.13, "episode_reward_trend_value": -0.059631022977680456, "biggest_recent_change": 2.4158548344871633},
{ "step": 1524, "visits": [277.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1250, "q_vals": [-8.145, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1525, "visits": [278.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1250, "q_vals": [-8.195, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1526, "visits": [279.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1252, "q_vals": [-8.244, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1527, "visits": [280.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1254, "q_vals": [-8.246, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1528, "visits": [281.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1254, "q_vals": [-8.247, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1529, "visits": [282.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1254, "q_vals": [-8.249, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1530, "visits": [283.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1257, "q_vals": [-8.251, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1531, "visits": [284.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1258, "q_vals": [-8.222, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1532, "visits": [285.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1258, "q_vals": [-8.224, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1261, "number_of_timesteps": 147304, "per_episode_reward": -482.69, "episode_reward_trend_value": -0.07530756249365267, "biggest_recent_change": 2.4158548344871633},
{ "step": 1533, "visits": [286.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1261, "q_vals": [-8.226, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1534, "visits": [287.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1261, "q_vals": [-8.227, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1535, "visits": [288.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1262, "q_vals": [-8.229, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1536, "visits": [289.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1264, "q_vals": [-8.201, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1537, "visits": [290.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1265, "q_vals": [-8.203, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1538, "visits": [291.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1266, "q_vals": [-8.174, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1539, "visits": [292.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1269, "q_vals": [-8.176, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1271, "number_of_timesteps": 148041, "per_episode_reward": -482.11, "episode_reward_trend_value": -0.04926064005714466, "biggest_recent_change": 2.4158548344871633},
{ "step": 1540, "visits": [293.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1271, "q_vals": [-8.178, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1541, "visits": [294.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1271, "q_vals": [-8.18, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
[-8.153, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938]
{ "step": 1543, "visits": [296.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1274, "q_vals": [-8.125, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1544, "visits": [297.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1276, "q_vals": [-8.127, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1545, "visits": [298.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1276, "q_vals": [-8.129, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1546, "visits": [299.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1277, "q_vals": [-8.131, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1547, "visits": [300.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1279, "q_vals": [-8.177, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1548, "visits": [301.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1280, "q_vals": [-8.15, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1282, "number_of_timesteps": 148780, "per_episode_reward": -482.87, "episode_reward_trend_value": -0.030855652344066203, "biggest_recent_change": 1.5569799223397354},
{ "step": 1549, "visits": [302.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1282, "q_vals": [-8.152, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1550, "visits": [303.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1284, "q_vals": [-8.197, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1551, "visits": [304.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1284, "q_vals": [-8.199, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1552, "visits": [305.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1286, "q_vals": [-8.201, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1553, "visits": [306.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1286, "q_vals": [-8.203, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1554, "visits": [307.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1289, "q_vals": [-8.204, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1555, "visits": [308.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1291, "q_vals": [-8.206, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1292, "number_of_timesteps": 149449, "per_episode_reward": -483.3, "episode_reward_trend_value": -0.021188216638058872, "biggest_recent_change": 1.5569799223397354},
{ "step": 1556, "visits": [309.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1292, "q_vals": [-8.208, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1557, "visits": [310.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1293, "q_vals": [-8.21, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1558, "visits": [311.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1295, "q_vals": [-8.211, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1559, "visits": [312.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1295, "q_vals": [-8.213, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1560, "visits": [313.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1296, "q_vals": [-8.257, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1561, "visits": [314.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1296, "q_vals": [-8.258, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1562, "visits": [315.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1301, "q_vals": [-8.26, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1302, "number_of_timesteps": 150167, "per_episode_reward": -484.14, "episode_reward_trend_value": -0.03039375953843862, "biggest_recent_change": 1.5569799223397354},
{ "step": 1563, "visits": [316.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1302, "q_vals": [-8.234, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1564, "visits": [317.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1303, "q_vals": [-8.235, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1565, "visits": [318.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1303, "q_vals": [-8.21, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1566, "visits": [319.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1305, "q_vals": [-8.211, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1567, "visits": [320.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1306, "q_vals": [-8.254, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1568, "visits": [321.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1306, "q_vals": [-8.255, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1569, "visits": [322.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1308, "q_vals": [-8.257, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1312, "number_of_timesteps": 150857, "per_episode_reward": -485.5, "episode_reward_trend_value": -0.04515198838099018, "biggest_recent_change": 1.5569799223397354},
{ "step": 1570, "visits": [323.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1312, "q_vals": [-8.299, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1571, "visits": [324.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1312, "q_vals": [-8.301, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1572, "visits": [325.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1312, "q_vals": [-8.302, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1573, "visits": [326.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1313, "q_vals": [-8.276, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
[-8.251, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938]
{ "step": 1575, "visits": [328.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1317, "q_vals": [-8.253, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1576, "visits": [329.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1318, "q_vals": [-8.228, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1577, "visits": [330.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1320, "q_vals": [-8.229, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1322, "number_of_timesteps": 151591, "per_episode_reward": -486.41, "episode_reward_trend_value": -0.054371621051008866, "biggest_recent_change": 1.5569799223397354},
{ "step": 1578, "visits": [331.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1322, "q_vals": [-8.231, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1579, "visits": [332.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1323, "q_vals": [-8.272, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1580, "visits": [333.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1323, "q_vals": [-8.273, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1581, "visits": [334.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1324, "q_vals": [-8.275, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1582, "visits": [335.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1326, "q_vals": [-8.276, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1583, "visits": [336.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1327, "q_vals": [-8.278, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1584, "visits": [337.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1328, "q_vals": [-8.253, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1585, "visits": [338.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1330, "q_vals": [-8.293, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1333, "number_of_timesteps": 152338, "per_episode_reward": -485.22, "episode_reward_trend_value": -0.05256672281894592, "biggest_recent_change": 1.5569799223397354},
{ "step": 1586, "visits": [339.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1333, "q_vals": [-8.295, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1587, "visits": [340.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1334, "q_vals": [-8.296, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1588, "visits": [341.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1334, "q_vals": [-8.272, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1589, "visits": [342.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1334, "q_vals": [-8.273, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1590, "visits": [343.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1336, "q_vals": [-8.274, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1591, "visits": [344.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1337, "q_vals": [-8.276, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1592, "visits": [345.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1340, "q_vals": [-8.277, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1593, "visits": [346.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1341, "q_vals": [-8.279, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1594, "visits": [347.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1341, "q_vals": [-8.255, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1595, "visits": [348.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1342, "q_vals": [-8.256, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1344, "number_of_timesteps": 153161, "per_episode_reward": -485.15, "episode_reward_trend_value": -0.044619524771169636, "biggest_recent_change": 1.5569799223397354},
{ "step": 1596, "visits": [349.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1344, "q_vals": [-8.232, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1597, "visits": [350.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1346, "q_vals": [-8.234, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1598, "visits": [351.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1347, "q_vals": [-8.235, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1599, "visits": [352.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1348, "q_vals": [-8.237, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1600, "visits": [353.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1348, "q_vals": [-8.276, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1601, "visits": [354.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1348, "q_vals": [-8.277, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1602, "visits": [355.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1351, "q_vals": [-8.278, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1603, "visits": [356.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1351, "q_vals": [-8.28, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1604, "visits": [357.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1352, "q_vals": [-8.281, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1355, "number_of_timesteps": 153948, "per_episode_reward": -486.01, "episode_reward_trend_value": -0.03690840063289708, "biggest_recent_change": 1.3534261362352709},
{ "step": 1605, "visits": [358.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1355, "q_vals": [-8.258, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1606, "visits": [359.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1357, "q_vals": [-8.259, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1607, "visits": [360.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1357, "q_vals": [-8.26, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1608, "visits": [361.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1357, "q_vals": [-8.262, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1609, "visits": [362.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1357, "q_vals": [-8.263, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1610, "visits": [363.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1360, "q_vals": [-8.264, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1611, "visits": [364.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1360, "q_vals": [-8.266, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1612, "visits": [365.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1362, "q_vals": [-8.243, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1365, "number_of_timesteps": 154818, "per_episode_reward": -486.25, "episode_reward_trend_value": -0.04603037267446805, "biggest_recent_change": 1.3534261362352709},
{ "step": 1613, "visits": [366.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1365, "q_vals": [-8.28, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1614, "visits": [367.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1367, "q_vals": [-8.258, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1615, "visits": [368.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1367, "q_vals": [-8.235, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1616, "visits": [369.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1367, "q_vals": [-8.237, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1617, "visits": [370.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1368, "q_vals": [-8.238, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1618, "visits": [371.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1368, "q_vals": [-8.24, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1619, "visits": [372.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1370, "q_vals": [-8.217, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1620, "visits": [373.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1373, "q_vals": [-8.195, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1376, "number_of_timesteps": 155650, "per_episode_reward": -486.67, "episode_reward_trend_value": -0.04221878091714252, "biggest_recent_change": 1.3534261362352709},
{ "step": 1621, "visits": [374.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1376, "q_vals": [-8.173, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1622, "visits": [375.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1377, "q_vals": [-8.175, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1623, "visits": [376.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1378, "q_vals": [-8.153, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1624, "visits": [377.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1378, "q_vals": [-8.132, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1625, "visits": [378.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1378, "q_vals": [-8.133, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1626, "visits": [379.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1378, "q_vals": [-8.135, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1627, "visits": [380.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1382, "q_vals": [-8.137, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1628, "visits": [381.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1382, "q_vals": [-8.138, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1629, "visits": [382.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1384, "q_vals": [-8.117, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1387, "number_of_timesteps": 156464, "per_episode_reward": -485.23, "episode_reward_trend_value": -0.021490022909991545, "biggest_recent_change": 1.4407425158528326},
{ "step": 1630, "visits": [383.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1387, "q_vals": [-8.118, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1631, "visits": [384.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1388, "q_vals": [-8.154, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1632, "visits": [385.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1388, "q_vals": [-8.156, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1633, "visits": [386.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1388, "q_vals": [-8.157, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1634, "visits": [387.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1388, "q_vals": [-8.193, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1635, "visits": [388.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1391, "q_vals": [-8.194, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1636, "visits": [389.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1395, "q_vals": [-8.173, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1637, "visits": [390.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1395, "q_vals": [-8.175, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1397, "number_of_timesteps": 157210, "per_episode_reward": -484.79, "episode_reward_trend_value": -0.007206915820818773, "biggest_recent_change": 1.4407425158528326},
{ "step": 1638, "visits": [391.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1397, "q_vals": [-8.176, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1639, "visits": [392.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1397, "q_vals": [-8.178, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1640, "visits": [393.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1397, "q_vals": [-8.179, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1641, "visits": [394.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1398, "q_vals": [-8.158, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1642, "visits": [395.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1399, "q_vals": [-8.16, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1643, "visits": [396.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1399, "q_vals": [-8.161, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1644, "visits": [397.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1402, "q_vals": [-8.141, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1645, "visits": [398.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1404, "q_vals": [-8.175, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1407, "number_of_timesteps": 158029, "per_episode_reward": -486.25, "episode_reward_trend_value": -0.008428069953002807, "biggest_recent_change": 1.463330008131834},
{ "step": 1646, "visits": [399.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1407, "q_vals": [-8.177, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1647, "visits": [400.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1407, "q_vals": [-8.156, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1648, "visits": [401.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1407, "q_vals": [-8.158, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1649, "visits": [402.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1407, "q_vals": [-8.192, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1650, "visits": [403.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1409, "q_vals": [-8.172, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1651, "visits": [404.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1412, "q_vals": [-8.151, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1652, "visits": [405.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1416, "q_vals": [-8.153, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1653, "visits": [406.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1416, "q_vals": [-8.154, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1654, "visits": [407.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1416, "q_vals": [-8.134, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1655, "visits": [408.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1416, "q_vals": [-8.168, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1418, "number_of_timesteps": 158778, "per_episode_reward": -485.27, "episode_reward_trend_value": 0.012657134541795281, "biggest_recent_change": 1.463330008131834},
{ "step": 1656, "visits": [409.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1418, "q_vals": [-8.169, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1657, "visits": [410.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1419, "q_vals": [-8.171, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1658, "visits": [411.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1420, "q_vals": [-8.172, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1659, "visits": [412.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1422, "q_vals": [-8.174, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1660, "visits": [413.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1423, "q_vals": [-8.175, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1661, "visits": [414.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1425, "q_vals": [-8.176, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1662, "visits": [415.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1426, "q_vals": [-8.157, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1663, "visits": [416.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1427, "q_vals": [-8.137, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1664, "visits": [417.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1427, "q_vals": [-8.118, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1428, "number_of_timesteps": 159514, "per_episode_reward": -485.21, "episode_reward_trend_value": 0.0001778486656967794, "biggest_recent_change": 1.463330008131834},
{ "step": 1665, "visits": [418.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1428, "q_vals": [-8.119, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1666, "visits": [419.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1430, "q_vals": [-8.121, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1667, "visits": [420.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1431, "q_vals": [-8.101, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1668, "visits": [421.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1433, "q_vals": [-8.103, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1669, "visits": [422.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1436, "q_vals": [-8.104, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1670, "visits": [423.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1436, "q_vals": [-8.106, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1671, "visits": [424.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1437, "q_vals": [-8.107, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1438, "number_of_timesteps": 160278, "per_episode_reward": -485.71, "episode_reward_trend_value": -0.006220798942623181, "biggest_recent_change": 1.463330008131834},
{ "step": 1672, "visits": [425.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1438, "q_vals": [-8.109, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1673, "visits": [426.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1438, "q_vals": [-8.11, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1674, "visits": [427.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1441, "q_vals": [-8.112, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1675, "visits": [428.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1442, "q_vals": [-8.113, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1676, "visits": [429.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1444, "q_vals": [-8.115, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1677, "visits": [430.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1445, "q_vals": [-8.116, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1678, "visits": [431.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1445, "q_vals": [-8.097, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1679, "visits": [432.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1446, "q_vals": [-8.099, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1680, "visits": [433.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1447, "q_vals": [-8.1, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1448, "number_of_timesteps": 161057, "per_episode_reward": -486.23, "episode_reward_trend_value": -0.002514818845434598, "biggest_recent_change": 1.463330008131834},
{ "step": 1681, "visits": [434.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1448, "q_vals": [-8.102, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1682, "visits": [435.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1449, "q_vals": [-8.103, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1683, "visits": [436.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1451, "q_vals": [-8.105, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1684, "visits": [437.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1453, "q_vals": [-8.106, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1685, "visits": [438.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1454, "q_vals": [-8.088, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1686, "visits": [439.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1456, "q_vals": [-8.089, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1687, "visits": [440.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1457, "q_vals": [-8.091, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1458, "number_of_timesteps": 161821, "per_episode_reward": -486.44, "episode_reward_trend_value": -0.002071338532795153, "biggest_recent_change": 1.463330008131834},
{ "step": 1688, "visits": [441.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1458, "q_vals": [-8.092, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1689, "visits": [442.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1458, "q_vals": [-8.124, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1690, "visits": [443.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1459, "q_vals": [-8.105, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1691, "visits": [444.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1459, "q_vals": [-8.107, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1692, "visits": [445.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1461, "q_vals": [-8.108, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1693, "visits": [446.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1464, "q_vals": [-8.11, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1694, "visits": [447.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1467, "q_vals": [-8.111, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1695, "visits": [448.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1467, "q_vals": [-8.093, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1696, "visits": [449.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1467, "q_vals": [-8.094, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1697, "visits": [450.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1467, "q_vals": [-8.096, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1469, "number_of_timesteps": 162712, "per_episode_reward": -487.23, "episode_reward_trend_value": -0.00625531459297248, "biggest_recent_change": 1.463330008131834},
{ "step": 1698, "visits": [451.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1469, "q_vals": [-8.097, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1699, "visits": [452.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1471, "q_vals": [-8.099, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1700, "visits": [453.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1472, "q_vals": [-8.129, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1701, "visits": [454.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1473, "q_vals": [-8.159, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1702, "visits": [455.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1474, "q_vals": [-8.161, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1703, "visits": [456.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1476, "q_vals": [-8.162, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1704, "visits": [457.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1476, "q_vals": [-8.192, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1705, "visits": [458.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1477, "q_vals": [-8.193, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1706, "visits": [459.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1478, "q_vals": [-8.223, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1479, "number_of_timesteps": 163518, "per_episode_reward": -488.01, "episode_reward_trend_value": -0.030943600092505602, "biggest_recent_change": 1.463330008131834},
{ "step": 1707, "visits": [460.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1479, "q_vals": [-8.253, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1708, "visits": [461.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1481, "q_vals": [-8.254, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1709, "visits": [462.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1483, "q_vals": [-8.255, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1710, "visits": [463.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1483, "q_vals": [-8.256, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1711, "visits": [464.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1484, "q_vals": [-8.257, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1712, "visits": [465.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1485, "q_vals": [-8.258, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1713, "visits": [466.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1487, "q_vals": [-8.259, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1714, "visits": [467.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1487, "q_vals": [-8.26, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1715, "visits": [468.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1488, "q_vals": [-8.261, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1716, "visits": [469.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1488, "q_vals": [-8.244, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1490, "number_of_timesteps": 164455, "per_episode_reward": -488.12, "episode_reward_trend_value": -0.03703975185190479, "biggest_recent_change": 1.463330008131834},
{ "step": 1717, "visits": [470.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1490, "q_vals": [-8.226, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1718, "visits": [471.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1492, "q_vals": [-8.227, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1719, "visits": [472.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1492, "q_vals": [-8.228, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1720, "visits": [473.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1493, "q_vals": [-8.257, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1721, "visits": [474.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1496, "q_vals": [-8.258, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1722, "visits": [475.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1498, "q_vals": [-8.259, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1723, "visits": [476.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1498, "q_vals": [-8.26, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1724, "visits": [477.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1499, "q_vals": [-8.243, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1725, "visits": [478.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1499, "q_vals": [-8.244, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1726, "visits": [479.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1499, "q_vals": [-8.245, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1500, "number_of_timesteps": 165333, "per_episode_reward": -489.52, "episode_reward_trend_value": -0.03627989722140355, "biggest_recent_change": 1.3949430913867218},
{ "step": 1727, "visits": [480.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1500, "q_vals": [-8.246, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1728, "visits": [481.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1501, "q_vals": [-8.247, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1729, "visits": [482.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1502, "q_vals": [-8.275, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1730, "visits": [483.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1504, "q_vals": [-8.276, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1731, "visits": [484.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1505, "q_vals": [-8.277, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1732, "visits": [485.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1507, "q_vals": [-8.26, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1733, "visits": [486.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1508, "q_vals": [-8.261, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1734, "visits": [487.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1508, "q_vals": [-8.262, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1510, "number_of_timesteps": 166275, "per_episode_reward": -490.95, "episode_reward_trend_value": -0.06309295803591794, "biggest_recent_change": 1.4327194776020633},
{ "step": 1735, "visits": [488.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1510, "q_vals": [-8.263, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1736, "visits": [489.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1510, "q_vals": [-8.246, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1737, "visits": [490.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1512, "q_vals": [-8.247, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1738, "visits": [491.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1513, "q_vals": [-8.248, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1739, "visits": [492.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1515, "q_vals": [-8.249, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1740, "visits": [493.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1516, "q_vals": [-8.251, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1741, "visits": [494.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1517, "q_vals": [-8.252, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1742, "visits": [495.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1517, "q_vals": [-8.253, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1743, "visits": [496.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1519, "q_vals": [-8.236, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1744, "visits": [497.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1519, "q_vals": [-8.237, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1520, "number_of_timesteps": 167100, "per_episode_reward": -491.42, "episode_reward_trend_value": -0.06899968533567429, "biggest_recent_change": 1.4327194776020633},
{ "step": 1745, "visits": [498.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1520, "q_vals": [-8.238, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1746, "visits": [499.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1523, "q_vals": [-8.239, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1747, "visits": [500.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1523, "q_vals": [-8.24, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1748, "visits": [501.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1525, "q_vals": [-8.241, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1749, "visits": [502.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1527, "q_vals": [-8.225, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1750, "visits": [503.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1528, "q_vals": [-8.252, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1751, "visits": [504.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1529, "q_vals": [-8.253, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1530, "number_of_timesteps": 167884, "per_episode_reward": -491.58, "episode_reward_trend_value": -0.0652777388770864, "biggest_recent_change": 1.4327194776020633},
{ "step": 1752, "visits": [505.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1530, "q_vals": [-8.254, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1753, "visits": [506.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1530, "q_vals": [-8.255, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1754, "visits": [507.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1531, "q_vals": [-8.256, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1755, "visits": [508.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1532, "q_vals": [-8.257, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1756, "visits": [509.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1535, "q_vals": [-8.258, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1757, "visits": [510.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1536, "q_vals": [-8.259, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1758, "visits": [511.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1539, "q_vals": [-8.26, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1540, "number_of_timesteps": 168593, "per_episode_reward": -492.29, "episode_reward_trend_value": -0.0673064486936356, "biggest_recent_change": 1.4327194776020633},
{ "step": 1759, "visits": [512.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1540, "q_vals": [-8.261, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1760, "visits": [513.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1541, "q_vals": [-8.261, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1761, "visits": [514.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1541, "q_vals": [-8.245, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1762, "visits": [515.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1541, "q_vals": [-8.272, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1763, "visits": [516.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1544, "q_vals": [-8.273, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
[-8.257, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938]
{ "step": 1765, "visits": [518.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1546, "q_vals": [-8.241, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1766, "visits": [519.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1549, "q_vals": [-8.242, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1551, "number_of_timesteps": 169448, "per_episode_reward": -492.3, "episode_reward_trend_value": -0.06509642130790591, "biggest_recent_change": 1.4327194776020633},
{ "step": 1767, "visits": [520.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1551, "q_vals": [-8.243, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1768, "visits": [521.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1551, "q_vals": [-8.244, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1769, "visits": [522.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1552, "q_vals": [-8.245, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1770, "visits": [523.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1552, "q_vals": [-8.271, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1771, "visits": [524.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1552, "q_vals": [-8.272, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1772, "visits": [525.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1555, "q_vals": [-8.256, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1773, "visits": [526.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1558, "q_vals": [-8.257, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1774, "visits": [527.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1560, "q_vals": [-8.258, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1775, "visits": [528.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1560, "q_vals": [-8.259, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1561, "number_of_timesteps": 170180, "per_episode_reward": -492.53, "episode_reward_trend_value": -0.0588696482219354, "biggest_recent_change": 1.4327194776020633},
{ "step": 1776, "visits": [529.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1561, "q_vals": [-8.26, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1777, "visits": [530.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1561, "q_vals": [-8.244, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1778, "visits": [531.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1562, "q_vals": [-8.245, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1779, "visits": [532.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1564, "q_vals": [-8.246, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1780, "visits": [533.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1566, "q_vals": [-8.231, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1781, "visits": [534.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1568, "q_vals": [-8.232, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1782, "visits": [535.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1568, "q_vals": [-8.232, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1571, "number_of_timesteps": 170933, "per_episode_reward": -492.21, "episode_reward_trend_value": -0.046615261046669174, "biggest_recent_change": 1.4327194776020633},
{ "step": 1783, "visits": [536.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1571, "q_vals": [-8.233, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1784, "visits": [537.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1572, "q_vals": [-8.234, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1785, "visits": [538.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1573, "q_vals": [-8.26, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1786, "visits": [539.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1574, "q_vals": [-8.261, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1787, "visits": [540.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1574, "q_vals": [-8.262, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1788, "visits": [541.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1575, "q_vals": [-8.262, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1789, "visits": [542.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1577, "q_vals": [-8.263, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1790, "visits": [543.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1579, "q_vals": [-8.264, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1581, "number_of_timesteps": 171618, "per_episode_reward": -491.77, "episode_reward_trend_value": -0.04049406424230079, "biggest_recent_change": 1.4327194776020633},
{ "step": 1791, "visits": [544.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1581, "q_vals": [-8.265, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1792, "visits": [545.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1584, "q_vals": [-8.266, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1793, "visits": [546.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1584, "q_vals": [-8.267, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1794, "visits": [547.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1584, "q_vals": [-8.268, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1795, "visits": [548.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1585, "q_vals": [-8.253, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1796, "visits": [549.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1586, "q_vals": [-8.254, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1797, "visits": [550.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1589, "q_vals": [-8.278, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1798, "visits": [551.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1589, "q_vals": [-8.279, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1591, "number_of_timesteps": 172304, "per_episode_reward": -490.83, "episode_reward_trend_value": -0.014595561866378956, "biggest_recent_change": 1.4327194776020633},
{ "step": 1799, "visits": [552.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1591, "q_vals": [-8.264, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1800, "visits": [553.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1592, "q_vals": [-8.289, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1801, "visits": [554.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1594, "q_vals": [-8.29, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1802, "visits": [555.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1596, "q_vals": [-8.291, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1803, "visits": [556.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1596, "q_vals": [-8.291, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1804, "visits": [557.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1597, "q_vals": [-8.292, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1805, "visits": [558.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1598, "q_vals": [-8.277, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1601, "number_of_timesteps": 173026, "per_episode_reward": -491.32, "episode_reward_trend_value": -0.004079243680575928, "biggest_recent_change": 0.9359221224462431},
{ "step": 1806, "visits": [559.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1601, "q_vals": [-8.278, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1807, "visits": [560.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1602, "q_vals": [-8.279, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1808, "visits": [561.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1603, "q_vals": [-8.28, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1809, "visits": [562.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1605, "q_vals": [-8.281, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1810, "visits": [563.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1605, "q_vals": [-8.282, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1811, "visits": [564.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1607, "q_vals": [-8.306, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1812, "visits": [565.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1608, "q_vals": [-8.291, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1813, "visits": [566.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1610, "q_vals": [-8.276, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1814, "visits": [567.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1610, "q_vals": [-8.277, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1611, "number_of_timesteps": 173741, "per_episode_reward": -491.33, "episode_reward_trend_value": 0.0009959404068752065, "biggest_recent_change": 0.9359221224462431},
{ "step": 1815, "visits": [568.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1611, "q_vals": [-8.278, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1816, "visits": [569.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1613, "q_vals": [-8.279, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1817, "visits": [570.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1616, "q_vals": [-8.28, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1818, "visits": [571.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1617, "q_vals": [-8.303, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1819, "visits": [572.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1618, "q_vals": [-8.327, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1820, "visits": [573.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1618, "q_vals": [-8.328, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1821, "visits": [574.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1619, "q_vals": [-8.329, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1822, "visits": [575.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1620, "q_vals": [-8.314, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1622, "number_of_timesteps": 174530, "per_episode_reward": -491.7, "episode_reward_trend_value": -0.0013619721812302842, "biggest_recent_change": 0.9359221224462431},
{ "step": 1823, "visits": [576.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1622, "q_vals": [-8.3, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1824, "visits": [577.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1624, "q_vals": [-8.3, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1825, "visits": [578.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1625, "q_vals": [-8.301, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1826, "visits": [579.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1627, "q_vals": [-8.302, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1827, "visits": [580.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1628, "q_vals": [-8.288, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1828, "visits": [581.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1630, "q_vals": [-8.273, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1829, "visits": [582.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1631, "q_vals": [-8.274, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1830, "visits": [583.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1631, "q_vals": [-8.26, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1632, "number_of_timesteps": 175210, "per_episode_reward": -491.25, "episode_reward_trend_value": 0.011587393287232493, "biggest_recent_change": 0.9359221224462431},
{ "step": 1831, "visits": [584.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1632, "q_vals": [-8.261, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1832, "visits": [585.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1634, "q_vals": [-8.284, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1833, "visits": [586.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1636, "q_vals": [-8.285, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1834, "visits": [587.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1639, "q_vals": [-8.286, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1835, "visits": [588.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1640, "q_vals": [-8.287, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1836, "visits": [589.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1640, "q_vals": [-8.273, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1837, "visits": [590.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1641, "q_vals": [-8.296, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1838, "visits": [591.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1641, "q_vals": [-8.282, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1643, "number_of_timesteps": 175968, "per_episode_reward": -492.64, "episode_reward_trend_value": -0.003841226662695539, "biggest_recent_change": 1.395146025253723},
{ "step": 1839, "visits": [592.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1643, "q_vals": [-8.282, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1840, "visits": [593.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1646, "q_vals": [-8.268, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1841, "visits": [594.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1648, "q_vals": [-8.269, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1842, "visits": [595.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1648, "q_vals": [-8.27, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1843, "visits": [596.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1650, "q_vals": [-8.271, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1844, "visits": [597.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1650, "q_vals": [-8.272, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1845, "visits": [598.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1650, "q_vals": [-8.272, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1846, "visits": [599.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1652, "q_vals": [-8.259, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1653, "number_of_timesteps": 176683, "per_episode_reward": -492.54, "episode_reward_trend_value": -7.748960879136272e-05, "biggest_recent_change": 1.395146025253723},
{ "step": 1847, "visits": [600.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1653, "q_vals": [-8.259, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1848, "visits": [601.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1656, "q_vals": [-8.282, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1849, "visits": [602.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1658, "q_vals": [-8.283, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1850, "visits": [603.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1659, "q_vals": [-8.269, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1851, "visits": [604.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1660, "q_vals": [-8.255, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1852, "visits": [605.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1660, "q_vals": [-8.256, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1853, "visits": [606.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1662, "q_vals": [-8.257, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1663, "number_of_timesteps": 177392, "per_episode_reward": -492.58, "episode_reward_trend_value": -0.00416676794491448, "biggest_recent_change": 1.395146025253723},
{ "step": 1854, "visits": [607.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1663, "q_vals": [-8.258, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1855, "visits": [608.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1665, "q_vals": [-8.259, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1856, "visits": [609.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1665, "q_vals": [-8.259, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1857, "visits": [610.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1668, "q_vals": [-8.26, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
 [-8.261, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938]
{ "step": 1859, "visits": [612.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1672, "q_vals": [-8.262, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1860, "visits": [613.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1672, "q_vals": [-8.263, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1861, "visits": [614.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1672, "q_vals": [-8.263, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1673, "number_of_timesteps": 178103, "per_episode_reward": -493.36, "episode_reward_trend_value": -0.017704454407054173, "biggest_recent_change": 1.395146025253723},
{ "step": 1862, "visits": [615.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1673, "q_vals": [-8.25, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1863, "visits": [616.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1675, "q_vals": [-8.272, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1864, "visits": [617.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1678, "q_vals": [-8.273, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1865, "visits": [618.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1680, "q_vals": [-8.274, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1866, "visits": [619.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1680, "q_vals": [-8.274, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1867, "visits": [620.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1680, "q_vals": [-8.275, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1868, "visits": [621.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1682, "q_vals": [-8.297, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1684, "number_of_timesteps": 178881, "per_episode_reward": -492.35, "episode_reward_trend_value": -0.01687757562978113, "biggest_recent_change": 1.395146025253723},
{ "step": 1869, "visits": [622.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1684, "q_vals": [-8.298, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1870, "visits": [623.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1685, "q_vals": [-8.299, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1871, "visits": [624.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1686, "q_vals": [-8.299, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1872, "visits": [625.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1688, "q_vals": [-8.3, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1873, "visits": [626.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1690, "q_vals": [-8.301, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1874, "visits": [627.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1690, "q_vals": [-8.301, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1875, "visits": [628.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1691, "q_vals": [-8.323, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1876, "visits": [629.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1692, "q_vals": [-8.345, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1694, "number_of_timesteps": 179611, "per_episode_reward": -492.4, "episode_reward_trend_value": -0.011971082012761751, "biggest_recent_change": 1.395146025253723},
{ "step": 1877, "visits": [630.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1694, "q_vals": [-8.366, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1878, "visits": [631.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1695, "q_vals": [-8.367, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1879, "visits": [632.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1697, "q_vals": [-8.367, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1880, "visits": [633.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1698, "q_vals": [-8.354, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1881, "visits": [634.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1699, "q_vals": [-8.355, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1882, "visits": [635.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1700, "q_vals": [-8.355, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1704, "number_of_timesteps": 180331, "per_episode_reward": -492.66, "episode_reward_trend_value": -0.014872182459629357, "biggest_recent_change": 1.395146025253723},
{ "step": 1883, "visits": [636.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1704, "q_vals": [-8.342, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1884, "visits": [637.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1704, "q_vals": [-8.343, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1885, "visits": [638.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1705, "q_vals": [-8.343, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1886, "visits": [639.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1707, "q_vals": [-8.344, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1887, "visits": [640.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1707, "q_vals": [-8.345, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1888, "visits": [641.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1709, "q_vals": [-8.345, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1889, "visits": [642.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1710, "q_vals": [-8.346, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
 episode_count: 1710 q_vals: [-8.367, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938]
{ "step": 1891, "visits": [644.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1713, "q_vals": [-8.368, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1715, "number_of_timesteps": 181085, "per_episode_reward": -492.65, "episode_reward_trend_value": -0.010510819335017787, "biggest_recent_change": 1.395146025253723},
{ "step": 1892, "visits": [645.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1715, "q_vals": [-8.368, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1893, "visits": [646.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1716, "q_vals": [-8.369, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1894, "visits": [647.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1717, "q_vals": [-8.369, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1895, "visits": [648.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1719, "q_vals": [-8.37, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1896, "visits": [649.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1719, "q_vals": [-8.371, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1897, "visits": [650.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1719, "q_vals": [-8.358, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1898, "visits": [651.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1722, "q_vals": [-8.378, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1899, "visits": [652.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1723, "q_vals": [-8.379, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1900, "visits": [653.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1723, "q_vals": [-8.38, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1725, "number_of_timesteps": 181821, "per_episode_reward": -492.77, "episode_reward_trend_value": -0.01695171025475967, "biggest_recent_change": 1.395146025253723},
{ "step": 1901, "visits": [654.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1725, "q_vals": [-8.38, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1902, "visits": [655.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1727, "q_vals": [-8.381, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1903, "visits": [656.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1729, "q_vals": [-8.381, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1904, "visits": [657.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1729, "q_vals": [-8.369, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1905, "visits": [658.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1731, "q_vals": [-8.369, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1906, "visits": [659.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1733, "q_vals": [-8.39, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1907, "visits": [660.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1733, "q_vals": [-8.39, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1908, "visits": [661.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1734, "q_vals": [-8.377, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1736, "number_of_timesteps": 182624, "per_episode_reward": -492.26, "episode_reward_trend_value": 0.00427503241090474, "biggest_recent_change": 1.0103412124008173},
{ "step": 1909, "visits": [662.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1736, "q_vals": [-8.378, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1910, "visits": [663.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1737, "q_vals": [-8.398, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1911, "visits": [664.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1739, "q_vals": [-8.399, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1912, "visits": [665.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1741, "q_vals": [-8.386, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1913, "visits": [666.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1742, "q_vals": [-8.387, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1914, "visits": [667.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1744, "q_vals": [-8.374, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1915, "visits": [668.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1744, "q_vals": [-8.375, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1747, "number_of_timesteps": 183356, "per_episode_reward": -492.19, "episode_reward_trend_value": 0.003913649342931396, "biggest_recent_change": 1.0103412124008173},
{ "step": 1916, "visits": [669.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1747, "q_vals": [-8.362, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1917, "visits": [670.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1748, "q_vals": [-8.363, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1918, "visits": [671.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1749, "q_vals": [-8.363, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1919, "visits": [672.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1751, "q_vals": [-8.351, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1920, "visits": [673.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1753, "q_vals": [-8.352, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1921, "visits": [674.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1753, "q_vals": [-8.352, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1922, "visits": [675.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1755, "q_vals": [-8.353, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1757, "number_of_timesteps": 184008, "per_episode_reward": -491.65, "episode_reward_trend_value": 0.01034956219792649, "biggest_recent_change": 1.0103412124008173},
{ "step": 1923, "visits": [676.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1757, "q_vals": [-8.353, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1924, "visits": [677.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1757, "q_vals": [-8.341, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1925, "visits": [678.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1759, "q_vals": [-8.342, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1926, "visits": [679.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1761, "q_vals": [-8.342, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1927, "visits": [680.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1762, "q_vals": [-8.343, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1928, "visits": [681.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1763, "q_vals": [-8.363, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1929, "visits": [682.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1763, "q_vals": [-8.35, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1930, "visits": [683.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1766, "q_vals": [-8.351, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1768, "number_of_timesteps": 184762, "per_episode_reward": -491.03, "episode_reward_trend_value": 0.0259199826635457, "biggest_recent_change": 1.0103412124008173},
{ "step": 1931, "visits": [684.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1768, "q_vals": [-8.352, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1932, "visits": [685.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1768, "q_vals": [-8.371, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1933, "visits": [686.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1770, "q_vals": [-8.391, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1934, "visits": [687.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1772, "q_vals": [-8.392, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1935, "visits": [688.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1772, "q_vals": [-8.411, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1936, "visits": [689.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1773, "q_vals": [-8.399, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1937, "visits": [690.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1776, "q_vals": [-8.399, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1938, "visits": [691.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1776, "q_vals": [-8.4, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1939, "visits": [692.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1777, "q_vals": [-8.4, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1778, "number_of_timesteps": 185474, "per_episode_reward": -491.08, "episode_reward_trend_value": 0.014159735343141872, "biggest_recent_change": 0.6230505536847772},
{ "step": 1940, "visits": [693.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1778, "q_vals": [-8.42, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1941, "visits": [694.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1778, "q_vals": [-8.42, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1942, "visits": [695.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1780, "q_vals": [-8.44, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1943, "visits": [696.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1781, "q_vals": [-8.44, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1944, "visits": [697.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1782, "q_vals": [-8.428, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1945, "visits": [698.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1783, "q_vals": [-8.429, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1946, "visits": [699.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1786, "q_vals": [-8.448, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1947, "visits": [700.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1786, "q_vals": [-8.448, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1948, "visits": [701.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1787, "q_vals": [-8.449, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1949, "visits": [702.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1787, "q_vals": [-8.449, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1788, "number_of_timesteps": 186323, "per_episode_reward": -491.83, "episode_reward_trend_value": 0.006259796134427613, "biggest_recent_change": 0.7556609441323303},
{ "step": 1950, "visits": [703.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1788, "q_vals": [-8.45, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1951, "visits": [704.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1790, "q_vals": [-8.45, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1952, "visits": [705.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1792, "q_vals": [-8.45, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1953, "visits": [706.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1793, "q_vals": [-8.451, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1954, "visits": [707.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1794, "q_vals": [-8.451, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1955, "visits": [708.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1796, "q_vals": [-8.452, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1956, "visits": [709.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1796, "q_vals": [-8.452, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1957, "visits": [710.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1797, "q_vals": [-8.44, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1958, "visits": [711.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1797, "q_vals": [-8.441, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1799, "number_of_timesteps": 187212, "per_episode_reward": -491.95, "episode_reward_trend_value": 0.007884344400546046, "biggest_recent_change": 0.7556609441323303},
{ "step": 1959, "visits": [712.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1799, "q_vals": [-8.441, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1960, "visits": [713.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1802, "q_vals": [-8.441, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1961, "visits": [714.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1804, "q_vals": [-8.442, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1962, "visits": [715.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1805, "q_vals": [-8.461, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1963, "visits": [716.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1805, "q_vals": [-8.449, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1964, "visits": [717.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1806, "q_vals": [-8.449, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1965, "visits": [718.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1807, "q_vals": [-8.45, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1809, "number_of_timesteps": 187970, "per_episode_reward": -492.16, "episode_reward_trend_value": 0.005417679286577797, "biggest_recent_change": 0.7556609441323303},
{ "step": 1966, "visits": [719.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1809, "q_vals": [-8.45, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1967, "visits": [720.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1812, "q_vals": [-8.451, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1968, "visits": [721.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1813, "q_vals": [-8.469, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1969, "visits": [722.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1815, "q_vals": [-8.47, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1970, "visits": [723.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1815, "q_vals": [-8.458, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1971, "visits": [724.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1815, "q_vals": [-8.458, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1972, "visits": [725.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1816, "q_vals": [-8.459, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1973, "visits": [726.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1817, "q_vals": [-8.459, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1819, "number_of_timesteps": 188645, "per_episode_reward": -490.67, "episode_reward_trend_value": 0.023392050170726483, "biggest_recent_change": 1.4914316643206007},
{ "step": 1974, "visits": [727.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1819, "q_vals": [-8.459, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1975, "visits": [728.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1822, "q_vals": [-8.46, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1976, "visits": [729.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1823, "q_vals": [-8.46, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1977, "visits": [730.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1823, "q_vals": [-8.479, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1978, "visits": [731.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1826, "q_vals": [-8.479, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1979, "visits": [732.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1827, "q_vals": [-8.479, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1980, "visits": [733.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1827, "q_vals": [-8.498, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1981, "visits": [734.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1828, "q_vals": [-8.498, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1829, "number_of_timesteps": 189381, "per_episode_reward": -490.88, "episode_reward_trend_value": 0.015344992145243926, "biggest_recent_change": 1.4914316643206007},
{ "step": 1982, "visits": [735.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1829, "q_vals": [-8.498, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1983, "visits": [736.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1832, "q_vals": [-8.499, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1984, "visits": [737.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1834, "q_vals": [-8.487, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1985, "visits": [738.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1836, "q_vals": [-8.487, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1986, "visits": [739.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1837, "q_vals": [-8.488, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1987, "visits": [740.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1837, "q_vals": [-8.488, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1988, "visits": [741.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1837, "q_vals": [-8.506, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1989, "visits": [742.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1838, "q_vals": [-8.507, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1841, "number_of_timesteps": 190213, "per_episode_reward": -489.88, "episode_reward_trend_value": 0.02559201551935202, "biggest_recent_change": 1.4914316643206007},
{ "step": 1990, "visits": [743.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1841, "q_vals": [-8.525, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1991, "visits": [744.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1843, "q_vals": [-8.525, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1992, "visits": [745.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1846, "q_vals": [-8.525, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1993, "visits": [746.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1847, "q_vals": [-8.525, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1994, "visits": [747.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1847, "q_vals": [-8.526, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1995, "visits": [748.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1847, "q_vals": [-8.526, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1996, "visits": [749.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1848, "q_vals": [-8.526, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1997, "visits": [750.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1850, "q_vals": [-8.527, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1852, "number_of_timesteps": 190945, "per_episode_reward": -489.06, "episode_reward_trend_value": 0.028757671598520395, "biggest_recent_change": 1.4914316643206007},
{ "step": 1998, "visits": [751.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1852, "q_vals": [-8.515, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 1999, "visits": [752.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1854, "q_vals": [-8.516, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2000, "visits": [753.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1854, "q_vals": [-8.504, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2001, "visits": [754.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1856, "q_vals": [-8.505, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2002, "visits": [755.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1857, "q_vals": [-8.505, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2003, "visits": [756.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1857, "q_vals": [-8.505, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2004, "visits": [757.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1859, "q_vals": [-8.506, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2005, "visits": [758.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1860, "q_vals": [-8.506, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1862, "number_of_timesteps": 191728, "per_episode_reward": -489.56, "episode_reward_trend_value": 0.01637024683188315, "biggest_recent_change": 1.4914316643206007},
{ "step": 2006, "visits": [759.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1862, "q_vals": [-8.495, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2007, "visits": [760.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1862, "q_vals": [-8.495, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2008, "visits": [761.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1864, "q_vals": [-8.484, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2009, "visits": [762.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1865, "q_vals": [-8.473, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2010, "visits": [763.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1866, "q_vals": [-8.473, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2011, "visits": [764.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1867, "q_vals": [-8.473, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2012, "visits": [765.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1868, "q_vals": [-8.474, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1872, "number_of_timesteps": 192517, "per_episode_reward": -490.54, "episode_reward_trend_value": 0.005940705968896509, "biggest_recent_change": 1.4914316643206007},
{ "step": 2013, "visits": [766.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1872, "q_vals": [-8.474, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2014, "visits": [767.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1872, "q_vals": [-8.475, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2015, "visits": [768.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1872, "q_vals": [-8.475, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2016, "visits": [769.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1873, "q_vals": [-8.475, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2017, "visits": [770.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1875, "q_vals": [-8.493, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2018, "visits": [771.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1878, "q_vals": [-8.493, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2019, "visits": [772.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1880, "q_vals": [-8.493, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2020, "visits": [773.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1881, "q_vals": [-8.494, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2021, "visits": [774.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1881, "q_vals": [-8.494, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1883, "number_of_timesteps": 193261, "per_episode_reward": -490.45, "episode_reward_trend_value": 0.015373978423903307, "biggest_recent_change": 1.4914316643206007},
{ "step": 2022, "visits": [775.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1883, "q_vals": [-8.494, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2023, "visits": [776.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1885, "q_vals": [-8.483, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2024, "visits": [777.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1885, "q_vals": [-8.484, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2025, "visits": [778.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1887, "q_vals": [-8.484, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2026, "visits": [779.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1889, "q_vals": [-8.484, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2027, "visits": [780.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1891, "q_vals": [-8.485, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2028, "visits": [781.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1892, "q_vals": [-8.485, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1894, "number_of_timesteps": 193966, "per_episode_reward": -490.13, "episode_reward_trend_value": 0.02026140620432544, "biggest_recent_change": 1.4914316643206007},
{ "step": 2029, "visits": [782.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1894, "q_vals": [-8.485, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2030, "visits": [783.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1894, "q_vals": [-8.486, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2031, "visits": [784.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1896, "q_vals": [-8.475, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2032, "visits": [785.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1896, "q_vals": [-8.475, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2033, "visits": [786.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1897, "q_vals": [-8.476, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2034, "visits": [787.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1897, "q_vals": [-8.493, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2035, "visits": [788.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1900, "q_vals": [-8.493, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2036, "visits": [789.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1903, "q_vals": [-8.482, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2037, "visits": [790.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1903, "q_vals": [-8.483, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1906, "number_of_timesteps": 194864, "per_episode_reward": -490.19, "episode_reward_trend_value": 0.02186584918432383, "biggest_recent_change": 1.4914316643206007},
{ "step": 2038, "visits": [791.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1906, "q_vals": [-8.472, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2039, "visits": [792.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1906, "q_vals": [-8.472, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2040, "visits": [793.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1906, "q_vals": [-8.473, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2041, "visits": [794.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1908, "q_vals": [-8.473, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2042, "visits": [795.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1909, "q_vals": [-8.49, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2043, "visits": [796.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1911, "q_vals": [-8.49, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2044, "visits": [797.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1914, "q_vals": [-8.49, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2045, "visits": [798.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1915, "q_vals": [-8.491, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1916, "number_of_timesteps": 195543, "per_episode_reward": -489.01, "episode_reward_trend_value": 0.01838891663798563, "biggest_recent_change": 1.1785077351501627},
{ "step": 2046, "visits": [799.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1916, "q_vals": [-8.48, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2047, "visits": [800.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1917, "q_vals": [-8.48, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2048, "visits": [801.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1918, "q_vals": [-8.47, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2049, "visits": [802.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1919, "q_vals": [-8.47, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2050, "visits": [803.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1921, "q_vals": [-8.471, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2051, "visits": [804.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1922, "q_vals": [-8.471, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2052, "visits": [805.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1925, "q_vals": [-8.471, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1926, "number_of_timesteps": 196218, "per_episode_reward": -488.58, "episode_reward_trend_value": 0.025586343065349283, "biggest_recent_change": 1.1785077351501627},
{ "step": 2053, "visits": [806.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1926, "q_vals": [-8.488, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2054, "visits": [807.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1926, "q_vals": [-8.488, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2055, "visits": [808.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1926, "q_vals": [-8.478, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2056, "visits": [809.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1929, "q_vals": [-8.478, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2057, "visits": [810.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1929, "q_vals": [-8.478, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2058, "visits": [811.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1931, "q_vals": [-8.479, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2059, "visits": [812.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1935, "q_vals": [-8.468, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1936, "number_of_timesteps": 196960, "per_episode_reward": -488.81, "episode_reward_trend_value": 0.011879782793507982, "biggest_recent_change": 1.1785077351501627},
{ "step": 2060, "visits": [813.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1936, "q_vals": [-8.469, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2061, "visits": [814.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1936, "q_vals": [-8.469, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2062, "visits": [815.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1937, "q_vals": [-8.469, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2063, "visits": [816.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1938, "q_vals": [-8.47, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2064, "visits": [817.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1939, "q_vals": [-8.47, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2065, "visits": [818.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1940, "q_vals": [-8.47, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2066, "visits": [819.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1941, "q_vals": [-8.471, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2067, "visits": [820.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1943, "q_vals": [-8.471, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1946, "number_of_timesteps": 197646, "per_episode_reward": -488.65, "episode_reward_trend_value": 0.0046162794978506045, "biggest_recent_change": 1.1785077351501627},
{ "step": 2068, "visits": [821.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1946, "q_vals": [-8.487, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2069, "visits": [822.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1946, "q_vals": [-8.477, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2070, "visits": [823.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1947, "q_vals": [-8.477, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2071, "visits": [824.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1948, "q_vals": [-8.478, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2072, "visits": [825.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1950, "q_vals": [-8.478, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2073, "visits": [826.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1952, "q_vals": [-8.478, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2074, "visits": [827.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1953, "q_vals": [-8.479, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1956, "number_of_timesteps": 198360, "per_episode_reward": -487.74, "episode_reward_trend_value": 0.020233907356718976, "biggest_recent_change": 1.1785077351501627},
{ "step": 2075, "visits": [828.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1956, "q_vals": [-8.479, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2076, "visits": [829.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1956, "q_vals": [-8.495, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2077, "visits": [830.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1956, "q_vals": [-8.495, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2078, "visits": [831.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1956, "q_vals": [-8.496, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
[832.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0]  episode_count: 1958 q_vals: [-8.496, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938]
{ "step": 2080, "visits": [833.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1961, "q_vals": [-8.486, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2081, "visits": [834.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1962, "q_vals": [-8.486, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2082, "visits": [835.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1964, "q_vals": [-8.487, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2083, "visits": [836.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1964, "q_vals": [-8.476, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2084, "visits": [837.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1965, "q_vals": [-8.477, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1967, "number_of_timesteps": 199182, "per_episode_reward": -488.66, "episode_reward_trend_value": 0.020963455425652457, "biggest_recent_change": 1.1785077351501627},
{ "step": 2085, "visits": [838.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1967, "q_vals": [-8.477, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2086, "visits": [839.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1967, "q_vals": [-8.493, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2087, "visits": [840.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1968, "q_vals": [-8.493, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2088, "visits": [841.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1971, "q_vals": [-8.483, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2089, "visits": [842.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1972, "q_vals": [-8.484, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2090, "visits": [843.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1975, "q_vals": [-8.484, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2091, "visits": [844.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1976, "q_vals": [-8.5, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1977, "number_of_timesteps": 199882, "per_episode_reward": -489.31, "episode_reward_trend_value": 0.012633899064981177, "biggest_recent_change": 1.1785077351501627},
{ "step": 2092, "visits": [845.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1977, "q_vals": [-8.5, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2093, "visits": [846.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1978, "q_vals": [-8.5, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2094, "visits": [847.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1978, "q_vals": [-8.49, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2095, "visits": [848.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1979, "q_vals": [-8.491, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2096, "visits": [849.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1981, "q_vals": [-8.491, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2097, "visits": [850.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1981, "q_vals": [-8.491, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2098, "visits": [851.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1983, "q_vals": [-8.481, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2099, "visits": [852.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1986, "q_vals": [-8.497, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2100, "visits": [853.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1986, "q_vals": [-8.497, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1988, "number_of_timesteps": 200705, "per_episode_reward": -488.42, "episode_reward_trend_value": 0.01902593162066637, "biggest_recent_change": 1.1785077351501627},
{ "step": 2101, "visits": [854.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1988, "q_vals": [-8.487, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2102, "visits": [855.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1988, "q_vals": [-8.477, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2103, "visits": [856.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1990, "q_vals": [-8.478, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2104, "visits": [857.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1992, "q_vals": [-8.478, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2105, "visits": [858.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1993, "q_vals": [-8.478, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2106, "visits": [859.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1994, "q_vals": [-8.479, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2107, "visits": [860.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1994, "q_vals": [-8.479, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2108, "visits": [861.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1997, "q_vals": [-8.479, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2109, "visits": [862.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1997, "q_vals": [-8.48, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 1999, "number_of_timesteps": 201499, "per_episode_reward": -489.65, "episode_reward_trend_value": 0.006068728992479086, "biggest_recent_change": 1.2280859908294701},
{ "step": 2110, "visits": [863.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 1999, "q_vals": [-8.48, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2111, "visits": [864.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2000, "q_vals": [-8.48, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2112, "visits": [865.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2002, "q_vals": [-8.48, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2113, "visits": [866.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2002, "q_vals": [-8.471, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2114, "visits": [867.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2006, "q_vals": [-8.461, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2115, "visits": [868.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2006, "q_vals": [-8.461, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2116, "visits": [869.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2007, "q_vals": [-8.462, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2117, "visits": [870.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2007, "q_vals": [-8.462, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 2010, "number_of_timesteps": 202302, "per_episode_reward": -489.34, "episode_reward_trend_value": -0.0035954898230386332, "biggest_recent_change": 1.2280859908294701},
{ "step": 2118, "visits": [871.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2010, "q_vals": [-8.462, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2119, "visits": [872.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2011, "q_vals": [-8.463, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2120, "visits": [873.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2013, "q_vals": [-8.453, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2121, "visits": [874.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2013, "q_vals": [-8.453, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2122, "visits": [875.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2013, "q_vals": [-8.469, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2123, "visits": [876.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2017, "q_vals": [-8.469, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2124, "visits": [877.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2018, "q_vals": [-8.469, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2125, "visits": [878.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2019, "q_vals": [-8.47, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 2022, "number_of_timesteps": 203139, "per_episode_reward": -489.74, "episode_reward_trend_value": -0.012906299085802982, "biggest_recent_change": 1.2280859908294701},
{ "step": 2126, "visits": [879.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2022, "q_vals": [-8.46, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2127, "visits": [880.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2023, "q_vals": [-8.46, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2128, "visits": [881.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2023, "q_vals": [-8.461, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2129, "visits": [882.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2024, "q_vals": [-8.461, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2130, "visits": [883.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2027, "q_vals": [-8.461, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2131, "visits": [884.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2028, "q_vals": [-8.476, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2132, "visits": [885.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2030, "q_vals": [-8.477, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2133, "visits": [886.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2031, "q_vals": [-8.477, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 2032, "number_of_timesteps": 203777, "per_episode_reward": -489.72, "episode_reward_trend_value": -0.010045692416745548, "biggest_recent_change": 1.2280859908294701},
{ "step": 2134, "visits": [887.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2032, "q_vals": [-8.467, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2135, "visits": [888.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2033, "q_vals": [-8.468, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2136, "visits": [889.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2034, "q_vals": [-8.458, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2137, "visits": [890.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2036, "q_vals": [-8.459, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2138, "visits": [891.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2038, "q_vals": [-8.459, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2139, "visits": [892.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2039, "q_vals": [-8.474, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2140, "visits": [893.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2040, "q_vals": [-8.474, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 2042, "number_of_timesteps": 204489, "per_episode_reward": -489.68, "episode_reward_trend_value": -0.011498281099262108, "biggest_recent_change": 1.2280859908294701},
{ "step": 2141, "visits": [894.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2042, "q_vals": [-8.465, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2142, "visits": [895.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2043, "q_vals": [-8.465, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
[896.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0]  episode_count: 2044 q_vals: [-8.456, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938]
{ "step": 2144, "visits": [897.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2044, "q_vals": [-8.471, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2145, "visits": [898.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2047, "q_vals": [-8.471, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2146, "visits": [899.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2050, "q_vals": [-8.461, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2147, "visits": [900.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2051, "q_vals": [-8.462, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2148, "visits": [901.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2051, "q_vals": [-8.462, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 2053, "number_of_timesteps": 205247, "per_episode_reward": -489.9, "episode_reward_trend_value": -0.02400673027619165, "biggest_recent_change": 1.2280859908294701},
{ "step": 2149, "visits": [902.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2053, "q_vals": [-8.453, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2150, "visits": [903.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2053, "q_vals": [-8.443, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2151, "visits": [904.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2053, "q_vals": [-8.434, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2152, "visits": [905.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2055, "q_vals": [-8.434, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2153, "visits": [906.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2058, "q_vals": [-8.435, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2154, "visits": [907.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2059, "q_vals": [-8.435, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2155, "visits": [908.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2060, "q_vals": [-8.45, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2156, "visits": [909.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2061, "q_vals": [-8.441, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2157, "visits": [910.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2062, "q_vals": [-8.441, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 2064, "number_of_timesteps": 206068, "per_episode_reward": -489.73, "episode_reward_trend_value": -0.01195498220778859, "biggest_recent_change": 1.2280859908294701},
{ "step": 2158, "visits": [911.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2064, "q_vals": [-8.432, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2159, "visits": [912.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2064, "q_vals": [-8.422, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2160, "visits": [913.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2065, "q_vals": [-8.423, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2161, "visits": [914.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2065, "q_vals": [-8.438, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2162, "visits": [915.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2068, "q_vals": [-8.438, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2163, "visits": [916.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2068, "q_vals": [-8.438, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2164, "visits": [917.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2069, "q_vals": [-8.429, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2165, "visits": [918.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2070, "q_vals": [-8.429, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2166, "visits": [919.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2071, "q_vals": [-8.42, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2167, "visits": [920.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2072, "q_vals": [-8.421, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 2075, "number_of_timesteps": 207058, "per_episode_reward": -489.7, "episode_reward_trend_value": -0.004251665494680563, "biggest_recent_change": 1.2280859908294701},
{ "step": 2168, "visits": [921.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2075, "q_vals": [-8.421, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2169, "visits": [922.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2076, "q_vals": [-8.435, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2170, "visits": [923.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2076, "q_vals": [-8.436, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2171, "visits": [924.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2076, "q_vals": [-8.427, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2172, "visits": [925.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2078, "q_vals": [-8.418, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2173, "visits": [926.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2079, "q_vals": [-8.418, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2174, "visits": [927.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2080, "q_vals": [-8.409, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2175, "visits": [928.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2084, "q_vals": [-8.409, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2176, "visits": [929.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2084, "q_vals": [-8.41, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 2086, "number_of_timesteps": 207946, "per_episode_reward": -490.17, "episode_reward_trend_value": -0.019510534818783752, "biggest_recent_change": 1.2280859908294701},
{ "step": 2177, "visits": [930.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2086, "q_vals": [-8.401, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2178, "visits": [931.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2086, "q_vals": [-8.401, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2179, "visits": [932.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2087, "q_vals": [-8.401, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2180, "visits": [933.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2088, "q_vals": [-8.402, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2181, "visits": [934.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2089, "q_vals": [-8.402, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2182, "visits": [935.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2089, "q_vals": [-8.402, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2183, "visits": [936.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2089, "q_vals": [-8.403, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2184, "visits": [937.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2091, "q_vals": [-8.417, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2185, "visits": [938.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2095, "q_vals": [-8.408, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 2096, "number_of_timesteps": 208792, "per_episode_reward": -490.7, "episode_reward_trend_value": -0.011675914571309755, "biggest_recent_change": 0.5229701685568102},
{ "step": 2186, "visits": [939.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2096, "q_vals": [-8.409, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2187, "visits": [940.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2096, "q_vals": [-8.409, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2188, "visits": [941.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2097, "q_vals": [-8.409, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2189, "visits": [942.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2097, "q_vals": [-8.41, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2190, "visits": [943.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2098, "q_vals": [-8.41, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2191, "visits": [944.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2098, "q_vals": [-8.401, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2192, "visits": [945.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2102, "q_vals": [-8.401, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2193, "visits": [946.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2104, "q_vals": [-8.402, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2194, "visits": [947.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2105, "q_vals": [-8.402, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 2106, "number_of_timesteps": 209603, "per_episode_reward": -490.8, "episode_reward_trend_value": -0.016255587439348396, "biggest_recent_change": 0.5229701685568102},
{ "step": 2195, "visits": [948.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2106, "q_vals": [-8.393, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2196, "visits": [949.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2106, "q_vals": [-8.384, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2197, "visits": [950.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2107, "q_vals": [-8.385, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2198, "visits": [951.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2107, "q_vals": [-8.385, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2199, "visits": [952.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2109, "q_vals": [-8.386, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2200, "visits": [953.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2110, "q_vals": [-8.4, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2201, "visits": [954.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2110, "q_vals": [-8.4, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2202, "visits": [955.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2112, "q_vals": [-8.391, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2203, "visits": [956.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2113, "q_vals": [-8.392, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 2116, "number_of_timesteps": 210494, "per_episode_reward": -491.23, "episode_reward_trend_value": -0.016553693219064296, "biggest_recent_change": 0.5229701685568102},
{ "step": 2204, "visits": [957.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2116, "q_vals": [-8.406, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2205, "visits": [958.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2117, "q_vals": [-8.406, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2206, "visits": [959.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2117, "q_vals": [-8.407, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
 episode_count: 2117 q_vals: [-8.407, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938]
{ "step": 2208, "visits": [961.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2117, "q_vals": [-8.407, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2209, "visits": [962.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2117, "q_vals": [-8.421, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2210, "visits": [963.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2117, "q_vals": [-8.413, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2211, "visits": [964.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2118, "q_vals": [-8.413, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2212, "visits": [965.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2120, "q_vals": [-8.413, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2213, "visits": [966.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2120, "q_vals": [-8.414, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2214, "visits": [967.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2121, "q_vals": [-8.414, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2215, "visits": [968.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2122, "q_vals": [-8.414, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2216, "visits": [969.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2122, "q_vals": [-8.428, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2217, "visits": [970.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2124, "q_vals": [-8.428, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2218, "visits": [971.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2125, "q_vals": [-8.429, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2219, "visits": [972.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2125, "q_vals": [-8.429, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 2126, "number_of_timesteps": 211707, "per_episode_reward": -492.42, "episode_reward_trend_value": -0.030042457624151413, "biggest_recent_change": 1.1941916081343038},
{ "step": 2220, "visits": [973.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2126, "q_vals": [-8.429, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2221, "visits": [974.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2127, "q_vals": [-8.43, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2222, "visits": [975.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2128, "q_vals": [-8.43, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2223, "visits": [976.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2128, "q_vals": [-8.43, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2224, "visits": [977.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2128, "q_vals": [-8.431, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2225, "visits": [978.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2128, "q_vals": [-8.431, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2226, "visits": [979.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2128, "q_vals": [-8.431, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2227, "visits": [980.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2128, "q_vals": [-8.445, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2228, "visits": [981.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2130, "q_vals": [-8.445, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2229, "visits": [982.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2132, "q_vals": [-8.459, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2230, "visits": [983.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2133, "q_vals": [-8.459, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2231, "visits": [984.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2134, "q_vals": [-8.46, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2232, "visits": [985.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2134, "q_vals": [-8.451, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2233, "visits": [986.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2135, "q_vals": [-8.465, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 2137, "number_of_timesteps": 213255, "per_episode_reward": -493.61, "episode_reward_trend_value": -0.04362207119333574, "biggest_recent_change": 1.1941916081343038},
{ "step": 2234, "visits": [987.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2137, "q_vals": [-8.478, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2235, "visits": [988.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2138, "q_vals": [-8.479, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2236, "visits": [989.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2138, "q_vals": [-8.479, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2237, "visits": [990.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2140, "q_vals": [-8.47, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2238, "visits": [991.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2140, "q_vals": [-8.471, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2239, "visits": [992.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2140, "q_vals": [-8.462, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2240, "visits": [993.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2140, "q_vals": [-8.462, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2241, "visits": [994.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2142, "q_vals": [-8.463, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2242, "visits": [995.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2144, "q_vals": [-8.463, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2243, "visits": [996.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2144, "q_vals": [-8.454, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2244, "visits": [997.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2145, "q_vals": [-8.468, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2245, "visits": [998.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2145, "q_vals": [-8.468, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{"total_number_of_episodes": 2147, "number_of_timesteps": 214297, "per_episode_reward": -494.04, "episode_reward_trend_value": -0.04609203677224072, "biggest_recent_change": 1.1941916081343038},
{ "step": 2246, "visits": [999.0, 1000.0, 2.0, 18.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0] , "episode_count": 2147, "q_vals": [-8.468, -inf, -15.312, -9.236, -10.208, -13.125, -21.875, -10.208, -21.875, -10.938] }
{ "step": 2247, "visits": [1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 2148, "q_vals": [-inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 2248, "visits": [1000.0, 1000.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 2148, "q_vals": [-inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 2249, "visits": [1000.0, 1000.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 2151, "q_vals": [-inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 2250, "visits": [1000.0, 1000.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 2152, "q_vals": [-inf, -inf, 0.0, 0.0, -9.796, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 2251, "visits": [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 2152, "q_vals": [-inf, -inf, 0.0, 0.0, -9.796, -9.796, 0.0, 0.0, 0.0, 0.0] }
{ "step": 2252, "visits": [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0] , "episode_count": 2153, "q_vals": [-inf, -inf, 0.0, 0.0, -9.796, -9.796, 0.0, 0.0, 0.0, 0.0] }
{ "step": 2253, "visits": [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0] , "episode_count": 2155, "q_vals": [-inf, -inf, 0.0, 0.0, -9.796, -9.796, 0.0, -9.796, 0.0, 0.0] }
{ "step": 2254, "visits": [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0] , "episode_count": 2155, "q_vals": [-inf, -inf, 0.0, 0.0, -9.796, -9.796, 0.0, -9.796, -9.796, 0.0] }
{ "step": 2255, "visits": [1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 2155, "q_vals": [-inf, -inf, 0.0, 0.0, -9.796, -9.796, 0.0, -9.796, -9.796, -9.796] }
{ "step": 2256, "visits": [1000.0, 1000.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 2155, "q_vals": [-inf, -inf, -4.898, 0.0, -9.796, -9.796, 0.0, -9.796, -9.796, -9.796] }
{ "step": 2257, "visits": [1000.0, 1000.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 2156, "q_vals": [-inf, -inf, -4.898, 0.0, -9.796, -9.796, 0.0, -9.796, -9.796, -9.796] }
{ "step": 2258, "visits": [1000.0, 1000.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2156, "q_vals": [-inf, -inf, -4.898, 0.0, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2157, "number_of_timesteps": 215334, "per_episode_reward": -438.63, "episode_reward_trend_value": 0.5678002008752931, "biggest_recent_change": 55.41387831653401},
{ "step": 2259, "visits": [1000.0, 1000.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2157, "q_vals": [-inf, -inf, -4.898, -3.265, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2260, "visits": [1000.0, 1000.0, 2.0, 4.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2160, "q_vals": [-inf, -inf, -4.898, -2.449, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2261, "visits": [1000.0, 1000.0, 2.0, 5.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2161, "q_vals": [-inf, -inf, -4.898, -3.918, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2262, "visits": [1000.0, 1000.0, 2.0, 6.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2161, "q_vals": [-inf, -inf, -4.898, -4.898, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2263, "visits": [1000.0, 1000.0, 3.0, 6.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2162, "q_vals": [-inf, -inf, -3.265, -4.898, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2264, "visits": [1000.0, 1000.0, 4.0, 6.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2164, "q_vals": [-inf, -inf, -4.898, -4.898, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2265, "visits": [1000.0, 1000.0, 5.0, 6.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2165, "q_vals": [-inf, -inf, -3.918, -4.898, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2266, "visits": [1000.0, 1000.0, 6.0, 6.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2165, "q_vals": [-inf, -inf, -4.898, -4.898, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2267, "visits": [1000.0, 1000.0, 6.0, 7.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2165, "q_vals": [-inf, -inf, -4.898, -5.598, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2268, "visits": [1000.0, 1000.0, 7.0, 7.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2166, "q_vals": [-inf, -inf, -5.598, -5.598, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2167, "number_of_timesteps": 216487, "per_episode_reward": -440.67, "episode_reward_trend_value": 0.5447525406256053, "biggest_recent_change": 55.41387831653401},
{ "step": 2269, "visits": [1000.0, 1000.0, 7.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2167, "q_vals": [-inf, -inf, -5.598, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2270, "visits": [1000.0, 1000.0, 8.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2167, "q_vals": [-inf, -inf, -4.898, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2271, "visits": [1000.0, 1000.0, 9.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2167, "q_vals": [-inf, -inf, -4.354, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2272, "visits": [1000.0, 1000.0, 10.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2167, "q_vals": [-inf, -inf, -3.918, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2273, "visits": [1000.0, 1000.0, 11.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2169, "q_vals": [-inf, -inf, -4.453, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2274, "visits": [1000.0, 1000.0, 12.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2170, "q_vals": [-inf, -inf, -4.898, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2275, "visits": [1000.0, 1000.0, 13.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2171, "q_vals": [-inf, -inf, -5.275, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2276, "visits": [1000.0, 1000.0, 14.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2171, "q_vals": [-inf, -inf, -4.898, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2277, "visits": [1000.0, 1000.0, 15.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2171, "q_vals": [-inf, -inf, -5.224, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2278, "visits": [1000.0, 1000.0, 16.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2172, "q_vals": [-inf, -inf, -4.898, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2279, "visits": [1000.0, 1000.0, 17.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2173, "q_vals": [-inf, -inf, -4.61, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2280, "visits": [1000.0, 1000.0, 18.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2174, "q_vals": [-inf, -inf, -4.898, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2281, "visits": [1000.0, 1000.0, 19.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2175, "q_vals": [-inf, -inf, -4.64, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2282, "visits": [1000.0, 1000.0, 20.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2176, "q_vals": [-inf, -inf, -4.898, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2283, "visits": [1000.0, 1000.0, 21.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2176, "q_vals": [-inf, -inf, -5.131, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2177, "number_of_timesteps": 217676, "per_episode_reward": -441.56, "episode_reward_trend_value": 0.5401919900364949, "biggest_recent_change": 55.41387831653401},
{ "step": 2284, "visits": [1000.0, 1000.0, 22.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2177, "q_vals": [-inf, -inf, -5.343, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2285, "visits": [1000.0, 1000.0, 23.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2177, "q_vals": [-inf, -inf, -5.537, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2286, "visits": [1000.0, 1000.0, 24.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2179, "q_vals": [-inf, -inf, -5.306, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2287, "visits": [1000.0, 1000.0, 25.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2181, "q_vals": [-inf, -inf, -5.486, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2288, "visits": [1000.0, 1000.0, 26.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2181, "q_vals": [-inf, -inf, -5.651, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2289, "visits": [1000.0, 1000.0, 27.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2182, "q_vals": [-inf, -inf, -5.805, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2290, "visits": [1000.0, 1000.0, 28.0, 8.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2183, "q_vals": [-inf, -inf, -5.948, -6.122, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2291, "visits": [1000.0, 1000.0, 28.0, 9.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2185, "q_vals": [-inf, -inf, -5.948, -6.531, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2292, "visits": [1000.0, 1000.0, 29.0, 9.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2185, "q_vals": [-inf, -inf, -6.08, -6.531, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2293, "visits": [1000.0, 1000.0, 30.0, 9.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2186, "q_vals": [-inf, -inf, -6.204, -6.531, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2187, "number_of_timesteps": 218961, "per_episode_reward": -442.1, "episode_reward_trend_value": 0.5400199886073368, "biggest_recent_change": 55.41387831653401},
{ "step": 2294, "visits": [1000.0, 1000.0, 31.0, 9.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2187, "q_vals": [-inf, -inf, -6.32, -6.531, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2295, "visits": [1000.0, 1000.0, 31.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2188, "q_vals": [-inf, -inf, -6.32, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2296, "visits": [1000.0, 1000.0, 32.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2190, "q_vals": [-inf, -inf, -6.122, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2297, "visits": [1000.0, 1000.0, 33.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2190, "q_vals": [-inf, -inf, -6.234, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2298, "visits": [1000.0, 1000.0, 34.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2190, "q_vals": [-inf, -inf, -6.339, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2299, "visits": [1000.0, 1000.0, 35.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2192, "q_vals": [-inf, -inf, -6.157, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2300, "visits": [1000.0, 1000.0, 36.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2192, "q_vals": [-inf, -inf, -6.259, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2301, "visits": [1000.0, 1000.0, 37.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2194, "q_vals": [-inf, -inf, -6.089, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2197, "number_of_timesteps": 219867, "per_episode_reward": -442.67, "episode_reward_trend_value": 0.5347649393169762, "biggest_recent_change": 55.41387831653401},
{ "step": 2302, "visits": [1000.0, 1000.0, 38.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2197, "q_vals": [-inf, -inf, -5.929, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2303, "visits": [1000.0, 1000.0, 39.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2198, "q_vals": [-inf, -inf, -6.028, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2304, "visits": [1000.0, 1000.0, 40.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2200, "q_vals": [-inf, -inf, -6.122, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2305, "visits": [1000.0, 1000.0, 41.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2200, "q_vals": [-inf, -inf, -5.973, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2306, "visits": [1000.0, 1000.0, 42.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2200, "q_vals": [-inf, -inf, -6.064, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2307, "visits": [1000.0, 1000.0, 43.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2202, "q_vals": [-inf, -inf, -6.151, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2308, "visits": [1000.0, 1000.0, 44.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2202, "q_vals": [-inf, -inf, -6.234, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2309, "visits": [1000.0, 1000.0, 45.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2204, "q_vals": [-inf, -inf, -6.313, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2310, "visits": [1000.0, 1000.0, 46.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2205, "q_vals": [-inf, -inf, -6.176, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2311, "visits": [1000.0, 1000.0, 47.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2205, "q_vals": [-inf, -inf, -6.044, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2208, "number_of_timesteps": 220780, "per_episode_reward": -443.93, "episode_reward_trend_value": 0.5255394570850815, "biggest_recent_change": 55.41387831653401},
{ "step": 2312, "visits": [1000.0, 1000.0, 48.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2208, "q_vals": [-inf, -inf, -6.122, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2313, "visits": [1000.0, 1000.0, 49.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2208, "q_vals": [-inf, -inf, -6.197, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2314, "visits": [1000.0, 1000.0, 50.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2209, "q_vals": [-inf, -inf, -6.073, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2315, "visits": [1000.0, 1000.0, 51.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2210, "q_vals": [-inf, -inf, -6.146, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2316, "visits": [1000.0, 1000.0, 52.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2212, "q_vals": [-inf, -inf, -6.217, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2317, "visits": [1000.0, 1000.0, 53.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2212, "q_vals": [-inf, -inf, -6.284, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2318, "visits": [1000.0, 1000.0, 54.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2213, "q_vals": [-inf, -inf, -6.349, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2319, "visits": [1000.0, 1000.0, 55.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2215, "q_vals": [-inf, -inf, -6.234, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2320, "visits": [1000.0, 1000.0, 56.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2216, "q_vals": [-inf, -inf, -6.297, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2321, "visits": [1000.0, 1000.0, 57.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2216, "q_vals": [-inf, -inf, -6.359, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2322, "visits": [1000.0, 1000.0, 58.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2217, "q_vals": [-inf, -inf, -6.249, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2218, "number_of_timesteps": 221694, "per_episode_reward": -445.82, "episode_reward_trend_value": 0.5178328344891308, "biggest_recent_change": 55.41387831653401},
{ "step": 2323, "visits": [1000.0, 1000.0, 59.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2218, "q_vals": [-inf, -inf, -6.309, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2324, "visits": [1000.0, 1000.0, 60.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2220, "q_vals": [-inf, -inf, -6.367, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2325, "visits": [1000.0, 1000.0, 61.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2220, "q_vals": [-inf, -inf, -6.424, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2326, "visits": [1000.0, 1000.0, 62.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2220, "q_vals": [-inf, -inf, -6.32, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2327, "visits": [1000.0, 1000.0, 63.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2221, "q_vals": [-inf, -inf, -6.375, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2328, "visits": [1000.0, 1000.0, 64.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2222, "q_vals": [-inf, -inf, -6.429, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2329, "visits": [1000.0, 1000.0, 65.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2222, "q_vals": [-inf, -inf, -6.33, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2330, "visits": [1000.0, 1000.0, 66.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2225, "q_vals": [-inf, -inf, -6.234, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2331, "visits": [1000.0, 1000.0, 67.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2227, "q_vals": [-inf, -inf, -6.287, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2228, "number_of_timesteps": 222698, "per_episode_reward": -446.51, "episode_reward_trend_value": 0.5233508032466792, "biggest_recent_change": 55.41387831653401},
{ "step": 2332, "visits": [1000.0, 1000.0, 68.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2228, "q_vals": [-inf, -inf, -6.339, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2333, "visits": [1000.0, 1000.0, 69.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2228, "q_vals": [-inf, -inf, -6.247, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2334, "visits": [1000.0, 1000.0, 70.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2230, "q_vals": [-inf, -inf, -6.297, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2335, "visits": [1000.0, 1000.0, 71.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2230, "q_vals": [-inf, -inf, -6.347, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2336, "visits": [1000.0, 1000.0, 72.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2230, "q_vals": [-inf, -inf, -6.395, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2337, "visits": [1000.0, 1000.0, 73.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2232, "q_vals": [-inf, -inf, -6.307, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2338, "visits": [1000.0, 1000.0, 74.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2234, "q_vals": [-inf, -inf, -6.354, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2339, "visits": [1000.0, 1000.0, 75.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2236, "q_vals": [-inf, -inf, -6.4, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2340, "visits": [1000.0, 1000.0, 76.0, 10.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2237, "q_vals": [-inf, -inf, -6.445, -6.857, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2341, "visits": [1000.0, 1000.0, 76.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2237, "q_vals": [-inf, -inf, -6.445, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2342, "visits": [1000.0, 1000.0, 77.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2237, "q_vals": [-inf, -inf, -6.488, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2239, "number_of_timesteps": 223689, "per_episode_reward": -446.48, "episode_reward_trend_value": 0.5284653535659294, "biggest_recent_change": 55.41387831653401},
{ "step": 2343, "visits": [1000.0, 1000.0, 78.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2239, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2344, "visits": [1000.0, 1000.0, 79.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2240, "q_vals": [-inf, -inf, -6.572, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2345, "visits": [1000.0, 1000.0, 80.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2240, "q_vals": [-inf, -inf, -6.612, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2346, "visits": [1000.0, 1000.0, 81.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2242, "q_vals": [-inf, -inf, -6.652, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2347, "visits": [1000.0, 1000.0, 82.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2243, "q_vals": [-inf, -inf, -6.69, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2348, "visits": [1000.0, 1000.0, 83.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2244, "q_vals": [-inf, -inf, -6.727, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2349, "visits": [1000.0, 1000.0, 84.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2246, "q_vals": [-inf, -inf, -6.764, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2350, "visits": [1000.0, 1000.0, 85.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2246, "q_vals": [-inf, -inf, -6.8, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2249, "number_of_timesteps": 224595, "per_episode_reward": -446.67, "episode_reward_trend_value": -0.08927175081289723, "biggest_recent_change": 2.0373174139343178},
{ "step": 2351, "visits": [1000.0, 1000.0, 86.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2249, "q_vals": [-inf, -inf, -6.834, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2352, "visits": [1000.0, 1000.0, 87.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2249, "q_vals": [-inf, -inf, -6.868, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2353, "visits": [1000.0, 1000.0, 88.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2249, "q_vals": [-inf, -inf, -6.902, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2354, "visits": [1000.0, 1000.0, 89.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2251, "q_vals": [-inf, -inf, -6.824, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2355, "visits": [1000.0, 1000.0, 90.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2252, "q_vals": [-inf, -inf, -6.748, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2356, "visits": [1000.0, 1000.0, 91.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2252, "q_vals": [-inf, -inf, -6.782, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2357, "visits": [1000.0, 1000.0, 92.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2255, "q_vals": [-inf, -inf, -6.815, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2358, "visits": [1000.0, 1000.0, 93.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2256, "q_vals": [-inf, -inf, -6.741, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2359, "visits": [1000.0, 1000.0, 94.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2257, "q_vals": [-inf, -inf, -6.67, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2360, "visits": [1000.0, 1000.0, 95.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2257, "q_vals": [-inf, -inf, -6.702, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2260, "number_of_timesteps": 225527, "per_episode_reward": -447.52, "episode_reward_trend_value": -0.07608023324998878, "biggest_recent_change": 1.8877876417698758},
{ "step": 2361, "visits": [1000.0, 1000.0, 96.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2260, "q_vals": [-inf, -inf, -6.735, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2362, "visits": [1000.0, 1000.0, 97.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2261, "q_vals": [-inf, -inf, -6.766, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2363, "visits": [1000.0, 1000.0, 98.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2261, "q_vals": [-inf, -inf, -6.697, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2364, "visits": [1000.0, 1000.0, 99.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2262, "q_vals": [-inf, -inf, -6.729, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2365, "visits": [1000.0, 1000.0, 100.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2262, "q_vals": [-inf, -inf, -6.661, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2366, "visits": [1000.0, 1000.0, 101.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2262, "q_vals": [-inf, -inf, -6.595, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2367, "visits": [1000.0, 1000.0, 102.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2264, "q_vals": [-inf, -inf, -6.627, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2368, "visits": [1000.0, 1000.0, 103.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2267, "q_vals": [-inf, -inf, -6.562, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2369, "visits": [1000.0, 1000.0, 104.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2268, "q_vals": [-inf, -inf, -6.593, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2370, "visits": [1000.0, 1000.0, 105.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2268, "q_vals": [-inf, -inf, -6.624, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2371, "visits": [1000.0, 1000.0, 106.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2268, "q_vals": [-inf, -inf, -6.654, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2270, "number_of_timesteps": 226445, "per_episode_reward": -448.12, "episode_reward_trend_value": -0.07289495314836358, "biggest_recent_change": 1.8877876417698758},
{ "step": 2372, "visits": [1000.0, 1000.0, 107.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2270, "q_vals": [-inf, -inf, -6.683, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
[1000.0, 1000.0, 108.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 2270 q_vals: [-inf, -inf, -6.712, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796]
{ "step": 2374, "visits": [1000.0, 1000.0, 109.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2271, "q_vals": [-inf, -inf, -6.65, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2375, "visits": [1000.0, 1000.0, 110.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2272, "q_vals": [-inf, -inf, -6.679, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2376, "visits": [1000.0, 1000.0, 111.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2273, "q_vals": [-inf, -inf, -6.707, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2377, "visits": [1000.0, 1000.0, 112.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2274, "q_vals": [-inf, -inf, -6.735, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2378, "visits": [1000.0, 1000.0, 113.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2276, "q_vals": [-inf, -inf, -6.675, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2379, "visits": [1000.0, 1000.0, 114.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2278, "q_vals": [-inf, -inf, -6.617, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2380, "visits": [1000.0, 1000.0, 115.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2279, "q_vals": [-inf, -inf, -6.644, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2381, "visits": [1000.0, 1000.0, 116.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2279, "q_vals": [-inf, -inf, -6.587, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2382, "visits": [1000.0, 1000.0, 117.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2279, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2383, "visits": [1000.0, 1000.0, 118.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2279, "q_vals": [-inf, -inf, -6.558, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2384, "visits": [1000.0, 1000.0, 119.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2279, "q_vals": [-inf, -inf, -6.585, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2385, "visits": [1000.0, 1000.0, 120.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2279, "q_vals": [-inf, -inf, -6.612, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2281, "number_of_timesteps": 227421, "per_episode_reward": -448.59, "episode_reward_trend_value": -0.07213973351413883, "biggest_recent_change": 1.8877876417698758},
{ "step": 2386, "visits": [1000.0, 1000.0, 121.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2281, "q_vals": [-inf, -inf, -6.639, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2387, "visits": [1000.0, 1000.0, 122.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2284, "q_vals": [-inf, -inf, -6.584, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2388, "visits": [1000.0, 1000.0, 123.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2286, "q_vals": [-inf, -inf, -6.61, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2389, "visits": [1000.0, 1000.0, 124.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2288, "q_vals": [-inf, -inf, -6.636, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2390, "visits": [1000.0, 1000.0, 125.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2288, "q_vals": [-inf, -inf, -6.583, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2391, "visits": [1000.0, 1000.0, 126.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2288, "q_vals": [-inf, -inf, -6.608, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2392, "visits": [1000.0, 1000.0, 127.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2289, "q_vals": [-inf, -inf, -6.556, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2393, "visits": [1000.0, 1000.0, 128.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2289, "q_vals": [-inf, -inf, -6.582, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2394, "visits": [1000.0, 1000.0, 129.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2289, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2395, "visits": [1000.0, 1000.0, 130.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2290, "q_vals": [-inf, -inf, -6.48, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2291, "number_of_timesteps": 228541, "per_episode_reward": -448.66, "episode_reward_trend_value": -0.06653937217026219, "biggest_recent_change": 1.8877876417698758},
{ "step": 2396, "visits": [1000.0, 1000.0, 131.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2291, "q_vals": [-inf, -inf, -6.431, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2397, "visits": [1000.0, 1000.0, 132.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2294, "q_vals": [-inf, -inf, -6.456, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2398, "visits": [1000.0, 1000.0, 133.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2296, "q_vals": [-inf, -inf, -6.482, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2399, "visits": [1000.0, 1000.0, 134.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2296, "q_vals": [-inf, -inf, -6.433, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2400, "visits": [1000.0, 1000.0, 135.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2297, "q_vals": [-inf, -inf, -6.458, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2401, "visits": [1000.0, 1000.0, 136.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2297, "q_vals": [-inf, -inf, -6.483, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2402, "visits": [1000.0, 1000.0, 137.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2298, "q_vals": [-inf, -inf, -6.507, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2403, "visits": [1000.0, 1000.0, 138.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2298, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2404, "visits": [1000.0, 1000.0, 139.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2299, "q_vals": [-inf, -inf, -6.484, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2405, "visits": [1000.0, 1000.0, 140.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2299, "q_vals": [-inf, -inf, -6.437, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2302, "number_of_timesteps": 229628, "per_episode_reward": -448.56, "episode_reward_trend_value": -0.05140967361616807, "biggest_recent_change": 1.8877876417698758},
[-inf, -inf, -6.461, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796]
{ "step": 2407, "visits": [1000.0, 1000.0, 142.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2302, "q_vals": [-inf, -inf, -6.485, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2408, "visits": [1000.0, 1000.0, 143.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2305, "q_vals": [-inf, -inf, -6.439, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2409, "visits": [1000.0, 1000.0, 144.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2305, "q_vals": [-inf, -inf, -6.395, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2410, "visits": [1000.0, 1000.0, 145.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2306, "q_vals": [-inf, -inf, -6.35, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2411, "visits": [1000.0, 1000.0, 146.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2308, "q_vals": [-inf, -inf, -6.374, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2412, "visits": [1000.0, 1000.0, 147.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2308, "q_vals": [-inf, -inf, -6.397, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2413, "visits": [1000.0, 1000.0, 148.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2311, "q_vals": [-inf, -inf, -6.42, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2312, "number_of_timesteps": 230608, "per_episode_reward": -449.27, "episode_reward_trend_value": -0.03841706436098018, "biggest_recent_change": 0.8500808332725569},
{ "step": 2414, "visits": [1000.0, 1000.0, 149.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2312, "q_vals": [-inf, -inf, -6.443, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2415, "visits": [1000.0, 1000.0, 150.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2312, "q_vals": [-inf, -inf, -6.465, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2416, "visits": [1000.0, 1000.0, 151.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2313, "q_vals": [-inf, -inf, -6.487, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2417, "visits": [1000.0, 1000.0, 152.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2314, "q_vals": [-inf, -inf, -6.509, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2418, "visits": [1000.0, 1000.0, 153.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2314, "q_vals": [-inf, -inf, -6.467, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2419, "visits": [1000.0, 1000.0, 154.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2315, "q_vals": [-inf, -inf, -6.488, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2420, "visits": [1000.0, 1000.0, 155.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2316, "q_vals": [-inf, -inf, -6.51, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2421, "visits": [1000.0, 1000.0, 156.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2318, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2422, "visits": [1000.0, 1000.0, 157.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2319, "q_vals": [-inf, -inf, -6.551, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2423, "visits": [1000.0, 1000.0, 158.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2319, "q_vals": [-inf, -inf, -6.51, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2424, "visits": [1000.0, 1000.0, 159.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2320, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2425, "visits": [1000.0, 1000.0, 160.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2320, "q_vals": [-inf, -inf, -6.551, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2426, "visits": [1000.0, 1000.0, 161.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2321, "q_vals": [-inf, -inf, -6.51, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2322, "number_of_timesteps": 231507, "per_episode_reward": -449.62, "episode_reward_trend_value": -0.03452161099052849, "biggest_recent_change": 0.8500808332725569},
{ "step": 2427, "visits": [1000.0, 1000.0, 162.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2322, "q_vals": [-inf, -inf, -6.47, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2428, "visits": [1000.0, 1000.0, 163.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2324, "q_vals": [-inf, -inf, -6.491, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2429, "visits": [1000.0, 1000.0, 164.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2327, "q_vals": [-inf, -inf, -6.511, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2430, "visits": [1000.0, 1000.0, 165.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2327, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2431, "visits": [1000.0, 1000.0, 166.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2328, "q_vals": [-inf, -inf, -6.55, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2432, "visits": [1000.0, 1000.0, 167.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2329, "q_vals": [-inf, -inf, -6.57, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2433, "visits": [1000.0, 1000.0, 168.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2330, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2332, "number_of_timesteps": 232492, "per_episode_reward": -449.65, "episode_reward_trend_value": -0.03515251846391657, "biggest_recent_change": 0.8500808332725569},
{ "step": 2434, "visits": [1000.0, 1000.0, 169.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2332, "q_vals": [-inf, -inf, -6.55, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2435, "visits": [1000.0, 1000.0, 170.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2333, "q_vals": [-inf, -inf, -6.569, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2436, "visits": [1000.0, 1000.0, 171.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2335, "q_vals": [-inf, -inf, -6.588, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2437, "visits": [1000.0, 1000.0, 172.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2335, "q_vals": [-inf, -inf, -6.55, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2438, "visits": [1000.0, 1000.0, 173.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2336, "q_vals": [-inf, -inf, -6.512, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2439, "visits": [1000.0, 1000.0, 174.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2338, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2440, "visits": [1000.0, 1000.0, 175.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2339, "q_vals": [-inf, -inf, -6.549, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2441, "visits": [1000.0, 1000.0, 176.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2341, "q_vals": [-inf, -inf, -6.568, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2442, "visits": [1000.0, 1000.0, 177.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2341, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2343, "number_of_timesteps": 233332, "per_episode_reward": -449.55, "episode_reward_trend_value": -0.03201703428999786, "biggest_recent_change": 0.8500808332725569},
{ "step": 2443, "visits": [1000.0, 1000.0, 178.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2343, "q_vals": [-inf, -inf, -6.494, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2444, "visits": [1000.0, 1000.0, 179.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2344, "q_vals": [-inf, -inf, -6.512, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2445, "visits": [1000.0, 1000.0, 180.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2344, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2446, "visits": [1000.0, 1000.0, 181.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2345, "q_vals": [-inf, -inf, -6.549, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2447, "visits": [1000.0, 1000.0, 182.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2346, "q_vals": [-inf, -inf, -6.513, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2448, "visits": [1000.0, 1000.0, 183.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2348, "q_vals": [-inf, -inf, -6.477, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2449, "visits": [1000.0, 1000.0, 184.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2350, "q_vals": [-inf, -inf, -6.495, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2450, "visits": [1000.0, 1000.0, 185.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2350, "q_vals": [-inf, -inf, -6.46, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2353, "number_of_timesteps": 234173, "per_episode_reward": -448.78, "episode_reward_trend_value": -0.014063573193928074, "biggest_recent_change": 0.7657306653737237},
{ "step": 2451, "visits": [1000.0, 1000.0, 186.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2353, "q_vals": [-inf, -inf, -6.478, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2452, "visits": [1000.0, 1000.0, 187.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2353, "q_vals": [-inf, -inf, -6.496, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2453, "visits": [1000.0, 1000.0, 188.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2355, "q_vals": [-inf, -inf, -6.513, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2454, "visits": [1000.0, 1000.0, 189.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2357, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2455, "visits": [1000.0, 1000.0, 190.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2359, "q_vals": [-inf, -inf, -6.496, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2456, "visits": [1000.0, 1000.0, 191.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2360, "q_vals": [-inf, -inf, -6.462, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2457, "visits": [1000.0, 1000.0, 192.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2360, "q_vals": [-inf, -inf, -6.48, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2458, "visits": [1000.0, 1000.0, 193.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2361, "q_vals": [-inf, -inf, -6.497, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2459, "visits": [1000.0, 1000.0, 194.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2362, "q_vals": [-inf, -inf, -6.514, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2365, "number_of_timesteps": 234992, "per_episode_reward": -448.89, "episode_reward_trend_value": -0.008579642236903358, "biggest_recent_change": 0.7657306653737237},
{ "step": 2460, "visits": [1000.0, 1000.0, 195.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2365, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2461, "visits": [1000.0, 1000.0, 196.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2367, "q_vals": [-inf, -inf, -6.497, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2462, "visits": [1000.0, 1000.0, 197.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2368, "q_vals": [-inf, -inf, -6.514, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2463, "visits": [1000.0, 1000.0, 198.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2368, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2464, "visits": [1000.0, 1000.0, 199.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2369, "q_vals": [-inf, -inf, -6.498, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2465, "visits": [1000.0, 1000.0, 200.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2370, "q_vals": [-inf, -inf, -6.514, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2466, "visits": [1000.0, 1000.0, 201.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2371, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2467, "visits": [1000.0, 1000.0, 202.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2373, "q_vals": [-inf, -inf, -6.547, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2375, "number_of_timesteps": 235702, "per_episode_reward": -448.4, "episode_reward_trend_value": 0.0020536634152759034, "biggest_recent_change": 0.7657306653737237},
{ "step": 2468, "visits": [1000.0, 1000.0, 203.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2375, "q_vals": [-inf, -inf, -6.515, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2469, "visits": [1000.0, 1000.0, 204.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2377, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2470, "visits": [1000.0, 1000.0, 205.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2379, "q_vals": [-inf, -inf, -6.499, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2471, "visits": [1000.0, 1000.0, 206.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2379, "q_vals": [-inf, -inf, -6.515, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
[1000.0, 1000.0, 207.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 2380 q_vals: [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796]
{ "step": 2473, "visits": [1000.0, 1000.0, 208.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2381, "q_vals": [-inf, -inf, -6.499, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2474, "visits": [1000.0, 1000.0, 209.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2382, "q_vals": [-inf, -inf, -6.515, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2475, "visits": [1000.0, 1000.0, 210.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2382, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2385, "number_of_timesteps": 236382, "per_episode_reward": -447.97, "episode_reward_trend_value": 0.0076330305806784, "biggest_recent_change": 0.7657306653737237},
{ "step": 2476, "visits": [1000.0, 1000.0, 211.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2385, "q_vals": [-inf, -inf, -6.5, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2477, "visits": [1000.0, 1000.0, 212.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2387, "q_vals": [-inf, -inf, -6.469, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2478, "visits": [1000.0, 1000.0, 213.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2388, "q_vals": [-inf, -inf, -6.485, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2479, "visits": [1000.0, 1000.0, 214.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2389, "q_vals": [-inf, -inf, -6.5, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2480, "visits": [1000.0, 1000.0, 215.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2390, "q_vals": [-inf, -inf, -6.515, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2481, "visits": [1000.0, 1000.0, 216.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2391, "q_vals": [-inf, -inf, -6.485, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2482, "visits": [1000.0, 1000.0, 217.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2391, "q_vals": [-inf, -inf, -6.501, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2483, "visits": [1000.0, 1000.0, 218.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2394, "q_vals": [-inf, -inf, -6.516, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2484, "visits": [1000.0, 1000.0, 219.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2394, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2396, "number_of_timesteps": 237274, "per_episode_reward": -448.02, "episode_reward_trend_value": 0.005974319534881386, "biggest_recent_change": 0.7657306653737237},
{ "step": 2485, "visits": [1000.0, 1000.0, 220.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2396, "q_vals": [-inf, -inf, -6.545, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2486, "visits": [1000.0, 1000.0, 221.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2396, "q_vals": [-inf, -inf, -6.56, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2487, "visits": [1000.0, 1000.0, 222.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2397, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2488, "visits": [1000.0, 1000.0, 223.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2400, "q_vals": [-inf, -inf, -6.501, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2489, "visits": [1000.0, 1000.0, 224.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2400, "q_vals": [-inf, -inf, -6.472, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2490, "visits": [1000.0, 1000.0, 225.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2401, "q_vals": [-inf, -inf, -6.487, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2491, "visits": [1000.0, 1000.0, 226.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2402, "q_vals": [-inf, -inf, -6.458, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2492, "visits": [1000.0, 1000.0, 227.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2403, "q_vals": [-inf, -inf, -6.473, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2493, "visits": [1000.0, 1000.0, 228.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2405, "q_vals": [-inf, -inf, -6.488, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2494, "visits": [1000.0, 1000.0, 229.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2405, "q_vals": [-inf, -inf, -6.459, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2495, "visits": [1000.0, 1000.0, 230.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2405, "q_vals": [-inf, -inf, -6.431, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2408, "number_of_timesteps": 238290, "per_episode_reward": -448.77, "episode_reward_trend_value": 0.00558790714977767, "biggest_recent_change": 0.7657306653737237},
{ "step": 2496, "visits": [1000.0, 1000.0, 231.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2408, "q_vals": [-inf, -inf, -6.446, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2497, "visits": [1000.0, 1000.0, 232.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2409, "q_vals": [-inf, -inf, -6.46, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2498, "visits": [1000.0, 1000.0, 233.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2412, "q_vals": [-inf, -inf, -6.475, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2499, "visits": [1000.0, 1000.0, 234.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2412, "q_vals": [-inf, -inf, -6.489, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2500, "visits": [1000.0, 1000.0, 235.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2412, "q_vals": [-inf, -inf, -6.461, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2501, "visits": [1000.0, 1000.0, 236.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2413, "q_vals": [-inf, -inf, -6.434, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2502, "visits": [1000.0, 1000.0, 237.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2415, "q_vals": [-inf, -inf, -6.448, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2503, "visits": [1000.0, 1000.0, 238.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2417, "q_vals": [-inf, -inf, -6.421, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2504, "visits": [1000.0, 1000.0, 239.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2417, "q_vals": [-inf, -inf, -6.435, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2418, "number_of_timesteps": 239071, "per_episode_reward": -449.03, "episode_reward_trend_value": 0.0064543859678041025, "biggest_recent_change": 0.7657306653737237},
{ "step": 2505, "visits": [1000.0, 1000.0, 240.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2418, "q_vals": [-inf, -inf, -6.408, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2506, "visits": [1000.0, 1000.0, 241.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2419, "q_vals": [-inf, -inf, -6.422, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2507, "visits": [1000.0, 1000.0, 242.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2421, "q_vals": [-inf, -inf, -6.436, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2508, "visits": [1000.0, 1000.0, 243.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2421, "q_vals": [-inf, -inf, -6.41, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2509, "visits": [1000.0, 1000.0, 244.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2423, "q_vals": [-inf, -inf, -6.424, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2510, "visits": [1000.0, 1000.0, 245.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2424, "q_vals": [-inf, -inf, -6.437, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2511, "visits": [1000.0, 1000.0, 246.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2426, "q_vals": [-inf, -inf, -6.451, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2512, "visits": [1000.0, 1000.0, 247.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2427, "q_vals": [-inf, -inf, -6.425, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2429, "number_of_timesteps": 239947, "per_episode_reward": -449.09, "episode_reward_trend_value": 0.00620535244945649, "biggest_recent_change": 0.7657306653737237},
{ "step": 2513, "visits": [1000.0, 1000.0, 248.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2429, "q_vals": [-inf, -inf, -6.399, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2514, "visits": [1000.0, 1000.0, 249.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2431, "q_vals": [-inf, -inf, -6.373, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2515, "visits": [1000.0, 1000.0, 250.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2431, "q_vals": [-inf, -inf, -6.387, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2516, "visits": [1000.0, 1000.0, 251.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2431, "q_vals": [-inf, -inf, -6.401, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2517, "visits": [1000.0, 1000.0, 252.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2433, "q_vals": [-inf, -inf, -6.375, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2518, "visits": [1000.0, 1000.0, 253.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2433, "q_vals": [-inf, -inf, -6.389, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2519, "visits": [1000.0, 1000.0, 254.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2435, "q_vals": [-inf, -inf, -6.402, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2520, "visits": [1000.0, 1000.0, 255.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2437, "q_vals": [-inf, -inf, -6.415, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2439, "number_of_timesteps": 240730, "per_episode_reward": -449.34, "episode_reward_trend_value": 0.0022821427245029707, "biggest_recent_change": 0.7657306653737237},
{ "step": 2521, "visits": [1000.0, 1000.0, 256.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2439, "q_vals": [-inf, -inf, -6.429, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2522, "visits": [1000.0, 1000.0, 257.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2440, "q_vals": [-inf, -inf, -6.442, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2523, "visits": [1000.0, 1000.0, 258.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2440, "q_vals": [-inf, -inf, -6.455, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2524, "visits": [1000.0, 1000.0, 259.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2443, "q_vals": [-inf, -inf, -6.468, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2525, "visits": [1000.0, 1000.0, 260.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2443, "q_vals": [-inf, -inf, -6.48, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2526, "visits": [1000.0, 1000.0, 261.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2444, "q_vals": [-inf, -inf, -6.493, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2527, "visits": [1000.0, 1000.0, 262.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2445, "q_vals": [-inf, -inf, -6.506, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2528, "visits": [1000.0, 1000.0, 263.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2446, "q_vals": [-inf, -inf, -6.481, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2529, "visits": [1000.0, 1000.0, 264.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2447, "q_vals": [-inf, -inf, -6.456, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2530, "visits": [1000.0, 1000.0, 265.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2448, "q_vals": [-inf, -inf, -6.469, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2449, "number_of_timesteps": 241487, "per_episode_reward": -448.77, "episode_reward_trend_value": 8.294545505565212e-05, "biggest_recent_change": 0.7532299234622997},
{ "step": 2531, "visits": [1000.0, 1000.0, 266.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2449, "q_vals": [-inf, -inf, -6.482, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2532, "visits": [1000.0, 1000.0, 267.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2451, "q_vals": [-inf, -inf, -6.494, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2533, "visits": [1000.0, 1000.0, 268.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2452, "q_vals": [-inf, -inf, -6.506, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2534, "visits": [1000.0, 1000.0, 269.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2452, "q_vals": [-inf, -inf, -6.518, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2535, "visits": [1000.0, 1000.0, 270.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2454, "q_vals": [-inf, -inf, -6.531, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2536, "visits": [1000.0, 1000.0, 271.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2455, "q_vals": [-inf, -inf, -6.543, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2537, "visits": [1000.0, 1000.0, 272.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2456, "q_vals": [-inf, -inf, -6.555, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2538, "visits": [1000.0, 1000.0, 273.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2458, "q_vals": [-inf, -inf, -6.563, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2539, "visits": [1000.0, 1000.0, 274.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2458, "q_vals": [-inf, -inf, -6.574, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2540, "visits": [1000.0, 1000.0, 275.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2458, "q_vals": [-inf, -inf, -6.586, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2461, "number_of_timesteps": 242539, "per_episode_reward": -449.28, "episode_reward_trend_value": -0.004294528130115319, "biggest_recent_change": 0.7532299234622997},
{ "step": 2541, "visits": [1000.0, 1000.0, 276.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2461, "q_vals": [-inf, -inf, -6.598, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2542, "visits": [1000.0, 1000.0, 277.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2461, "q_vals": [-inf, -inf, -6.574, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2543, "visits": [1000.0, 1000.0, 278.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2462, "q_vals": [-inf, -inf, -6.585, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2544, "visits": [1000.0, 1000.0, 279.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2462, "q_vals": [-inf, -inf, -6.597, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2545, "visits": [1000.0, 1000.0, 280.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2463, "q_vals": [-inf, -inf, -6.608, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2546, "visits": [1000.0, 1000.0, 281.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2464, "q_vals": [-inf, -inf, -6.62, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2547, "visits": [1000.0, 1000.0, 282.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2464, "q_vals": [-inf, -inf, -6.596, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2548, "visits": [1000.0, 1000.0, 283.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2465, "q_vals": [-inf, -inf, -6.608, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2549, "visits": [1000.0, 1000.0, 284.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2465, "q_vals": [-inf, -inf, -6.619, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2550, "visits": [1000.0, 1000.0, 285.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2467, "q_vals": [-inf, -inf, -6.63, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2551, "visits": [1000.0, 1000.0, 286.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2470, "q_vals": [-inf, -inf, -6.607, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2471, "number_of_timesteps": 243616, "per_episode_reward": -450.24, "episode_reward_trend_value": -0.02038199489132858, "biggest_recent_change": 0.9613550299138751},
{ "step": 2552, "visits": [1000.0, 1000.0, 287.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2471, "q_vals": [-inf, -inf, -6.618, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2553, "visits": [1000.0, 1000.0, 288.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2472, "q_vals": [-inf, -inf, -6.595, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2554, "visits": [1000.0, 1000.0, 289.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2473, "q_vals": [-inf, -inf, -6.606, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2555, "visits": [1000.0, 1000.0, 290.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2474, "q_vals": [-inf, -inf, -6.583, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2556, "visits": [1000.0, 1000.0, 291.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2474, "q_vals": [-inf, -inf, -6.561, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2557, "visits": [1000.0, 1000.0, 292.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2474, "q_vals": [-inf, -inf, -6.572, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2558, "visits": [1000.0, 1000.0, 293.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2476, "q_vals": [-inf, -inf, -6.583, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2559, "visits": [1000.0, 1000.0, 294.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2479, "q_vals": [-inf, -inf, -6.594, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2481, "number_of_timesteps": 244459, "per_episode_reward": -450.12, "episode_reward_trend_value": -0.02382588709207375, "biggest_recent_change": 0.9613550299138751},
{ "step": 2560, "visits": [1000.0, 1000.0, 295.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2481, "q_vals": [-inf, -inf, -6.604, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2561, "visits": [1000.0, 1000.0, 296.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2483, "q_vals": [-inf, -inf, -6.582, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2562, "visits": [1000.0, 1000.0, 297.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2483, "q_vals": [-inf, -inf, -6.593, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2563, "visits": [1000.0, 1000.0, 298.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2483, "q_vals": [-inf, -inf, -6.604, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2564, "visits": [1000.0, 1000.0, 299.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2483, "q_vals": [-inf, -inf, -6.614, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2565, "visits": [1000.0, 1000.0, 300.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2484, "q_vals": [-inf, -inf, -6.625, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2566, "visits": [1000.0, 1000.0, 301.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2485, "q_vals": [-inf, -inf, -6.636, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2567, "visits": [1000.0, 1000.0, 302.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2486, "q_vals": [-inf, -inf, -6.646, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2568, "visits": [1000.0, 1000.0, 303.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2488, "q_vals": [-inf, -inf, -6.656, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2569, "visits": [1000.0, 1000.0, 304.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2490, "q_vals": [-inf, -inf, -6.667, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2492, "number_of_timesteps": 245404, "per_episode_reward": -450.15, "episode_reward_trend_value": -0.023669425315235533, "biggest_recent_change": 0.9613550299138751},
{ "step": 2570, "visits": [1000.0, 1000.0, 305.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2492, "q_vals": [-inf, -inf, -6.645, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2571, "visits": [1000.0, 1000.0, 306.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2493, "q_vals": [-inf, -inf, -6.655, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2572, "visits": [1000.0, 1000.0, 307.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2493, "q_vals": [-inf, -inf, -6.665, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2573, "visits": [1000.0, 1000.0, 308.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2493, "q_vals": [-inf, -inf, -6.644, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2574, "visits": [1000.0, 1000.0, 309.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2494, "q_vals": [-inf, -inf, -6.654, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2575, "visits": [1000.0, 1000.0, 310.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2496, "q_vals": [-inf, -inf, -6.632, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2576, "visits": [1000.0, 1000.0, 311.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2497, "q_vals": [-inf, -inf, -6.611, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2577, "visits": [1000.0, 1000.0, 312.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2498, "q_vals": [-inf, -inf, -6.59, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2578, "visits": [1000.0, 1000.0, 313.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2501, "q_vals": [-inf, -inf, -6.569, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2579, "visits": [1000.0, 1000.0, 314.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2501, "q_vals": [-inf, -inf, -6.579, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2503, "number_of_timesteps": 246352, "per_episode_reward": -450.39, "episode_reward_trend_value": -0.017951362807589376, "biggest_recent_change": 0.9613550299138751},
{ "step": 2580, "visits": [1000.0, 1000.0, 315.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2503, "q_vals": [-inf, -inf, -6.589, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2581, "visits": [1000.0, 1000.0, 316.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2504, "q_vals": [-inf, -inf, -6.569, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2582, "visits": [1000.0, 1000.0, 317.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2504, "q_vals": [-inf, -inf, -6.548, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2583, "visits": [1000.0, 1000.0, 318.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2504, "q_vals": [-inf, -inf, -6.558, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2584, "visits": [1000.0, 1000.0, 319.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2505, "q_vals": [-inf, -inf, -6.568, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2585, "visits": [1000.0, 1000.0, 320.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2507, "q_vals": [-inf, -inf, -6.578, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2586, "visits": [1000.0, 1000.0, 321.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2508, "q_vals": [-inf, -inf, -6.588, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2587, "visits": [1000.0, 1000.0, 322.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2510, "q_vals": [-inf, -inf, -6.568, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2588, "visits": [1000.0, 1000.0, 323.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2511, "q_vals": [-inf, -inf, -6.548, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2589, "visits": [1000.0, 1000.0, 324.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2512, "q_vals": [-inf, -inf, -6.558, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2513, "number_of_timesteps": 247207, "per_episode_reward": -450.83, "episode_reward_trend_value": -0.01999027183393183, "biggest_recent_change": 0.9613550299138751},
{ "step": 2590, "visits": [1000.0, 1000.0, 325.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2513, "q_vals": [-inf, -inf, -6.537, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2591, "visits": [1000.0, 1000.0, 326.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2514, "q_vals": [-inf, -inf, -6.547, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2592, "visits": [1000.0, 1000.0, 327.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2515, "q_vals": [-inf, -inf, -6.557, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2593, "visits": [1000.0, 1000.0, 328.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2516, "q_vals": [-inf, -inf, -6.537, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2594, "visits": [1000.0, 1000.0, 329.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2516, "q_vals": [-inf, -inf, -6.547, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2595, "visits": [1000.0, 1000.0, 330.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2517, "q_vals": [-inf, -inf, -6.557, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2596, "visits": [1000.0, 1000.0, 331.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2519, "q_vals": [-inf, -inf, -6.537, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2597, "visits": [1000.0, 1000.0, 332.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2522, "q_vals": [-inf, -inf, -6.547, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2523, "number_of_timesteps": 248083, "per_episode_reward": -451.1, "episode_reward_trend_value": -0.02230443078951162, "biggest_recent_change": 0.9613550299138751},
{ "step": 2598, "visits": [1000.0, 1000.0, 333.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2523, "q_vals": [-inf, -inf, -6.527, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2599, "visits": [1000.0, 1000.0, 334.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2523, "q_vals": [-inf, -inf, -6.508, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2600, "visits": [1000.0, 1000.0, 335.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2523, "q_vals": [-inf, -inf, -6.488, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2601, "visits": [1000.0, 1000.0, 336.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2524, "q_vals": [-inf, -inf, -6.498, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2602, "visits": [1000.0, 1000.0, 337.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2526, "q_vals": [-inf, -inf, -6.508, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2603, "visits": [1000.0, 1000.0, 338.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2527, "q_vals": [-inf, -inf, -6.518, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2604, "visits": [1000.0, 1000.0, 339.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2529, "q_vals": [-inf, -inf, -6.527, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2605, "visits": [1000.0, 1000.0, 340.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2531, "q_vals": [-inf, -inf, -6.537, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2606, "visits": [1000.0, 1000.0, 341.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2532, "q_vals": [-inf, -inf, -6.547, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2607, "visits": [1000.0, 1000.0, 342.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2532, "q_vals": [-inf, -inf, -6.556, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2608, "visits": [1000.0, 1000.0, 343.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2532, "q_vals": [-inf, -inf, -6.566, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2609, "visits": [1000.0, 1000.0, 344.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2532, "q_vals": [-inf, -inf, -6.546, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2610, "visits": [1000.0, 1000.0, 345.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2532, "q_vals": [-inf, -inf, -6.556, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2535, "number_of_timesteps": 249114, "per_episode_reward": -451.49, "episode_reward_trend_value": -0.02382578942956444, "biggest_recent_change": 0.9613550299138751},
{ "step": 2611, "visits": [1000.0, 1000.0, 346.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2535, "q_vals": [-inf, -inf, -6.565, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2612, "visits": [1000.0, 1000.0, 347.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2538, "q_vals": [-inf, -inf, -6.575, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2613, "visits": [1000.0, 1000.0, 348.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2538, "q_vals": [-inf, -inf, -6.556, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2614, "visits": [1000.0, 1000.0, 349.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2540, "q_vals": [-inf, -inf, -6.565, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2615, "visits": [1000.0, 1000.0, 350.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2540, "q_vals": [-inf, -inf, -6.574, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2616, "visits": [1000.0, 1000.0, 351.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2541, "q_vals": [-inf, -inf, -6.583, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2617, "visits": [1000.0, 1000.0, 352.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2542, "q_vals": [-inf, -inf, -6.565, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2618, "visits": [1000.0, 1000.0, 353.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2542, "q_vals": [-inf, -inf, -6.546, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2619, "visits": [1000.0, 1000.0, 354.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2543, "q_vals": [-inf, -inf, -6.555, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2620, "visits": [1000.0, 1000.0, 355.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2543, "q_vals": [-inf, -inf, -6.537, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2621, "visits": [1000.0, 1000.0, 356.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2544, "q_vals": [-inf, -inf, -6.546, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2622, "visits": [1000.0, 1000.0, 357.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2544, "q_vals": [-inf, -inf, -6.555, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2545, "number_of_timesteps": 250043, "per_episode_reward": -451.79, "episode_reward_trend_value": -0.03352182925795293, "biggest_recent_change": 0.9613550299138751},
{ "step": 2623, "visits": [1000.0, 1000.0, 358.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2545, "q_vals": [-inf, -inf, -6.537, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2624, "visits": [1000.0, 1000.0, 359.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2547, "q_vals": [-inf, -inf, -6.546, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2625, "visits": [1000.0, 1000.0, 360.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2547, "q_vals": [-inf, -inf, -6.528, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2626, "visits": [1000.0, 1000.0, 361.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2547, "q_vals": [-inf, -inf, -6.537, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2627, "visits": [1000.0, 1000.0, 362.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2548, "q_vals": [-inf, -inf, -6.546, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2628, "visits": [1000.0, 1000.0, 363.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2549, "q_vals": [-inf, -inf, -6.555, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2629, "visits": [1000.0, 1000.0, 364.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2552, "q_vals": [-inf, -inf, -6.537, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2630, "visits": [1000.0, 1000.0, 365.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2553, "q_vals": [-inf, -inf, -6.519, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2631, "visits": [1000.0, 1000.0, 366.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2553, "q_vals": [-inf, -inf, -6.528, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2555, "number_of_timesteps": 251268, "per_episode_reward": -452.31, "episode_reward_trend_value": -0.03367771668374833, "biggest_recent_change": 0.9613550299138751},
{ "step": 2632, "visits": [1000.0, 1000.0, 367.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2555, "q_vals": [-inf, -inf, -6.537, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2633, "visits": [1000.0, 1000.0, 368.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2555, "q_vals": [-inf, -inf, -6.545, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2634, "visits": [1000.0, 1000.0, 369.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2555, "q_vals": [-inf, -inf, -6.554, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2635, "visits": [1000.0, 1000.0, 370.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2558, "q_vals": [-inf, -inf, -6.563, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2636, "visits": [1000.0, 1000.0, 371.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2558, "q_vals": [-inf, -inf, -6.572, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2637, "visits": [1000.0, 1000.0, 372.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2558, "q_vals": [-inf, -inf, -6.554, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2638, "visits": [1000.0, 1000.0, 373.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2560, "q_vals": [-inf, -inf, -6.563, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2639, "visits": [1000.0, 1000.0, 374.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2560, "q_vals": [-inf, -inf, -6.545, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2640, "visits": [1000.0, 1000.0, 375.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2561, "q_vals": [-inf, -inf, -6.554, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2641, "visits": [1000.0, 1000.0, 376.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2562, "q_vals": [-inf, -inf, -6.536, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2642, "visits": [1000.0, 1000.0, 377.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2563, "q_vals": [-inf, -inf, -6.519, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2643, "visits": [1000.0, 1000.0, 378.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2563, "q_vals": [-inf, -inf, -6.502, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2644, "visits": [1000.0, 1000.0, 379.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2564, "q_vals": [-inf, -inf, -6.485, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2565, "number_of_timesteps": 252291, "per_episode_reward": -452.86, "episode_reward_trend_value": -0.029090397313242672, "biggest_recent_change": 0.5484962865683656},
{ "step": 2645, "visits": [1000.0, 1000.0, 380.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2565, "q_vals": [-inf, -inf, -6.493, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2646, "visits": [1000.0, 1000.0, 381.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2565, "q_vals": [-inf, -inf, -6.502, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2647, "visits": [1000.0, 1000.0, 382.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2567, "q_vals": [-inf, -inf, -6.511, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2648, "visits": [1000.0, 1000.0, 383.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2567, "q_vals": [-inf, -inf, -6.519, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2649, "visits": [1000.0, 1000.0, 384.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2568, "q_vals": [-inf, -inf, -6.528, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2650, "visits": [1000.0, 1000.0, 385.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2568, "q_vals": [-inf, -inf, -6.511, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2651, "visits": [1000.0, 1000.0, 386.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2571, "q_vals": [-inf, -inf, -6.519, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2652, "visits": [1000.0, 1000.0, 387.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2572, "q_vals": [-inf, -inf, -6.528, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2653, "visits": [1000.0, 1000.0, 388.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2572, "q_vals": [-inf, -inf, -6.536, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2654, "visits": [1000.0, 1000.0, 389.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2573, "q_vals": [-inf, -inf, -6.545, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2575, "number_of_timesteps": 253452, "per_episode_reward": -453.38, "episode_reward_trend_value": -0.036227325017281625, "biggest_recent_change": 0.5484962865683656},
{ "step": 2655, "visits": [1000.0, 1000.0, 390.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2575, "q_vals": [-inf, -inf, -6.528, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2656, "visits": [1000.0, 1000.0, 391.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2577, "q_vals": [-inf, -inf, -6.511, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2657, "visits": [1000.0, 1000.0, 392.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2577, "q_vals": [-inf, -inf, -6.495, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2658, "visits": [1000.0, 1000.0, 393.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2578, "q_vals": [-inf, -inf, -6.478, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2659, "visits": [1000.0, 1000.0, 394.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2579, "q_vals": [-inf, -inf, -6.486, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2660, "visits": [1000.0, 1000.0, 395.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2581, "q_vals": [-inf, -inf, -6.47, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2661, "visits": [1000.0, 1000.0, 396.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2582, "q_vals": [-inf, -inf, -6.478, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2662, "visits": [1000.0, 1000.0, 397.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2584, "q_vals": [-inf, -inf, -6.487, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2585, "number_of_timesteps": 254278, "per_episode_reward": -453.47, "episode_reward_trend_value": -0.0369285023638497, "biggest_recent_change": 0.5484962865683656},
{ "step": 2663, "visits": [1000.0, 1000.0, 398.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2585, "q_vals": [-inf, -inf, -6.495, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2664, "visits": [1000.0, 1000.0, 399.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2585, "q_vals": [-inf, -inf, -6.503, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2665, "visits": [1000.0, 1000.0, 400.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2586, "q_vals": [-inf, -inf, -6.487, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2666, "visits": [1000.0, 1000.0, 401.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2588, "q_vals": [-inf, -inf, -6.495, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2667, "visits": [1000.0, 1000.0, 402.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2589, "q_vals": [-inf, -inf, -6.504, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
[-inf, -inf, -6.512, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796]
{ "step": 2669, "visits": [1000.0, 1000.0, 404.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2591, "q_vals": [-inf, -inf, -6.52, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2595, "number_of_timesteps": 255084, "per_episode_reward": -453.33, "episode_reward_trend_value": -0.03266494019650408, "biggest_recent_change": 0.5484962865683656},
{ "step": 2670, "visits": [1000.0, 1000.0, 405.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2595, "q_vals": [-inf, -inf, -6.504, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2671, "visits": [1000.0, 1000.0, 406.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2595, "q_vals": [-inf, -inf, -6.512, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2672, "visits": [1000.0, 1000.0, 407.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2596, "q_vals": [-inf, -inf, -6.52, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2673, "visits": [1000.0, 1000.0, 408.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2598, "q_vals": [-inf, -inf, -6.504, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2674, "visits": [1000.0, 1000.0, 409.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2598, "q_vals": [-inf, -inf, -6.512, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2675, "visits": [1000.0, 1000.0, 410.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2599, "q_vals": [-inf, -inf, -6.52, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2676, "visits": [1000.0, 1000.0, 411.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2601, "q_vals": [-inf, -inf, -6.528, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2677, "visits": [1000.0, 1000.0, 412.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2603, "q_vals": [-inf, -inf, -6.512, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2678, "visits": [1000.0, 1000.0, 413.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2603, "q_vals": [-inf, -inf, -6.52, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2605, "number_of_timesteps": 255797, "per_episode_reward": -453.02, "episode_reward_trend_value": -0.024248401006712404, "biggest_recent_change": 0.5484962865683656},
{ "step": 2679, "visits": [1000.0, 1000.0, 414.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2605, "q_vals": [-inf, -inf, -6.504, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2680, "visits": [1000.0, 1000.0, 415.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2606, "q_vals": [-inf, -inf, -6.489, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2681, "visits": [1000.0, 1000.0, 416.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2607, "q_vals": [-inf, -inf, -6.473, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2682, "visits": [1000.0, 1000.0, 417.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2609, "q_vals": [-inf, -inf, -6.481, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2683, "visits": [1000.0, 1000.0, 418.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2611, "q_vals": [-inf, -inf, -6.489, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2684, "visits": [1000.0, 1000.0, 419.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2611, "q_vals": [-inf, -inf, -6.497, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2685, "visits": [1000.0, 1000.0, 420.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2611, "q_vals": [-inf, -inf, -6.505, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2686, "visits": [1000.0, 1000.0, 421.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2613, "q_vals": [-inf, -inf, -6.513, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2687, "visits": [1000.0, 1000.0, 422.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2614, "q_vals": [-inf, -inf, -6.52, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2615, "number_of_timesteps": 256586, "per_episode_reward": -453.24, "episode_reward_trend_value": -0.023786099874800785, "biggest_recent_change": 0.5484962865683656},
{ "step": 2688, "visits": [1000.0, 1000.0, 423.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2615, "q_vals": [-inf, -inf, -6.505, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2689, "visits": [1000.0, 1000.0, 424.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2617, "q_vals": [-inf, -inf, -6.513, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2690, "visits": [1000.0, 1000.0, 425.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2618, "q_vals": [-inf, -inf, -6.52, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2691, "visits": [1000.0, 1000.0, 426.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2621, "q_vals": [-inf, -inf, -6.528, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2692, "visits": [1000.0, 1000.0, 427.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2621, "q_vals": [-inf, -inf, -6.536, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2693, "visits": [1000.0, 1000.0, 428.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2622, "q_vals": [-inf, -inf, -6.543, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2694, "visits": [1000.0, 1000.0, 429.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2623, "q_vals": [-inf, -inf, -6.551, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2625, "number_of_timesteps": 257342, "per_episode_reward": -453.19, "episode_reward_trend_value": -0.01896574134953476, "biggest_recent_change": 0.5484962865683656},
{ "step": 2695, "visits": [1000.0, 1000.0, 430.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2625, "q_vals": [-inf, -inf, -6.559, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2696, "visits": [1000.0, 1000.0, 431.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2626, "q_vals": [-inf, -inf, -6.566, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2697, "visits": [1000.0, 1000.0, 432.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2626, "q_vals": [-inf, -inf, -6.573, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2698, "visits": [1000.0, 1000.0, 433.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2629, "q_vals": [-inf, -inf, -6.581, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2699, "visits": [1000.0, 1000.0, 434.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2630, "q_vals": [-inf, -inf, -6.588, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2700, "visits": [1000.0, 1000.0, 435.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2630, "q_vals": [-inf, -inf, -6.573, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
 q_vals: [-inf, -inf, -6.581, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796]
{ "step": 2702, "visits": [1000.0, 1000.0, 437.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2634, "q_vals": [-inf, -inf, -6.588, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2636, "number_of_timesteps": 258158, "per_episode_reward": -453.14, "episode_reward_trend_value": -0.015046213161904612, "biggest_recent_change": 0.5484962865683656},
{ "step": 2703, "visits": [1000.0, 1000.0, 438.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2636, "q_vals": [-inf, -inf, -6.595, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2704, "visits": [1000.0, 1000.0, 439.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2636, "q_vals": [-inf, -inf, -6.603, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2705, "visits": [1000.0, 1000.0, 440.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2637, "q_vals": [-inf, -inf, -6.588, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2706, "visits": [1000.0, 1000.0, 441.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2638, "q_vals": [-inf, -inf, -6.573, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2707, "visits": [1000.0, 1000.0, 442.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2640, "q_vals": [-inf, -inf, -6.558, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2708, "visits": [1000.0, 1000.0, 443.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2640, "q_vals": [-inf, -inf, -6.565, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2709, "visits": [1000.0, 1000.0, 444.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2641, "q_vals": [-inf, -inf, -6.572, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2710, "visits": [1000.0, 1000.0, 445.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2643, "q_vals": [-inf, -inf, -6.558, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2646, "number_of_timesteps": 258939, "per_episode_reward": -453.17, "episode_reward_trend_value": -0.009564814952009077, "biggest_recent_change": 0.5484962865683656},
{ "step": 2711, "visits": [1000.0, 1000.0, 446.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2646, "q_vals": [-inf, -inf, -6.565, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2712, "visits": [1000.0, 1000.0, 447.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2647, "q_vals": [-inf, -inf, -6.572, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2713, "visits": [1000.0, 1000.0, 448.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2649, "q_vals": [-inf, -inf, -6.557, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2714, "visits": [1000.0, 1000.0, 449.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2649, "q_vals": [-inf, -inf, -6.543, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2715, "visits": [1000.0, 1000.0, 450.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2649, "q_vals": [-inf, -inf, -6.528, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2716, "visits": [1000.0, 1000.0, 451.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2650, "q_vals": [-inf, -inf, -6.535, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2717, "visits": [1000.0, 1000.0, 452.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2650, "q_vals": [-inf, -inf, -6.521, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2718, "visits": [1000.0, 1000.0, 453.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2652, "q_vals": [-inf, -inf, -6.507, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2719, "visits": [1000.0, 1000.0, 454.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2653, "q_vals": [-inf, -inf, -6.492, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2720, "visits": [1000.0, 1000.0, 455.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2655, "q_vals": [-inf, -inf, -6.5, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2656, "number_of_timesteps": 259733, "per_episode_reward": -453.31, "episode_reward_trend_value": -0.005041497449142045, "biggest_recent_change": 0.5224951780978131},
{ "step": 2721, "visits": [1000.0, 1000.0, 456.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2656, "q_vals": [-inf, -inf, -6.507, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2722, "visits": [1000.0, 1000.0, 457.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2658, "q_vals": [-inf, -inf, -6.514, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2723, "visits": [1000.0, 1000.0, 458.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2658, "q_vals": [-inf, -inf, -6.521, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2724, "visits": [1000.0, 1000.0, 459.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2660, "q_vals": [-inf, -inf, -6.528, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2725, "visits": [1000.0, 1000.0, 460.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2662, "q_vals": [-inf, -inf, -6.535, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2726, "visits": [1000.0, 1000.0, 461.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2662, "q_vals": [-inf, -inf, -6.542, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2727, "visits": [1000.0, 1000.0, 462.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2663, "q_vals": [-inf, -inf, -6.55, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2728, "visits": [1000.0, 1000.0, 463.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2663, "q_vals": [-inf, -inf, -6.557, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2729, "visits": [1000.0, 1000.0, 464.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2665, "q_vals": [-inf, -inf, -6.563, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2666, "number_of_timesteps": 260537, "per_episode_reward": -453.53, "episode_reward_trend_value": -0.0016636288922711629, "biggest_recent_change": 0.310362121083017},
{ "step": 2730, "visits": [1000.0, 1000.0, 465.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2666, "q_vals": [-inf, -inf, -6.57, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2731, "visits": [1000.0, 1000.0, 466.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2668, "q_vals": [-inf, -inf, -6.577, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2732, "visits": [1000.0, 1000.0, 467.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2670, "q_vals": [-inf, -inf, -6.584, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2733, "visits": [1000.0, 1000.0, 468.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2670, "q_vals": [-inf, -inf, -6.57, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }

{ "step": 2734, "visits": [1000.0, 1000.0, 469.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2670, "q_vals": [-inf, -inf, -6.577, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2735, "visits": [1000.0, 1000.0, 470.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2671, "q_vals": [-inf, -inf, -6.584, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2736, "visits": [1000.0, 1000.0, 471.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2671, "q_vals": [-inf, -inf, -6.57, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2737, "visits": [1000.0, 1000.0, 472.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2674, "q_vals": [-inf, -inf, -6.577, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2678, "number_of_timesteps": 261566, "per_episode_reward": -453.73, "episode_reward_trend_value": -0.0028336938838486327, "biggest_recent_change": 0.310362121083017},
{ "step": 2738, "visits": [1000.0, 1000.0, 473.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2678, "q_vals": [-inf, -inf, -6.563, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2739, "visits": [1000.0, 1000.0, 474.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2678, "q_vals": [-inf, -inf, -6.57, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2740, "visits": [1000.0, 1000.0, 475.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2680, "q_vals": [-inf, -inf, -6.576, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2741, "visits": [1000.0, 1000.0, 476.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2680, "q_vals": [-inf, -inf, -6.583, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2742, "visits": [1000.0, 1000.0, 477.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2680, "q_vals": [-inf, -inf, -6.569, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2743, "visits": [1000.0, 1000.0, 478.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2681, "q_vals": [-inf, -inf, -6.556, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2744, "visits": [1000.0, 1000.0, 479.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2681, "q_vals": [-inf, -inf, -6.562, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2745, "visits": [1000.0, 1000.0, 480.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2682, "q_vals": [-inf, -inf, -6.549, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2746, "visits": [1000.0, 1000.0, 481.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2683, "q_vals": [-inf, -inf, -6.535, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2747, "visits": [1000.0, 1000.0, 482.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2685, "q_vals": [-inf, -inf, -6.522, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2748, "visits": [1000.0, 1000.0, 483.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2685, "q_vals": [-inf, -inf, -6.528, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2749, "visits": [1000.0, 1000.0, 484.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2685, "q_vals": [-inf, -inf, -6.535, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2750, "visits": [1000.0, 1000.0, 485.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2686, "q_vals": [-inf, -inf, -6.542, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2689, "number_of_timesteps": 262598, "per_episode_reward": -454.12, "episode_reward_trend_value": -0.008763030748387893, "biggest_recent_change": 0.3885240205215723},
{ "step": 2751, "visits": [1000.0, 1000.0, 486.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2689, "q_vals": [-inf, -inf, -6.549, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2752, "visits": [1000.0, 1000.0, 487.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2690, "q_vals": [-inf, -inf, -6.535, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2753, "visits": [1000.0, 1000.0, 488.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2691, "q_vals": [-inf, -inf, -6.542, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2754, "visits": [1000.0, 1000.0, 489.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2692, "q_vals": [-inf, -inf, -6.548, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2755, "visits": [1000.0, 1000.0, 490.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2692, "q_vals": [-inf, -inf, -6.535, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2756, "visits": [1000.0, 1000.0, 491.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2694, "q_vals": [-inf, -inf, -6.522, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2757, "visits": [1000.0, 1000.0, 492.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2694, "q_vals": [-inf, -inf, -6.528, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2758, "visits": [1000.0, 1000.0, 493.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2694, "q_vals": [-inf, -inf, -6.535, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2759, "visits": [1000.0, 1000.0, 494.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2695, "q_vals": [-inf, -inf, -6.542, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2760, "visits": [1000.0, 1000.0, 495.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2695, "q_vals": [-inf, -inf, -6.548, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2761, "visits": [1000.0, 1000.0, 496.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2696, "q_vals": [-inf, -inf, -6.555, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2762, "visits": [1000.0, 1000.0, 497.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2697, "q_vals": [-inf, -inf, -6.542, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2763, "visits": [1000.0, 1000.0, 498.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2698, "q_vals": [-inf, -inf, -6.548, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2699, "number_of_timesteps": 263589, "per_episode_reward": -454.45, "episode_reward_trend_value": -0.015905641326844487, "biggest_recent_change": 0.3885240205215723},
{ "step": 2764, "visits": [1000.0, 1000.0, 499.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2699, "q_vals": [-inf, -inf, -6.555, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2765, "visits": [1000.0, 1000.0, 500.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2700, "q_vals": [-inf, -inf, -6.542, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2766, "visits": [1000.0, 1000.0, 501.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2703, "q_vals": [-inf, -inf, -6.548, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
[-inf, -inf, -6.555, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796]
{ "step": 2768, "visits": [1000.0, 1000.0, 503.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2704, "q_vals": [-inf, -inf, -6.541, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2769, "visits": [1000.0, 1000.0, 504.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2704, "q_vals": [-inf, -inf, -6.548, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2770, "visits": [1000.0, 1000.0, 505.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2704, "q_vals": [-inf, -inf, -6.535, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2771, "visits": [1000.0, 1000.0, 506.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2705, "q_vals": [-inf, -inf, -6.541, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2772, "visits": [1000.0, 1000.0, 507.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2708, "q_vals": [-inf, -inf, -6.529, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2709, "number_of_timesteps": 264671, "per_episode_reward": -454.99, "episode_reward_trend_value": -0.01945472717349806, "biggest_recent_change": 0.5392585868921742},
{ "step": 2773, "visits": [1000.0, 1000.0, 508.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2709, "q_vals": [-inf, -inf, -6.535, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2774, "visits": [1000.0, 1000.0, 509.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2709, "q_vals": [-inf, -inf, -6.522, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2775, "visits": [1000.0, 1000.0, 510.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2710, "q_vals": [-inf, -inf, -6.529, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2776, "visits": [1000.0, 1000.0, 511.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2711, "q_vals": [-inf, -inf, -6.535, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2777, "visits": [1000.0, 1000.0, 512.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2713, "q_vals": [-inf, -inf, -6.541, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2778, "visits": [1000.0, 1000.0, 513.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2713, "q_vals": [-inf, -inf, -6.548, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2779, "visits": [1000.0, 1000.0, 514.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2714, "q_vals": [-inf, -inf, -6.535, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2780, "visits": [1000.0, 1000.0, 515.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2714, "q_vals": [-inf, -inf, -6.541, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2781, "visits": [1000.0, 1000.0, 516.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2716, "q_vals": [-inf, -inf, -6.548, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2782, "visits": [1000.0, 1000.0, 517.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2716, "q_vals": [-inf, -inf, -6.554, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2783, "visits": [1000.0, 1000.0, 518.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2718, "q_vals": [-inf, -inf, -6.56, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2719, "number_of_timesteps": 265634, "per_episode_reward": -455.23, "episode_reward_trend_value": -0.022646639344894005, "biggest_recent_change": 0.5392585868921742},
{ "step": 2784, "visits": [1000.0, 1000.0, 519.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2719, "q_vals": [-inf, -inf, -6.566, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2785, "visits": [1000.0, 1000.0, 520.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2722, "q_vals": [-inf, -inf, -6.573, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2786, "visits": [1000.0, 1000.0, 521.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2722, "q_vals": [-inf, -inf, -6.56, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2787, "visits": [1000.0, 1000.0, 522.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2724, "q_vals": [-inf, -inf, -6.566, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2788, "visits": [1000.0, 1000.0, 523.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2725, "q_vals": [-inf, -inf, -6.554, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2789, "visits": [1000.0, 1000.0, 524.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2726, "q_vals": [-inf, -inf, -6.56, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2790, "visits": [1000.0, 1000.0, 525.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2726, "q_vals": [-inf, -inf, -6.566, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2791, "visits": [1000.0, 1000.0, 526.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2726, "q_vals": [-inf, -inf, -6.572, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2792, "visits": [1000.0, 1000.0, 527.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2727, "q_vals": [-inf, -inf, -6.56, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2730, "number_of_timesteps": 266619, "per_episode_reward": -455.19, "episode_reward_trend_value": -0.02278274967302486, "biggest_recent_change": 0.5392585868921742},
{ "step": 2793, "visits": [1000.0, 1000.0, 528.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2730, "q_vals": [-inf, -inf, -6.566, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2794, "visits": [1000.0, 1000.0, 529.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2731, "q_vals": [-inf, -inf, -6.572, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2795, "visits": [1000.0, 1000.0, 530.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2732, "q_vals": [-inf, -inf, -6.578, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2796, "visits": [1000.0, 1000.0, 531.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2732, "q_vals": [-inf, -inf, -6.584, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2797, "visits": [1000.0, 1000.0, 532.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2734, "q_vals": [-inf, -inf, -6.59, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2798, "visits": [1000.0, 1000.0, 533.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2734, "q_vals": [-inf, -inf, -6.596, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2799, "visits": [1000.0, 1000.0, 534.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2735, "q_vals": [-inf, -inf, -6.584, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
[-inf, -inf, -6.571, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796]
{ "step": 2801, "visits": [1000.0, 1000.0, 536.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2736, "q_vals": [-inf, -inf, -6.577, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2802, "visits": [1000.0, 1000.0, 537.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2739, "q_vals": [-inf, -inf, -6.583, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2803, "visits": [1000.0, 1000.0, 538.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2739, "q_vals": [-inf, -inf, -6.571, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2741, "number_of_timesteps": 267597, "per_episode_reward": -455.72, "episode_reward_trend_value": -0.02831161322115842, "biggest_recent_change": 0.5392585868921742},
{ "step": 2804, "visits": [1000.0, 1000.0, 539.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2741, "q_vals": [-inf, -inf, -6.577, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2805, "visits": [1000.0, 1000.0, 540.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2742, "q_vals": [-inf, -inf, -6.583, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2806, "visits": [1000.0, 1000.0, 541.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2743, "q_vals": [-inf, -inf, -6.571, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2807, "visits": [1000.0, 1000.0, 542.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2743, "q_vals": [-inf, -inf, -6.577, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2808, "visits": [1000.0, 1000.0, 543.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2743, "q_vals": [-inf, -inf, -6.583, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2809, "visits": [1000.0, 1000.0, 544.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2744, "q_vals": [-inf, -inf, -6.589, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2810, "visits": [1000.0, 1000.0, 545.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2745, "q_vals": [-inf, -inf, -6.595, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2811, "visits": [1000.0, 1000.0, 546.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2747, "q_vals": [-inf, -inf, -6.6, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2812, "visits": [1000.0, 1000.0, 547.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2747, "q_vals": [-inf, -inf, -6.588, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2813, "visits": [1000.0, 1000.0, 548.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2750, "q_vals": [-inf, -inf, -6.594, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2751, "number_of_timesteps": 268513, "per_episode_reward": -456.15, "episode_reward_trend_value": -0.03152440950816905, "biggest_recent_change": 0.5392585868921742},
{ "step": 2814, "visits": [1000.0, 1000.0, 549.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2751, "q_vals": [-inf, -inf, -6.6, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2815, "visits": [1000.0, 1000.0, 550.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2751, "q_vals": [-inf, -inf, -6.606, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2816, "visits": [1000.0, 1000.0, 551.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2751, "q_vals": [-inf, -inf, -6.612, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2817, "visits": [1000.0, 1000.0, 552.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2752, "q_vals": [-inf, -inf, -6.617, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2818, "visits": [1000.0, 1000.0, 553.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2753, "q_vals": [-inf, -inf, -6.623, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2819, "visits": [1000.0, 1000.0, 554.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2753, "q_vals": [-inf, -inf, -6.629, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2820, "visits": [1000.0, 1000.0, 555.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2754, "q_vals": [-inf, -inf, -6.635, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2821, "visits": [1000.0, 1000.0, 556.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2754, "q_vals": [-inf, -inf, -6.64, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2822, "visits": [1000.0, 1000.0, 557.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2755, "q_vals": [-inf, -inf, -6.646, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2823, "visits": [1000.0, 1000.0, 558.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2755, "q_vals": [-inf, -inf, -6.652, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2824, "visits": [1000.0, 1000.0, 559.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2757, "q_vals": [-inf, -inf, -6.657, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2825, "visits": [1000.0, 1000.0, 560.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2758, "q_vals": [-inf, -inf, -6.663, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2826, "visits": [1000.0, 1000.0, 561.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2759, "q_vals": [-inf, -inf, -6.651, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2827, "visits": [1000.0, 1000.0, 562.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2760, "q_vals": [-inf, -inf, -6.657, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2762, "number_of_timesteps": 269900, "per_episode_reward": -456.79, "episode_reward_trend_value": -0.03621432347690959, "biggest_recent_change": 0.6405792651660818},
{ "step": 2828, "visits": [1000.0, 1000.0, 563.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2762, "q_vals": [-inf, -inf, -6.645, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2829, "visits": [1000.0, 1000.0, 564.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2762, "q_vals": [-inf, -inf, -6.65, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2830, "visits": [1000.0, 1000.0, 565.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2763, "q_vals": [-inf, -inf, -6.656, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2831, "visits": [1000.0, 1000.0, 566.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2763, "q_vals": [-inf, -inf, -6.661, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2832, "visits": [1000.0, 1000.0, 567.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2763, "q_vals": [-inf, -inf, -6.65, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2833, "visits": [1000.0, 1000.0, 568.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2764, "q_vals": [-inf, -inf, -6.655, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2834, "visits": [1000.0, 1000.0, 569.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2765, "q_vals": [-inf, -inf, -6.661, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2835, "visits": [1000.0, 1000.0, 570.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2765, "q_vals": [-inf, -inf, -6.649, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2836, "visits": [1000.0, 1000.0, 571.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2767, "q_vals": [-inf, -inf, -6.637, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2837, "visits": [1000.0, 1000.0, 572.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2769, "q_vals": [-inf, -inf, -6.643, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2838, "visits": [1000.0, 1000.0, 573.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2771, "q_vals": [-inf, -inf, -6.648, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2839, "visits": [1000.0, 1000.0, 574.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2771, "q_vals": [-inf, -inf, -6.654, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2840, "visits": [1000.0, 1000.0, 575.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2771, "q_vals": [-inf, -inf, -6.659, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2841, "visits": [1000.0, 1000.0, 576.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2771, "q_vals": [-inf, -inf, -6.665, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2772, "number_of_timesteps": 271007, "per_episode_reward": -456.82, "episode_reward_trend_value": -0.03431998715471359, "biggest_recent_change": 0.6405792651660818},
{ "step": 2842, "visits": [1000.0, 1000.0, 577.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2772, "q_vals": [-inf, -inf, -6.67, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2843, "visits": [1000.0, 1000.0, 578.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2776, "q_vals": [-inf, -inf, -6.659, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2844, "visits": [1000.0, 1000.0, 579.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2777, "q_vals": [-inf, -inf, -6.647, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2845, "visits": [1000.0, 1000.0, 580.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2780, "q_vals": [-inf, -inf, -6.653, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2846, "visits": [1000.0, 1000.0, 581.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2781, "q_vals": [-inf, -inf, -6.658, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2847, "visits": [1000.0, 1000.0, 582.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2781, "q_vals": [-inf, -inf, -6.663, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2782, "number_of_timesteps": 271875, "per_episode_reward": -456.79, "episode_reward_trend_value": -0.029676282929802435, "biggest_recent_change": 0.6405792651660818},
{ "step": 2848, "visits": [1000.0, 1000.0, 583.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2782, "q_vals": [-inf, -inf, -6.669, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2849, "visits": [1000.0, 1000.0, 584.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2784, "q_vals": [-inf, -inf, -6.657, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2850, "visits": [1000.0, 1000.0, 585.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2785, "q_vals": [-inf, -inf, -6.663, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2851, "visits": [1000.0, 1000.0, 586.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2787, "q_vals": [-inf, -inf, -6.668, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2852, "visits": [1000.0, 1000.0, 587.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2790, "q_vals": [-inf, -inf, -6.673, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2853, "visits": [1000.0, 1000.0, 588.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2790, "q_vals": [-inf, -inf, -6.662, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2854, "visits": [1000.0, 1000.0, 589.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2791, "q_vals": [-inf, -inf, -6.651, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2855, "visits": [1000.0, 1000.0, 590.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2791, "q_vals": [-inf, -inf, -6.639, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2792, "number_of_timesteps": 272549, "per_episode_reward": -456.69, "episode_reward_trend_value": -0.024891333732626385, "biggest_recent_change": 0.6405792651660818},
{ "step": 2856, "visits": [1000.0, 1000.0, 591.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2792, "q_vals": [-inf, -inf, -6.645, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2857, "visits": [1000.0, 1000.0, 592.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2793, "q_vals": [-inf, -inf, -6.65, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2858, "visits": [1000.0, 1000.0, 593.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2797, "q_vals": [-inf, -inf, -6.655, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2859, "visits": [1000.0, 1000.0, 594.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2798, "q_vals": [-inf, -inf, -6.661, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2860, "visits": [1000.0, 1000.0, 595.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2799, "q_vals": [-inf, -inf, -6.666, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2861, "visits": [1000.0, 1000.0, 596.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2800, "q_vals": [-inf, -inf, -6.655, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2862, "visits": [1000.0, 1000.0, 597.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2801, "q_vals": [-inf, -inf, -6.66, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2863, "visits": [1000.0, 1000.0, 598.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2801, "q_vals": [-inf, -inf, -6.649, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2803, "number_of_timesteps": 273366, "per_episode_reward": -456.75, "episode_reward_trend_value": -0.01958884076585529, "biggest_recent_change": 0.6405792651660818},
{ "step": 2864, "visits": [1000.0, 1000.0, 599.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2803, "q_vals": [-inf, -inf, -6.654, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2865, "visits": [1000.0, 1000.0, 600.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2806, "q_vals": [-inf, -inf, -6.659, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2866, "visits": [1000.0, 1000.0, 601.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2808, "q_vals": [-inf, -inf, -6.665, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2867, "visits": [1000.0, 1000.0, 602.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2810, "q_vals": [-inf, -inf, -6.67, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2868, "visits": [1000.0, 1000.0, 603.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2810, "q_vals": [-inf, -inf, -6.659, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2869, "visits": [1000.0, 1000.0, 604.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2810, "q_vals": [-inf, -inf, -6.664, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2870, "visits": [1000.0, 1000.0, 605.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2811, "q_vals": [-inf, -inf, -6.669, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2871, "visits": [1000.0, 1000.0, 606.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2812, "q_vals": [-inf, -inf, -6.674, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2815, "number_of_timesteps": 274169, "per_episode_reward": -456.8, "episode_reward_trend_value": -0.01740654502919104, "biggest_recent_change": 0.6405792651660818},
{ "step": 2872, "visits": [1000.0, 1000.0, 607.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2815, "q_vals": [-inf, -inf, -6.679, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2873, "visits": [1000.0, 1000.0, 608.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2818, "q_vals": [-inf, -inf, -6.685, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2874, "visits": [1000.0, 1000.0, 609.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2819, "q_vals": [-inf, -inf, -6.69, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2875, "visits": [1000.0, 1000.0, 610.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2820, "q_vals": [-inf, -inf, -6.695, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2876, "visits": [1000.0, 1000.0, 611.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2821, "q_vals": [-inf, -inf, -6.684, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2877, "visits": [1000.0, 1000.0, 612.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2821, "q_vals": [-inf, -inf, -6.689, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2878, "visits": [1000.0, 1000.0, 613.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2822, "q_vals": [-inf, -inf, -6.694, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2879, "visits": [1000.0, 1000.0, 614.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2824, "q_vals": [-inf, -inf, -6.699, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2880, "visits": [1000.0, 1000.0, 615.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2824, "q_vals": [-inf, -inf, -6.704, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2826, "number_of_timesteps": 274952, "per_episode_reward": -456.25, "episode_reward_trend_value": -0.011678209787300551, "biggest_recent_change": 0.6405792651660818},
{ "step": 2881, "visits": [1000.0, 1000.0, 616.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2826, "q_vals": [-inf, -inf, -6.693, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2882, "visits": [1000.0, 1000.0, 617.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2827, "q_vals": [-inf, -inf, -6.682, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2883, "visits": [1000.0, 1000.0, 618.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2829, "q_vals": [-inf, -inf, -6.687, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2884, "visits": [1000.0, 1000.0, 619.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2829, "q_vals": [-inf, -inf, -6.677, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2885, "visits": [1000.0, 1000.0, 620.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2831, "q_vals": [-inf, -inf, -6.666, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2886, "visits": [1000.0, 1000.0, 621.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2832, "q_vals": [-inf, -inf, -6.671, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2887, "visits": [1000.0, 1000.0, 622.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2833, "q_vals": [-inf, -inf, -6.66, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2888, "visits": [1000.0, 1000.0, 623.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2834, "q_vals": [-inf, -inf, -6.649, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2889, "visits": [1000.0, 1000.0, 624.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2834, "q_vals": [-inf, -inf, -6.654, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2890, "visits": [1000.0, 1000.0, 625.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2834, "q_vals": [-inf, -inf, -6.644, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2836, "number_of_timesteps": 275807, "per_episode_reward": -456.2, "episode_reward_trend_value": -0.005379598812985225, "biggest_recent_change": 0.6405792651660818},
{ "step": 2891, "visits": [1000.0, 1000.0, 626.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2836, "q_vals": [-inf, -inf, -6.649, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2892, "visits": [1000.0, 1000.0, 627.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2838, "q_vals": [-inf, -inf, -6.654, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2893, "visits": [1000.0, 1000.0, 628.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2839, "q_vals": [-inf, -inf, -6.659, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2894, "visits": [1000.0, 1000.0, 629.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2842, "q_vals": [-inf, -inf, -6.648, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2895, "visits": [1000.0, 1000.0, 630.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2843, "q_vals": [-inf, -inf, -6.638, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2896, "visits": [1000.0, 1000.0, 631.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2843, "q_vals": [-inf, -inf, -6.627, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2897, "visits": [1000.0, 1000.0, 632.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2844, "q_vals": [-inf, -inf, -6.617, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2898, "visits": [1000.0, 1000.0, 633.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2845, "q_vals": [-inf, -inf, -6.622, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2846, "number_of_timesteps": 276661, "per_episode_reward": -456.84, "episode_reward_trend_value": -0.007714801486899761, "biggest_recent_change": 0.640717617793598},
{ "step": 2899, "visits": [1000.0, 1000.0, 634.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2846, "q_vals": [-inf, -inf, -6.627, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2900, "visits": [1000.0, 1000.0, 635.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2847, "q_vals": [-inf, -inf, -6.616, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2901, "visits": [1000.0, 1000.0, 636.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2848, "q_vals": [-inf, -inf, -6.621, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2902, "visits": [1000.0, 1000.0, 637.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2849, "q_vals": [-inf, -inf, -6.611, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2903, "visits": [1000.0, 1000.0, 638.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2850, "q_vals": [-inf, -inf, -6.616, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2904, "visits": [1000.0, 1000.0, 639.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2851, "q_vals": [-inf, -inf, -6.606, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2905, "visits": [1000.0, 1000.0, 640.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2853, "q_vals": [-inf, -inf, -6.611, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2906, "visits": [1000.0, 1000.0, 641.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2853, "q_vals": [-inf, -inf, -6.616, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2907, "visits": [1000.0, 1000.0, 642.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2853, "q_vals": [-inf, -inf, -6.62, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2908, "visits": [1000.0, 1000.0, 643.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2855, "q_vals": [-inf, -inf, -6.625, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2857, "number_of_timesteps": 277666, "per_episode_reward": -457.63, "episode_reward_trend_value": -0.009412951771227224, "biggest_recent_change": 0.7934127907555535},
{ "step": 2909, "visits": [1000.0, 1000.0, 644.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2857, "q_vals": [-inf, -inf, -6.63, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2910, "visits": [1000.0, 1000.0, 645.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2857, "q_vals": [-inf, -inf, -6.62, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2911, "visits": [1000.0, 1000.0, 646.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2857, "q_vals": [-inf, -inf, -6.625, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2912, "visits": [1000.0, 1000.0, 647.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2858, "q_vals": [-inf, -inf, -6.63, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2913, "visits": [1000.0, 1000.0, 648.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2858, "q_vals": [-inf, -inf, -6.635, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2914, "visits": [1000.0, 1000.0, 649.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2858, "q_vals": [-inf, -inf, -6.64, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2915, "visits": [1000.0, 1000.0, 650.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2859, "q_vals": [-inf, -inf, -6.645, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2916, "visits": [1000.0, 1000.0, 651.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2861, "q_vals": [-inf, -inf, -6.649, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2917, "visits": [1000.0, 1000.0, 652.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2862, "q_vals": [-inf, -inf, -6.639, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2918, "visits": [1000.0, 1000.0, 653.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2863, "q_vals": [-inf, -inf, -6.644, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2919, "visits": [1000.0, 1000.0, 654.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2864, "q_vals": [-inf, -inf, -6.634, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2920, "visits": [1000.0, 1000.0, 655.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2865, "q_vals": [-inf, -inf, -6.639, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2921, "visits": [1000.0, 1000.0, 656.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2866, "q_vals": [-inf, -inf, -6.629, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2922, "visits": [1000.0, 1000.0, 657.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2866, "q_vals": [-inf, -inf, -6.633, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2867, "number_of_timesteps": 278809, "per_episode_reward": -457.8, "episode_reward_trend_value": -0.010973372384167608, "biggest_recent_change": 0.7934127907555535},
{ "step": 2923, "visits": [1000.0, 1000.0, 658.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2867, "q_vals": [-inf, -inf, -6.638, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2924, "visits": [1000.0, 1000.0, 659.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2868, "q_vals": [-inf, -inf, -6.643, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2925, "visits": [1000.0, 1000.0, 660.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2869, "q_vals": [-inf, -inf, -6.633, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2926, "visits": [1000.0, 1000.0, 661.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2870, "q_vals": [-inf, -inf, -6.638, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2927, "visits": [1000.0, 1000.0, 662.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2872, "q_vals": [-inf, -inf, -6.628, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2928, "visits": [1000.0, 1000.0, 663.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2873, "q_vals": [-inf, -inf, -6.632, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2929, "visits": [1000.0, 1000.0, 664.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2874, "q_vals": [-inf, -inf, -6.622, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2930, "visits": [1000.0, 1000.0, 665.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2875, "q_vals": [-inf, -inf, -6.612, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2931, "visits": [1000.0, 1000.0, 666.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2875, "q_vals": [-inf, -inf, -6.603, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2932, "visits": [1000.0, 1000.0, 667.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2875, "q_vals": [-inf, -inf, -6.607, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2877, "number_of_timesteps": 279793, "per_episode_reward": -459.06, "episode_reward_trend_value": -0.025303741571522348, "biggest_recent_change": 1.2603238671414942},
{ "step": 2933, "visits": [1000.0, 1000.0, 668.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2877, "q_vals": [-inf, -inf, -6.612, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2934, "visits": [1000.0, 1000.0, 669.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2880, "q_vals": [-inf, -inf, -6.617, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2935, "visits": [1000.0, 1000.0, 670.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2881, "q_vals": [-inf, -inf, -6.622, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2936, "visits": [1000.0, 1000.0, 671.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2882, "q_vals": [-inf, -inf, -6.612, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2937, "visits": [1000.0, 1000.0, 672.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2883, "q_vals": [-inf, -inf, -6.616, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2938, "visits": [1000.0, 1000.0, 673.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2883, "q_vals": [-inf, -inf, -6.607, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2939, "visits": [1000.0, 1000.0, 674.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2883, "q_vals": [-inf, -inf, -6.611, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2940, "visits": [1000.0, 1000.0, 675.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2883, "q_vals": [-inf, -inf, -6.616, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2941, "visits": [1000.0, 1000.0, 676.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2885, "q_vals": [-inf, -inf, -6.621, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2887, "number_of_timesteps": 280735, "per_episode_reward": -458.36, "episode_reward_trend_value": -0.018569910882777346, "biggest_recent_change": 1.2603238671414942},
{ "step": 2942, "visits": [1000.0, 1000.0, 677.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2887, "q_vals": [-inf, -inf, -6.611, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2943, "visits": [1000.0, 1000.0, 678.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2888, "q_vals": [-inf, -inf, -6.616, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2944, "visits": [1000.0, 1000.0, 679.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2890, "q_vals": [-inf, -inf, -6.62, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2945, "visits": [1000.0, 1000.0, 680.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2891, "q_vals": [-inf, -inf, -6.625, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2946, "visits": [1000.0, 1000.0, 681.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2892, "q_vals": [-inf, -inf, -6.63, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2947, "visits": [1000.0, 1000.0, 682.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2893, "q_vals": [-inf, -inf, -6.634, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2948, "visits": [1000.0, 1000.0, 683.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2893, "q_vals": [-inf, -inf, -6.639, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2949, "visits": [1000.0, 1000.0, 684.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2893, "q_vals": [-inf, -inf, -6.644, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2950, "visits": [1000.0, 1000.0, 685.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2893, "q_vals": [-inf, -inf, -6.634, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2951, "visits": [1000.0, 1000.0, 686.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2895, "q_vals": [-inf, -inf, -6.639, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2897, "number_of_timesteps": 281637, "per_episode_reward": -458.76, "episode_reward_trend_value": -0.022280193392211028, "biggest_recent_change": 1.2603238671414942},
{ "step": 2952, "visits": [1000.0, 1000.0, 687.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2897, "q_vals": [-inf, -inf, -6.643, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2953, "visits": [1000.0, 1000.0, 688.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2897, "q_vals": [-inf, -inf, -6.648, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2954, "visits": [1000.0, 1000.0, 689.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2899, "q_vals": [-inf, -inf, -6.652, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2955, "visits": [1000.0, 1000.0, 690.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2901, "q_vals": [-inf, -inf, -6.643, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2956, "visits": [1000.0, 1000.0, 691.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2902, "q_vals": [-inf, -inf, -6.647, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2957, "visits": [1000.0, 1000.0, 692.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2903, "q_vals": [-inf, -inf, -6.652, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2958, "visits": [1000.0, 1000.0, 693.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2903, "q_vals": [-inf, -inf, -6.656, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2959, "visits": [1000.0, 1000.0, 694.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2905, "q_vals": [-inf, -inf, -6.661, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2960, "visits": [1000.0, 1000.0, 695.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2906, "q_vals": [-inf, -inf, -6.665, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2907, "number_of_timesteps": 282576, "per_episode_reward": -459.48, "episode_reward_trend_value": -0.029802571584078424, "biggest_recent_change": 1.2603238671414942},
{ "step": 2961, "visits": [1000.0, 1000.0, 696.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2907, "q_vals": [-inf, -inf, -6.67, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2962, "visits": [1000.0, 1000.0, 697.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2908, "q_vals": [-inf, -inf, -6.674, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2963, "visits": [1000.0, 1000.0, 698.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2911, "q_vals": [-inf, -inf, -6.665, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2964, "visits": [1000.0, 1000.0, 699.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2912, "q_vals": [-inf, -inf, -6.669, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2965, "visits": [1000.0, 1000.0, 700.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2912, "q_vals": [-inf, -inf, -6.674, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2966, "visits": [1000.0, 1000.0, 701.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2915, "q_vals": [-inf, -inf, -6.678, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2967, "visits": [1000.0, 1000.0, 702.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2916, "q_vals": [-inf, -inf, -6.683, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2917, "number_of_timesteps": 283335, "per_episode_reward": -459.42, "episode_reward_trend_value": -0.03523036552209457, "biggest_recent_change": 1.2603238671414942},
{ "step": 2968, "visits": [1000.0, 1000.0, 703.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2917, "q_vals": [-inf, -inf, -6.687, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2969, "visits": [1000.0, 1000.0, 704.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2917, "q_vals": [-inf, -inf, -6.691, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2970, "visits": [1000.0, 1000.0, 705.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2918, "q_vals": [-inf, -inf, -6.682, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2971, "visits": [1000.0, 1000.0, 706.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2919, "q_vals": [-inf, -inf, -6.686, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2972, "visits": [1000.0, 1000.0, 707.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2919, "q_vals": [-inf, -inf, -6.691, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2973, "visits": [1000.0, 1000.0, 708.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2923, "q_vals": [-inf, -inf, -6.681, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2974, "visits": [1000.0, 1000.0, 709.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2925, "q_vals": [-inf, -inf, -6.686, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2975, "visits": [1000.0, 1000.0, 710.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2926, "q_vals": [-inf, -inf, -6.676, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2927, "number_of_timesteps": 284129, "per_episode_reward": -460.01, "episode_reward_trend_value": -0.0423609145382904, "biggest_recent_change": 1.2603238671414942},
{ "step": 2976, "visits": [1000.0, 1000.0, 711.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2927, "q_vals": [-inf, -inf, -6.681, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2977, "visits": [1000.0, 1000.0, 712.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2928, "q_vals": [-inf, -inf, -6.685, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2978, "visits": [1000.0, 1000.0, 713.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2929, "q_vals": [-inf, -inf, -6.689, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2979, "visits": [1000.0, 1000.0, 714.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2929, "q_vals": [-inf, -inf, -6.694, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2980, "visits": [1000.0, 1000.0, 715.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2929, "q_vals": [-inf, -inf, -6.698, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2981, "visits": [1000.0, 1000.0, 716.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2932, "q_vals": [-inf, -inf, -6.702, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2982, "visits": [1000.0, 1000.0, 717.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2933, "q_vals": [-inf, -inf, -6.707, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2983, "visits": [1000.0, 1000.0, 718.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2935, "q_vals": [-inf, -inf, -6.711, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2984, "visits": [1000.0, 1000.0, 719.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2936, "q_vals": [-inf, -inf, -6.715, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2939, "number_of_timesteps": 285058, "per_episode_reward": -460.24, "episode_reward_trend_value": -0.037733175047607245, "biggest_recent_change": 1.2603238671414942},
{ "step": 2985, "visits": [1000.0, 1000.0, 720.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2939, "q_vals": [-inf, -inf, -6.72, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2986, "visits": [1000.0, 1000.0, 721.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2939, "q_vals": [-inf, -inf, -6.724, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2987, "visits": [1000.0, 1000.0, 722.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2940, "q_vals": [-inf, -inf, -6.728, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2988, "visits": [1000.0, 1000.0, 723.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2943, "q_vals": [-inf, -inf, -6.732, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2989, "visits": [1000.0, 1000.0, 724.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2944, "q_vals": [-inf, -inf, -6.737, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2990, "visits": [1000.0, 1000.0, 725.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2945, "q_vals": [-inf, -inf, -6.727, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2991, "visits": [1000.0, 1000.0, 726.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2945, "q_vals": [-inf, -inf, -6.732, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2992, "visits": [1000.0, 1000.0, 727.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2945, "q_vals": [-inf, -inf, -6.722, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2949, "number_of_timesteps": 285704, "per_episode_reward": -459.7, "episode_reward_trend_value": -0.022891823129367595, "biggest_recent_change": 1.2603238671414942},
{ "step": 2993, "visits": [1000.0, 1000.0, 728.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2949, "q_vals": [-inf, -inf, -6.713, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2994, "visits": [1000.0, 1000.0, 729.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2951, "q_vals": [-inf, -inf, -6.717, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2995, "visits": [1000.0, 1000.0, 730.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2953, "q_vals": [-inf, -inf, -6.721, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2996, "visits": [1000.0, 1000.0, 731.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2954, "q_vals": [-inf, -inf, -6.726, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
visits [1000.0, 1000.0, 732.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 2955 q_vals: [-inf, -inf, -6.717, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796]
{ "step": 2998, "visits": [1000.0, 1000.0, 733.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2955, "q_vals": [-inf, -inf, -6.707, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 2999, "visits": [1000.0, 1000.0, 734.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2955, "q_vals": [-inf, -inf, -6.698, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3000, "visits": [1000.0, 1000.0, 735.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2956, "q_vals": [-inf, -inf, -6.702, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3001, "visits": [1000.0, 1000.0, 736.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2958, "q_vals": [-inf, -inf, -6.707, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2961, "number_of_timesteps": 286555, "per_episode_reward": -459.42, "episode_reward_trend_value": -0.018006604467890007, "biggest_recent_change": 1.2603238671414942},
{ "step": 3002, "visits": [1000.0, 1000.0, 737.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2961, "q_vals": [-inf, -inf, -6.711, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3003, "visits": [1000.0, 1000.0, 738.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2962, "q_vals": [-inf, -inf, -6.715, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3004, "visits": [1000.0, 1000.0, 739.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2964, "q_vals": [-inf, -inf, -6.719, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3005, "visits": [1000.0, 1000.0, 740.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2964, "q_vals": [-inf, -inf, -6.723, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3006, "visits": [1000.0, 1000.0, 741.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2965, "q_vals": [-inf, -inf, -6.714, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3007, "visits": [1000.0, 1000.0, 742.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2967, "q_vals": [-inf, -inf, -6.718, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3008, "visits": [1000.0, 1000.0, 743.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2968, "q_vals": [-inf, -inf, -6.723, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3009, "visits": [1000.0, 1000.0, 744.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2969, "q_vals": [-inf, -inf, -6.727, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2971, "number_of_timesteps": 287279, "per_episode_reward": -459.62, "episode_reward_trend_value": -0.0062247915255151534, "biggest_recent_change": 0.7243259038782526},
{ "step": 3010, "visits": [1000.0, 1000.0, 745.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2971, "q_vals": [-inf, -inf, -6.731, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3011, "visits": [1000.0, 1000.0, 746.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2974, "q_vals": [-inf, -inf, -6.735, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3012, "visits": [1000.0, 1000.0, 747.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2974, "q_vals": [-inf, -inf, -6.726, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3013, "visits": [1000.0, 1000.0, 748.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2975, "q_vals": [-inf, -inf, -6.717, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3014, "visits": [1000.0, 1000.0, 749.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2976, "q_vals": [-inf, -inf, -6.721, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3015, "visits": [1000.0, 1000.0, 750.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2976, "q_vals": [-inf, -inf, -6.725, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3016, "visits": [1000.0, 1000.0, 751.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2977, "q_vals": [-inf, -inf, -6.729, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3017, "visits": [1000.0, 1000.0, 752.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2980, "q_vals": [-inf, -inf, -6.733, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2983, "number_of_timesteps": 288136, "per_episode_reward": -458.84, "episode_reward_trend_value": -0.005336309296535546, "biggest_recent_change": 0.7841807593629824},
{ "step": 3018, "visits": [1000.0, 1000.0, 753.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2983, "q_vals": [-inf, -inf, -6.724, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3019, "visits": [1000.0, 1000.0, 754.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2983, "q_vals": [-inf, -inf, -6.728, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3020, "visits": [1000.0, 1000.0, 755.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2984, "q_vals": [-inf, -inf, -6.732, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3021, "visits": [1000.0, 1000.0, 756.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2984, "q_vals": [-inf, -inf, -6.737, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3022, "visits": [1000.0, 1000.0, 757.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2986, "q_vals": [-inf, -inf, -6.741, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3023, "visits": [1000.0, 1000.0, 758.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2988, "q_vals": [-inf, -inf, -6.745, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3024, "visits": [1000.0, 1000.0, 759.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2990, "q_vals": [-inf, -inf, -6.749, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3025, "visits": [1000.0, 1000.0, 760.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2990, "q_vals": [-inf, -inf, -6.74, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3026, "visits": [1000.0, 1000.0, 761.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2991, "q_vals": [-inf, -inf, -6.744, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 2993, "number_of_timesteps": 288884, "per_episode_reward": -459.03, "episode_reward_trend_value": -0.0030021674123550685, "biggest_recent_change": 0.7841807593629824},
{ "step": 3027, "visits": [1000.0, 1000.0, 762.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2993, "q_vals": [-inf, -inf, -6.748, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3028, "visits": [1000.0, 1000.0, 763.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2994, "q_vals": [-inf, -inf, -6.752, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
[-inf, -inf, -6.756, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796]
{ "step": 3030, "visits": [1000.0, 1000.0, 765.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 2995, "q_vals": [-inf, -inf, -6.76, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3031, "visits": [1000.0, 1000.0, 766.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3001, "q_vals": [-inf, -inf, -6.751, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3032, "visits": [1000.0, 1000.0, 767.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3001, "q_vals": [-inf, -inf, -6.742, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3033, "visits": [1000.0, 1000.0, 768.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3002, "q_vals": [-inf, -inf, -6.746, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3003, "number_of_timesteps": 289577, "per_episode_reward": -459.3, "episode_reward_trend_value": 0.001955112007284596, "biggest_recent_change": 0.7841807593629824},
{ "step": 3034, "visits": [1000.0, 1000.0, 769.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3003, "q_vals": [-inf, -inf, -6.75, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3035, "visits": [1000.0, 1000.0, 770.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3004, "q_vals": [-inf, -inf, -6.741, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3036, "visits": [1000.0, 1000.0, 771.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3004, "q_vals": [-inf, -inf, -6.745, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3037, "visits": [1000.0, 1000.0, 772.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3006, "q_vals": [-inf, -inf, -6.736, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3038, "visits": [1000.0, 1000.0, 773.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3007, "q_vals": [-inf, -inf, -6.74, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3039, "visits": [1000.0, 1000.0, 774.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3010, "q_vals": [-inf, -inf, -6.744, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3013, "number_of_timesteps": 290276, "per_episode_reward": -459.17, "episode_reward_trend_value": 0.0027070119504748564, "biggest_recent_change": 0.7841807593629824},
{ "step": 3040, "visits": [1000.0, 1000.0, 775.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3013, "q_vals": [-inf, -inf, -6.748, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3041, "visits": [1000.0, 1000.0, 776.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3013, "q_vals": [-inf, -inf, -6.752, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3042, "visits": [1000.0, 1000.0, 777.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3013, "q_vals": [-inf, -inf, -6.756, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3043, "visits": [1000.0, 1000.0, 778.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3015, "q_vals": [-inf, -inf, -6.747, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3044, "visits": [1000.0, 1000.0, 779.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3017, "q_vals": [-inf, -inf, -6.751, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3045, "visits": [1000.0, 1000.0, 780.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3018, "q_vals": [-inf, -inf, -6.743, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3046, "visits": [1000.0, 1000.0, 781.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3019, "q_vals": [-inf, -inf, -6.747, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3047, "visits": [1000.0, 1000.0, 782.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3022, "q_vals": [-inf, -inf, -6.751, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3023, "number_of_timesteps": 290917, "per_episode_reward": -458.67, "episode_reward_trend_value": 0.014954646890480363, "biggest_recent_change": 0.7841807593629824},
{ "step": 3048, "visits": [1000.0, 1000.0, 783.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3023, "q_vals": [-inf, -inf, -6.742, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3049, "visits": [1000.0, 1000.0, 784.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3024, "q_vals": [-inf, -inf, -6.746, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3050, "visits": [1000.0, 1000.0, 785.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3024, "q_vals": [-inf, -inf, -6.75, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3051, "visits": [1000.0, 1000.0, 786.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3026, "q_vals": [-inf, -inf, -6.754, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3052, "visits": [1000.0, 1000.0, 787.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3028, "q_vals": [-inf, -inf, -6.757, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3053, "visits": [1000.0, 1000.0, 788.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3029, "q_vals": [-inf, -inf, -6.761, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3054, "visits": [1000.0, 1000.0, 789.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3029, "q_vals": [-inf, -inf, -6.753, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3055, "visits": [1000.0, 1000.0, 790.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3031, "q_vals": [-inf, -inf, -6.744, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3033, "number_of_timesteps": 291616, "per_episode_reward": -458.97, "episode_reward_trend_value": 0.01407704600501726, "biggest_recent_change": 0.7841807593629824},
{ "step": 3056, "visits": [1000.0, 1000.0, 791.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3033, "q_vals": [-inf, -inf, -6.748, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3057, "visits": [1000.0, 1000.0, 792.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3034, "q_vals": [-inf, -inf, -6.74, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3058, "visits": [1000.0, 1000.0, 793.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3035, "q_vals": [-inf, -inf, -6.743, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3059, "visits": [1000.0, 1000.0, 794.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3036, "q_vals": [-inf, -inf, -6.735, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3060, "visits": [1000.0, 1000.0, 795.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3038, "q_vals": [-inf, -inf, -6.739, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3061, "visits": [1000.0, 1000.0, 796.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3039, "q_vals": [-inf, -inf, -6.743, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
visits [1000.0, 1000.0, 797.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 3041 q_vals: [-inf, -inf, -6.734, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796]
{ "step": 3063, "visits": [1000.0, 1000.0, 798.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3041, "q_vals": [-inf, -inf, -6.738, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3043, "number_of_timesteps": 292344, "per_episode_reward": -458.71, "episode_reward_trend_value": 0.01099184801760455, "biggest_recent_change": 0.7841807593629824},
{ "step": 3064, "visits": [1000.0, 1000.0, 799.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3043, "q_vals": [-inf, -inf, -6.73, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3065, "visits": [1000.0, 1000.0, 800.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3043, "q_vals": [-inf, -inf, -6.733, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3066, "visits": [1000.0, 1000.0, 801.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3043, "q_vals": [-inf, -inf, -6.725, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3067, "visits": [1000.0, 1000.0, 802.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3045, "q_vals": [-inf, -inf, -6.729, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3068, "visits": [1000.0, 1000.0, 803.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3050, "q_vals": [-inf, -inf, -6.72, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3069, "visits": [1000.0, 1000.0, 804.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3051, "q_vals": [-inf, -inf, -6.724, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3070, "visits": [1000.0, 1000.0, 805.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3051, "q_vals": [-inf, -inf, -6.728, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3053, "number_of_timesteps": 293073, "per_episode_reward": -458.65, "episode_reward_trend_value": 0.008638090828273765, "biggest_recent_change": 0.7841807593629824},
{ "step": 3071, "visits": [1000.0, 1000.0, 806.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3053, "q_vals": [-inf, -inf, -6.732, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3072, "visits": [1000.0, 1000.0, 807.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3053, "q_vals": [-inf, -inf, -6.724, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3073, "visits": [1000.0, 1000.0, 808.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3053, "q_vals": [-inf, -inf, -6.715, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3074, "visits": [1000.0, 1000.0, 809.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3056, "q_vals": [-inf, -inf, -6.719, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3075, "visits": [1000.0, 1000.0, 810.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3057, "q_vals": [-inf, -inf, -6.723, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3076, "visits": [1000.0, 1000.0, 811.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3059, "q_vals": [-inf, -inf, -6.727, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3077, "visits": [1000.0, 1000.0, 812.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3060, "q_vals": [-inf, -inf, -6.718, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3078, "visits": [1000.0, 1000.0, 813.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3062, "q_vals": [-inf, -inf, -6.722, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3063, "number_of_timesteps": 293795, "per_episode_reward": -458.63, "episode_reward_trend_value": 0.011064596223928271, "biggest_recent_change": 0.7841807593629824},
{ "step": 3079, "visits": [1000.0, 1000.0, 814.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3063, "q_vals": [-inf, -inf, -6.726, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3080, "visits": [1000.0, 1000.0, 815.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3064, "q_vals": [-inf, -inf, -6.73, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3081, "visits": [1000.0, 1000.0, 816.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3064, "q_vals": [-inf, -inf, -6.721, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3082, "visits": [1000.0, 1000.0, 817.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3065, "q_vals": [-inf, -inf, -6.725, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3083, "visits": [1000.0, 1000.0, 818.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3066, "q_vals": [-inf, -inf, -6.717, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3084, "visits": [1000.0, 1000.0, 819.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3066, "q_vals": [-inf, -inf, -6.709, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3085, "visits": [1000.0, 1000.0, 820.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3068, "q_vals": [-inf, -inf, -6.712, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3086, "visits": [1000.0, 1000.0, 821.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3071, "q_vals": [-inf, -inf, -6.716, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3087, "visits": [1000.0, 1000.0, 822.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3072, "q_vals": [-inf, -inf, -6.72, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3074, "number_of_timesteps": 294693, "per_episode_reward": -458.94, "episode_reward_trend_value": -0.001075324928306524, "biggest_recent_change": 0.5058023962344009},
{ "step": 3088, "visits": [1000.0, 1000.0, 823.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3074, "q_vals": [-inf, -inf, -6.724, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3089, "visits": [1000.0, 1000.0, 824.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3075, "q_vals": [-inf, -inf, -6.727, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3090, "visits": [1000.0, 1000.0, 825.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3076, "q_vals": [-inf, -inf, -6.719, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3091, "visits": [1000.0, 1000.0, 826.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3076, "q_vals": [-inf, -inf, -6.711, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3092, "visits": [1000.0, 1000.0, 827.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3078, "q_vals": [-inf, -inf, -6.703, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3093, "visits": [1000.0, 1000.0, 828.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3081, "q_vals": [-inf, -inf, -6.707, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3094, "visits": [1000.0, 1000.0, 829.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3081, "q_vals": [-inf, -inf, -6.711, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3095, "visits": [1000.0, 1000.0, 830.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3082, "q_vals": [-inf, -inf, -6.702, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3084, "number_of_timesteps": 295350, "per_episode_reward": -458.26, "episode_reward_trend_value": 0.008464057024605785, "biggest_recent_change": 0.6726574996065438},
{ "step": 3096, "visits": [1000.0, 1000.0, 831.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3084, "q_vals": [-inf, -inf, -6.706, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3097, "visits": [1000.0, 1000.0, 832.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3085, "q_vals": [-inf, -inf, -6.71, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3098, "visits": [1000.0, 1000.0, 833.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3086, "q_vals": [-inf, -inf, -6.714, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3099, "visits": [1000.0, 1000.0, 834.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3086, "q_vals": [-inf, -inf, -6.706, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3100, "visits": [1000.0, 1000.0, 835.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3089, "q_vals": [-inf, -inf, -6.697, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3101, "visits": [1000.0, 1000.0, 836.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3090, "q_vals": [-inf, -inf, -6.701, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3102, "visits": [1000.0, 1000.0, 837.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3090, "q_vals": [-inf, -inf, -6.705, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3103, "visits": [1000.0, 1000.0, 838.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3090, "q_vals": [-inf, -inf, -6.709, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3104, "visits": [1000.0, 1000.0, 839.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3091, "q_vals": [-inf, -inf, -6.712, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3105, "visits": [1000.0, 1000.0, 840.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3093, "q_vals": [-inf, -inf, -6.716, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3094, "number_of_timesteps": 296203, "per_episode_reward": -458.41, "episode_reward_trend_value": 0.009917668180192626, "biggest_recent_change": 0.6726574996065438},
{ "step": 3106, "visits": [1000.0, 1000.0, 841.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3094, "q_vals": [-inf, -inf, -6.72, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3107, "visits": [1000.0, 1000.0, 842.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3094, "q_vals": [-inf, -inf, -6.712, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3108, "visits": [1000.0, 1000.0, 843.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3097, "q_vals": [-inf, -inf, -6.715, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3109, "visits": [1000.0, 1000.0, 844.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3097, "q_vals": [-inf, -inf, -6.719, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3110, "visits": [1000.0, 1000.0, 845.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3100, "q_vals": [-inf, -inf, -6.723, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3111, "visits": [1000.0, 1000.0, 846.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3100, "q_vals": [-inf, -inf, -6.715, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3112, "visits": [1000.0, 1000.0, 847.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3101, "q_vals": [-inf, -inf, -6.718, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3113, "visits": [1000.0, 1000.0, 848.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3102, "q_vals": [-inf, -inf, -6.722, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3114, "visits": [1000.0, 1000.0, 849.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3102, "q_vals": [-inf, -inf, -6.714, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3104, "number_of_timesteps": 296983, "per_episode_reward": -458.45, "episode_reward_trend_value": 0.007980907788033972, "biggest_recent_change": 0.6726574996065438},
{ "step": 3115, "visits": [1000.0, 1000.0, 850.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3104, "q_vals": [-inf, -inf, -6.718, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3116, "visits": [1000.0, 1000.0, 851.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3106, "q_vals": [-inf, -inf, -6.721, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3117, "visits": [1000.0, 1000.0, 852.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3106, "q_vals": [-inf, -inf, -6.725, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3118, "visits": [1000.0, 1000.0, 853.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3107, "q_vals": [-inf, -inf, -6.728, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3119, "visits": [1000.0, 1000.0, 854.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3107, "q_vals": [-inf, -inf, -6.732, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3120, "visits": [1000.0, 1000.0, 855.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3108, "q_vals": [-inf, -inf, -6.736, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3121, "visits": [1000.0, 1000.0, 856.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3109, "q_vals": [-inf, -inf, -6.728, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3122, "visits": [1000.0, 1000.0, 857.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3110, "q_vals": [-inf, -inf, -6.731, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3123, "visits": [1000.0, 1000.0, 858.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3113, "q_vals": [-inf, -inf, -6.735, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3124, "visits": [1000.0, 1000.0, 859.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3113, "q_vals": [-inf, -inf, -6.727, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3115, "number_of_timesteps": 297898, "per_episode_reward": -458.26, "episode_reward_trend_value": 0.0045488798448565775, "biggest_recent_change": 0.6726574996065438},
{ "step": 3125, "visits": [1000.0, 1000.0, 860.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3115, "q_vals": [-inf, -inf, -6.731, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3126, "visits": [1000.0, 1000.0, 861.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3115, "q_vals": [-inf, -inf, -6.734, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3127, "visits": [1000.0, 1000.0, 862.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3116, "q_vals": [-inf, -inf, -6.738, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3128, "visits": [1000.0, 1000.0, 863.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3116, "q_vals": [-inf, -inf, -6.73, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3129, "visits": [1000.0, 1000.0, 864.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3117, "q_vals": [-inf, -inf, -6.733, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3130, "visits": [1000.0, 1000.0, 865.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3117, "q_vals": [-inf, -inf, -6.737, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3131, "visits": [1000.0, 1000.0, 866.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3120, "q_vals": [-inf, -inf, -6.741, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3132, "visits": [1000.0, 1000.0, 867.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3121, "q_vals": [-inf, -inf, -6.744, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3133, "visits": [1000.0, 1000.0, 868.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3122, "q_vals": [-inf, -inf, -6.736, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3134, "visits": [1000.0, 1000.0, 869.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3124, "q_vals": [-inf, -inf, -6.729, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3125, "number_of_timesteps": 299045, "per_episode_reward": -458.39, "episode_reward_trend_value": 0.00642636676677297, "biggest_recent_change": 0.6726574996065438},
{ "step": 3135, "visits": [1000.0, 1000.0, 870.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3125, "q_vals": [-inf, -inf, -6.732, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3136, "visits": [1000.0, 1000.0, 871.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3126, "q_vals": [-inf, -inf, -6.724, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3137, "visits": [1000.0, 1000.0, 872.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3126, "q_vals": [-inf, -inf, -6.717, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3138, "visits": [1000.0, 1000.0, 873.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3127, "q_vals": [-inf, -inf, -6.709, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3139, "visits": [1000.0, 1000.0, 874.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3128, "q_vals": [-inf, -inf, -6.701, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3140, "visits": [1000.0, 1000.0, 875.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3129, "q_vals": [-inf, -inf, -6.705, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3141, "visits": [1000.0, 1000.0, 876.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3133, "q_vals": [-inf, -inf, -6.708, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3142, "visits": [1000.0, 1000.0, 877.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3133, "q_vals": [-inf, -inf, -6.712, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3135, "number_of_timesteps": 299863, "per_episode_reward": -458.46, "episode_reward_trend_value": 0.0027169383823143615, "biggest_recent_change": 0.6726574996065438},
{ "step": 3143, "visits": [1000.0, 1000.0, 878.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3135, "q_vals": [-inf, -inf, -6.715, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3144, "visits": [1000.0, 1000.0, 879.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3135, "q_vals": [-inf, -inf, -6.719, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3145, "visits": [1000.0, 1000.0, 880.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3137, "q_vals": [-inf, -inf, -6.722, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3146, "visits": [1000.0, 1000.0, 881.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3139, "q_vals": [-inf, -inf, -6.726, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3147, "visits": [1000.0, 1000.0, 882.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3139, "q_vals": [-inf, -inf, -6.729, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3148, "visits": [1000.0, 1000.0, 883.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3139, "q_vals": [-inf, -inf, -6.733, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3149, "visits": [1000.0, 1000.0, 884.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3140, "q_vals": [-inf, -inf, -6.736, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3150, "visits": [1000.0, 1000.0, 885.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3141, "q_vals": [-inf, -inf, -6.74, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3151, "visits": [1000.0, 1000.0, 886.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3142, "q_vals": [-inf, -inf, -6.743, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3146, "number_of_timesteps": 300744, "per_episode_reward": -459.05, "episode_reward_trend_value": -0.004491717424793427, "biggest_recent_change": 0.6726574996065438},
{ "step": 3152, "visits": [1000.0, 1000.0, 887.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3146, "q_vals": [-inf, -inf, -6.747, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3153, "visits": [1000.0, 1000.0, 888.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3147, "q_vals": [-inf, -inf, -6.75, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3154, "visits": [1000.0, 1000.0, 889.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3148, "q_vals": [-inf, -inf, -6.742, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3155, "visits": [1000.0, 1000.0, 890.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3149, "q_vals": [-inf, -inf, -6.746, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3156, "visits": [1000.0, 1000.0, 891.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3149, "q_vals": [-inf, -inf, -6.749, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3157, "visits": [1000.0, 1000.0, 892.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3149, "q_vals": [-inf, -inf, -6.753, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3158, "visits": [1000.0, 1000.0, 893.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3150, "q_vals": [-inf, -inf, -6.745, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3159, "visits": [1000.0, 1000.0, 894.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3151, "q_vals": [-inf, -inf, -6.749, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
[1000.0, 1000.0, 895.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 3151 q_vals: [-inf, -inf, -6.752, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796]
{ "step": 3161, "visits": [1000.0, 1000.0, 896.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3153, "q_vals": [-inf, -inf, -6.755, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3162, "visits": [1000.0, 1000.0, 897.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3155, "q_vals": [-inf, -inf, -6.748, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3157, "number_of_timesteps": 301670, "per_episode_reward": -459.61, "episode_reward_trend_value": -0.010967177278378256, "biggest_recent_change": 0.6726574996065438},
{ "step": 3163, "visits": [1000.0, 1000.0, 898.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3157, "q_vals": [-inf, -inf, -6.74, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3164, "visits": [1000.0, 1000.0, 899.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3159, "q_vals": [-inf, -inf, -6.733, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3165, "visits": [1000.0, 1000.0, 900.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3159, "q_vals": [-inf, -inf, -6.725, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3166, "visits": [1000.0, 1000.0, 901.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3160, "q_vals": [-inf, -inf, -6.729, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3167, "visits": [1000.0, 1000.0, 902.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3160, "q_vals": [-inf, -inf, -6.732, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3168, "visits": [1000.0, 1000.0, 903.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3162, "q_vals": [-inf, -inf, -6.736, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3169, "visits": [1000.0, 1000.0, 904.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3163, "q_vals": [-inf, -inf, -6.739, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3170, "visits": [1000.0, 1000.0, 905.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3165, "q_vals": [-inf, -inf, -6.731, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3171, "visits": [1000.0, 1000.0, 906.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3165, "q_vals": [-inf, -inf, -6.735, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3172, "visits": [1000.0, 1000.0, 907.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3166, "q_vals": [-inf, -inf, -6.738, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3167, "number_of_timesteps": 302515, "per_episode_reward": -460.13, "episode_reward_trend_value": -0.013244397711092561, "biggest_recent_change": 0.6726574996065438},
{ "step": 3173, "visits": [1000.0, 1000.0, 908.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3167, "q_vals": [-inf, -inf, -6.742, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3174, "visits": [1000.0, 1000.0, 909.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3169, "q_vals": [-inf, -inf, -6.745, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3175, "visits": [1000.0, 1000.0, 910.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3169, "q_vals": [-inf, -inf, -6.748, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3176, "visits": [1000.0, 1000.0, 911.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3171, "q_vals": [-inf, -inf, -6.741, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3177, "visits": [1000.0, 1000.0, 912.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3175, "q_vals": [-inf, -inf, -6.744, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3178, "visits": [1000.0, 1000.0, 913.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3175, "q_vals": [-inf, -inf, -6.748, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3179, "visits": [1000.0, 1000.0, 914.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3175, "q_vals": [-inf, -inf, -6.751, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3180, "visits": [1000.0, 1000.0, 915.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3175, "q_vals": [-inf, -inf, -6.754, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3181, "visits": [1000.0, 1000.0, 916.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3175, "q_vals": [-inf, -inf, -6.758, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3182, "visits": [1000.0, 1000.0, 917.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3175, "q_vals": [-inf, -inf, -6.761, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3177, "number_of_timesteps": 303347, "per_episode_reward": -460.14, "episode_reward_trend_value": -0.02089774598713095, "biggest_recent_change": 0.5891382349527703},
{ "step": 3183, "visits": [1000.0, 1000.0, 918.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3177, "q_vals": [-inf, -inf, -6.754, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3184, "visits": [1000.0, 1000.0, 919.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3179, "q_vals": [-inf, -inf, -6.757, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3185, "visits": [1000.0, 1000.0, 920.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3183, "q_vals": [-inf, -inf, -6.76, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3186, "visits": [1000.0, 1000.0, 921.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3185, "q_vals": [-inf, -inf, -6.763, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3187, "visits": [1000.0, 1000.0, 922.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3185, "q_vals": [-inf, -inf, -6.767, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3188, "visits": [1000.0, 1000.0, 923.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3185, "q_vals": [-inf, -inf, -6.759, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3189, "visits": [1000.0, 1000.0, 924.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3185, "q_vals": [-inf, -inf, -6.752, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3190, "visits": [1000.0, 1000.0, 925.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3185, "q_vals": [-inf, -inf, -6.745, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3191, "visits": [1000.0, 1000.0, 926.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3186, "q_vals": [-inf, -inf, -6.738, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3189, "number_of_timesteps": 304330, "per_episode_reward": -460.01, "episode_reward_trend_value": -0.017822390745021722, "biggest_recent_change": 0.5891382349527703},
{ "step": 3192, "visits": [1000.0, 1000.0, 927.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3189, "q_vals": [-inf, -inf, -6.741, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3193, "visits": [1000.0, 1000.0, 928.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3190, "q_vals": [-inf, -inf, -6.744, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3194, "visits": [1000.0, 1000.0, 929.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3193, "q_vals": [-inf, -inf, -6.747, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3195, "visits": [1000.0, 1000.0, 930.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3194, "q_vals": [-inf, -inf, -6.74, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3196, "visits": [1000.0, 1000.0, 931.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3195, "q_vals": [-inf, -inf, -6.743, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3197, "visits": [1000.0, 1000.0, 932.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3195, "q_vals": [-inf, -inf, -6.747, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3198, "visits": [1000.0, 1000.0, 933.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3195, "q_vals": [-inf, -inf, -6.75, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3199, "visits": [1000.0, 1000.0, 934.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3195, "q_vals": [-inf, -inf, -6.753, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3200, "visits": [1000.0, 1000.0, 935.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3195, "q_vals": [-inf, -inf, -6.746, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3201, "visits": [1000.0, 1000.0, 936.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3196, "q_vals": [-inf, -inf, -6.749, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3202, "visits": [1000.0, 1000.0, 937.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3198, "q_vals": [-inf, -inf, -6.753, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3201, "number_of_timesteps": 305388, "per_episode_reward": -460.39, "episode_reward_trend_value": -0.021508744775861212, "biggest_recent_change": 0.5891382349527703},
{ "step": 3203, "visits": [1000.0, 1000.0, 938.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3201, "q_vals": [-inf, -inf, -6.745, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3204, "visits": [1000.0, 1000.0, 939.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3204, "q_vals": [-inf, -inf, -6.749, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3205, "visits": [1000.0, 1000.0, 940.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3204, "q_vals": [-inf, -inf, -6.752, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3206, "visits": [1000.0, 1000.0, 941.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3204, "q_vals": [-inf, -inf, -6.755, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3207, "visits": [1000.0, 1000.0, 942.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3204, "q_vals": [-inf, -inf, -6.758, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3208, "visits": [1000.0, 1000.0, 943.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3205, "q_vals": [-inf, -inf, -6.761, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3209, "visits": [1000.0, 1000.0, 944.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3205, "q_vals": [-inf, -inf, -6.765, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3210, "visits": [1000.0, 1000.0, 945.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3206, "q_vals": [-inf, -inf, -6.758, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3211, "number_of_timesteps": 306279, "per_episode_reward": -460.28, "episode_reward_trend_value": -0.02249823637836812, "biggest_recent_change": 0.5891382349527703},
{ "step": 3211, "visits": [1000.0, 1000.0, 946.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3211, "q_vals": [-inf, -inf, -6.761, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3212, "visits": [1000.0, 1000.0, 947.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3212, "q_vals": [-inf, -inf, -6.764, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3213, "visits": [1000.0, 1000.0, 948.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3214, "q_vals": [-inf, -inf, -6.767, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3214, "visits": [1000.0, 1000.0, 949.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3214, "q_vals": [-inf, -inf, -6.77, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3215, "visits": [1000.0, 1000.0, 950.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3215, "q_vals": [-inf, -inf, -6.774, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3216, "visits": [1000.0, 1000.0, 951.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3215, "q_vals": [-inf, -inf, -6.777, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3217, "visits": [1000.0, 1000.0, 952.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3215, "q_vals": [-inf, -inf, -6.777, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3218, "visits": [1000.0, 1000.0, 953.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3215, "q_vals": [-inf, -inf, -6.77, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3219, "visits": [1000.0, 1000.0, 954.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3216, "q_vals": [-inf, -inf, -6.773, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3220, "visits": [1000.0, 1000.0, 955.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3218, "q_vals": [-inf, -inf, -6.777, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3221, "visits": [1000.0, 1000.0, 956.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3220, "q_vals": [-inf, -inf, -6.769, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3222, "number_of_timesteps": 307260, "per_episode_reward": -460.5, "episode_reward_trend_value": -0.023442926781652634, "biggest_recent_change": 0.5891382349527703},
{ "step": 3222, "visits": [1000.0, 1000.0, 957.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3222, "q_vals": [-inf, -inf, -6.773, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3223, "visits": [1000.0, 1000.0, 958.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3222, "q_vals": [-inf, -inf, -6.766, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3224, "visits": [1000.0, 1000.0, 959.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3222, "q_vals": [-inf, -inf, -6.769, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3225, "visits": [1000.0, 1000.0, 960.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3222, "q_vals": [-inf, -inf, -6.772, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3226, "visits": [1000.0, 1000.0, 961.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3222, "q_vals": [-inf, -inf, -6.775, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3227, "visits": [1000.0, 1000.0, 962.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3223, "q_vals": [-inf, -inf, -6.778, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3228, "visits": [1000.0, 1000.0, 963.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3225, "q_vals": [-inf, -inf, -6.781, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3229, "visits": [1000.0, 1000.0, 964.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3225, "q_vals": [-inf, -inf, -6.784, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3230, "visits": [1000.0, 1000.0, 965.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3227, "q_vals": [-inf, -inf, -6.787, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3231, "visits": [1000.0, 1000.0, 966.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3227, "q_vals": [-inf, -inf, -6.78, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3232, "visits": [1000.0, 1000.0, 967.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3228, "q_vals": [-inf, -inf, -6.784, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3233, "visits": [1000.0, 1000.0, 968.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3230, "q_vals": [-inf, -inf, -6.787, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3234, "visits": [1000.0, 1000.0, 969.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3231, "q_vals": [-inf, -inf, -6.79, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3235, "visits": [1000.0, 1000.0, 970.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3231, "q_vals": [-inf, -inf, -6.793, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3236, "visits": [1000.0, 1000.0, 971.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3231, "q_vals": [-inf, -inf, -6.796, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3237, "visits": [1000.0, 1000.0, 972.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3231, "q_vals": [-inf, -inf, -6.789, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3238, "visits": [1000.0, 1000.0, 973.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3231, "q_vals": [-inf, -inf, -6.782, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3232, "number_of_timesteps": 308402, "per_episode_reward": -460.89, "episode_reward_trend_value": -0.02699805495273419, "biggest_recent_change": 0.5891382349527703},
{ "step": 3239, "visits": [1000.0, 1000.0, 974.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3232, "q_vals": [-inf, -inf, -6.775, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3240, "visits": [1000.0, 1000.0, 975.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3235, "q_vals": [-inf, -inf, -6.768, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3241, "visits": [1000.0, 1000.0, 976.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3237, "q_vals": [-inf, -inf, -6.771, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3242, "visits": [1000.0, 1000.0, 977.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3237, "q_vals": [-inf, -inf, -6.774, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3243, "visits": [1000.0, 1000.0, 978.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3238, "q_vals": [-inf, -inf, -6.767, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3244, "visits": [1000.0, 1000.0, 979.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3238, "q_vals": [-inf, -inf, -6.77, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3245, "visits": [1000.0, 1000.0, 980.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3240, "q_vals": [-inf, -inf, -6.774, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3246, "visits": [1000.0, 1000.0, 981.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3240, "q_vals": [-inf, -inf, -6.767, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3247, "visits": [1000.0, 1000.0, 982.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3241, "q_vals": [-inf, -inf, -6.77, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3242, "number_of_timesteps": 309621, "per_episode_reward": -461.17, "episode_reward_trend_value": -0.02355152446161305, "biggest_recent_change": 0.5643666035414867},
{ "step": 3248, "visits": [1000.0, 1000.0, 983.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3242, "q_vals": [-inf, -inf, -6.773, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3249, "visits": [1000.0, 1000.0, 984.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3243, "q_vals": [-inf, -inf, -6.776, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3250, "visits": [1000.0, 1000.0, 985.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3244, "q_vals": [-inf, -inf, -6.779, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3251, "visits": [1000.0, 1000.0, 986.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3245, "q_vals": [-inf, -inf, -6.772, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3252, "visits": [1000.0, 1000.0, 987.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3248, "q_vals": [-inf, -inf, -6.775, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3253, "visits": [1000.0, 1000.0, 988.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3248, "q_vals": [-inf, -inf, -6.768, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3254, "visits": [1000.0, 1000.0, 989.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3248, "q_vals": [-inf, -inf, -6.771, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3255, "visits": [1000.0, 1000.0, 990.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3250, "q_vals": [-inf, -inf, -6.774, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3256, "visits": [1000.0, 1000.0, 991.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3250, "q_vals": [-inf, -inf, -6.777, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3252, "number_of_timesteps": 310541, "per_episode_reward": -461.48, "episode_reward_trend_value": -0.02075065190876444, "biggest_recent_change": 0.5133619832824365},
{ "step": 3257, "visits": [1000.0, 1000.0, 992.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3252, "q_vals": [-inf, -inf, -6.771, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
[-inf, -inf, -6.774, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796]
{ "step": 3259, "visits": [1000.0, 1000.0, 994.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3255, "q_vals": [-inf, -inf, -6.777, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3260, "visits": [1000.0, 1000.0, 995.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3256, "q_vals": [-inf, -inf, -6.78, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3261, "visits": [1000.0, 1000.0, 996.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3258, "q_vals": [-inf, -inf, -6.773, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3262, "visits": [1000.0, 1000.0, 997.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3258, "q_vals": [-inf, -inf, -6.776, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3263, "visits": [1000.0, 1000.0, 998.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3260, "q_vals": [-inf, -inf, -6.779, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{ "step": 3264, "visits": [1000.0, 1000.0, 999.0, 11.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 3260, "q_vals": [-inf, -inf, -6.782, -8.46, -9.796, -9.796, -12.245, -9.796, -9.796, -9.796] }
{"total_number_of_episodes": 3262, "number_of_timesteps": 311364, "per_episode_reward": -461.42, "episode_reward_trend_value": -0.014386866601967719, "biggest_recent_change": 0.38916902697974365},
{ "step": 3265, "visits": [1000.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 3262, "q_vals": [-inf, -inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{"total_number_of_episodes": 3272, "number_of_timesteps": 312219, "per_episode_reward": -403.49, "episode_reward_trend_value": 0.6295034689617491, "biggest_recent_change": 57.93398635549761},
{"total_number_of_episodes": 3283, "number_of_timesteps": 313161, "per_episode_reward": -403.69, "episode_reward_trend_value": 0.6257918399252889, "biggest_recent_change": 57.93398635549761},
{"total_number_of_episodes": 3293, "number_of_timesteps": 314220, "per_episode_reward": -404.14, "episode_reward_trend_value": 0.625001342258031, "biggest_recent_change": 57.93398635549761},
{"total_number_of_episodes": 3303, "number_of_timesteps": 315082, "per_episode_reward": -404.62, "episode_reward_trend_value": 0.6185009282589129, "biggest_recent_change": 57.93398635549761},
{"total_number_of_episodes": 3313, "number_of_timesteps": 315849, "per_episode_reward": -404.89, "episode_reward_trend_value": 0.6179369920925359, "biggest_recent_change": 57.93398635549761},
{"total_number_of_episodes": 3323, "number_of_timesteps": 316781, "per_episode_reward": -404.57, "episode_reward_trend_value": 0.62576852626368, "biggest_recent_change": 57.93398635549761},
{"total_number_of_episodes": 3333, "number_of_timesteps": 317827, "per_episode_reward": -405.39, "episode_reward_trend_value": 0.6197662200825764, "biggest_recent_change": 57.93398635549761},
{"total_number_of_episodes": 3343, "number_of_timesteps": 318809, "per_episode_reward": -405.79, "episode_reward_trend_value": 0.6187777898819017, "biggest_recent_change": 57.93398635549761},
{"total_number_of_episodes": 3353, "number_of_timesteps": 319984, "per_episode_reward": -406.07, "episode_reward_trend_value": 0.6150683723718442, "biggest_recent_change": 57.93398635549761},
{"total_number_of_episodes": 3363, "number_of_timesteps": 320988, "per_episode_reward": -406.25, "episode_reward_trend_value": -0.030624445550447237, "biggest_recent_change": 0.8191580470511894},
{"total_number_of_episodes": 3373, "number_of_timesteps": 322170, "per_episode_reward": -406.6, "episode_reward_trend_value": -0.032259752497105866, "biggest_recent_change": 0.8191580470511894},
{"total_number_of_episodes": 3383, "number_of_timesteps": 323071, "per_episode_reward": -406.13, "episode_reward_trend_value": -0.022071830707068963, "biggest_recent_change": 0.8191580470511894},
{"total_number_of_episodes": 3393, "number_of_timesteps": 323996, "per_episode_reward": -406.21, "episode_reward_trend_value": -0.017657425840302998, "biggest_recent_change": 0.8191580470511894},
{"total_number_of_episodes": 3403, "number_of_timesteps": 324954, "per_episode_reward": -406.87, "episode_reward_trend_value": -0.021981269918071197, "biggest_recent_change": 0.8191580470511894},
{"total_number_of_episodes": 3414, "number_of_timesteps": 326225, "per_episode_reward": -407.22, "episode_reward_trend_value": -0.02940846407093368, "biggest_recent_change": 0.8191580470511894},
{"total_number_of_episodes": 3424, "number_of_timesteps": 327066, "per_episode_reward": -407.34, "episode_reward_trend_value": -0.021600910955246237, "biggest_recent_change": 0.6591536786199867},
{"total_number_of_episodes": 3434, "number_of_timesteps": 327945, "per_episode_reward": -407.32, "episode_reward_trend_value": -0.01695689616824312, "biggest_recent_change": 0.6591536786199867},
{"total_number_of_episodes": 3444, "number_of_timesteps": 328840, "per_episode_reward": -407.68, "episode_reward_trend_value": -0.01790084837408522, "biggest_recent_change": 0.6591536786199867},
{"total_number_of_episodes": 3455, "number_of_timesteps": 329781, "per_episode_reward": -407.59, "episode_reward_trend_value": -0.014985610868798935, "biggest_recent_change": 0.6591536786199867},
{"total_number_of_episodes": 3465, "number_of_timesteps": 330867, "per_episode_reward": -408.47, "episode_reward_trend_value": -0.02079316056104593, "biggest_recent_change": 0.8744674911009724},
{"total_number_of_episodes": 3478, "number_of_timesteps": 332132, "per_episode_reward": -409.06, "episode_reward_trend_value": -0.03256858763528309, "biggest_recent_change": 0.8744674911009724},
{"total_number_of_episodes": 3488, "number_of_timesteps": 332989, "per_episode_reward": -409.11, "episode_reward_trend_value": -0.03223135509099204, "biggest_recent_change": 0.8744674911009724},
{"total_number_of_episodes": 3498, "number_of_timesteps": 333755, "per_episode_reward": -409.09, "episode_reward_trend_value": -0.024713150659321552, "biggest_recent_change": 0.8744674911009724},
{"total_number_of_episodes": 3508, "number_of_timesteps": 334537, "per_episode_reward": -409.22, "episode_reward_trend_value": -0.02228464470499287, "biggest_recent_change": 0.8744674911009724},
{"total_number_of_episodes": 3519, "number_of_timesteps": 335649, "per_episode_reward": -409.37, "episode_reward_trend_value": -0.02259066061459786, "biggest_recent_change": 0.8744674911009724},
{"total_number_of_episodes": 3531, "number_of_timesteps": 336713, "per_episode_reward": -409.75, "episode_reward_trend_value": -0.027060078633084888, "biggest_recent_change": 0.8744674911009724},
{"total_number_of_episodes": 3542, "number_of_timesteps": 337958, "per_episode_reward": -409.85, "episode_reward_trend_value": -0.024188134277251392, "biggest_recent_change": 0.8744674911009724},
{"total_number_of_episodes": 3552, "number_of_timesteps": 338891, "per_episode_reward": -410.06, "episode_reward_trend_value": -0.027351033666955498, "biggest_recent_change": 0.8744674911009724},
{"total_number_of_episodes": 3563, "number_of_timesteps": 340027, "per_episode_reward": -409.99, "episode_reward_trend_value": -0.016901670360836205, "biggest_recent_change": 0.5897139175418147},
{"total_number_of_episodes": 3573, "number_of_timesteps": 341035, "per_episode_reward": -410.19, "episode_reward_trend_value": -0.012625382171106972, "biggest_recent_change": 0.38553308267938746},
{"total_number_of_episodes": 3584, "number_of_timesteps": 342051, "per_episode_reward": -410.43, "episode_reward_trend_value": -0.014704154858777152, "biggest_recent_change": 0.38553308267938746},
{"total_number_of_episodes": 3595, "number_of_timesteps": 342904, "per_episode_reward": -410.57, "episode_reward_trend_value": -0.016450230483178528, "biggest_recent_change": 0.38553308267938746},
{"total_number_of_episodes": 3605, "number_of_timesteps": 343739, "per_episode_reward": -410.85, "episode_reward_trend_value": -0.018018141839703756, "biggest_recent_change": 0.38553308267938746},
{"total_number_of_episodes": 3615, "number_of_timesteps": 344813, "per_episode_reward": -410.84, "episode_reward_trend_value": -0.016313425474370685, "biggest_recent_change": 0.38553308267938746},
{"total_number_of_episodes": 3625, "number_of_timesteps": 345825, "per_episode_reward": -411.14, "episode_reward_trend_value": -0.015425309098647708, "biggest_recent_change": 0.30560260886431934},
{"total_number_of_episodes": 3636, "number_of_timesteps": 346922, "per_episode_reward": -411.3, "episode_reward_trend_value": -0.016097146115434828, "biggest_recent_change": 0.30560260886431934},
{"total_number_of_episodes": 3646, "number_of_timesteps": 347810, "per_episode_reward": -411.73, "episode_reward_trend_value": -0.018608777953015, "biggest_recent_change": 0.4267036924884451},
{"total_number_of_episodes": 3658, "number_of_timesteps": 349185, "per_episode_reward": -411.88, "episode_reward_trend_value": -0.021043908678922207, "biggest_recent_change": 0.4267036924884451},
{"total_number_of_episodes": 3668, "number_of_timesteps": 350167, "per_episode_reward": -411.48, "episode_reward_trend_value": -0.014308757981093045, "biggest_recent_change": 0.4267036924884451},
{"total_number_of_episodes": 3679, "number_of_timesteps": 351524, "per_episode_reward": -412.21, "episode_reward_trend_value": -0.01972747435093475, "biggest_recent_change": 0.7242982709787498},
{"total_number_of_episodes": 3689, "number_of_timesteps": 352405, "per_episode_reward": -411.81, "episode_reward_trend_value": -0.013745124116549176, "biggest_recent_change": 0.7242982709787498},
{"total_number_of_episodes": 3700, "number_of_timesteps": 353419, "per_episode_reward": -412.42, "episode_reward_trend_value": -0.017505026878229853, "biggest_recent_change": 0.7242982709787498},
{"total_number_of_episodes": 3711, "number_of_timesteps": 354424, "per_episode_reward": -412.68, "episode_reward_trend_value": -0.020438058648958052, "biggest_recent_change": 0.7242982709787498},
{"total_number_of_episodes": 3721, "number_of_timesteps": 355406, "per_episode_reward": -412.51, "episode_reward_trend_value": -0.015224761923465419, "biggest_recent_change": 0.7242982709787498},
{"total_number_of_episodes": 3732, "number_of_timesteps": 356721, "per_episode_reward": -413.04, "episode_reward_trend_value": -0.01926242495716224, "biggest_recent_change": 0.7242982709787498},
{"total_number_of_episodes": 3743, "number_of_timesteps": 357785, "per_episode_reward": -413.61, "episode_reward_trend_value": -0.020840261993787912, "biggest_recent_change": 0.7242982709787498},
{"total_number_of_episodes": 3753, "number_of_timesteps": 359013, "per_episode_reward": -414.35, "episode_reward_trend_value": -0.027378912110444593, "biggest_recent_change": 0.7416650693809856},
{"total_number_of_episodes": 3764, "number_of_timesteps": 359951, "per_episode_reward": -413.99, "episode_reward_trend_value": -0.027823791097365026, "biggest_recent_change": 0.7416650693809856},
{"total_number_of_episodes": 3775, "number_of_timesteps": 360867, "per_episode_reward": -414.25, "episode_reward_trend_value": -0.022709331820445617, "biggest_recent_change": 0.7416650693809856},
{"total_number_of_episodes": 3785, "number_of_timesteps": 361633, "per_episode_reward": -413.89, "episode_reward_trend_value": -0.023086655628323648, "biggest_recent_change": 0.7416650693809856},
{"total_number_of_episodes": 3795, "number_of_timesteps": 362397, "per_episode_reward": -413.44, "episode_reward_trend_value": -0.011362842068840312, "biggest_recent_change": 0.7416650693809856},
{"total_number_of_episodes": 3806, "number_of_timesteps": 363348, "per_episode_reward": -414.0, "episode_reward_trend_value": -0.014733969870981254, "biggest_recent_change": 0.7416650693809856},
{"total_number_of_episodes": 3816, "number_of_timesteps": 364144, "per_episode_reward": -413.98, "episode_reward_trend_value": -0.016342228774875088, "biggest_recent_change": 0.7416650693809856},
{"total_number_of_episodes": 3826, "number_of_timesteps": 364936, "per_episode_reward": -413.86, "episode_reward_trend_value": -0.009162478403427106, "biggest_recent_change": 0.7416650693809856},
{"total_number_of_episodes": 3837, "number_of_timesteps": 365852, "per_episode_reward": -414.05, "episode_reward_trend_value": -0.004987240426876522, "biggest_recent_change": 0.7416650693809856},
{"total_number_of_episodes": 3849, "number_of_timesteps": 366826, "per_episode_reward": -413.97, "episode_reward_trend_value": 0.004198133706173874, "biggest_recent_change": 0.557969587182015},
{"total_number_of_episodes": 3859, "number_of_timesteps": 367747, "per_episode_reward": -414.23, "episode_reward_trend_value": -0.002744636757750464, "biggest_recent_change": 0.557969587182015},
{"total_number_of_episodes": 3869, "number_of_timesteps": 368647, "per_episode_reward": -414.65, "episode_reward_trend_value": -0.004446989278839434, "biggest_recent_change": 0.557969587182015},
{"total_number_of_episodes": 3879, "number_of_timesteps": 369523, "per_episode_reward": -414.96, "episode_reward_trend_value": -0.011981000485504486, "biggest_recent_change": 0.557969587182015},
{"total_number_of_episodes": 3889, "number_of_timesteps": 370566, "per_episode_reward": -414.78, "episode_reward_trend_value": -0.014878829426220996, "biggest_recent_change": 0.557969587182015},
{"total_number_of_episodes": 3899, "number_of_timesteps": 371573, "per_episode_reward": -415.01, "episode_reward_trend_value": -0.011250847681838472, "biggest_recent_change": 0.4172086629540104},
{"total_number_of_episodes": 3909, "number_of_timesteps": 372647, "per_episode_reward": -415.1, "episode_reward_trend_value": -0.012406023389416987, "biggest_recent_change": 0.4172086629540104},
{"total_number_of_episodes": 3919, "number_of_timesteps": 373564, "per_episode_reward": -415.22, "episode_reward_trend_value": -0.01510879842629341, "biggest_recent_change": 0.4172086629540104},
{"total_number_of_episodes": 3929, "number_of_timesteps": 374480, "per_episode_reward": -415.7, "episode_reward_trend_value": -0.01825487067950146, "biggest_recent_change": 0.476084110683928},
{"total_number_of_episodes": 3939, "number_of_timesteps": 375223, "per_episode_reward": -415.6, "episode_reward_trend_value": -0.01809444952425439, "biggest_recent_change": 0.476084110683928},
{"total_number_of_episodes": 3951, "number_of_timesteps": 376141, "per_episode_reward": -415.02, "episode_reward_trend_value": -0.00874199958355967, "biggest_recent_change": 0.5781476264249363},
{"total_number_of_episodes": 3961, "number_of_timesteps": 376942, "per_episode_reward": -415.47, "episode_reward_trend_value": -0.009063046223328304, "biggest_recent_change": 0.5781476264249363},
{"total_number_of_episodes": 3972, "number_of_timesteps": 377893, "per_episode_reward": -416.0, "episode_reward_trend_value": -0.011491850087974678, "biggest_recent_change": 0.5781476264249363},
{"total_number_of_episodes": 3984, "number_of_timesteps": 378908, "per_episode_reward": -415.96, "episode_reward_trend_value": -0.013120049270810341, "biggest_recent_change": 0.5781476264249363},
{"total_number_of_episodes": 3994, "number_of_timesteps": 379717, "per_episode_reward": -415.83, "episode_reward_trend_value": -0.009105763724253773, "biggest_recent_change": 0.5781476264249363},
{"total_number_of_episodes": 4004, "number_of_timesteps": 380558, "per_episode_reward": -415.76, "episode_reward_trend_value": -0.007354522828129954, "biggest_recent_change": 0.5781476264249363},
{"total_number_of_episodes": 4014, "number_of_timesteps": 381343, "per_episode_reward": -415.88, "episode_reward_trend_value": -0.007293517016907775, "biggest_recent_change": 0.5781476264249363},
{"total_number_of_episodes": 4024, "number_of_timesteps": 382193, "per_episode_reward": -415.88, "episode_reward_trend_value": -0.001982951896100202, "biggest_recent_change": 0.5781476264249363},
{"total_number_of_episodes": 4034, "number_of_timesteps": 382970, "per_episode_reward": -415.59, "episode_reward_trend_value": 5.9947668177705454e-05, "biggest_recent_change": 0.5781476264249363},
{"total_number_of_episodes": 4044, "number_of_timesteps": 383743, "per_episode_reward": -415.36, "episode_reward_trend_value": -0.0038034281476768683, "biggest_recent_change": 0.5318630639981166},
{"total_number_of_episodes": 4054, "number_of_timesteps": 384599, "per_episode_reward": -415.71, "episode_reward_trend_value": -0.002677906358239726, "biggest_recent_change": 0.5318630639981166},
{"total_number_of_episodes": 4064, "number_of_timesteps": 385495, "per_episode_reward": -415.72, "episode_reward_trend_value": 0.003087621868465678, "biggest_recent_change": 0.34480589948384477},
{"total_number_of_episodes": 4074, "number_of_timesteps": 386363, "per_episode_reward": -415.85, "episode_reward_trend_value": 0.001233240869673106, "biggest_recent_change": 0.34480589948384477},
{"total_number_of_episodes": 4084, "number_of_timesteps": 387245, "per_episode_reward": -415.67, "episode_reward_trend_value": 0.0018504187238553033, "biggest_recent_change": 0.34480589948384477},
{"total_number_of_episodes": 4094, "number_of_timesteps": 388293, "per_episode_reward": -415.98, "episode_reward_trend_value": -0.0024403114906192515, "biggest_recent_change": 0.34480589948384477},
{"total_number_of_episodes": 4104, "number_of_timesteps": 389464, "per_episode_reward": -416.22, "episode_reward_trend_value": -0.00384063248237112, "biggest_recent_change": 0.34480589948384477},
{"total_number_of_episodes": 4115, "number_of_timesteps": 390573, "per_episode_reward": -416.07, "episode_reward_trend_value": -0.002197471049517061, "biggest_recent_change": 0.34480589948384477},
{"total_number_of_episodes": 4125, "number_of_timesteps": 391666, "per_episode_reward": -416.51, "episode_reward_trend_value": -0.010160782290761164, "biggest_recent_change": 0.4333805443611709},
{"total_number_of_episodes": 4138, "number_of_timesteps": 392795, "per_episode_reward": -416.82, "episode_reward_trend_value": -0.016160252303297463, "biggest_recent_change": 0.4333805443611709},
{"total_number_of_episodes": 4148, "number_of_timesteps": 393531, "per_episode_reward": -416.17, "episode_reward_trend_value": -0.0051967955339522285, "biggest_recent_change": 0.6419052097572262},
{"total_number_of_episodes": 4159, "number_of_timesteps": 394575, "per_episode_reward": -416.25, "episode_reward_trend_value": -0.0058332436371882875, "biggest_recent_change": 0.6419052097572262},
{"total_number_of_episodes": 4169, "number_of_timesteps": 395675, "per_episode_reward": -416.31, "episode_reward_trend_value": -0.0051097514080121675, "biggest_recent_change": 0.6419052097572262},
{"total_number_of_episodes": 4179, "number_of_timesteps": 396620, "per_episode_reward": -416.41, "episode_reward_trend_value": -0.008287908566566355, "biggest_recent_change": 0.6419052097572262},
{"total_number_of_episodes": 4190, "number_of_timesteps": 397597, "per_episode_reward": -416.27, "episode_reward_trend_value": -0.0031642596106040504, "biggest_recent_change": 0.6419052097572262},
{"total_number_of_episodes": 4200, "number_of_timesteps": 398617, "per_episode_reward": -416.72, "episode_reward_trend_value": -0.005523145193993489, "biggest_recent_change": 0.6419052097572262},
{"total_number_of_episodes": 4210, "number_of_timesteps": 399717, "per_episode_reward": -416.67, "episode_reward_trend_value": -0.006639134664318489, "biggest_recent_change": 0.6419052097572262},
{"total_number_of_episodes": 4221, "number_of_timesteps": 400782, "per_episode_reward": -417.04, "episode_reward_trend_value": -0.005885569692389304, "biggest_recent_change": 0.6419052097572262},
{"total_number_of_episodes": 4231, "number_of_timesteps": 401806, "per_episode_reward": -417.22, "episode_reward_trend_value": -0.004455991639302839, "biggest_recent_change": 0.6419052097572262},
{"total_number_of_episodes": 4241, "number_of_timesteps": 402857, "per_episode_reward": -417.14, "episode_reward_trend_value": -0.010748916064233702, "biggest_recent_change": 0.45471488126150916},
{"total_number_of_episodes": 4251, "number_of_timesteps": 403783, "per_episode_reward": -417.27, "episode_reward_trend_value": -0.011342919681260987, "biggest_recent_change": 0.45471488126150916},
{"total_number_of_episodes": 4263, "number_of_timesteps": 404982, "per_episode_reward": -417.44, "episode_reward_trend_value": -0.012506690574742959, "biggest_recent_change": 0.45471488126150916},
{"total_number_of_episodes": 4273, "number_of_timesteps": 406030, "per_episode_reward": -417.73, "episode_reward_trend_value": -0.014609515048208423, "biggest_recent_change": 0.45471488126150916},
{"total_number_of_episodes": 4283, "number_of_timesteps": 406982, "per_episode_reward": -417.7, "episode_reward_trend_value": -0.015922348081049777, "biggest_recent_change": 0.45471488126150916},
{"total_number_of_episodes": 4294, "number_of_timesteps": 407846, "per_episode_reward": -417.81, "episode_reward_trend_value": -0.012050575286344333, "biggest_recent_change": 0.3655596968875443},
{"total_number_of_episodes": 4304, "number_of_timesteps": 408914, "per_episode_reward": -418.3, "episode_reward_trend_value": -0.01812649566107641, "biggest_recent_change": 0.49752060690951794},
{"total_number_of_episodes": 4314, "number_of_timesteps": 409909, "per_episode_reward": -418.23, "episode_reward_trend_value": -0.0132365937559238, "biggest_recent_change": 0.49752060690951794},
{"total_number_of_episodes": 4325, "number_of_timesteps": 410908, "per_episode_reward": -418.16, "episode_reward_trend_value": -0.010492255495770703, "biggest_recent_change": 0.49752060690951794},
{"total_number_of_episodes": 4335, "number_of_timesteps": 411794, "per_episode_reward": -418.2, "episode_reward_trend_value": -0.011780743067277576, "biggest_recent_change": 0.49752060690951794},
{"total_number_of_episodes": 4345, "number_of_timesteps": 412728, "per_episode_reward": -418.11, "episode_reward_trend_value": -0.009380760498219665, "biggest_recent_change": 0.49752060690951794},
{"total_number_of_episodes": 4355, "number_of_timesteps": 413681, "per_episode_reward": -417.89, "episode_reward_trend_value": -0.005051028829888714, "biggest_recent_change": 0.49752060690951794},
{"total_number_of_episodes": 4366, "number_of_timesteps": 414940, "per_episode_reward": -418.12, "episode_reward_trend_value": -0.004301071439601224, "biggest_recent_change": 0.49752060690951794},
{"total_number_of_episodes": 4377, "number_of_timesteps": 415910, "per_episode_reward": -418.26, "episode_reward_trend_value": -0.006272570761382212, "biggest_recent_change": 0.49752060690951794},
{"total_number_of_episodes": 4387, "number_of_timesteps": 417044, "per_episode_reward": -418.23, "episode_reward_trend_value": -0.004705138370995125, "biggest_recent_change": 0.49752060690951794},
{"total_number_of_episodes": 4399, "number_of_timesteps": 418442, "per_episode_reward": -418.21, "episode_reward_trend_value": 0.0009915344921176306, "biggest_recent_change": 0.22241170587699344},
{"total_number_of_episodes": 4409, "number_of_timesteps": 419374, "per_episode_reward": -417.98, "episode_reward_trend_value": 0.0027173505831866703, "biggest_recent_change": 0.22985492277240382},
{"total_number_of_episodes": 4420, "number_of_timesteps": 420479, "per_episode_reward": -417.35, "episode_reward_trend_value": 0.009002896723471723, "biggest_recent_change": 0.6318431226869734},
{"total_number_of_episodes": 4430, "number_of_timesteps": 421409, "per_episode_reward": -417.45, "episode_reward_trend_value": 0.008386079241446017, "biggest_recent_change": 0.6318431226869734},
{"total_number_of_episodes": 4441, "number_of_timesteps": 422502, "per_episode_reward": -417.24, "episode_reward_trend_value": 0.00963910492723446, "biggest_recent_change": 0.6318431226869734},
{"total_number_of_episodes": 4451, "number_of_timesteps": 423390, "per_episode_reward": -417.28, "episode_reward_trend_value": 0.006780406555796187, "biggest_recent_change": 0.6318431226869734},
{"total_number_of_episodes": 4462, "number_of_timesteps": 424679, "per_episode_reward": -416.93, "episode_reward_trend_value": 0.013189994497556276, "biggest_recent_change": 0.6318431226869734},
{"total_number_of_episodes": 4472, "number_of_timesteps": 425699, "per_episode_reward": -416.45, "episode_reward_trend_value": 0.020159596433240445, "biggest_recent_change": 0.6318431226869734},
{"total_number_of_episodes": 4482, "number_of_timesteps": 426637, "per_episode_reward": -415.73, "episode_reward_trend_value": 0.027725158734660405, "biggest_recent_change": 0.7157141925246151},
{"total_number_of_episodes": 4492, "number_of_timesteps": 427848, "per_episode_reward": -415.42, "episode_reward_trend_value": 0.03101920193306442, "biggest_recent_change": 0.7157141925246151},
{"total_number_of_episodes": 4503, "number_of_timesteps": 428905, "per_episode_reward": -414.95, "episode_reward_trend_value": 0.033727259468527865, "biggest_recent_change": 0.7157141925246151},
{"total_number_of_episodes": 4513, "number_of_timesteps": 429698, "per_episode_reward": -414.46, "episode_reward_trend_value": 0.03209671123091008, "biggest_recent_change": 0.7157141925246151},
{"total_number_of_episodes": 4524, "number_of_timesteps": 430516, "per_episode_reward": -413.97, "episode_reward_trend_value": 0.03863043760729283, "biggest_recent_change": 0.7157141925246151},
{"total_number_of_episodes": 4534, "number_of_timesteps": 431362, "per_episode_reward": -413.73, "episode_reward_trend_value": 0.03904163922116355, "biggest_recent_change": 0.7157141925246151},
{"total_number_of_episodes": 4545, "number_of_timesteps": 432324, "per_episode_reward": -413.27, "episode_reward_trend_value": 0.04461192044540717, "biggest_recent_change": 0.7157141925246151},
{"total_number_of_episodes": 4555, "number_of_timesteps": 433355, "per_episode_reward": -412.75, "episode_reward_trend_value": 0.046460884248623165, "biggest_recent_change": 0.7157141925246151},
{"total_number_of_episodes": 4565, "number_of_timesteps": 434372, "per_episode_reward": -412.32, "episode_reward_trend_value": 0.04592848532951797, "biggest_recent_change": 0.7157141925246151},
{"total_number_of_episodes": 4575, "number_of_timesteps": 435139, "per_episode_reward": -411.89, "episode_reward_trend_value": 0.04275891798784086, "biggest_recent_change": 0.5208579511708535},
{"total_number_of_episodes": 4585, "number_of_timesteps": 436023, "per_episode_reward": -411.49, "episode_reward_trend_value": 0.04374289766638716, "biggest_recent_change": 0.5208579511708535},
{"total_number_of_episodes": 4595, "number_of_timesteps": 436751, "per_episode_reward": -411.04, "episode_reward_trend_value": 0.04338382335126375, "biggest_recent_change": 0.5208579511708535},
{"total_number_of_episodes": 4605, "number_of_timesteps": 437601, "per_episode_reward": -410.82, "episode_reward_trend_value": 0.040472460589587755, "biggest_recent_change": 0.5208579511708535},
{"total_number_of_episodes": 4615, "number_of_timesteps": 438381, "per_episode_reward": -410.71, "episode_reward_trend_value": 0.036216893409953044, "biggest_recent_change": 0.5208579511708535},
{"total_number_of_episodes": 4626, "number_of_timesteps": 439396, "per_episode_reward": -410.21, "episode_reward_trend_value": 0.03915558501473002, "biggest_recent_change": 0.5208579511708535},
{"total_number_of_episodes": 4636, "number_of_timesteps": 440374, "per_episode_reward": -409.65, "episode_reward_trend_value": 0.04016203360837191, "biggest_recent_change": 0.5518638398016265},
{"total_number_of_episodes": 4647, "number_of_timesteps": 441733, "per_episode_reward": -409.3, "episode_reward_trend_value": 0.0383507696245993, "biggest_recent_change": 0.5518638398016265},
{"total_number_of_episodes": 4658, "number_of_timesteps": 442993, "per_episode_reward": -409.06, "episode_reward_trend_value": 0.036175761780690305, "biggest_recent_change": 0.5518638398016265},
{"total_number_of_episodes": 4670, "number_of_timesteps": 444741, "per_episode_reward": -408.81, "episode_reward_trend_value": 0.03414211829147449, "biggest_recent_change": 0.5518638398016265},
{"total_number_of_episodes": 4680, "number_of_timesteps": 446085, "per_episode_reward": -408.65, "episode_reward_trend_value": 0.031553848798862166, "biggest_recent_change": 0.5518638398016265},
{"total_number_of_episodes": 4691, "number_of_timesteps": 447709, "per_episode_reward": -408.3, "episode_reward_trend_value": 0.03043179086630137, "biggest_recent_change": 0.5518638398016265},
{"total_number_of_episodes": 4702, "number_of_timesteps": 449124, "per_episode_reward": -407.81, "episode_reward_trend_value": 0.033461730641036205, "biggest_recent_change": 0.5518638398016265},
{"total_number_of_episodes": 4713, "number_of_timesteps": 450761, "per_episode_reward": -407.4, "episode_reward_trend_value": 0.036844437404593894, "biggest_recent_change": 0.5518638398016265},
{"total_number_of_episodes": 4724, "number_of_timesteps": 451916, "per_episode_reward": -407.17, "episode_reward_trend_value": 0.0337431180629052, "biggest_recent_change": 0.5518638398016265},
{"total_number_of_episodes": 4734, "number_of_timesteps": 453259, "per_episode_reward": -407.02, "episode_reward_trend_value": 0.02927127265602078, "biggest_recent_change": 0.49576571247666834},
{"total_number_of_episodes": 4745, "number_of_timesteps": 454332, "per_episode_reward": -406.64, "episode_reward_trend_value": 0.0295196947101753, "biggest_recent_change": 0.49576571247666834},
{"total_number_of_episodes": 4757, "number_of_timesteps": 455113, "per_episode_reward": -406.38, "episode_reward_trend_value": 0.029828369883614415, "biggest_recent_change": 0.49576571247666834},
{"total_number_of_episodes": 4768, "number_of_timesteps": 455885, "per_episode_reward": -405.93, "episode_reward_trend_value": 0.0320334842705942, "biggest_recent_change": 0.49576571247666834},
{"total_number_of_episodes": 4778, "number_of_timesteps": 456562, "per_episode_reward": -405.71, "episode_reward_trend_value": 0.03258672642231836, "biggest_recent_change": 0.49576571247666834},
{"total_number_of_episodes": 4788, "number_of_timesteps": 457231, "per_episode_reward": -405.69, "episode_reward_trend_value": 0.029089524065135364, "biggest_recent_change": 0.49576571247666834},
{"total_number_of_episodes": 4799, "number_of_timesteps": 457944, "per_episode_reward": -405.46, "episode_reward_trend_value": 0.026117566916126912, "biggest_recent_change": 0.44588551257243125},
{"total_number_of_episodes": 4809, "number_of_timesteps": 458581, "per_episode_reward": -404.69, "episode_reward_trend_value": 0.0300100683621142, "biggest_recent_change": 0.7638676232618877},
{"total_number_of_episodes": 4821, "number_of_timesteps": 459408, "per_episode_reward": -404.59, "episode_reward_trend_value": 0.028660901646413904, "biggest_recent_change": 0.7638676232618877},
{"total_number_of_episodes": 4831, "number_of_timesteps": 460113, "per_episode_reward": -404.24, "episode_reward_trend_value": 0.030834113009156127, "biggest_recent_change": 0.7638676232618877},
{"total_number_of_episodes": 4841, "number_of_timesteps": 460843, "per_episode_reward": -404.38, "episode_reward_trend_value": 0.025061804702064844, "biggest_recent_change": 0.7638676232618877},
{"total_number_of_episodes": 4852, "number_of_timesteps": 461589, "per_episode_reward": -403.72, "episode_reward_trend_value": 0.029486617637071, "biggest_recent_change": 0.7638676232618877},
{"total_number_of_episodes": 4863, "number_of_timesteps": 462330, "per_episode_reward": -403.22, "episode_reward_trend_value": 0.030156586339643354, "biggest_recent_change": 0.7638676232618877},
{"total_number_of_episodes": 4873, "number_of_timesteps": 463005, "per_episode_reward": -402.86, "episode_reward_trend_value": 0.03171831885082384, "biggest_recent_change": 0.7638676232618877},
{"total_number_of_episodes": 4885, "number_of_timesteps": 463876, "per_episode_reward": -402.72, "episode_reward_trend_value": 0.03298934362826458, "biggest_recent_change": 0.7638676232618877},
{"total_number_of_episodes": 4896, "number_of_timesteps": 464744, "per_episode_reward": -402.45, "episode_reward_trend_value": 0.03343699252492911, "biggest_recent_change": 0.7638676232618877},
{"total_number_of_episodes": 4906, "number_of_timesteps": 465513, "per_episode_reward": -402.23, "episode_reward_trend_value": 0.02741083357696602, "biggest_recent_change": 0.66148093216691},
{"total_number_of_episodes": 4917, "number_of_timesteps": 466383, "per_episode_reward": -402.0, "episode_reward_trend_value": 0.028786508584710824, "biggest_recent_change": 0.66148093216691},
{"total_number_of_episodes": 4927, "number_of_timesteps": 467189, "per_episode_reward": -401.68, "episode_reward_trend_value": 0.028505701044475827, "biggest_recent_change": 0.66148093216691},
{"total_number_of_episodes": 4937, "number_of_timesteps": 468173, "per_episode_reward": -401.26, "episode_reward_trend_value": 0.03468912003937071, "biggest_recent_change": 0.66148093216691},
{"total_number_of_episodes": 4947, "number_of_timesteps": 469431, "per_episode_reward": -400.79, "episode_reward_trend_value": 0.032563648293789056, "biggest_recent_change": 0.5061826958039433},
{"total_number_of_episodes": 4958, "number_of_timesteps": 470785, "per_episode_reward": -400.76, "episode_reward_trend_value": 0.027281334881676382, "biggest_recent_change": 0.4701884750645604},
{"total_number_of_episodes": 4969, "number_of_timesteps": 471886, "per_episode_reward": -400.73, "episode_reward_trend_value": 0.02364449922756901, "biggest_recent_change": 0.4701884750645604},
{"total_number_of_episodes": 4979, "number_of_timesteps": 472811, "per_episode_reward": -400.4, "episode_reward_trend_value": 0.025748552607279863, "biggest_recent_change": 0.4701884750645604},
{"total_number_of_episodes": 4989, "number_of_timesteps": 473948, "per_episode_reward": -400.17, "episode_reward_trend_value": 0.025283411025079278, "biggest_recent_change": 0.4701884750645604},
{"total_number_of_episodes": 4999, "number_of_timesteps": 475223, "per_episode_reward": -399.67, "episode_reward_trend_value": 0.028370066844605746, "biggest_recent_change": 0.4993123417025913},
{"total_number_of_episodes": 5009, "number_of_timesteps": 476156, "per_episode_reward": -399.24, "episode_reward_trend_value": 0.03067411869012378, "biggest_recent_change": 0.4993123417025913},
{"total_number_of_episodes": 5019, "number_of_timesteps": 477148, "per_episode_reward": -398.62, "episode_reward_trend_value": 0.0339824393047176, "biggest_recent_change": 0.617462952521123},
{"total_number_of_episodes": 5030, "number_of_timesteps": 478108, "per_episode_reward": -397.95, "episode_reward_trend_value": 0.036835276474525044, "biggest_recent_change": 0.6739574846902201},
{"total_number_of_episodes": 5040, "number_of_timesteps": 478964, "per_episode_reward": -397.49, "episode_reward_trend_value": 0.0366640991857859, "biggest_recent_change": 0.6739574846902201},
{"total_number_of_episodes": 5050, "number_of_timesteps": 479745, "per_episode_reward": -397.23, "episode_reward_trend_value": 0.03922786601412377, "biggest_recent_change": 0.6739574846902201},
{"total_number_of_episodes": 5060, "number_of_timesteps": 480603, "per_episode_reward": -396.97, "episode_reward_trend_value": 0.04180331987943318, "biggest_recent_change": 0.6739574846902201},
{"total_number_of_episodes": 5071, "number_of_timesteps": 481634, "per_episode_reward": -396.66, "episode_reward_trend_value": 0.04157463620572533, "biggest_recent_change": 0.6739574846902201},
{"total_number_of_episodes": 5081, "number_of_timesteps": 482719, "per_episode_reward": -396.27, "episode_reward_trend_value": 0.04339078535053444, "biggest_recent_change": 0.6739574846902201},
{"total_number_of_episodes": 5091, "number_of_timesteps": 483829, "per_episode_reward": -395.95, "episode_reward_trend_value": 0.04143365644498671, "biggest_recent_change": 0.6739574846902201},
{"total_number_of_episodes": 5101, "number_of_timesteps": 484825, "per_episode_reward": -395.77, "episode_reward_trend_value": 0.03857792146153479, "biggest_recent_change": 0.6739574846902201},
{"total_number_of_episodes": 5111, "number_of_timesteps": 485669, "per_episode_reward": -395.41, "episode_reward_trend_value": 0.03567652286583072, "biggest_recent_change": 0.6739574846902201},
{"total_number_of_episodes": 5121, "number_of_timesteps": 486548, "per_episode_reward": -394.84, "episode_reward_trend_value": 0.034520477984723484, "biggest_recent_change": 0.5699134453905685},
{"total_number_of_episodes": 5131, "number_of_timesteps": 487622, "per_episode_reward": -394.5, "episode_reward_trend_value": 0.033198650729120045, "biggest_recent_change": 0.5699134453905685},
{"total_number_of_episodes": 5141, "number_of_timesteps": 488779, "per_episode_reward": -394.39, "episode_reward_trend_value": 0.03160120321324926, "biggest_recent_change": 0.5699134453905685},
{"total_number_of_episodes": 5151, "number_of_timesteps": 489907, "per_episode_reward": -394.18, "episode_reward_trend_value": 0.031025277398798477, "biggest_recent_change": 0.5699134453905685},
{"total_number_of_episodes": 5161, "number_of_timesteps": 491164, "per_episode_reward": -394.05, "episode_reward_trend_value": 0.02900127350607009, "biggest_recent_change": 0.5699134453905685},
{"total_number_of_episodes": 5171, "number_of_timesteps": 492073, "per_episode_reward": -393.97, "episode_reward_trend_value": 0.025593511606302223, "biggest_recent_change": 0.5699134453905685},
{"total_number_of_episodes": 5181, "number_of_timesteps": 493236, "per_episode_reward": -393.85, "episode_reward_trend_value": 0.02327510375621197, "biggest_recent_change": 0.5699134453905685},

{"total_number_of_episodes": 5191, "number_of_timesteps": 494519, "per_episode_reward": -393.65, "episode_reward_trend_value": 0.023461222688936485, "biggest_recent_change": 0.5699134453905685},
{"total_number_of_episodes": 5202, "number_of_timesteps": 495618, "per_episode_reward": -393.48, "episode_reward_trend_value": 0.02138552565049723, "biggest_recent_change": 0.5699134453905685},
{"total_number_of_episodes": 5212, "number_of_timesteps": 496624, "per_episode_reward": -392.65, "episode_reward_trend_value": 0.024352845732659036, "biggest_recent_change": 0.8369722527851309},
{"total_number_of_episodes": 5222, "number_of_timesteps": 497606, "per_episode_reward": -392.34, "episode_reward_trend_value": 0.0239852475035933, "biggest_recent_change": 0.8369722527851309},
{"total_number_of_episodes": 5232, "number_of_timesteps": 498770, "per_episode_reward": -392.07, "episode_reward_trend_value": 0.02576307089761119, "biggest_recent_change": 0.8369722527851309},
{"total_number_of_episodes": 5242, "number_of_timesteps": 500067, "per_episode_reward": -391.85, "episode_reward_trend_value": 0.02587543079118796, "biggest_recent_change": 0.8369722527851309},
{"total_number_of_episodes": 5252, "number_of_timesteps": 500971, "per_episode_reward": -391.51, "episode_reward_trend_value": 0.02816797997480573, "biggest_recent_change": 0.8369722527851309},
{"total_number_of_episodes": 5263, "number_of_timesteps": 502078, "per_episode_reward": -391.13, "episode_reward_trend_value": 0.0314546198738564, "biggest_recent_change": 0.8369722527851309},
{"total_number_of_episodes": 5273, "number_of_timesteps": 503267, "per_episode_reward": -390.81, "episode_reward_trend_value": 0.033783623153698907, "biggest_recent_change": 0.8369722527851309},
{"total_number_of_episodes": 5284, "number_of_timesteps": 504825, "per_episode_reward": -390.49, "episode_reward_trend_value": 0.03511544282360685, "biggest_recent_change": 0.8369722527851309},
{"total_number_of_episodes": 5294, "number_of_timesteps": 505896, "per_episode_reward": -390.19, "episode_reward_trend_value": 0.03658025279605176, "biggest_recent_change": 0.8369722527851309},
{"total_number_of_episodes": 5304, "number_of_timesteps": 507072, "per_episode_reward": -390.12, "episode_reward_trend_value": 0.028128053106164924, "biggest_recent_change": 0.3792676703359348},
{"total_number_of_episodes": 5314, "number_of_timesteps": 508303, "per_episode_reward": -389.99, "episode_reward_trend_value": 0.02614226603629517, "biggest_recent_change": 0.3792676703359348},
{"total_number_of_episodes": 5324, "number_of_timesteps": 509234, "per_episode_reward": -389.48, "episode_reward_trend_value": 0.028742419899569743, "biggest_recent_change": 0.5117611799921633},
{"total_number_of_episodes": 5334, "number_of_timesteps": 510208, "per_episode_reward": -389.26, "episode_reward_trend_value": 0.028782584214278966, "biggest_recent_change": 0.5117611799921633},
{"total_number_of_episodes": 5345, "number_of_timesteps": 511855, "per_episode_reward": -387.57, "episode_reward_trend_value": 0.04384859607865792, "biggest_recent_change": 1.6888156340101546},
{"total_number_of_episodes": 5355, "number_of_timesteps": 513422, "per_episode_reward": -386.97, "episode_reward_trend_value": 0.04629490305418421, "biggest_recent_change": 1.6888156340101546},
{"total_number_of_episodes": 5365, "number_of_timesteps": 514377, "per_episode_reward": -386.73, "episode_reward_trend_value": 0.045298374029310806, "biggest_recent_change": 1.6888156340101546},
{"total_number_of_episodes": 5375, "number_of_timesteps": 515493, "per_episode_reward": -386.56, "episode_reward_trend_value": 0.04370194890799439, "biggest_recent_change": 1.6888156340101546},
{"total_number_of_episodes": 5386, "number_of_timesteps": 516624, "per_episode_reward": -386.38, "episode_reward_trend_value": 0.04240245324372911, "biggest_recent_change": 1.6888156340101546},
{"total_number_of_episodes": 5396, "number_of_timesteps": 517521, "per_episode_reward": -386.07, "episode_reward_trend_value": 0.04494533108608923, "biggest_recent_change": 1.6888156340101546},
{"total_number_of_episodes": 5406, "number_of_timesteps": 518622, "per_episode_reward": -385.65, "episode_reward_trend_value": 0.04820105651862971, "biggest_recent_change": 1.6888156340101546},
{"total_number_of_episodes": 5416, "number_of_timesteps": 519715, "per_episode_reward": -385.48, "episode_reward_trend_value": 0.04448009028270626, "biggest_recent_change": 1.6888156340101546},
{"total_number_of_episodes": 5427, "number_of_timesteps": 520769, "per_episode_reward": -385.03, "episode_reward_trend_value": 0.04696723874152566, "biggest_recent_change": 1.6888156340101546},
{"total_number_of_episodes": 5437, "number_of_timesteps": 521699, "per_episode_reward": -384.8, "episode_reward_trend_value": 0.030713442580505696, "biggest_recent_change": 0.5994352981333009},
{"total_number_of_episodes": 5448, "number_of_timesteps": 523123, "per_episode_reward": -384.38, "episode_reward_trend_value": 0.028717182023259763, "biggest_recent_change": 0.44781833076956445},
{"total_number_of_episodes": 5459, "number_of_timesteps": 524809, "per_episode_reward": -384.0, "episode_reward_trend_value": 0.030338034921389107, "biggest_recent_change": 0.44781833076956445},
{"total_number_of_episodes": 5471, "number_of_timesteps": 526354, "per_episode_reward": -383.84, "episode_reward_trend_value": 0.03024178830409912, "biggest_recent_change": 0.44781833076956445},
{"total_number_of_episodes": 5481, "number_of_timesteps": 527785, "per_episode_reward": -383.38, "episode_reward_trend_value": 0.0333271730895995, "biggest_recent_change": 0.46208726387942534},
{"total_number_of_episodes": 5491, "number_of_timesteps": 529065, "per_episode_reward": -382.83, "episode_reward_trend_value": 0.036024303826013696, "biggest_recent_change": 0.5478750527850025},
{"total_number_of_episodes": 5501, "number_of_timesteps": 530462, "per_episode_reward": -382.47, "episode_reward_trend_value": 0.03532962692334347, "biggest_recent_change": 0.5478750527850025},
{"total_number_of_episodes": 5511, "number_of_timesteps": 531719, "per_episode_reward": -382.17, "episode_reward_trend_value": 0.03672273653376313, "biggest_recent_change": 0.5478750527850025},
{"total_number_of_episodes": 5521, "number_of_timesteps": 532984, "per_episode_reward": -382.03, "episode_reward_trend_value": 0.03335001527999945, "biggest_recent_change": 0.5478750527850025},
{"total_number_of_episodes": 5531, "number_of_timesteps": 533919, "per_episode_reward": -381.85, "episode_reward_trend_value": 0.03277039093372246, "biggest_recent_change": 0.5478750527850025},
{"total_number_of_episodes": 5541, "number_of_timesteps": 534955, "per_episode_reward": -381.6, "episode_reward_trend_value": 0.030919097925983074, "biggest_recent_change": 0.5478750527850025},
{"total_number_of_episodes": 5552, "number_of_timesteps": 536298, "per_episode_reward": -381.27, "episode_reward_trend_value": 0.030419023796865, "biggest_recent_change": 0.5478750527850025},
{"total_number_of_episodes": 5562, "number_of_timesteps": 537349, "per_episode_reward": -380.95, "episode_reward_trend_value": 0.032077504801122814, "biggest_recent_change": 0.5478750527850025},
{"total_number_of_episodes": 5572, "number_of_timesteps": 538371, "per_episode_reward": -380.75, "episode_reward_trend_value": 0.02917542584321243, "biggest_recent_change": 0.5478750527850025},
{"total_number_of_episodes": 5583, "number_of_timesteps": 539811, "per_episode_reward": -380.24, "episode_reward_trend_value": 0.02877321075904875, "biggest_recent_change": 0.5116756952102719},
{"total_number_of_episodes": 5593, "number_of_timesteps": 541091, "per_episode_reward": -379.88, "episode_reward_trend_value": 0.028814091368934036, "biggest_recent_change": 0.5116756952102719},
{"total_number_of_episodes": 5603, "number_of_timesteps": 542172, "per_episode_reward": -378.79, "episode_reward_trend_value": 0.03753077299496049, "biggest_recent_change": 1.0867554300392044},
{"total_number_of_episodes": 5614, "number_of_timesteps": 543424, "per_episode_reward": -378.33, "episode_reward_trend_value": 0.04102964717317263, "biggest_recent_change": 1.0867554300392044},
{"total_number_of_episodes": 5624, "number_of_timesteps": 544506, "per_episode_reward": -377.96, "episode_reward_trend_value": 0.043247971082342296, "biggest_recent_change": 1.0867554300392044},
{"total_number_of_episodes": 5635, "number_of_timesteps": 545799, "per_episode_reward": -377.65, "episode_reward_trend_value": 0.04388057059561813, "biggest_recent_change": 1.0867554300392044},
{"total_number_of_episodes": 5646, "number_of_timesteps": 547410, "per_episode_reward": -377.4, "episode_reward_trend_value": 0.0428929513401335, "biggest_recent_change": 1.0867554300392044},
{"total_number_of_episodes": 5656, "number_of_timesteps": 548483, "per_episode_reward": -377.28, "episode_reward_trend_value": 0.0407972351559124, "biggest_recent_change": 1.0867554300392044},
{"total_number_of_episodes": 5666, "number_of_timesteps": 549496, "per_episode_reward": -377.02, "episode_reward_trend_value": 0.04144075707960092, "biggest_recent_change": 1.0867554300392044},
{"total_number_of_episodes": 5676, "number_of_timesteps": 550317, "per_episode_reward": -376.61, "episode_reward_trend_value": 0.04029661989417137, "biggest_recent_change": 1.0867554300392044},
{"total_number_of_episodes": 5687, "number_of_timesteps": 551266, "per_episode_reward": -376.45, "episode_reward_trend_value": 0.03811382507099349, "biggest_recent_change": 1.0867554300392044},
{"total_number_of_episodes": 5697, "number_of_timesteps": 552208, "per_episode_reward": -376.31, "episode_reward_trend_value": 0.027602815271997844, "biggest_recent_change": 0.45917209396992575},
{"total_number_of_episodes": 5707, "number_of_timesteps": 553277, "per_episode_reward": -376.08, "episode_reward_trend_value": 0.025097754979429964, "biggest_recent_change": 0.4087033485216125},
{"total_number_of_episodes": 5717, "number_of_timesteps": 554607, "per_episode_reward": -375.7, "episode_reward_trend_value": 0.025179128202962097, "biggest_recent_change": 0.4087033485216125},
{"total_number_of_episodes": 5727, "number_of_timesteps": 556611, "per_episode_reward": -375.03, "episode_reward_trend_value": 0.02908755681490523, "biggest_recent_change": 0.6618480085543297},
{"total_number_of_episodes": 5737, "number_of_timesteps": 557972, "per_episode_reward": -374.89, "episode_reward_trend_value": 0.027930359730253762, "biggest_recent_change": 0.6618480085543297},
{"total_number_of_episodes": 5747, "number_of_timesteps": 560013, "per_episode_reward": -374.59, "episode_reward_trend_value": 0.029853307981382686, "biggest_recent_change": 0.6618480085543297},
{"total_number_of_episodes": 5757, "number_of_timesteps": 561406, "per_episode_reward": -374.32, "episode_reward_trend_value": 0.029988646332302298, "biggest_recent_change": 0.6618480085543297},
{"total_number_of_episodes": 5767, "number_of_timesteps": 562843, "per_episode_reward": -374.2, "episode_reward_trend_value": 0.026828877173208338, "biggest_recent_change": 0.6618480085543297},
{"total_number_of_episodes": 5777, "number_of_timesteps": 564424, "per_episode_reward": -373.78, "episode_reward_trend_value": 0.029722388688242063, "biggest_recent_change": 0.6618480085543297},
{"total_number_of_episodes": 5789, "number_of_timesteps": 566336, "per_episode_reward": -373.36, "episode_reward_trend_value": 0.032811806499598285, "biggest_recent_change": 0.6618480085543297},
{"total_number_of_episodes": 5799, "number_of_timesteps": 567661, "per_episode_reward": -373.05, "episode_reward_trend_value": 0.03356706401096403, "biggest_recent_change": 0.6618480085543297},
{"total_number_of_episodes": 5810, "number_of_timesteps": 568930, "per_episode_reward": -372.71, "episode_reward_trend_value": 0.03319140833311722, "biggest_recent_change": 0.6618480085543297},
{"total_number_of_episodes": 5820, "number_of_timesteps": 570068, "per_episode_reward": -372.5, "episode_reward_trend_value": 0.028183860498374243, "biggest_recent_change": 0.4221515140145584},
{"total_number_of_episodes": 5830, "number_of_timesteps": 571374, "per_episode_reward": -372.4, "episode_reward_trend_value": 0.027670192087391698, "biggest_recent_change": 0.4221515140145584},
{"total_number_of_episodes": 5840, "number_of_timesteps": 573098, "per_episode_reward": -372.22, "episode_reward_trend_value": 0.02639370179519902, "biggest_recent_change": 0.4221515140145584},
{"total_number_of_episodes": 5852, "number_of_timesteps": 574887, "per_episode_reward": -371.8, "episode_reward_trend_value": 0.027979170233297483, "biggest_recent_change": 0.4221515140145584},
{"total_number_of_episodes": 5862, "number_of_timesteps": 575939, "per_episode_reward": -370.93, "episode_reward_trend_value": 0.03626034739675864, "biggest_recent_change": 0.8696300689146597},
{"total_number_of_episodes": 5872, "number_of_timesteps": 577252, "per_episode_reward": -370.68, "episode_reward_trend_value": 0.03442068248820078, "biggest_recent_change": 0.8696300689146597},
{"total_number_of_episodes": 5882, "number_of_timesteps": 578924, "per_episode_reward": -370.36, "episode_reward_trend_value": 0.03326228289642283, "biggest_recent_change": 0.8696300689146597},
{"total_number_of_episodes": 5892, "number_of_timesteps": 580070, "per_episode_reward": -370.01, "episode_reward_trend_value": 0.03385503946897693, "biggest_recent_change": 0.8696300689146597},
{"total_number_of_episodes": 5902, "number_of_timesteps": 581705, "per_episode_reward": -369.72, "episode_reward_trend_value": 0.033211899094084806, "biggest_recent_change": 0.8696300689146597},
{"total_number_of_episodes": 5913, "number_of_timesteps": 583360, "per_episode_reward": -369.19, "episode_reward_trend_value": 0.03678452647728755, "biggest_recent_change": 0.8696300689146597},
{"total_number_of_episodes": 5926, "number_of_timesteps": 584990, "per_episode_reward": -368.89, "episode_reward_trend_value": 0.03901773633109479, "biggest_recent_change": 0.8696300689146597},
{"total_number_of_episodes": 5936, "number_of_timesteps": 586158, "per_episode_reward": -368.44, "episode_reward_trend_value": 0.042003543161310594, "biggest_recent_change": 0.8696300689146597},
{"total_number_of_episodes": 5946, "number_of_timesteps": 587628, "per_episode_reward": -368.15, "episode_reward_trend_value": 0.04055559541503031, "biggest_recent_change": 0.8696300689146597},
{"total_number_of_episodes": 5957, "number_of_timesteps": 589008, "per_episode_reward": -367.69, "episode_reward_trend_value": 0.03602716964897152, "biggest_recent_change": 0.532705167915708},
{"total_number_of_episodes": 5967, "number_of_timesteps": 590061, "per_episode_reward": -367.4, "episode_reward_trend_value": 0.03646427881997801, "biggest_recent_change": 0.532705167915708},
{"total_number_of_episodes": 5977, "number_of_timesteps": 591232, "per_episode_reward": -367.14, "episode_reward_trend_value": 0.03584437466348302, "biggest_recent_change": 0.532705167915708},
{"total_number_of_episodes": 5987, "number_of_timesteps": 592265, "per_episode_reward": -366.93, "episode_reward_trend_value": 0.034199867631682285, "biggest_recent_change": 0.532705167915708},
{"total_number_of_episodes": 5997, "number_of_timesteps": 593390, "per_episode_reward": -366.69, "episode_reward_trend_value": 0.03361350210985405, "biggest_recent_change": 0.532705167915708},
{"total_number_of_episodes": 6008, "number_of_timesteps": 595072, "per_episode_reward": -366.17, "episode_reward_trend_value": 0.03355331683521033, "biggest_recent_change": 0.5272884931977728},
{"total_number_of_episodes": 6018, "number_of_timesteps": 596355, "per_episode_reward": -365.8, "episode_reward_trend_value": 0.034361387921208256, "biggest_recent_change": 0.5272884931977728},
{"total_number_of_episodes": 6028, "number_of_timesteps": 597602, "per_episode_reward": -365.39, "episode_reward_trend_value": 0.03388684014243874, "biggest_recent_change": 0.5272884931977728},
{"total_number_of_episodes": 6038, "number_of_timesteps": 598696, "per_episode_reward": -365.05, "episode_reward_trend_value": 0.03451084439494834, "biggest_recent_change": 0.5272884931977728},
{"total_number_of_episodes": 6048, "number_of_timesteps": 600121, "per_episode_reward": -364.74, "episode_reward_trend_value": 0.03284903384788752, "biggest_recent_change": 0.5272884931977728},
{"total_number_of_episodes": 6058, "number_of_timesteps": 601451, "per_episode_reward": -364.38, "episode_reward_trend_value": 0.03355602533478709, "biggest_recent_change": 0.5272884931977728},
{"total_number_of_episodes": 6069, "number_of_timesteps": 603117, "per_episode_reward": -363.84, "episode_reward_trend_value": 0.03666127358279141, "biggest_recent_change": 0.5382371561274795},
{"total_number_of_episodes": 6079, "number_of_timesteps": 604570, "per_episode_reward": -363.35, "episode_reward_trend_value": 0.039782199987716794, "biggest_recent_change": 0.5382371561274795},
{"total_number_of_episodes": 6090, "number_of_timesteps": 605603, "per_episode_reward": -362.94, "episode_reward_trend_value": 0.041692573785014196, "biggest_recent_change": 0.5382371561274795},
{"total_number_of_episodes": 6100, "number_of_timesteps": 606557, "per_episode_reward": -362.36, "episode_reward_trend_value": 0.042318050488487795, "biggest_recent_change": 0.5835813965103966},
{"total_number_of_episodes": 6110, "number_of_timesteps": 607676, "per_episode_reward": -362.02, "episode_reward_trend_value": 0.04198679030856359, "biggest_recent_change": 0.5835813965103966},
{"total_number_of_episodes": 6121, "number_of_timesteps": 609210, "per_episode_reward": -361.57, "episode_reward_trend_value": 0.04237282826394638, "biggest_recent_change": 0.5835813965103966},
{"total_number_of_episodes": 6132, "number_of_timesteps": 610435, "per_episode_reward": -360.64, "episode_reward_trend_value": 0.0490068902277004, "biggest_recent_change": 0.9366004041095835},
{"total_number_of_episodes": 6142, "number_of_timesteps": 611394, "per_episode_reward": -360.55, "episode_reward_trend_value": 0.04645617499552499, "biggest_recent_change": 0.9366004041095835},
{"total_number_of_episodes": 6153, "number_of_timesteps": 612507, "per_episode_reward": -360.47, "episode_reward_trend_value": 0.04342420527481118, "biggest_recent_change": 0.9366004041095835},
{"total_number_of_episodes": 6163, "number_of_timesteps": 613661, "per_episode_reward": -360.17, "episode_reward_trend_value": 0.040697283459707655, "biggest_recent_change": 0.9366004041095835},
{"total_number_of_episodes": 6173, "number_of_timesteps": 614847, "per_episode_reward": -360.03, "episode_reward_trend_value": 0.0368986451826888, "biggest_recent_change": 0.9366004041095835},
{"total_number_of_episodes": 6184, "number_of_timesteps": 615850, "per_episode_reward": -359.65, "episode_reward_trend_value": 0.03653849502860125, "biggest_recent_change": 0.9366004041095835},
{"total_number_of_episodes": 6196, "number_of_timesteps": 617057, "per_episode_reward": -359.24, "episode_reward_trend_value": 0.034640786339809895, "biggest_recent_change": 0.9366004041095835},
{"total_number_of_episodes": 6207, "number_of_timesteps": 618589, "per_episode_reward": -359.08, "episode_reward_trend_value": 0.03264995865217265, "biggest_recent_change": 0.9366004041095835},
{"total_number_of_episodes": 6218, "number_of_timesteps": 620474, "per_episode_reward": -358.76, "episode_reward_trend_value": 0.0312983714730731, "biggest_recent_change": 0.9366004041095835},
{"total_number_of_episodes": 6228, "number_of_timesteps": 622176, "per_episode_reward": -358.48, "episode_reward_trend_value": 0.02399658189968553, "biggest_recent_change": 0.4127876145191749},
{"total_number_of_episodes": 6238, "number_of_timesteps": 623786, "per_episode_reward": -358.18, "episode_reward_trend_value": 0.026388428991390357, "biggest_recent_change": 0.4127876145191749},
{"total_number_of_episodes": 6248, "number_of_timesteps": 625018, "per_episode_reward": -357.79, "episode_reward_trend_value": 0.02971902471869296, "biggest_recent_change": 0.4127876145191749},
{"total_number_of_episodes": 6259, "number_of_timesteps": 626191, "per_episode_reward": -357.28, "episode_reward_trend_value": 0.03219585814559499, "biggest_recent_change": 0.5157292011893446},
{"total_number_of_episodes": 6269, "number_of_timesteps": 627551, "per_episode_reward": -356.86, "episode_reward_trend_value": 0.03517216598588548, "biggest_recent_change": 0.5157292011893446},
{"total_number_of_episodes": 6280, "number_of_timesteps": 628881, "per_episode_reward": -356.6, "episode_reward_trend_value": 0.03388535992980653, "biggest_recent_change": 0.5157292011893446},
{"total_number_of_episodes": 6290, "number_of_timesteps": 630317, "per_episode_reward": -356.37, "episode_reward_trend_value": 0.031859826772882925, "biggest_recent_change": 0.5157292011893446},
{"total_number_of_episodes": 6300, "number_of_timesteps": 631668, "per_episode_reward": -356.03, "episode_reward_trend_value": 0.0338517996263066, "biggest_recent_change": 0.5157292011893446},
{"total_number_of_episodes": 6310, "number_of_timesteps": 632932, "per_episode_reward": -355.62, "episode_reward_trend_value": 0.0348309054541264, "biggest_recent_change": 0.5157292011893446},
{"total_number_of_episodes": 6320, "number_of_timesteps": 634628, "per_episode_reward": -355.32, "episode_reward_trend_value": 0.03511075257707527, "biggest_recent_change": 0.5157292011893446},
{"total_number_of_episodes": 6330, "number_of_timesteps": 636138, "per_episode_reward": -355.04, "episode_reward_trend_value": 0.03490496558572431, "biggest_recent_change": 0.5157292011893446},
{"total_number_of_episodes": 6341, "number_of_timesteps": 638416, "per_episode_reward": -354.64, "episode_reward_trend_value": 0.03498366049095062, "biggest_recent_change": 0.5157292011893446},
{"total_number_of_episodes": 6352, "number_of_timesteps": 639854, "per_episode_reward": -354.37, "episode_reward_trend_value": 0.032286474081714304, "biggest_recent_change": 0.41390593946726995},
{"total_number_of_episodes": 6364, "number_of_timesteps": 641723, "per_episode_reward": -354.05, "episode_reward_trend_value": 0.031288757900752744, "biggest_recent_change": 0.4105079541834584},
{"total_number_of_episodes": 6374, "number_of_timesteps": 643024, "per_episode_reward": -353.88, "episode_reward_trend_value": 0.030293778976718182, "biggest_recent_change": 0.4105079541834584},
{"total_number_of_episodes": 6384, "number_of_timesteps": 644295, "per_episode_reward": -353.5, "episode_reward_trend_value": 0.03197250835856948, "biggest_recent_change": 0.4105079541834584},
{"total_number_of_episodes": 6394, "number_of_timesteps": 645839, "per_episode_reward": -353.04, "episode_reward_trend_value": 0.0332117564957116, "biggest_recent_change": 0.45158044390558416},
{"total_number_of_episodes": 6404, "number_of_timesteps": 647254, "per_episode_reward": -352.52, "episode_reward_trend_value": 0.034451259272262606, "biggest_recent_change": 0.5220632040730493},
{"total_number_of_episodes": 6414, "number_of_timesteps": 648927, "per_episode_reward": -352.19, "episode_reward_trend_value": 0.03474744611018663, "biggest_recent_change": 0.5220632040730493},
{"total_number_of_episodes": 6424, "number_of_timesteps": 649960, "per_episode_reward": -351.83, "episode_reward_trend_value": 0.035595670287219466, "biggest_recent_change": 0.5220632040730493},
{"total_number_of_episodes": 6435, "number_of_timesteps": 651705, "per_episode_reward": -351.47, "episode_reward_trend_value": 0.035234501263157525, "biggest_recent_change": 0.5220632040730493},
{"total_number_of_episodes": 6445, "number_of_timesteps": 653169, "per_episode_reward": -351.11, "episode_reward_trend_value": 0.03620384461038447, "biggest_recent_change": 0.5220632040730493},
{"total_number_of_episodes": 6455, "number_of_timesteps": 655035, "per_episode_reward": -350.8, "episode_reward_trend_value": 0.03606493936733209, "biggest_recent_change": 0.5220632040730493},
{"total_number_of_episodes": 6465, "number_of_timesteps": 656747, "per_episode_reward": -350.46, "episode_reward_trend_value": 0.03792867062982295, "biggest_recent_change": 0.5220632040730493},
{"total_number_of_episodes": 6475, "number_of_timesteps": 658071, "per_episode_reward": -350.19, "episode_reward_trend_value": 0.03667735688670114, "biggest_recent_change": 0.5220632040730493},
{"total_number_of_episodes": 6485, "number_of_timesteps": 659258, "per_episode_reward": -349.99, "episode_reward_trend_value": 0.03392760532215233, "biggest_recent_change": 0.5220632040730493},
{"total_number_of_episodes": 6495, "number_of_timesteps": 660626, "per_episode_reward": -349.82, "episode_reward_trend_value": 0.029969481180330604, "biggest_recent_change": 0.36100440135368217},
{"total_number_of_episodes": 6506, "number_of_timesteps": 662402, "per_episode_reward": -349.43, "episode_reward_trend_value": 0.030640163219567917, "biggest_recent_change": 0.3916437825146204},
{"total_number_of_episodes": 6516, "number_of_timesteps": 663775, "per_episode_reward": -348.99, "episode_reward_trend_value": 0.03157743954283458, "biggest_recent_change": 0.4403848838969111},
{"total_number_of_episodes": 6526, "number_of_timesteps": 664961, "per_episode_reward": -348.59, "episode_reward_trend_value": 0.032062380744895334, "biggest_recent_change": 0.4403848838969111},
{"total_number_of_episodes": 6536, "number_of_timesteps": 666233, "per_episode_reward": -348.28, "episode_reward_trend_value": 0.03147556182023802, "biggest_recent_change": 0.4403848838969111},
{"total_number_of_episodes": 6546, "number_of_timesteps": 667575, "per_episode_reward": -348.07, "episode_reward_trend_value": 0.030368552831468304, "biggest_recent_change": 0.4403848838969111},
{"total_number_of_episodes": 6556, "number_of_timesteps": 668836, "per_episode_reward": -347.78, "episode_reward_trend_value": 0.029857544348232068, "biggest_recent_change": 0.4403848838969111},
{"total_number_of_episodes": 6566, "number_of_timesteps": 670258, "per_episode_reward": -347.43, "episode_reward_trend_value": 0.030731167266263053, "biggest_recent_change": 0.4403848838969111},
{"total_number_of_episodes": 6576, "number_of_timesteps": 671695, "per_episode_reward": -346.91, "episode_reward_trend_value": 0.034213768645420514, "biggest_recent_change": 0.5175369272203625},
{"total_number_of_episodes": 6588, "number_of_timesteps": 673195, "per_episode_reward": -346.56, "episode_reward_trend_value": 0.036243230676134566, "biggest_recent_change": 0.5175369272203625},
{"total_number_of_episodes": 6598, "number_of_timesteps": 674341, "per_episode_reward": -346.31, "episode_reward_trend_value": 0.03474059987574378, "biggest_recent_change": 0.5175369272203625},
{"total_number_of_episodes": 6608, "number_of_timesteps": 675529, "per_episode_reward": -345.68, "episode_reward_trend_value": 0.03675772655360434, "biggest_recent_change": 0.6219262849043616},
{"total_number_of_episodes": 6619, "number_of_timesteps": 677235, "per_episode_reward": -345.2, "episode_reward_trend_value": 0.03758799456645016, "biggest_recent_change": 0.6219262849043616},
{"total_number_of_episodes": 6629, "number_of_timesteps": 678699, "per_episode_reward": -344.5, "episode_reward_trend_value": 0.04204595181882319, "biggest_recent_change": 0.7086257751029166},
{"total_number_of_episodes": 6639, "number_of_timesteps": 680217, "per_episode_reward": -343.51, "episode_reward_trend_value": 0.05061687903107163, "biggest_recent_change": 0.9833626514190996},
{"total_number_of_episodes": 6649, "number_of_timesteps": 681510, "per_episode_reward": -342.48, "episode_reward_trend_value": 0.058868402922508445, "biggest_recent_change": 1.0348576686264437},
{"total_number_of_episodes": 6659, "number_of_timesteps": 683187, "per_episode_reward": -342.1, "episode_reward_trend_value": 0.05923548243161084, "biggest_recent_change": 1.0348576686264437},
{"total_number_of_episodes": 6669, "number_of_timesteps": 684626, "per_episode_reward": -341.8, "episode_reward_trend_value": 0.05683121386797123, "biggest_recent_change": 1.0348576686264437},
{"total_number_of_episodes": 6679, "number_of_timesteps": 686555, "per_episode_reward": -341.45, "episode_reward_trend_value": 0.05684862531094331, "biggest_recent_change": 1.0348576686264437},
{"total_number_of_episodes": 6689, "number_of_timesteps": 688065, "per_episode_reward": -341.13, "episode_reward_trend_value": 0.05747647660662033, "biggest_recent_change": 1.0348576686264437},
{"total_number_of_episodes": 6700, "number_of_timesteps": 689652, "per_episode_reward": -340.8, "episode_reward_trend_value": 0.054246529820720625, "biggest_recent_change": 1.0348576686264437},
{"total_number_of_episodes": 6710, "number_of_timesteps": 691235, "per_episode_reward": -340.24, "episode_reward_trend_value": 0.05520058038522583, "biggest_recent_change": 1.0348576686264437},
{"total_number_of_episodes": 6721, "number_of_timesteps": 692708, "per_episode_reward": -340.02, "episode_reward_trend_value": 0.049700770231864526, "biggest_recent_change": 1.0348576686264437},
{"total_number_of_episodes": 6732, "number_of_timesteps": 694509, "per_episode_reward": -339.71, "episode_reward_trend_value": 0.0422060159695017, "biggest_recent_change": 1.0348576686264437},
{"total_number_of_episodes": 6742, "number_of_timesteps": 695863, "per_episode_reward": -339.4, "episode_reward_trend_value": 0.03417577486678865, "biggest_recent_change": 0.5652377815007412},
{"total_number_of_episodes": 6752, "number_of_timesteps": 697186, "per_episode_reward": -339.16, "episode_reward_trend_value": 0.03268284713184357, "biggest_recent_change": 0.5652377815007412},
{"total_number_of_episodes": 6762, "number_of_timesteps": 698728, "per_episode_reward": -338.81, "episode_reward_trend_value": 0.03312643325379933, "biggest_recent_change": 0.5652377815007412},
{"total_number_of_episodes": 6772, "number_of_timesteps": 700190, "per_episode_reward": -338.19, "episode_reward_trend_value": 0.03621988260249825, "biggest_recent_change": 0.6284610853237496},
{"total_number_of_episodes": 6782, "number_of_timesteps": 701575, "per_episode_reward": -337.84, "episode_reward_trend_value": 0.036535684427934076, "biggest_recent_change": 0.6284610853237496},
{"total_number_of_episodes": 6792, "number_of_timesteps": 703340, "per_episode_reward": -337.59, "episode_reward_trend_value": 0.035663251364768986, "biggest_recent_change": 0.6284610853237496},
{"total_number_of_episodes": 6802, "number_of_timesteps": 705038, "per_episode_reward": -337.37, "episode_reward_trend_value": 0.031802360807781344, "biggest_recent_change": 0.6284610853237496},
{"total_number_of_episodes": 6812, "number_of_timesteps": 706532, "per_episode_reward": -337.19, "episode_reward_trend_value": 0.031476522394704415, "biggest_recent_change": 0.6284610853237496},
{"total_number_of_episodes": 6822, "number_of_timesteps": 708383, "per_episode_reward": -337.02, "episode_reward_trend_value": 0.029926518054235705, "biggest_recent_change": 0.6284610853237496},
{"total_number_of_episodes": 6832, "number_of_timesteps": 710167, "per_episode_reward": -336.7, "episode_reward_trend_value": 0.030056908214892375, "biggest_recent_change": 0.6284610853237496},
{"total_number_of_episodes": 6844, "number_of_timesteps": 712041, "per_episode_reward": -336.28, "episode_reward_trend_value": 0.031897370335948, "biggest_recent_change": 0.6284610853237496},
{"total_number_of_episodes": 6854, "number_of_timesteps": 713323, "per_episode_reward": -335.87, "episode_reward_trend_value": 0.03268060959611161, "biggest_recent_change": 0.6284610853237496},
{"total_number_of_episodes": 6865, "number_of_timesteps": 715171, "per_episode_reward": -335.56, "episode_reward_trend_value": 0.02920803157984058, "biggest_recent_change": 0.4118983510736598},
{"total_number_of_episodes": 6875, "number_of_timesteps": 716901, "per_episode_reward": -335.33, "episode_reward_trend_value": 0.027911764095138854, "biggest_recent_change": 0.4118983510736598},
{"total_number_of_episodes": 6885, "number_of_timesteps": 718465, "per_episode_reward": -335.21, "episode_reward_trend_value": 0.026473710857842687, "biggest_recent_change": 0.4118983510736598},
{"total_number_of_episodes": 6895, "number_of_timesteps": 720267, "per_episode_reward": -334.96, "episode_reward_trend_value": 0.026789241342404086, "biggest_recent_change": 0.4118983510736598},
{"total_number_of_episodes": 6906, "number_of_timesteps": 721573, "per_episode_reward": -334.41, "episode_reward_trend_value": 0.03088330639725869, "biggest_recent_change": 0.5527832590603907},
{"total_number_of_episodes": 6916, "number_of_timesteps": 722778, "per_episode_reward": -334.08, "episode_reward_trend_value": 0.03262651243601719, "biggest_recent_change": 0.5527832590603907},

{"total_number_of_episodes": 6927, "number_of_timesteps": 724534, "per_episode_reward": -333.73, "episode_reward_trend_value": 0.03301668837291598, "biggest_recent_change": 0.5527832590603907},
{"total_number_of_episodes": 6939, "number_of_timesteps": 726756, "per_episode_reward": -333.37, "episode_reward_trend_value": 0.032402325645798806, "biggest_recent_change": 0.5527832590603907},
{"total_number_of_episodes": 6949, "number_of_timesteps": 728475, "per_episode_reward": -332.94, "episode_reward_trend_value": 0.03259075918326807, "biggest_recent_change": 0.5527832590603907},
{"total_number_of_episodes": 6959, "number_of_timesteps": 729788, "per_episode_reward": -332.72, "episode_reward_trend_value": 0.03155877592246586, "biggest_recent_change": 0.5527832590603907},
{"total_number_of_episodes": 6969, "number_of_timesteps": 730983, "per_episode_reward": -332.33, "episode_reward_trend_value": 0.03336710218499156, "biggest_recent_change": 0.5527832590603907},
{"total_number_of_episodes": 6979, "number_of_timesteps": 732357, "per_episode_reward": -331.89, "episode_reward_trend_value": 0.036939078194620834, "biggest_recent_change": 0.5527832590603907},
{"total_number_of_episodes": 6989, "number_of_timesteps": 733760, "per_episode_reward": -331.65, "episode_reward_trend_value": 0.036816310529875156, "biggest_recent_change": 0.5527832590603907},
{"total_number_of_episodes": 6999, "number_of_timesteps": 735197, "per_episode_reward": -331.43, "episode_reward_trend_value": 0.033083163422430874, "biggest_recent_change": 0.44476514799850975},
{"total_number_of_episodes": 7009, "number_of_timesteps": 736598, "per_episode_reward": -331.3, "episode_reward_trend_value": 0.030978468637996075, "biggest_recent_change": 0.44476514799850975},
{"total_number_of_episodes": 7019, "number_of_timesteps": 737977, "per_episode_reward": -330.72, "episode_reward_trend_value": 0.03343103915215882, "biggest_recent_change": 0.5797182644369059},
{"total_number_of_episodes": 7029, "number_of_timesteps": 739700, "per_episode_reward": -330.18, "episode_reward_trend_value": 0.03544773886732489, "biggest_recent_change": 0.5797182644369059},
{"total_number_of_episodes": 7039, "number_of_timesteps": 741390, "per_episode_reward": -329.55, "episode_reward_trend_value": 0.03767246263767497, "biggest_recent_change": 0.6287511985872811},
{"total_number_of_episodes": 7049, "number_of_timesteps": 743133, "per_episode_reward": -329.29, "episode_reward_trend_value": 0.03808444087545695, "biggest_recent_change": 0.6287511985872811},
{"total_number_of_episodes": 7059, "number_of_timesteps": 744662, "per_episode_reward": -329.15, "episode_reward_trend_value": 0.035281040253559895, "biggest_recent_change": 0.6287511985872811},
{"total_number_of_episodes": 7069, "number_of_timesteps": 746521, "per_episode_reward": -328.97, "episode_reward_trend_value": 0.032387364516017036, "biggest_recent_change": 0.6287511985872811},
{"total_number_of_episodes": 7079, "number_of_timesteps": 747663, "per_episode_reward": -328.76, "episode_reward_trend_value": 0.03206808487455785, "biggest_recent_change": 0.6287511985872811},
{"total_number_of_episodes": 7089, "number_of_timesteps": 748987, "per_episode_reward": -328.63, "episode_reward_trend_value": 0.031153179469407, "biggest_recent_change": 0.6287511985872811},
{"total_number_of_episodes": 7099, "number_of_timesteps": 750786, "per_episode_reward": -328.39, "episode_reward_trend_value": 0.03233605544553863, "biggest_recent_change": 0.6287511985872811},
{"total_number_of_episodes": 7109, "number_of_timesteps": 752139, "per_episode_reward": -328.17, "episode_reward_trend_value": 0.028314074714111508, "biggest_recent_change": 0.6287511985872811},
{"total_number_of_episodes": 7119, "number_of_timesteps": 753833, "per_episode_reward": -327.93, "episode_reward_trend_value": 0.024942761026270292, "biggest_recent_change": 0.6287511985872811},
{"total_number_of_episodes": 7129, "number_of_timesteps": 755718, "per_episode_reward": -327.7, "episode_reward_trend_value": 0.02060138381941417, "biggest_recent_change": 0.2601286117875361},
{"total_number_of_episodes": 7139, "number_of_timesteps": 758129, "per_episode_reward": -327.41, "episode_reward_trend_value": 0.020929142036532587, "biggest_recent_change": 0.2896268513281939},
{"total_number_of_episodes": 7150, "number_of_timesteps": 759906, "per_episode_reward": -327.1, "episode_reward_trend_value": 0.022813236373397987, "biggest_recent_change": 0.3046835157309147},
{"total_number_of_episodes": 7161, "number_of_timesteps": 761424, "per_episode_reward": -326.66, "episode_reward_trend_value": 0.02566913512621593, "biggest_recent_change": 0.44136521937326734},
{"total_number_of_episodes": 7171, "number_of_timesteps": 763114, "per_episode_reward": -326.45, "episode_reward_trend_value": 0.025664288245378152, "biggest_recent_change": 0.44136521937326734},
{"total_number_of_episodes": 7182, "number_of_timesteps": 765376, "per_episode_reward": -326.21, "episode_reward_trend_value": 0.026910014774540515, "biggest_recent_change": 0.44136521937326734},
{"total_number_of_episodes": 7192, "number_of_timesteps": 767715, "per_episode_reward": -326.03, "episode_reward_trend_value": 0.026159570279189536, "biggest_recent_change": 0.44136521937326734},

{"total_number_of_episodes": 7202, "number_of_timesteps": 769335, "per_episode_reward": -325.93, "episode_reward_trend_value": 0.024836293783036784, "biggest_recent_change": 0.44136521937326734},
{"total_number_of_episodes": 7212, "number_of_timesteps": 771080, "per_episode_reward": -325.67, "episode_reward_trend_value": 0.025194151096919387, "biggest_recent_change": 0.44136521937326734},
{"total_number_of_episodes": 7222, "number_of_timesteps": 772482, "per_episode_reward": -325.42, "episode_reward_trend_value": 0.025289103477036355, "biggest_recent_change": 0.44136521937326734},
{"total_number_of_episodes": 7232, "number_of_timesteps": 774107, "per_episode_reward": -325.12, "episode_reward_trend_value": 0.025378773115627633, "biggest_recent_change": 0.44136521937326734},
{"total_number_of_episodes": 7242, "number_of_timesteps": 775847, "per_episode_reward": -324.9, "episode_reward_trend_value": 0.02442278836468606, "biggest_recent_change": 0.44136521937326734},
{"total_number_of_episodes": 7252, "number_of_timesteps": 777915, "per_episode_reward": -324.63, "episode_reward_trend_value": 0.022590501040531306, "biggest_recent_change": 0.29769711880140903},
{"total_number_of_episodes": 7262, "number_of_timesteps": 779705, "per_episode_reward": -324.08, "episode_reward_trend_value": 0.02635595558464085, "biggest_recent_change": 0.5448258071184},
{"total_number_of_episodes": 7272, "number_of_timesteps": 782971, "per_episode_reward": -323.56, "episode_reward_trend_value": 0.029406596442752668, "biggest_recent_change": 0.5448258071184},
{"total_number_of_episodes": 7282, "number_of_timesteps": 784380, "per_episode_reward": -323.13, "episode_reward_trend_value": 0.0322887175363639, "biggest_recent_change": 0.5448258071184},
{"total_number_of_episodes": 7292, "number_of_timesteps": 785872, "per_episode_reward": -322.5, "episode_reward_trend_value": 0.038145527855871504, "biggest_recent_change": 0.6257580427104017},
{"total_number_of_episodes": 7302, "number_of_timesteps": 787634, "per_episode_reward": -322.1, "episode_reward_trend_value": 0.0395940841626523, "biggest_recent_change": 0.6257580427104017},
{"total_number_of_episodes": 7312, "number_of_timesteps": 789218, "per_episode_reward": -321.73, "episode_reward_trend_value": 0.040940606483152606, "biggest_recent_change": 0.6257580427104017},
{"total_number_of_episodes": 7322, "number_of_timesteps": 790684, "per_episode_reward": -321.47, "episode_reward_trend_value": 0.0405517205788063, "biggest_recent_change": 0.6257580427104017},
{"total_number_of_episodes": 7332, "number_of_timesteps": 792520, "per_episode_reward": -321.28, "episode_reward_trend_value": 0.040260032698531886, "biggest_recent_change": 0.6257580427104017},
{"total_number_of_episodes": 7342, "number_of_timesteps": 794154, "per_episode_reward": -321.03, "episode_reward_trend_value": 0.039937603120113054, "biggest_recent_change": 0.6257580427104017},
{"total_number_of_episodes": 7352, "number_of_timesteps": 798777, "per_episode_reward": -320.78, "episode_reward_trend_value": 0.036661736486544465, "biggest_recent_change": 0.6257580427104017},
{"total_number_of_episodes": 7362, "number_of_timesteps": 800763, "per_episode_reward": -320.33, "episode_reward_trend_value": 0.035914013061309584, "biggest_recent_change": 0.6257580427104017},
{"total_number_of_episodes": 7372, "number_of_timesteps": 801885, "per_episode_reward": -319.98, "episode_reward_trend_value": 0.03495924048349871, "biggest_recent_change": 0.6257580427104017},
{"total_number_of_episodes": 7382, "number_of_timesteps": 803097, "per_episode_reward": -319.69, "episode_reward_trend_value": 0.031214886585473778, "biggest_recent_change": 0.4538364895103655},
{"total_number_of_episodes": 7393, "number_of_timesteps": 804401, "per_episode_reward": -319.32, "episode_reward_trend_value": 0.030882773130446774, "biggest_recent_change": 0.4538364895103655},
{"total_number_of_episodes": 7403, "number_of_timesteps": 805537, "per_episode_reward": -318.98, "episode_reward_trend_value": 0.030655794849169776, "biggest_recent_change": 0.4538364895103655},
{"total_number_of_episodes": 7413, "number_of_timesteps": 806965, "per_episode_reward": -318.58, "episode_reward_trend_value": 0.032113663608766455, "biggest_recent_change": 0.4538364895103655},
{"total_number_of_episodes": 7423, "number_of_timesteps": 808407, "per_episode_reward": -318.38, "episode_reward_trend_value": 0.03218105085094926, "biggest_recent_change": 0.4538364895103655},
{"total_number_of_episodes": 7433, "number_of_timesteps": 810058, "per_episode_reward": -318.07, "episode_reward_trend_value": 0.03291450989822996, "biggest_recent_change": 0.4538364895103655},
{"total_number_of_episodes": 7444, "number_of_timesteps": 812996, "per_episode_reward": -317.66, "episode_reward_trend_value": 0.03464873654824727, "biggest_recent_change": 0.4538364895103655},
{"total_number_of_episodes": 7454, "number_of_timesteps": 814380, "per_episode_reward": -317.3, "episode_reward_trend_value": 0.03366082551614479, "biggest_recent_change": 0.4060782085987853},
{"total_number_of_episodes": 7465, "number_of_timesteps": 816445, "per_episode_reward": -317.05, "episode_reward_trend_value": 0.03255042614184036, "biggest_recent_change": 0.4060782085987853},
{"total_number_of_episodes": 7475, "number_of_timesteps": 818301, "per_episode_reward": -316.67, "episode_reward_trend_value": 0.03361408247459142, "biggest_recent_change": 0.4060782085987853},
{"total_number_of_episodes": 7485, "number_of_timesteps": 819987, "per_episode_reward": -315.95, "episode_reward_trend_value": 0.03751692436855857, "biggest_recent_change": 0.7186332334566714},
{"total_number_of_episodes": 7495, "number_of_timesteps": 823130, "per_episode_reward": -315.46, "episode_reward_trend_value": 0.039042796272144006, "biggest_recent_change": 0.7186332334566714},
{"total_number_of_episodes": 7505, "number_of_timesteps": 826448, "per_episode_reward": -314.45, "episode_reward_trend_value": 0.04586342658478518, "biggest_recent_change": 1.0077623039116475},
{"total_number_of_episodes": 7515, "number_of_timesteps": 829134, "per_episode_reward": -314.2, "episode_reward_trend_value": 0.046483651060482446, "biggest_recent_change": 1.0077623039116475},
{"total_number_of_episodes": 7525, "number_of_timesteps": 830779, "per_episode_reward": -313.88, "episode_reward_trend_value": 0.046589212093625876, "biggest_recent_change": 1.0077623039116475},
{"total_number_of_episodes": 7535, "number_of_timesteps": 834887, "per_episode_reward": -313.46, "episode_reward_trend_value": 0.046658856271080316, "biggest_recent_change": 1.0077623039116475},
{"total_number_of_episodes": 7545, "number_of_timesteps": 837928, "per_episode_reward": -313.1, "episode_reward_trend_value": 0.04661331056137278, "biggest_recent_change": 1.0077623039116475},
{"total_number_of_episodes": 7555, "number_of_timesteps": 840502, "per_episode_reward": -311.94, "episode_reward_trend_value": 0.05680787439799183, "biggest_recent_change": 1.1667553913540019},
{"total_number_of_episodes": 7565, "number_of_timesteps": 844687, "per_episode_reward": -311.51, "episode_reward_trend_value": 0.057336312638204844, "biggest_recent_change": 1.1667553913540019},
{"total_number_of_episodes": 7577, "number_of_timesteps": 847469, "per_episode_reward": -311.2, "episode_reward_trend_value": 0.05272251659366639, "biggest_recent_change": 1.1667553913540019},
{"total_number_of_episodes": 7587, "number_of_timesteps": 848905, "per_episode_reward": -310.86, "episode_reward_trend_value": 0.05114157409060453, "biggest_recent_change": 1.1667553913540019},
{"total_number_of_episodes": 7598, "number_of_timesteps": 851704, "per_episode_reward": -310.54, "episode_reward_trend_value": 0.04346786418398223, "biggest_recent_change": 1.1667553913540019},
{"total_number_of_episodes": 7608, "number_of_timesteps": 857137, "per_episode_reward": -310.31, "episode_reward_trend_value": 0.04320547958237171, "biggest_recent_change": 1.1667553913540019},
{"total_number_of_episodes": 7618, "number_of_timesteps": 859876, "per_episode_reward": -310.11, "episode_reward_trend_value": 0.04190977252320383, "biggest_recent_change": 1.1667553913540019},
{"total_number_of_episodes": 7628, "number_of_timesteps": 862547, "per_episode_reward": -309.82, "episode_reward_trend_value": 0.040529611130574496, "biggest_recent_change": 1.1667553913540019},
{"total_number_of_episodes": 7638, "number_of_timesteps": 864641, "per_episode_reward": -309.15, "episode_reward_trend_value": 0.04393668307431098, "biggest_recent_change": 1.1667553913540019},
{"total_number_of_episodes": 7650, "number_of_timesteps": 867327, "per_episode_reward": -308.44, "episode_reward_trend_value": 0.03882204344192246, "biggest_recent_change": 0.7064378244390355},
{"total_number_of_episodes": 7661, "number_of_timesteps": 869844, "per_episode_reward": -307.98, "episode_reward_trend_value": 0.03916167360930179, "biggest_recent_change": 0.7064378244390355},
{"total_number_of_episodes": 7671, "number_of_timesteps": 871965, "per_episode_reward": -307.67, "episode_reward_trend_value": 0.039291476451361024, "biggest_recent_change": 0.7064378244390355},
{"total_number_of_episodes": 7681, "number_of_timesteps": 874267, "per_episode_reward": -307.02, "episode_reward_trend_value": 0.042680249748749094, "biggest_recent_change": 0.7064378244390355},
{"total_number_of_episodes": 7691, "number_of_timesteps": 877759, "per_episode_reward": -306.61, "episode_reward_trend_value": 0.04364436073267244, "biggest_recent_change": 0.7064378244390355},
{"total_number_of_episodes": 7701, "number_of_timesteps": 880273, "per_episode_reward": -306.29, "episode_reward_trend_value": 0.04467558483059217, "biggest_recent_change": 0.7064378244390355},
{"total_number_of_episodes": 7711, "number_of_timesteps": 881710, "per_episode_reward": -305.85, "episode_reward_trend_value": 0.047240414697625965, "biggest_recent_change": 0.7064378244390355},
{"total_number_of_episodes": 7721, "number_of_timesteps": 884115, "per_episode_reward": -305.62, "episode_reward_trend_value": 0.04666707302207745, "biggest_recent_change": 0.7064378244390355},
{"total_number_of_episodes": 7731, "number_of_timesteps": 886240, "per_episode_reward": -305.14, "episode_reward_trend_value": 0.04459380089337957, "biggest_recent_change": 0.7064378244390355},
{"total_number_of_episodes": 7743, "number_of_timesteps": 889789, "per_episode_reward": -304.7, "episode_reward_trend_value": 0.041638006192963914, "biggest_recent_change": 0.6473651705229031},
{"total_number_of_episodes": 7753, "number_of_timesteps": 891646, "per_episode_reward": -304.1, "episode_reward_trend_value": 0.043132417745757975, "biggest_recent_change": 0.6473651705229031},
{"total_number_of_episodes": 7763, "number_of_timesteps": 894315, "per_episode_reward": -303.49, "episode_reward_trend_value": 0.046422783439140226, "biggest_recent_change": 0.6473651705229031},
{"total_number_of_episodes": 7773, "number_of_timesteps": 896608, "per_episode_reward": -302.77, "episode_reward_trend_value": 0.04724361439245083, "biggest_recent_change": 0.7212399563208578},
{"total_number_of_episodes": 7783, "number_of_timesteps": 899983, "per_episode_reward": -302.2, "episode_reward_trend_value": 0.048996778528634065, "biggest_recent_change": 0.7212399563208578},

{"total_number_of_episodes": 7794, "number_of_timesteps": 903657, "per_episode_reward": -302.06, "episode_reward_trend_value": 0.04705898899082083, "biggest_recent_change": 0.7212399563208578},
{"total_number_of_episodes": 7804, "number_of_timesteps": 907799, "per_episode_reward": -301.81, "episode_reward_trend_value": 0.04493325102941602, "biggest_recent_change": 0.7212399563208578},
{"total_number_of_episodes": 7814, "number_of_timesteps": 911065, "per_episode_reward": -300.71, "episode_reward_trend_value": 0.05448689705089009, "biggest_recent_change": 1.0963590503663454},
{"total_number_of_episodes": 7824, "number_of_timesteps": 912336, "per_episode_reward": -300.26, "episode_reward_trend_value": 0.054164452511663005, "biggest_recent_change": 1.0963590503663454},
{"total_number_of_episodes": 7834, "number_of_timesteps": 914373, "per_episode_reward": -299.82, "episode_reward_trend_value": 0.05420238420356769, "biggest_recent_change": 1.0963590503663454},
{"total_number_of_episodes": 7844, "number_of_timesteps": 917299, "per_episode_reward": -299.4, "episode_reward_trend_value": 0.05221631640133827, "biggest_recent_change": 1.0963590503663454},
{"total_number_of_episodes": 7854, "number_of_timesteps": 921459, "per_episode_reward": -299.08, "episode_reward_trend_value": 0.0489695296774572, "biggest_recent_change": 1.0963590503663454},
{"total_number_of_episodes": 7864, "number_of_timesteps": 923976, "per_episode_reward": -298.95, "episode_reward_trend_value": 0.04238214516892892, "biggest_recent_change": 1.0963590503663454},
{"total_number_of_episodes": 7875, "number_of_timesteps": 927467, "per_episode_reward": -298.58, "episode_reward_trend_value": 0.04028389059352675, "biggest_recent_change": 1.0963590503663454},
{"total_number_of_episodes": 7885, "number_of_timesteps": 931605, "per_episode_reward": -298.27, "episode_reward_trend_value": 0.042026119164671624, "biggest_recent_change": 1.0963590503663454},
{"total_number_of_episodes": 7895, "number_of_timesteps": 934709, "per_episode_reward": -298.03, "episode_reward_trend_value": 0.04201644348211996, "biggest_recent_change": 1.0963590503663454},
{"total_number_of_episodes": 7905, "number_of_timesteps": 936755, "per_episode_reward": -297.46, "episode_reward_trend_value": 0.03618816098220666, "biggest_recent_change": 0.5718136253741477},
{"total_number_of_episodes": 7915, "number_of_timesteps": 938629, "per_episode_reward": -296.62, "episode_reward_trend_value": 0.04046450711642503, "biggest_recent_change": 0.8367185096501544},
{"total_number_of_episodes": 7926, "number_of_timesteps": 941827, "per_episode_reward": -296.17, "episode_reward_trend_value": 0.04054117786090564, "biggest_recent_change": 0.8367185096501544},
{"total_number_of_episodes": 7936, "number_of_timesteps": 943422, "per_episode_reward": -295.89, "episode_reward_trend_value": 0.03893717718981217, "biggest_recent_change": 0.8367185096501544},
{"total_number_of_episodes": 7946, "number_of_timesteps": 946606, "per_episode_reward": -295.63, "episode_reward_trend_value": 0.038329508620173806, "biggest_recent_change": 0.8367185096501544},
{"total_number_of_episodes": 7956, "number_of_timesteps": 950182, "per_episode_reward": -294.98, "episode_reward_trend_value": 0.04418049174043025, "biggest_recent_change": 0.8367185096501544},
{"total_number_of_episodes": 7966, "number_of_timesteps": 952092, "per_episode_reward": -294.79, "episode_reward_trend_value": 0.04208624340826709, "biggest_recent_change": 0.8367185096501544},
{"total_number_of_episodes": 7976, "number_of_timesteps": 956304, "per_episode_reward": -294.37, "episode_reward_trend_value": 0.04338294773623059, "biggest_recent_change": 0.8367185096501544},
{"total_number_of_episodes": 7986, "number_of_timesteps": 958365, "per_episode_reward": -293.96, "episode_reward_trend_value": 0.04523627481559692, "biggest_recent_change": 0.8367185096501544},
{"total_number_of_episodes": 7996, "number_of_timesteps": 961084, "per_episode_reward": -293.6, "episode_reward_trend_value": 0.04280722811969895, "biggest_recent_change": 0.8367185096501544},
{"total_number_of_episodes": 8006, "number_of_timesteps": 965412, "per_episode_reward": -293.01, "episode_reward_trend_value": 0.040057891170526244, "biggest_recent_change": 0.6549638313763921},
{"total_number_of_episodes": 8016, "number_of_timesteps": 969764, "per_episode_reward": -292.27, "episode_reward_trend_value": 0.043333852830629536, "biggest_recent_change": 0.745567070085599},
{"total_number_of_episodes": 8026, "number_of_timesteps": 971635, "per_episode_reward": -291.96, "episode_reward_trend_value": 0.043691072352227266, "biggest_recent_change": 0.745567070085599},
{"total_number_of_episodes": 8036, "number_of_timesteps": 975094, "per_episode_reward": -291.42, "episode_reward_trend_value": 0.04683161796194213, "biggest_recent_change": 0.745567070085599},
{"total_number_of_episodes": 8046, "number_of_timesteps": 977668, "per_episode_reward": -291.29, "episode_reward_trend_value": 0.04097270538454533, "biggest_recent_change": 0.745567070085599},
{"total_number_of_episodes": 8057, "number_of_timesteps": 981132, "per_episode_reward": -290.68, "episode_reward_trend_value": 0.045698940307142444, "biggest_recent_change": 0.745567070085599},
{"total_number_of_episodes": 8067, "number_of_timesteps": 984557, "per_episode_reward": -290.34, "episode_reward_trend_value": 0.04480518899794674, "biggest_recent_change": 0.745567070085599},
{"total_number_of_episodes": 8080, "number_of_timesteps": 987592, "per_episode_reward": -290.03, "episode_reward_trend_value": 0.04362652356431782, "biggest_recent_change": 0.745567070085599},
{"total_number_of_episodes": 8092, "number_of_timesteps": 990419, "per_episode_reward": -289.84, "episode_reward_trend_value": 0.04182710994019898, "biggest_recent_change": 0.745567070085599},
{"total_number_of_episodes": 8102, "number_of_timesteps": 992269, "per_episode_reward": -289.57, "episode_reward_trend_value": 0.03827056473058847, "biggest_recent_change": 0.745567070085599},
{"total_number_of_episodes": 8112, "number_of_timesteps": 996513, "per_episode_reward": -289.11, "episode_reward_trend_value": 0.0350762452789013, "biggest_recent_change": 0.6097190544780915},
{"total_number_of_episodes": 8122, "number_of_timesteps": 1000418, "per_episode_reward": -288.83, "episode_reward_trend_value": 0.03480130288984608, "biggest_recent_change": 0.6097190544780915},
{"total_number_of_episodes": 8132, "number_of_timesteps": 1006300, "per_episode_reward": -288.35, "episode_reward_trend_value": 0.03405843307572809, "biggest_recent_change": 0.6097190544780915},
{"total_number_of_episodes": 8142, "number_of_timesteps": 1011665, "per_episode_reward": -287.96, "episode_reward_trend_value": 0.03694192302952817, "biggest_recent_change": 0.6097190544780915},
{"total_number_of_episodes": 8152, "number_of_timesteps": 1015122, "per_episode_reward": -287.78, "episode_reward_trend_value": 0.03224634228016359, "biggest_recent_change": 0.48009660282491495},
{"total_number_of_episodes": 8162, "number_of_timesteps": 1017151, "per_episode_reward": -287.5, "episode_reward_trend_value": 0.03151480460167275, "biggest_recent_change": 0.48009660282491495},
{"total_number_of_episodes": 8172, "number_of_timesteps": 1019279, "per_episode_reward": -286.84, "episode_reward_trend_value": 0.03543826191923674, "biggest_recent_change": 0.6588170368287933},
{"total_number_of_episodes": 8182, "number_of_timesteps": 1021891, "per_episode_reward": -286.42, "episode_reward_trend_value": 0.03799803878709819, "biggest_recent_change": 0.6588170368287933},
{"total_number_of_episodes": 8192, "number_of_timesteps": 1025329, "per_episode_reward": -286.17, "episode_reward_trend_value": 0.037738828383396594, "biggest_recent_change": 0.6588170368287933},
{"total_number_of_episodes": 8202, "number_of_timesteps": 1027007, "per_episode_reward": -285.53, "episode_reward_trend_value": 0.03977415725390883, "biggest_recent_change": 0.6588170368287933},
{"total_number_of_episodes": 8212, "number_of_timesteps": 1029987, "per_episode_reward": -284.7, "episode_reward_trend_value": 0.04594909497098519, "biggest_recent_change": 0.8371616321371675},
{"total_number_of_episodes": 8222, "number_of_timesteps": 1031785, "per_episode_reward": -283.47, "episode_reward_trend_value": 0.054235100607578114, "biggest_recent_change": 1.2258371101182775},
{"total_number_of_episodes": 8233, "number_of_timesteps": 1036090, "per_episode_reward": -282.46, "episode_reward_trend_value": 0.06110851272212964, "biggest_recent_change": 1.2258371101182775},
{"total_number_of_episodes": 8243, "number_of_timesteps": 1039365, "per_episode_reward": -281.89, "episode_reward_trend_value": 0.06543750177437144, "biggest_recent_change": 1.2258371101182775},
{"total_number_of_episodes": 8253, "number_of_timesteps": 1041787, "per_episode_reward": -281.19, "episode_reward_trend_value": 0.07015801359018686, "biggest_recent_change": 1.2258371101182775},
{"total_number_of_episodes": 8263, "number_of_timesteps": 1043672, "per_episode_reward": -280.53, "episode_reward_trend_value": 0.07012672995825192, "biggest_recent_change": 1.2258371101182775},
{"total_number_of_episodes": 8273, "number_of_timesteps": 1046415, "per_episode_reward": -280.14, "episode_reward_trend_value": 0.06980198433969412, "biggest_recent_change": 1.2258371101182775},

{"total_number_of_episodes": 8283, "number_of_timesteps": 1048057, "per_episode_reward": -279.88, "episode_reward_trend_value": 0.06998011725363981, "biggest_recent_change": 1.2258371101182775},
{"total_number_of_episodes": 8293, "number_of_timesteps": 1051393, "per_episode_reward": -279.37, "episode_reward_trend_value": 0.06842415515305143, "biggest_recent_change": 1.2258371101182775},
{"total_number_of_episodes": 8303, "number_of_timesteps": 1053192, "per_episode_reward": -279.13, "episode_reward_trend_value": 0.06182289381113656, "biggest_recent_change": 1.2258371101182775},
{"total_number_of_episodes": 8313, "number_of_timesteps": 1055964, "per_episode_reward": -278.85, "episode_reward_trend_value": 0.0512718633007618, "biggest_recent_change": 1.0057828855623256},
{"total_number_of_episodes": 8323, "number_of_timesteps": 1058241, "per_episode_reward": -278.55, "episode_reward_trend_value": 0.04348638370752269, "biggest_recent_change": 0.7011465452466723},
{"total_number_of_episodes": 8333, "number_of_timesteps": 1060219, "per_episode_reward": -276.62, "episode_reward_trend_value": 0.05850098015713456, "biggest_recent_change": 1.9280394822021094},
{"total_number_of_episodes": 8343, "number_of_timesteps": 1062336, "per_episode_reward": -276.38, "episode_reward_trend_value": 0.05340035260659369, "biggest_recent_change": 1.9280394822021094},
{"total_number_of_episodes": 8353, "number_of_timesteps": 1064802, "per_episode_reward": -276.1, "episode_reward_trend_value": 0.04917608049263183, "biggest_recent_change": 1.9280394822021094},
{"total_number_of_episodes": 8363, "number_of_timesteps": 1065952, "per_episode_reward": -275.75, "episode_reward_trend_value": 0.04870506149486131, "biggest_recent_change": 1.9280394822021094},
{"total_number_of_episodes": 8373, "number_of_timesteps": 1066992, "per_episode_reward": -275.42, "episode_reward_trend_value": 0.04954312451539522, "biggest_recent_change": 1.9280394822021094},
{"total_number_of_episodes": 8383, "number_of_timesteps": 1069001, "per_episode_reward": -275.13, "episode_reward_trend_value": 0.0471047249775236, "biggest_recent_change": 1.9280394822021094},
{"total_number_of_episodes": 8393, "number_of_timesteps": 1070237, "per_episode_reward": -274.71, "episode_reward_trend_value": 0.04907091688421651, "biggest_recent_change": 1.9280394822021094},
{"total_number_of_episodes": 8403, "number_of_timesteps": 1071831, "per_episode_reward": -274.24, "episode_reward_trend_value": 0.05123302326955341, "biggest_recent_change": 1.9280394822021094},
{"total_number_of_episodes": 8414, "number_of_timesteps": 1073885, "per_episode_reward": -273.94, "episode_reward_trend_value": 0.05118836391624641, "biggest_recent_change": 1.9280394822021094},
{"total_number_of_episodes": 8424, "number_of_timesteps": 1075980, "per_episode_reward": -273.63, "episode_reward_trend_value": 0.03321157265187051, "biggest_recent_change": 0.470833938864871},
{"total_number_of_episodes": 8436, "number_of_timesteps": 1078134, "per_episode_reward": -273.06, "episode_reward_trend_value": 0.0368297554775457, "biggest_recent_change": 0.5677265200087618},
{"total_number_of_episodes": 8447, "number_of_timesteps": 1079962, "per_episode_reward": -272.33, "episode_reward_trend_value": 0.04194049232190637, "biggest_recent_change": 0.7357833356905417},
{"total_number_of_episodes": 8457, "number_of_timesteps": 1082689, "per_episode_reward": -271.85, "episode_reward_trend_value": 0.0433455970154436, "biggest_recent_change": 0.7357833356905417},
{"total_number_of_episodes": 8467, "number_of_timesteps": 1084568, "per_episode_reward": -271.44, "episode_reward_trend_value": 0.04420096652239888, "biggest_recent_change": 0.7357833356905417},
{"total_number_of_episodes": 8477, "number_of_timesteps": 1086590, "per_episode_reward": -270.81, "episode_reward_trend_value": 0.048044843143369084, "biggest_recent_change": 0.7357833356905417},
{"total_number_of_episodes": 8488, "number_of_timesteps": 1088836, "per_episode_reward": -269.68, "episode_reward_trend_value": 0.05598476695193363, "biggest_recent_change": 1.1345985257379994},
{"total_number_of_episodes": 8499, "number_of_timesteps": 1091922, "per_episode_reward": -268.99, "episode_reward_trend_value": 0.058379573335074354, "biggest_recent_change": 1.1345985257379994},
{"total_number_of_episodes": 8510, "number_of_timesteps": 1096918, "per_episode_reward": -268.15, "episode_reward_trend_value": 0.06435277963640133, "biggest_recent_change": 1.1345985257379994},
{"total_number_of_episodes": 8521, "number_of_timesteps": 1104610, "per_episode_reward": -267.52, "episode_reward_trend_value": 0.06796840183534099, "biggest_recent_change": 1.1345985257379994},
{"total_number_of_episodes": 8532, "number_of_timesteps": 1109532, "per_episode_reward": -266.78, "episode_reward_trend_value": 0.0697900996187943, "biggest_recent_change": 1.1345985257379994},
{"total_number_of_episodes": 8542, "number_of_timesteps": 1114747, "per_episode_reward": -265.91, "episode_reward_trend_value": 0.07127991577364318, "biggest_recent_change": 1.1345985257379994},
{"total_number_of_episodes": 8552, "number_of_timesteps": 1119405, "per_episode_reward": -265.2, "episode_reward_trend_value": 0.07389193932554766, "biggest_recent_change": 1.1345985257379994},
{"total_number_of_episodes": 8562, "number_of_timesteps": 1121488, "per_episode_reward": -264.58, "episode_reward_trend_value": 0.07621050430619031, "biggest_recent_change": 1.1345985257379994},
{"total_number_of_episodes": 8572, "number_of_timesteps": 1122739, "per_episode_reward": -264.06, "episode_reward_trend_value": 0.07498222238374283, "biggest_recent_change": 1.1345985257379994},
{"total_number_of_episodes": 8582, "number_of_timesteps": 1125163, "per_episode_reward": -263.49, "episode_reward_trend_value": 0.0687808164417062, "biggest_recent_change": 0.8698667896269399},
{"total_number_of_episodes": 8592, "number_of_timesteps": 1128746, "per_episode_reward": -263.28, "episode_reward_trend_value": 0.06343568500322666, "biggest_recent_change": 0.8698667896269399},
{"total_number_of_episodes": 8602, "number_of_timesteps": 1134693, "per_episode_reward": -261.68, "episode_reward_trend_value": 0.07185927222372912, "biggest_recent_change": 1.596781797337826},
{"total_number_of_episodes": 8612, "number_of_timesteps": 1137431, "per_episode_reward": -261.3, "episode_reward_trend_value": 0.06910153590408186, "biggest_recent_change": 1.596781797337826},
{"total_number_of_episodes": 8622, "number_of_timesteps": 1139269, "per_episode_reward": -260.52, "episode_reward_trend_value": 0.06964224343745842, "biggest_recent_change": 1.596781797337826},
{"total_number_of_episodes": 8632, "number_of_timesteps": 1140957, "per_episode_reward": -260.03, "episode_reward_trend_value": 0.0653870090950079, "biggest_recent_change": 1.596781797337826},
{"total_number_of_episodes": 8642, "number_of_timesteps": 1143049, "per_episode_reward": -259.42, "episode_reward_trend_value": 0.06424873236468771, "biggest_recent_change": 1.596781797337826},
{"total_number_of_episodes": 8653, "number_of_timesteps": 1146108, "per_episode_reward": -258.74, "episode_reward_trend_value": 0.06485095707129934, "biggest_recent_change": 1.596781797337826},
{"total_number_of_episodes": 8663, "number_of_timesteps": 1147740, "per_episode_reward": -258.15, "episode_reward_trend_value": 0.06570861148809652, "biggest_recent_change": 1.596781797337826},
{"total_number_of_episodes": 8673, "number_of_timesteps": 1149547, "per_episode_reward": -256.95, "episode_reward_trend_value": 0.07256857238722256, "biggest_recent_change": 1.596781797337826},
{"total_number_of_episodes": 8683, "number_of_timesteps": 1153998, "per_episode_reward": -256.48, "episode_reward_trend_value": 0.07553144021093393, "biggest_recent_change": 1.596781797337826},
{"total_number_of_episodes": 8693, "number_of_timesteps": 1158537, "per_episode_reward": -256.17, "episode_reward_trend_value": 0.06129302652736518, "biggest_recent_change": 1.1938684718760442},
{"total_number_of_episodes": 8703, "number_of_timesteps": 1160487, "per_episode_reward": -255.57, "episode_reward_trend_value": 0.063672777291451, "biggest_recent_change": 1.1938684718760442},
{"total_number_of_episodes": 8713, "number_of_timesteps": 1163589, "per_episode_reward": -254.83, "episode_reward_trend_value": 0.06318618796180495, "biggest_recent_change": 1.1938684718760442},
{"total_number_of_episodes": 8723, "number_of_timesteps": 1166363, "per_episode_reward": -254.54, "episode_reward_trend_value": 0.06095561623265584, "biggest_recent_change": 1.1938684718760442},
{"total_number_of_episodes": 8733, "number_of_timesteps": 1170789, "per_episode_reward": -253.48, "episode_reward_trend_value": 0.0659997454858828, "biggest_recent_change": 1.1938684718760442},
{"total_number_of_episodes": 8743, "number_of_timesteps": 1173662, "per_episode_reward": -252.7, "episode_reward_trend_value": 0.06718874670768982, "biggest_recent_change": 1.1938684718760442},
{"total_number_of_episodes": 8753, "number_of_timesteps": 1178287, "per_episode_reward": -252.23, "episode_reward_trend_value": 0.06580720099064669, "biggest_recent_change": 1.1938684718760442},
{"total_number_of_episodes": 8763, "number_of_timesteps": 1184063, "per_episode_reward": -251.47, "episode_reward_trend_value": 0.06098247253712006, "biggest_recent_change": 1.06308156836198},
{"total_number_of_episodes": 8773, "number_of_timesteps": 1186739, "per_episode_reward": -250.44, "episode_reward_trend_value": 0.06717755631692562, "biggest_recent_change": 1.06308156836198},
{"total_number_of_episodes": 8783, "number_of_timesteps": 1189009, "per_episode_reward": -249.74, "episode_reward_trend_value": 0.0713782494952669, "biggest_recent_change": 1.06308156836198},
{"total_number_of_episodes": 8793, "number_of_timesteps": 1192730, "per_episode_reward": -249.1, "episode_reward_trend_value": 0.07179641696068587, "biggest_recent_change": 1.06308156836198},
{"total_number_of_episodes": 8803, "number_of_timesteps": 1197253, "per_episode_reward": -248.12, "episode_reward_trend_value": 0.07456097248378184, "biggest_recent_change": 1.06308156836198},
{"total_number_of_episodes": 8813, "number_of_timesteps": 1202434, "per_episode_reward": -246.51, "episode_reward_trend_value": 0.0892409599519842, "biggest_recent_change": 1.6073431153211857},
{"total_number_of_episodes": 8823, "number_of_timesteps": 1206760, "per_episode_reward": -246.39, "episode_reward_trend_value": 0.07873687141380306, "biggest_recent_change": 1.6073431153211857},
{"total_number_of_episodes": 8833, "number_of_timesteps": 1211439, "per_episode_reward": -245.79, "episode_reward_trend_value": 0.07668500214306183, "biggest_recent_change": 1.6073431153211857},
{"total_number_of_episodes": 8843, "number_of_timesteps": 1214313, "per_episode_reward": -245.07, "episode_reward_trend_value": 0.07956007774651128, "biggest_recent_change": 1.6073431153211857},
{"total_number_of_episodes": 8853, "number_of_timesteps": 1218634, "per_episode_reward": -244.04, "episode_reward_trend_value": 0.08250875000267273, "biggest_recent_change": 1.6073431153211857},
{"total_number_of_episodes": 8863, "number_of_timesteps": 1222093, "per_episode_reward": -243.09, "episode_reward_trend_value": 0.08164691960786981, "biggest_recent_change": 1.6073431153211857},
{"total_number_of_episodes": 8873, "number_of_timesteps": 1223991, "per_episode_reward": -242.48, "episode_reward_trend_value": 0.08069213540275719, "biggest_recent_change": 1.6073431153211857},
{"total_number_of_episodes": 8884, "number_of_timesteps": 1226393, "per_episode_reward": -241.2, "episode_reward_trend_value": 0.08786052447278128, "biggest_recent_change": 1.6073431153211857},
{"total_number_of_episodes": 8894, "number_of_timesteps": 1229051, "per_episode_reward": -240.53, "episode_reward_trend_value": 0.08437118148577996, "biggest_recent_change": 1.6073431153211857},
{"total_number_of_episodes": 8904, "number_of_timesteps": 1231815, "per_episode_reward": -239.98, "episode_reward_trend_value": 0.07260486994492762, "biggest_recent_change": 1.284305654502191},
{"total_number_of_episodes": 8914, "number_of_timesteps": 1235327, "per_episode_reward": -239.66, "episode_reward_trend_value": 0.0748046674856397, "biggest_recent_change": 1.284305654502191},
{"total_number_of_episodes": 8924, "number_of_timesteps": 1239877, "per_episode_reward": -239.12, "episode_reward_trend_value": 0.07417160739846054, "biggest_recent_change": 1.284305654502191},
{"total_number_of_episodes": 8935, "number_of_timesteps": 1244481, "per_episode_reward": -238.41, "episode_reward_trend_value": 0.07389795267628725, "biggest_recent_change": 1.284305654502191},
{"total_number_of_episodes": 8945, "number_of_timesteps": 1248097, "per_episode_reward": -238.03, "episode_reward_trend_value": 0.06678342061559148, "biggest_recent_change": 1.284305654502191},
{"total_number_of_episodes": 8955, "number_of_timesteps": 1253351, "per_episode_reward": -237.35, "episode_reward_trend_value": 0.06373673309615432, "biggest_recent_change": 1.284305654502191},
{"total_number_of_episodes": 8965, "number_of_timesteps": 1257937, "per_episode_reward": -236.93, "episode_reward_trend_value": 0.06163433955613932, "biggest_recent_change": 1.284305654502191},
{"total_number_of_episodes": 8975, "number_of_timesteps": 1263998, "per_episode_reward": -236.34, "episode_reward_trend_value": 0.053945840558036674, "biggest_recent_change": 0.7041465554782178},
{"total_number_of_episodes": 8985, "number_of_timesteps": 1268599, "per_episode_reward": -234.83, "episode_reward_trend_value": 0.06330369211874824, "biggest_recent_change": 1.5135257275678669},
{"total_number_of_episodes": 8995, "number_of_timesteps": 1275605, "per_episode_reward": -234.32, "episode_reward_trend_value": 0.06282197908834916, "biggest_recent_change": 1.5135257275678669},
{"total_number_of_episodes": 9005, "number_of_timesteps": 1279368, "per_episode_reward": -233.39, "episode_reward_trend_value": 0.06973140761600279, "biggest_recent_change": 1.5135257275678669},
{"total_number_of_episodes": 9015, "number_of_timesteps": 1286166, "per_episode_reward": -232.91, "episode_reward_trend_value": 0.0690118221893177, "biggest_recent_change": 1.5135257275678669},
{"total_number_of_episodes": 9025, "number_of_timesteps": 1289775, "per_episode_reward": -232.55, "episode_reward_trend_value": 0.06515320566266875, "biggest_recent_change": 1.5135257275678669},
{"total_number_of_episodes": 9035, "number_of_timesteps": 1294149, "per_episode_reward": -232.25, "episode_reward_trend_value": 0.06423863476140133, "biggest_recent_change": 1.5135257275678669},
{"total_number_of_episodes": 9045, "number_of_timesteps": 1299392, "per_episode_reward": -231.89, "episode_reward_trend_value": 0.060684531496067326, "biggest_recent_change": 1.5135257275678669},
{"total_number_of_episodes": 9055, "number_of_timesteps": 1304709, "per_episode_reward": -231.53, "episode_reward_trend_value": 0.06001696953060439, "biggest_recent_change": 1.5135257275678669},
{"total_number_of_episodes": 9065, "number_of_timesteps": 1312340, "per_episode_reward": -231.03, "episode_reward_trend_value": 0.05901699572152066, "biggest_recent_change": 1.5135257275678669},
{"total_number_of_episodes": 9075, "number_of_timesteps": 1320068, "per_episode_reward": -230.48, "episode_reward_trend_value": 0.04828701519048637, "biggest_recent_change": 0.9375439460785913},
{"total_number_of_episodes": 9085, "number_of_timesteps": 1324543, "per_episode_reward": -229.24, "episode_reward_trend_value": 0.056503581790527356, "biggest_recent_change": 1.244511897912247},
{"total_number_of_episodes": 9095, "number_of_timesteps": 1328109, "per_episode_reward": -228.0, "episode_reward_trend_value": 0.059869514261401635, "biggest_recent_change": 1.244511897912247},
{"total_number_of_episodes": 9105, "number_of_timesteps": 1332654, "per_episode_reward": -225.97, "episode_reward_trend_value": 0.07711129537229625, "biggest_recent_change": 2.0295362199371993},
{"total_number_of_episodes": 9115, "number_of_timesteps": 1336927, "per_episode_reward": -225.07, "episode_reward_trend_value": 0.08314577128188666, "biggest_recent_change": 2.0295362199371993},
{"total_number_of_episodes": 9125, "number_of_timesteps": 1341366, "per_episode_reward": -224.45, "episode_reward_trend_value": 0.08659541524769325, "biggest_recent_change": 2.0295362199371993},
{"total_number_of_episodes": 9135, "number_of_timesteps": 1344291, "per_episode_reward": -223.94, "episode_reward_trend_value": 0.08836243219913027, "biggest_recent_change": 2.0295362199371993},
{"total_number_of_episodes": 9145, "number_of_timesteps": 1348670, "per_episode_reward": -223.3, "episode_reward_trend_value": 0.09145976941690542, "biggest_recent_change": 2.0295362199371993},
{"total_number_of_episodes": 9155, "number_of_timesteps": 1356357, "per_episode_reward": -222.37, "episode_reward_trend_value": 0.09617576005806099, "biggest_recent_change": 2.0295362199371993},
{"total_number_of_episodes": 9165, "number_of_timesteps": 1363172, "per_episode_reward": -221.24, "episode_reward_trend_value": 0.10266907623138795, "biggest_recent_change": 2.0295362199371993},
{"total_number_of_episodes": 9175, "number_of_timesteps": 1372405, "per_episode_reward": -220.64, "episode_reward_trend_value": 0.0954881612288697, "biggest_recent_change": 2.0295362199371993},
{"total_number_of_episodes": 9185, "number_of_timesteps": 1377033, "per_episode_reward": -220.57, "episode_reward_trend_value": 0.0825398257527095, "biggest_recent_change": 2.0295362199371993},
{"total_number_of_episodes": 9195, "number_of_timesteps": 1383122, "per_episode_reward": -219.77, "episode_reward_trend_value": 0.06888822262227165, "biggest_recent_change": 1.1322259353742083},
{"total_number_of_episodes": 9205, "number_of_timesteps": 1386761, "per_episode_reward": -219.51, "episode_reward_trend_value": 0.0617262888071467, "biggest_recent_change": 1.1322259353742083},
{"total_number_of_episodes": 9215, "number_of_timesteps": 1389540, "per_episode_reward": -218.03, "episode_reward_trend_value": 0.07140841318930503, "biggest_recent_change": 1.4842632988533353},
{"total_number_of_episodes": 9225, "number_of_timesteps": 1394791, "per_episode_reward": -216.51, "episode_reward_trend_value": 0.08252376881637373, "biggest_recent_change": 1.5172979541047482},
{"total_number_of_episodes": 9235, "number_of_timesteps": 1399996, "per_episode_reward": -215.71, "episode_reward_trend_value": 0.08434156646188329, "biggest_recent_change": 1.5172979541047482},
{"total_number_of_episodes": 9245, "number_of_timesteps": 1404367, "per_episode_reward": -215.16, "episode_reward_trend_value": 0.0801859757986487, "biggest_recent_change": 1.5172979541047482},
{"total_number_of_episodes": 9255, "number_of_timesteps": 1409480, "per_episode_reward": -212.81, "episode_reward_trend_value": 0.09372924012755499, "biggest_recent_change": 2.3511197249757743},
{"total_number_of_episodes": 9265, "number_of_timesteps": 1413885, "per_episode_reward": -212.13, "episode_reward_trend_value": 0.09455377056188215, "biggest_recent_change": 2.3511197249757743},
{"total_number_of_episodes": 9275, "number_of_timesteps": 1416758, "per_episode_reward": -212.02, "episode_reward_trend_value": 0.09496742467731659, "biggest_recent_change": 2.3511197249757743},
{"total_number_of_episodes": 9285, "number_of_timesteps": 1424337, "per_episode_reward": -211.15, "episode_reward_trend_value": 0.09572202858146378, "biggest_recent_change": 2.3511197249757743},
{"total_number_of_episodes": 9295, "number_of_timesteps": 1427847, "per_episode_reward": -210.37, "episode_reward_trend_value": 0.10154267777063428, "biggest_recent_change": 2.3511197249757743},
{"total_number_of_episodes": 9305, "number_of_timesteps": 1433067, "per_episode_reward": -209.8, "episode_reward_trend_value": 0.09136865545840149, "biggest_recent_change": 2.3511197249757743},
{"total_number_of_episodes": 9315, "number_of_timesteps": 1439965, "per_episode_reward": -209.16, "episode_reward_trend_value": 0.08168850337298814, "biggest_recent_change": 2.3511197249757743},
{"total_number_of_episodes": 9326, "number_of_timesteps": 1445276, "per_episode_reward": -207.44, "episode_reward_trend_value": 0.09185724225294634, "biggest_recent_change": 2.3511197249757743},
{"total_number_of_episodes": 9338, "number_of_timesteps": 1449022, "per_episode_reward": -206.42, "episode_reward_trend_value": 0.09708419350630557, "biggest_recent_change": 2.3511197249757743},
{"total_number_of_episodes": 9348, "number_of_timesteps": 1453998, "per_episode_reward": -205.5, "episode_reward_trend_value": 0.08120510435081138, "biggest_recent_change": 1.715709014806066},
{"total_number_of_episodes": 9358, "number_of_timesteps": 1455827, "per_episode_reward": -204.63, "episode_reward_trend_value": 0.08335469551398723, "biggest_recent_change": 1.715709014806066},
{"total_number_of_episodes": 9368, "number_of_timesteps": 1458553, "per_episode_reward": -202.27, "episode_reward_trend_value": 0.10832256139858443, "biggest_recent_change": 2.359464475605705},
{"total_number_of_episodes": 9378, "number_of_timesteps": 1463704, "per_episode_reward": -200.43, "episode_reward_trend_value": 0.11916664043620276, "biggest_recent_change": 2.359464475605705},
{"total_number_of_episodes": 9388, "number_of_timesteps": 1468117, "per_episode_reward": -200.05, "episode_reward_trend_value": 0.11469002492850551, "biggest_recent_change": 2.359464475605705},
{"total_number_of_episodes": 9398, "number_of_timesteps": 1471616, "per_episode_reward": -199.32, "episode_reward_trend_value": 0.11653771227465641, "biggest_recent_change": 2.359464475605705},
{"total_number_of_episodes": 9408, "number_of_timesteps": 1475004, "per_episode_reward": -198.64, "episode_reward_trend_value": 0.11687314421530018, "biggest_recent_change": 2.359464475605705},
{"total_number_of_episodes": 9418, "number_of_timesteps": 1479297, "per_episode_reward": -197.78, "episode_reward_trend_value": 0.10739017626780703, "biggest_recent_change": 2.359464475605705},
{"total_number_of_episodes": 9428, "number_of_timesteps": 1485531, "per_episode_reward": -197.49, "episode_reward_trend_value": 0.09920379553012582, "biggest_recent_change": 2.359464475605705},
{"total_number_of_episodes": 9438, "number_of_timesteps": 1490830, "per_episode_reward": -196.84, "episode_reward_trend_value": 0.09624482944386759, "biggest_recent_change": 2.359464475605705},
{"total_number_of_episodes": 9448, "number_of_timesteps": 1497716, "per_episode_reward": -195.99, "episode_reward_trend_value": 0.09606421751769542, "biggest_recent_change": 2.359464475605705},
{"total_number_of_episodes": 9458, "number_of_timesteps": 1505723, "per_episode_reward": -195.36, "episode_reward_trend_value": 0.07682710757855174, "biggest_recent_change": 1.8447734029566902},
{"total_number_of_episodes": 9468, "number_of_timesteps": 1512020, "per_episode_reward": -193.99, "episode_reward_trend_value": 0.0715196223526994, "biggest_recent_change": 1.3670997326299812},
{"total_number_of_episodes": 9478, "number_of_timesteps": 1522020, "per_episode_reward": -193.5, "episode_reward_trend_value": 0.07280014974791445, "biggest_recent_change": 1.3670997326299812},
{"total_number_of_episodes": 9488, "number_of_timesteps": 1531112, "per_episode_reward": -193.01, "episode_reward_trend_value": 0.07011834312917845, "biggest_recent_change": 1.3670997326299812},
{"total_number_of_episodes": 9498, "number_of_timesteps": 1539668, "per_episode_reward": -192.54, "episode_reward_trend_value": 0.06775508324459104, "biggest_recent_change": 1.3670997326299812},
{"total_number_of_episodes": 9508, "number_of_timesteps": 1548247, "per_episode_reward": -191.41, "episode_reward_trend_value": 0.07073784808704128, "biggest_recent_change": 1.3670997326299812},
{"total_number_of_episodes": 9519, "number_of_timesteps": 1557136, "per_episode_reward": -191.09, "episode_reward_trend_value": 0.07111721378933408, "biggest_recent_change": 1.3670997326299812},
{"total_number_of_episodes": 9529, "number_of_timesteps": 1567136, "per_episode_reward": -190.78, "episode_reward_trend_value": 0.06728104325642145, "biggest_recent_change": 1.3670997326299812},
{"total_number_of_episodes": 9540, "number_of_timesteps": 1576654, "per_episode_reward": -190.34, "episode_reward_trend_value": 0.06277430744703168, "biggest_recent_change": 1.3670997326299812},
{"total_number_of_episodes": 9551, "number_of_timesteps": 1586887, "per_episode_reward": -189.98, "episode_reward_trend_value": 0.05978397213101422, "biggest_recent_change": 1.3670997326299812},
{"total_number_of_episodes": 9561, "number_of_timesteps": 1592961, "per_episode_reward": -189.49, "episode_reward_trend_value": 0.04996246520125125, "biggest_recent_change": 1.1306907353522035},
{"total_number_of_episodes": 9571, "number_of_timesteps": 1599037, "per_episode_reward": -189.04, "episode_reward_trend_value": 0.04957476489547237, "biggest_recent_change": 1.1306907353522035},
{"total_number_of_episodes": 9581, "number_of_timesteps": 1603545, "per_episode_reward": -188.43, "episode_reward_trend_value": 0.050860572278842955, "biggest_recent_change": 1.1306907353522035},
{"total_number_of_episodes": 9591, "number_of_timesteps": 1609012, "per_episode_reward": -188.13, "episode_reward_trend_value": 0.048971168570817424, "biggest_recent_change": 1.1306907353522035},
{"total_number_of_episodes": 9601, "number_of_timesteps": 1617484, "per_episode_reward": -187.52, "episode_reward_trend_value": 0.043196360278502904, "biggest_recent_change": 0.6109579890438965},
{"total_number_of_episodes": 9611, "number_of_timesteps": 1625991, "per_episode_reward": -186.71, "episode_reward_trend_value": 0.048648246086127896, "biggest_recent_change": 0.8112430821719272},
{"total_number_of_episodes": 9621, "number_of_timesteps": 1634522, "per_episode_reward": -185.91, "episode_reward_trend_value": 0.05414894597758051, "biggest_recent_change": 0.8112430821719272},
{"total_number_of_episodes": 9631, "number_of_timesteps": 1644522, "per_episode_reward": -184.2, "episode_reward_trend_value": 0.0681670635713674, "biggest_recent_change": 1.7056697787011217},
{"total_number_of_episodes": 9641, "number_of_timesteps": 1653749, "per_episode_reward": -183.13, "episode_reward_trend_value": 0.07604398468752183, "biggest_recent_change": 1.7056697787011217},
{"total_number_of_episodes": 9651, "number_of_timesteps": 1662185, "per_episode_reward": -182.15, "episode_reward_trend_value": 0.08163605078763428, "biggest_recent_change": 1.7056697787011217},
{"total_number_of_episodes": 9661, "number_of_timesteps": 1669908, "per_episode_reward": -181.25, "episode_reward_trend_value": 0.08648433340121263, "biggest_recent_change": 1.7056697787011217},
{"total_number_of_episodes": 9671, "number_of_timesteps": 1677578, "per_episode_reward": -180.3, "episode_reward_trend_value": 0.09029508202093521, "biggest_recent_change": 1.7056697787011217},
{"total_number_of_episodes": 9681, "number_of_timesteps": 1682174, "per_episode_reward": -180.06, "episode_reward_trend_value": 0.08972260301248727, "biggest_recent_change": 1.7056697787011217},
{"total_number_of_episodes": 9692, "number_of_timesteps": 1688347, "per_episode_reward": -178.29, "episode_reward_trend_value": 0.10257846106234499, "biggest_recent_change": 1.767985213531091},
{"total_number_of_episodes": 9702, "number_of_timesteps": 1692746, "per_episode_reward": -177.0, "episode_reward_trend_value": 0.10788722211635944, "biggest_recent_change": 1.767985213531091},
{"total_number_of_episodes": 9712, "number_of_timesteps": 1696213, "per_episode_reward": -176.47, "episode_reward_trend_value": 0.10481808083357862, "biggest_recent_change": 1.767985213531091},
{"total_number_of_episodes": 9722, "number_of_timesteps": 1699617, "per_episode_reward": -176.17, "episode_reward_trend_value": 0.0892305875922397, "biggest_recent_change": 1.767985213531091},
{"total_number_of_episodes": 9732, "number_of_timesteps": 1703131, "per_episode_reward": -175.28, "episode_reward_trend_value": 0.08725361619235122, "biggest_recent_change": 1.767985213531091},
{"total_number_of_episodes": 9742, "number_of_timesteps": 1709189, "per_episode_reward": -174.68, "episode_reward_trend_value": 0.08299369162674913, "biggest_recent_change": 1.767985213531091},
{"total_number_of_episodes": 9752, "number_of_timesteps": 1714397, "per_episode_reward": -174.22, "episode_reward_trend_value": 0.07819125894761278, "biggest_recent_change": 1.767985213531091},
{"total_number_of_episodes": 9762, "number_of_timesteps": 1721177, "per_episode_reward": -173.32, "episode_reward_trend_value": 0.0776278557136395, "biggest_recent_change": 1.767985213531091},
{"total_number_of_episodes": 9772, "number_of_timesteps": 1728825, "per_episode_reward": -172.63, "episode_reward_trend_value": 0.08254588942362899, "biggest_recent_change": 1.767985213531091},
{"total_number_of_episodes": 9782, "number_of_timesteps": 1736588, "per_episode_reward": -171.99, "episode_reward_trend_value": 0.07004401038556662, "biggest_recent_change": 1.289031577033228},
{"total_number_of_episodes": 9792, "number_of_timesteps": 1742790, "per_episode_reward": -171.01, "episode_reward_trend_value": 0.06654846918790219, "biggest_recent_change": 0.9744328692434294},
{"total_number_of_episodes": 9802, "number_of_timesteps": 1752048, "per_episode_reward": -170.67, "episode_reward_trend_value": 0.06448092331664271, "biggest_recent_change": 0.9744328692434294},
{"total_number_of_episodes": 9812, "number_of_timesteps": 1760480, "per_episode_reward": -169.98, "episode_reward_trend_value": 0.06883216361143998, "biggest_recent_change": 0.9744328692434294},
{"total_number_of_episodes": 9822, "number_of_timesteps": 1766545, "per_episode_reward": -169.55, "episode_reward_trend_value": 0.06368456633468327, "biggest_recent_change": 0.9744328692434294},
{"total_number_of_episodes": 9832, "number_of_timesteps": 1771827, "per_episode_reward": -169.01, "episode_reward_trend_value": 0.06296922009018052, "biggest_recent_change": 0.9744328692434294},
{"total_number_of_episodes": 9842, "number_of_timesteps": 1777032, "per_episode_reward": -168.52, "episode_reward_trend_value": 0.06330413425939285, "biggest_recent_change": 0.9744328692434294},
{"total_number_of_episodes": 9852, "number_of_timesteps": 1781383, "per_episode_reward": -167.93, "episode_reward_trend_value": 0.05986463594644502, "biggest_recent_change": 0.9744328692434294},
{"total_number_of_episodes": 9862, "number_of_timesteps": 1787390, "per_episode_reward": -167.56, "episode_reward_trend_value": 0.05633884882735616, "biggest_recent_change": 0.9744328692434294},
{"total_number_of_episodes": 9872, "number_of_timesteps": 1791746, "per_episode_reward": -166.83, "episode_reward_trend_value": 0.05735262942073436, "biggest_recent_change": 0.9744328692434294},
{"total_number_of_episodes": 9882, "number_of_timesteps": 1797660, "per_episode_reward": -166.47, "episode_reward_trend_value": 0.050454282269093806, "biggest_recent_change": 0.7340563535095157},
{"total_number_of_episodes": 9892, "number_of_timesteps": 1801144, "per_episode_reward": -165.28, "episode_reward_trend_value": 0.05990169198418679, "biggest_recent_change": 1.193467425981396},
{"total_number_of_episodes": 9902, "number_of_timesteps": 1804618, "per_episode_reward": -164.49, "episode_reward_trend_value": 0.060972763587006464, "biggest_recent_change": 1.193467425981396},
{"total_number_of_episodes": 9912, "number_of_timesteps": 1806377, "per_episode_reward": -163.91, "episode_reward_trend_value": 0.06262394918971856, "biggest_recent_change": 1.193467425981396},
{"total_number_of_episodes": 9922, "number_of_timesteps": 1808928, "per_episode_reward": -163.41, "episode_reward_trend_value": 0.06219184602681323, "biggest_recent_change": 1.193467425981396},
{"total_number_of_episodes": 9932, "number_of_timesteps": 1811699, "per_episode_reward": -162.52, "episode_reward_trend_value": 0.06663590014157326, "biggest_recent_change": 1.193467425981396},
{"total_number_of_episodes": 9942, "number_of_timesteps": 1813225, "per_episode_reward": -161.13, "episode_reward_trend_value": 0.07554934579167139, "biggest_recent_change": 1.3941695657840398},
{"total_number_of_episodes": 9952, "number_of_timesteps": 1816493, "per_episode_reward": -160.79, "episode_reward_trend_value": 0.07526165690784031, "biggest_recent_change": 1.3941695657840398},
{"total_number_of_episodes": 9963, "number_of_timesteps": 1819170, "per_episode_reward": -160.31, "episode_reward_trend_value": 0.07245081356372352, "biggest_recent_change": 1.3941695657840398},
{"total_number_of_episodes": 9973, "number_of_timesteps": 1821711, "per_episode_reward": -159.78, "episode_reward_trend_value": 0.07434844692262396, "biggest_recent_change": 1.3941695657840398},
{"total_number_of_episodes": 9983, "number_of_timesteps": 1823519, "per_episode_reward": -159.36, "episode_reward_trend_value": 0.06579150475144376, "biggest_recent_change": 1.3941695657840398},
{"total_number_of_episodes": 9993, "number_of_timesteps": 1828636, "per_episode_reward": -158.8, "episode_reward_trend_value": 0.06324143473191586, "biggest_recent_change": 1.3941695657840398},
{"total_number_of_episodes": 10003, "number_of_timesteps": 1832924, "per_episode_reward": -158.18, "episode_reward_trend_value": 0.0636760507446414, "biggest_recent_change": 1.3941695657840398},
{"total_number_of_episodes": 10013, "number_of_timesteps": 1838834, "per_episode_reward": -157.51, "episode_reward_trend_value": 0.06559467964063306, "biggest_recent_change": 1.3941695657840398},
{"total_number_of_episodes": 10023, "number_of_timesteps": 1843105, "per_episode_reward": -157.21, "episode_reward_trend_value": 0.05898265059210467, "biggest_recent_change": 1.3941695657840398},
{"total_number_of_episodes": 10033, "number_of_timesteps": 1847415, "per_episode_reward": -156.75, "episode_reward_trend_value": 0.04863759296932055, "biggest_recent_change": 0.6724630010297687},
{"total_number_of_episodes": 10043, "number_of_timesteps": 1854167, "per_episode_reward": -156.22, "episode_reward_trend_value": 0.050685437305471245, "biggest_recent_change": 0.6724630010297687},
{"total_number_of_episodes": 10053, "number_of_timesteps": 1859265, "per_episode_reward": -155.59, "episode_reward_trend_value": 0.052354260047005455, "biggest_recent_change": 0.6724630010297687},
{"total_number_of_episodes": 10063, "number_of_timesteps": 1866003, "per_episode_reward": -155.15, "episode_reward_trend_value": 0.051502091227875565, "biggest_recent_change": 0.6724630010297687},
{"total_number_of_episodes": 10073, "number_of_timesteps": 1872046, "per_episode_reward": -154.44, "episode_reward_trend_value": 0.054661884224797876, "biggest_recent_change": 0.7077240002981853},
{"total_number_of_episodes": 10083, "number_of_timesteps": 1873851, "per_episode_reward": -154.08, "episode_reward_trend_value": 0.05237865779455875, "biggest_recent_change": 0.7077240002981853},
{"total_number_of_episodes": 10093, "number_of_timesteps": 1882192, "per_episode_reward": -153.46, "episode_reward_trend_value": 0.052439538854826794, "biggest_recent_change": 0.7077240002981853},
{"total_number_of_episodes": 10103, "number_of_timesteps": 1886448, "per_episode_reward": -152.97, "episode_reward_trend_value": 0.05046104668409031, "biggest_recent_change": 0.7077240002981853},
{"total_number_of_episodes": 10113, "number_of_timesteps": 1893127, "per_episode_reward": -152.45, "episode_reward_trend_value": 0.052967041211934116, "biggest_recent_change": 0.7077240002981853},
{"total_number_of_episodes": 10123, "number_of_timesteps": 1898287, "per_episode_reward": -152.09, "episode_reward_trend_value": 0.05176980278848381, "biggest_recent_change": 0.7077240002981853},
{"total_number_of_episodes": 10133, "number_of_timesteps": 1903448, "per_episode_reward": -151.4, "episode_reward_trend_value": 0.05364605932398818, "biggest_recent_change": 0.7077240002981853},
{"total_number_of_episodes": 10143, "number_of_timesteps": 1911031, "per_episode_reward": -151.24, "episode_reward_trend_value": 0.048328008074217464, "biggest_recent_change": 0.7077240002981853},
{"total_number_of_episodes": 10153, "number_of_timesteps": 1916118, "per_episode_reward": -150.29, "episode_reward_trend_value": 0.053958226402589717, "biggest_recent_change": 0.9543930837286325},
{"total_number_of_episodes": 10163, "number_of_timesteps": 1920412, "per_episode_reward": -150.02, "episode_reward_trend_value": 0.049135252800915435, "biggest_recent_change": 0.9543930837286325},
{"total_number_of_episodes": 10173, "number_of_timesteps": 1925515, "per_episode_reward": -149.77, "episode_reward_trend_value": 0.04793248014621996, "biggest_recent_change": 0.9543930837286325},
{"total_number_of_episodes": 10183, "number_of_timesteps": 1929764, "per_episode_reward": -149.14, "episode_reward_trend_value": 0.0480080039194582, "biggest_recent_change": 0.9543930837286325},
{"total_number_of_episodes": 10193, "number_of_timesteps": 1935694, "per_episode_reward": -148.85, "episode_reward_trend_value": 0.04570392407587715, "biggest_recent_change": 0.9543930837286325},
{"total_number_of_episodes": 10203, "number_of_timesteps": 1942488, "per_episode_reward": -147.87, "episode_reward_trend_value": 0.05089364253147216, "biggest_recent_change": 0.9884825197627833},
{"total_number_of_episodes": 10213, "number_of_timesteps": 1948433, "per_episode_reward": -147.21, "episode_reward_trend_value": 0.05428646379368603, "biggest_recent_change": 0.9884825197627833},
{"total_number_of_episodes": 10223, "number_of_timesteps": 1956804, "per_episode_reward": -146.31, "episode_reward_trend_value": 0.05650709815536174, "biggest_recent_change": 0.9884825197627833},
{"total_number_of_episodes": 10233, "number_of_timesteps": 1964084, "per_episode_reward": -145.68, "episode_reward_trend_value": 0.06187815394608422, "biggest_recent_change": 0.9884825197627833},
{"total_number_of_episodes": 10243, "number_of_timesteps": 1968143, "per_episode_reward": -144.88, "episode_reward_trend_value": 0.06013397961762242, "biggest_recent_change": 0.9884825197627833},
{"total_number_of_episodes": 10253, "number_of_timesteps": 1973157, "per_episode_reward": -143.99, "episode_reward_trend_value": 0.06693445643459293, "biggest_recent_change": 0.9884825197627833},
{"total_number_of_episodes": 10263, "number_of_timesteps": 1979863, "per_episode_reward": -143.61, "episode_reward_trend_value": 0.06846440388688804, "biggest_recent_change": 0.9884825197627833},
{"total_number_of_episodes": 10273, "number_of_timesteps": 1986215, "per_episode_reward": -143.35, "episode_reward_trend_value": 0.06435354775682987, "biggest_recent_change": 0.9884825197627833},
{"total_number_of_episodes": 10283, "number_of_timesteps": 1995415, "per_episode_reward": -142.45, "episode_reward_trend_value": 0.07110952885707414, "biggest_recent_change": 0.9884825197627833},
{"total_number_of_episodes": 10293, "number_of_timesteps": 2002150, "per_episode_reward": -142.28, "episode_reward_trend_value": 0.06205023451318792, "biggest_recent_change": 0.8950698187631758},
{"total_number_of_episodes": 10303, "number_of_timesteps": 2007191, "per_episode_reward": -141.99, "episode_reward_trend_value": 0.05790133103117891, "biggest_recent_change": 0.8950698187631758},
{"total_number_of_episodes": 10313, "number_of_timesteps": 2014828, "per_episode_reward": -141.59, "episode_reward_trend_value": 0.05245516915066256, "biggest_recent_change": 0.8950698187631758},
{"total_number_of_episodes": 10323, "number_of_timesteps": 2024001, "per_episode_reward": -140.83, "episode_reward_trend_value": 0.05386208736982338, "biggest_recent_change": 0.8950698187631758},
{"total_number_of_episodes": 10333, "number_of_timesteps": 2030776, "per_episode_reward": -140.64, "episode_reward_trend_value": 0.0471117744763218, "biggest_recent_change": 0.8950698187631758},
{"total_number_of_episodes": 10343, "number_of_timesteps": 2038381, "per_episode_reward": -139.98, "episode_reward_trend_value": 0.044619269289421795, "biggest_recent_change": 0.8950698187631758},
{"total_number_of_episodes": 10353, "number_of_timesteps": 2044153, "per_episode_reward": -139.22, "episode_reward_trend_value": 0.048733074559840536, "biggest_recent_change": 0.8950698187631758},
{"total_number_of_episodes": 10363, "number_of_timesteps": 2051474, "per_episode_reward": -138.73, "episode_reward_trend_value": 0.05133896084044175, "biggest_recent_change": 0.8950698187631758},

{"total_number_of_episodes": 10373, "number_of_timesteps": 2061074, "per_episode_reward": -137.95, "episode_reward_trend_value": 0.05005240526069517, "biggest_recent_change": 0.7792798165859836},
{"total_number_of_episodes": 10383, "number_of_timesteps": 2071074, "per_episode_reward": -136.93, "episode_reward_trend_value": 0.05950469009881879, "biggest_recent_change": 1.0238516642441482},
{"total_number_of_episodes": 10394, "number_of_timesteps": 2081669, "per_episode_reward": -136.05, "episode_reward_trend_value": 0.06603845446319162, "biggest_recent_change": 1.0238516642441482},
{"total_number_of_episodes": 10404, "number_of_timesteps": 2089312, "per_episode_reward": -134.35, "episode_reward_trend_value": 0.08049286951457854, "biggest_recent_change": 1.7051894569943897},
{"total_number_of_episodes": 10414, "number_of_timesteps": 2095601, "per_episode_reward": -133.66, "episode_reward_trend_value": 0.07959896808343514, "biggest_recent_change": 1.7051894569943897},
{"total_number_of_episodes": 10424, "number_of_timesteps": 2105336, "per_episode_reward": -133.16, "episode_reward_trend_value": 0.08311109583147085, "biggest_recent_change": 1.7051894569943897},
{"total_number_of_episodes": 10434, "number_of_timesteps": 2113852, "per_episode_reward": -132.61, "episode_reward_trend_value": 0.08181507522090656, "biggest_recent_change": 1.7051894569943897},
{"total_number_of_episodes": 10444, "number_of_timesteps": 2123087, "per_episode_reward": -132.11, "episode_reward_trend_value": 0.07901365021281777, "biggest_recent_change": 1.7051894569943897},
{"total_number_of_episodes": 10454, "number_of_timesteps": 2131433, "per_episode_reward": -131.77, "episode_reward_trend_value": 0.07737004393100903, "biggest_recent_change": 1.7051894569943897},
{"total_number_of_episodes": 10464, "number_of_timesteps": 2137572, "per_episode_reward": -131.38, "episode_reward_trend_value": 0.07295361801493527, "biggest_recent_change": 1.7051894569943897},
{"total_number_of_episodes": 10474, "number_of_timesteps": 2145940, "per_episode_reward": -130.81, "episode_reward_trend_value": 0.06791980763675269, "biggest_recent_change": 1.7051894569943897},
{"total_number_of_episodes": 10484, "number_of_timesteps": 2153569, "per_episode_reward": -130.22, "episode_reward_trend_value": 0.0648271641888439, "biggest_recent_change": 1.7051894569943897},
{"total_number_of_episodes": 10494, "number_of_timesteps": 2162040, "per_episode_reward": -130.01, "episode_reward_trend_value": 0.048136330990411126, "biggest_recent_change": 0.682216418884309},
{"total_number_of_episodes": 10504, "number_of_timesteps": 2170385, "per_episode_reward": -129.65, "episode_reward_trend_value": 0.044541277690278644, "biggest_recent_change": 0.5970164043231421},
{"total_number_of_episodes": 10514, "number_of_timesteps": 2176997, "per_episode_reward": -128.89, "episode_reward_trend_value": 0.047441774505816804, "biggest_recent_change": 0.7670254444735747},
{"total_number_of_episodes": 10524, "number_of_timesteps": 2181872, "per_episode_reward": -127.91, "episode_reward_trend_value": 0.052307664886464676, "biggest_recent_change": 0.9826621021613704},
{"total_number_of_episodes": 10534, "number_of_timesteps": 2186497, "per_episode_reward": -127.48, "episode_reward_trend_value": 0.05138820399941295, "biggest_recent_change": 0.9826621021613704},
{"total_number_of_episodes": 10544, "number_of_timesteps": 2189692, "per_episode_reward": -126.78, "episode_reward_trend_value": 0.05544287127408075, "biggest_recent_change": 0.9826621021613704},
{"total_number_of_episodes": 10554, "number_of_timesteps": 2191878, "per_episode_reward": -126.36, "episode_reward_trend_value": 0.05579214047234112, "biggest_recent_change": 0.9826621021613704},
{"total_number_of_episodes": 10564, "number_of_timesteps": 2194939, "per_episode_reward": -125.97, "episode_reward_trend_value": 0.05384515475545536, "biggest_recent_change": 0.9826621021613704},
{"total_number_of_episodes": 10574, "number_of_timesteps": 2196170, "per_episode_reward": -125.71, "episode_reward_trend_value": 0.05009789434057047, "biggest_recent_change": 0.9826621021613704},
{"total_number_of_episodes": 10584, "number_of_timesteps": 2197475, "per_episode_reward": -125.46, "episode_reward_trend_value": 0.05057336294397854, "biggest_recent_change": 0.9826621021613704},
{"total_number_of_episodes": 10594, "number_of_timesteps": 2200568, "per_episode_reward": -125.36, "episode_reward_trend_value": 0.047677859608132346, "biggest_recent_change": 0.9826621021613704},
{"total_number_of_episodes": 10604, "number_of_timesteps": 2202188, "per_episode_reward": -125.09, "episode_reward_trend_value": 0.042181541393276865, "biggest_recent_change": 0.9826621021613704},
{"total_number_of_episodes": 10614, "number_of_timesteps": 2205516, "per_episode_reward": -124.47, "episode_reward_trend_value": 0.03820344555088503, "biggest_recent_change": 0.708252905508175},
{"total_number_of_episodes": 10624, "number_of_timesteps": 2208689, "per_episode_reward": -123.9, "episode_reward_trend_value": 0.03986610659548025, "biggest_recent_change": 0.708252905508175},
{"total_number_of_episodes": 10634, "number_of_timesteps": 2210953, "per_episode_reward": -123.58, "episode_reward_trend_value": 0.03554133244725459, "biggest_recent_change": 0.624633476346105},
{"total_number_of_episodes": 10644, "number_of_timesteps": 2215647, "per_episode_reward": -123.14, "episode_reward_trend_value": 0.03586000417848933, "biggest_recent_change": 0.624633476346105},
{"total_number_of_episodes": 10654, "number_of_timesteps": 2218739, "per_episode_reward": -122.72, "episode_reward_trend_value": 0.03610953864076392, "biggest_recent_change": 0.624633476346105},
{"total_number_of_episodes": 10664, "number_of_timesteps": 2221865, "per_episode_reward": -122.4, "episode_reward_trend_value": 0.03680044053338002, "biggest_recent_change": 0.624633476346105},
{"total_number_of_episodes": 10674, "number_of_timesteps": 2224916, "per_episode_reward": -122.25, "episode_reward_trend_value": 0.03564846761081321, "biggest_recent_change": 0.624633476346105},
{"total_number_of_episodes": 10684, "number_of_timesteps": 2228074, "per_episode_reward": -122.14, "episode_reward_trend_value": 0.03578929131618022, "biggest_recent_change": 0.624633476346105},
{"total_number_of_episodes": 10694, "number_of_timesteps": 2231990, "per_episode_reward": -121.94, "episode_reward_trend_value": 0.03503851840636069, "biggest_recent_change": 0.624633476346105},
{"total_number_of_episodes": 10704, "number_of_timesteps": 2234502, "per_episode_reward": -121.82, "episode_reward_trend_value": 0.02941838023019064, "biggest_recent_change": 0.570254746859689},
{"total_number_of_episodes": 10714, "number_of_timesteps": 2237087, "per_episode_reward": -121.17, "episode_reward_trend_value": 0.030299905841067065, "biggest_recent_change": 0.6495920518385674},
{"total_number_of_episodes": 10724, "number_of_timesteps": 2238275, "per_episode_reward": -120.73, "episode_reward_trend_value": 0.03161962138977244, "biggest_recent_change": 0.6495920518385674},
{"total_number_of_episodes": 10734, "number_of_timesteps": 2239623, "per_episode_reward": -120.11, "episode_reward_trend_value": 0.03360115958099941, "biggest_recent_change": 0.6495920518385674},
{"total_number_of_episodes": 10744, "number_of_timesteps": 2241811, "per_episode_reward": -119.76, "episode_reward_trend_value": 0.03284688614891991, "biggest_recent_change": 0.6495920518385674},
{"total_number_of_episodes": 10754, "number_of_timesteps": 2243999, "per_episode_reward": -119.44, "episode_reward_trend_value": 0.032805057870762905, "biggest_recent_change": 0.6495920518385674},
{"total_number_of_episodes": 10764, "number_of_timesteps": 2245239, "per_episode_reward": -118.99, "episode_reward_trend_value": 0.03630333192738565, "biggest_recent_change": 0.6495920518385674},
{"total_number_of_episodes": 10774, "number_of_timesteps": 2246689, "per_episode_reward": -118.52, "episode_reward_trend_value": 0.04026781981122664, "biggest_recent_change": 0.6495920518385674},
{"total_number_of_episodes": 10785, "number_of_timesteps": 2249415, "per_episode_reward": -117.93, "episode_reward_trend_value": 0.0444813977785581, "biggest_recent_change": 0.6495920518385674},
{"total_number_of_episodes": 10795, "number_of_timesteps": 2252115, "per_episode_reward": -117.47, "episode_reward_trend_value": 0.048271357813264616, "biggest_recent_change": 0.6495920518385674},
{"total_number_of_episodes": 10805, "number_of_timesteps": 2257973, "per_episode_reward": -116.85, "episode_reward_trend_value": 0.04801671710287031, "biggest_recent_change": 0.6266743879030798},
{"total_number_of_episodes": 10815, "number_of_timesteps": 2265464, "per_episode_reward": -116.07, "episode_reward_trend_value": 0.05177785713747546, "biggest_recent_change": 0.7763002346658112},
{"total_number_of_episodes": 10825, "number_of_timesteps": 2270394, "per_episode_reward": -115.84, "episode_reward_trend_value": 0.04743626313004544, "biggest_recent_change": 0.7763002346658112},
{"total_number_of_episodes": 10835, "number_of_timesteps": 2276205, "per_episode_reward": -115.6, "episode_reward_trend_value": 0.04627600628498259, "biggest_recent_change": 0.7763002346658112},
{"total_number_of_episodes": 10845, "number_of_timesteps": 2282833, "per_episode_reward": -114.26, "episode_reward_trend_value": 0.057645892723885414, "biggest_recent_change": 1.3414693717860757},
{"total_number_of_episodes": 10855, "number_of_timesteps": 2287380, "per_episode_reward": -114.01, "episode_reward_trend_value": 0.05524791029602609, "biggest_recent_change": 1.3414693717860757},
{"total_number_of_episodes": 10865, "number_of_timesteps": 2290181, "per_episode_reward": -113.85, "episode_reward_trend_value": 0.05187209363575975, "biggest_recent_change": 1.3414693717860757},
{"total_number_of_episodes": 10875, "number_of_timesteps": 2294569, "per_episode_reward": -113.43, "episode_reward_trend_value": 0.05004085003425414, "biggest_recent_change": 1.3414693717860757},
{"total_number_of_episodes": 10885, "number_of_timesteps": 2300540, "per_episode_reward": -113.06, "episode_reward_trend_value": 0.049082251479879976, "biggest_recent_change": 1.3414693717860757},
{"total_number_of_episodes": 10895, "number_of_timesteps": 2307721, "per_episode_reward": -112.7, "episode_reward_trend_value": 0.046087085419062784, "biggest_recent_change": 1.3414693717860757},
{"total_number_of_episodes": 10905, "number_of_timesteps": 2316959, "per_episode_reward": -112.27, "episode_reward_trend_value": 0.04227463231073629, "biggest_recent_change": 1.3414693717860757},
{"total_number_of_episodes": 10915, "number_of_timesteps": 2326709, "per_episode_reward": -111.86, "episode_reward_trend_value": 0.04423911927233522, "biggest_recent_change": 1.3414693717860757},
{"total_number_of_episodes": 10925, "number_of_timesteps": 2334967, "per_episode_reward": -111.55, "episode_reward_trend_value": 0.04500695224382206, "biggest_recent_change": 1.3414693717860757},
{"total_number_of_episodes": 10935, "number_of_timesteps": 2342561, "per_episode_reward": -110.47, "episode_reward_trend_value": 0.04209279307107639, "biggest_recent_change": 1.079195046238965},
{"total_number_of_episodes": 10946, "number_of_timesteps": 2352038, "per_episode_reward": -110.13, "episode_reward_trend_value": 0.043194353329121464, "biggest_recent_change": 1.079195046238965},
{"total_number_of_episodes": 10956, "number_of_timesteps": 2362038, "per_episode_reward": -109.87, "episode_reward_trend_value": 0.044176318459754935, "biggest_recent_change": 1.079195046238965},
{"total_number_of_episodes": 10966, "number_of_timesteps": 2368016, "per_episode_reward": -109.41, "episode_reward_trend_value": 0.04468566839276523, "biggest_recent_change": 1.079195046238965},
{"total_number_of_episodes": 10976, "number_of_timesteps": 2374020, "per_episode_reward": -109.03, "episode_reward_trend_value": 0.04478228865649119, "biggest_recent_change": 1.079195046238965},
{"total_number_of_episodes": 10986, "number_of_timesteps": 2381002, "per_episode_reward": -108.53, "episode_reward_trend_value": 0.04634642738189601, "biggest_recent_change": 1.079195046238965},
{"total_number_of_episodes": 10996, "number_of_timesteps": 2390166, "per_episode_reward": -108.03, "episode_reward_trend_value": 0.047104771378595624, "biggest_recent_change": 1.079195046238965},
{"total_number_of_episodes": 11006, "number_of_timesteps": 2398384, "per_episode_reward": -107.56, "episode_reward_trend_value": 0.04773590648294619, "biggest_recent_change": 1.079195046238965},
{"total_number_of_episodes": 11016, "number_of_timesteps": 2405003, "per_episode_reward": -107.24, "episode_reward_trend_value": 0.04788055363500787, "biggest_recent_change": 1.079195046238965},
{"total_number_of_episodes": 11026, "number_of_timesteps": 2412465, "per_episode_reward": -107.1, "episode_reward_trend_value": 0.037390184846693826, "biggest_recent_change": 0.5014304146193922},
{"total_number_of_episodes": 11036, "number_of_timesteps": 2417520, "per_episode_reward": -106.84, "episode_reward_trend_value": 0.036505698346416676, "biggest_recent_change": 0.5014304146193922},
{"total_number_of_episodes": 11046, "number_of_timesteps": 2425895, "per_episode_reward": -106.75, "episode_reward_trend_value": 0.034688171072214245, "biggest_recent_change": 0.5014304146193922},
{"total_number_of_episodes": 11056, "number_of_timesteps": 2433024, "per_episode_reward": -106.65, "episode_reward_trend_value": 0.030666207296795277, "biggest_recent_change": 0.5014304146193922},
{"total_number_of_episodes": 11066, "number_of_timesteps": 2441197, "per_episode_reward": -106.47, "episode_reward_trend_value": 0.02845631963321122, "biggest_recent_change": 0.5014304146193922},
{"total_number_of_episodes": 11076, "number_of_timesteps": 2447270, "per_episode_reward": -106.1, "episode_reward_trend_value": 0.026971698439136715, "biggest_recent_change": 0.5014304146193922},
{"total_number_of_episodes": 11086, "number_of_timesteps": 2456486, "per_episode_reward": -105.28, "episode_reward_trend_value": 0.030566613147739, "biggest_recent_change": 0.8249727383935976},
{"total_number_of_episodes": 11096, "number_of_timesteps": 2464917, "per_episode_reward": -104.64, "episode_reward_trend_value": 0.032460927689887356, "biggest_recent_change": 0.8249727383935976},
{"total_number_of_episodes": 11106, "number_of_timesteps": 2473147, "per_episode_reward": -104.42, "episode_reward_trend_value": 0.03134008296742302, "biggest_recent_change": 0.8249727383935976},
{"total_number_of_episodes": 11116, "number_of_timesteps": 2482318, "per_episode_reward": -104.04, "episode_reward_trend_value": 0.034057898838280684, "biggest_recent_change": 0.8249727383935976},
{"total_number_of_episodes": 11126, "number_of_timesteps": 2488567, "per_episode_reward": -103.5, "episode_reward_trend_value": 0.037081873133026653, "biggest_recent_change": 0.8249727383935976},
{"total_number_of_episodes": 11136, "number_of_timesteps": 2496578, "per_episode_reward": -103.34, "episode_reward_trend_value": 0.03786173132210706, "biggest_recent_change": 0.8249727383935976},
{"total_number_of_episodes": 11146, "number_of_timesteps": 2506434, "per_episode_reward": -103.2, "episode_reward_trend_value": 0.038360821291688926, "biggest_recent_change": 0.8249727383935976},
{"total_number_of_episodes": 11156, "number_of_timesteps": 2515169, "per_episode_reward": -103.05, "episode_reward_trend_value": 0.03797118814847427, "biggest_recent_change": 0.8249727383935976},
{"total_number_of_episodes": 11166, "number_of_timesteps": 2524475, "per_episode_reward": -102.78, "episode_reward_trend_value": 0.03689120627446019, "biggest_recent_change": 0.8249727383935976},
{"total_number_of_episodes": 11176, "number_of_timesteps": 2534322, "per_episode_reward": -102.57, "episode_reward_trend_value": 0.030090920616605232, "biggest_recent_change": 0.6336054390644392},

{"total_number_of_episodes": 11186, "number_of_timesteps": 2544222, "per_episode_reward": -102.47, "episode_reward_trend_value": 0.02411022537940255, "biggest_recent_change": 0.5328496517261101},
{"total_number_of_episodes": 11196, "number_of_timesteps": 2550735, "per_episode_reward": -101.61, "episode_reward_trend_value": 0.03122955389665268, "biggest_recent_change": 0.8677171449999861},
{"total_number_of_episodes": 11206, "number_of_timesteps": 2557184, "per_episode_reward": -101.22, "episode_reward_trend_value": 0.03132298814899362, "biggest_recent_change": 0.8677171449999861},
{"total_number_of_episodes": 11216, "number_of_timesteps": 2562530, "per_episode_reward": -100.92, "episode_reward_trend_value": 0.028719061316970836, "biggest_recent_change": 0.8677171449999861},
{"total_number_of_episodes": 11226, "number_of_timesteps": 2567028, "per_episode_reward": -100.83, "episode_reward_trend_value": 0.027888622141403134, "biggest_recent_change": 0.8677171449999861},
{"total_number_of_episodes": 11236, "number_of_timesteps": 2574540, "per_episode_reward": -100.56, "episode_reward_trend_value": 0.02924646247992576, "biggest_recent_change": 0.8677171449999861},
{"total_number_of_episodes": 11246, "number_of_timesteps": 2581312, "per_episode_reward": -100.34, "episode_reward_trend_value": 0.03005737017856249, "biggest_recent_change": 0.8677171449999861},
{"total_number_of_episodes": 11256, "number_of_timesteps": 2585338, "per_episode_reward": -100.2, "episode_reward_trend_value": 0.028709068174895297, "biggest_recent_change": 0.8677171449999861},
{"total_number_of_episodes": 11266, "number_of_timesteps": 2587132, "per_episode_reward": -100.07, "episode_reward_trend_value": 0.027728468561666848, "biggest_recent_change": 0.8677171449999861},
{"total_number_of_episodes": 11276, "number_of_timesteps": 2592205, "per_episode_reward": -99.79, "episode_reward_trend_value": 0.029818970565123948, "biggest_recent_change": 0.8677171449999861},
{"total_number_of_episodes": 11286, "number_of_timesteps": 2596584, "per_episode_reward": -99.48, "episode_reward_trend_value": 0.023656541100343986, "biggest_recent_change": 0.38807436637857506},
{"total_number_of_episodes": 11296, "number_of_timesteps": 2602880, "per_episode_reward": -99.17, "episode_reward_trend_value": 0.022734779459809496, "biggest_recent_change": 0.31309849316978955},
{"total_number_of_episodes": 11306, "number_of_timesteps": 2610467, "per_episode_reward": -99.06, "episode_reward_trend_value": 0.020654011568078248, "biggest_recent_change": 0.31309849316978955},
{"total_number_of_episodes": 11316, "number_of_timesteps": 2616799, "per_episode_reward": -98.92, "episode_reward_trend_value": 0.021277043562636145, "biggest_recent_change": 0.31309849316978955},
{"total_number_of_episodes": 11326, "number_of_timesteps": 2624964, "per_episode_reward": -97.94, "episode_reward_trend_value": 0.029186119978221355, "biggest_recent_change": 0.9820026954924401},
{"total_number_of_episodes": 11336, "number_of_timesteps": 2632131, "per_episode_reward": -97.61, "episode_reward_trend_value": 0.030320152677497943, "biggest_recent_change": 0.9820026954924401},
{"total_number_of_episodes": 11346, "number_of_timesteps": 2638238, "per_episode_reward": -97.36, "episode_reward_trend_value": 0.031556035331460286, "biggest_recent_change": 0.9820026954924401},
{"total_number_of_episodes": 11356, "number_of_timesteps": 2645918, "per_episode_reward": -97.15, "episode_reward_trend_value": 0.03245143425805423, "biggest_recent_change": 0.9820026954924401},
{"total_number_of_episodes": 11366, "number_of_timesteps": 2651593, "per_episode_reward": -97.07, "episode_reward_trend_value": 0.03025741029287572, "biggest_recent_change": 0.9820026954924401},
{"total_number_of_episodes": 11376, "number_of_timesteps": 2660726, "per_episode_reward": -96.71, "episode_reward_trend_value": 0.030691982418779656, "biggest_recent_change": 0.9820026954924401},
{"total_number_of_episodes": 11386, "number_of_timesteps": 2667275, "per_episode_reward": -96.18, "episode_reward_trend_value": 0.03326386151086812, "biggest_recent_change": 0.9820026954924401},
{"total_number_of_episodes": 11396, "number_of_timesteps": 2674480, "per_episode_reward": -95.9, "episode_reward_trend_value": 0.03513068697877959, "biggest_recent_change": 0.9820026954924401},
{"total_number_of_episodes": 11406, "number_of_timesteps": 2682760, "per_episode_reward": -95.65, "episode_reward_trend_value": 0.0363659124716531, "biggest_recent_change": 0.9820026954924401},
{"total_number_of_episodes": 11416, "number_of_timesteps": 2688322, "per_episode_reward": -95.31, "episode_reward_trend_value": 0.029241728935569554, "biggest_recent_change": 0.5365849370184321},
{"total_number_of_episodes": 11426, "number_of_timesteps": 2696214, "per_episode_reward": -95.03, "episode_reward_trend_value": 0.028719528271510187, "biggest_recent_change": 0.5365849370184321},
{"total_number_of_episodes": 11436, "number_of_timesteps": 2702558, "per_episode_reward": -94.84, "episode_reward_trend_value": 0.027927653132061737, "biggest_recent_change": 0.5365849370184321},
{"total_number_of_episodes": 11446, "number_of_timesteps": 2708720, "per_episode_reward": -94.77, "episode_reward_trend_value": 0.026416378675840707, "biggest_recent_change": 0.5365849370184321},
{"total_number_of_episodes": 11456, "number_of_timesteps": 2716503, "per_episode_reward": -94.35, "episode_reward_trend_value": 0.03013541226230735, "biggest_recent_change": 0.5365849370184321},
{"total_number_of_episodes": 11466, "number_of_timesteps": 2724827, "per_episode_reward": -94.06, "episode_reward_trend_value": 0.029504473410163396, "biggest_recent_change": 0.5365849370184321},
{"total_number_of_episodes": 11477, "number_of_timesteps": 2732403, "per_episode_reward": -93.75, "episode_reward_trend_value": 0.027009207784996492, "biggest_recent_change": 0.4207389139432678},
{"total_number_of_episodes": 11487, "number_of_timesteps": 2738332, "per_episode_reward": -93.52, "episode_reward_trend_value": 0.02646031175309673, "biggest_recent_change": 0.4207389139432678},
{"total_number_of_episodes": 11497, "number_of_timesteps": 2745650, "per_episode_reward": -93.06, "episode_reward_trend_value": 0.028730268980908767, "biggest_recent_change": 0.4555073079178271},
{"total_number_of_episodes": 11507, "number_of_timesteps": 2749665, "per_episode_reward": -92.71, "episode_reward_trend_value": 0.028831295146119373, "biggest_recent_change": 0.4555073079178271},
{"total_number_of_episodes": 11517, "number_of_timesteps": 2756604, "per_episode_reward": -92.45, "episode_reward_trend_value": 0.028700269210212542, "biggest_recent_change": 0.4555073079178271},
{"total_number_of_episodes": 11527, "number_of_timesteps": 2762040, "per_episode_reward": -92.01, "episode_reward_trend_value": 0.031500275419801785, "biggest_recent_change": 0.4555073079178271},
{"total_number_of_episodes": 11537, "number_of_timesteps": 2768198, "per_episode_reward": -91.72, "episode_reward_trend_value": 0.0339152425363461, "biggest_recent_change": 0.4555073079178271},
{"total_number_of_episodes": 11547, "number_of_timesteps": 2774709, "per_episode_reward": -91.43, "episode_reward_trend_value": 0.03247202907517356, "biggest_recent_change": 0.4555073079178271},
{"total_number_of_episodes": 11557, "number_of_timesteps": 2780173, "per_episode_reward": -91.15, "episode_reward_trend_value": 0.03228775055083446, "biggest_recent_change": 0.4555073079178271},
{"total_number_of_episodes": 11567, "number_of_timesteps": 2787383, "per_episode_reward": -90.8, "episode_reward_trend_value": 0.03277837720678289, "biggest_recent_change": 0.4555073079178271},
{"total_number_of_episodes": 11577, "number_of_timesteps": 2793755, "per_episode_reward": -90.48, "episode_reward_trend_value": 0.03376007393783674, "biggest_recent_change": 0.4555073079178271},
{"total_number_of_episodes": 11588, "number_of_timesteps": 2802047, "per_episode_reward": -90.28, "episode_reward_trend_value": 0.030890974081671473, "biggest_recent_change": 0.43768170642722737},
{"total_number_of_episodes": 11599, "number_of_timesteps": 2812132, "per_episode_reward": -90.08, "episode_reward_trend_value": 0.029287142008515826, "biggest_recent_change": 0.43768170642722737},
{"total_number_of_episodes": 11609, "number_of_timesteps": 2819908, "per_episode_reward": -89.85, "episode_reward_trend_value": 0.02889473822027766, "biggest_recent_change": 0.43768170642722737},
{"total_number_of_episodes": 11620, "number_of_timesteps": 2830349, "per_episode_reward": -89.63, "episode_reward_trend_value": 0.02640220315101847, "biggest_recent_change": 0.35616742978876914},
{"total_number_of_episodes": 11630, "number_of_timesteps": 2840349, "per_episode_reward": -89.47, "episode_reward_trend_value": 0.025071945275642805, "biggest_recent_change": 0.35616742978876914},
{"total_number_of_episodes": 11640, "number_of_timesteps": 2848445, "per_episode_reward": -89.29, "episode_reward_trend_value": 0.023820379626485217, "biggest_recent_change": 0.35616742978876914},
{"total_number_of_episodes": 11650, "number_of_timesteps": 2855882, "per_episode_reward": -89.09, "episode_reward_trend_value": 0.022962888368814858, "biggest_recent_change": 0.35616742978876914},
{"total_number_of_episodes": 11660, "number_of_timesteps": 2861721, "per_episode_reward": -88.91, "episode_reward_trend_value": 0.020996320938784643, "biggest_recent_change": 0.3181934816241494},
{"total_number_of_episodes": 11670, "number_of_timesteps": 2866081, "per_episode_reward": -88.75, "episode_reward_trend_value": 0.019207664146868808, "biggest_recent_change": 0.2293204257179724},
{"total_number_of_episodes": 11680, "number_of_timesteps": 2871982, "per_episode_reward": -88.37, "episode_reward_trend_value": 0.02125890706400655, "biggest_recent_change": 0.3819001834053495},
{"total_number_of_episodes": 11690, "number_of_timesteps": 2878016, "per_episode_reward": -88.24, "episode_reward_trend_value": 0.020405314331709532, "biggest_recent_change": 0.3819001834053495},
{"total_number_of_episodes": 11700, "number_of_timesteps": 2884759, "per_episode_reward": -88.15, "episode_reward_trend_value": 0.01882672465343028, "biggest_recent_change": 0.3819001834053495},
{"total_number_of_episodes": 11710, "number_of_timesteps": 2892492, "per_episode_reward": -88.03, "episode_reward_trend_value": 0.017856317189557873, "biggest_recent_change": 0.3819001834053495},
{"total_number_of_episodes": 11720, "number_of_timesteps": 2902004, "per_episode_reward": -87.77, "episode_reward_trend_value": 0.018862743237894917, "biggest_recent_change": 0.3819001834053495},
{"total_number_of_episodes": 11730, "number_of_timesteps": 2909516, "per_episode_reward": -87.71, "episode_reward_trend_value": 0.017568508154696537, "biggest_recent_change": 0.3819001834053495},
{"total_number_of_episodes": 11740, "number_of_timesteps": 2917441, "per_episode_reward": -87.52, "episode_reward_trend_value": 0.017454340516257754, "biggest_recent_change": 0.3819001834053495},
{"total_number_of_episodes": 11750, "number_of_timesteps": 2923573, "per_episode_reward": -87.34, "episode_reward_trend_value": 0.01739059576975295, "biggest_recent_change": 0.3819001834053495},
{"total_number_of_episodes": 11760, "number_of_timesteps": 2930031, "per_episode_reward": -87.1, "episode_reward_trend_value": 0.018298543471243375, "biggest_recent_change": 0.3819001834053495},
{"total_number_of_episodes": 11770, "number_of_timesteps": 2935572, "per_episode_reward": -86.99, "episode_reward_trend_value": 0.01528384536005013, "biggest_recent_change": 0.2574664423851658},
{"total_number_of_episodes": 11780, "number_of_timesteps": 2941860, "per_episode_reward": -86.74, "episode_reward_trend_value": 0.016707253464436495, "biggest_recent_change": 0.2574664423851658},
{"total_number_of_episodes": 11790, "number_of_timesteps": 2947280, "per_episode_reward": -86.41, "episode_reward_trend_value": 0.019355898491007256, "biggest_recent_change": 0.3256254070642086},
{"total_number_of_episodes": 11801, "number_of_timesteps": 2952337, "per_episode_reward": -86.03, "episode_reward_trend_value": 0.022162088176419716, "biggest_recent_change": 0.3785739501325054},
{"total_number_of_episodes": 11811, "number_of_timesteps": 2957608, "per_episode_reward": -85.84, "episode_reward_trend_value": 0.02144774161137756, "biggest_recent_change": 0.3785739501325054},
{"total_number_of_episodes": 11821, "number_of_timesteps": 2962102, "per_episode_reward": -85.63, "episode_reward_trend_value": 0.023096041069832533, "biggest_recent_change": 0.3785739501325054},
{"total_number_of_episodes": 11831, "number_of_timesteps": 2968902, "per_episode_reward": -85.25, "episode_reward_trend_value": 0.025221989717753007, "biggest_recent_change": 0.3827264982806895},
{"total_number_of_episodes": 11841, "number_of_timesteps": 2971931, "per_episode_reward": -84.45, "episode_reward_trend_value": 0.032110809102429035, "biggest_recent_change": 0.7934330785214598},
{"total_number_of_episodes": 11851, "number_of_timesteps": 2976879, "per_episode_reward": -84.27, "episode_reward_trend_value": 0.03151665109016288, "biggest_recent_change": 0.7934330785214598},
{"total_number_of_episodes": 11861, "number_of_timesteps": 2981324, "per_episode_reward": -83.52, "episode_reward_trend_value": 0.03856635285895954, "biggest_recent_change": 0.7934330785214598},
{"total_number_of_episodes": 11871, "number_of_timesteps": 2987680, "per_episode_reward": -83.42, "episode_reward_trend_value": 0.03679947664380292, "biggest_recent_change": 0.7934330785214598},
{"total_number_of_episodes": 11881, "number_of_timesteps": 2991387, "per_episode_reward": -83.26, "episode_reward_trend_value": 0.03498385379100928, "biggest_recent_change": 0.7934330785214598},
{"total_number_of_episodes": 11891, "number_of_timesteps": 2995603, "per_episode_reward": -83.05, "episode_reward_trend_value": 0.03309482328174325, "biggest_recent_change": 0.7934330785214598},
{"total_number_of_episodes": 11902, "number_of_timesteps": 3001609, "per_episode_reward": -82.82, "episode_reward_trend_value": 0.033507227646780775, "biggest_recent_change": 0.7934330785214598},
{"total_number_of_episodes": 11912, "number_of_timesteps": 3005829, "per_episode_reward": -82.64, "episode_reward_trend_value": 0.03325385105221383, "biggest_recent_change": 0.7934330785214598},
{"total_number_of_episodes": 11922, "number_of_timesteps": 3009669, "per_episode_reward": -82.35, "episode_reward_trend_value": 0.03213626650618898, "biggest_recent_change": 0.7934330785214598},
{"total_number_of_episodes": 11932, "number_of_timesteps": 3015583, "per_episode_reward": -82.25, "episode_reward_trend_value": 0.024424169285169876, "biggest_recent_change": 0.7450505125896569},
{"total_number_of_episodes": 11943, "number_of_timesteps": 3019662, "per_episode_reward": -81.93, "episode_reward_trend_value": 0.026011615921178254, "biggest_recent_change": 0.7450505125896569},
{"total_number_of_episodes": 11953, "number_of_timesteps": 3024385, "per_episode_reward": -81.66, "episode_reward_trend_value": 0.020652011099250307, "biggest_recent_change": 0.3283256396226619},
{"total_number_of_episodes": 11963, "number_of_timesteps": 3031401, "per_episode_reward": -81.18, "episode_reward_trend_value": 0.02492158877988828, "biggest_recent_change": 0.4821001609112301},
{"total_number_of_episodes": 11973, "number_of_timesteps": 3037731, "per_episode_reward": -80.92, "episode_reward_trend_value": 0.02598314695655246, "biggest_recent_change": 0.4821001609112301},
{"total_number_of_episodes": 11983, "number_of_timesteps": 3043335, "per_episode_reward": -80.62, "episode_reward_trend_value": 0.02700475047138045, "biggest_recent_change": 0.4821001609112301},
{"total_number_of_episodes": 11993, "number_of_timesteps": 3049527, "per_episode_reward": -80.4, "episode_reward_trend_value": 0.0268667620089398, "biggest_recent_change": 0.4821001609112301},
{"total_number_of_episodes": 12003, "number_of_timesteps": 3056603, "per_episode_reward": -80.16, "episode_reward_trend_value": 0.027507512565085317, "biggest_recent_change": 0.4821001609112301},
{"total_number_of_episodes": 12013, "number_of_timesteps": 3063642, "per_episode_reward": -79.85, "episode_reward_trend_value": 0.02776798893046046, "biggest_recent_change": 0.4821001609112301},
{"total_number_of_episodes": 12023, "number_of_timesteps": 3069528, "per_episode_reward": -79.72, "episode_reward_trend_value": 0.028161879906783344, "biggest_recent_change": 0.4821001609112301},
{"total_number_of_episodes": 12033, "number_of_timesteps": 3078972, "per_episode_reward": -79.65, "episode_reward_trend_value": 0.0252335685732722, "biggest_recent_change": 0.4821001609112301},
{"total_number_of_episodes": 12043, "number_of_timesteps": 3086308, "per_episode_reward": -79.45, "episode_reward_trend_value": 0.02456184182533671, "biggest_recent_change": 0.4821001609112301},
{"total_number_of_episodes": 12053, "number_of_timesteps": 3092457, "per_episode_reward": -79.24, "episode_reward_trend_value": 0.02157061234994965, "biggest_recent_change": 0.3055867620222159},
{"total_number_of_episodes": 12063, "number_of_timesteps": 3100572, "per_episode_reward": -79.06, "episode_reward_trend_value": 0.020694615211533256, "biggest_recent_change": 0.3055867620222159},
{"total_number_of_episodes": 12074, "number_of_timesteps": 3107165, "per_episode_reward": -78.92, "episode_reward_trend_value": 0.018888338301944745, "biggest_recent_change": 0.3055867620222159},
{"total_number_of_episodes": 12084, "number_of_timesteps": 3111020, "per_episode_reward": -78.72, "episode_reward_trend_value": 0.018733450561681922, "biggest_recent_change": 0.3055867620222159},
{"total_number_of_episodes": 12094, "number_of_timesteps": 3115806, "per_episode_reward": -78.14, "episode_reward_trend_value": 0.022476282808675623, "biggest_recent_change": 0.5817931465581552},
{"total_number_of_episodes": 12104, "number_of_timesteps": 3120958, "per_episode_reward": -77.97, "episode_reward_trend_value": 0.020944429052401542, "biggest_recent_change": 0.5817931465581552},
{"total_number_of_episodes": 12114, "number_of_timesteps": 3125259, "per_episode_reward": -77.82, "episode_reward_trend_value": 0.02106902067648093, "biggest_recent_change": 0.5817931465581552},
{"total_number_of_episodes": 12124, "number_of_timesteps": 3126809, "per_episode_reward": -77.71, "episode_reward_trend_value": 0.02162271248995956, "biggest_recent_change": 0.5817931465581552},
{"total_number_of_episodes": 12134, "number_of_timesteps": 3129928, "per_episode_reward": -77.57, "episode_reward_trend_value": 0.02093603901790162, "biggest_recent_change": 0.5817931465581552},
{"total_number_of_episodes": 12144, "number_of_timesteps": 3132461, "per_episode_reward": -77.42, "episode_reward_trend_value": 0.020168792350273967, "biggest_recent_change": 0.5817931465581552},
{"total_number_of_episodes": 12154, "number_of_timesteps": 3134730, "per_episode_reward": -77.27, "episode_reward_trend_value": 0.019859355475715608, "biggest_recent_change": 0.5817931465581552},
{"total_number_of_episodes": 12164, "number_of_timesteps": 3138105, "per_episode_reward": -77.0, "episode_reward_trend_value": 0.021344184657996517, "biggest_recent_change": 0.5817931465581552},
{"total_number_of_episodes": 12175, "number_of_timesteps": 3142291, "per_episode_reward": -76.85, "episode_reward_trend_value": 0.02078738122265978, "biggest_recent_change": 0.5817931465581552},
{"total_number_of_episodes": 12185, "number_of_timesteps": 3144735, "per_episode_reward": -76.8, "episode_reward_trend_value": 0.01488434090294943, "biggest_recent_change": 0.2715752251753969},
{"total_number_of_episodes": 12195, "number_of_timesteps": 3151310, "per_episode_reward": -76.63, "episode_reward_trend_value": 0.014880668597734667, "biggest_recent_change": 0.2715752251753969},
{"total_number_of_episodes": 12205, "number_of_timesteps": 3156276, "per_episode_reward": -76.55, "episode_reward_trend_value": 0.014103611783709388, "biggest_recent_change": 0.2715752251753969},
{"total_number_of_episodes": 12215, "number_of_timesteps": 3161324, "per_episode_reward": -76.28, "episode_reward_trend_value": 0.015813814968720565, "biggest_recent_change": 0.2715752251753969},
{"total_number_of_episodes": 12225, "number_of_timesteps": 3166690, "per_episode_reward": -76.05, "episode_reward_trend_value": 0.016918997479560792, "biggest_recent_change": 0.2715752251753969},
{"total_number_of_episodes": 12237, "number_of_timesteps": 3170484, "per_episode_reward": -75.81, "episode_reward_trend_value": 0.01794263475137667, "biggest_recent_change": 0.2715752251753969},
{"total_number_of_episodes": 12247, "number_of_timesteps": 3173397, "per_episode_reward": -75.72, "episode_reward_trend_value": 0.017283562550723115, "biggest_recent_change": 0.2715752251753969},
{"total_number_of_episodes": 12257, "number_of_timesteps": 3177262, "per_episode_reward": -75.59, "episode_reward_trend_value": 0.01570529616101671, "biggest_recent_change": 0.2685281694707413},
{"total_number_of_episodes": 12267, "number_of_timesteps": 3179528, "per_episode_reward": -75.42, "episode_reward_trend_value": 0.015875816144090827, "biggest_recent_change": 0.2685281694707413},
{"total_number_of_episodes": 12277, "number_of_timesteps": 3183601, "per_episode_reward": -75.26, "episode_reward_trend_value": 0.017117133246011284, "biggest_recent_change": 0.2685281694707413},
{"total_number_of_episodes": 12287, "number_of_timesteps": 3187285, "per_episode_reward": -74.91, "episode_reward_trend_value": 0.019117011472533342, "biggest_recent_change": 0.3473784568752052},
{"total_number_of_episodes": 12297, "number_of_timesteps": 3192844, "per_episode_reward": -74.71, "episode_reward_trend_value": 0.0204966777427695, "biggest_recent_change": 0.3473784568752052},
{"total_number_of_episodes": 12307, "number_of_timesteps": 3195979, "per_episode_reward": -74.66, "episode_reward_trend_value": 0.018067667532232986, "biggest_recent_change": 0.3473784568752052},
{"total_number_of_episodes": 12317, "number_of_timesteps": 3197961, "per_episode_reward": -74.6, "episode_reward_trend_value": 0.01603455644399677, "biggest_recent_change": 0.3473784568752052},
{"total_number_of_episodes": 12328, "number_of_timesteps": 3201547, "per_episode_reward": -74.51, "episode_reward_trend_value": 0.014382208306581707, "biggest_recent_change": 0.3473784568752052},
{"total_number_of_episodes": 12338, "number_of_timesteps": 3203999, "per_episode_reward": -74.39, "episode_reward_trend_value": 0.014748619374164995, "biggest_recent_change": 0.3473784568752052},
{"total_number_of_episodes": 12348, "number_of_timesteps": 3208156, "per_episode_reward": -74.3, "episode_reward_trend_value": 0.014337182563603949, "biggest_recent_change": 0.3473784568752052},
{"total_number_of_episodes": 12358, "number_of_timesteps": 3213083, "per_episode_reward": -74.17, "episode_reward_trend_value": 0.01383310209711747, "biggest_recent_change": 0.3473784568752052},
{"total_number_of_episodes": 12368, "number_of_timesteps": 3215709, "per_episode_reward": -73.96, "episode_reward_trend_value": 0.014351677958272071, "biggest_recent_change": 0.3473784568752052},
{"total_number_of_episodes": 12378, "number_of_timesteps": 3219234, "per_episode_reward": -73.81, "episode_reward_trend_value": 0.012175670104348373, "biggest_recent_change": 0.20890988446097936},
{"total_number_of_episodes": 12388, "number_of_timesteps": 3221825, "per_episode_reward": -73.75, "episode_reward_trend_value": 0.010661097876100062, "biggest_recent_change": 0.20890988446097936},
{"total_number_of_episodes": 12398, "number_of_timesteps": 3224471, "per_episode_reward": -73.52, "episode_reward_trend_value": 0.012680631269730546, "biggest_recent_change": 0.2316752559491988},
{"total_number_of_episodes": 12408, "number_of_timesteps": 3229272, "per_episode_reward": -73.37, "episode_reward_trend_value": 0.013640437005413572, "biggest_recent_change": 0.2316752559491988},
{"total_number_of_episodes": 12418, "number_of_timesteps": 3230666, "per_episode_reward": -73.15, "episode_reward_trend_value": 0.015187884387605285, "biggest_recent_change": 0.2316752559491988},
{"total_number_of_episodes": 12428, "number_of_timesteps": 3233657, "per_episode_reward": -73.06, "episode_reward_trend_value": 0.014819251948918893, "biggest_recent_change": 0.2316752559491988},
{"total_number_of_episodes": 12438, "number_of_timesteps": 3236227, "per_episode_reward": -72.89, "episode_reward_trend_value": 0.015594663870196732, "biggest_recent_change": 0.2316752559491988},
{"total_number_of_episodes": 12448, "number_of_timesteps": 3238592, "per_episode_reward": -72.71, "episode_reward_trend_value": 0.01624578604033628, "biggest_recent_change": 0.2316752559491988},
{"total_number_of_episodes": 12458, "number_of_timesteps": 3240923, "per_episode_reward": -72.59, "episode_reward_trend_value": 0.015281556535983518, "biggest_recent_change": 0.2316752559491988},
{"total_number_of_episodes": 12468, "number_of_timesteps": 3242443, "per_episode_reward": -72.38, "episode_reward_trend_value": 0.015945028047051026, "biggest_recent_change": 0.2316752559491988},
{"total_number_of_episodes": 12478, "number_of_timesteps": 3244588, "per_episode_reward": -72.07, "episode_reward_trend_value": 0.018665949779947434, "biggest_recent_change": 0.3088140691432528},
{"total_number_of_episodes": 12488, "number_of_timesteps": 3247221, "per_episode_reward": -71.8, "episode_reward_trend_value": 0.01904836207828456, "biggest_recent_change": 0.3088140691432528},
{"total_number_of_episodes": 12499, "number_of_timesteps": 3250593, "per_episode_reward": -71.5, "episode_reward_trend_value": 0.020864037426499258, "biggest_recent_change": 0.3088140691432528},
{"total_number_of_episodes": 12510, "number_of_timesteps": 3252135, "per_episode_reward": -71.26, "episode_reward_trend_value": 0.021000194100609486, "biggest_recent_change": 0.3088140691432528},
{"total_number_of_episodes": 12521, "number_of_timesteps": 3254859, "per_episode_reward": -70.98, "episode_reward_trend_value": 0.02304054819823765, "biggest_recent_change": 0.3088140691432528},
{"total_number_of_episodes": 12532, "number_of_timesteps": 3256460, "per_episode_reward": -70.8, "episode_reward_trend_value": 0.023227654839405906, "biggest_recent_change": 0.3088140691432528},
{"total_number_of_episodes": 12543, "number_of_timesteps": 3261010, "per_episode_reward": -70.65, "episode_reward_trend_value": 0.022943820487479942, "biggest_recent_change": 0.3088140691432528},
{"total_number_of_episodes": 12553, "number_of_timesteps": 3264163, "per_episode_reward": -70.44, "episode_reward_trend_value": 0.023852092232199754, "biggest_recent_change": 0.3088140691432528},
{"total_number_of_episodes": 12564, "number_of_timesteps": 3268271, "per_episode_reward": -70.25, "episode_reward_trend_value": 0.023673659985796923, "biggest_recent_change": 0.3088140691432528},
{"total_number_of_episodes": 12574, "number_of_timesteps": 3270498, "per_episode_reward": -70.04, "episode_reward_trend_value": 0.022577155750866655, "biggest_recent_change": 0.3067097844018889},
{"total_number_of_episodes": 12584, "number_of_timesteps": 3272724, "per_episode_reward": -69.73, "episode_reward_trend_value": 0.02302111145795654, "biggest_recent_change": 0.3067097844018889},
{"total_number_of_episodes": 12594, "number_of_timesteps": 3276792, "per_episode_reward": -69.49, "episode_reward_trend_value": 0.022261528265190438, "biggest_recent_change": 0.30604837643763005},
{"total_number_of_episodes": 12604, "number_of_timesteps": 3278777, "per_episode_reward": -69.27, "episode_reward_trend_value": 0.022093067764675962, "biggest_recent_change": 0.30604837643763005},
{"total_number_of_episodes": 12614, "number_of_timesteps": 3281437, "per_episode_reward": -68.95, "episode_reward_trend_value": 0.02258339728133715, "biggest_recent_change": 0.3193156288727721},
{"total_number_of_episodes": 12624, "number_of_timesteps": 3283101, "per_episode_reward": -68.7, "episode_reward_trend_value": 0.02339795192167347, "biggest_recent_change": 0.3193156288727721},
{"total_number_of_episodes": 12634, "number_of_timesteps": 3287289, "per_episode_reward": -68.63, "episode_reward_trend_value": 0.02244420124171253, "biggest_recent_change": 0.3193156288727721},
{"total_number_of_episodes": 12644, "number_of_timesteps": 3292282, "per_episode_reward": -68.5, "episode_reward_trend_value": 0.021561342125807906, "biggest_recent_change": 0.3193156288727721},
{"total_number_of_episodes": 12654, "number_of_timesteps": 3297133, "per_episode_reward": -68.27, "episode_reward_trend_value": 0.02197752588619311, "biggest_recent_change": 0.3193156288727721},
{"total_number_of_episodes": 12664, "number_of_timesteps": 3298701, "per_episode_reward": -68.09, "episode_reward_trend_value": 0.02167788546813859, "biggest_recent_change": 0.3193156288727721},
{"total_number_of_episodes": 12675, "number_of_timesteps": 3300601, "per_episode_reward": -68.02, "episode_reward_trend_value": 0.019065875020877362, "biggest_recent_change": 0.3193156288727721},
{"total_number_of_episodes": 12685, "number_of_timesteps": 3306189, "per_episode_reward": -67.94, "episode_reward_trend_value": 0.017242630128571867, "biggest_recent_change": 0.3193156288727721},
{"total_number_of_episodes": 12696, "number_of_timesteps": 3307876, "per_episode_reward": -67.83, "episode_reward_trend_value": 0.01602623873958022, "biggest_recent_change": 0.3193156288727721},
{"total_number_of_episodes": 12707, "number_of_timesteps": 3309501, "per_episode_reward": -67.57, "episode_reward_trend_value": 0.015297107860973824, "biggest_recent_change": 0.2536938497981964},
{"total_number_of_episodes": 12717, "number_of_timesteps": 3311897, "per_episode_reward": -67.35, "episode_reward_trend_value": 0.014935514830403129, "biggest_recent_change": 0.2536938497981964},
{"total_number_of_episodes": 12727, "number_of_timesteps": 3314181, "per_episode_reward": -67.08, "episode_reward_trend_value": 0.01720631636484945, "biggest_recent_change": 0.2753905139969248},
{"total_number_of_episodes": 12737, "number_of_timesteps": 3319996, "per_episode_reward": -66.91, "episode_reward_trend_value": 0.017688939613456807, "biggest_recent_change": 0.2753905139969248},
{"total_number_of_episodes": 12747, "number_of_timesteps": 3321726, "per_episode_reward": -66.67, "episode_reward_trend_value": 0.017822828845964978, "biggest_recent_change": 0.2753905139969248},
{"total_number_of_episodes": 12757, "number_of_timesteps": 3326425, "per_episode_reward": -66.39, "episode_reward_trend_value": 0.01888437576501221, "biggest_recent_change": 0.278700273088873},
{"total_number_of_episodes": 12767, "number_of_timesteps": 3329560, "per_episode_reward": -66.27, "episode_reward_trend_value": 0.01935267495267428, "biggest_recent_change": 0.278700273088873},
{"total_number_of_episodes": 12777, "number_of_timesteps": 3332133, "per_episode_reward": -66.18, "episode_reward_trend_value": 0.01952454582825535, "biggest_recent_change": 0.278700273088873},
{"total_number_of_episodes": 12787, "number_of_timesteps": 3335145, "per_episode_reward": -66.0, "episode_reward_trend_value": 0.020354977359008174, "biggest_recent_change": 0.278700273088873},
{"total_number_of_episodes": 12798, "number_of_timesteps": 3336986, "per_episode_reward": -65.9, "episode_reward_trend_value": 0.018590933662121896, "biggest_recent_change": 0.278700273088873},
{"total_number_of_episodes": 12809, "number_of_timesteps": 3340754, "per_episode_reward": -65.79, "episode_reward_trend_value": 0.017319394883719023, "biggest_recent_change": 0.278700273088873},
{"total_number_of_episodes": 12819, "number_of_timesteps": 3343338, "per_episode_reward": -65.73, "episode_reward_trend_value": 0.015008459297954524, "biggest_recent_change": 0.278700273088873},
{"total_number_of_episodes": 12829, "number_of_timesteps": 3348619, "per_episode_reward": -65.54, "episode_reward_trend_value": 0.015200831611103163, "biggest_recent_change": 0.278700273088873},
{"total_number_of_episodes": 12839, "number_of_timesteps": 3354851, "per_episode_reward": -65.39, "episode_reward_trend_value": 0.014174858175938235, "biggest_recent_change": 0.278700273088873},
{"total_number_of_episodes": 12849, "number_of_timesteps": 3359750, "per_episode_reward": -65.29, "episode_reward_trend_value": 0.012207807127087102, "biggest_recent_change": 0.18887986291535697},
{"total_number_of_episodes": 12859, "number_of_timesteps": 3367121, "per_episode_reward": -65.07, "episode_reward_trend_value": 0.01341003920297652, "biggest_recent_change": 0.2213152499037534},
{"total_number_of_episodes": 12869, "number_of_timesteps": 3371264, "per_episode_reward": -65.06, "episode_reward_trend_value": 0.012455742324103231, "biggest_recent_change": 0.2213152499037534},
{"total_number_of_episodes": 12879, "number_of_timesteps": 3379166, "per_episode_reward": -64.89, "episode_reward_trend_value": 0.012293478900020697, "biggest_recent_change": 0.2213152499037534},
{"total_number_of_episodes": 12889, "number_of_timesteps": 3386860, "per_episode_reward": -64.78, "episode_reward_trend_value": 0.012487244185478454, "biggest_recent_change": 0.2213152499037534},
{"total_number_of_episodes": 12899, "number_of_timesteps": 3394775, "per_episode_reward": -64.54, "episode_reward_trend_value": 0.013956596326096835, "biggest_recent_change": 0.23769835524977623},
{"total_number_of_episodes": 12909, "number_of_timesteps": 3403570, "per_episode_reward": -64.54, "episode_reward_trend_value": 0.013237871313994435, "biggest_recent_change": 0.23769835524977623},
{"total_number_of_episodes": 12919, "number_of_timesteps": 3411685, "per_episode_reward": -64.17, "episode_reward_trend_value": 0.015194432146157687, "biggest_recent_change": 0.36125644111533006},
{"total_number_of_episodes": 12929, "number_of_timesteps": 3418559, "per_episode_reward": -64.3, "episode_reward_trend_value": 0.012125962885009124, "biggest_recent_change": 0.36125644111533006},
{"total_number_of_episodes": 12939, "number_of_timesteps": 3424901, "per_episode_reward": -64.11, "episode_reward_trend_value": 0.013132609692666442, "biggest_recent_change": 0.36125644111533006},
{"total_number_of_episodes": 12949, "number_of_timesteps": 3431465, "per_episode_reward": -63.83, "episode_reward_trend_value": 0.013791167922959997, "biggest_recent_change": 0.36125644111533006},
{"total_number_of_episodes": 12959, "number_of_timesteps": 3438515, "per_episode_reward": -63.66, "episode_reward_trend_value": 0.015585672772050353, "biggest_recent_change": 0.36125644111533006},
{"total_number_of_episodes": 12969, "number_of_timesteps": 3444675, "per_episode_reward": -63.38, "episode_reward_trend_value": 0.01674656716928532, "biggest_recent_change": 0.36125644111533006},
{"total_number_of_episodes": 12979, "number_of_timesteps": 3448731, "per_episode_reward": -63.05, "episode_reward_trend_value": 0.01913689153414495, "biggest_recent_change": 0.36125644111533006},
{"total_number_of_episodes": 12989, "number_of_timesteps": 3453992, "per_episode_reward": -62.93, "episode_reward_trend_value": 0.017913922653295344, "biggest_recent_change": 0.36125644111533006},
{"total_number_of_episodes": 12999, "number_of_timesteps": 3460086, "per_episode_reward": -62.77, "episode_reward_trend_value": 0.019665519418198586, "biggest_recent_change": 0.36125644111533006},
{"total_number_of_episodes": 13010, "number_of_timesteps": 3466080, "per_episode_reward": -62.55, "episode_reward_trend_value": 0.018026605746552272, "biggest_recent_change": 0.32749798560699617},
{"total_number_of_episodes": 13020, "number_of_timesteps": 3471260, "per_episode_reward": -62.48, "episode_reward_trend_value": 0.02015541701757321, "biggest_recent_change": 0.32749798560699617},
{"total_number_of_episodes": 13030, "number_of_timesteps": 3474789, "per_episode_reward": -62.39, "episode_reward_trend_value": 0.019073253726772224, "biggest_recent_change": 0.32749798560699617},
{"total_number_of_episodes": 13040, "number_of_timesteps": 3480673, "per_episode_reward": -62.23, "episode_reward_trend_value": 0.01775618870098757, "biggest_recent_change": 0.32749798560699617},
{"total_number_of_episodes": 13050, "number_of_timesteps": 3485275, "per_episode_reward": -62.12, "episode_reward_trend_value": 0.017072027937058306, "biggest_recent_change": 0.32749798560699617},
{"total_number_of_episodes": 13060, "number_of_timesteps": 3491970, "per_episode_reward": -62.03, "episode_reward_trend_value": 0.015013136319266745, "biggest_recent_change": 0.32749798560699617},
{"total_number_of_episodes": 13070, "number_of_timesteps": 3498105, "per_episode_reward": -61.95, "episode_reward_trend_value": 0.012289454652610804, "biggest_recent_change": 0.21375421066716171},
{"total_number_of_episodes": 13080, "number_of_timesteps": 3503492, "per_episode_reward": -61.86, "episode_reward_trend_value": 0.011813628398371714, "biggest_recent_change": 0.21375421066716171},
{"total_number_of_episodes": 13090, "number_of_timesteps": 3509936, "per_episode_reward": -61.7, "episode_reward_trend_value": 0.01186024086438064, "biggest_recent_change": 0.21375421066716171},
{"total_number_of_episodes": 13100, "number_of_timesteps": 3514280, "per_episode_reward": -61.47, "episode_reward_trend_value": 0.012057213722564736, "biggest_recent_change": 0.23148176790373043},
{"total_number_of_episodes": 13110, "number_of_timesteps": 3518368, "per_episode_reward": -61.35, "episode_reward_trend_value": 0.012573125504217427, "biggest_recent_change": 0.23148176790373043},
{"total_number_of_episodes": 13120, "number_of_timesteps": 3524335, "per_episode_reward": -61.23, "episode_reward_trend_value": 0.012875642345828928, "biggest_recent_change": 0.23148176790373043},
{"total_number_of_episodes": 13130, "number_of_timesteps": 3529586, "per_episode_reward": -61.12, "episode_reward_trend_value": 0.012321840130277432, "biggest_recent_change": 0.23148176790373043},
{"total_number_of_episodes": 13140, "number_of_timesteps": 3533014, "per_episode_reward": -60.87, "episode_reward_trend_value": 0.013886938843759744, "biggest_recent_change": 0.244626768327052},
{"total_number_of_episodes": 13150, "number_of_timesteps": 3538731, "per_episode_reward": -60.65, "episode_reward_trend_value": 0.015377591600302842, "biggest_recent_change": 0.244626768327052},
{"total_number_of_episodes": 13160, "number_of_timesteps": 3542100, "per_episode_reward": -59.99, "episode_reward_trend_value": 0.021753087476132058, "biggest_recent_change": 0.6561612644325905},
{"total_number_of_episodes": 13170, "number_of_timesteps": 3544784, "per_episode_reward": -59.87, "episode_reward_trend_value": 0.022164656266178816, "biggest_recent_change": 0.6561612644325905},
{"total_number_of_episodes": 13180, "number_of_timesteps": 3548750, "per_episode_reward": -59.84, "episode_reward_trend_value": 0.02060097088491146, "biggest_recent_change": 0.6561612644325905},
{"total_number_of_episodes": 13190, "number_of_timesteps": 3552377, "per_episode_reward": -59.75, "episode_reward_trend_value": 0.019050809946255576, "biggest_recent_change": 0.6561612644325905},
{"total_number_of_episodes": 13200, "number_of_timesteps": 3557668, "per_episode_reward": -59.7, "episode_reward_trend_value": 0.018403479321396552, "biggest_recent_change": 0.6561612644325905},
{"total_number_of_episodes": 13210, "number_of_timesteps": 3562730, "per_episode_reward": -59.63, "episode_reward_trend_value": 0.017773169356131685, "biggest_recent_change": 0.6561612644325905},
{"total_number_of_episodes": 13220, "number_of_timesteps": 3566786, "per_episode_reward": -59.56, "episode_reward_trend_value": 0.017354141627376248, "biggest_recent_change": 0.6561612644325905},
{"total_number_of_episodes": 13230, "number_of_timesteps": 3572036, "per_episode_reward": -59.25, "episode_reward_trend_value": 0.0180087259128208, "biggest_recent_change": 0.6561612644325905},
{"total_number_of_episodes": 13240, "number_of_timesteps": 3576813, "per_episode_reward": -59.13, "episode_reward_trend_value": 0.01682794100166305, "biggest_recent_change": 0.6561612644325905},
{"total_number_of_episodes": 13250, "number_of_timesteps": 3581831, "per_episode_reward": -59.02, "episode_reward_trend_value": 0.010769092336606039, "biggest_recent_change": 0.30353935401706167},
{"total_number_of_episodes": 13260, "number_of_timesteps": 3587306, "per_episode_reward": -58.97, "episode_reward_trend_value": 0.009950100941946654, "biggest_recent_change": 0.30353935401706167},
{"total_number_of_episodes": 13270, "number_of_timesteps": 3591824, "per_episode_reward": -58.86, "episode_reward_trend_value": 0.010985742917777389, "biggest_recent_change": 0.30353935401706167},
{"total_number_of_episodes": 13280, "number_of_timesteps": 3599138, "per_episode_reward": -58.57, "episode_reward_trend_value": 0.013179001616784643, "biggest_recent_change": 0.30353935401706167},
{"total_number_of_episodes": 13290, "number_of_timesteps": 3606453, "per_episode_reward": -58.42, "episode_reward_trend_value": 0.014160724960116037, "biggest_recent_change": 0.30353935401706167},
{"total_number_of_episodes": 13300, "number_of_timesteps": 3612954, "per_episode_reward": -58.36, "episode_reward_trend_value": 0.014178465794525388, "biggest_recent_change": 0.30353935401706167},
{"total_number_of_episodes": 13310, "number_of_timesteps": 3617859, "per_episode_reward": -58.25, "episode_reward_trend_value": 0.014475466838318202, "biggest_recent_change": 0.30353935401706167},
{"total_number_of_episodes": 13320, "number_of_timesteps": 3625745, "per_episode_reward": -58.08, "episode_reward_trend_value": 0.012988375739426614, "biggest_recent_change": 0.289360566335354},
{"total_number_of_episodes": 13330, "number_of_timesteps": 3631005, "per_episode_reward": -57.96, "episode_reward_trend_value": 0.013005777024046792, "biggest_recent_change": 0.289360566335354},
{"total_number_of_episodes": 13340, "number_of_timesteps": 3637292, "per_episode_reward": -57.84, "episode_reward_trend_value": 0.013100736817269384, "biggest_recent_change": 0.289360566335354},
{"total_number_of_episodes": 13350, "number_of_timesteps": 3642139, "per_episode_reward": -57.68, "episode_reward_trend_value": 0.014311364728639198, "biggest_recent_change": 0.289360566335354},
{"total_number_of_episodes": 13360, "number_of_timesteps": 3648002, "per_episode_reward": -57.63, "episode_reward_trend_value": 0.013659713589208089, "biggest_recent_change": 0.289360566335354},
{"total_number_of_episodes": 13370, "number_of_timesteps": 3654563, "per_episode_reward": -57.54, "episode_reward_trend_value": 0.011452047871681576, "biggest_recent_change": 0.16970115511681882},
{"total_number_of_episodes": 13381, "number_of_timesteps": 3660510, "per_episode_reward": -57.37, "episode_reward_trend_value": 0.01172704945083017, "biggest_recent_change": 0.16970115511681882},
{"total_number_of_episodes": 13391, "number_of_timesteps": 3668127, "per_episode_reward": -57.29, "episode_reward_trend_value": 0.011885184484324105, "biggest_recent_change": 0.16970115511681882},
{"total_number_of_episodes": 13401, "number_of_timesteps": 3673885, "per_episode_reward": -56.88, "episode_reward_trend_value": 0.015212758358764867, "biggest_recent_change": 0.4007066859629518},
{"total_number_of_episodes": 13411, "number_of_timesteps": 3679125, "per_episode_reward": -56.78, "episode_reward_trend_value": 0.014496751093202124, "biggest_recent_change": 0.4007066859629518},
{"total_number_of_episodes": 13421, "number_of_timesteps": 3684900, "per_episode_reward": -56.63, "episode_reward_trend_value": 0.01477995411361061, "biggest_recent_change": 0.4007066859629518},
{"total_number_of_episodes": 13431, "number_of_timesteps": 3688894, "per_episode_reward": -56.54, "episode_reward_trend_value": 0.014458790188908527, "biggest_recent_change": 0.4007066859629518},
{"total_number_of_episodes": 13441, "number_of_timesteps": 3694491, "per_episode_reward": -56.45, "episode_reward_trend_value": 0.013709161532502397, "biggest_recent_change": 0.4007066859629518},
{"total_number_of_episodes": 13451, "number_of_timesteps": 3700095, "per_episode_reward": -56.34, "episode_reward_trend_value": 0.0143194767188542, "biggest_recent_change": 0.4007066859629518},
{"total_number_of_episodes": 13461, "number_of_timesteps": 3705896, "per_episode_reward": -56.23, "episode_reward_trend_value": 0.014474717548177316, "biggest_recent_change": 0.4007066859629518},
{"total_number_of_episodes": 13471, "number_of_timesteps": 3710219, "per_episode_reward": -56.2, "episode_reward_trend_value": 0.012954745330742017, "biggest_recent_change": 0.4007066859629518},
{"total_number_of_episodes": 13482, "number_of_timesteps": 3715329, "per_episode_reward": -56.1, "episode_reward_trend_value": 0.013206071932986419, "biggest_recent_change": 0.4007066859629518},
{"total_number_of_episodes": 13492, "number_of_timesteps": 3719734, "per_episode_reward": -55.9, "episode_reward_trend_value": 0.01096824913476624, "biggest_recent_change": 0.19930263412313565},
{"total_number_of_episodes": 13503, "number_of_timesteps": 3726992, "per_episode_reward": -55.76, "episode_reward_trend_value": 0.011376782338527233, "biggest_recent_change": 0.19930263412313565},
{"total_number_of_episodes": 13514, "number_of_timesteps": 3730941, "per_episode_reward": -55.34, "episode_reward_trend_value": 0.014387509490131834, "biggest_recent_change": 0.41936434207951123},
{"total_number_of_episodes": 13524, "number_of_timesteps": 3736536, "per_episode_reward": -55.21, "episode_reward_trend_value": 0.014799014980053394, "biggest_recent_change": 0.41936434207951123},
{"total_number_of_episodes": 13534, "number_of_timesteps": 3744263, "per_episode_reward": -55.12, "episode_reward_trend_value": 0.014760740416980885, "biggest_recent_change": 0.41936434207951123},
{"total_number_of_episodes": 13544, "number_of_timesteps": 3751274, "per_episode_reward": -55.02, "episode_reward_trend_value": 0.014586586881884422, "biggest_recent_change": 0.41936434207951123},
{"total_number_of_episodes": 13554, "number_of_timesteps": 3757919, "per_episode_reward": -54.8, "episode_reward_trend_value": 0.01588475843818197, "biggest_recent_change": 0.41936434207951123},
{"total_number_of_episodes": 13564, "number_of_timesteps": 3764691, "per_episode_reward": -54.71, "episode_reward_trend_value": 0.0165996488501726, "biggest_recent_change": 0.41936434207951123},
{"total_number_of_episodes": 13576, "number_of_timesteps": 3770862, "per_episode_reward": -54.47, "episode_reward_trend_value": 0.01811630571113001, "biggest_recent_change": 0.41936434207951123},
{"total_number_of_episodes": 13586, "number_of_timesteps": 3775127, "per_episode_reward": -54.26, "episode_reward_trend_value": 0.018243683709653957, "biggest_recent_change": 0.41936434207951123},
{"total_number_of_episodes": 13596, "number_of_timesteps": 3780966, "per_episode_reward": -54.17, "episode_reward_trend_value": 0.017573480077013037, "biggest_recent_change": 0.41936434207951123},
{"total_number_of_episodes": 13606, "number_of_timesteps": 3785824, "per_episode_reward": -54.05, "episode_reward_trend_value": 0.014290943891996635, "biggest_recent_change": 0.24031515387999747},
{"total_number_of_episodes": 13616, "number_of_timesteps": 3792627, "per_episode_reward": -54.0, "episode_reward_trend_value": 0.013427132876962292, "biggest_recent_change": 0.24031515387999747},
{"total_number_of_episodes": 13626, "number_of_timesteps": 3799141, "per_episode_reward": -53.95, "episode_reward_trend_value": 0.012977454325808522, "biggest_recent_change": 0.24031515387999747},
{"total_number_of_episodes": 13636, "number_of_timesteps": 3806129, "per_episode_reward": -53.9, "episode_reward_trend_value": 0.01252247947942264, "biggest_recent_change": 0.24031515387999747},
{"total_number_of_episodes": 13646, "number_of_timesteps": 3812896, "per_episode_reward": -53.79, "episode_reward_trend_value": 0.011228112421310183, "biggest_recent_change": 0.24031515387999747},
{"total_number_of_episodes": 13656, "number_of_timesteps": 3820168, "per_episode_reward": -53.69, "episode_reward_trend_value": 0.011275775431692382, "biggest_recent_change": 0.24031515387999747},
{"total_number_of_episodes": 13666, "number_of_timesteps": 3826126, "per_episode_reward": -53.62, "episode_reward_trend_value": 0.009384063466299056, "biggest_recent_change": 0.21076665399029082},
{"total_number_of_episodes": 13676, "number_of_timesteps": 3831528, "per_episode_reward": -53.33, "episode_reward_trend_value": 0.010324539779267086, "biggest_recent_change": 0.29540952215741356},
{"total_number_of_episodes": 13686, "number_of_timesteps": 3837557, "per_episode_reward": -53.16, "episode_reward_trend_value": 0.011297457925182958, "biggest_recent_change": 0.29540952215741356},
{"total_number_of_episodes": 13696, "number_of_timesteps": 3841471, "per_episode_reward": -53.11, "episode_reward_trend_value": 0.010478688156396031, "biggest_recent_change": 0.29540952215741356},
{"total_number_of_episodes": 13706, "number_of_timesteps": 3848127, "per_episode_reward": -53.0, "episode_reward_trend_value": 0.01115968807750581, "biggest_recent_change": 0.29540952215741356},
{"total_number_of_episodes": 13716, "number_of_timesteps": 3854847, "per_episode_reward": -52.77, "episode_reward_trend_value": 0.013115149857884095, "biggest_recent_change": 0.29540952215741356},
{"total_number_of_episodes": 13726, "number_of_timesteps": 3860911, "per_episode_reward": -52.66, "episode_reward_trend_value": 0.013788899770437032, "biggest_recent_change": 0.29540952215741356},
{"total_number_of_episodes": 13736, "number_of_timesteps": 3864428, "per_episode_reward": -52.35, "episode_reward_trend_value": 0.01602708161025753, "biggest_recent_change": 0.3064210968175516},
{"total_number_of_episodes": 13746, "number_of_timesteps": 3869044, "per_episode_reward": -52.22, "episode_reward_trend_value": 0.016371792832331287, "biggest_recent_change": 0.3064210968175516},
{"total_number_of_episodes": 13756, "number_of_timesteps": 3874015, "per_episode_reward": -52.12, "episode_reward_trend_value": 0.01663896691943426, "biggest_recent_change": 0.3064210968175516},
{"total_number_of_episodes": 13766, "number_of_timesteps": 3881264, "per_episode_reward": -51.97, "episode_reward_trend_value": 0.015023006715601245, "biggest_recent_change": 0.3064210968175516},
{"total_number_of_episodes": 13776, "number_of_timesteps": 3888907, "per_episode_reward": -51.97, "episode_reward_trend_value": 0.01315486775565328, "biggest_recent_change": 0.3064210968175516},
{"total_number_of_episodes": 13786, "number_of_timesteps": 3895136, "per_episode_reward": -51.86, "episode_reward_trend_value": 0.013910698686443132, "biggest_recent_change": 0.3064210968175516},
{"total_number_of_episodes": 13796, "number_of_timesteps": 3901692, "per_episode_reward": -51.57, "episode_reward_trend_value": 0.015851368203288592, "biggest_recent_change": 0.3064210968175516},
{"total_number_of_episodes": 13806, "number_of_timesteps": 3907126, "per_episode_reward": -51.52, "episode_reward_trend_value": 0.013886919276057183, "biggest_recent_change": 0.3064210968175516},
{"total_number_of_episodes": 13816, "number_of_timesteps": 3914145, "per_episode_reward": -51.41, "episode_reward_trend_value": 0.01389884353011297, "biggest_recent_change": 0.3064210968175516},
{"total_number_of_episodes": 13826, "number_of_timesteps": 3921746, "per_episode_reward": -51.38, "episode_reward_trend_value": 0.010818209132246261, "biggest_recent_change": 0.28574926490012587},
{"total_number_of_episodes": 13836, "number_of_timesteps": 3930337, "per_episode_reward": -51.3, "episode_reward_trend_value": 0.01019171584851277, "biggest_recent_change": 0.28574926490012587},
{"total_number_of_episodes": 13846, "number_of_timesteps": 3936554, "per_episode_reward": -51.22, "episode_reward_trend_value": 0.010080574119430391, "biggest_recent_change": 0.28574926490012587},
{"total_number_of_episodes": 13856, "number_of_timesteps": 3942856, "per_episode_reward": -51.09, "episode_reward_trend_value": 0.009848356285339498, "biggest_recent_change": 0.28574926490012587},
{"total_number_of_episodes": 13866, "number_of_timesteps": 3947991, "per_episode_reward": -50.98, "episode_reward_trend_value": 0.011067342768206442, "biggest_recent_change": 0.28574926490012587},
{"total_number_of_episodes": 13876, "number_of_timesteps": 3951780, "per_episode_reward": -50.89, "episode_reward_trend_value": 0.01071034348678918, "biggest_recent_change": 0.28574926490012587},
{"total_number_of_episodes": 13886, "number_of_timesteps": 3956423, "per_episode_reward": -50.83, "episode_reward_trend_value": 0.008255006036656217, "biggest_recent_change": 0.12907349874426188},
{"total_number_of_episodes": 13896, "number_of_timesteps": 3961653, "per_episode_reward": -50.73, "episode_reward_trend_value": 0.00879370182189163, "biggest_recent_change": 0.12907349874426188},
{"total_number_of_episodes": 13906, "number_of_timesteps": 3966850, "per_episode_reward": -50.69, "episode_reward_trend_value": 0.007961346197867177, "biggest_recent_change": 0.12907349874426188},
{"total_number_of_episodes": 13916, "number_of_timesteps": 3971499, "per_episode_reward": -50.6, "episode_reward_trend_value": 0.008659697534350702, "biggest_recent_change": 0.12907349874426188},
{"total_number_of_episodes": 13926, "number_of_timesteps": 3977807, "per_episode_reward": -50.55, "episode_reward_trend_value": 0.008342763946402461, "biggest_recent_change": 0.12907349874426188},
{"total_number_of_episodes": 13936, "number_of_timesteps": 3984185, "per_episode_reward": -50.11, "episode_reward_trend_value": 0.012282909063149106, "biggest_recent_change": 0.43871704972364967},
{"total_number_of_episodes": 13946, "number_of_timesteps": 3988696, "per_episode_reward": -50.09, "episode_reward_trend_value": 0.01105635975899762, "biggest_recent_change": 0.43871704972364967},
{"total_number_of_episodes": 13956, "number_of_timesteps": 3993690, "per_episode_reward": -49.86, "episode_reward_trend_value": 0.012440466887764342, "biggest_recent_change": 0.43871704972364967},
{"total_number_of_episodes": 13966, "number_of_timesteps": 3999408, "per_episode_reward": -49.74, "episode_reward_trend_value": 0.012789575350872046, "biggest_recent_change": 0.43871704972364967},
{"total_number_of_episodes": 13976, "number_of_timesteps": 4006633, "per_episode_reward": -49.61, "episode_reward_trend_value": 0.013553297561428933, "biggest_recent_change": 0.43871704972364967},
{"total_number_of_episodes": 13986, "number_of_timesteps": 4014286, "per_episode_reward": -49.42, "episode_reward_trend_value": 0.014583535543192503, "biggest_recent_change": 0.43871704972364967},
{"total_number_of_episodes": 13996, "number_of_timesteps": 4021593, "per_episode_reward": -49.39, "episode_reward_trend_value": 0.01448054996957716, "biggest_recent_change": 0.43871704972364967},
{"total_number_of_episodes": 14006, "number_of_timesteps": 4029175, "per_episode_reward": -49.31, "episode_reward_trend_value": 0.01430822668717495, "biggest_recent_change": 0.43871704972364967},
{"total_number_of_episodes": 14016, "number_of_timesteps": 4031461, "per_episode_reward": -49.19, "episode_reward_trend_value": 0.015170714858265358, "biggest_recent_change": 0.43871704972364967},
{"total_number_of_episodes": 14026, "number_of_timesteps": 4039052, "per_episode_reward": -49.12, "episode_reward_trend_value": 0.011045164316262736, "biggest_recent_change": 0.2354187144011206},
{"total_number_of_episodes": 14037, "number_of_timesteps": 4043771, "per_episode_reward": -49.02, "episode_reward_trend_value": 0.011936061893472624, "biggest_recent_change": 0.2354187144011206},
{"total_number_of_episodes": 14047, "number_of_timesteps": 4047167, "per_episode_reward": -48.92, "episode_reward_trend_value": 0.010395666811067312, "biggest_recent_change": 0.18610810715615145},
{"total_number_of_episodes": 14057, "number_of_timesteps": 4051595, "per_episode_reward": -48.76, "episode_reward_trend_value": 0.010919253497703982, "biggest_recent_change": 0.18610810715615145},
{"total_number_of_episodes": 14067, "number_of_timesteps": 4055731, "per_episode_reward": -48.62, "episode_reward_trend_value": 0.010920352807215355, "biggest_recent_change": 0.18610810715615145},
{"total_number_of_episodes": 14077, "number_of_timesteps": 4059335, "per_episode_reward": -48.55, "episode_reward_trend_value": 0.009646497427578124, "biggest_recent_change": 0.16468421815773837},
{"total_number_of_episodes": 14088, "number_of_timesteps": 4063312, "per_episode_reward": -48.45, "episode_reward_trend_value": 0.01045672722388002, "biggest_recent_change": 0.16468421815773837},
{"total_number_of_episodes": 14098, "number_of_timesteps": 4066983, "per_episode_reward": -48.36, "episode_reward_trend_value": 0.010572734143866017, "biggest_recent_change": 0.16468421815773837},
{"total_number_of_episodes": 14108, "number_of_timesteps": 4072377, "per_episode_reward": -48.08, "episode_reward_trend_value": 0.012309246021279956, "biggest_recent_change": 0.2809264764056465},
{"total_number_of_episodes": 14118, "number_of_timesteps": 4077060, "per_episode_reward": -47.89, "episode_reward_trend_value": 0.01363601915873092, "biggest_recent_change": 0.2809264764056465},
{"total_number_of_episodes": 14128, "number_of_timesteps": 4082328, "per_episode_reward": -47.79, "episode_reward_trend_value": 0.0137064793378396, "biggest_recent_change": 0.2809264764056465},
{"total_number_of_episodes": 14138, "number_of_timesteps": 4087957, "per_episode_reward": -47.66, "episode_reward_trend_value": 0.014006021487727022, "biggest_recent_change": 0.2809264764056465},
{"total_number_of_episodes": 14148, "number_of_timesteps": 4094744, "per_episode_reward": -47.52, "episode_reward_trend_value": 0.013696798605434898, "biggest_recent_change": 0.2809264764056465},
{"total_number_of_episodes": 14158, "number_of_timesteps": 4099387, "per_episode_reward": -47.4, "episode_reward_trend_value": 0.013582867259337661, "biggest_recent_change": 0.2809264764056465},
{"total_number_of_episodes": 14168, "number_of_timesteps": 4105197, "per_episode_reward": -47.19, "episode_reward_trend_value": 0.01514126511291257, "biggest_recent_change": 0.2809264764056465},
{"total_number_of_episodes": 14178, "number_of_timesteps": 4110798, "per_episode_reward": -46.86, "episode_reward_trend_value": 0.017598180537291737, "biggest_recent_change": 0.32826723143965353},

{"total_number_of_episodes": 14188, "number_of_timesteps": 4116415, "per_episode_reward": -46.75, "episode_reward_trend_value": 0.01782343790810417, "biggest_recent_change": 0.32826723143965353},
{"total_number_of_episodes": 14198, "number_of_timesteps": 4120894, "per_episode_reward": -46.67, "episode_reward_trend_value": 0.01564756899135552, "biggest_recent_change": 0.32826723143965353},
{"total_number_of_episodes": 14208, "number_of_timesteps": 4125924, "per_episode_reward": -46.62, "episode_reward_trend_value": 0.014120514461611893, "biggest_recent_change": 0.32826723143965353},
{"total_number_of_episodes": 14218, "number_of_timesteps": 4132445, "per_episode_reward": -46.5, "episode_reward_trend_value": 0.01424422214932777, "biggest_recent_change": 0.32826723143965353},
{"total_number_of_episodes": 14228, "number_of_timesteps": 4135057, "per_episode_reward": -46.37, "episode_reward_trend_value": 0.01433079725015784, "biggest_recent_change": 0.32826723143965353},
{"total_number_of_episodes": 14238, "number_of_timesteps": 4139438, "per_episode_reward": -46.2, "episode_reward_trend_value": 0.014687012079253492, "biggest_recent_change": 0.32826723143965353},
{"total_number_of_episodes": 14248, "number_of_timesteps": 4146348, "per_episode_reward": -46.1, "episode_reward_trend_value": 0.014409173423658928, "biggest_recent_change": 0.32826723143965353},
{"total_number_of_episodes": 14258, "number_of_timesteps": 4153148, "per_episode_reward": -45.96, "episode_reward_trend_value": 0.01370726899382117, "biggest_recent_change": 0.32826723143965353},
{"total_number_of_episodes": 14268, "number_of_timesteps": 4156588, "per_episode_reward": -45.91, "episode_reward_trend_value": 0.010616560800822742, "biggest_recent_change": 0.1689134933700558},
{"total_number_of_episodes": 14278, "number_of_timesteps": 4162405, "per_episode_reward": -45.53, "episode_reward_trend_value": 0.013585500212408952, "biggest_recent_change": 0.3744248590914836},
{"total_number_of_episodes": 14288, "number_of_timesteps": 4164925, "per_episode_reward": -45.34, "episode_reward_trend_value": 0.014740074148643523, "biggest_recent_change": 0.3744248590914836},
{"total_number_of_episodes": 14298, "number_of_timesteps": 4168966, "per_episode_reward": -45.09, "episode_reward_trend_value": 0.016996266852301052, "biggest_recent_change": 0.3744248590914836},
{"total_number_of_episodes": 14308, "number_of_timesteps": 4171488, "per_episode_reward": -44.79, "episode_reward_trend_value": 0.01899564362560145, "biggest_recent_change": 0.3744248590914836},
{"total_number_of_episodes": 14318, "number_of_timesteps": 4174969, "per_episode_reward": -44.64, "episode_reward_trend_value": 0.019290691252913442, "biggest_recent_change": 0.3744248590914836},
{"total_number_of_episodes": 14328, "number_of_timesteps": 4178477, "per_episode_reward": -44.52, "episode_reward_trend_value": 0.018726063617707133, "biggest_recent_change": 0.3744248590914836},
{"total_number_of_episodes": 14338, "number_of_timesteps": 4183613, "per_episode_reward": -44.3, "episode_reward_trend_value": 0.019993850368510854, "biggest_recent_change": 0.3744248590914836},
{"total_number_of_episodes": 14348, "number_of_timesteps": 4192159, "per_episode_reward": -44.22, "episode_reward_trend_value": 0.01928575767589567, "biggest_recent_change": 0.3744248590914836},
{"total_number_of_episodes": 14358, "number_of_timesteps": 4196298, "per_episode_reward": -44.24, "episode_reward_trend_value": 0.01850226464728798, "biggest_recent_change": 0.3744248590914836},
{"total_number_of_episodes": 14368, "number_of_timesteps": 4199529, "per_episode_reward": -44.17, "episode_reward_trend_value": 0.015155356671024755, "biggest_recent_change": 0.29628386093076386},
{"total_number_of_episodes": 14378, "number_of_timesteps": 4203294, "per_episode_reward": -44.08, "episode_reward_trend_value": 0.014024871505709375, "biggest_recent_change": 0.29628386093076386},
{"total_number_of_episodes": 14388, "number_of_timesteps": 4210101, "per_episode_reward": -44.0, "episode_reward_trend_value": 0.012081273738615374, "biggest_recent_change": 0.29628386093076386},
{"total_number_of_episodes": 14398, "number_of_timesteps": 4214111, "per_episode_reward": -43.87, "episode_reward_trend_value": 0.010249993774944165, "biggest_recent_change": 0.21244433861437528},
{"total_number_of_episodes": 14408, "number_of_timesteps": 4220922, "per_episode_reward": -43.84, "episode_reward_trend_value": 0.008866995239435798, "biggest_recent_change": 0.21244433861437528},
{"total_number_of_episodes": 14418, "number_of_timesteps": 4226676, "per_episode_reward": -43.69, "episode_reward_trend_value": 0.009151981543686027, "biggest_recent_change": 0.21244433861437528},
{"total_number_of_episodes": 14428, "number_of_timesteps": 4231100, "per_episode_reward": -43.53, "episode_reward_trend_value": 0.00863355390901922, "biggest_recent_change": 0.16578585149436265},
{"total_number_of_episodes": 14438, "number_of_timesteps": 4234819, "per_episode_reward": -43.42, "episode_reward_trend_value": 0.008919924387551327, "biggest_recent_change": 0.16578585149436265},
{"total_number_of_episodes": 14448, "number_of_timesteps": 4240752, "per_episode_reward": -43.33, "episode_reward_trend_value": 0.010062323948933265, "biggest_recent_change": 0.16578585149436265},
{"total_number_of_episodes": 14458, "number_of_timesteps": 4246867, "per_episode_reward": -43.2, "episode_reward_trend_value": 0.010796631647175935, "biggest_recent_change": 0.16578585149436265},
{"total_number_of_episodes": 14468, "number_of_timesteps": 4251816, "per_episode_reward": -43.09, "episode_reward_trend_value": 0.01101501276121234, "biggest_recent_change": 0.16578585149436265},
{"total_number_of_episodes": 14478, "number_of_timesteps": 4256601, "per_episode_reward": -42.97, "episode_reward_trend_value": 0.011442235144761052, "biggest_recent_change": 0.16578585149436265},
{"total_number_of_episodes": 14488, "number_of_timesteps": 4261774, "per_episode_reward": -42.93, "episode_reward_trend_value": 0.010485565229537978, "biggest_recent_change": 0.16578585149436265},
{"total_number_of_episodes": 14498, "number_of_timesteps": 4267476, "per_episode_reward": -42.83, "episode_reward_trend_value": 0.011164599752774822, "biggest_recent_change": 0.16578585149436265},
{"total_number_of_episodes": 14508, "number_of_timesteps": 4271483, "per_episode_reward": -42.7, "episode_reward_trend_value": 0.011065414390220003, "biggest_recent_change": 0.16578585149436265},
{"total_number_of_episodes": 14518, "number_of_timesteps": 4277641, "per_episode_reward": -42.58, "episode_reward_trend_value": 0.010576173461409629, "biggest_recent_change": 0.13929083406963372},
{"total_number_of_episodes": 14528, "number_of_timesteps": 4283500, "per_episode_reward": -42.51, "episode_reward_trend_value": 0.010057806849159572, "biggest_recent_change": 0.13929083406963372},
{"total_number_of_episodes": 14538, "number_of_timesteps": 4291237, "per_episode_reward": -42.51, "episode_reward_trend_value": 0.00915832737987535, "biggest_recent_change": 0.13929083406963372},
{"total_number_of_episodes": 14548, "number_of_timesteps": 4295134, "per_episode_reward": -42.42, "episode_reward_trend_value": 0.008565777780705257, "biggest_recent_change": 0.13481909095407474},
{"total_number_of_episodes": 14558, "number_of_timesteps": 4301398, "per_episode_reward": -42.36, "episode_reward_trend_value": 0.008113884879801563, "biggest_recent_change": 0.13481909095407474},
{"total_number_of_episodes": 14568, "number_of_timesteps": 4306838, "per_episode_reward": -42.14, "episode_reward_trend_value": 0.009286828063263404, "biggest_recent_change": 0.22154062095874139},
{"total_number_of_episodes": 14578, "number_of_timesteps": 4312277, "per_episode_reward": -42.09, "episode_reward_trend_value": 0.009339433848271265, "biggest_recent_change": 0.22154062095874139},
{"total_number_of_episodes": 14588, "number_of_timesteps": 4317418, "per_episode_reward": -41.96, "episode_reward_trend_value": 0.009642083833460349, "biggest_recent_change": 0.22154062095874139},
{"total_number_of_episodes": 14599, "number_of_timesteps": 4321459, "per_episode_reward": -41.84, "episode_reward_trend_value": 0.009558619446627465, "biggest_recent_change": 0.22154062095874139},
{"total_number_of_episodes": 14609, "number_of_timesteps": 4325586, "per_episode_reward": -41.79, "episode_reward_trend_value": 0.008702149674208057, "biggest_recent_change": 0.22154062095874139},
{"total_number_of_episodes": 14619, "number_of_timesteps": 4329055, "per_episode_reward": -41.74, "episode_reward_trend_value": 0.008548568941890504, "biggest_recent_change": 0.22154062095874139},
{"total_number_of_episodes": 14629, "number_of_timesteps": 4332651, "per_episode_reward": -41.62, "episode_reward_trend_value": 0.009898997787045102, "biggest_recent_change": 0.22154062095874139},
{"total_number_of_episodes": 14639, "number_of_timesteps": 4336541, "per_episode_reward": -41.58, "episode_reward_trend_value": 0.009365989029436072, "biggest_recent_change": 0.22154062095874139},
{"total_number_of_episodes": 14649, "number_of_timesteps": 4342864, "per_episode_reward": -41.45, "episode_reward_trend_value": 0.010061226766130619, "biggest_recent_change": 0.22154062095874139},
{"total_number_of_episodes": 14659, "number_of_timesteps": 4349503, "per_episode_reward": -41.28, "episode_reward_trend_value": 0.009482974878312848, "biggest_recent_change": 0.16949795105514198},
{"total_number_of_episodes": 14669, "number_of_timesteps": 4356828, "per_episode_reward": -41.1, "episode_reward_trend_value": 0.01091678348108071, "biggest_recent_change": 0.17914566673009347},
{"total_number_of_episodes": 14679, "number_of_timesteps": 4362642, "per_episode_reward": -41.05, "episode_reward_trend_value": 0.01020613261619619, "biggest_recent_change": 0.17914566673009347},
{"total_number_of_episodes": 14689, "number_of_timesteps": 4366959, "per_episode_reward": -40.98, "episode_reward_trend_value": 0.009478453694933758, "biggest_recent_change": 0.17914566673009347},
{"total_number_of_episodes": 14699, "number_of_timesteps": 4371234, "per_episode_reward": -40.77, "episode_reward_trend_value": 0.011316181648705816, "biggest_recent_change": 0.2100674042231674},
{"total_number_of_episodes": 14709, "number_of_timesteps": 4374002, "per_episode_reward": -40.69, "episode_reward_trend_value": 0.011650288716935128, "biggest_recent_change": 0.2100674042231674},

{"total_number_of_episodes": 14719, "number_of_timesteps": 4376451, "per_episode_reward": -40.65, "episode_reward_trend_value": 0.010790412126158739, "biggest_recent_change": 0.2100674042231674},
{"total_number_of_episodes": 14730, "number_of_timesteps": 4380546, "per_episode_reward": -40.54, "episode_reward_trend_value": 0.01153949151814836, "biggest_recent_change": 0.2100674042231674},
{"total_number_of_episodes": 14740, "number_of_timesteps": 4383505, "per_episode_reward": -40.32, "episode_reward_trend_value": 0.01262725250252138, "biggest_recent_change": 0.22672008735901983},
{"total_number_of_episodes": 14750, "number_of_timesteps": 4389012, "per_episode_reward": -40.27, "episode_reward_trend_value": 0.011251171625341921, "biggest_recent_change": 0.22672008735901983},
{"total_number_of_episodes": 14760, "number_of_timesteps": 4394298, "per_episode_reward": -40.18, "episode_reward_trend_value": 0.01026009627131575, "biggest_recent_change": 0.22672008735901983},
{"total_number_of_episodes": 14770, "number_of_timesteps": 4401092, "per_episode_reward": -40.12, "episode_reward_trend_value": 0.010262297366873223, "biggest_recent_change": 0.22672008735901983},
{"total_number_of_episodes": 14781, "number_of_timesteps": 4405515, "per_episode_reward": -40.1, "episode_reward_trend_value": 0.009866125527340192, "biggest_recent_change": 0.22672008735901983},

{"total_number_of_episodes": 14791, "number_of_timesteps": 4412051, "per_episode_reward": -40.01, "episode_reward_trend_value": 0.008455062860348524, "biggest_recent_change": 0.22672008735901983},
{"total_number_of_episodes": 14801, "number_of_timesteps": 4418553, "per_episode_reward": -39.93, "episode_reward_trend_value": 0.00845021550483196, "biggest_recent_change": 0.22672008735901983},
{"total_number_of_episodes": 14811, "number_of_timesteps": 4422335, "per_episode_reward": -39.72, "episode_reward_trend_value": 0.010281200922944895, "biggest_recent_change": 0.22672008735901983},
{"total_number_of_episodes": 14822, "number_of_timesteps": 4428369, "per_episode_reward": -39.65, "episode_reward_trend_value": 0.009871411807192329, "biggest_recent_change": 0.22672008735901983},
{"total_number_of_episodes": 14832, "number_of_timesteps": 4433989, "per_episode_reward": -39.56, "episode_reward_trend_value": 0.008426175423048538, "biggest_recent_change": 0.21039032030810034},
{"total_number_of_episodes": 14842, "number_of_timesteps": 4437154, "per_episode_reward": -39.47, "episode_reward_trend_value": 0.008931838711681274, "biggest_recent_change": 0.21039032030810034},
{"total_number_of_episodes": 14852, "number_of_timesteps": 4440678, "per_episode_reward": -39.39, "episode_reward_trend_value": 0.00880096452049391, "biggest_recent_change": 0.21039032030810034},
{"total_number_of_episodes": 14862, "number_of_timesteps": 4443779, "per_episode_reward": -39.17, "episode_reward_trend_value": 0.010600056995551436, "biggest_recent_change": 0.22012757708561992},
{"total_number_of_episodes": 14872, "number_of_timesteps": 4446553, "per_episode_reward": -39.03, "episode_reward_trend_value": 0.01189785941613582, "biggest_recent_change": 0.22012757708561992},
{"total_number_of_episodes": 14882, "number_of_timesteps": 4450251, "per_episode_reward": -38.99, "episode_reward_trend_value": 0.011417174640800137, "biggest_recent_change": 0.22012757708561992},
{"total_number_of_episodes": 14892, "number_of_timesteps": 4455557, "per_episode_reward": -38.75, "episode_reward_trend_value": 0.01313243967834915, "biggest_recent_change": 0.23412249837014087},
{"total_number_of_episodes": 14902, "number_of_timesteps": 4459992, "per_episode_reward": -38.63, "episode_reward_trend_value": 0.012104123957257053, "biggest_recent_change": 0.23412249837014087},
{"total_number_of_episodes": 14912, "number_of_timesteps": 4461925, "per_episode_reward": -38.53, "episode_reward_trend_value": 0.012539218324624337, "biggest_recent_change": 0.23412249837014087},
{"total_number_of_episodes": 14922, "number_of_timesteps": 4465317, "per_episode_reward": -38.44, "episode_reward_trend_value": 0.012465481282700431, "biggest_recent_change": 0.23412249837014087},
{"total_number_of_episodes": 14932, "number_of_timesteps": 4466819, "per_episode_reward": -38.4, "episode_reward_trend_value": 0.011877016934132298, "biggest_recent_change": 0.23412249837014087},
{"total_number_of_episodes": 14943, "number_of_timesteps": 4471670, "per_episode_reward": -38.33, "episode_reward_trend_value": 0.011795422782661862, "biggest_recent_change": 0.23412249837014087},
{"total_number_of_episodes": 14953, "number_of_timesteps": 4477065, "per_episode_reward": -38.26, "episode_reward_trend_value": 0.010143628442759775, "biggest_recent_change": 0.23412249837014087},
{"total_number_of_episodes": 14963, "number_of_timesteps": 4482782, "per_episode_reward": -38.07, "episode_reward_trend_value": 0.01057862683092452, "biggest_recent_change": 0.23412249837014087},
{"total_number_of_episodes": 14974, "number_of_timesteps": 4486231, "per_episode_reward": -38.05, "episode_reward_trend_value": 0.010395831421863575, "biggest_recent_change": 0.23412249837014087},
{"total_number_of_episodes": 14984, "number_of_timesteps": 4489338, "per_episode_reward": -37.86, "episode_reward_trend_value": 0.009910319414264516, "biggest_recent_change": 0.1904264176862256},
{"total_number_of_episodes": 14994, "number_of_timesteps": 4494091, "per_episode_reward": -37.82, "episode_reward_trend_value": 0.009063829268245864, "biggest_recent_change": 0.1904264176862256},
{"total_number_of_episodes": 15004, "number_of_timesteps": 4498096, "per_episode_reward": -37.68, "episode_reward_trend_value": 0.009415491273973705, "biggest_recent_change": 0.1904264176862256},
{"total_number_of_episodes": 15014, "number_of_timesteps": 4502944, "per_episode_reward": -37.66, "episode_reward_trend_value": 0.008596755181757093, "biggest_recent_change": 0.1904264176862256},
{"total_number_of_episodes": 15024, "number_of_timesteps": 4508620, "per_episode_reward": -37.56, "episode_reward_trend_value": 0.00933862101599077, "biggest_recent_change": 0.1904264176862256},
{"total_number_of_episodes": 15034, "number_of_timesteps": 4515346, "per_episode_reward": -37.5, "episode_reward_trend_value": 0.00922442430369917, "biggest_recent_change": 0.1904264176862256},
{"total_number_of_episodes": 15044, "number_of_timesteps": 4521695, "per_episode_reward": -37.52, "episode_reward_trend_value": 0.00822754381484327, "biggest_recent_change": 0.1904264176862256},
{"total_number_of_episodes": 15054, "number_of_timesteps": 4528901, "per_episode_reward": -37.38, "episode_reward_trend_value": 0.0076664969476999386, "biggest_recent_change": 0.1904264176862256},
{"total_number_of_episodes": 15064, "number_of_timesteps": 4537233, "per_episode_reward": -37.39, "episode_reward_trend_value": 0.007380581708172763, "biggest_recent_change": 0.1904264176862256},
{"total_number_of_episodes": 15076, "number_of_timesteps": 4541864, "per_episode_reward": -37.22, "episode_reward_trend_value": 0.007056546076391691, "biggest_recent_change": 0.1612632108259291},
{"total_number_of_episodes": 15086, "number_of_timesteps": 4547893, "per_episode_reward": -37.18, "episode_reward_trend_value": 0.007042346951263628, "biggest_recent_change": 0.1612632108259291},
{"total_number_of_episodes": 15096, "number_of_timesteps": 4555906, "per_episode_reward": -37.11, "episode_reward_trend_value": 0.006316556581865898, "biggest_recent_change": 0.1612632108259291},
{"total_number_of_episodes": 15106, "number_of_timesteps": 4562635, "per_episode_reward": -37.08, "episode_reward_trend_value": 0.006470208486292724, "biggest_recent_change": 0.1612632108259291},
{"total_number_of_episodes": 15116, "number_of_timesteps": 4568987, "per_episode_reward": -37.07, "episode_reward_trend_value": 0.005406955847818216, "biggest_recent_change": 0.1612632108259291},
{"total_number_of_episodes": 15126, "number_of_timesteps": 4576323, "per_episode_reward": -37.03, "episode_reward_trend_value": 0.005190054086912789, "biggest_recent_change": 0.1612632108259291},
{"total_number_of_episodes": 15136, "number_of_timesteps": 4583531, "per_episode_reward": -36.93, "episode_reward_trend_value": 0.006515350229492928, "biggest_recent_change": 0.1612632108259291},
{"total_number_of_episodes": 15147, "number_of_timesteps": 4589501, "per_episode_reward": -36.85, "episode_reward_trend_value": 0.0059123583197363576, "biggest_recent_change": 0.1612632108259291},
{"total_number_of_episodes": 15157, "number_of_timesteps": 4593782, "per_episode_reward": -36.82, "episode_reward_trend_value": 0.006255513034735177, "biggest_recent_change": 0.1612632108259291},
{"total_number_of_episodes": 15168, "number_of_timesteps": 4600822, "per_episode_reward": -36.79, "episode_reward_trend_value": 0.004801547036966901, "biggest_recent_change": 0.10102349532961341},
{"total_number_of_episodes": 15178, "number_of_timesteps": 4607163, "per_episode_reward": -36.68, "episode_reward_trend_value": 0.005632375649217951, "biggest_recent_change": 0.11515444610920156},
{"total_number_of_episodes": 15188, "number_of_timesteps": 4613717, "per_episode_reward": -36.59, "episode_reward_trend_value": 0.005762532659704394, "biggest_recent_change": 0.11515444610920156},
{"total_number_of_episodes": 15198, "number_of_timesteps": 4621269, "per_episode_reward": -36.57, "episode_reward_trend_value": 0.00570487644681279, "biggest_recent_change": 0.11515444610920156},
{"total_number_of_episodes": 15208, "number_of_timesteps": 4629285, "per_episode_reward": -36.56, "episode_reward_trend_value": 0.00570651536531233, "biggest_recent_change": 0.11515444610920156},
{"total_number_of_episodes": 15218, "number_of_timesteps": 4638491, "per_episode_reward": -36.56, "episode_reward_trend_value": 0.0052435109063754875, "biggest_recent_change": 0.11515444610920156},
{"total_number_of_episodes": 15228, "number_of_timesteps": 4646738, "per_episode_reward": -36.41, "episode_reward_trend_value": 0.005819741543904891, "biggest_recent_change": 0.1528842527072598},
{"total_number_of_episodes": 15238, "number_of_timesteps": 4652346, "per_episode_reward": -36.33, "episode_reward_trend_value": 0.005768644033303616, "biggest_recent_change": 0.1528842527072598},
{"total_number_of_episodes": 15248, "number_of_timesteps": 4657014, "per_episode_reward": -36.28, "episode_reward_trend_value": 0.006042806682892395, "biggest_recent_change": 0.1528842527072598},
{"total_number_of_episodes": 15258, "number_of_timesteps": 4664071, "per_episode_reward": -36.23, "episode_reward_trend_value": 0.006284941100410574, "biggest_recent_change": 0.1528842527072598},
{"total_number_of_episodes": 15268, "number_of_timesteps": 4670147, "per_episode_reward": -36.12, "episode_reward_trend_value": 0.006152581864485364, "biggest_recent_change": 0.1528842527072598},
{"total_number_of_episodes": 15278, "number_of_timesteps": 4674877, "per_episode_reward": -36.05, "episode_reward_trend_value": 0.0060076003942105185, "biggest_recent_change": 0.1528842527072598},
{"total_number_of_episodes": 15288, "number_of_timesteps": 4681303, "per_episode_reward": -35.97, "episode_reward_trend_value": 0.00659185763874272, "biggest_recent_change": 0.1528842527072598},
{"total_number_of_episodes": 15298, "number_of_timesteps": 4686902, "per_episode_reward": -35.88, "episode_reward_trend_value": 0.00757942460220262, "biggest_recent_change": 0.1528842527072598},
{"total_number_of_episodes": 15308, "number_of_timesteps": 4695336, "per_episode_reward": -35.77, "episode_reward_trend_value": 0.00877228681600602, "biggest_recent_change": 0.1528842527072598},
{"total_number_of_episodes": 15318, "number_of_timesteps": 4703366, "per_episode_reward": -35.73, "episode_reward_trend_value": 0.007457004054466804, "biggest_recent_change": 0.10671506937879371},

{"total_number_of_episodes": 15328, "number_of_timesteps": 4707570, "per_episode_reward": -35.68, "episode_reward_trend_value": 0.007302208437202513, "biggest_recent_change": 0.10671506937879371},
{"total_number_of_episodes": 15338, "number_of_timesteps": 4713747, "per_episode_reward": -35.64, "episode_reward_trend_value": 0.007096998200996296, "biggest_recent_change": 0.10671506937879371},
{"total_number_of_episodes": 15348, "number_of_timesteps": 4721000, "per_episode_reward": -35.58, "episode_reward_trend_value": 0.0072425583897664115, "biggest_recent_change": 0.10671506937879371},
{"total_number_of_episodes": 15358, "number_of_timesteps": 4726698, "per_episode_reward": -35.32, "episode_reward_trend_value": 0.008967076771433666, "biggest_recent_change": 0.2584487692259856},
{"total_number_of_episodes": 15369, "number_of_timesteps": 4732213, "per_episode_reward": -35.16, "episode_reward_trend_value": 0.009856423395036432, "biggest_recent_change": 0.2584487692259856},
{"total_number_of_episodes": 15379, "number_of_timesteps": 4738492, "per_episode_reward": -35.02, "episode_reward_trend_value": 0.010562658337534319, "biggest_recent_change": 0.2584487692259856},
{"total_number_of_episodes": 15389, "number_of_timesteps": 4743777, "per_episode_reward": -35.0, "episode_reward_trend_value": 0.009776467927449694, "biggest_recent_change": 0.2584487692259856},
{"total_number_of_episodes": 15399, "number_of_timesteps": 4751403, "per_episode_reward": -34.91, "episode_reward_trend_value": 0.009495711905605869, "biggest_recent_change": 0.2584487692259856},
{"total_number_of_episodes": 15409, "number_of_timesteps": 4756740, "per_episode_reward": -34.82, "episode_reward_trend_value": 0.010158088334868944, "biggest_recent_change": 0.2584487692259856},
{"total_number_of_episodes": 15419, "number_of_timesteps": 4762874, "per_episode_reward": -34.73, "episode_reward_trend_value": 0.010547261008078124, "biggest_recent_change": 0.2584487692259856},
{"total_number_of_episodes": 15429, "number_of_timesteps": 4771663, "per_episode_reward": -34.62, "episode_reward_trend_value": 0.011322443380030241, "biggest_recent_change": 0.2584487692259856},
{"total_number_of_episodes": 15439, "number_of_timesteps": 4778253, "per_episode_reward": -34.57, "episode_reward_trend_value": 0.011139825453010527, "biggest_recent_change": 0.2584487692259856},
{"total_number_of_episodes": 15449, "number_of_timesteps": 4784072, "per_episode_reward": -34.56, "episode_reward_trend_value": 0.00836443763636549, "biggest_recent_change": 0.15272064189690582},
{"total_number_of_episodes": 15459, "number_of_timesteps": 4792324, "per_episode_reward": -34.5, "episode_reward_trend_value": 0.007359709837028244, "biggest_recent_change": 0.14111013978430975},
{"total_number_of_episodes": 15469, "number_of_timesteps": 4797996, "per_episode_reward": -34.43, "episode_reward_trend_value": 0.006538360503875633, "biggest_recent_change": 0.10448223107079002},
{"total_number_of_episodes": 15479, "number_of_timesteps": 4803768, "per_episode_reward": -34.4, "episode_reward_trend_value": 0.006588245590177087, "biggest_recent_change": 0.10448223107079002},
{"total_number_of_episodes": 15489, "number_of_timesteps": 4809794, "per_episode_reward": -34.41, "episode_reward_trend_value": 0.00560800855459094, "biggest_recent_change": 0.10448223107079002},
{"total_number_of_episodes": 15499, "number_of_timesteps": 4817118, "per_episode_reward": -34.39, "episode_reward_trend_value": 0.004811122092674936, "biggest_recent_change": 0.10448223107079002},

{"total_number_of_episodes": 15509, "number_of_timesteps": 4823520, "per_episode_reward": -34.36, "episode_reward_trend_value": 0.00410141953185372, "biggest_recent_change": 0.10448223107079002},
{"total_number_of_episodes": 15519, "number_of_timesteps": 4832269, "per_episode_reward": -34.3, "episode_reward_trend_value": 0.0035578699690193595, "biggest_recent_change": 0.06718869980057462},
{"total_number_of_episodes": 15529, "number_of_timesteps": 4838310, "per_episode_reward": -34.25, "episode_reward_trend_value": 0.0035878951960379075, "biggest_recent_change": 0.06718869980057462},
{"total_number_of_episodes": 15539, "number_of_timesteps": 4844737, "per_episode_reward": -34.09, "episode_reward_trend_value": 0.005300536884691572, "biggest_recent_change": 0.16280161770676216},
{"total_number_of_episodes": 15549, "number_of_timesteps": 4851457, "per_episode_reward": -33.9, "episode_reward_trend_value": 0.006679746289448553, "biggest_recent_change": 0.18642398638468194},
{"total_number_of_episodes": 15559, "number_of_timesteps": 4856391, "per_episode_reward": -33.82, "episode_reward_trend_value": 0.006792166488526005, "biggest_recent_change": 0.18642398638468194},
{"total_number_of_episodes": 15569, "number_of_timesteps": 4862645, "per_episode_reward": -33.7, "episode_reward_trend_value": 0.007849210830812187, "biggest_recent_change": 0.18642398638468194},
{"total_number_of_episodes": 15579, "number_of_timesteps": 4870472, "per_episode_reward": -33.66, "episode_reward_trend_value": 0.008340558114129948, "biggest_recent_change": 0.18642398638468194},
{"total_number_of_episodes": 15590, "number_of_timesteps": 4876539, "per_episode_reward": -33.62, "episode_reward_trend_value": 0.008548966230194724, "biggest_recent_change": 0.18642398638468194},
{"total_number_of_episodes": 15600, "number_of_timesteps": 4881157, "per_episode_reward": -33.57, "episode_reward_trend_value": 0.008706008620470287, "biggest_recent_change": 0.18642398638468194},
{"total_number_of_episodes": 15610, "number_of_timesteps": 4888254, "per_episode_reward": -33.53, "episode_reward_trend_value": 0.008558238995612772, "biggest_recent_change": 0.18642398638468194},
{"total_number_of_episodes": 15620, "number_of_timesteps": 4893556, "per_episode_reward": -33.37, "episode_reward_trend_value": 0.00976471613859502, "biggest_recent_change": 0.18642398638468194},
{"total_number_of_episodes": 15630, "number_of_timesteps": 4898938, "per_episode_reward": -33.29, "episode_reward_trend_value": 0.008894004613794554, "biggest_recent_change": 0.18642398638468194},
{"total_number_of_episodes": 15640, "number_of_timesteps": 4903558, "per_episode_reward": -33.17, "episode_reward_trend_value": 0.008100493781556552, "biggest_recent_change": 0.16014838546102794},
{"total_number_of_episodes": 15650, "number_of_timesteps": 4908728, "per_episode_reward": -33.12, "episode_reward_trend_value": 0.007835953574877961, "biggest_recent_change": 0.16014838546102794},
{"total_number_of_episodes": 15660, "number_of_timesteps": 4912603, "per_episode_reward": -33.1, "episode_reward_trend_value": 0.006658479685380787, "biggest_recent_change": 0.16014838546102794},
{"total_number_of_episodes": 15670, "number_of_timesteps": 4917278, "per_episode_reward": -33.04, "episode_reward_trend_value": 0.00683252863911466, "biggest_recent_change": 0.16014838546102794},
{"total_number_of_episodes": 15680, "number_of_timesteps": 4922595, "per_episode_reward": -33.02, "episode_reward_trend_value": 0.006598559195056373, "biggest_recent_change": 0.16014838546102794},
{"total_number_of_episodes": 15690, "number_of_timesteps": 4926142, "per_episode_reward": -32.98, "episode_reward_trend_value": 0.006595130663304695, "biggest_recent_change": 0.16014838546102794},
{"total_number_of_episodes": 15700, "number_of_timesteps": 4930639, "per_episode_reward": -32.93, "episode_reward_trend_value": 0.006703191108825814, "biggest_recent_change": 0.16014838546102794},
{"total_number_of_episodes": 15710, "number_of_timesteps": 4936008, "per_episode_reward": -32.9, "episode_reward_trend_value": 0.005281880143517902, "biggest_recent_change": 0.1150080114832619},
{"total_number_of_episodes": 15720, "number_of_timesteps": 4943297, "per_episode_reward": -32.79, "episode_reward_trend_value": 0.005551773039589531, "biggest_recent_change": 0.1150080114832619},
{"total_number_of_episodes": 15730, "number_of_timesteps": 4948129, "per_episode_reward": -32.59, "episode_reward_trend_value": 0.006407793777612388, "biggest_recent_change": 0.19204987790531902},
{"total_number_of_episodes": 15740, "number_of_timesteps": 4954866, "per_episode_reward": -32.51, "episode_reward_trend_value": 0.006799604669127194, "biggest_recent_change": 0.19204987790531902},
{"total_number_of_episodes": 15751, "number_of_timesteps": 4962730, "per_episode_reward": -32.46, "episode_reward_trend_value": 0.007121503605876553, "biggest_recent_change": 0.19204987790531902},
{"total_number_of_episodes": 15761, "number_of_timesteps": 4967162, "per_episode_reward": -32.4, "episode_reward_trend_value": 0.007143403298729506, "biggest_recent_change": 0.19204987790531902},
{"total_number_of_episodes": 15771, "number_of_timesteps": 4972575, "per_episode_reward": -32.33, "episode_reward_trend_value": 0.007730837569883261, "biggest_recent_change": 0.19204987790531902},
{"total_number_of_episodes": 15781, "number_of_timesteps": 4976542, "per_episode_reward": -32.25, "episode_reward_trend_value": 0.008060583037213576, "biggest_recent_change": 0.19204987790531902},
{"total_number_of_episodes": 15791, "number_of_timesteps": 4980440, "per_episode_reward": -32.2, "episode_reward_trend_value": 0.008108423555374836, "biggest_recent_change": 0.19204987790531902},
{"total_number_of_episodes": 15801, "number_of_timesteps": 4984981, "per_episode_reward": -32.16, "episode_reward_trend_value": 0.008180481722944994, "biggest_recent_change": 0.19204987790531902},
{"total_number_of_episodes": 15811, "number_of_timesteps": 4988209, "per_episode_reward": -32.08, "episode_reward_trend_value": 0.007833312871300218, "biggest_recent_change": 0.19204987790531902},
{"total_number_of_episodes": 15821, "number_of_timesteps": 4994747, "per_episode_reward": -32.03, "episode_reward_trend_value": 0.006313780172483125, "biggest_recent_change": 0.08876087935280452},
{"total_number_of_episodes": 15831, "number_of_timesteps": 4999644, "per_episode_reward": -31.89, "episode_reward_trend_value": 0.006806542362335142, "biggest_recent_change": 0.13310947643948623},
{"total_number_of_episodes": 15841, "number_of_timesteps": 5005657, "per_episode_reward": -31.71, "episode_reward_trend_value": 0.008329490020142277, "biggest_recent_change": 0.18723234883009},
{"total_number_of_episodes": 15851, "number_of_timesteps": 5010851, "per_episode_reward": -31.64, "episode_reward_trend_value": 0.00848737709311875, "biggest_recent_change": 0.18723234883009},
{"total_number_of_episodes": 15861, "number_of_timesteps": 5015466, "per_episode_reward": -31.56, "episode_reward_trend_value": 0.008505585115864791, "biggest_recent_change": 0.18723234883009},
{"total_number_of_episodes": 15871, "number_of_timesteps": 5019662, "per_episode_reward": -31.53, "episode_reward_trend_value": 0.008029794332408358, "biggest_recent_change": 0.18723234883009},
{"total_number_of_episodes": 15881, "number_of_timesteps": 5025821, "per_episode_reward": -31.34, "episode_reward_trend_value": 0.009579233596307822, "biggest_recent_change": 0.1957441246608873},
{"total_number_of_episodes": 15891, "number_of_timesteps": 5030781, "per_episode_reward": -31.34, "episode_reward_trend_value": 0.009117714390964416, "biggest_recent_change": 0.1957441246608873},
{"total_number_of_episodes": 15901, "number_of_timesteps": 5037913, "per_episode_reward": -31.3, "episode_reward_trend_value": 0.008734380990492358, "biggest_recent_change": 0.1957441246608873},
{"total_number_of_episodes": 15913, "number_of_timesteps": 5044940, "per_episode_reward": -31.24, "episode_reward_trend_value": 0.008723908161802562, "biggest_recent_change": 0.1957441246608873},
{"total_number_of_episodes": 15923, "number_of_timesteps": 5047325, "per_episode_reward": -31.16, "episode_reward_trend_value": 0.008130271211938161, "biggest_recent_change": 0.1957441246608873},
{"total_number_of_episodes": 15933, "number_of_timesteps": 5049970, "per_episode_reward": -31.12, "episode_reward_trend_value": 0.006520554081829823, "biggest_recent_change": 0.1957441246608873},
{"total_number_of_episodes": 15943, "number_of_timesteps": 5057807, "per_episode_reward": -31.09, "episode_reward_trend_value": 0.006047684915780099, "biggest_recent_change": 0.1957441246608873},
{"total_number_of_episodes": 15953, "number_of_timesteps": 5062367, "per_episode_reward": -31.04, "episode_reward_trend_value": 0.00582452944470858, "biggest_recent_change": 0.1957441246608873},
{"total_number_of_episodes": 15963, "number_of_timesteps": 5067611, "per_episode_reward": -30.95, "episode_reward_trend_value": 0.0064218368444133814, "biggest_recent_change": 0.1957441246608873},
{"total_number_of_episodes": 15973, "number_of_timesteps": 5073391, "per_episode_reward": -30.9, "episode_reward_trend_value": 0.00483946807471697, "biggest_recent_change": 0.08441007393020072},
{"total_number_of_episodes": 15983, "number_of_timesteps": 5081055, "per_episode_reward": -30.82, "episode_reward_trend_value": 0.005800585688053141, "biggest_recent_change": 0.08441007393020072},
{"total_number_of_episodes": 15993, "number_of_timesteps": 5090091, "per_episode_reward": -30.79, "episode_reward_trend_value": 0.0056349425856395165, "biggest_recent_change": 0.08441007393020072},
{"total_number_of_episodes": 16003, "number_of_timesteps": 5097822, "per_episode_reward": -30.53, "episode_reward_trend_value": 0.007897611085107552, "biggest_recent_change": 0.2579895453818217},
{"total_number_of_episodes": 16013, "number_of_timesteps": 5104921, "per_episode_reward": -30.44, "episode_reward_trend_value": 0.008058799127191246, "biggest_recent_change": 0.2579895453818217},
{"total_number_of_episodes": 16023, "number_of_timesteps": 5110353, "per_episode_reward": -30.4, "episode_reward_trend_value": 0.007949511259728502, "biggest_recent_change": 0.2579895453818217},
{"total_number_of_episodes": 16033, "number_of_timesteps": 5115758, "per_episode_reward": -30.23, "episode_reward_trend_value": 0.009597842641086984, "biggest_recent_change": 0.2579895453818217},
{"total_number_of_episodes": 16043, "number_of_timesteps": 5122456, "per_episode_reward": -30.24, "episode_reward_trend_value": 0.008841375580632437, "biggest_recent_change": 0.2579895453818217},
{"total_number_of_episodes": 16053, "number_of_timesteps": 5126423, "per_episode_reward": -30.18, "episode_reward_trend_value": 0.00856516486124003, "biggest_recent_change": 0.2579895453818217},
{"total_number_of_episodes": 16063, "number_of_timesteps": 5129427, "per_episode_reward": -30.05, "episode_reward_trend_value": 0.00944027592896184, "biggest_recent_change": 0.2579895453818217},
{"total_number_of_episodes": 16073, "number_of_timesteps": 5131273, "per_episode_reward": -29.96, "episode_reward_trend_value": 0.009525638063050144, "biggest_recent_change": 0.2579895453818217},
{"total_number_of_episodes": 16083, "number_of_timesteps": 5134399, "per_episode_reward": -29.86, "episode_reward_trend_value": 0.010282678177756249, "biggest_recent_change": 0.2579895453818217},
{"total_number_of_episodes": 16093, "number_of_timesteps": 5139283, "per_episode_reward": -29.82, "episode_reward_trend_value": 0.007933564906686088, "biggest_recent_change": 0.17508376384718005},
{"total_number_of_episodes": 16103, "number_of_timesteps": 5145134, "per_episode_reward": -29.77, "episode_reward_trend_value": 0.007413230306154578, "biggest_recent_change": 0.17508376384718005},
{"total_number_of_episodes": 16113, "number_of_timesteps": 5153630, "per_episode_reward": -29.71, "episode_reward_trend_value": 0.007663633939190994, "biggest_recent_change": 0.17508376384718005},
{"total_number_of_episodes": 16123, "number_of_timesteps": 5159604, "per_episode_reward": -29.58, "episode_reward_trend_value": 0.007207613379624394, "biggest_recent_change": 0.1340419134861861},

{"total_number_of_episodes": 16133, "number_of_timesteps": 5168159, "per_episode_reward": -29.5, "episode_reward_trend_value": 0.008214038373431303, "biggest_recent_change": 0.1340419134861861},
{"total_number_of_episodes": 16143, "number_of_timesteps": 5175975, "per_episode_reward": -29.46, "episode_reward_trend_value": 0.007992664986810796, "biggest_recent_change": 0.1340419134861861},
{"total_number_of_episodes": 16153, "number_of_timesteps": 5181705, "per_episode_reward": -29.39, "episode_reward_trend_value": 0.007293996738453777, "biggest_recent_change": 0.1340419134861861},
{"total_number_of_episodes": 16163, "number_of_timesteps": 5189338, "per_episode_reward": -29.33, "episode_reward_trend_value": 0.0070066712880951735, "biggest_recent_change": 0.1340419134861861},
{"total_number_of_episodes": 16173, "number_of_timesteps": 5197192, "per_episode_reward": -29.25, "episode_reward_trend_value": 0.0067941123951784105, "biggest_recent_change": 0.1340419134861861},
{"total_number_of_episodes": 16183, "number_of_timesteps": 5206043, "per_episode_reward": -29.27, "episode_reward_trend_value": 0.006087108584078709, "biggest_recent_change": 0.1340419134861861},
{"total_number_of_episodes": 16193, "number_of_timesteps": 5214252, "per_episode_reward": -29.23, "episode_reward_trend_value": 0.005953092529517789, "biggest_recent_change": 0.1340419134861861},
{"total_number_of_episodes": 16203, "number_of_timesteps": 5222996, "per_episode_reward": -29.19, "episode_reward_trend_value": 0.005806257156911817, "biggest_recent_change": 0.1340419134861861},
{"total_number_of_episodes": 16213, "number_of_timesteps": 5231273, "per_episode_reward": -29.15, "episode_reward_trend_value": 0.004731608561963993, "biggest_recent_change": 0.07707816917446664},
{"total_number_of_episodes": 16223, "number_of_timesteps": 5236154, "per_episode_reward": -29.03, "episode_reward_trend_value": 0.005235752634639271, "biggest_recent_change": 0.12239537630758335},
{"total_number_of_episodes": 16233, "number_of_timesteps": 5243632, "per_episode_reward": -28.99, "episode_reward_trend_value": 0.005277541966249267, "biggest_recent_change": 0.12239537630758335},
{"total_number_of_episodes": 16243, "number_of_timesteps": 5248967, "per_episode_reward": -28.96, "episode_reward_trend_value": 0.004793801323135503, "biggest_recent_change": 0.12239537630758335},
{"total_number_of_episodes": 16253, "number_of_timesteps": 5252888, "per_episode_reward": -28.94, "episode_reward_trend_value": 0.004355207134602463, "biggest_recent_change": 0.12239537630758335},
{"total_number_of_episodes": 16263, "number_of_timesteps": 5260619, "per_episode_reward": -28.87, "episode_reward_trend_value": 0.004200643403821047, "biggest_recent_change": 0.12239537630758335},
{"total_number_of_episodes": 16273, "number_of_timesteps": 5265555, "per_episode_reward": -28.7, "episode_reward_trend_value": 0.006356619614263319, "biggest_recent_change": 0.17697686692633852},
{"total_number_of_episodes": 16283, "number_of_timesteps": 5272807, "per_episode_reward": -28.64, "episode_reward_trend_value": 0.006584065936299963, "biggest_recent_change": 0.17697686692633852},
{"total_number_of_episodes": 16293, "number_of_timesteps": 5280099, "per_episode_reward": -28.58, "episode_reward_trend_value": 0.006783139032508284, "biggest_recent_change": 0.17697686692633852},
{"total_number_of_episodes": 16304, "number_of_timesteps": 5288095, "per_episode_reward": -28.53, "episode_reward_trend_value": 0.006935044105115454, "biggest_recent_change": 0.17697686692633852},
{"total_number_of_episodes": 16314, "number_of_timesteps": 5293158, "per_episode_reward": -28.51, "episode_reward_trend_value": 0.005781674218396185, "biggest_recent_change": 0.17697686692633852},
{"total_number_of_episodes": 16324, "number_of_timesteps": 5300085, "per_episode_reward": -28.42, "episode_reward_trend_value": 0.006299158629101677, "biggest_recent_change": 0.17697686692633852},
{"total_number_of_episodes": 16334, "number_of_timesteps": 5307795, "per_episode_reward": -28.32, "episode_reward_trend_value": 0.007091849165433059, "biggest_recent_change": 0.17697686692633852},
{"total_number_of_episodes": 16344, "number_of_timesteps": 5314178, "per_episode_reward": -28.23, "episode_reward_trend_value": 0.007896197576182156, "biggest_recent_change": 0.17697686692633852},
{"total_number_of_episodes": 16354, "number_of_timesteps": 5323599, "per_episode_reward": -28.17, "episode_reward_trend_value": 0.007818265902999184, "biggest_recent_change": 0.17697686692633852},
{"total_number_of_episodes": 16364, "number_of_timesteps": 5329088, "per_episode_reward": -28.06, "episode_reward_trend_value": 0.007104204134682017, "biggest_recent_change": 0.11271130777779348},
{"total_number_of_episodes": 16374, "number_of_timesteps": 5334979, "per_episode_reward": -28.03, "episode_reward_trend_value": 0.006796880845771211, "biggest_recent_change": 0.11271130777779348},
{"total_number_of_episodes": 16384, "number_of_timesteps": 5342327, "per_episode_reward": -28.03, "episode_reward_trend_value": 0.006132950413140787, "biggest_recent_change": 0.11271130777779348},
{"total_number_of_episodes": 16394, "number_of_timesteps": 5348373, "per_episode_reward": -27.87, "episode_reward_trend_value": 0.007316906875826372, "biggest_recent_change": 0.1575510781172298},
{"total_number_of_episodes": 16404, "number_of_timesteps": 5351904, "per_episode_reward": -27.81, "episode_reward_trend_value": 0.007787131435360688, "biggest_recent_change": 0.1575510781172298},
{"total_number_of_episodes": 16414, "number_of_timesteps": 5357246, "per_episode_reward": -27.76, "episode_reward_trend_value": 0.007348913110203309, "biggest_recent_change": 0.1575510781172298},
{"total_number_of_episodes": 16424, "number_of_timesteps": 5363427, "per_episode_reward": -27.68, "episode_reward_trend_value": 0.007189898755240993, "biggest_recent_change": 0.1575510781172298},
{"total_number_of_episodes": 16434, "number_of_timesteps": 5368386, "per_episode_reward": -27.63, "episode_reward_trend_value": 0.006660927900225151, "biggest_recent_change": 0.1575510781172298},
{"total_number_of_episodes": 16444, "number_of_timesteps": 5374283, "per_episode_reward": -27.58, "episode_reward_trend_value": 0.00650292441523877, "biggest_recent_change": 0.1575510781172298},
{"total_number_of_episodes": 16454, "number_of_timesteps": 5382185, "per_episode_reward": -27.54, "episode_reward_trend_value": 0.0056978930565100205, "biggest_recent_change": 0.1575510781172298},
{"total_number_of_episodes": 16464, "number_of_timesteps": 5390141, "per_episode_reward": -27.48, "episode_reward_trend_value": 0.006061011986795725, "biggest_recent_change": 0.1575510781172298},
{"total_number_of_episodes": 16474, "number_of_timesteps": 5395394, "per_episode_reward": -27.41, "episode_reward_trend_value": 0.006823745698347257, "biggest_recent_change": 0.1575510781172298},
{"total_number_of_episodes": 16484, "number_of_timesteps": 5403647, "per_episode_reward": -27.35, "episode_reward_trend_value": 0.005840762069346539, "biggest_recent_change": 0.08270498757401867},
{"total_number_of_episodes": 16494, "number_of_timesteps": 5410762, "per_episode_reward": -27.32, "episode_reward_trend_value": 0.00548207653870689, "biggest_recent_change": 0.08270498757401867},
{"total_number_of_episodes": 16504, "number_of_timesteps": 5416676, "per_episode_reward": -27.23, "episode_reward_trend_value": 0.005862726033223195, "biggest_recent_change": 0.08478094643973577},
{"total_number_of_episodes": 16514, "number_of_timesteps": 5420090, "per_episode_reward": -27.1, "episode_reward_trend_value": 0.006364192663542667, "biggest_recent_change": 0.12783698430277113},
{"total_number_of_episodes": 16524, "number_of_timesteps": 5425166, "per_episode_reward": -27.02, "episode_reward_trend_value": 0.006706307432452066, "biggest_recent_change": 0.12783698430277113},
{"total_number_of_episodes": 16534, "number_of_timesteps": 5430658, "per_episode_reward": -26.91, "episode_reward_trend_value": 0.007475748611590542, "biggest_recent_change": 0.12783698430277113},
{"total_number_of_episodes": 16544, "number_of_timesteps": 5435913, "per_episode_reward": -26.91, "episode_reward_trend_value": 0.0070750365835609424, "biggest_recent_change": 0.12783698430277113},
{"total_number_of_episodes": 16555, "number_of_timesteps": 5441451, "per_episode_reward": -26.85, "episode_reward_trend_value": 0.007094902086041246, "biggest_recent_change": 0.12783698430277113},
{"total_number_of_episodes": 16565, "number_of_timesteps": 5446079, "per_episode_reward": -26.81, "episode_reward_trend_value": 0.006678290920669107, "biggest_recent_change": 0.12783698430277113},
{"total_number_of_episodes": 16575, "number_of_timesteps": 5451371, "per_episode_reward": -26.77, "episode_reward_trend_value": 0.006350338239406462, "biggest_recent_change": 0.12783698430277113},
{"total_number_of_episodes": 16585, "number_of_timesteps": 5456238, "per_episode_reward": -26.75, "episode_reward_trend_value": 0.006341393013784389, "biggest_recent_change": 0.12783698430277113},
{"total_number_of_episodes": 16595, "number_of_timesteps": 5462425, "per_episode_reward": -26.71, "episode_reward_trend_value": 0.005752261496153347, "biggest_recent_change": 0.12783698430277113},
{"total_number_of_episodes": 16605, "number_of_timesteps": 5467904, "per_episode_reward": -26.67, "episode_reward_trend_value": 0.004788008995578056, "biggest_recent_change": 0.11118297529136001},
{"total_number_of_episodes": 16615, "number_of_timesteps": 5472181, "per_episode_reward": -26.65, "episode_reward_trend_value": 0.004198294029758484, "biggest_recent_change": 0.11118297529136001},
{"total_number_of_episodes": 16626, "number_of_timesteps": 5479886, "per_episode_reward": -26.6, "episode_reward_trend_value": 0.0034383584902893775, "biggest_recent_change": 0.06257718771117027},
{"total_number_of_episodes": 16636, "number_of_timesteps": 5483880, "per_episode_reward": -26.48, "episode_reward_trend_value": 0.004728947729517567, "biggest_recent_change": 0.12034743450007923},
{"total_number_of_episodes": 16646, "number_of_timesteps": 5489861, "per_episode_reward": -26.42, "episode_reward_trend_value": 0.004676171728241366, "biggest_recent_change": 0.12034743450007923},
{"total_number_of_episodes": 16656, "number_of_timesteps": 5495137, "per_episode_reward": -26.35, "episode_reward_trend_value": 0.005191706237983004, "biggest_recent_change": 0.12034743450007923},
{"total_number_of_episodes": 16666, "number_of_timesteps": 5500784, "per_episode_reward": -26.19, "episode_reward_trend_value": 0.006469848006317294, "biggest_recent_change": 0.1545995693436133},
{"total_number_of_episodes": 16676, "number_of_timesteps": 5506043, "per_episode_reward": -26.15, "episode_reward_trend_value": 0.006678325405994043, "biggest_recent_change": 0.1545995693436133},
{"total_number_of_episodes": 16686, "number_of_timesteps": 5509514, "per_episode_reward": -26.1, "episode_reward_trend_value": 0.0068847377180864, "biggest_recent_change": 0.1545995693436133},
{"total_number_of_episodes": 16696, "number_of_timesteps": 5519089, "per_episode_reward": -26.04, "episode_reward_trend_value": 0.007031706106738314, "biggest_recent_change": 0.1545995693436133},
{"total_number_of_episodes": 16706, "number_of_timesteps": 5524400, "per_episode_reward": -26.0, "episode_reward_trend_value": 0.0072060250030189996, "biggest_recent_change": 0.1545995693436133},
{"total_number_of_episodes": 16716, "number_of_timesteps": 5530014, "per_episode_reward": -25.97, "episode_reward_trend_value": 0.007027620071910097, "biggest_recent_change": 0.1545995693436133},
{"total_number_of_episodes": 16726, "number_of_timesteps": 5534494, "per_episode_reward": -25.95, "episode_reward_trend_value": 0.005952098724511896, "biggest_recent_change": 0.1545995693436133},
{"total_number_of_episodes": 16736, "number_of_timesteps": 5540792, "per_episode_reward": -25.88, "episode_reward_trend_value": 0.006059608144603641, "biggest_recent_change": 0.1545995693436133},
{"total_number_of_episodes": 16746, "number_of_timesteps": 5546864, "per_episode_reward": -25.83, "episode_reward_trend_value": 0.005721497612557513, "biggest_recent_change": 0.1545995693436133},
{"total_number_of_episodes": 16756, "number_of_timesteps": 5552589, "per_episode_reward": -25.75, "episode_reward_trend_value": 0.004936297218069146, "biggest_recent_change": 0.08393153383966023},
{"total_number_of_episodes": 16767, "number_of_timesteps": 5558309, "per_episode_reward": -25.68, "episode_reward_trend_value": 0.00516665424373757, "biggest_recent_change": 0.08393153383966023},
{"total_number_of_episodes": 16777, "number_of_timesteps": 5562822, "per_episode_reward": -25.58, "episode_reward_trend_value": 0.005723701611697665, "biggest_recent_change": 0.10047048105766265},
{"total_number_of_episodes": 16787, "number_of_timesteps": 5569976, "per_episode_reward": -25.53, "episode_reward_trend_value": 0.005645065330543907, "biggest_recent_change": 0.10047048105766265},
{"total_number_of_episodes": 16797, "number_of_timesteps": 5574926, "per_episode_reward": -25.49, "episode_reward_trend_value": 0.005635627034033379, "biggest_recent_change": 0.10047048105766265},
{"total_number_of_episodes": 16807, "number_of_timesteps": 5581299, "per_episode_reward": -25.39, "episode_reward_trend_value": 0.006473995973713069, "biggest_recent_change": 0.10218553751051118},
{"total_number_of_episodes": 16817, "number_of_timesteps": 5585182, "per_episode_reward": -25.31, "episode_reward_trend_value": 0.007087661738048033, "biggest_recent_change": 0.10218553751051118},
{"total_number_of_episodes": 16827, "number_of_timesteps": 5589029, "per_episode_reward": -25.26, "episode_reward_trend_value": 0.006908243828428853, "biggest_recent_change": 0.10218553751051118},
{"total_number_of_episodes": 16837, "number_of_timesteps": 5595619, "per_episode_reward": -25.23, "episode_reward_trend_value": 0.006698756097738468, "biggest_recent_change": 0.10218553751051118},
{"total_number_of_episodes": 16847, "number_of_timesteps": 5603397, "per_episode_reward": -25.18, "episode_reward_trend_value": 0.006274984471955847, "biggest_recent_change": 0.10218553751051118},
{"total_number_of_episodes": 16857, "number_of_timesteps": 5609156, "per_episode_reward": -25.19, "episode_reward_trend_value": 0.005434357829960016, "biggest_recent_change": 0.10218553751051118},
{"total_number_of_episodes": 16868, "number_of_timesteps": 5616315, "per_episode_reward": -25.09, "episode_reward_trend_value": 0.005413282458370756, "biggest_recent_change": 0.10218553751051118},
{"total_number_of_episodes": 16878, "number_of_timesteps": 5621541, "per_episode_reward": -25.03, "episode_reward_trend_value": 0.005628331912020536, "biggest_recent_change": 0.10218553751051118},
{"total_number_of_episodes": 16888, "number_of_timesteps": 5628792, "per_episode_reward": -24.98, "episode_reward_trend_value": 0.0057011840271173975, "biggest_recent_change": 0.10218553751051118},
{"total_number_of_episodes": 16898, "number_of_timesteps": 5636835, "per_episode_reward": -24.98, "episode_reward_trend_value": 0.004538869351930015, "biggest_recent_change": 0.0985736976146292},
{"total_number_of_episodes": 16909, "number_of_timesteps": 5642201, "per_episode_reward": -24.86, "episode_reward_trend_value": 0.005001804984583084, "biggest_recent_change": 0.12044463896316415},
{"total_number_of_episodes": 16919, "number_of_timesteps": 5648192, "per_episode_reward": -24.83, "episode_reward_trend_value": 0.004743619616420365, "biggest_recent_change": 0.12044463896316415},
{"total_number_of_episodes": 16929, "number_of_timesteps": 5653572, "per_episode_reward": -24.8, "episode_reward_trend_value": 0.004759110164367226, "biggest_recent_change": 0.12044463896316415},
{"total_number_of_episodes": 16939, "number_of_timesteps": 5659106, "per_episode_reward": -24.76, "episode_reward_trend_value": 0.004652434666228129, "biggest_recent_change": 0.12044463896316415},
{"total_number_of_episodes": 16949, "number_of_timesteps": 5664410, "per_episode_reward": -24.76, "episode_reward_trend_value": 0.004769350685824452, "biggest_recent_change": 0.12044463896316415},
{"total_number_of_episodes": 16959, "number_of_timesteps": 5668958, "per_episode_reward": -24.73, "episode_reward_trend_value": 0.004016545673435621, "biggest_recent_change": 0.12044463896316415},
{"total_number_of_episodes": 16970, "number_of_timesteps": 5677917, "per_episode_reward": -24.69, "episode_reward_trend_value": 0.0037058327078533975, "biggest_recent_change": 0.12044463896316415},
{"total_number_of_episodes": 16980, "number_of_timesteps": 5680780, "per_episode_reward": -24.63, "episode_reward_trend_value": 0.00384316657342841, "biggest_recent_change": 0.12044463896316415},
{"total_number_of_episodes": 16990, "number_of_timesteps": 5686466, "per_episode_reward": -24.51, "episode_reward_trend_value": 0.005215880098617534, "biggest_recent_change": 0.12112143401066788},
{"total_number_of_episodes": 17000, "number_of_timesteps": 5692089, "per_episode_reward": -24.56, "episode_reward_trend_value": 0.0033611840501610937, "biggest_recent_change": 0.12112143401066788},
{"total_number_of_episodes": 17010, "number_of_timesteps": 5695636, "per_episode_reward": -24.44, "episode_reward_trend_value": 0.004327651391043988, "biggest_recent_change": 0.12112143401066788},
{"total_number_of_episodes": 17020, "number_of_timesteps": 5700521, "per_episode_reward": -24.43, "episode_reward_trend_value": 0.004109927262734598, "biggest_recent_change": 0.12112143401066788},
{"total_number_of_episodes": 17030, "number_of_timesteps": 5704299, "per_episode_reward": -24.39, "episode_reward_trend_value": 0.00418704893375303, "biggest_recent_change": 0.12112143401066788},
{"total_number_of_episodes": 17040, "number_of_timesteps": 5709295, "per_episode_reward": -24.09, "episode_reward_trend_value": 0.007426734649811648, "biggest_recent_change": 0.29375838550776834},
{"total_number_of_episodes": 17050, "number_of_timesteps": 5714145, "per_episode_reward": -24.03, "episode_reward_trend_value": 0.007830766918399866, "biggest_recent_change": 0.29375838550776834},
{"total_number_of_episodes": 17060, "number_of_timesteps": 5721951, "per_episode_reward": -23.93, "episode_reward_trend_value": 0.008419558909085526, "biggest_recent_change": 0.29375838550776834},
{"total_number_of_episodes": 17070, "number_of_timesteps": 5727831, "per_episode_reward": -23.93, "episode_reward_trend_value": 0.00783318866031186, "biggest_recent_change": 0.29375838550776834},
{"total_number_of_episodes": 17080, "number_of_timesteps": 5733141, "per_episode_reward": -23.89, "episode_reward_trend_value": 0.006898623771336314, "biggest_recent_change": 0.29375838550776834},
{"total_number_of_episodes": 17090, "number_of_timesteps": 5738885, "per_episode_reward": -23.77, "episode_reward_trend_value": 0.008726781815133736, "biggest_recent_change": 0.29375838550776834},
{"total_number_of_episodes": 17100, "number_of_timesteps": 5745379, "per_episode_reward": -23.74, "episode_reward_trend_value": 0.007767644570651239, "biggest_recent_change": 0.29375838550776834},
{"total_number_of_episodes": 17110, "number_of_timesteps": 5753004, "per_episode_reward": -23.7, "episode_reward_trend_value": 0.00811806025251486, "biggest_recent_change": 0.29375838550776834},
{"total_number_of_episodes": 17120, "number_of_timesteps": 5762166, "per_episode_reward": -23.62, "episode_reward_trend_value": 0.008558697770087933, "biggest_recent_change": 0.29375838550776834},
{"total_number_of_episodes": 17130, "number_of_timesteps": 5769152, "per_episode_reward": -23.52, "episode_reward_trend_value": 0.006326633945147482, "biggest_recent_change": 0.11805621854385251},
{"total_number_of_episodes": 17140, "number_of_timesteps": 5775063, "per_episode_reward": -23.44, "episode_reward_trend_value": 0.0065065421435399175, "biggest_recent_change": 0.11805621854385251},
{"total_number_of_episodes": 17150, "number_of_timesteps": 5781890, "per_episode_reward": -23.31, "episode_reward_trend_value": 0.006989509228655028, "biggest_recent_change": 0.13505274967397796},
{"total_number_of_episodes": 17160, "number_of_timesteps": 5787173, "per_episode_reward": -23.27, "episode_reward_trend_value": 0.007252933420130524, "biggest_recent_change": 0.13505274967397796},
{"total_number_of_episodes": 17170, "number_of_timesteps": 5794899, "per_episode_reward": -23.1, "episode_reward_trend_value": 0.008746348672058701, "biggest_recent_change": 0.17141796667640463},
{"total_number_of_episodes": 17180, "number_of_timesteps": 5801832, "per_episode_reward": -23.03, "episode_reward_trend_value": 0.008174983121625188, "biggest_recent_change": 0.17141796667640463},
{"total_number_of_episodes": 17190, "number_of_timesteps": 5807985, "per_episode_reward": -22.96, "episode_reward_trend_value": 0.008651283492878095, "biggest_recent_change": 0.17141796667640463},
{"total_number_of_episodes": 17201, "number_of_timesteps": 5812633, "per_episode_reward": -22.94, "episode_reward_trend_value": 0.008451148696570085, "biggest_recent_change": 0.17141796667640463},
{"total_number_of_episodes": 17211, "number_of_timesteps": 5819281, "per_episode_reward": -22.9, "episode_reward_trend_value": 0.007922586378337985, "biggest_recent_change": 0.17141796667640463},
{"total_number_of_episodes": 17221, "number_of_timesteps": 5823683, "per_episode_reward": -22.84, "episode_reward_trend_value": 0.0075990096909007735, "biggest_recent_change": 0.17141796667640463},
{"total_number_of_episodes": 17231, "number_of_timesteps": 5831323, "per_episode_reward": -22.81, "episode_reward_trend_value": 0.007021265791857997, "biggest_recent_change": 0.17141796667640463},
{"total_number_of_episodes": 17242, "number_of_timesteps": 5838995, "per_episode_reward": -22.76, "episode_reward_trend_value": 0.006059142705627825, "biggest_recent_change": 0.17141796667640463},
{"total_number_of_episodes": 17252, "number_of_timesteps": 5844425, "per_episode_reward": -22.72, "episode_reward_trend_value": 0.006147699511831917, "biggest_recent_change": 0.17141796667640463},
{"total_number_of_episodes": 17262, "number_of_timesteps": 5853045, "per_episode_reward": -22.66, "episode_reward_trend_value": 0.004891845334309311, "biggest_recent_change": 0.07164564249299588},
{"total_number_of_episodes": 17272, "number_of_timesteps": 5860572, "per_episode_reward": -22.58, "episode_reward_trend_value": 0.005061003682055601, "biggest_recent_change": 0.08185757030200236},
{"total_number_of_episodes": 17282, "number_of_timesteps": 5866494, "per_episode_reward": -22.56, "episode_reward_trend_value": 0.00442938320516034, "biggest_recent_change": 0.08185757030200236},
{"total_number_of_episodes": 17292, "number_of_timesteps": 5873522, "per_episode_reward": -22.4, "episode_reward_trend_value": 0.005970072966295663, "biggest_recent_change": 0.16225750956560603},
{"total_number_of_episodes": 17302, "number_of_timesteps": 5878994, "per_episode_reward": -22.23, "episode_reward_trend_value": 0.00746177209215758, "biggest_recent_change": 0.1694719323466245},
{"total_number_of_episodes": 17312, "number_of_timesteps": 5885504, "per_episode_reward": -22.23, "episode_reward_trend_value": 0.006824584952301925, "biggest_recent_change": 0.1694719323466245},
{"total_number_of_episodes": 17322, "number_of_timesteps": 5890424, "per_episode_reward": -22.17, "episode_reward_trend_value": 0.007120112674283557, "biggest_recent_change": 0.1694719323466245},
{"total_number_of_episodes": 17332, "number_of_timesteps": 5896276, "per_episode_reward": -22.11, "episode_reward_trend_value": 0.007255444834451434, "biggest_recent_change": 0.1694719323466245},
{"total_number_of_episodes": 17342, "number_of_timesteps": 5902791, "per_episode_reward": -22.09, "episode_reward_trend_value": 0.007001374133852619, "biggest_recent_change": 0.1694719323466245},
{"total_number_of_episodes": 17353, "number_of_timesteps": 5908942, "per_episode_reward": -22.01, "episode_reward_trend_value": 0.007245798990806386, "biggest_recent_change": 0.1694719323466245},
{"total_number_of_episodes": 17363, "number_of_timesteps": 5911877, "per_episode_reward": -21.93, "episode_reward_trend_value": 0.007232874532607643, "biggest_recent_change": 0.1694719323466245},
{"total_number_of_episodes": 17373, "number_of_timesteps": 5915348, "per_episode_reward": -21.85, "episode_reward_trend_value": 0.007990464991146792, "biggest_recent_change": 0.1694719323466245},
{"total_number_of_episodes": 17383, "number_of_timesteps": 5921450, "per_episode_reward": -21.76, "episode_reward_trend_value": 0.007157789549435062, "biggest_recent_change": 0.1694719323466245},
{"total_number_of_episodes": 17393, "number_of_timesteps": 5928564, "per_episode_reward": -21.71, "episode_reward_trend_value": 0.005783254686921898, "biggest_recent_change": 0.08731671981155031},
{"total_number_of_episodes": 17403, "number_of_timesteps": 5935385, "per_episode_reward": -21.67, "episode_reward_trend_value": 0.006190948235676982, "biggest_recent_change": 0.08731671981155031},
{"total_number_of_episodes": 17414, "number_of_timesteps": 5941765, "per_episode_reward": -21.6, "episode_reward_trend_value": 0.006319846572819384, "biggest_recent_change": 0.08731671981155031},
{"total_number_of_episodes": 17424, "number_of_timesteps": 5946131, "per_episode_reward": -21.56, "episode_reward_trend_value": 0.006111741532058564, "biggest_recent_change": 0.08731671981155031},
{"total_number_of_episodes": 17434, "number_of_timesteps": 5953156, "per_episode_reward": -21.43, "episode_reward_trend_value": 0.007293963425424129, "biggest_recent_change": 0.12472384423607963},
{"total_number_of_episodes": 17444, "number_of_timesteps": 5960535, "per_episode_reward": -21.38, "episode_reward_trend_value": 0.00702233031004494, "biggest_recent_change": 0.12472384423607963},
{"total_number_of_episodes": 17454, "number_of_timesteps": 5968582, "per_episode_reward": -21.33, "episode_reward_trend_value": 0.006631065997287975, "biggest_recent_change": 0.12472384423607963},
{"total_number_of_episodes": 17464, "number_of_timesteps": 5976775, "per_episode_reward": -21.27, "episode_reward_trend_value": 0.006427063690284819, "biggest_recent_change": 0.12472384423607963},
{"total_number_of_episodes": 17474, "number_of_timesteps": 5986381, "per_episode_reward": -21.24, "episode_reward_trend_value": 0.005750390771775136, "biggest_recent_change": 0.12472384423607963},
{"total_number_of_episodes": 17484, "number_of_timesteps": 5993526, "per_episode_reward": -21.23, "episode_reward_trend_value": 0.0053421678033801125, "biggest_recent_change": 0.12472384423607963},
{"total_number_of_episodes": 17494, "number_of_timesteps": 6000058, "per_episode_reward": -21.17, "episode_reward_trend_value": 0.00550673314199391, "biggest_recent_change": 0.12472384423607963},
{"total_number_of_episodes": 17504, "number_of_timesteps": 6003606, "per_episode_reward": -21.13, "episode_reward_trend_value": 0.005200425728752478, "biggest_recent_change": 0.12472384423607963},
{"total_number_of_episodes": 17514, "number_of_timesteps": 6009777, "per_episode_reward": -21.06, "episode_reward_trend_value": 0.0054989999653072465, "biggest_recent_change": 0.12472384423607963},
{"total_number_of_episodes": 17524, "number_of_timesteps": 6015274, "per_episode_reward": -21.01, "episode_reward_trend_value": 0.004675768491455696, "biggest_recent_change": 0.06878379394982659},
{"total_number_of_episodes": 17534, "number_of_timesteps": 6019084, "per_episode_reward": -20.99, "episode_reward_trend_value": 0.0043434436194356215, "biggest_recent_change": 0.06878379394982659},
{"total_number_of_episodes": 17544, "number_of_timesteps": 6023895, "per_episode_reward": -20.93, "episode_reward_trend_value": 0.0044294883538825445, "biggest_recent_change": 0.06878379394982659},
{"total_number_of_episodes": 17554, "number_of_timesteps": 6026912, "per_episode_reward": -20.82, "episode_reward_trend_value": 0.004928593540414442, "biggest_recent_change": 0.10954219999853265},
{"total_number_of_episodes": 17564, "number_of_timesteps": 6031647, "per_episode_reward": -20.75, "episode_reward_trend_value": 0.0054377919859778245, "biggest_recent_change": 0.10954219999853265},
{"total_number_of_episodes": 17574, "number_of_timesteps": 6034363, "per_episode_reward": -20.71, "episode_reward_trend_value": 0.005747214626346223, "biggest_recent_change": 0.10954219999853265},
{"total_number_of_episodes": 17584, "number_of_timesteps": 6037762, "per_episode_reward": -20.54, "episode_reward_trend_value": 0.00708603079082282, "biggest_recent_change": 0.1784006514728631},
{"total_number_of_episodes": 17596, "number_of_timesteps": 6041337, "per_episode_reward": -20.45, "episode_reward_trend_value": 0.007553952472496306, "biggest_recent_change": 0.1784006514728631},
{"total_number_of_episodes": 17606, "number_of_timesteps": 6045099, "per_episode_reward": -20.46, "episode_reward_trend_value": 0.006672532019971753, "biggest_recent_change": 0.1784006514728631},
{"total_number_of_episodes": 17616, "number_of_timesteps": 6047371, "per_episode_reward": -20.42, "episode_reward_trend_value": 0.006625415336839818, "biggest_recent_change": 0.1784006514728631},
{"total_number_of_episodes": 17626, "number_of_timesteps": 6051810, "per_episode_reward": -20.3, "episode_reward_trend_value": 0.007635058792168081, "biggest_recent_change": 0.1784006514728631},
{"total_number_of_episodes": 17636, "number_of_timesteps": 6056343, "per_episode_reward": -20.21, "episode_reward_trend_value": 0.008043434305735096, "biggest_recent_change": 0.1784006514728631},
{"total_number_of_episodes": 17646, "number_of_timesteps": 6062500, "per_episode_reward": -20.15, "episode_reward_trend_value": 0.007481146640747956, "biggest_recent_change": 0.1784006514728631},
{"total_number_of_episodes": 17656, "number_of_timesteps": 6068859, "per_episode_reward": -20.08, "episode_reward_trend_value": 0.007468350817208286, "biggest_recent_change": 0.1784006514728631},
{"total_number_of_episodes": 17666, "number_of_timesteps": 6077751, "per_episode_reward": -20.02, "episode_reward_trend_value": 0.007656658126056312, "biggest_recent_change": 0.1784006514728631},
{"total_number_of_episodes": 17676, "number_of_timesteps": 6087751, "per_episode_reward": -19.95, "episode_reward_trend_value": 0.006518282297012748, "biggest_recent_change": 0.11690101993881896},
{"total_number_of_episodes": 17686, "number_of_timesteps": 6096202, "per_episode_reward": -19.92, "episode_reward_trend_value": 0.005925823951756904, "biggest_recent_change": 0.11690101993881896},
{"total_number_of_episodes": 17696, "number_of_timesteps": 6100531, "per_episode_reward": -19.8, "episode_reward_trend_value": 0.007344821629968755, "biggest_recent_change": 0.11716574426168336},
{"total_number_of_episodes": 17706, "number_of_timesteps": 6108037, "per_episode_reward": -19.77, "episode_reward_trend_value": 0.0072291045599571805, "biggest_recent_change": 0.11716574426168336},
{"total_number_of_episodes": 17716, "number_of_timesteps": 6114231, "per_episode_reward": -19.68, "episode_reward_trend_value": 0.006830071646906038, "biggest_recent_change": 0.11716574426168336},
{"total_number_of_episodes": 17726, "number_of_timesteps": 6123024, "per_episode_reward": -19.63, "episode_reward_trend_value": 0.006408742714630161, "biggest_recent_change": 0.11716574426168336},
{"total_number_of_episodes": 17736, "number_of_timesteps": 6131263, "per_episode_reward": -19.56, "episode_reward_trend_value": 0.006507334303442826, "biggest_recent_change": 0.11716574426168336},
{"total_number_of_episodes": 17746, "number_of_timesteps": 6133751, "per_episode_reward": -19.51, "episode_reward_trend_value": 0.0063646516674159175, "biggest_recent_change": 0.11716574426168336},
{"total_number_of_episodes": 17756, "number_of_timesteps": 6139867, "per_episode_reward": -19.46, "episode_reward_trend_value": 0.006321221658111792, "biggest_recent_change": 0.11716574426168336},
{"total_number_of_episodes": 17766, "number_of_timesteps": 6145716, "per_episode_reward": -19.4, "episode_reward_trend_value": 0.006049649655059181, "biggest_recent_change": 0.11716574426168336},
{"total_number_of_episodes": 17776, "number_of_timesteps": 6149483, "per_episode_reward": -19.34, "episode_reward_trend_value": 0.006373791117731721, "biggest_recent_change": 0.11716574426168336},
{"total_number_of_episodes": 17786, "number_of_timesteps": 6156006, "per_episode_reward": -19.32, "episode_reward_trend_value": 0.005315102884328324, "biggest_recent_change": 0.08098805776421614},
{"total_number_of_episodes": 17796, "number_of_timesteps": 6161868, "per_episode_reward": -19.27, "episode_reward_trend_value": 0.005472995642452282, "biggest_recent_change": 0.08098805776421614},
{"total_number_of_episodes": 17806, "number_of_timesteps": 6167406, "per_episode_reward": -19.24, "episode_reward_trend_value": 0.00491611024154221, "biggest_recent_change": 0.06780955314282977},
{"total_number_of_episodes": 17816, "number_of_timesteps": 6174857, "per_episode_reward": -19.19, "episode_reward_trend_value": 0.004917636891374697, "biggest_recent_change": 0.06780955314282977},
{"total_number_of_episodes": 17826, "number_of_timesteps": 6180800, "per_episode_reward": -19.02, "episode_reward_trend_value": 0.006059825974817793, "biggest_recent_change": 0.17060657065270846},
{"total_number_of_episodes": 17836, "number_of_timesteps": 6189370, "per_episode_reward": -18.99, "episode_reward_trend_value": 0.005747781402768876, "biggest_recent_change": 0.17060657065270846},
{"total_number_of_episodes": 17846, "number_of_timesteps": 6198224, "per_episode_reward": -18.93, "episode_reward_trend_value": 0.0058117286207197884, "biggest_recent_change": 0.17060657065270846},
{"total_number_of_episodes": 17857, "number_of_timesteps": 6205455, "per_episode_reward": -18.88, "episode_reward_trend_value": 0.005820841813914828, "biggest_recent_change": 0.17060657065270846},
{"total_number_of_episodes": 17867, "number_of_timesteps": 6212519, "per_episode_reward": -18.83, "episode_reward_trend_value": 0.005674012456756867, "biggest_recent_change": 0.17060657065270846},
{"total_number_of_episodes": 17877, "number_of_timesteps": 6219934, "per_episode_reward": -18.78, "episode_reward_trend_value": 0.006069719053506814, "biggest_recent_change": 0.17060657065270846},
{"total_number_of_episodes": 17887, "number_of_timesteps": 6227330, "per_episode_reward": -18.73, "episode_reward_trend_value": 0.006003635516920467, "biggest_recent_change": 0.17060657065270846},
{"total_number_of_episodes": 17898, "number_of_timesteps": 6232968, "per_episode_reward": -18.72, "episode_reward_trend_value": 0.005764847479479506, "biggest_recent_change": 0.17060657065270846},
{"total_number_of_episodes": 17908, "number_of_timesteps": 6238501, "per_episode_reward": -18.65, "episode_reward_trend_value": 0.005993254137344076, "biggest_recent_change": 0.17060657065270846},
{"total_number_of_episodes": 17918, "number_of_timesteps": 6245526, "per_episode_reward": -18.62, "episode_reward_trend_value": 0.004437475964692203, "biggest_recent_change": 0.07275279702514936},

{"total_number_of_episodes": 17928, "number_of_timesteps": 6249730, "per_episode_reward": -18.57, "episode_reward_trend_value": 0.004626440144706913, "biggest_recent_change": 0.07275279702514936},
{"total_number_of_episodes": 17938, "number_of_timesteps": 6254357, "per_episode_reward": -18.55, "episode_reward_trend_value": 0.004269443815936727, "biggest_recent_change": 0.07275279702514936},
{"total_number_of_episodes": 17948, "number_of_timesteps": 6260523, "per_episode_reward": -18.44, "episode_reward_trend_value": 0.004903591849879479, "biggest_recent_change": 0.10939885702660845},
{"total_number_of_episodes": 17958, "number_of_timesteps": 6267006, "per_episode_reward": -18.41, "episode_reward_trend_value": 0.004674770913269397, "biggest_recent_change": 0.10939885702660845},
{"total_number_of_episodes": 17968, "number_of_timesteps": 6274054, "per_episode_reward": -18.39, "episode_reward_trend_value": 0.004275646835652383, "biggest_recent_change": 0.10939885702660845},
{"total_number_of_episodes": 17978, "number_of_timesteps": 6280050, "per_episode_reward": -18.37, "episode_reward_trend_value": 0.004061524903186095, "biggest_recent_change": 0.10939885702660845},

{"total_number_of_episodes": 17988, "number_of_timesteps": 6284609, "per_episode_reward": -18.27, "episode_reward_trend_value": 0.005060524416596638, "biggest_recent_change": 0.10939885702660845},
{"total_number_of_episodes": 17998, "number_of_timesteps": 6289502, "per_episode_reward": -18.2, "episode_reward_trend_value": 0.004962762999637604, "biggest_recent_change": 0.10939885702660845},
{"total_number_of_episodes": 18008, "number_of_timesteps": 6293316, "per_episode_reward": -18.14, "episode_reward_trend_value": 0.005371542029441617, "biggest_recent_change": 0.10939885702660845},
{"total_number_of_episodes": 18018, "number_of_timesteps": 6298769, "per_episode_reward": -18.07, "episode_reward_trend_value": 0.00563307791013005, "biggest_recent_change": 0.10939885702660845},
{"total_number_of_episodes": 18029, "number_of_timesteps": 6305830, "per_episode_reward": -17.98, "episode_reward_trend_value": 0.006301928325902395, "biggest_recent_change": 0.10939885702660845},
{"total_number_of_episodes": 18039, "number_of_timesteps": 6309814, "per_episode_reward": -17.95, "episode_reward_trend_value": 0.005426339359422114, "biggest_recent_change": 0.09928740451957196},
{"total_number_of_episodes": 18049, "number_of_timesteps": 6313346, "per_episode_reward": -17.9, "episode_reward_trend_value": 0.005685279613691405, "biggest_recent_change": 0.09928740451957196},
{"total_number_of_episodes": 18060, "number_of_timesteps": 6319735, "per_episode_reward": -17.78, "episode_reward_trend_value": 0.006769459393438144, "biggest_recent_change": 0.11915241015454825},
{"total_number_of_episodes": 18070, "number_of_timesteps": 6326164, "per_episode_reward": -17.72, "episode_reward_trend_value": 0.007160556987390541, "biggest_recent_change": 0.11915241015454825},
{"total_number_of_episodes": 18082, "number_of_timesteps": 6335378, "per_episode_reward": -17.54, "episode_reward_trend_value": 0.008134824771317994, "biggest_recent_change": 0.18697150507304272},
{"total_number_of_episodes": 18092, "number_of_timesteps": 6341245, "per_episode_reward": -17.48, "episode_reward_trend_value": 0.008028736567007439, "biggest_recent_change": 0.18697150507304272},
{"total_number_of_episodes": 18102, "number_of_timesteps": 6349057, "per_episode_reward": -17.41, "episode_reward_trend_value": 0.008066284082736254, "biggest_recent_change": 0.18697150507304272},
{"total_number_of_episodes": 18112, "number_of_timesteps": 6356965, "per_episode_reward": -17.38, "episode_reward_trend_value": 0.0075887378484275235, "biggest_recent_change": 0.18697150507304272},
{"total_number_of_episodes": 18123, "number_of_timesteps": 6366228, "per_episode_reward": -17.29, "episode_reward_trend_value": 0.007723791998017759, "biggest_recent_change": 0.18697150507304272},
{"total_number_of_episodes": 18133, "number_of_timesteps": 6374712, "per_episode_reward": -17.26, "episode_reward_trend_value": 0.007657414640523186, "biggest_recent_change": 0.18697150507304272},
{"total_number_of_episodes": 18143, "number_of_timesteps": 6384534, "per_episode_reward": -17.22, "episode_reward_trend_value": 0.007571876529309268, "biggest_recent_change": 0.18697150507304272},
{"total_number_of_episodes": 18153, "number_of_timesteps": 6389768, "per_episode_reward": -17.18, "episode_reward_trend_value": 0.006679525677224124, "biggest_recent_change": 0.18697150507304272},
{"total_number_of_episodes": 18163, "number_of_timesteps": 6396525, "per_episode_reward": -17.15, "episode_reward_trend_value": 0.00630724606322796, "biggest_recent_change": 0.18697150507304272},
{"total_number_of_episodes": 18173, "number_of_timesteps": 6402157, "per_episode_reward": -17.11, "episode_reward_trend_value": 0.004743720639019166, "biggest_recent_change": 0.09588771306589194},
{"total_number_of_episodes": 18183, "number_of_timesteps": 6409542, "per_episode_reward": -17.02, "episode_reward_trend_value": 0.005075537275535622, "biggest_recent_change": 0.09588771306589194},
{"total_number_of_episodes": 18193, "number_of_timesteps": 6416614, "per_episode_reward": -16.99, "episode_reward_trend_value": 0.004641893132400041, "biggest_recent_change": 0.09588771306589194},
{"total_number_of_episodes": 18203, "number_of_timesteps": 6425110, "per_episode_reward": -16.98, "episode_reward_trend_value": 0.004512916458574681, "biggest_recent_change": 0.09588771306589194},
{"total_number_of_episodes": 18213, "number_of_timesteps": 6432302, "per_episode_reward": -16.87, "episode_reward_trend_value": 0.0045971154768919414, "biggest_recent_change": 0.10346562471444543},
{"total_number_of_episodes": 18223, "number_of_timesteps": 6438723, "per_episode_reward": -16.82, "episode_reward_trend_value": 0.004951570321930158, "biggest_recent_change": 0.10346562471444543},
{"total_number_of_episodes": 18233, "number_of_timesteps": 6445926, "per_episode_reward": -16.79, "episode_reward_trend_value": 0.004750376821574934, "biggest_recent_change": 0.10346562471444543},
{"total_number_of_episodes": 18243, "number_of_timesteps": 6451386, "per_episode_reward": -16.74, "episode_reward_trend_value": 0.004956792928416892, "biggest_recent_change": 0.10346562471444543},
{"total_number_of_episodes": 18253, "number_of_timesteps": 6454740, "per_episode_reward": -16.7, "episode_reward_trend_value": 0.0050331834719764225, "biggest_recent_change": 0.10346562471444543},
{"total_number_of_episodes": 18263, "number_of_timesteps": 6459027, "per_episode_reward": -16.71, "episode_reward_trend_value": 0.004396352025238236, "biggest_recent_change": 0.10346562471444543},
{"total_number_of_episodes": 18273, "number_of_timesteps": 6468333, "per_episode_reward": -16.72, "episode_reward_trend_value": 0.0033502913101211597, "biggest_recent_change": 0.10346562471444543},
{"total_number_of_episodes": 18283, "number_of_timesteps": 6475967, "per_episode_reward": -16.71, "episode_reward_trend_value": 0.0031759350006444953, "biggest_recent_change": 0.10346562471444543},
{"total_number_of_episodes": 18293, "number_of_timesteps": 6483353, "per_episode_reward": -16.67, "episode_reward_trend_value": 0.0034220534027510274, "biggest_recent_change": 0.10346562471444543},
{"total_number_of_episodes": 18303, "number_of_timesteps": 6491417, "per_episode_reward": -16.58, "episode_reward_trend_value": 0.0033041785529124785, "biggest_recent_change": 0.09285688822897598},
{"total_number_of_episodes": 18313, "number_of_timesteps": 6498778, "per_episode_reward": -16.55, "episode_reward_trend_value": 0.0029453568604100077, "biggest_recent_change": 0.09285688822897598},
{"total_number_of_episodes": 18323, "number_of_timesteps": 6503685, "per_episode_reward": -16.52, "episode_reward_trend_value": 0.0030102505796950002, "biggest_recent_change": 0.09285688822897598},
{"total_number_of_episodes": 18333, "number_of_timesteps": 6510405, "per_episode_reward": -16.48, "episode_reward_trend_value": 0.00285802773842513, "biggest_recent_change": 0.09285688822897598},
{"total_number_of_episodes": 18343, "number_of_timesteps": 6517103, "per_episode_reward": -16.46, "episode_reward_trend_value": 0.002699441011567474, "biggest_recent_change": 0.09285688822897598},
{"total_number_of_episodes": 18353, "number_of_timesteps": 6524646, "per_episode_reward": -16.34, "episode_reward_trend_value": 0.004168126321200876, "biggest_recent_change": 0.12112106455482063},
{"total_number_of_episodes": 18363, "number_of_timesteps": 6529999, "per_episode_reward": -16.29, "episode_reward_trend_value": 0.004777776820543364, "biggest_recent_change": 0.12112106455482063},
{"total_number_of_episodes": 18373, "number_of_timesteps": 6535616, "per_episode_reward": -16.21, "episode_reward_trend_value": 0.005501563135505134, "biggest_recent_change": 0.12112106455482063},
{"total_number_of_episodes": 18383, "number_of_timesteps": 6540326, "per_episode_reward": -16.11, "episode_reward_trend_value": 0.0061926138543463025, "biggest_recent_change": 0.12112106455482063},
{"total_number_of_episodes": 18393, "number_of_timesteps": 6547572, "per_episode_reward": -16.03, "episode_reward_trend_value": 0.006053990014942083, "biggest_recent_change": 0.12112106455482063},
{"total_number_of_episodes": 18403, "number_of_timesteps": 6552980, "per_episode_reward": -15.98, "episode_reward_trend_value": 0.006373072889825318, "biggest_recent_change": 0.12112106455482063},
{"total_number_of_episodes": 18413, "number_of_timesteps": 6559229, "per_episode_reward": -15.94, "episode_reward_trend_value": 0.0064761369860153115, "biggest_recent_change": 0.12112106455482063},
{"total_number_of_episodes": 18423, "number_of_timesteps": 6565760, "per_episode_reward": -15.89, "episode_reward_trend_value": 0.006572488534279842, "biggest_recent_change": 0.12112106455482063},
{"total_number_of_episodes": 18433, "number_of_timesteps": 6571024, "per_episode_reward": -15.84, "episode_reward_trend_value": 0.006892743715915096, "biggest_recent_change": 0.12112106455482063},
{"total_number_of_episodes": 18443, "number_of_timesteps": 6578387, "per_episode_reward": -15.8, "episode_reward_trend_value": 0.005983853484317139, "biggest_recent_change": 0.10047010901749687},
{"total_number_of_episodes": 18453, "number_of_timesteps": 6582896, "per_episode_reward": -15.76, "episode_reward_trend_value": 0.005969082922859847, "biggest_recent_change": 0.10047010901749687},
{"total_number_of_episodes": 18463, "number_of_timesteps": 6588651, "per_episode_reward": -15.72, "episode_reward_trend_value": 0.005504198710412863, "biggest_recent_change": 0.10047010901749687},
{"total_number_of_episodes": 18473, "number_of_timesteps": 6595167, "per_episode_reward": -15.68, "episode_reward_trend_value": 0.00482479659735395, "biggest_recent_change": 0.0803807426825962},
{"total_number_of_episodes": 18483, "number_of_timesteps": 6598819, "per_episode_reward": -15.64, "episode_reward_trend_value": 0.004389765880949663, "biggest_recent_change": 0.052946330336579805},
{"total_number_of_episodes": 18493, "number_of_timesteps": 6603006, "per_episode_reward": -15.58, "episode_reward_trend_value": 0.004448043085052807, "biggest_recent_change": 0.058191278705862715},
{"total_number_of_episodes": 18503, "number_of_timesteps": 6611388, "per_episode_reward": -15.53, "episode_reward_trend_value": 0.0045728986795421315, "biggest_recent_change": 0.058191278705862715},
{"total_number_of_episodes": 18513, "number_of_timesteps": 6619676, "per_episode_reward": -15.48, "episode_reward_trend_value": 0.004471265795451353, "biggest_recent_change": 0.058191278705862715},
{"total_number_of_episodes": 18524, "number_of_timesteps": 6626290, "per_episode_reward": -15.48, "episode_reward_trend_value": 0.004000795282805293, "biggest_recent_change": 0.058191278705862715},
{"total_number_of_episodes": 18534, "number_of_timesteps": 6631816, "per_episode_reward": -15.44, "episode_reward_trend_value": 0.003967467258277679, "biggest_recent_change": 0.058191278705862715},
{"total_number_of_episodes": 18544, "number_of_timesteps": 6639840, "per_episode_reward": -15.4, "episode_reward_trend_value": 0.003978887890480327, "biggest_recent_change": 0.058191278705862715},
{"total_number_of_episodes": 18555, "number_of_timesteps": 6650137, "per_episode_reward": -15.31, "episode_reward_trend_value": 0.0044631109799790755, "biggest_recent_change": 0.08291715075811013},
{"total_number_of_episodes": 18565, "number_of_timesteps": 6656614, "per_episode_reward": -15.26, "episode_reward_trend_value": 0.004653061912347529, "biggest_recent_change": 0.08291715075811013},
{"total_number_of_episodes": 18575, "number_of_timesteps": 6663222, "per_episode_reward": -15.22, "episode_reward_trend_value": 0.004626204010646755, "biggest_recent_change": 0.08291715075811013},
{"total_number_of_episodes": 18585, "number_of_timesteps": 6670058, "per_episode_reward": -15.11, "episode_reward_trend_value": 0.005174815361541482, "biggest_recent_change": 0.10756630028638803},
{"total_number_of_episodes": 18595, "number_of_timesteps": 6676304, "per_episode_reward": -15.11, "episode_reward_trend_value": 0.004646565832554176, "biggest_recent_change": 0.10756630028638803},
{"total_number_of_episodes": 18605, "number_of_timesteps": 6681986, "per_episode_reward": -15.08, "episode_reward_trend_value": 0.004531961593177907, "biggest_recent_change": 0.10756630028638803},
{"total_number_of_episodes": 18615, "number_of_timesteps": 6688737, "per_episode_reward": -14.95, "episode_reward_trend_value": 0.005907555139366869, "biggest_recent_change": 0.12954983088820704},
{"total_number_of_episodes": 18625, "number_of_timesteps": 6696808, "per_episode_reward": -14.93, "episode_reward_trend_value": 0.005736608431834611, "biggest_recent_change": 0.12954983088820704},
{"total_number_of_episodes": 18635, "number_of_timesteps": 6704224, "per_episode_reward": -14.92, "episode_reward_trend_value": 0.005328323540039845, "biggest_recent_change": 0.12954983088820704},
{"total_number_of_episodes": 18645, "number_of_timesteps": 6710598, "per_episode_reward": -14.87, "episode_reward_trend_value": 0.004976413157466868, "biggest_recent_change": 0.12954983088820704},
{"total_number_of_episodes": 18656, "number_of_timesteps": 6716216, "per_episode_reward": -14.84, "episode_reward_trend_value": 0.0046044960909578676, "biggest_recent_change": 0.12954983088820704},
{"total_number_of_episodes": 18666, "number_of_timesteps": 6720474, "per_episode_reward": -14.78, "episode_reward_trend_value": 0.004867556435299727, "biggest_recent_change": 0.12954983088820704},
{"total_number_of_episodes": 18677, "number_of_timesteps": 6727147, "per_episode_reward": -14.75, "episode_reward_trend_value": 0.004050964000648073, "biggest_recent_change": 0.12954983088820704},
{"total_number_of_episodes": 18687, "number_of_timesteps": 6734341, "per_episode_reward": -14.71, "episode_reward_trend_value": 0.004385913905733436, "biggest_recent_change": 0.12954983088820704},
{"total_number_of_episodes": 18698, "number_of_timesteps": 6739254, "per_episode_reward": -14.63, "episode_reward_trend_value": 0.004980103890701118, "biggest_recent_change": 0.12954983088820704},

{"total_number_of_episodes": 18708, "number_of_timesteps": 6744942, "per_episode_reward": -14.57, "episode_reward_trend_value": 0.004223641444584381, "biggest_recent_change": 0.08640562424723797},
{"total_number_of_episodes": 18718, "number_of_timesteps": 6750323, "per_episode_reward": -14.51, "episode_reward_trend_value": 0.004575036256273831, "biggest_recent_change": 0.08640562424723797},
{"total_number_of_episodes": 18728, "number_of_timesteps": 6758280, "per_episode_reward": -14.47, "episode_reward_trend_value": 0.004990331219209487, "biggest_recent_change": 0.08640562424723797},
{"total_number_of_episodes": 18738, "number_of_timesteps": 6762247, "per_episode_reward": -14.41, "episode_reward_trend_value": 0.005074747510960975, "biggest_recent_change": 0.08640562424723797},
{"total_number_of_episodes": 18748, "number_of_timesteps": 6766474, "per_episode_reward": -14.37, "episode_reward_trend_value": 0.005237270333600444, "biggest_recent_change": 0.08640562424723797},
{"total_number_of_episodes": 18758, "number_of_timesteps": 6772151, "per_episode_reward": -14.3, "episode_reward_trend_value": 0.0053932834395697465, "biggest_recent_change": 0.08640562424723797},
{"total_number_of_episodes": 18769, "number_of_timesteps": 6777994, "per_episode_reward": -14.19, "episode_reward_trend_value": 0.006143995969543939, "biggest_recent_change": 0.10163710886541644},
{"total_number_of_episodes": 18779, "number_of_timesteps": 6783517, "per_episode_reward": -14.08, "episode_reward_trend_value": 0.007026446917154277, "biggest_recent_change": 0.11204112509602737},
{"total_number_of_episodes": 18789, "number_of_timesteps": 6786969, "per_episode_reward": -14.05, "episode_reward_trend_value": 0.006400500061391136, "biggest_recent_change": 0.11204112509602737},
{"total_number_of_episodes": 18799, "number_of_timesteps": 6792813, "per_episode_reward": -14.02, "episode_reward_trend_value": 0.0061094744547312944, "biggest_recent_change": 0.11204112509602737},
{"total_number_of_episodes": 18810, "number_of_timesteps": 6797075, "per_episode_reward": -13.99, "episode_reward_trend_value": 0.005840747774896392, "biggest_recent_change": 0.11204112509602737},
{"total_number_of_episodes": 18820, "number_of_timesteps": 6799650, "per_episode_reward": -13.92, "episode_reward_trend_value": 0.006092377669347332, "biggest_recent_change": 0.11204112509602737},
{"total_number_of_episodes": 18830, "number_of_timesteps": 6806328, "per_episode_reward": -13.89, "episode_reward_trend_value": 0.005729728566998698, "biggest_recent_change": 0.11204112509602737},
{"total_number_of_episodes": 18841, "number_of_timesteps": 6815121, "per_episode_reward": -13.86, "episode_reward_trend_value": 0.005640193111385372, "biggest_recent_change": 0.11204112509602737},
{"total_number_of_episodes": 18852, "number_of_timesteps": 6823728, "per_episode_reward": -13.8, "episode_reward_trend_value": 0.0054631670699947085, "biggest_recent_change": 0.11204112509602737},
{"total_number_of_episodes": 18862, "number_of_timesteps": 6829685, "per_episode_reward": -13.76, "episode_reward_trend_value": 0.004786432310790052, "biggest_recent_change": 0.11204112509602737},
{"total_number_of_episodes": 18872, "number_of_timesteps": 6833910, "per_episode_reward": -13.61, "episode_reward_trend_value": 0.005202240108663681, "biggest_recent_change": 0.14946382690465398},
{"total_number_of_episodes": 18882, "number_of_timesteps": 6839528, "per_episode_reward": -13.57, "episode_reward_trend_value": 0.005349387989997526, "biggest_recent_change": 0.14946382690465398},
{"total_number_of_episodes": 18892, "number_of_timesteps": 6845128, "per_episode_reward": -13.52, "episode_reward_trend_value": 0.0054951719958945275, "biggest_recent_change": 0.14946382690465398},
{"total_number_of_episodes": 18902, "number_of_timesteps": 6852029, "per_episode_reward": -13.5, "episode_reward_trend_value": 0.005408766725564796, "biggest_recent_change": 0.14946382690465398},
{"total_number_of_episodes": 18912, "number_of_timesteps": 6859264, "per_episode_reward": -13.47, "episode_reward_trend_value": 0.004966831352064835, "biggest_recent_change": 0.14946382690465398},
{"total_number_of_episodes": 18922, "number_of_timesteps": 6865714, "per_episode_reward": -13.47, "episode_reward_trend_value": 0.004664952973688013, "biggest_recent_change": 0.14946382690465398},
{"total_number_of_episodes": 18932, "number_of_timesteps": 6872365, "per_episode_reward": -13.45, "episode_reward_trend_value": 0.004551429583044787, "biggest_recent_change": 0.14946382690465398},
{"total_number_of_episodes": 18942, "number_of_timesteps": 6881200, "per_episode_reward": -13.43, "episode_reward_trend_value": 0.004129347490960021, "biggest_recent_change": 0.14946382690465398},
{"total_number_of_episodes": 18952, "number_of_timesteps": 6888845, "per_episode_reward": -13.38, "episode_reward_trend_value": 0.004246833738880183, "biggest_recent_change": 0.14946382690465398},
{"total_number_of_episodes": 18962, "number_of_timesteps": 6894365, "per_episode_reward": -13.34, "episode_reward_trend_value": 0.00301537040858493, "biggest_recent_change": 0.0513047428498119},
{"total_number_of_episodes": 18972, "number_of_timesteps": 6899894, "per_episode_reward": -13.29, "episode_reward_trend_value": 0.003073482352285417, "biggest_recent_change": 0.0513047428498119},
{"total_number_of_episodes": 18982, "number_of_timesteps": 6903110, "per_episode_reward": -13.26, "episode_reward_trend_value": 0.0028758308921666754, "biggest_recent_change": 0.0513047428498119},
{"total_number_of_episodes": 18992, "number_of_timesteps": 6907383, "per_episode_reward": -13.24, "episode_reward_trend_value": 0.002884195801436877, "biggest_recent_change": 0.0513047428498119},
{"total_number_of_episodes": 19003, "number_of_timesteps": 6914807, "per_episode_reward": -13.19, "episode_reward_trend_value": 0.0031925559533604346, "biggest_recent_change": 0.05594724230612513},
{"total_number_of_episodes": 19013, "number_of_timesteps": 6919370, "per_episode_reward": -13.15, "episode_reward_trend_value": 0.0035613080037184253, "biggest_recent_change": 0.05594724230612513},
{"total_number_of_episodes": 19023, "number_of_timesteps": 6924882, "per_episode_reward": -13.14, "episode_reward_trend_value": 0.0034488577528287933, "biggest_recent_change": 0.05594724230612513},
{"total_number_of_episodes": 19033, "number_of_timesteps": 6931424, "per_episode_reward": -13.11, "episode_reward_trend_value": 0.0036246785479998695, "biggest_recent_change": 0.05594724230612513},
{"total_number_of_episodes": 19043, "number_of_timesteps": 6935965, "per_episode_reward": -13.09, "episode_reward_trend_value": 0.0032877696784599742, "biggest_recent_change": 0.05594724230612513},
{"total_number_of_episodes": 19054, "number_of_timesteps": 6943966, "per_episode_reward": -13.04, "episode_reward_trend_value": 0.0033497185042603824, "biggest_recent_change": 0.05594724230612513},
{"total_number_of_episodes": 19064, "number_of_timesteps": 6947314, "per_episode_reward": -13.0, "episode_reward_trend_value": 0.0033173285605641923, "biggest_recent_change": 0.05594724230612513},
{"total_number_of_episodes": 19074, "number_of_timesteps": 6951383, "per_episode_reward": -12.94, "episode_reward_trend_value": 0.0035581033504757816, "biggest_recent_change": 0.05594724230612513},
{"total_number_of_episodes": 19084, "number_of_timesteps": 6958614, "per_episode_reward": -12.88, "episode_reward_trend_value": 0.0039720762095758625, "biggest_recent_change": 0.058610274516174954},
{"total_number_of_episodes": 19094, "number_of_timesteps": 6963018, "per_episode_reward": -12.84, "episode_reward_trend_value": 0.003818110015999506, "biggest_recent_change": 0.058610274516174954},
{"total_number_of_episodes": 19104, "number_of_timesteps": 6965567, "per_episode_reward": -12.79, "episode_reward_trend_value": 0.004042491826741252, "biggest_recent_change": 0.058610274516174954},
{"total_number_of_episodes": 19114, "number_of_timesteps": 6968552, "per_episode_reward": -12.74, "episode_reward_trend_value": 0.004517983876097157, "biggest_recent_change": 0.058610274516174954},
{"total_number_of_episodes": 19124, "number_of_timesteps": 6970686, "per_episode_reward": -12.53, "episode_reward_trend_value": 0.006450534870750602, "biggest_recent_change": 0.2123611066525637},
{"total_number_of_episodes": 19134, "number_of_timesteps": 6973659, "per_episode_reward": -12.53, "episode_reward_trend_value": 0.006148519323223923, "biggest_recent_change": 0.2123611066525637},
{"total_number_of_episodes": 19144, "number_of_timesteps": 6976605, "per_episode_reward": -12.49, "episode_reward_trend_value": 0.0061440291245127635, "biggest_recent_change": 0.2123611066525637},
{"total_number_of_episodes": 19154, "number_of_timesteps": 6979225, "per_episode_reward": -12.47, "episode_reward_trend_value": 0.005857103307947496, "biggest_recent_change": 0.2123611066525637},
{"total_number_of_episodes": 19164, "number_of_timesteps": 6982193, "per_episode_reward": -12.45, "episode_reward_trend_value": 0.00544666652416943, "biggest_recent_change": 0.2123611066525637},
{"total_number_of_episodes": 19174, "number_of_timesteps": 6988020, "per_episode_reward": -12.41, "episode_reward_trend_value": 0.005227457376252155, "biggest_recent_change": 0.2123611066525637},
{"total_number_of_episodes": 19186, "number_of_timesteps": 6993315, "per_episode_reward": -12.37, "episode_reward_trend_value": 0.0052891279795632285, "biggest_recent_change": 0.2123611066525637},
{"total_number_of_episodes": 19196, "number_of_timesteps": 6997535, "per_episode_reward": -12.35, "episode_reward_trend_value": 0.004894968152870148, "biggest_recent_change": 0.2123611066525637},
{"total_number_of_episodes": 19206, "number_of_timesteps": 7002100, "per_episode_reward": -12.32, "episode_reward_trend_value": 0.004586865452483756, "biggest_recent_change": 0.2123611066525637},
{"total_number_of_episodes": 19216, "number_of_timesteps": 7006076, "per_episode_reward": -12.29, "episode_reward_trend_value": 0.0025933051612524833, "biggest_recent_change": 0.0476406391822497},
{"total_number_of_episodes": 19226, "number_of_timesteps": 7009917, "per_episode_reward": -12.28, "episode_reward_trend_value": 0.0028018328568297137, "biggest_recent_change": 0.0476406391822497},
{"total_number_of_episodes": 19236, "number_of_timesteps": 7017126, "per_episode_reward": -12.26, "episode_reward_trend_value": 0.0025415671109103935, "biggest_recent_change": 0.0476406391822497},
{"total_number_of_episodes": 19246, "number_of_timesteps": 7019802, "per_episode_reward": -12.21, "episode_reward_trend_value": 0.002835697659679918, "biggest_recent_change": 0.0476406391822497},
{"total_number_of_episodes": 19256, "number_of_timesteps": 7024575, "per_episode_reward": -12.18, "episode_reward_trend_value": 0.0030225195761337136, "biggest_recent_change": 0.0476406391822497},
{"total_number_of_episodes": 19266, "number_of_timesteps": 7028544, "per_episode_reward": -12.11, "episode_reward_trend_value": 0.0033947553481422964, "biggest_recent_change": 0.07238267068439264},
{"total_number_of_episodes": 19276, "number_of_timesteps": 7032409, "per_episode_reward": -12.05, "episode_reward_trend_value": 0.0035644390498411837, "biggest_recent_change": 0.07238267068439264},
{"total_number_of_episodes": 19286, "number_of_timesteps": 7037000, "per_episode_reward": -12.03, "episode_reward_trend_value": 0.00357972691712547, "biggest_recent_change": 0.07238267068439264},
{"total_number_of_episodes": 19296, "number_of_timesteps": 7041278, "per_episode_reward": -11.99, "episode_reward_trend_value": 0.003715304328001206, "biggest_recent_change": 0.07238267068439264},
{"total_number_of_episodes": 19306, "number_of_timesteps": 7047940, "per_episode_reward": -12.01, "episode_reward_trend_value": 0.00315832666590929, "biggest_recent_change": 0.07238267068439264},
{"total_number_of_episodes": 19316, "number_of_timesteps": 7054677, "per_episode_reward": -11.98, "episode_reward_trend_value": 0.0033570186634843875, "biggest_recent_change": 0.07238267068439264},
{"total_number_of_episodes": 19326, "number_of_timesteps": 7062197, "per_episode_reward": -11.91, "episode_reward_trend_value": 0.0038264066158732075, "biggest_recent_change": 0.07238267068439264},
{"total_number_of_episodes": 19336, "number_of_timesteps": 7066700, "per_episode_reward": -11.86, "episode_reward_trend_value": 0.003962250696085077, "biggest_recent_change": 0.07238267068439264},
{"total_number_of_episodes": 19346, "number_of_timesteps": 7070659, "per_episode_reward": -11.82, "episode_reward_trend_value": 0.0040618467609577595, "biggest_recent_change": 0.07238267068439264},
{"total_number_of_episodes": 19356, "number_of_timesteps": 7073408, "per_episode_reward": -11.8, "episode_reward_trend_value": 0.003393115711479232, "biggest_recent_change": 0.06291217233514956},
{"total_number_of_episodes": 19366, "number_of_timesteps": 7076027, "per_episode_reward": -11.76, "episode_reward_trend_value": 0.003129126667357834, "biggest_recent_change": 0.0626244021983684},
{"total_number_of_episodes": 19376, "number_of_timesteps": 7078764, "per_episode_reward": -11.66, "episode_reward_trend_value": 0.00412341095986858, "biggest_recent_change": 0.10780436679703698},
{"total_number_of_episodes": 19386, "number_of_timesteps": 7084275, "per_episode_reward": -11.64, "episode_reward_trend_value": 0.0038714178464946706, "biggest_recent_change": 0.10780436679703698},
{"total_number_of_episodes": 19396, "number_of_timesteps": 7088319, "per_episode_reward": -11.61, "episode_reward_trend_value": 0.004458580104009258, "biggest_recent_change": 0.10780436679703698},
{"total_number_of_episodes": 19407, "number_of_timesteps": 7093039, "per_episode_reward": -11.53, "episode_reward_trend_value": 0.004939127032847898, "biggest_recent_change": 0.10780436679703698},
{"total_number_of_episodes": 19417, "number_of_timesteps": 7098826, "per_episode_reward": -11.51, "episode_reward_trend_value": 0.004551711685303555, "biggest_recent_change": 0.10780436679703698},
{"total_number_of_episodes": 19427, "number_of_timesteps": 7103400, "per_episode_reward": -11.49, "episode_reward_trend_value": 0.004037730889319372, "biggest_recent_change": 0.10780436679703698},
{"total_number_of_episodes": 19437, "number_of_timesteps": 7107382, "per_episode_reward": -11.43, "episode_reward_trend_value": 0.0043280344615361736, "biggest_recent_change": 0.10780436679703698},
{"total_number_of_episodes": 19447, "number_of_timesteps": 7111521, "per_episode_reward": -11.41, "episode_reward_trend_value": 0.004416539399741579, "biggest_recent_change": 0.10780436679703698},
{"total_number_of_episodes": 19457, "number_of_timesteps": 7117607, "per_episode_reward": -11.29, "episode_reward_trend_value": 0.005228516341215636, "biggest_recent_change": 0.1122310830968889},
{"total_number_of_episodes": 19467, "number_of_timesteps": 7125112, "per_episode_reward": -11.22, "episode_reward_trend_value": 0.004858756648588288, "biggest_recent_change": 0.1122310830968889},
{"total_number_of_episodes": 19477, "number_of_timesteps": 7128305, "per_episode_reward": -11.18, "episode_reward_trend_value": 0.005162541594420864, "biggest_recent_change": 0.1122310830968889},
{"total_number_of_episodes": 19487, "number_of_timesteps": 7131201, "per_episode_reward": -11.07, "episode_reward_trend_value": 0.00598657294133612, "biggest_recent_change": 0.1122310830968889},
{"total_number_of_episodes": 19497, "number_of_timesteps": 7135402, "per_episode_reward": -11.04, "episode_reward_trend_value": 0.005527334106035317, "biggest_recent_change": 0.1122310830968889},
{"total_number_of_episodes": 19507, "number_of_timesteps": 7139941, "per_episode_reward": -11.01, "episode_reward_trend_value": 0.005509574148529279, "biggest_recent_change": 0.1122310830968889},

{"total_number_of_episodes": 19517, "number_of_timesteps": 7146709, "per_episode_reward": -10.97, "episode_reward_trend_value": 0.00575511420489511, "biggest_recent_change": 0.1122310830968889},
{"total_number_of_episodes": 19527, "number_of_timesteps": 7152230, "per_episode_reward": -10.98, "episode_reward_trend_value": 0.004968527239847928, "biggest_recent_change": 0.1122310830968889},
{"total_number_of_episodes": 19537, "number_of_timesteps": 7157439, "per_episode_reward": -10.98, "episode_reward_trend_value": 0.004733395336815999, "biggest_recent_change": 0.1122310830968889},
{"total_number_of_episodes": 19547, "number_of_timesteps": 7162653, "per_episode_reward": -10.97, "episode_reward_trend_value": 0.003589330825469518, "biggest_recent_change": 0.10982011525216251},
{"total_number_of_episodes": 19557, "number_of_timesteps": 7165567, "per_episode_reward": -10.94, "episode_reward_trend_value": 0.003071727386608241, "biggest_recent_change": 0.10982011525216251},
{"total_number_of_episodes": 19567, "number_of_timesteps": 7171889, "per_episode_reward": -10.91, "episode_reward_trend_value": 0.0029588099367615565, "biggest_recent_change": 0.10982011525216251},
{"total_number_of_episodes": 19577, "number_of_timesteps": 7176402, "per_episode_reward": -10.86, "episode_reward_trend_value": 0.0023013697511648857, "biggest_recent_change": 0.05065049854846215},
{"total_number_of_episodes": 19587, "number_of_timesteps": 7178533, "per_episode_reward": -10.81, "episode_reward_trend_value": 0.0025357424575597814, "biggest_recent_change": 0.05346258969147577},
{"total_number_of_episodes": 19597, "number_of_timesteps": 7182712, "per_episode_reward": -10.77, "episode_reward_trend_value": 0.002693461945106929, "biggest_recent_change": 0.05346258969147577},
{"total_number_of_episodes": 19607, "number_of_timesteps": 7188156, "per_episode_reward": -10.73, "episode_reward_trend_value": 0.002743465713913275, "biggest_recent_change": 0.05346258969147577},
{"total_number_of_episodes": 19617, "number_of_timesteps": 7193981, "per_episode_reward": -10.67, "episode_reward_trend_value": 0.003463185882891414, "biggest_recent_change": 0.06122518398305665},
{"total_number_of_episodes": 19627, "number_of_timesteps": 7198404, "per_episode_reward": -10.63, "episode_reward_trend_value": 0.003895325227668659, "biggest_recent_change": 0.06122518398305665},
{"total_number_of_episodes": 19637, "number_of_timesteps": 7202361, "per_episode_reward": -10.59, "episode_reward_trend_value": 0.0041784790399638306, "biggest_recent_change": 0.06122518398305665},
{"total_number_of_episodes": 19647, "number_of_timesteps": 7206547, "per_episode_reward": -10.46, "episode_reward_trend_value": 0.005321772335796934, "biggest_recent_change": 0.1308380815880401},
{"total_number_of_episodes": 19657, "number_of_timesteps": 7213861, "per_episode_reward": -10.42, "episode_reward_trend_value": 0.005444611176715972, "biggest_recent_change": 0.1308380815880401},
{"total_number_of_episodes": 19667, "number_of_timesteps": 7216999, "per_episode_reward": -10.37, "episode_reward_trend_value": 0.005421030990995194, "biggest_recent_change": 0.1308380815880401},
{"total_number_of_episodes": 19677, "number_of_timesteps": 7220557, "per_episode_reward": -10.34, "episode_reward_trend_value": 0.005219692980576637, "biggest_recent_change": 0.1308380815880401},
{"total_number_of_episodes": 19687, "number_of_timesteps": 7225076, "per_episode_reward": -10.28, "episode_reward_trend_value": 0.00537182939882407, "biggest_recent_change": 0.1308380815880401},
{"total_number_of_episodes": 19697, "number_of_timesteps": 7229574, "per_episode_reward": -10.28, "episode_reward_trend_value": 0.004922057922826342, "biggest_recent_change": 0.1308380815880401},
{"total_number_of_episodes": 19707, "number_of_timesteps": 7235807, "per_episode_reward": -10.24, "episode_reward_trend_value": 0.004697925345497526, "biggest_recent_change": 0.1308380815880401},
{"total_number_of_episodes": 19717, "number_of_timesteps": 7241426, "per_episode_reward": -10.22, "episode_reward_trend_value": 0.004509654791653301, "biggest_recent_change": 0.1308380815880401},
{"total_number_of_episodes": 19727, "number_of_timesteps": 7243830, "per_episode_reward": -10.21, "episode_reward_trend_value": 0.004316203416287795, "biggest_recent_change": 0.1308380815880401},
{"total_number_of_episodes": 19737, "number_of_timesteps": 7248159, "per_episode_reward": -10.11, "episode_reward_trend_value": 0.0038868225132892677, "biggest_recent_change": 0.09219380031817259},
{"total_number_of_episodes": 19747, "number_of_timesteps": 7251911, "per_episode_reward": -10.05, "episode_reward_trend_value": 0.00407331946136345, "biggest_recent_change": 0.09219380031817259},
{"total_number_of_episodes": 19757, "number_of_timesteps": 7256761, "per_episode_reward": -10.02, "episode_reward_trend_value": 0.003965728055230303, "biggest_recent_change": 0.09219380031817259},
{"total_number_of_episodes": 19767, "number_of_timesteps": 7261642, "per_episode_reward": -9.97, "episode_reward_trend_value": 0.004088111109211133, "biggest_recent_change": 0.09219380031817259},
{"total_number_of_episodes": 19777, "number_of_timesteps": 7264699, "per_episode_reward": -9.95, "episode_reward_trend_value": 0.003651296472604789, "biggest_recent_change": 0.09219380031817259},
{"total_number_of_episodes": 19787, "number_of_timesteps": 7270494, "per_episode_reward": -9.92, "episode_reward_trend_value": 0.00410816765076911, "biggest_recent_change": 0.09219380031817259},
{"total_number_of_episodes": 19797, "number_of_timesteps": 7276564, "per_episode_reward": -9.85, "episode_reward_trend_value": 0.004350499900552348, "biggest_recent_change": 0.09219380031817259},
{"total_number_of_episodes": 19807, "number_of_timesteps": 7280060, "per_episode_reward": -9.82, "episode_reward_trend_value": 0.004505466320424922, "biggest_recent_change": 0.09219380031817259},
{"total_number_of_episodes": 19817, "number_of_timesteps": 7283579, "per_episode_reward": -9.8, "episode_reward_trend_value": 0.004526294949542119, "biggest_recent_change": 0.09219380031817259},
{"total_number_of_episodes": 19827, "number_of_timesteps": 7287947, "per_episode_reward": -9.78, "episode_reward_trend_value": 0.0037093059343590675, "biggest_recent_change": 0.06286315450395463},
{"total_number_of_episodes": 19837, "number_of_timesteps": 7292641, "per_episode_reward": -9.77, "episode_reward_trend_value": 0.0031978920316638416, "biggest_recent_change": 0.06286315450395463},
{"total_number_of_episodes": 19847, "number_of_timesteps": 7297551, "per_episode_reward": -9.73, "episode_reward_trend_value": 0.0032061631653049634, "biggest_recent_change": 0.06286315450395463},
{"total_number_of_episodes": 19857, "number_of_timesteps": 7300891, "per_episode_reward": -9.72, "episode_reward_trend_value": 0.0027931525342007922, "biggest_recent_change": 0.06286315450395463},
{"total_number_of_episodes": 19867, "number_of_timesteps": 7303797, "per_episode_reward": -9.65, "episode_reward_trend_value": 0.003343914104427527, "biggest_recent_change": 0.06430088029118153},
{"total_number_of_episodes": 19877, "number_of_timesteps": 7308295, "per_episode_reward": -9.56, "episode_reward_trend_value": 0.003994500292571522, "biggest_recent_change": 0.09803549242131204},
{"total_number_of_episodes": 19887, "number_of_timesteps": 7310955, "per_episode_reward": -9.54, "episode_reward_trend_value": 0.0034882942549472966, "biggest_recent_change": 0.09803549242131204},
{"total_number_of_episodes": 19897, "number_of_timesteps": 7314679, "per_episode_reward": -9.51, "episode_reward_trend_value": 0.0034019939507121872, "biggest_recent_change": 0.09803549242131204},
{"total_number_of_episodes": 19907, "number_of_timesteps": 7316639, "per_episode_reward": -9.48, "episode_reward_trend_value": 0.003553620189863535, "biggest_recent_change": 0.09803549242131204},
{"total_number_of_episodes": 19917, "number_of_timesteps": 7319023, "per_episode_reward": -9.43, "episode_reward_trend_value": 0.003931573071445607, "biggest_recent_change": 0.09803549242131204},
{"total_number_of_episodes": 19928, "number_of_timesteps": 7321616, "per_episode_reward": -9.42, "episode_reward_trend_value": 0.0038295001295545737, "biggest_recent_change": 0.09803549242131204},
{"total_number_of_episodes": 19938, "number_of_timesteps": 7324034, "per_episode_reward": -9.38, "episode_reward_trend_value": 0.003846372415992564, "biggest_recent_change": 0.09803549242131204},
{"total_number_of_episodes": 19948, "number_of_timesteps": 7326427, "per_episode_reward": -9.34, "episode_reward_trend_value": 0.004193741909945755, "biggest_recent_change": 0.09803549242131204},
{"total_number_of_episodes": 19958, "number_of_timesteps": 7329522, "per_episode_reward": -9.33, "episode_reward_trend_value": 0.0035682001430531094, "biggest_recent_change": 0.09803549242131204},
{"total_number_of_episodes": 19968, "number_of_timesteps": 7334346, "per_episode_reward": -9.28, "episode_reward_trend_value": 0.003084179965733726, "biggest_recent_change": 0.05447367646256751},
{"total_number_of_episodes": 19978, "number_of_timesteps": 7339320, "per_episode_reward": -9.24, "episode_reward_trend_value": 0.0033560032171615676, "biggest_recent_change": 0.05447367646256751},
{"total_number_of_episodes": 19988, "number_of_timesteps": 7343923, "per_episode_reward": -9.15, "episode_reward_trend_value": 0.003967480401737432, "biggest_recent_change": 0.08216153760010947},
{"total_number_of_episodes": 19998, "number_of_timesteps": 7347209, "per_episode_reward": -9.1, "episode_reward_trend_value": 0.004149642980449997, "biggest_recent_change": 0.08216153760010947},
{"total_number_of_episodes": 20008, "number_of_timesteps": 7349711, "per_episode_reward": -9.08, "episode_reward_trend_value": 0.003884788980356567, "biggest_recent_change": 0.08216153760010947},
{"total_number_of_episodes": 20018, "number_of_timesteps": 7352594, "per_episode_reward": -9.02, "episode_reward_trend_value": 0.004463539176216654, "biggest_recent_change": 0.08216153760010947},
{"total_number_of_episodes": 20028, "number_of_timesteps": 7355237, "per_episode_reward": -8.92, "episode_reward_trend_value": 0.005141112200355873, "biggest_recent_change": 0.10208953526125875},
{"total_number_of_episodes": 20038, "number_of_timesteps": 7358376, "per_episode_reward": -8.91, "episode_reward_trend_value": 0.004770686499731763, "biggest_recent_change": 0.10208953526125875},
{"total_number_of_episodes": 20048, "number_of_timesteps": 7360973, "per_episode_reward": -8.88, "episode_reward_trend_value": 0.004975231993593986, "biggest_recent_change": 0.10208953526125875},
{"total_number_of_episodes": 20059, "number_of_timesteps": 7365645, "per_episode_reward": -8.83, "episode_reward_trend_value": 0.004977006540309089, "biggest_recent_change": 0.10208953526125875},
{"total_number_of_episodes": 20069, "number_of_timesteps": 7369556, "per_episode_reward": -8.82, "episode_reward_trend_value": 0.004602747544148716, "biggest_recent_change": 0.10208953526125875},
{"total_number_of_episodes": 20079, "number_of_timesteps": 7376588, "per_episode_reward": -8.8, "episode_reward_trend_value": 0.003975272634159231, "biggest_recent_change": 0.10208953526125875},
{"total_number_of_episodes": 20089, "number_of_timesteps": 7379732, "per_episode_reward": -8.78, "episode_reward_trend_value": 0.0036388977620627158, "biggest_recent_change": 0.10208953526125875},
{"total_number_of_episodes": 20099, "number_of_timesteps": 7386243, "per_episode_reward": -8.72, "episode_reward_trend_value": 0.003940140806637062, "biggest_recent_change": 0.10208953526125875},
{"total_number_of_episodes": 20109, "number_of_timesteps": 7391779, "per_episode_reward": -8.68, "episode_reward_trend_value": 0.003745528063903711, "biggest_recent_change": 0.10208953526125875},
{"total_number_of_episodes": 20119, "number_of_timesteps": 7396162, "per_episode_reward": -8.62, "episode_reward_trend_value": 0.003350938574630291, "biggest_recent_change": 0.06657648122665094},
{"total_number_of_episodes": 20129, "number_of_timesteps": 7400298, "per_episode_reward": -8.59, "episode_reward_trend_value": 0.003532203667660245, "biggest_recent_change": 0.06657648122665094},
{"total_number_of_episodes": 20139, "number_of_timesteps": 7404593, "per_episode_reward": -8.53, "episode_reward_trend_value": 0.0039245227915517865, "biggest_recent_change": 0.06657648122665094},
{"total_number_of_episodes": 20149, "number_of_timesteps": 7409980, "per_episode_reward": -8.52, "episode_reward_trend_value": 0.003424418414269602, "biggest_recent_change": 0.06657648122665094},
{"total_number_of_episodes": 20159, "number_of_timesteps": 7412039, "per_episode_reward": -8.33, "episode_reward_trend_value": 0.005485668646287915, "biggest_recent_change": 0.19359791497349477},
{"total_number_of_episodes": 20169, "number_of_timesteps": 7415415, "per_episode_reward": -8.29, "episode_reward_trend_value": 0.005654547978245243, "biggest_recent_change": 0.19359791497349477},
{"total_number_of_episodes": 20179, "number_of_timesteps": 7420459, "per_episode_reward": -8.24, "episode_reward_trend_value": 0.005947902073933283, "biggest_recent_change": 0.19359791497349477},
{"total_number_of_episodes": 20189, "number_of_timesteps": 7424252, "per_episode_reward": -8.17, "episode_reward_trend_value": 0.006166530249698493, "biggest_recent_change": 0.19359791497349477},
{"total_number_of_episodes": 20199, "number_of_timesteps": 7429975, "per_episode_reward": -8.13, "episode_reward_trend_value": 0.006148272420149464, "biggest_recent_change": 0.19359791497349477},
{"total_number_of_episodes": 20209, "number_of_timesteps": 7435505, "per_episode_reward": -8.08, "episode_reward_trend_value": 0.00601780667947573, "biggest_recent_change": 0.19359791497349477},
{"total_number_of_episodes": 20219, "number_of_timesteps": 7439761, "per_episode_reward": -8.08, "episode_reward_trend_value": 0.005659636876169374, "biggest_recent_change": 0.19359791497349477},
{"total_number_of_episodes": 20229, "number_of_timesteps": 7442698, "per_episode_reward": -8.03, "episode_reward_trend_value": 0.005520375368989446, "biggest_recent_change": 0.19359791497349477},
{"total_number_of_episodes": 20239, "number_of_timesteps": 7446911, "per_episode_reward": -8.0, "episode_reward_trend_value": 0.005808688552270672, "biggest_recent_change": 0.19359791497349477},
{"total_number_of_episodes": 20249, "number_of_timesteps": 7454051, "per_episode_reward": -7.98, "episode_reward_trend_value": 0.0038792973583330636, "biggest_recent_change": 0.07563209811623572},
{"total_number_of_episodes": 20259, "number_of_timesteps": 7458282, "per_episode_reward": -7.97, "episode_reward_trend_value": 0.003556015843611525, "biggest_recent_change": 0.07563209811623572},
{"total_number_of_episodes": 20269, "number_of_timesteps": 7461403, "per_episode_reward": -7.99, "episode_reward_trend_value": 0.0028182883869936207, "biggest_recent_change": 0.07563209811623572},
{"total_number_of_episodes": 20279, "number_of_timesteps": 7464646, "per_episode_reward": -7.94, "episode_reward_trend_value": 0.0025466389540879913, "biggest_recent_change": 0.054834564566014876},
{"total_number_of_episodes": 20289, "number_of_timesteps": 7466693, "per_episode_reward": -7.88, "episode_reward_trend_value": 0.002737190416278443, "biggest_recent_change": 0.054834564566014876},
{"total_number_of_episodes": 20299, "number_of_timesteps": 7469157, "per_episode_reward": -7.87, "episode_reward_trend_value": 0.002225545139255638, "biggest_recent_change": 0.05364910760085273},

{"total_number_of_episodes": 20309, "number_of_timesteps": 7472249, "per_episode_reward": -7.83, "episode_reward_trend_value": 0.002838972780630922, "biggest_recent_change": 0.05364910760085273},
{"total_number_of_episodes": 20319, "number_of_timesteps": 7475461, "per_episode_reward": -7.79, "episode_reward_trend_value": 0.0027691304653898663, "biggest_recent_change": 0.05364910760085273},
{"total_number_of_episodes": 20329, "number_of_timesteps": 7478071, "per_episode_reward": -7.78, "episode_reward_trend_value": 0.0024715766129112045, "biggest_recent_change": 0.05364910760085273},
{"total_number_of_episodes": 20339, "number_of_timesteps": 7480793, "per_episode_reward": -7.77, "episode_reward_trend_value": 0.002323492454019692, "biggest_recent_change": 0.05364910760085273},
{"total_number_of_episodes": 20349, "number_of_timesteps": 7483574, "per_episode_reward": -7.75, "episode_reward_trend_value": 0.0024376391896985556, "biggest_recent_change": 0.05364910760085273},
{"total_number_of_episodes": 20359, "number_of_timesteps": 7487191, "per_episode_reward": -7.69, "episode_reward_trend_value": 0.003276728194878577, "biggest_recent_change": 0.05450473612150297},
{"total_number_of_episodes": 20369, "number_of_timesteps": 7489387, "per_episode_reward": -7.68, "episode_reward_trend_value": 0.002866961989014695, "biggest_recent_change": 0.05450473612150297},
{"total_number_of_episodes": 20379, "number_of_timesteps": 7493364, "per_episode_reward": -7.65, "episode_reward_trend_value": 0.002557767625176588, "biggest_recent_change": 0.05450473612150297},
{"total_number_of_episodes": 20389, "number_of_timesteps": 7498811, "per_episode_reward": -7.62, "episode_reward_trend_value": 0.002882337918869639, "biggest_recent_change": 0.05450473612150297},
{"total_number_of_episodes": 20399, "number_of_timesteps": 7503255, "per_episode_reward": -7.56, "episode_reward_trend_value": 0.002954420447613939, "biggest_recent_change": 0.05450473612150297},
{"total_number_of_episodes": 20409, "number_of_timesteps": 7505290, "per_episode_reward": -7.55, "episode_reward_trend_value": 0.002607747517934131, "biggest_recent_change": 0.05450473612150297},
{"total_number_of_episodes": 20419, "number_of_timesteps": 7506941, "per_episode_reward": -7.55, "episode_reward_trend_value": 0.002466100436317949, "biggest_recent_change": 0.05450473612150297},
{"total_number_of_episodes": 20429, "number_of_timesteps": 7509400, "per_episode_reward": -7.52, "episode_reward_trend_value": 0.0027400754090900923, "biggest_recent_change": 0.05450473612150297},
{"total_number_of_episodes": 20439, "number_of_timesteps": 7512409, "per_episode_reward": -7.47, "episode_reward_trend_value": 0.003044662442076154, "biggest_recent_change": 0.05450473612150297},
{"total_number_of_episodes": 20449, "number_of_timesteps": 7515820, "per_episode_reward": -7.43, "episode_reward_trend_value": 0.0029101284885246674, "biggest_recent_change": 0.05288511959820852},
{"total_number_of_episodes": 20459, "number_of_timesteps": 7520145, "per_episode_reward": -7.39, "episode_reward_trend_value": 0.0032219010615099366, "biggest_recent_change": 0.05288511959820852},
{"total_number_of_episodes": 20469, "number_of_timesteps": 7523557, "per_episode_reward": -7.4, "episode_reward_trend_value": 0.0028537687454753603, "biggest_recent_change": 0.05288511959820852},
{"total_number_of_episodes": 20479, "number_of_timesteps": 7527962, "per_episode_reward": -7.37, "episode_reward_trend_value": 0.002673263839377851, "biggest_recent_change": 0.05288511959820852},
{"total_number_of_episodes": 20489, "number_of_timesteps": 7534314, "per_episode_reward": -7.32, "episode_reward_trend_value": 0.0027474014555335475, "biggest_recent_change": 0.05955750505222124},
{"total_number_of_episodes": 20499, "number_of_timesteps": 7538877, "per_episode_reward": -7.28, "episode_reward_trend_value": 0.003023606656767994, "biggest_recent_change": 0.05955750505222124},
{"total_number_of_episodes": 20509, "number_of_timesteps": 7541493, "per_episode_reward": -7.26, "episode_reward_trend_value": 0.0033133823324907516, "biggest_recent_change": 0.05955750505222124},
{"total_number_of_episodes": 20519, "number_of_timesteps": 7546276, "per_episode_reward": -7.23, "episode_reward_trend_value": 0.003297115725601824, "biggest_recent_change": 0.05955750505222124},
{"total_number_of_episodes": 20529, "number_of_timesteps": 7550816, "per_episode_reward": -7.18, "episode_reward_trend_value": 0.003229124306952337, "biggest_recent_change": 0.05955750505222124},
{"total_number_of_episodes": 20539, "number_of_timesteps": 7555356, "per_episode_reward": -7.1, "episode_reward_trend_value": 0.0036442788905688118, "biggest_recent_change": 0.07976059282735193},
{"total_number_of_episodes": 20549, "number_of_timesteps": 7559702, "per_episode_reward": -7.07, "episode_reward_trend_value": 0.0035669287205001704, "biggest_recent_change": 0.07976059282735193},
{"total_number_of_episodes": 20559, "number_of_timesteps": 7564470, "per_episode_reward": -7.08, "episode_reward_trend_value": 0.003536731908007557, "biggest_recent_change": 0.07976059282735193},
{"total_number_of_episodes": 20569, "number_of_timesteps": 7569605, "per_episode_reward": -7.07, "episode_reward_trend_value": 0.003368301892747451, "biggest_recent_change": 0.07976059282735193},
{"total_number_of_episodes": 20579, "number_of_timesteps": 7574327, "per_episode_reward": -7.05, "episode_reward_trend_value": 0.002924681973967975, "biggest_recent_change": 0.07976059282735193},
{"total_number_of_episodes": 20589, "number_of_timesteps": 7580117, "per_episode_reward": -6.99, "episode_reward_trend_value": 0.0032614227073089015, "biggest_recent_change": 0.07976059282735193},
{"total_number_of_episodes": 20599, "number_of_timesteps": 7583123, "per_episode_reward": -6.95, "episode_reward_trend_value": 0.0034249078525048562, "biggest_recent_change": 0.07976059282735193},
{"total_number_of_episodes": 20609, "number_of_timesteps": 7589168, "per_episode_reward": -6.84, "episode_reward_trend_value": 0.0043503786414523914, "biggest_recent_change": 0.11311125715364145},
{"total_number_of_episodes": 20619, "number_of_timesteps": 7593938, "per_episode_reward": -6.82, "episode_reward_trend_value": 0.004091026287089861, "biggest_recent_change": 0.11311125715364145},
{"total_number_of_episodes": 20629, "number_of_timesteps": 7597943, "per_episode_reward": -6.79, "episode_reward_trend_value": 0.003481877036671202, "biggest_recent_change": 0.11311125715364145},
{"total_number_of_episodes": 20639, "number_of_timesteps": 7601370, "per_episode_reward": -6.75, "episode_reward_trend_value": 0.0035922524799474826, "biggest_recent_change": 0.11311125715364145},
{"total_number_of_episodes": 20649, "number_of_timesteps": 7603212, "per_episode_reward": -6.73, "episode_reward_trend_value": 0.0038300210065576835, "biggest_recent_change": 0.11311125715364145},
{"total_number_of_episodes": 20659, "number_of_timesteps": 7604854, "per_episode_reward": -6.72, "episode_reward_trend_value": 0.003929466499771757, "biggest_recent_change": 0.11311125715364145},
{"total_number_of_episodes": 20669, "number_of_timesteps": 7607464, "per_episode_reward": -6.62, "episode_reward_trend_value": 0.004806854462748441, "biggest_recent_change": 0.11311125715364145},
{"total_number_of_episodes": 20679, "number_of_timesteps": 7610483, "per_episode_reward": -6.55, "episode_reward_trend_value": 0.0048283145162247385, "biggest_recent_change": 0.11311125715364145},
{"total_number_of_episodes": 20690, "number_of_timesteps": 7614269, "per_episode_reward": -6.53, "episode_reward_trend_value": 0.004700407827706984, "biggest_recent_change": 0.11311125715364145},
{"total_number_of_episodes": 20700, "number_of_timesteps": 7617592, "per_episode_reward": -6.49, "episode_reward_trend_value": 0.0038054742288789454, "biggest_recent_change": 0.09859662902997002},
{"total_number_of_episodes": 20710, "number_of_timesteps": 7619965, "per_episode_reward": -6.46, "episode_reward_trend_value": 0.003940043719135734, "biggest_recent_change": 0.09859662902997002},
{"total_number_of_episodes": 20720, "number_of_timesteps": 7624374, "per_episode_reward": -6.42, "episode_reward_trend_value": 0.004059801844501227, "biggest_recent_change": 0.09859662902997002},
{"total_number_of_episodes": 20730, "number_of_timesteps": 7627916, "per_episode_reward": -6.42, "episode_reward_trend_value": 0.003661855512686913, "biggest_recent_change": 0.09859662902997002},
{"total_number_of_episodes": 20740, "number_of_timesteps": 7631209, "per_episode_reward": -6.37, "episode_reward_trend_value": 0.004088399096956794, "biggest_recent_change": 0.09859662902997002},
{"total_number_of_episodes": 20750, "number_of_timesteps": 7636564, "per_episode_reward": -6.32, "episode_reward_trend_value": 0.00442222961821083, "biggest_recent_change": 0.09859662902997002},
{"total_number_of_episodes": 20760, "number_of_timesteps": 7640312, "per_episode_reward": -6.28, "episode_reward_trend_value": 0.0037857888379922815, "biggest_recent_change": 0.06879656810426127},
{"total_number_of_episodes": 20770, "number_of_timesteps": 7643093, "per_episode_reward": -6.24, "episode_reward_trend_value": 0.0034498525098838823, "biggest_recent_change": 0.0497600832671834},
{"total_number_of_episodes": 20781, "number_of_timesteps": 7647135, "per_episode_reward": -6.22, "episode_reward_trend_value": 0.0033657541213796766, "biggest_recent_change": 0.0497600832671834},
{"total_number_of_episodes": 20791, "number_of_timesteps": 7650912, "per_episode_reward": -6.18, "episode_reward_trend_value": 0.0034638072326430543, "biggest_recent_change": 0.0497600832671834},
{"total_number_of_episodes": 20801, "number_of_timesteps": 7656650, "per_episode_reward": -6.13, "episode_reward_trend_value": 0.0036823573331472917, "biggest_recent_change": 0.05179846202953087},
{"total_number_of_episodes": 20811, "number_of_timesteps": 7662387, "per_episode_reward": -6.15, "episode_reward_trend_value": 0.0030371231730499677, "biggest_recent_change": 0.05179846202953087},
{"total_number_of_episodes": 20821, "number_of_timesteps": 7665422, "per_episode_reward": -6.12, "episode_reward_trend_value": 0.0032362372094585667, "biggest_recent_change": 0.05179846202953087},
{"total_number_of_episodes": 20831, "number_of_timesteps": 7670407, "per_episode_reward": -6.04, "episode_reward_trend_value": 0.003671375229924786, "biggest_recent_change": 0.08892250510914312},
{"total_number_of_episodes": 20841, "number_of_timesteps": 7674506, "per_episode_reward": -6.02, "episode_reward_trend_value": 0.0033657610198989637, "biggest_recent_change": 0.08892250510914312},
{"total_number_of_episodes": 20851, "number_of_timesteps": 7678010, "per_episode_reward": -5.88, "episode_reward_trend_value": 0.004452629499572078, "biggest_recent_change": 0.13913512198088096},
{"total_number_of_episodes": 20862, "number_of_timesteps": 7681967, "per_episode_reward": -5.86, "episode_reward_trend_value": 0.0042662922119406, "biggest_recent_change": 0.13913512198088096},
{"total_number_of_episodes": 20872, "number_of_timesteps": 7685918, "per_episode_reward": -5.83, "episode_reward_trend_value": 0.004323757367566886, "biggest_recent_change": 0.13913512198088096},
{"total_number_of_episodes": 20882, "number_of_timesteps": 7689631, "per_episode_reward": -5.79, "episode_reward_trend_value": 0.0043019838500406435, "biggest_recent_change": 0.13913512198088096},
{"total_number_of_episodes": 20892, "number_of_timesteps": 7693319, "per_episode_reward": -5.75, "episode_reward_trend_value": 0.004215209148836458, "biggest_recent_change": 0.13913512198088096},
{"total_number_of_episodes": 20902, "number_of_timesteps": 7696733, "per_episode_reward": -5.71, "episode_reward_trend_value": 0.004944431560538693, "biggest_recent_change": 0.13913512198088096},
{"total_number_of_episodes": 20913, "number_of_timesteps": 7701991, "per_episode_reward": -5.65, "episode_reward_trend_value": 0.005215724047904096, "biggest_recent_change": 0.13913512198088096},
{"total_number_of_episodes": 20923, "number_of_timesteps": 7706465, "per_episode_reward": -5.66, "episode_reward_trend_value": 0.004213410470698313, "biggest_recent_change": 0.13913512198088096},
{"total_number_of_episodes": 20933, "number_of_timesteps": 7712580, "per_episode_reward": -5.65, "episode_reward_trend_value": 0.0040579968624248315, "biggest_recent_change": 0.13913512198088096},
{"total_number_of_episodes": 20943, "number_of_timesteps": 7719065, "per_episode_reward": -5.66, "episode_reward_trend_value": 0.0024414874409855497, "biggest_recent_change": 0.051857914060713384},
{"total_number_of_episodes": 20953, "number_of_timesteps": 7723267, "per_episode_reward": -5.71, "episode_reward_trend_value": 0.0016325042580206766, "biggest_recent_change": 0.051857914060713384},
{"total_number_of_episodes": 20963, "number_of_timesteps": 7725632, "per_episode_reward": -5.67, "episode_reward_trend_value": 0.0017940883489691868, "biggest_recent_change": 0.051857914060713384},
{"total_number_of_episodes": 20973, "number_of_timesteps": 7729583, "per_episode_reward": -5.61, "episode_reward_trend_value": 0.002084660568281175, "biggest_recent_change": 0.06558389643353912},
{"total_number_of_episodes": 20984, "number_of_timesteps": 7734802, "per_episode_reward": -5.55, "episode_reward_trend_value": 0.002213324589446625, "biggest_recent_change": 0.06558389643353912},
{"total_number_of_episodes": 20994, "number_of_timesteps": 7738169, "per_episode_reward": -5.5, "episode_reward_trend_value": 0.00231405280995933, "biggest_recent_change": 0.06558389643353912},
{"total_number_of_episodes": 21004, "number_of_timesteps": 7742517, "per_episode_reward": -5.55, "episode_reward_trend_value": 0.0012163155282391043, "biggest_recent_change": 0.06558389643353912},
{"total_number_of_episodes": 21014, "number_of_timesteps": 7747348, "per_episode_reward": -5.5, "episode_reward_trend_value": 0.0017188962161337844, "biggest_recent_change": 0.06558389643353912},
{"total_number_of_episodes": 21024, "number_of_timesteps": 7750265, "per_episode_reward": -5.48, "episode_reward_trend_value": 0.0018992536846491506, "biggest_recent_change": 0.06558389643353912},
{"total_number_of_episodes": 21034, "number_of_timesteps": 7755105, "per_episode_reward": -5.45, "episode_reward_trend_value": 0.00227884048285722, "biggest_recent_change": 0.06558389643353912},
{"total_number_of_episodes": 21044, "number_of_timesteps": 7758058, "per_episode_reward": -5.34, "episode_reward_trend_value": 0.00409298565195363, "biggest_recent_change": 0.11225652143951059},
{"total_number_of_episodes": 21055, "number_of_timesteps": 7762075, "per_episode_reward": -5.33, "episode_reward_trend_value": 0.0037898953207146217, "biggest_recent_change": 0.11225652143951059},
{"total_number_of_episodes": 21065, "number_of_timesteps": 7764436, "per_episode_reward": -5.34, "episode_reward_trend_value": 0.0029308161914223894, "biggest_recent_change": 0.11225652143951059},
{"total_number_of_episodes": 21075, "number_of_timesteps": 7770588, "per_episode_reward": -5.27, "episode_reward_trend_value": 0.0030750202577692182, "biggest_recent_change": 0.11225652143951059},
{"total_number_of_episodes": 21085, "number_of_timesteps": 7773515, "per_episode_reward": -5.26, "episode_reward_trend_value": 0.002634795113188944, "biggest_recent_change": 0.11225652143951059},
{"total_number_of_episodes": 21095, "number_of_timesteps": 7775948, "per_episode_reward": -5.3, "episode_reward_trend_value": 0.0027692387293939587, "biggest_recent_change": 0.11225652143951059},
{"total_number_of_episodes": 21105, "number_of_timesteps": 7778569, "per_episode_reward": -5.23, "episode_reward_trend_value": 0.0029619975101132273, "biggest_recent_change": 0.11225652143951059},
{"total_number_of_episodes": 21115, "number_of_timesteps": 7783233, "per_episode_reward": -5.24, "episode_reward_trend_value": 0.0026647886596107085, "biggest_recent_change": 0.11225652143951059},
{"total_number_of_episodes": 21125, "number_of_timesteps": 7787147, "per_episode_reward": -5.17, "episode_reward_trend_value": 0.0031508179142516273, "biggest_recent_change": 0.11225652143951059},
{"total_number_of_episodes": 21135, "number_of_timesteps": 7792275, "per_episode_reward": -5.07, "episode_reward_trend_value": 0.003003856575410572, "biggest_recent_change": 0.09903000094381564},
{"total_number_of_episodes": 21145, "number_of_timesteps": 7796235, "per_episode_reward": -5.04, "episode_reward_trend_value": 0.0032826173242204207, "biggest_recent_change": 0.09903000094381564},
{"total_number_of_episodes": 21155, "number_of_timesteps": 7800503, "per_episode_reward": -5.04, "episode_reward_trend_value": 0.003312461038891426, "biggest_recent_change": 0.09903000094381564},
{"total_number_of_episodes": 21165, "number_of_timesteps": 7805587, "per_episode_reward": -5.01, "episode_reward_trend_value": 0.0028811508950900037, "biggest_recent_change": 0.09903000094381564},
{"total_number_of_episodes": 21175, "number_of_timesteps": 7811768, "per_episode_reward": -4.95, "episode_reward_trend_value": 0.0034350397708442946, "biggest_recent_change": 0.09903000094381564},
{"total_number_of_episodes": 21187, "number_of_timesteps": 7822149, "per_episode_reward": -4.87, "episode_reward_trend_value": 0.004744407456572958, "biggest_recent_change": 0.09903000094381564},
{"total_number_of_episodes": 21197, "number_of_timesteps": 7827442, "per_episode_reward": -4.81, "episode_reward_trend_value": 0.0046999139514234695, "biggest_recent_change": 0.09903000094381564},
{"total_number_of_episodes": 21207, "number_of_timesteps": 7831826, "per_episode_reward": -4.81, "episode_reward_trend_value": 0.004740431736999165, "biggest_recent_change": 0.09903000094381564},
{"total_number_of_episodes": 21217, "number_of_timesteps": 7835403, "per_episode_reward": -4.78, "episode_reward_trend_value": 0.004288568541413134, "biggest_recent_change": 0.09903000094381564},
{"total_number_of_episodes": 21227, "number_of_timesteps": 7839737, "per_episode_reward": -4.75, "episode_reward_trend_value": 0.003549480475093376, "biggest_recent_change": 0.08300457587992405},
{"total_number_of_episodes": 21237, "number_of_timesteps": 7844171, "per_episode_reward": -4.77, "episode_reward_trend_value": 0.0029623033616193537, "biggest_recent_change": 0.08300457587992405},
{"total_number_of_episodes": 21247, "number_of_timesteps": 7848097, "per_episode_reward": -4.74, "episode_reward_trend_value": 0.003377514397006435, "biggest_recent_change": 0.08300457587992405},
{"total_number_of_episodes": 21258, "number_of_timesteps": 7854391, "per_episode_reward": -4.7, "episode_reward_trend_value": 0.0034911007460084243, "biggest_recent_change": 0.08300457587992405},
{"total_number_of_episodes": 21268, "number_of_timesteps": 7859915, "per_episode_reward": -4.68, "episode_reward_trend_value": 0.003022436997094255, "biggest_recent_change": 0.08300457587992405},
{"total_number_of_episodes": 21278, "number_of_timesteps": 7863766, "per_episode_reward": -4.68, "episode_reward_trend_value": 0.0021511926607736993, "biggest_recent_change": 0.057290419872424},
{"total_number_of_episodes": 21289, "number_of_timesteps": 7867466, "per_episode_reward": -4.67, "episode_reward_trend_value": 0.001555940464560616, "biggest_recent_change": 0.03995172526531032},
{"total_number_of_episodes": 21299, "number_of_timesteps": 7871811, "per_episode_reward": -4.67, "episode_reward_trend_value": 0.0015741271890422897, "biggest_recent_change": 0.03995172526531032},
{"total_number_of_episodes": 21309, "number_of_timesteps": 7875475, "per_episode_reward": -4.58, "episode_reward_trend_value": 0.002253128347388669, "biggest_recent_change": 0.09199713545618593},
{"total_number_of_episodes": 21319, "number_of_timesteps": 7879187, "per_episode_reward": -4.55, "episode_reward_trend_value": 0.0022730648527492783, "biggest_recent_change": 0.09199713545618593},
{"total_number_of_episodes": 21329, "number_of_timesteps": 7881133, "per_episode_reward": -4.52, "episode_reward_trend_value": 0.002804575792327175, "biggest_recent_change": 0.09199713545618593},
{"total_number_of_episodes": 21339, "number_of_timesteps": 7885553, "per_episode_reward": -4.54, "episode_reward_trend_value": 0.002232791962633031, "biggest_recent_change": 0.09199713545618593},
{"total_number_of_episodes": 21349, "number_of_timesteps": 7890030, "per_episode_reward": -4.51, "episode_reward_trend_value": 0.0020719492764223603, "biggest_recent_change": 0.09199713545618593},
{"total_number_of_episodes": 21359, "number_of_timesteps": 7893758, "per_episode_reward": -4.48, "episode_reward_trend_value": 0.0022703511193979216, "biggest_recent_change": 0.09199713545618593},
{"total_number_of_episodes": 21369, "number_of_timesteps": 7897261, "per_episode_reward": -4.45, "episode_reward_trend_value": 0.00250912209576237, "biggest_recent_change": 0.09199713545618593},
{"total_number_of_episodes": 21379, "number_of_timesteps": 7899461, "per_episode_reward": -4.41, "episode_reward_trend_value": 0.002866530820277339, "biggest_recent_change": 0.09199713545618593},
{"total_number_of_episodes": 21389, "number_of_timesteps": 7903288, "per_episode_reward": -4.39, "episode_reward_trend_value": 0.0031194161105980675, "biggest_recent_change": 0.09199713545618593},
{"total_number_of_episodes": 21400, "number_of_timesteps": 7907279, "per_episode_reward": -4.33, "episode_reward_trend_value": 0.002738140948117953, "biggest_recent_change": 0.05768237083297567},
{"total_number_of_episodes": 21410, "number_of_timesteps": 7911228, "per_episode_reward": -4.37, "episode_reward_trend_value": 0.0019196122356214928, "biggest_recent_change": 0.05768237083297567},
{"total_number_of_episodes": 21420, "number_of_timesteps": 7913483, "per_episode_reward": -4.36, "episode_reward_trend_value": 0.0017902226304402288, "biggest_recent_change": 0.05768237083297567},
{"total_number_of_episodes": 21430, "number_of_timesteps": 7918667, "per_episode_reward": -4.32, "episode_reward_trend_value": 0.0024288473954947104, "biggest_recent_change": 0.05768237083297567},
{"total_number_of_episodes": 21440, "number_of_timesteps": 7921068, "per_episode_reward": -4.32, "episode_reward_trend_value": 0.002105494343954008, "biggest_recent_change": 0.05768237083297567},
{"total_number_of_episodes": 21450, "number_of_timesteps": 7923828, "per_episode_reward": -4.28, "episode_reward_trend_value": 0.002119217879953488, "biggest_recent_change": 0.05768237083297567},
{"total_number_of_episodes": 21460, "number_of_timesteps": 7926288, "per_episode_reward": -4.3, "episode_reward_trend_value": 0.0016898747077986737, "biggest_recent_change": 0.05768237083297567},
{"total_number_of_episodes": 21471, "number_of_timesteps": 7931200, "per_episode_reward": -4.27, "episode_reward_trend_value": 0.0016322475435502051, "biggest_recent_change": 0.05768237083297567},
{"total_number_of_episodes": 21481, "number_of_timesteps": 7934468, "per_episode_reward": -4.24, "episode_reward_trend_value": 0.0016647168157455025, "biggest_recent_change": 0.05768237083297567},
{"total_number_of_episodes": 21491, "number_of_timesteps": 7938470, "per_episode_reward": -4.25, "episode_reward_trend_value": 0.0009132080443892083, "biggest_recent_change": 0.03948115657429252},
{"total_number_of_episodes": 21501, "number_of_timesteps": 7942400, "per_episode_reward": -4.24, "episode_reward_trend_value": 0.0015094267133986031, "biggest_recent_change": 0.03948115657429252},
{"total_number_of_episodes": 21511, "number_of_timesteps": 7944604, "per_episode_reward": -4.17, "episode_reward_trend_value": 0.00200701373548083, "biggest_recent_change": 0.06340969273255492},
{"total_number_of_episodes": 21521, "number_of_timesteps": 7947785, "per_episode_reward": -4.16, "episode_reward_trend_value": 0.0017798274435925619, "biggest_recent_change": 0.06340969273255492},
{"total_number_of_episodes": 21531, "number_of_timesteps": 7950343, "per_episode_reward": -4.17, "episode_reward_trend_value": 0.0017492334974870498, "biggest_recent_change": 0.06340969273255492},
{"total_number_of_episodes": 21541, "number_of_timesteps": 7955953, "per_episode_reward": -4.17, "episode_reward_trend_value": 0.0012870965235015457, "biggest_recent_change": 0.06340969273255492},
{"total_number_of_episodes": 21551, "number_of_timesteps": 7960040, "per_episode_reward": -4.17, "episode_reward_trend_value": 0.001407584400782882, "biggest_recent_change": 0.06340969273255492},
{"total_number_of_episodes": 21561, "number_of_timesteps": 7962998, "per_episode_reward": -4.17, "episode_reward_trend_value": 0.0010675661942837126, "biggest_recent_change": 0.06340969273255492},
{"total_number_of_episodes": 21571, "number_of_timesteps": 7966950, "per_episode_reward": -4.18, "episode_reward_trend_value": 0.0006901509522692233, "biggest_recent_change": 0.06340969273255492},
{"total_number_of_episodes": 21581, "number_of_timesteps": 7971429, "per_episode_reward": -4.17, "episode_reward_trend_value": 0.0009614298521824653, "biggest_recent_change": 0.06340969273255492},
{"total_number_of_episodes": 21591, "number_of_timesteps": 7974886, "per_episode_reward": -4.16, "episode_reward_trend_value": 0.000904649940534874, "biggest_recent_change": 0.06340969273255492},
{"total_number_of_episodes": 21601, "number_of_timesteps": 7978875, "per_episode_reward": -4.13, "episode_reward_trend_value": 0.0005121207477120353, "biggest_recent_change": 0.028082065378499443},
{"total_number_of_episodes": 21611, "number_of_timesteps": 7981728, "per_episode_reward": -4.12, "episode_reward_trend_value": 0.0005040623439333302, "biggest_recent_change": 0.028082065378499443},
{"total_number_of_episodes": 21621, "number_of_timesteps": 7984793, "per_episode_reward": -4.09, "episode_reward_trend_value": 0.0008501684219856543, "biggest_recent_change": 0.028082065378499443},
{"total_number_of_episodes": 21631, "number_of_timesteps": 7987670, "per_episode_reward": -4.08, "episode_reward_trend_value": 0.001012744986638984, "biggest_recent_change": 0.028082065378499443},
{"total_number_of_episodes": 21641, "number_of_timesteps": 7990113, "per_episode_reward": -4.02, "episode_reward_trend_value": 0.0016307473245956987, "biggest_recent_change": 0.053905207361365726},
{"total_number_of_episodes": 21651, "number_of_timesteps": 7992193, "per_episode_reward": -4.0, "episode_reward_trend_value": 0.0018739274047310534, "biggest_recent_change": 0.053905207361365726},
{"total_number_of_episodes": 21661, "number_of_timesteps": 7996621, "per_episode_reward": -3.97, "episode_reward_trend_value": 0.0023018997287238404, "biggest_recent_change": 0.053905207361365726},
{"total_number_of_episodes": 21671, "number_of_timesteps": 8000996, "per_episode_reward": -3.97, "episode_reward_trend_value": 0.002180003567343341, "biggest_recent_change": 0.053905207361365726},
{"total_number_of_episodes": 21681, "number_of_timesteps": 8004194, "per_episode_reward": -3.95, "episode_reward_trend_value": 0.002332849997924185, "biggest_recent_change": 0.053905207361365726},
{"total_number_of_episodes": 21691, "number_of_timesteps": 8007993, "per_episode_reward": -3.95, "episode_reward_trend_value": 0.001967719006065553, "biggest_recent_change": 0.053905207361365726},
{"total_number_of_episodes": 21701, "number_of_timesteps": 8011217, "per_episode_reward": -3.94, "episode_reward_trend_value": 0.0019014444812292936, "biggest_recent_change": 0.053905207361365726},
{"total_number_of_episodes": 21711, "number_of_timesteps": 8013934, "per_episode_reward": -3.92, "episode_reward_trend_value": 0.001929181004090023, "biggest_recent_change": 0.053905207361365726},
{"total_number_of_episodes": 21721, "number_of_timesteps": 8018005, "per_episode_reward": -3.9, "episode_reward_trend_value": 0.0019936800550654707, "biggest_recent_change": 0.053905207361365726},
{"total_number_of_episodes": 21731, "number_of_timesteps": 8021463, "per_episode_reward": -3.8, "episode_reward_trend_value": 0.0025108095479283647, "biggest_recent_change": 0.10044686171902617},
{"total_number_of_episodes": 21741, "number_of_timesteps": 8026303, "per_episode_reward": -3.8, "episode_reward_trend_value": 0.0022651534158056406, "biggest_recent_change": 0.10044686171902617},
{"total_number_of_episodes": 21752, "number_of_timesteps": 8030006, "per_episode_reward": -3.75, "episode_reward_trend_value": 0.0024810476884330936, "biggest_recent_change": 0.10044686171902617},
{"total_number_of_episodes": 21762, "number_of_timesteps": 8032745, "per_episode_reward": -3.75, "episode_reward_trend_value": 0.002486602024421325, "biggest_recent_change": 0.10044686171902617},
{"total_number_of_episodes": 21773, "number_of_timesteps": 8035646, "per_episode_reward": -3.74, "episode_reward_trend_value": 0.002320187831372304, "biggest_recent_change": 0.10044686171902617},
{"total_number_of_episodes": 21783, "number_of_timesteps": 8038927, "per_episode_reward": -3.74, "episode_reward_trend_value": 0.002340810621315, "biggest_recent_change": 0.10044686171902617},
{"total_number_of_episodes": 21793, "number_of_timesteps": 8042963, "per_episode_reward": -3.74, "episode_reward_trend_value": 0.0022447933094726035, "biggest_recent_change": 0.10044686171902617},
{"total_number_of_episodes": 21804, "number_of_timesteps": 8048057, "per_episode_reward": -3.76, "episode_reward_trend_value": 0.0017643338607247847, "biggest_recent_change": 0.10044686171902617},
{"total_number_of_episodes": 21814, "number_of_timesteps": 8051405, "per_episode_reward": -3.78, "episode_reward_trend_value": 0.001366420319637518, "biggest_recent_change": 0.10044686171902617},
{"total_number_of_episodes": 21824, "number_of_timesteps": 8055237, "per_episode_reward": -3.75, "episode_reward_trend_value": 0.0004885456688682331, "biggest_recent_change": 0.04852532486662353},
{"total_number_of_episodes": 21834, "number_of_timesteps": 8059240, "per_episode_reward": -3.71, "episode_reward_trend_value": 0.0010258723385387569, "biggest_recent_change": 0.04852532486662353},
{"total_number_of_episodes": 21844, "number_of_timesteps": 8063697, "per_episode_reward": -3.73, "episode_reward_trend_value": 0.00017372629978229032, "biggest_recent_change": 0.04823297964379014},
{"total_number_of_episodes": 21855, "number_of_timesteps": 8070816, "per_episode_reward": -3.74, "episode_reward_trend_value": 2.651001289472414e-05, "biggest_recent_change": 0.04823297964379014},
{"total_number_of_episodes": 21865, "number_of_timesteps": 8075692, "per_episode_reward": -3.77, "episode_reward_trend_value": -0.0003996844236943551, "biggest_recent_change": 0.04823297964379014},
{"total_number_of_episodes": 21875, "number_of_timesteps": 8078525, "per_episode_reward": -3.76, "episode_reward_trend_value": -0.00016397650941947105, "biggest_recent_change": 0.04823297964379014},
{"total_number_of_episodes": 21885, "number_of_timesteps": 8081563, "per_episode_reward": -3.75, "episode_reward_trend_value": -0.00011213664451538523, "biggest_recent_change": 0.04823297964379014},
{"total_number_of_episodes": 21895, "number_of_timesteps": 8086000, "per_episode_reward": -3.77, "episode_reward_trend_value": -0.00012953891198312422, "biggest_recent_change": 0.04823297964379014},
{"total_number_of_episodes": 21905, "number_of_timesteps": 8091083, "per_episode_reward": -3.75, "episode_reward_trend_value": 0.0002859311227372855, "biggest_recent_change": 0.04823297964379014},
{"total_number_of_episodes": 21916, "number_of_timesteps": 8093758, "per_episode_reward": -3.71, "episode_reward_trend_value": 0.0004454673459379727, "biggest_recent_change": 0.04823297964379014},
{"total_number_of_episodes": 21926, "number_of_timesteps": 8097102, "per_episode_reward": -3.66, "episode_reward_trend_value": 0.0005040198317042745, "biggest_recent_change": 0.05350270336275731},
{"total_number_of_episodes": 21936, "number_of_timesteps": 8099154, "per_episode_reward": -3.63, "episode_reward_trend_value": 0.0011504115881228916, "biggest_recent_change": 0.05350270336275731},
{"total_number_of_episodes": 21946, "number_of_timesteps": 8102579, "per_episode_reward": -3.61, "episode_reward_trend_value": 0.0015271013504298725, "biggest_recent_change": 0.05350270336275731},
{"total_number_of_episodes": 21956, "number_of_timesteps": 8105643, "per_episode_reward": -3.58, "episode_reward_trend_value": 0.002125326278072078, "biggest_recent_change": 0.05350270336275731},
{"total_number_of_episodes": 21966, "number_of_timesteps": 8108310, "per_episode_reward": -3.57, "episode_reward_trend_value": 0.0020827119789616996, "biggest_recent_change": 0.05350270336275731},
{"total_number_of_episodes": 21976, "number_of_timesteps": 8112579, "per_episode_reward": -3.55, "episode_reward_trend_value": 0.002280550254417088, "biggest_recent_change": 0.05350270336275731},
{"total_number_of_episodes": 21986, "number_of_timesteps": 8116795, "per_episode_reward": -3.57, "episode_reward_trend_value": 0.002268490921963383, "biggest_recent_change": 0.05350270336275731},
{"total_number_of_episodes": 21996, "number_of_timesteps": 8122793, "per_episode_reward": -3.6, "episode_reward_trend_value": 0.0016696649077010898, "biggest_recent_change": 0.05350270336275731},
{"total_number_of_episodes": 22007, "number_of_timesteps": 8127880, "per_episode_reward": -3.55, "episode_reward_trend_value": 0.0018748033595027784, "biggest_recent_change": 0.05425886390000434},
{"total_number_of_episodes": 22017, "number_of_timesteps": 8130415, "per_episode_reward": -3.53, "episode_reward_trend_value": 0.0014295827241636004, "biggest_recent_change": 0.05425886390000434},
{"total_number_of_episodes": 22027, "number_of_timesteps": 8133527, "per_episode_reward": -3.53, "episode_reward_trend_value": 0.0011643412005368336, "biggest_recent_change": 0.05425886390000434},
{"total_number_of_episodes": 22037, "number_of_timesteps": 8138800, "per_episode_reward": -3.51, "episode_reward_trend_value": 0.001068001133672405, "biggest_recent_change": 0.05425886390000434},
{"total_number_of_episodes": 22048, "number_of_timesteps": 8141455, "per_episode_reward": -3.48, "episode_reward_trend_value": 0.0011836904263101368, "biggest_recent_change": 0.05425886390000434},
{"total_number_of_episodes": 22058, "number_of_timesteps": 8144163, "per_episode_reward": -3.45, "episode_reward_trend_value": 0.0012977112880228562, "biggest_recent_change": 0.05425886390000434},
{"total_number_of_episodes": 22068, "number_of_timesteps": 8146680, "per_episode_reward": -3.45, "episode_reward_trend_value": 0.0010753155552485892, "biggest_recent_change": 0.05425886390000434},
{"total_number_of_episodes": 22078, "number_of_timesteps": 8149836, "per_episode_reward": -3.43, "episode_reward_trend_value": 0.001518559974298597, "biggest_recent_change": 0.05425886390000434},
{"total_number_of_episodes": 22088, "number_of_timesteps": 8151867, "per_episode_reward": -3.42, "episode_reward_trend_value": 0.0020244643394947866, "biggest_recent_change": 0.05425886390000434},
{"total_number_of_episodes": 22098, "number_of_timesteps": 8155144, "per_episode_reward": -3.38, "episode_reward_trend_value": 0.0018724288925773419, "biggest_recent_change": 0.04057567367743431},
{"total_number_of_episodes": 22108, "number_of_timesteps": 8157558, "per_episode_reward": -3.37, "episode_reward_trend_value": 0.0017783722072005057, "biggest_recent_change": 0.04057567367743431},
{"total_number_of_episodes": 22118, "number_of_timesteps": 8160726, "per_episode_reward": -3.35, "episode_reward_trend_value": 0.0019999531622866646, "biggest_recent_change": 0.04057567367743431},
{"total_number_of_episodes": 22128, "number_of_timesteps": 8163923, "per_episode_reward": -3.35, "episode_reward_trend_value": 0.001825371974913888, "biggest_recent_change": 0.04057567367743431},
{"total_number_of_episodes": 22138, "number_of_timesteps": 8168434, "per_episode_reward": -3.36, "episode_reward_trend_value": 0.0013089470837452785, "biggest_recent_change": 0.04057567367743431},
{"total_number_of_episodes": 22148, "number_of_timesteps": 8173435, "per_episode_reward": -3.36, "episode_reward_trend_value": 0.0010574841534733783, "biggest_recent_change": 0.04057567367743431},
{"total_number_of_episodes": 22158, "number_of_timesteps": 8178902, "per_episode_reward": -3.36, "episode_reward_trend_value": 0.00102284349105478, "biggest_recent_change": 0.04057567367743431},

{"total_number_of_episodes": 22168, "number_of_timesteps": 8185533, "per_episode_reward": -3.37, "episode_reward_trend_value": 0.0006203643585647722, "biggest_recent_change": 0.04057567367743431},
{"total_number_of_episodes": 22178, "number_of_timesteps": 8192457, "per_episode_reward": -3.38, "episode_reward_trend_value": 0.0004353458500412848, "biggest_recent_change": 0.04057567367743431},
{"total_number_of_episodes": 22188, "number_of_timesteps": 8195186, "per_episode_reward": -3.39, "episode_reward_trend_value": -0.00014265346000627135, "biggest_recent_change": 0.02607798828756236},
{"total_number_of_episodes": 22198, "number_of_timesteps": 8200079, "per_episode_reward": -3.37, "episode_reward_trend_value": 6.546920571191982e-06, "biggest_recent_change": 0.02607798828756236},
{"total_number_of_episodes": 22209, "number_of_timesteps": 8203701, "per_episode_reward": -3.36, "episode_reward_trend_value": -0.00021084937062388777, "biggest_recent_change": 0.01839577875028775},
{"total_number_of_episodes": 22219, "number_of_timesteps": 8205631, "per_episode_reward": -3.35, "episode_reward_trend_value": -3.869939196413776e-05, "biggest_recent_change": 0.01839577875028775},
{"total_number_of_episodes": 22229, "number_of_timesteps": 8208749, "per_episode_reward": -3.34, "episode_reward_trend_value": 0.00019485767023743605, "biggest_recent_change": 0.01839577875028775},
{"total_number_of_episodes": 22239, "number_of_timesteps": 8211396, "per_episode_reward": -3.33, "episode_reward_trend_value": 0.00027934696085492783, "biggest_recent_change": 0.01839577875028775},
{"total_number_of_episodes": 22249, "number_of_timesteps": 8213849, "per_episode_reward": -3.31, "episode_reward_trend_value": 0.0005038203401805596, "biggest_recent_change": 0.01839577875028775},
{"total_number_of_episodes": 22259, "number_of_timesteps": 8217219, "per_episode_reward": -3.3, "episode_reward_trend_value": 0.000832532847309918, "biggest_recent_change": 0.01839577875028775},
{"total_number_of_episodes": 22269, "number_of_timesteps": 8221439, "per_episode_reward": -3.3, "episode_reward_trend_value": 0.0008808631240420381, "biggest_recent_change": 0.01839577875028775},
{"total_number_of_episodes": 22280, "number_of_timesteps": 8226284, "per_episode_reward": -3.29, "episode_reward_trend_value": 0.0011046370580782097, "biggest_recent_change": 0.01839577875028775},
{"total_number_of_episodes": 22290, "number_of_timesteps": 8230079, "per_episode_reward": -3.28, "episode_reward_trend_value": 0.0009909611583547354, "biggest_recent_change": 0.018099459778091465},
{"total_number_of_episodes": 22300, "number_of_timesteps": 8234422, "per_episode_reward": -3.28, "episode_reward_trend_value": 0.000980105520210792, "biggest_recent_change": 0.018099459778091465},
{"total_number_of_episodes": 22310, "number_of_timesteps": 8236967, "per_episode_reward": -3.26, "episode_reward_trend_value": 0.0010152856089843867, "biggest_recent_change": 0.018920324093196772},
{"total_number_of_episodes": 22320, "number_of_timesteps": 8239460, "per_episode_reward": -3.22, "episode_reward_trend_value": 0.001313227576507408, "biggest_recent_change": 0.03521861887545308},
{"total_number_of_episodes": 22330, "number_of_timesteps": 8241080, "per_episode_reward": -3.2, "episode_reward_trend_value": 0.0014742115194735957, "biggest_recent_change": 0.03521861887545308},
{"total_number_of_episodes": 22340, "number_of_timesteps": 8244353, "per_episode_reward": -3.19, "episode_reward_trend_value": 0.0013560183017646684, "biggest_recent_change": 0.03521861887545308},
{"total_number_of_episodes": 22350, "number_of_timesteps": 8247370, "per_episode_reward": -3.15, "episode_reward_trend_value": 0.0016300822381760324, "biggest_recent_change": 0.03929234912919677},
{"total_number_of_episodes": 22360, "number_of_timesteps": 8251448, "per_episode_reward": -3.13, "episode_reward_trend_value": 0.0018482841601163487, "biggest_recent_change": 0.03929234912919677},
{"total_number_of_episodes": 22371, "number_of_timesteps": 8254878, "per_episode_reward": -3.07, "episode_reward_trend_value": 0.0024330344138244037, "biggest_recent_change": 0.06132291267013468},
{"total_number_of_episodes": 22381, "number_of_timesteps": 8258467, "per_episode_reward": -3.1, "episode_reward_trend_value": 0.0020766851003204165, "biggest_recent_change": 0.06132291267013468},
{"total_number_of_episodes": 22391, "number_of_timesteps": 8261458, "per_episode_reward": -3.09, "episode_reward_trend_value": 0.0020458049205284426, "biggest_recent_change": 0.06132291267013468},
{"total_number_of_episodes": 22401, "number_of_timesteps": 8265540, "per_episode_reward": -3.03, "episode_reward_trend_value": 0.0025512576508832058, "biggest_recent_change": 0.06441106982512546},
{"total_number_of_episodes": 22412, "number_of_timesteps": 8268627, "per_episode_reward": -3.0, "episode_reward_trend_value": 0.0025202891046339202, "biggest_recent_change": 0.06441106982512546},
{"total_number_of_episodes": 22422, "number_of_timesteps": 8271590, "per_episode_reward": -2.99, "episode_reward_trend_value": 0.002275753817219734, "biggest_recent_change": 0.06441106982512546},
{"total_number_of_episodes": 22432, "number_of_timesteps": 8274756, "per_episode_reward": -3.01, "episode_reward_trend_value": 0.002037800619410859, "biggest_recent_change": 0.06441106982512546},
{"total_number_of_episodes": 22442, "number_of_timesteps": 8277076, "per_episode_reward": -3.01, "episode_reward_trend_value": 0.001582111192593451, "biggest_recent_change": 0.06441106982512546},
{"total_number_of_episodes": 22452, "number_of_timesteps": 8280890, "per_episode_reward": -2.98, "episode_reward_trend_value": 0.00164216302560282, "biggest_recent_change": 0.06441106982512546},
{"total_number_of_episodes": 22463, "number_of_timesteps": 8285147, "per_episode_reward": -2.94, "episode_reward_trend_value": 0.0014375170906313303, "biggest_recent_change": 0.06441106982512546},
{"total_number_of_episodes": 22473, "number_of_timesteps": 8288540, "per_episode_reward": -2.87, "episode_reward_trend_value": 0.002481788811745202, "biggest_recent_change": 0.07007796446006465},
{"total_number_of_episodes": 22483, "number_of_timesteps": 8292353, "per_episode_reward": -2.85, "episode_reward_trend_value": 0.0027349462493470355, "biggest_recent_change": 0.07007796446006465},
{"total_number_of_episodes": 22493, "number_of_timesteps": 8296830, "per_episode_reward": -2.83, "episode_reward_trend_value": 0.0022386067373423154, "biggest_recent_change": 0.07007796446006465},
{"total_number_of_episodes": 22503, "number_of_timesteps": 8299064, "per_episode_reward": -2.83, "episode_reward_trend_value": 0.00187176283145135, "biggest_recent_change": 0.07007796446006465},
{"total_number_of_episodes": 22513, "number_of_timesteps": 8303151, "per_episode_reward": -2.87, "episode_reward_trend_value": 0.0014051671266271863, "biggest_recent_change": 0.07007796446006465},
{"total_number_of_episodes": 22523, "number_of_timesteps": 8307605, "per_episode_reward": -2.87, "episode_reward_trend_value": 0.0015145338369060043, "biggest_recent_change": 0.07007796446006465},
{"total_number_of_episodes": 22533, "number_of_timesteps": 8311056, "per_episode_reward": -2.88, "episode_reward_trend_value": 0.001479993359569878, "biggest_recent_change": 0.07007796446006465},
{"total_number_of_episodes": 22543, "number_of_timesteps": 8313715, "per_episode_reward": -2.82, "episode_reward_trend_value": 0.0018599842995857992, "biggest_recent_change": 0.07007796446006465},
{"total_number_of_episodes": 22554, "number_of_timesteps": 8318066, "per_episode_reward": -2.79, "episode_reward_trend_value": 0.0017314137048711222, "biggest_recent_change": 0.07007796446006465},
{"total_number_of_episodes": 22564, "number_of_timesteps": 8322185, "per_episode_reward": -2.75, "episode_reward_trend_value": 0.0013412798751257634, "biggest_recent_change": 0.05848285201890224},
{"total_number_of_episodes": 22574, "number_of_timesteps": 8324737, "per_episode_reward": -2.7, "episode_reward_trend_value": 0.0016021908573518682, "biggest_recent_change": 0.05848285201890224},
{"total_number_of_episodes": 22584, "number_of_timesteps": 8327871, "per_episode_reward": -2.67, "episode_reward_trend_value": 0.0017078069772500123, "biggest_recent_change": 0.05848285201890224},
{"total_number_of_episodes": 22594, "number_of_timesteps": 8333000, "per_episode_reward": -2.64, "episode_reward_trend_value": 0.002129184205670878, "biggest_recent_change": 0.05848285201890224},
{"total_number_of_episodes": 22604, "number_of_timesteps": 8338146, "per_episode_reward": -2.58, "episode_reward_trend_value": 0.003216045820784736, "biggest_recent_change": 0.05848285201890224},
{"total_number_of_episodes": 22614, "number_of_timesteps": 8342954, "per_episode_reward": -2.52, "episode_reward_trend_value": 0.003875228022407759, "biggest_recent_change": 0.05848285201890224},
{"total_number_of_episodes": 22624, "number_of_timesteps": 8347402, "per_episode_reward": -2.51, "episode_reward_trend_value": 0.0040403376313562795, "biggest_recent_change": 0.05848285201890224},
{"total_number_of_episodes": 22634, "number_of_timesteps": 8351940, "per_episode_reward": -2.45, "episode_reward_trend_value": 0.004053017257058484, "biggest_recent_change": 0.059624018332100626},
{"total_number_of_episodes": 22644, "number_of_timesteps": 8354833, "per_episode_reward": -2.43, "episode_reward_trend_value": 0.0039585214388601995, "biggest_recent_change": 0.059624018332100626},
{"total_number_of_episodes": 22654, "number_of_timesteps": 8359244, "per_episode_reward": -2.42, "episode_reward_trend_value": 0.003655234055185365, "biggest_recent_change": 0.059624018332100626},
{"total_number_of_episodes": 22664, "number_of_timesteps": 8363867, "per_episode_reward": -2.44, "episode_reward_trend_value": 0.0029231551930935557, "biggest_recent_change": 0.059624018332100626},
{"total_number_of_episodes": 22674, "number_of_timesteps": 8366708, "per_episode_reward": -2.41, "episode_reward_trend_value": 0.0029636851067993014, "biggest_recent_change": 0.059624018332100626},
{"total_number_of_episodes": 22684, "number_of_timesteps": 8370760, "per_episode_reward": -2.37, "episode_reward_trend_value": 0.0029995819183599613, "biggest_recent_change": 0.059624018332100626},
{"total_number_of_episodes": 22694, "number_of_timesteps": 8373151, "per_episode_reward": -2.42, "episode_reward_trend_value": 0.0017644227379916444, "biggest_recent_change": 0.059624018332100626},
{"total_number_of_episodes": 22704, "number_of_timesteps": 8376824, "per_episode_reward": -2.42, "episode_reward_trend_value": 0.001179085894886874, "biggest_recent_change": 0.059624018332100626},
{"total_number_of_episodes": 22716, "number_of_timesteps": 8379183, "per_episode_reward": -2.38, "episode_reward_trend_value": 0.0014578834328386235, "biggest_recent_change": 0.059624018332100626},
{"total_number_of_episodes": 22727, "number_of_timesteps": 8380807, "per_episode_reward": -2.38, "episode_reward_trend_value": 0.0008211086644733405, "biggest_recent_change": 0.053171012751277225},
{"total_number_of_episodes": 22737, "number_of_timesteps": 8382066, "per_episode_reward": -2.34, "episode_reward_trend_value": 0.0009673598595351873, "biggest_recent_change": 0.053171012751277225},
{"total_number_of_episodes": 22747, "number_of_timesteps": 8384575, "per_episode_reward": -2.32, "episode_reward_trend_value": 0.00117903113845247, "biggest_recent_change": 0.053171012751277225},
{"total_number_of_episodes": 22757, "number_of_timesteps": 8386694, "per_episode_reward": -2.27, "episode_reward_trend_value": 0.0018759377944702442, "biggest_recent_change": 0.053171012751277225},
{"total_number_of_episodes": 22767, "number_of_timesteps": 8389579, "per_episode_reward": -2.31, "episode_reward_trend_value": 0.0011094273031523303, "biggest_recent_change": 0.053171012751277225},
{"total_number_of_episodes": 22777, "number_of_timesteps": 8391867, "per_episode_reward": -2.27, "episode_reward_trend_value": 0.0010337562440467648, "biggest_recent_change": 0.053171012751277225},
{"total_number_of_episodes": 22787, "number_of_timesteps": 8394820, "per_episode_reward": -2.24, "episode_reward_trend_value": 0.0020113933569238726, "biggest_recent_change": 0.04585675770362396},
{"total_number_of_episodes": 22797, "number_of_timesteps": 8398793, "per_episode_reward": -2.22, "episode_reward_trend_value": 0.0022282020694557167, "biggest_recent_change": 0.04585675770362396},
{"total_number_of_episodes": 22807, "number_of_timesteps": 8402138, "per_episode_reward": -2.19, "episode_reward_trend_value": 0.0021242282864743166, "biggest_recent_change": 0.04585675770362396},
{"total_number_of_episodes": 22817, "number_of_timesteps": 8404551, "per_episode_reward": -2.18, "episode_reward_trend_value": 0.0022154121985173574, "biggest_recent_change": 0.04585675770362396},
{"total_number_of_episodes": 22827, "number_of_timesteps": 8407081, "per_episode_reward": -2.13, "episode_reward_trend_value": 0.002318983513937307, "biggest_recent_change": 0.04585675770362396},
{"total_number_of_episodes": 22837, "number_of_timesteps": 8410978, "per_episode_reward": -2.1, "episode_reward_trend_value": 0.0023751473272137485, "biggest_recent_change": 0.04585675770362396},
{"total_number_of_episodes": 22847, "number_of_timesteps": 8416914, "per_episode_reward": -2.08, "episode_reward_trend_value": 0.0021132947943232013, "biggest_recent_change": 0.04531282730389563},
{"total_number_of_episodes": 22857, "number_of_timesteps": 8422445, "per_episode_reward": -2.05, "episode_reward_trend_value": 0.0028527481026667406, "biggest_recent_change": 0.04531282730389563},
{"total_number_of_episodes": 22867, "number_of_timesteps": 8428288, "per_episode_reward": -2.04, "episode_reward_trend_value": 0.0025854297952699126, "biggest_recent_change": 0.04531282730389563},
{"total_number_of_episodes": 22877, "number_of_timesteps": 8432593, "per_episode_reward": -2.0, "episode_reward_trend_value": 0.002613544892855529, "biggest_recent_change": 0.04531282730389563},
{"total_number_of_episodes": 22887, "number_of_timesteps": 8437272, "per_episode_reward": -1.94, "episode_reward_trend_value": 0.0030451809314007913, "biggest_recent_change": 0.06089539617016526},
{"total_number_of_episodes": 22897, "number_of_timesteps": 8440090, "per_episode_reward": -1.94, "episode_reward_trend_value": 0.0027807755077518623, "biggest_recent_change": 0.06089539617016526},
{"total_number_of_episodes": 22907, "number_of_timesteps": 8442825, "per_episode_reward": -1.93, "episode_reward_trend_value": 0.002822827269931451, "biggest_recent_change": 0.06089539617016526},
{"total_number_of_episodes": 22917, "number_of_timesteps": 8447094, "per_episode_reward": -1.91, "episode_reward_trend_value": 0.002435235732563982, "biggest_recent_change": 0.06089539617016526},
{"total_number_of_episodes": 22927, "number_of_timesteps": 8452583, "per_episode_reward": -1.91, "episode_reward_trend_value": 0.0021068958423422863, "biggest_recent_change": 0.06089539617016526},
{"total_number_of_episodes": 22938, "number_of_timesteps": 8455164, "per_episode_reward": -1.88, "episode_reward_trend_value": 0.002254747512112089, "biggest_recent_change": 0.06089539617016526},
{"total_number_of_episodes": 22949, "number_of_timesteps": 8457738, "per_episode_reward": -1.86, "episode_reward_trend_value": 0.0021244415119981144, "biggest_recent_change": 0.06089539617016526},
{"total_number_of_episodes": 22959, "number_of_timesteps": 8460913, "per_episode_reward": -1.84, "episode_reward_trend_value": 0.0022461911269095382, "biggest_recent_change": 0.06089539617016526},
{"total_number_of_episodes": 22969, "number_of_timesteps": 8463327, "per_episode_reward": -1.83, "episode_reward_trend_value": 0.0019481074475338842, "biggest_recent_change": 0.06089539617016526},
{"total_number_of_episodes": 22979, "number_of_timesteps": 8466410, "per_episode_reward": -1.81, "episode_reward_trend_value": 0.0014763697640990368, "biggest_recent_change": 0.035596680022756955},
{"total_number_of_episodes": 22989, "number_of_timesteps": 8469886, "per_episode_reward": -1.79, "episode_reward_trend_value": 0.001608871589979656, "biggest_recent_change": 0.035596680022756955},
{"total_number_of_episodes": 22999, "number_of_timesteps": 8473584, "per_episode_reward": -1.78, "episode_reward_trend_value": 0.0016411400177192398, "biggest_recent_change": 0.035596680022756955},
{"total_number_of_episodes": 23009, "number_of_timesteps": 8476119, "per_episode_reward": -1.76, "episode_reward_trend_value": 0.0016914741170266391, "biggest_recent_change": 0.035596680022756955},
{"total_number_of_episodes": 23019, "number_of_timesteps": 8479262, "per_episode_reward": -1.74, "episode_reward_trend_value": 0.0018984457803541063, "biggest_recent_change": 0.035596680022756955},
{"total_number_of_episodes": 23029, "number_of_timesteps": 8482761, "per_episode_reward": -1.7, "episode_reward_trend_value": 0.0019192594545001257, "biggest_recent_change": 0.03746991069589867},
{"total_number_of_episodes": 23040, "number_of_timesteps": 8485486, "per_episode_reward": -1.64, "episode_reward_trend_value": 0.002391001964875423, "biggest_recent_change": 0.061187796224876134},
{"total_number_of_episodes": 23051, "number_of_timesteps": 8488998, "per_episode_reward": -1.6, "episode_reward_trend_value": 0.002617748191497032, "biggest_recent_change": 0.061187796224876134},
{"total_number_of_episodes": 23061, "number_of_timesteps": 8491915, "per_episode_reward": -1.59, "episode_reward_trend_value": 0.002610131751198747, "biggest_recent_change": 0.061187796224876134},
{"total_number_of_episodes": 23071, "number_of_timesteps": 8496013, "per_episode_reward": -1.59, "episode_reward_trend_value": 0.0024096515421706812, "biggest_recent_change": 0.061187796224876134},
{"total_number_of_episodes": 23081, "number_of_timesteps": 8497672, "per_episode_reward": -1.57, "episode_reward_trend_value": 0.0025006383517685296, "biggest_recent_change": 0.061187796224876134},
{"total_number_of_episodes": 23091, "number_of_timesteps": 8500681, "per_episode_reward": -1.56, "episode_reward_trend_value": 0.0024722678879501984, "biggest_recent_change": 0.061187796224876134},
{"total_number_of_episodes": 23101, "number_of_timesteps": 8503705, "per_episode_reward": -1.52, "episode_reward_trend_value": 0.0026520337830175512, "biggest_recent_change": 0.061187796224876134},
{"total_number_of_episodes": 23111, "number_of_timesteps": 8508833, "per_episode_reward": -1.48, "episode_reward_trend_value": 0.0028709437902939314, "biggest_recent_change": 0.061187796224876134},
{"total_number_of_episodes": 23121, "number_of_timesteps": 8512227, "per_episode_reward": -1.49, "episode_reward_trend_value": 0.002353337413679493, "biggest_recent_change": 0.061187796224876134},
{"total_number_of_episodes": 23131, "number_of_timesteps": 8515356, "per_episode_reward": -1.43, "episode_reward_trend_value": 0.0023234963327696478, "biggest_recent_change": 0.05850209894299008},
{"total_number_of_episodes": 23142, "number_of_timesteps": 8519048, "per_episode_reward": -1.43, "episode_reward_trend_value": 0.0018928227725209484, "biggest_recent_change": 0.05850209894299008},
{"total_number_of_episodes": 23152, "number_of_timesteps": 8521217, "per_episode_reward": -1.4, "episode_reward_trend_value": 0.002094822630962871, "biggest_recent_change": 0.05850209894299008},
{"total_number_of_episodes": 23162, "number_of_timesteps": 8523090, "per_episode_reward": -1.39, "episode_reward_trend_value": 0.0022697852645172387, "biggest_recent_change": 0.05850209894299008},
{"total_number_of_episodes": 23174, "number_of_timesteps": 8527588, "per_episode_reward": -1.36, "episode_reward_trend_value": 0.0023842234810312448, "biggest_recent_change": 0.05850209894299008},
{"total_number_of_episodes": 23185, "number_of_timesteps": 8530751, "per_episode_reward": -1.32, "episode_reward_trend_value": 0.0025659465411188307, "biggest_recent_change": 0.05850209894299008},
{"total_number_of_episodes": 23195, "number_of_timesteps": 8533880, "per_episode_reward": -1.33, "episode_reward_trend_value": 0.0021783156865637205, "biggest_recent_change": 0.05850209894299008},
{"total_number_of_episodes": 23205, "number_of_timesteps": 8537563, "per_episode_reward": -1.27, "episode_reward_trend_value": 0.00239600392510985, "biggest_recent_change": 0.060145915253227766},
{"total_number_of_episodes": 23215, "number_of_timesteps": 8540352, "per_episode_reward": -1.25, "episode_reward_trend_value": 0.002707766453738383, "biggest_recent_change": 0.060145915253227766},
{"total_number_of_episodes": 23225, "number_of_timesteps": 8543248, "per_episode_reward": -1.21, "episode_reward_trend_value": 0.002458764635561413, "biggest_recent_change": 0.060145915253227766},
{"total_number_of_episodes": 23235, "number_of_timesteps": 8546143, "per_episode_reward": -1.12, "episode_reward_trend_value": 0.0034287574161749436, "biggest_recent_change": 0.08960447436676011},
{"total_number_of_episodes": 23245, "number_of_timesteps": 8549122, "per_episode_reward": -1.09, "episode_reward_trend_value": 0.003475321421425501, "biggest_recent_change": 0.08960447436676011},
{"total_number_of_episodes": 23255, "number_of_timesteps": 8551601, "per_episode_reward": -1.12, "episode_reward_trend_value": 0.0029508806627125753, "biggest_recent_change": 0.08960447436676011},
{"total_number_of_episodes": 23266, "number_of_timesteps": 8553813, "per_episode_reward": -1.1, "episode_reward_trend_value": 0.0028465165608681816, "biggest_recent_change": 0.08960447436676011},
{"total_number_of_episodes": 23276, "number_of_timesteps": 8556278, "per_episode_reward": -1.11, "episode_reward_trend_value": 0.002335741491631442, "biggest_recent_change": 0.08960447436676011},
{"total_number_of_episodes": 23286, "number_of_timesteps": 8557820, "per_episode_reward": -1.08, "episode_reward_trend_value": 0.0027019357538625452, "biggest_recent_change": 0.08960447436676011},
{"total_number_of_episodes": 23297, "number_of_timesteps": 8563245, "per_episode_reward": -1.1, "episode_reward_trend_value": 0.00182306163242951, "biggest_recent_change": 0.08960447436676011},
{"total_number_of_episodes": 23307, "number_of_timesteps": 8568733, "per_episode_reward": -1.05, "episode_reward_trend_value": 0.0021741109100040395, "biggest_recent_change": 0.08960447436676011},
{"total_number_of_episodes": 23317, "number_of_timesteps": 8573361, "per_episode_reward": -1.04, "episode_reward_trend_value": 0.0019475142160514307, "biggest_recent_change": 0.08960447436676011},
{"total_number_of_episodes": 23328, "number_of_timesteps": 8579041, "per_episode_reward": -1.01, "episode_reward_trend_value": 0.0012642734213032462, "biggest_recent_change": 0.05053839935887483},
{"total_number_of_episodes": 23338, "number_of_timesteps": 8583649, "per_episode_reward": -0.99, "episode_reward_trend_value": 0.0010868868441658995, "biggest_recent_change": 0.05053839935887483},
{"total_number_of_episodes": 23348, "number_of_timesteps": 8586373, "per_episode_reward": -0.97, "episode_reward_trend_value": 0.0016331464888755625, "biggest_recent_change": 0.05053839935887483},
{"total_number_of_episodes": 23358, "number_of_timesteps": 8591697, "per_episode_reward": -0.97, "episode_reward_trend_value": 0.0013917187602177404, "biggest_recent_change": 0.05053839935887483},
{"total_number_of_episodes": 23369, "number_of_timesteps": 8595871, "per_episode_reward": -0.93, "episode_reward_trend_value": 0.00204830869904159, "biggest_recent_change": 0.05053839935887483},
{"total_number_of_episodes": 23379, "number_of_timesteps": 8601449, "per_episode_reward": -0.94, "episode_reward_trend_value": 0.0016145652722673186, "biggest_recent_change": 0.05053839935887483},
{"total_number_of_episodes": 23389, "number_of_timesteps": 8604778, "per_episode_reward": -0.94, "episode_reward_trend_value": 0.0018510065647864356, "biggest_recent_change": 0.05053839935887483},
{"total_number_of_episodes": 23399, "number_of_timesteps": 8606522, "per_episode_reward": -0.93, "episode_reward_trend_value": 0.0013223626695710732, "biggest_recent_change": 0.04413473028289705},
{"total_number_of_episodes": 23409, "number_of_timesteps": 8610158, "per_episode_reward": -0.91, "episode_reward_trend_value": 0.001452126293219955, "biggest_recent_change": 0.04413473028289705},
{"total_number_of_episodes": 23420, "number_of_timesteps": 8612387, "per_episode_reward": -0.91, "episode_reward_trend_value": 0.0010642273392337735, "biggest_recent_change": 0.04413473028289705},
{"total_number_of_episodes": 23430, "number_of_timesteps": 8617080, "per_episode_reward": -0.9, "episode_reward_trend_value": 0.0010674830727188198, "biggest_recent_change": 0.04413473028289705},
{"total_number_of_episodes": 23440, "number_of_timesteps": 8620421, "per_episode_reward": -0.88, "episode_reward_trend_value": 0.0010349876430697379, "biggest_recent_change": 0.04413473028289705},
{"total_number_of_episodes": 23450, "number_of_timesteps": 8624413, "per_episode_reward": -0.84, "episode_reward_trend_value": 0.0014346652488415811, "biggest_recent_change": 0.04413473028289705},
{"total_number_of_episodes": 23460, "number_of_timesteps": 8627150, "per_episode_reward": -0.82, "episode_reward_trend_value": 0.0012217015651997361, "biggest_recent_change": 0.03723230883326245},
{"total_number_of_episodes": 23472, "number_of_timesteps": 8630474, "per_episode_reward": -0.81, "episode_reward_trend_value": 0.0014927159712371327, "biggest_recent_change": 0.03723230883326245},
{"total_number_of_episodes": 23482, "number_of_timesteps": 8633144, "per_episode_reward": -0.8, "episode_reward_trend_value": 0.0014803592009159396, "biggest_recent_change": 0.03723230883326245},
{"total_number_of_episodes": 23492, "number_of_timesteps": 8636533, "per_episode_reward": -0.78, "episode_reward_trend_value": 0.0017494050533603076, "biggest_recent_change": 0.03723230883326245},
{"total_number_of_episodes": 23502, "number_of_timesteps": 8639659, "per_episode_reward": -0.78, "episode_reward_trend_value": 0.0014001112915396322, "biggest_recent_change": 0.03723230883326245},
{"total_number_of_episodes": 23512, "number_of_timesteps": 8642420, "per_episode_reward": -0.79, "episode_reward_trend_value": 0.0014217856283543673, "biggest_recent_change": 0.03723230883326245},
{"total_number_of_episodes": 23522, "number_of_timesteps": 8645610, "per_episode_reward": -0.77, "episode_reward_trend_value": 0.0013734898223278843, "biggest_recent_change": 0.03723230883326245},
{"total_number_of_episodes": 23532, "number_of_timesteps": 8650460, "per_episode_reward": -0.75, "episode_reward_trend_value": 0.0014462459001996966, "biggest_recent_change": 0.03723230883326245},
{"total_number_of_episodes": 23542, "number_of_timesteps": 8653113, "per_episode_reward": -0.74, "episode_reward_trend_value": 0.0011348311485797427, "biggest_recent_change": 0.02717457550948532},
{"total_number_of_episodes": 23552, "number_of_timesteps": 8656572, "per_episode_reward": -0.71, "episode_reward_trend_value": 0.0012166609475425805, "biggest_recent_change": 0.032332680661786406},
{"total_number_of_episodes": 23562, "number_of_timesteps": 8659107, "per_episode_reward": -0.7, "episode_reward_trend_value": 0.0011163826616574545, "biggest_recent_change": 0.032332680661786406},
{"total_number_of_episodes": 23572, "number_of_timesteps": 8662463, "per_episode_reward": -0.66, "episode_reward_trend_value": 0.0015704074227908809, "biggest_recent_change": 0.04207707982407616},
{"total_number_of_episodes": 23582, "number_of_timesteps": 8664811, "per_episode_reward": -0.65, "episode_reward_trend_value": 0.0014149232555766278, "biggest_recent_change": 0.04207707982407616},
{"total_number_of_episodes": 23592, "number_of_timesteps": 8667707, "per_episode_reward": -0.64, "episode_reward_trend_value": 0.0015711082197551883, "biggest_recent_change": 0.04207707982407616},
{"total_number_of_episodes": 23602, "number_of_timesteps": 8670684, "per_episode_reward": -0.64, "episode_reward_trend_value": 0.001636787189218826, "biggest_recent_change": 0.04207707982407616},
{"total_number_of_episodes": 23612, "number_of_timesteps": 8675047, "per_episode_reward": -0.63, "episode_reward_trend_value": 0.0015398872269985586, "biggest_recent_change": 0.04207707982407616},
{"total_number_of_episodes": 23622, "number_of_timesteps": 8678702, "per_episode_reward": -0.64, "episode_reward_trend_value": 0.0012803245075527412, "biggest_recent_change": 0.04207707982407616},
{"total_number_of_episodes": 23632, "number_of_timesteps": 8680743, "per_episode_reward": -0.62, "episode_reward_trend_value": 0.0013605485890634396, "biggest_recent_change": 0.04207707982407616},
{"total_number_of_episodes": 23642, "number_of_timesteps": 8682877, "per_episode_reward": -0.61, "episode_reward_trend_value": 0.0010608161400817192, "biggest_recent_change": 0.04207707982407616},
{"total_number_of_episodes": 23652, "number_of_timesteps": 8684350, "per_episode_reward": -0.58, "episode_reward_trend_value": 0.0013650259839445567, "biggest_recent_change": 0.04207707982407616},
{"total_number_of_episodes": 23662, "number_of_timesteps": 8686599, "per_episode_reward": -0.58, "episode_reward_trend_value": 0.0009624298531981027, "biggest_recent_change": 0.03291752347706589},
{"total_number_of_episodes": 23672, "number_of_timesteps": 8689876, "per_episode_reward": -0.54, "episode_reward_trend_value": 0.0012187422419103742, "biggest_recent_change": 0.03624911544430698},
{"total_number_of_episodes": 23683, "number_of_timesteps": 8692120, "per_episode_reward": -0.35, "episode_reward_trend_value": 0.00321116742838979, "biggest_recent_change": 0.18931543397508438},
{"total_number_of_episodes": 23693, "number_of_timesteps": 8694857, "per_episode_reward": -0.31, "episode_reward_trend_value": 0.0036744908775497623, "biggest_recent_change": 0.18931543397508438},
{"total_number_of_episodes": 23703, "number_of_timesteps": 8697410, "per_episode_reward": -0.32, "episode_reward_trend_value": 0.003525661033892037, "biggest_recent_change": 0.18931543397508438},
{"total_number_of_episodes": 23713, "number_of_timesteps": 8699092, "per_episode_reward": -0.29, "episode_reward_trend_value": 0.0038839774269067407, "biggest_recent_change": 0.18931543397508438},
{"total_number_of_episodes": 23723, "number_of_timesteps": 8701814, "per_episode_reward": -0.3, "episode_reward_trend_value": 0.0035940990164098547, "biggest_recent_change": 0.18931543397508438},
{"total_number_of_episodes": 23733, "number_of_timesteps": 8704058, "per_episode_reward": -0.3, "episode_reward_trend_value": 0.0035255925996154963, "biggest_recent_change": 0.18931543397508438},
{"total_number_of_episodes": 23743, "number_of_timesteps": 8705795, "per_episode_reward": -0.29, "episode_reward_trend_value": 0.003187022017244747, "biggest_recent_change": 0.18931543397508438},
{"total_number_of_episodes": 23753, "number_of_timesteps": 8708822, "per_episode_reward": -0.26, "episode_reward_trend_value": 0.0034665359150508196, "biggest_recent_change": 0.18931543397508438},
{"total_number_of_episodes": 23763, "number_of_timesteps": 8710155, "per_episode_reward": -0.27, "episode_reward_trend_value": 0.0029542349399271466, "biggest_recent_change": 0.18931543397508438},
{"total_number_of_episodes": 23773, "number_of_timesteps": 8712750, "per_episode_reward": -0.24, "episode_reward_trend_value": 0.0012025934283829624, "biggest_recent_change": 0.04276280497011831},
{"total_number_of_episodes": 23783, "number_of_timesteps": 8715099, "per_episode_reward": -0.24, "episode_reward_trend_value": 0.0007697628356843943, "biggest_recent_change": 0.0316676979361078},
{"total_number_of_episodes": 23793, "number_of_timesteps": 8717566, "per_episode_reward": -0.22, "episode_reward_trend_value": 0.0010910271861815583, "biggest_recent_change": 0.0316676979361078},
{"total_number_of_episodes": 23803, "number_of_timesteps": 8721139, "per_episode_reward": -0.19, "episode_reward_trend_value": 0.0010510798841005383, "biggest_recent_change": 0.0316676979361078},
{"total_number_of_episodes": 23813, "number_of_timesteps": 8723336, "per_episode_reward": -0.16, "episode_reward_trend_value": 0.001480224413684832, "biggest_recent_change": 0.0316676979361078},
{"total_number_of_episodes": 23823, "number_of_timesteps": 8725244, "per_episode_reward": -0.13, "episode_reward_trend_value": 0.0019113739010835225, "biggest_recent_change": 0.037994636607821514},
{"total_number_of_episodes": 23833, "number_of_timesteps": 8729086, "per_episode_reward": -0.09, "episode_reward_trend_value": 0.0022901198918457225, "biggest_recent_change": 0.037994636607821514},
{"total_number_of_episodes": 23843, "number_of_timesteps": 8732004, "per_episode_reward": -0.08, "episode_reward_trend_value": 0.00204368748987755, "biggest_recent_change": 0.037994636607821514},
{"total_number_of_episodes": 23854, "number_of_timesteps": 8733996, "per_episode_reward": -0.06, "episode_reward_trend_value": 0.0024208827316327753, "biggest_recent_change": 0.037994636607821514},
{"total_number_of_episodes": 23864, "number_of_timesteps": 8737121, "per_episode_reward": -0.04, "episode_reward_trend_value": 0.00222456721645845, "biggest_recent_change": 0.037994636607821514},
{"total_number_of_episodes": 23875, "number_of_timesteps": 8741103, "per_episode_reward": -0.02, "episode_reward_trend_value": 0.002454558467307612, "biggest_recent_change": 0.037994636607821514},
{"total_number_of_episodes": 23885, "number_of_timesteps": 8743280, "per_episode_reward": 0.01, "episode_reward_trend_value": 0.0025056142146283704, "biggest_recent_change": 0.037994636607821514},
{"total_number_of_episodes": 23896, "number_of_timesteps": 8745941, "per_episode_reward": 0.05, "episode_reward_trend_value": 0.0026854749426469893, "biggest_recent_change": 0.043209619903731955},
{"total_number_of_episodes": 23906, "number_of_timesteps": 8747269, "per_episode_reward": 0.06, "episode_reward_trend_value": 0.0025282777750804107, "biggest_recent_change": 0.043209619903731955},
{"total_number_of_episodes": 23916, "number_of_timesteps": 8748612, "per_episode_reward": 0.04, "episode_reward_trend_value": 0.0017891815483518634, "biggest_recent_change": 0.043209619903731955},
{"total_number_of_episodes": 23926, "number_of_timesteps": 8751541, "per_episode_reward": 0.0, "episode_reward_trend_value": 0.0010289388636465172, "biggest_recent_change": 0.043209619903731955},
{"total_number_of_episodes": 23936, "number_of_timesteps": 8752960, "per_episode_reward": -0.01, "episode_reward_trend_value": 0.0007626428987173543, "biggest_recent_change": 0.043209619903731955},
{"total_number_of_episodes": 23946, "number_of_timesteps": 8754412, "per_episode_reward": -0.01, "episode_reward_trend_value": 0.0005421476038497079, "biggest_recent_change": 0.043209619903731955},
{"total_number_of_episodes": 23956, "number_of_timesteps": 8756798, "per_episode_reward": 0.02, "episode_reward_trend_value": 0.0006816466872286854, "biggest_recent_change": 0.043209619903731955},
{"total_number_of_episodes": 23966, "number_of_timesteps": 8759302, "per_episode_reward": 0.04, "episode_reward_trend_value": 0.0006454999027592775, "biggest_recent_change": 0.043209619903731955},
{"total_number_of_episodes": 23976, "number_of_timesteps": 8765840, "per_episode_reward": 0.09, "episode_reward_trend_value": 0.0009540099585961177, "biggest_recent_change": 0.0513450559808554},
{"total_number_of_episodes": 23986, "number_of_timesteps": 8769791, "per_episode_reward": 0.08, "episode_reward_trend_value": 0.00037106061919775225, "biggest_recent_change": 0.0513450559808554},
{"total_number_of_episodes": 23996, "number_of_timesteps": 8773420, "per_episode_reward": 0.08, "episode_reward_trend_value": 0.00019219315334242918, "biggest_recent_change": 0.0513450559808554},
{"total_number_of_episodes": 24006, "number_of_timesteps": 8776038, "per_episode_reward": 0.07, "episode_reward_trend_value": 0.00033697322224312116, "biggest_recent_change": 0.0513450559808554},
{"total_number_of_episodes": 24016, "number_of_timesteps": 8780394, "per_episode_reward": 0.1, "episode_reward_trend_value": 0.0011237325647002233, "biggest_recent_change": 0.0513450559808554},
{"total_number_of_episodes": 24026, "number_of_timesteps": 8784294, "per_episode_reward": 0.15, "episode_reward_trend_value": 0.0017913103697994892, "biggest_recent_change": 0.0513450559808554},
{"total_number_of_episodes": 24036, "number_of_timesteps": 8787771, "per_episode_reward": 0.16, "episode_reward_trend_value": 0.0018894564671223947, "biggest_recent_change": 0.0513450559808554},
{"total_number_of_episodes": 24046, "number_of_timesteps": 8791570, "per_episode_reward": 0.19, "episode_reward_trend_value": 0.0018517648171475106, "biggest_recent_change": 0.0513450559808554},
{"total_number_of_episodes": 24056, "number_of_timesteps": 8793698, "per_episode_reward": 0.2, "episode_reward_trend_value": 0.001723916970809862, "biggest_recent_change": 0.0513450559808554},
{"total_number_of_episodes": 24066, "number_of_timesteps": 8797126, "per_episode_reward": 0.21, "episode_reward_trend_value": 0.0013472190948506184, "biggest_recent_change": 0.044936128297615605},
{"total_number_of_episodes": 24076, "number_of_timesteps": 8800260, "per_episode_reward": 0.25, "episode_reward_trend_value": 0.0018557557970568302, "biggest_recent_change": 0.044936128297615605},
{"total_number_of_episodes": 24086, "number_of_timesteps": 8803647, "per_episode_reward": 0.29, "episode_reward_trend_value": 0.0023246682964233106, "biggest_recent_change": 0.044936128297615605},
{"total_number_of_episodes": 24097, "number_of_timesteps": 8807438, "per_episode_reward": 0.31, "episode_reward_trend_value": 0.0026564821200129847, "biggest_recent_change": 0.044936128297615605},
{"total_number_of_episodes": 24108, "number_of_timesteps": 8812108, "per_episode_reward": 0.34, "episode_reward_trend_value": 0.0025998507933232104, "biggest_recent_change": 0.044936128297615605},
{"total_number_of_episodes": 24118, "number_of_timesteps": 8815773, "per_episode_reward": 0.36, "episode_reward_trend_value": 0.0023821683649543953, "biggest_recent_change": 0.04091540717630818},
{"total_number_of_episodes": 24128, "number_of_timesteps": 8818775, "per_episode_reward": 0.37, "episode_reward_trend_value": 0.0022580562933868483, "biggest_recent_change": 0.04091540717630818},
{"total_number_of_episodes": 24138, "number_of_timesteps": 8823740, "per_episode_reward": 0.38, "episode_reward_trend_value": 0.002148709356026844, "biggest_recent_change": 0.04091540717630818},
{"total_number_of_episodes": 24148, "number_of_timesteps": 8828145, "per_episode_reward": 0.4, "episode_reward_trend_value": 0.0022417527171424466, "biggest_recent_change": 0.04091540717630818},
{"total_number_of_episodes": 24158, "number_of_timesteps": 8834113, "per_episode_reward": 0.44, "episode_reward_trend_value": 0.00250655534100215, "biggest_recent_change": 0.04127448329189676},
{"total_number_of_episodes": 24168, "number_of_timesteps": 8837347, "per_episode_reward": 0.46, "episode_reward_trend_value": 0.002378376033655054, "biggest_recent_change": 0.04127448329189676},
{"total_number_of_episodes": 24178, "number_of_timesteps": 8839947, "per_episode_reward": 0.5, "episode_reward_trend_value": 0.002338778796401895, "biggest_recent_change": 0.04127448329189676},
{"total_number_of_episodes": 24188, "number_of_timesteps": 8844963, "per_episode_reward": 0.51, "episode_reward_trend_value": 0.00227347909221424, "biggest_recent_change": 0.04127448329189676},
{"total_number_of_episodes": 24198, "number_of_timesteps": 8848419, "per_episode_reward": 0.49, "episode_reward_trend_value": 0.0016615562986739719, "biggest_recent_change": 0.04127448329189676},
{"total_number_of_episodes": 24208, "number_of_timesteps": 8854177, "per_episode_reward": 0.51, "episode_reward_trend_value": 0.0016291837113428741, "biggest_recent_change": 0.04127448329189676},
{"total_number_of_episodes": 24218, "number_of_timesteps": 8858121, "per_episode_reward": 0.55, "episode_reward_trend_value": 0.00201596713367619, "biggest_recent_change": 0.04127448329189676},
{"total_number_of_episodes": 24228, "number_of_timesteps": 8861626, "per_episode_reward": 0.59, "episode_reward_trend_value": 0.0023033478778811496, "biggest_recent_change": 0.04127448329189676},
{"total_number_of_episodes": 24238, "number_of_timesteps": 8864519, "per_episode_reward": 0.59, "episode_reward_trend_value": 0.002141574367866323, "biggest_recent_change": 0.04127448329189676},
{"total_number_of_episodes": 24248, "number_of_timesteps": 8867455, "per_episode_reward": 0.61, "episode_reward_trend_value": 0.0018471857830539863, "biggest_recent_change": 0.03918501319283285},
{"total_number_of_episodes": 24258, "number_of_timesteps": 8871453, "per_episode_reward": 0.63, "episode_reward_trend_value": 0.0018892193333814495, "biggest_recent_change": 0.03918501319283285},
{"total_number_of_episodes": 24268, "number_of_timesteps": 8876162, "per_episode_reward": 0.63, "episode_reward_trend_value": 0.0014666830414303673, "biggest_recent_change": 0.03918501319283285},
{"total_number_of_episodes": 24278, "number_of_timesteps": 8881051, "per_episode_reward": 0.59, "episode_reward_trend_value": 0.0009138289719747037, "biggest_recent_change": 0.04126441310151352},
{"total_number_of_episodes": 24288, "number_of_timesteps": 8884235, "per_episode_reward": 0.59, "episode_reward_trend_value": 0.001129581562153301, "biggest_recent_change": 0.04126441310151352},
{"total_number_of_episodes": 24298, "number_of_timesteps": 8886982, "per_episode_reward": 0.56, "episode_reward_trend_value": 0.0005700735712635839, "biggest_recent_change": 0.04126441310151352},
{"total_number_of_episodes": 24308, "number_of_timesteps": 8889463, "per_episode_reward": 0.56, "episode_reward_trend_value": 0.00013912253164167037, "biggest_recent_change": 0.04126441310151352},
{"total_number_of_episodes": 24318, "number_of_timesteps": 8892094, "per_episode_reward": 0.55, "episode_reward_trend_value": -0.00039570689090344423, "biggest_recent_change": 0.04126441310151352},
{"total_number_of_episodes": 24328, "number_of_timesteps": 8895252, "per_episode_reward": 0.59, "episode_reward_trend_value": 5.018918423876547e-05, "biggest_recent_change": 0.04369268079290545},
{"total_number_of_episodes": 24339, "number_of_timesteps": 8898307, "per_episode_reward": 0.58, "episode_reward_trend_value": -0.00031855867447741184, "biggest_recent_change": 0.04369268079290545},
{"total_number_of_episodes": 24349, "number_of_timesteps": 8899616, "per_episode_reward": 0.58, "episode_reward_trend_value": -0.0006117278677334383, "biggest_recent_change": 0.04369268079290545},
{"total_number_of_episodes": 24359, "number_of_timesteps": 8901672, "per_episode_reward": 0.63, "episode_reward_trend_value": 1.829245061540178e-05, "biggest_recent_change": 0.05602521819932205},
{"total_number_of_episodes": 24369, "number_of_timesteps": 8908258, "per_episode_reward": 0.65, "episode_reward_trend_value": 0.0006429091793750447, "biggest_recent_change": 0.05602521819932205},
{"total_number_of_episodes": 24379, "number_of_timesteps": 8911941, "per_episode_reward": 0.65, "episode_reward_trend_value": 0.0007084702243190256, "biggest_recent_change": 0.05602521819932205},
{"total_number_of_episodes": 24389, "number_of_timesteps": 8916152, "per_episode_reward": 0.69, "episode_reward_trend_value": 0.0014358063999709947, "biggest_recent_change": 0.05602521819932205},
{"total_number_of_episodes": 24399, "number_of_timesteps": 8919071, "per_episode_reward": 0.64, "episode_reward_trend_value": 0.0009320854661662992, "biggest_recent_change": 0.05602521819932205},
{"total_number_of_episodes": 24409, "number_of_timesteps": 8922238, "per_episode_reward": 0.66, "episode_reward_trend_value": 0.0012513118666327698, "biggest_recent_change": 0.05602521819932205},
{"total_number_of_episodes": 24419, "number_of_timesteps": 8924894, "per_episode_reward": 0.7, "episode_reward_trend_value": 0.0011687724388436745, "biggest_recent_change": 0.05602521819932205},
{"total_number_of_episodes": 24430, "number_of_timesteps": 8928707, "per_episode_reward": 0.69, "episode_reward_trend_value": 0.0013081671458397262, "biggest_recent_change": 0.05602521819932205},
{"total_number_of_episodes": 24440, "number_of_timesteps": 8931629, "per_episode_reward": 0.74, "episode_reward_trend_value": 0.001775135002165508, "biggest_recent_change": 0.05602521819932205},
{"total_number_of_episodes": 24450, "number_of_timesteps": 8933449, "per_episode_reward": 0.76, "episode_reward_trend_value": 0.001337220838789245, "biggest_recent_change": 0.047401884377355596},
{"total_number_of_episodes": 24460, "number_of_timesteps": 8937232, "per_episode_reward": 0.76, "episode_reward_trend_value": 0.0012616346907263678, "biggest_recent_change": 0.047401884377355596},
{"total_number_of_episodes": 24470, "number_of_timesteps": 8939319, "per_episode_reward": 0.77, "episode_reward_trend_value": 0.001240937969144171, "biggest_recent_change": 0.047401884377355596},
{"total_number_of_episodes": 24480, "number_of_timesteps": 8941024, "per_episode_reward": 0.75, "episode_reward_trend_value": 0.0006929263328066278, "biggest_recent_change": 0.047401884377355596},
{"total_number_of_episodes": 24490, "number_of_timesteps": 8944950, "per_episode_reward": 0.78, "episode_reward_trend_value": 0.0015371404419446697, "biggest_recent_change": 0.044401244100949144},
{"total_number_of_episodes": 24500, "number_of_timesteps": 8947998, "per_episode_reward": 0.81, "episode_reward_trend_value": 0.0016101076773930444, "biggest_recent_change": 0.044401244100949144},
{"total_number_of_episodes": 24510, "number_of_timesteps": 8950667, "per_episode_reward": 0.82, "episode_reward_trend_value": 0.0013244730650168143, "biggest_recent_change": 0.044401244100949144},

{"total_number_of_episodes": 24520, "number_of_timesteps": 8952968, "per_episode_reward": 0.82, "episode_reward_trend_value": 0.0013779032202902294, "biggest_recent_change": 0.044401244100949144},
{"total_number_of_episodes": 24530, "number_of_timesteps": 8958550, "per_episode_reward": 0.84, "episode_reward_trend_value": 0.001171738872226776, "biggest_recent_change": 0.02857738544506816},
{"total_number_of_episodes": 24540, "number_of_timesteps": 8962750, "per_episode_reward": 0.87, "episode_reward_trend_value": 0.0012576850781907314, "biggest_recent_change": 0.02857738544506816},
{"total_number_of_episodes": 24550, "number_of_timesteps": 8966315, "per_episode_reward": 0.86, "episode_reward_trend_value": 0.0010671655028030359, "biggest_recent_change": 0.02857738544506816},
{"total_number_of_episodes": 24561, "number_of_timesteps": 8970221, "per_episode_reward": 0.85, "episode_reward_trend_value": 0.0008858078256382704, "biggest_recent_change": 0.02857738544506816},
{"total_number_of_episodes": 24571, "number_of_timesteps": 8973137, "per_episode_reward": 0.85, "episode_reward_trend_value": 0.0011190493620416649, "biggest_recent_change": 0.02857738544506816},
{"total_number_of_episodes": 24581, "number_of_timesteps": 8976823, "per_episode_reward": 0.88, "episode_reward_trend_value": 0.0010776017708112515, "biggest_recent_change": 0.026347792396108627},
{"total_number_of_episodes": 24591, "number_of_timesteps": 8979984, "per_episode_reward": 0.89, "episode_reward_trend_value": 0.0008643376166236215, "biggest_recent_change": 0.025846452775238338},
{"total_number_of_episodes": 24602, "number_of_timesteps": 8982867, "per_episode_reward": 0.9, "episode_reward_trend_value": 0.000870827089021379, "biggest_recent_change": 0.025846452775238338},
{"total_number_of_episodes": 24612, "number_of_timesteps": 8984976, "per_episode_reward": 0.91, "episode_reward_trend_value": 0.0010565858542612124, "biggest_recent_change": 0.025846452775238338},
{"total_number_of_episodes": 24622, "number_of_timesteps": 8988561, "per_episode_reward": 0.94, "episode_reward_trend_value": 0.001046781149303782, "biggest_recent_change": 0.024964029329069604},
{"total_number_of_episodes": 24632, "number_of_timesteps": 8992506, "per_episode_reward": 0.93, "episode_reward_trend_value": 0.0007232240934858438, "biggest_recent_change": 0.024964029329069604},
{"total_number_of_episodes": 24642, "number_of_timesteps": 8994312, "per_episode_reward": 0.95, "episode_reward_trend_value": 0.0009554617450001893, "biggest_recent_change": 0.024964029329069604},
{"total_number_of_episodes": 24652, "number_of_timesteps": 8996052, "per_episode_reward": 0.98, "episode_reward_trend_value": 0.0015009318859533001, "biggest_recent_change": 0.03497558256883604},
{"total_number_of_episodes": 24662, "number_of_timesteps": 8999299, "per_episode_reward": 1.0, "episode_reward_trend_value": 0.0016190795866484792, "biggest_recent_change": 0.03497558256883604},

{"total_number_of_episodes": 24672, "number_of_timesteps": 9001788, "per_episode_reward": 1.0, "episode_reward_trend_value": 0.001290632258323987, "biggest_recent_change": 0.03497558256883604},
{"total_number_of_episodes": 24682, "number_of_timesteps": 9006118, "per_episode_reward": 1.01, "episode_reward_trend_value": 0.001387768807028489, "biggest_recent_change": 0.03497558256883604},
{"total_number_of_episodes": 24692, "number_of_timesteps": 9009777, "per_episode_reward": 1.03, "episode_reward_trend_value": 0.0014848394908984523, "biggest_recent_change": 0.03497558256883604},
{"total_number_of_episodes": 24702, "number_of_timesteps": 9013682, "per_episode_reward": 1.07, "episode_reward_trend_value": 0.001723961717747686, "biggest_recent_change": 0.03718573026659855},
{"total_number_of_episodes": 24712, "number_of_timesteps": 9017666, "per_episode_reward": 1.11, "episode_reward_trend_value": 0.001876253708207952, "biggest_recent_change": 0.038670308470493575},
{"total_number_of_episodes": 24722, "number_of_timesteps": 9020171, "per_episode_reward": 1.11, "episode_reward_trend_value": 0.0019524561536452642, "biggest_recent_change": 0.038670308470493575},
{"total_number_of_episodes": 24732, "number_of_timesteps": 9025015, "per_episode_reward": 1.1, "episode_reward_trend_value": 0.0017600223951123668, "biggest_recent_change": 0.038670308470493575},
{"total_number_of_episodes": 24742, "number_of_timesteps": 9028964, "per_episode_reward": 1.11, "episode_reward_trend_value": 0.0014285121911393884, "biggest_recent_change": 0.038670308470493575},
{"total_number_of_episodes": 24752, "number_of_timesteps": 9030533, "per_episode_reward": 1.11, "episode_reward_trend_value": 0.0011766045363598107, "biggest_recent_change": 0.038670308470493575},
{"total_number_of_episodes": 24762, "number_of_timesteps": 9034954, "per_episode_reward": 1.14, "episode_reward_trend_value": 0.0016520114408688342, "biggest_recent_change": 0.038670308470493575},
{"total_number_of_episodes": 24772, "number_of_timesteps": 9039414, "per_episode_reward": 1.18, "episode_reward_trend_value": 0.0018852170431454102, "biggest_recent_change": 0.038670308470493575},
{"total_number_of_episodes": 24782, "number_of_timesteps": 9041619, "per_episode_reward": 1.21, "episode_reward_trend_value": 0.001966717689685206, "biggest_recent_change": 0.038670308470493575},
{"total_number_of_episodes": 24792, "number_of_timesteps": 9043455, "per_episode_reward": 1.23, "episode_reward_trend_value": 0.0017858530778234057, "biggest_recent_change": 0.038670308470493575},
{"total_number_of_episodes": 24802, "number_of_timesteps": 9045224, "per_episode_reward": 1.26, "episode_reward_trend_value": 0.0017457947446520455, "biggest_recent_change": 0.03807346409093881},
{"total_number_of_episodes": 24813, "number_of_timesteps": 9047860, "per_episode_reward": 1.27, "episode_reward_trend_value": 0.0018221031721907047, "biggest_recent_change": 0.03807346409093881},
{"total_number_of_episodes": 24823, "number_of_timesteps": 9049527, "per_episode_reward": 1.26, "episode_reward_trend_value": 0.001726903712895416, "biggest_recent_change": 0.03807346409093881},
{"total_number_of_episodes": 24833, "number_of_timesteps": 9051526, "per_episode_reward": 1.31, "episode_reward_trend_value": 0.002205518359745224, "biggest_recent_change": 0.048214982427750686},
{"total_number_of_episodes": 24843, "number_of_timesteps": 9054953, "per_episode_reward": 1.31, "episode_reward_trend_value": 0.0022967588717076604, "biggest_recent_change": 0.048214982427750686},
{"total_number_of_episodes": 24853, "number_of_timesteps": 9057408, "per_episode_reward": 1.34, "episode_reward_trend_value": 0.002189763583097916, "biggest_recent_change": 0.048214982427750686},
{"total_number_of_episodes": 24863, "number_of_timesteps": 9060586, "per_episode_reward": 1.38, "episode_reward_trend_value": 0.0021654281085283357, "biggest_recent_change": 0.048214982427750686},
{"total_number_of_episodes": 24873, "number_of_timesteps": 9062849, "per_episode_reward": 1.4, "episode_reward_trend_value": 0.002159780464247106, "biggest_recent_change": 0.048214982427750686},
{"total_number_of_episodes": 24883, "number_of_timesteps": 9064847, "per_episode_reward": 1.41, "episode_reward_trend_value": 0.0020266693263747094, "biggest_recent_change": 0.048214982427750686},
{"total_number_of_episodes": 24894, "number_of_timesteps": 9069247, "per_episode_reward": 1.46, "episode_reward_trend_value": 0.002197886852525488, "biggest_recent_change": 0.0504746358386412},
{"total_number_of_episodes": 24904, "number_of_timesteps": 9071961, "per_episode_reward": 1.49, "episode_reward_trend_value": 0.002390485900919474, "biggest_recent_change": 0.0504746358386412},
{"total_number_of_episodes": 24914, "number_of_timesteps": 9075026, "per_episode_reward": 1.5, "episode_reward_trend_value": 0.0027132172445214708, "biggest_recent_change": 0.0504746358386412},
{"total_number_of_episodes": 24925, "number_of_timesteps": 9079606, "per_episode_reward": 1.52, "episode_reward_trend_value": 0.0023438951466460208, "biggest_recent_change": 0.0504746358386412},
{"total_number_of_episodes": 24935, "number_of_timesteps": 9084104, "per_episode_reward": 1.52, "episode_reward_trend_value": 0.002308837543035564, "biggest_recent_change": 0.0504746358386412},
{"total_number_of_episodes": 24945, "number_of_timesteps": 9086432, "per_episode_reward": 1.56, "episode_reward_trend_value": 0.002398200923584142, "biggest_recent_change": 0.0504746358386412},
{"total_number_of_episodes": 24956, "number_of_timesteps": 9088907, "per_episode_reward": 1.54, "episode_reward_trend_value": 0.0018359574989455026, "biggest_recent_change": 0.0504746358386412},
{"total_number_of_episodes": 24967, "number_of_timesteps": 9091923, "per_episode_reward": 1.58, "episode_reward_trend_value": 0.0019333034811685062, "biggest_recent_change": 0.0504746358386412},
{"total_number_of_episodes": 24977, "number_of_timesteps": 9094550, "per_episode_reward": 1.64, "episode_reward_trend_value": 0.0025717790219065657, "biggest_recent_change": 0.0663907114569462},
{"total_number_of_episodes": 24987, "number_of_timesteps": 9098176, "per_episode_reward": 1.66, "episode_reward_trend_value": 0.0021989875332090107, "biggest_recent_change": 0.0663907114569462},
{"total_number_of_episodes": 24997, "number_of_timesteps": 9099715, "per_episode_reward": 1.71, "episode_reward_trend_value": 0.0025109971119497087, "biggest_recent_change": 0.0663907114569462},
{"total_number_of_episodes": 25007, "number_of_timesteps": 9102888, "per_episode_reward": 1.71, "episode_reward_trend_value": 0.0023469937257779745, "biggest_recent_change": 0.0663907114569462},
{"total_number_of_episodes": 25017, "number_of_timesteps": 9106195, "per_episode_reward": 1.73, "episode_reward_trend_value": 0.002361686611468936, "biggest_recent_change": 0.0663907114569462},
{"total_number_of_episodes": 25028, "number_of_timesteps": 9109596, "per_episode_reward": 1.79, "episode_reward_trend_value": 0.0029717533859996773, "biggest_recent_change": 0.0663907114569462},
{"total_number_of_episodes": 25038, "number_of_timesteps": 9113017, "per_episode_reward": 1.83, "episode_reward_trend_value": 0.0030770842951789645, "biggest_recent_change": 0.0663907114569462},
{"total_number_of_episodes": 25048, "number_of_timesteps": 9115121, "per_episode_reward": 1.85, "episode_reward_trend_value": 0.0033847918749207737, "biggest_recent_change": 0.0663907114569462},
{"total_number_of_episodes": 25058, "number_of_timesteps": 9118488, "per_episode_reward": 1.87, "episode_reward_trend_value": 0.0032552381228359907, "biggest_recent_change": 0.0663907114569462},
{"total_number_of_episodes": 25068, "number_of_timesteps": 9120024, "per_episode_reward": 1.91, "episode_reward_trend_value": 0.0029818355598412046, "biggest_recent_change": 0.05713048011100175},
{"total_number_of_episodes": 25078, "number_of_timesteps": 9122695, "per_episode_reward": 1.93, "episode_reward_trend_value": 0.0029964930099493055, "biggest_recent_change": 0.05713048011100175},
{"total_number_of_episodes": 25088, "number_of_timesteps": 9124726, "per_episode_reward": 1.96, "episode_reward_trend_value": 0.00276108765839111, "biggest_recent_change": 0.05713048011100175},
{"total_number_of_episodes": 25098, "number_of_timesteps": 9126815, "per_episode_reward": 2.0, "episode_reward_trend_value": 0.003205891642196043, "biggest_recent_change": 0.05713048011100175},
{"total_number_of_episodes": 25108, "number_of_timesteps": 9128814, "per_episode_reward": 2.02, "episode_reward_trend_value": 0.0032302051164084995, "biggest_recent_change": 0.05713048011100175},
{"total_number_of_episodes": 25118, "number_of_timesteps": 9130917, "per_episode_reward": 2.02, "episode_reward_trend_value": 0.0026156887406384617, "biggest_recent_change": 0.04596637419156968},
{"total_number_of_episodes": 25128, "number_of_timesteps": 9133529, "per_episode_reward": 2.05, "episode_reward_trend_value": 0.0023867858849768125, "biggest_recent_change": 0.04178448078741548},
{"total_number_of_episodes": 25138, "number_of_timesteps": 9136001, "per_episode_reward": 2.06, "episode_reward_trend_value": 0.002338414006965, "biggest_recent_change": 0.04178448078741548},
{"total_number_of_episodes": 25148, "number_of_timesteps": 9138616, "per_episode_reward": 2.07, "episode_reward_trend_value": 0.002281508802922547, "biggest_recent_change": 0.04178448078741548},
{"total_number_of_episodes": 25158, "number_of_timesteps": 9141067, "per_episode_reward": 2.08, "episode_reward_trend_value": 0.0018394326756305517, "biggest_recent_change": 0.04033385111922483},
{"total_number_of_episodes": 25168, "number_of_timesteps": 9143786, "per_episode_reward": 2.09, "episode_reward_trend_value": 0.0018265164606142519, "biggest_recent_change": 0.04033385111922483},
{"total_number_of_episodes": 25178, "number_of_timesteps": 9146696, "per_episode_reward": 2.14, "episode_reward_trend_value": 0.0019613354858906266, "biggest_recent_change": 0.04531595265319499},
{"total_number_of_episodes": 25188, "number_of_timesteps": 9149956, "per_episode_reward": 2.14, "episode_reward_trend_value": 0.0014649811533429603, "biggest_recent_change": 0.04531595265319499},
{"total_number_of_episodes": 25198, "number_of_timesteps": 9152447, "per_episode_reward": 2.14, "episode_reward_trend_value": 0.0013524590683605601, "biggest_recent_change": 0.04531595265319499},
{"total_number_of_episodes": 25208, "number_of_timesteps": 9155061, "per_episode_reward": 2.17, "episode_reward_trend_value": 0.0016795290217454478, "biggest_recent_change": 0.04531595265319499},
{"total_number_of_episodes": 25218, "number_of_timesteps": 9157547, "per_episode_reward": 2.22, "episode_reward_trend_value": 0.0018547800043306434, "biggest_recent_change": 0.04531595265319499},
{"total_number_of_episodes": 25228, "number_of_timesteps": 9159121, "per_episode_reward": 2.24, "episode_reward_trend_value": 0.0020060672554257438, "biggest_recent_change": 0.04531595265319499},
{"total_number_of_episodes": 25238, "number_of_timesteps": 9160573, "per_episode_reward": 2.22, "episode_reward_trend_value": 0.0016200154295822875, "biggest_recent_change": 0.04531595265319499},
{"total_number_of_episodes": 25248, "number_of_timesteps": 9162932, "per_episode_reward": 2.21, "episode_reward_trend_value": 0.001460443807639564, "biggest_recent_change": 0.04531595265319499},
{"total_number_of_episodes": 25258, "number_of_timesteps": 9165093, "per_episode_reward": 2.19, "episode_reward_trend_value": 0.001071060498380014, "biggest_recent_change": 0.04531595265319499},
{"total_number_of_episodes": 25268, "number_of_timesteps": 9167057, "per_episode_reward": 2.2, "episode_reward_trend_value": 0.0006372351844227649, "biggest_recent_change": 0.04113770561468888},
{"total_number_of_episodes": 25279, "number_of_timesteps": 9170052, "per_episode_reward": 2.21, "episode_reward_trend_value": 0.000781397634831402, "biggest_recent_change": 0.04113770561468888},
{"total_number_of_episodes": 25289, "number_of_timesteps": 9172201, "per_episode_reward": 2.25, "episode_reward_trend_value": 0.0011508929883332186, "biggest_recent_change": 0.04161416017701525},
{"total_number_of_episodes": 25299, "number_of_timesteps": 9173836, "per_episode_reward": 2.25, "episode_reward_trend_value": 0.0007893644984300587, "biggest_recent_change": 0.04161416017701525},
{"total_number_of_episodes": 25310, "number_of_timesteps": 9177133, "per_episode_reward": 2.27, "episode_reward_trend_value": 0.0006294187379330641, "biggest_recent_change": 0.04161416017701525},
{"total_number_of_episodes": 25320, "number_of_timesteps": 9178603, "per_episode_reward": 2.3, "episode_reward_trend_value": 0.0006617415953826515, "biggest_recent_change": 0.04161416017701525},
{"total_number_of_episodes": 25331, "number_of_timesteps": 9181287, "per_episode_reward": 2.25, "episode_reward_trend_value": 0.00037846788152154056, "biggest_recent_change": 0.04161416017701525},
{"total_number_of_episodes": 25341, "number_of_timesteps": 9183938, "per_episode_reward": 2.28, "episode_reward_trend_value": 0.000748765943899891, "biggest_recent_change": 0.04161416017701525},
{"total_number_of_episodes": 25351, "number_of_timesteps": 9187454, "per_episode_reward": 2.29, "episode_reward_trend_value": 0.0011015888628634475, "biggest_recent_change": 0.04161416017701525},
{"total_number_of_episodes": 25361, "number_of_timesteps": 9190591, "per_episode_reward": 2.36, "episode_reward_trend_value": 0.0017849033594513198, "biggest_recent_change": 0.06776997908995108},
{"total_number_of_episodes": 25372, "number_of_timesteps": 9195313, "per_episode_reward": 2.36, "episode_reward_trend_value": 0.0017525005911786923, "biggest_recent_change": 0.06776997908995108},
{"total_number_of_episodes": 25382, "number_of_timesteps": 9198261, "per_episode_reward": 2.38, "episode_reward_trend_value": 0.0014804817673794023, "biggest_recent_change": 0.06776997908995108},
{"total_number_of_episodes": 25393, "number_of_timesteps": 9201775, "per_episode_reward": 2.41, "episode_reward_trend_value": 0.0017826863693813206, "biggest_recent_change": 0.06776997908995108},
{"total_number_of_episodes": 25403, "number_of_timesteps": 9205379, "per_episode_reward": 2.42, "episode_reward_trend_value": 0.0016404218166612763, "biggest_recent_change": 0.06776997908995108},
{"total_number_of_episodes": 25413, "number_of_timesteps": 9208069, "per_episode_reward": 2.46, "episode_reward_trend_value": 0.0017943691947978637, "biggest_recent_change": 0.06776997908995108},
{"total_number_of_episodes": 25423, "number_of_timesteps": 9213307, "per_episode_reward": 2.48, "episode_reward_trend_value": 0.002507347058993581, "biggest_recent_change": 0.06776997908995108},
{"total_number_of_episodes": 25433, "number_of_timesteps": 9216106, "per_episode_reward": 2.47, "episode_reward_trend_value": 0.0021638740002175904, "biggest_recent_change": 0.06776997908995108},
{"total_number_of_episodes": 25443, "number_of_timesteps": 9218242, "per_episode_reward": 2.48, "episode_reward_trend_value": 0.002080058859314428, "biggest_recent_change": 0.06776997908995108},
{"total_number_of_episodes": 25453, "number_of_timesteps": 9220979, "per_episode_reward": 2.49, "episode_reward_trend_value": 0.0014672938843021074, "biggest_recent_change": 0.03781309813579359},
{"total_number_of_episodes": 25463, "number_of_timesteps": 9224662, "per_episode_reward": 2.5, "episode_reward_trend_value": 0.0014941565047116919, "biggest_recent_change": 0.03781309813579359},
{"total_number_of_episodes": 25473, "number_of_timesteps": 9227778, "per_episode_reward": 2.51, "episode_reward_trend_value": 0.001466358715552903, "biggest_recent_change": 0.03781309813579359},
{"total_number_of_episodes": 25484, "number_of_timesteps": 9231685, "per_episode_reward": 2.51, "episode_reward_trend_value": 0.00116980429877116, "biggest_recent_change": 0.03781309813579359},
{"total_number_of_episodes": 25494, "number_of_timesteps": 9235496, "per_episode_reward": 2.51, "episode_reward_trend_value": 0.0009964163619681987, "biggest_recent_change": 0.03781309813579359},
{"total_number_of_episodes": 25504, "number_of_timesteps": 9238638, "per_episode_reward": 2.52, "episode_reward_trend_value": 0.0006560644550322397, "biggest_recent_change": 0.022612742998214586},
{"total_number_of_episodes": 25514, "number_of_timesteps": 9244259, "per_episode_reward": 2.53, "episode_reward_trend_value": 0.0005027154212715009, "biggest_recent_change": 0.014630665010788135},
{"total_number_of_episodes": 25524, "number_of_timesteps": 9247648, "per_episode_reward": 2.52, "episode_reward_trend_value": 0.00056024190598717, "biggest_recent_change": 0.014630665010788135},
{"total_number_of_episodes": 25534, "number_of_timesteps": 9251404, "per_episode_reward": 2.54, "episode_reward_trend_value": 0.0007247734659546633, "biggest_recent_change": 0.021054155603273728},
{"total_number_of_episodes": 25544, "number_of_timesteps": 9256463, "per_episode_reward": 2.56, "episode_reward_trend_value": 0.0008072077436755531, "biggest_recent_change": 0.021054155603273728},
{"total_number_of_episodes": 25554, "number_of_timesteps": 9258865, "per_episode_reward": 2.6, "episode_reward_trend_value": 0.0011367809300783134, "biggest_recent_change": 0.03779955519528677},
{"total_number_of_episodes": 25564, "number_of_timesteps": 9262042, "per_episode_reward": 2.61, "episode_reward_trend_value": 0.0011143426370724976, "biggest_recent_change": 0.03779955519528677},
{"total_number_of_episodes": 25574, "number_of_timesteps": 9265748, "per_episode_reward": 2.62, "episode_reward_trend_value": 0.0011846974947929498, "biggest_recent_change": 0.03779955519528677},
{"total_number_of_episodes": 25584, "number_of_timesteps": 9267828, "per_episode_reward": 2.62, "episode_reward_trend_value": 0.0012185706502998539, "biggest_recent_change": 0.03779955519528677},
{"total_number_of_episodes": 25594, "number_of_timesteps": 9271347, "per_episode_reward": 2.64, "episode_reward_trend_value": 0.0013811363611479562, "biggest_recent_change": 0.03779955519528677},
{"total_number_of_episodes": 25604, "number_of_timesteps": 9273922, "per_episode_reward": 2.67, "episode_reward_trend_value": 0.0016412670436166603, "biggest_recent_change": 0.03779955519528677},
{"total_number_of_episodes": 25614, "number_of_timesteps": 9277396, "per_episode_reward": 2.68, "episode_reward_trend_value": 0.0017288236599005667, "biggest_recent_change": 0.03779955519528677},
{"total_number_of_episodes": 25625, "number_of_timesteps": 9281864, "per_episode_reward": 2.71, "episode_reward_trend_value": 0.0018631086913217377, "biggest_recent_change": 0.03779955519528677},
{"total_number_of_episodes": 25635, "number_of_timesteps": 9285936, "per_episode_reward": 2.75, "episode_reward_trend_value": 0.0020399101942145574, "biggest_recent_change": 0.03779955519528677},
{"total_number_of_episodes": 25645, "number_of_timesteps": 9290353, "per_episode_reward": 2.76, "episode_reward_trend_value": 0.001775214386746862, "biggest_recent_change": 0.03595235159407606},
{"total_number_of_episodes": 25656, "number_of_timesteps": 9292988, "per_episode_reward": 2.77, "episode_reward_trend_value": 0.001750861814218574, "biggest_recent_change": 0.03595235159407606},
{"total_number_of_episodes": 25666, "number_of_timesteps": 9295047, "per_episode_reward": 2.81, "episode_reward_trend_value": 0.002129685727545875, "biggest_recent_change": 0.03965734406916743},
{"total_number_of_episodes": 25676, "number_of_timesteps": 9301313, "per_episode_reward": 2.82, "episode_reward_trend_value": 0.002201728107431568, "biggest_recent_change": 0.03965734406916743},
{"total_number_of_episodes": 25686, "number_of_timesteps": 9306102, "per_episode_reward": 2.84, "episode_reward_trend_value": 0.0021719746496164085, "biggest_recent_change": 0.03965734406916743},
{"total_number_of_episodes": 25696, "number_of_timesteps": 9310626, "per_episode_reward": 2.85, "episode_reward_trend_value": 0.0019059180615600142, "biggest_recent_change": 0.03965734406916743},
{"total_number_of_episodes": 25706, "number_of_timesteps": 9315213, "per_episode_reward": 2.84, "episode_reward_trend_value": 0.0018553693515001295, "biggest_recent_change": 0.03965734406916743},
{"total_number_of_episodes": 25716, "number_of_timesteps": 9320098, "per_episode_reward": 2.85, "episode_reward_trend_value": 0.0015110671119804278, "biggest_recent_change": 0.03965734406916743},
{"total_number_of_episodes": 25726, "number_of_timesteps": 9324247, "per_episode_reward": 2.85, "episode_reward_trend_value": 0.0011944778399101106, "biggest_recent_change": 0.03965734406916743},
{"total_number_of_episodes": 25736, "number_of_timesteps": 9327609, "per_episode_reward": 2.84, "episode_reward_trend_value": 0.0009218749134496877, "biggest_recent_change": 0.03965734406916743},
{"total_number_of_episodes": 25746, "number_of_timesteps": 9331090, "per_episode_reward": 2.88, "episode_reward_trend_value": 0.0011671337215798604, "biggest_recent_change": 0.03965734406916743},
{"total_number_of_episodes": 25757, "number_of_timesteps": 9334329, "per_episode_reward": 2.86, "episode_reward_trend_value": 0.0005115627495582636, "biggest_recent_change": 0.03249277984443433},
{"total_number_of_episodes": 25767, "number_of_timesteps": 9335798, "per_episode_reward": 2.86, "episode_reward_trend_value": 0.0004166040207295928, "biggest_recent_change": 0.03249277984443433},
{"total_number_of_episodes": 25777, "number_of_timesteps": 9338370, "per_episode_reward": 2.85, "episode_reward_trend_value": 0.00016378650648306447, "biggest_recent_change": 0.03249277984443433},
{"total_number_of_episodes": 25787, "number_of_timesteps": 9340457, "per_episode_reward": 2.84, "episode_reward_trend_value": -6.547161016831184e-05, "biggest_recent_change": 0.03249277984443433},
{"total_number_of_episodes": 25797, "number_of_timesteps": 9342183, "per_episode_reward": 2.87, "episode_reward_trend_value": 0.000258624170155835, "biggest_recent_change": 0.03249277984443433},
{"total_number_of_episodes": 25807, "number_of_timesteps": 9346128, "per_episode_reward": 2.85, "episode_reward_trend_value": 3.212464854863089e-05, "biggest_recent_change": 0.03249277984443433},
{"total_number_of_episodes": 25817, "number_of_timesteps": 9350531, "per_episode_reward": 2.84, "episode_reward_trend_value": -0.00010576489118695835, "biggest_recent_change": 0.03249277984443433},
{"total_number_of_episodes": 25827, "number_of_timesteps": 9355182, "per_episode_reward": 2.86, "episode_reward_trend_value": 0.00015078248695035156, "biggest_recent_change": 0.03249277984443433},
{"total_number_of_episodes": 25837, "number_of_timesteps": 9358579, "per_episode_reward": 2.86, "episode_reward_trend_value": -0.0001731891993388906, "biggest_recent_change": 0.02772714909424856},
{"total_number_of_episodes": 25848, "number_of_timesteps": 9363492, "per_episode_reward": 2.85, "episode_reward_trend_value": -3.485474951158511e-05, "biggest_recent_change": 0.02772714909424856},
{"total_number_of_episodes": 25858, "number_of_timesteps": 9366206, "per_episode_reward": 2.87, "episode_reward_trend_value": 0.0001319032113053916, "biggest_recent_change": 0.02772714909424856},
{"total_number_of_episodes": 25868, "number_of_timesteps": 9369072, "per_episode_reward": 2.89, "episode_reward_trend_value": 0.0004264130072904789, "biggest_recent_change": 0.02772714909424856},
{"total_number_of_episodes": 25878, "number_of_timesteps": 9372398, "per_episode_reward": 2.89, "episode_reward_trend_value": 0.0005975253532100439, "biggest_recent_change": 0.02772714909424856},
{"total_number_of_episodes": 25888, "number_of_timesteps": 9374960, "per_episode_reward": 2.9, "episode_reward_trend_value": 0.0003678196634973979, "biggest_recent_change": 0.022886834640992504},
{"total_number_of_episodes": 25898, "number_of_timesteps": 9377298, "per_episode_reward": 2.9, "episode_reward_trend_value": 0.0005877967677707158, "biggest_recent_change": 0.022886834640992504},
{"total_number_of_episodes": 25908, "number_of_timesteps": 9379850, "per_episode_reward": 2.93, "episode_reward_trend_value": 0.000951927128792418, "biggest_recent_change": 0.027820991023497665},
{"total_number_of_episodes": 25918, "number_of_timesteps": 9383038, "per_episode_reward": 2.95, "episode_reward_trend_value": 0.00103253269024886, "biggest_recent_change": 0.027820991023497665},
{"total_number_of_episodes": 25928, "number_of_timesteps": 9386543, "per_episode_reward": 2.96, "episode_reward_trend_value": 0.0011351426028109568, "biggest_recent_change": 0.027820991023497665},
{"total_number_of_episodes": 25938, "number_of_timesteps": 9392175, "per_episode_reward": 3.0, "episode_reward_trend_value": 0.0016465188357955827, "biggest_recent_change": 0.03912991804029753},
{"total_number_of_episodes": 25948, "number_of_timesteps": 9396365, "per_episode_reward": 3.0, "episode_reward_trend_value": 0.001489751659211184, "biggest_recent_change": 0.03912991804029753},
{"total_number_of_episodes": 25958, "number_of_timesteps": 9399384, "per_episode_reward": 3.02, "episode_reward_trend_value": 0.0014450552555272376, "biggest_recent_change": 0.03912991804029753},
{"total_number_of_episodes": 25968, "number_of_timesteps": 9403240, "per_episode_reward": 3.03, "episode_reward_trend_value": 0.0014732943687968034, "biggest_recent_change": 0.03912991804029753},
{"total_number_of_episodes": 25978, "number_of_timesteps": 9406779, "per_episode_reward": 3.01, "episode_reward_trend_value": 0.0012472518436166305, "biggest_recent_change": 0.03912991804029753},
{"total_number_of_episodes": 25988, "number_of_timesteps": 9410367, "per_episode_reward": 3.0, "episode_reward_trend_value": 0.001054520467218372, "biggest_recent_change": 0.03912991804029753},
{"total_number_of_episodes": 25998, "number_of_timesteps": 9414389, "per_episode_reward": 2.99, "episode_reward_trend_value": 0.0007211058916978313, "biggest_recent_change": 0.03912991804029753},
{"total_number_of_episodes": 26008, "number_of_timesteps": 9417266, "per_episode_reward": 3.04, "episode_reward_trend_value": 0.0009844177085118213, "biggest_recent_change": 0.04348449721845293},
{"total_number_of_episodes": 26018, "number_of_timesteps": 9420417, "per_episode_reward": 3.01, "episode_reward_trend_value": 0.0005001790420607666, "biggest_recent_change": 0.04348449721845293},
{"total_number_of_episodes": 26028, "number_of_timesteps": 9423746, "per_episode_reward": 3.01, "episode_reward_trend_value": 0.00013333609638860937, "biggest_recent_change": 0.04348449721845293},
{"total_number_of_episodes": 26038, "number_of_timesteps": 9425239, "per_episode_reward": 3.01, "episode_reward_trend_value": 0.00011558328517798306, "biggest_recent_change": 0.04348449721845293},
{"total_number_of_episodes": 26048, "number_of_timesteps": 9427595, "per_episode_reward": 3.02, "episode_reward_trend_value": 1.603510391569153e-06, "biggest_recent_change": 0.04348449721845293},
{"total_number_of_episodes": 26058, "number_of_timesteps": 9430825, "per_episode_reward": 3.04, "episode_reward_trend_value": 0.0001283000410173053, "biggest_recent_change": 0.04348449721845293},
{"total_number_of_episodes": 26068, "number_of_timesteps": 9433294, "per_episode_reward": 3.05, "episode_reward_trend_value": 0.00046576896347292837, "biggest_recent_change": 0.04348449721845293},
{"total_number_of_episodes": 26078, "number_of_timesteps": 9436082, "per_episode_reward": 3.06, "episode_reward_trend_value": 0.0006667801320390342, "biggest_recent_change": 0.04348449721845293},
{"total_number_of_episodes": 26088, "number_of_timesteps": 9439474, "per_episode_reward": 3.05, "episode_reward_trend_value": 0.0006284050181487217, "biggest_recent_change": 0.04348449721845293},
{"total_number_of_episodes": 26098, "number_of_timesteps": 9441706, "per_episode_reward": 3.06, "episode_reward_trend_value": 0.0002265924539402183, "biggest_recent_change": 0.031011259771603683},
{"total_number_of_episodes": 26108, "number_of_timesteps": 9445545, "per_episode_reward": 3.05, "episode_reward_trend_value": 0.0005232827126096061, "biggest_recent_change": 0.017082012774900956},
{"total_number_of_episodes": 26119, "number_of_timesteps": 9448335, "per_episode_reward": 3.07, "episode_reward_trend_value": 0.0006020507809113833, "biggest_recent_change": 0.017082012774900956},
{"total_number_of_episodes": 26129, "number_of_timesteps": 9451360, "per_episode_reward": 3.09, "episode_reward_trend_value": 0.000868861448665776, "biggest_recent_change": 0.02263435337351316},
{"total_number_of_episodes": 26139, "number_of_timesteps": 9454316, "per_episode_reward": 3.07, "episode_reward_trend_value": 0.0006092474931331558, "biggest_recent_change": 0.02263435337351316},
{"total_number_of_episodes": 26149, "number_of_timesteps": 9457999, "per_episode_reward": 3.09, "episode_reward_trend_value": 0.0005939343549832621, "biggest_recent_change": 0.02263435337351316},
{"total_number_of_episodes": 26159, "number_of_timesteps": 9461367, "per_episode_reward": 3.1, "episode_reward_trend_value": 0.00048438290390299737, "biggest_recent_change": 0.02263435337351316},
{"total_number_of_episodes": 26169, "number_of_timesteps": 9463797, "per_episode_reward": 3.11, "episode_reward_trend_value": 0.0005423635358643974, "biggest_recent_change": 0.02263435337351316},
{"total_number_of_episodes": 26179, "number_of_timesteps": 9466607, "per_episode_reward": 3.15, "episode_reward_trend_value": 0.001078749096754297, "biggest_recent_change": 0.042634619456611844},
{"total_number_of_episodes": 26189, "number_of_timesteps": 9469533, "per_episode_reward": 3.2, "episode_reward_trend_value": 0.0015423572169793558, "biggest_recent_change": 0.04904609725994291},
{"total_number_of_episodes": 26199, "number_of_timesteps": 9473560, "per_episode_reward": 3.23, "episode_reward_trend_value": 0.0019234610310782823, "biggest_recent_change": 0.04904609725994291},
{"total_number_of_episodes": 26209, "number_of_timesteps": 9476505, "per_episode_reward": 3.22, "episode_reward_trend_value": 0.0016596369217968328, "biggest_recent_change": 0.04904609725994291},
{"total_number_of_episodes": 26219, "number_of_timesteps": 9479162, "per_episode_reward": 3.23, "episode_reward_trend_value": 0.001542796976149832, "biggest_recent_change": 0.04904609725994291},
{"total_number_of_episodes": 26229, "number_of_timesteps": 9482853, "per_episode_reward": 3.2, "episode_reward_trend_value": 0.001427306441875389, "biggest_recent_change": 0.04904609725994291},
{"total_number_of_episodes": 26239, "number_of_timesteps": 9486318, "per_episode_reward": 3.2, "episode_reward_trend_value": 0.0012105466946972035, "biggest_recent_change": 0.04904609725994291},
{"total_number_of_episodes": 26249, "number_of_timesteps": 9490061, "per_episode_reward": 3.24, "episode_reward_trend_value": 0.0015823843636308462, "biggest_recent_change": 0.04904609725994291},
{"total_number_of_episodes": 26259, "number_of_timesteps": 9492514, "per_episode_reward": 3.24, "episode_reward_trend_value": 0.001523821296636152, "biggest_recent_change": 0.04904609725994291},
{"total_number_of_episodes": 26269, "number_of_timesteps": 9494342, "per_episode_reward": 3.27, "episode_reward_trend_value": 0.0013985379390771997, "biggest_recent_change": 0.04904609725994291},
{"total_number_of_episodes": 26279, "number_of_timesteps": 9496118, "per_episode_reward": 3.26, "episode_reward_trend_value": 0.0007290504601474772, "biggest_recent_change": 0.040687772381704956},
{"total_number_of_episodes": 26289, "number_of_timesteps": 9497755, "per_episode_reward": 3.31, "episode_reward_trend_value": 0.0009352812374974108, "biggest_recent_change": 0.04855097673903863},
{"total_number_of_episodes": 26299, "number_of_timesteps": 9500145, "per_episode_reward": 3.31, "episode_reward_trend_value": 0.0010605756255220446, "biggest_recent_change": 0.04855097673903863},
{"total_number_of_episodes": 26310, "number_of_timesteps": 9506716, "per_episode_reward": 3.33, "episode_reward_trend_value": 0.0011562872685965835, "biggest_recent_change": 0.04855097673903863},
{"total_number_of_episodes": 26320, "number_of_timesteps": 9509887, "per_episode_reward": 3.34, "episode_reward_trend_value": 0.0014813775287779447, "biggest_recent_change": 0.04855097673903863},
{"total_number_of_episodes": 26330, "number_of_timesteps": 9512816, "per_episode_reward": 3.35, "episode_reward_trend_value": 0.001678791300655074, "biggest_recent_change": 0.04855097673903863},
{"total_number_of_episodes": 26340, "number_of_timesteps": 9516263, "per_episode_reward": 3.36, "episode_reward_trend_value": 0.0013543543586205932, "biggest_recent_change": 0.04855097673903863},
{"total_number_of_episodes": 26350, "number_of_timesteps": 9518886, "per_episode_reward": 3.37, "episode_reward_trend_value": 0.001438010048622049, "biggest_recent_change": 0.04855097673903863},
{"total_number_of_episodes": 26360, "number_of_timesteps": 9520316, "per_episode_reward": 3.38, "episode_reward_trend_value": 0.0011898755206313104, "biggest_recent_change": 0.04855097673903863},
{"total_number_of_episodes": 26371, "number_of_timesteps": 9521954, "per_episode_reward": 3.38, "episode_reward_trend_value": 0.0013524043293635165, "biggest_recent_change": 0.04855097673903863},
{"total_number_of_episodes": 26381, "number_of_timesteps": 9524062, "per_episode_reward": 3.4, "episode_reward_trend_value": 0.0010130046772892222, "biggest_recent_change": 0.020732806141991578},
{"total_number_of_episodes": 26391, "number_of_timesteps": 9528206, "per_episode_reward": 3.45, "episode_reward_trend_value": 0.001588331461535776, "biggest_recent_change": 0.052514914746039754},
{"total_number_of_episodes": 26401, "number_of_timesteps": 9529886, "per_episode_reward": 3.56, "episode_reward_trend_value": 0.0025314141353584133, "biggest_recent_change": 0.10561024678602893},
{"total_number_of_episodes": 26412, "number_of_timesteps": 9534333, "per_episode_reward": 3.58, "episode_reward_trend_value": 0.0027258408817038273, "biggest_recent_change": 0.10561024678602893},
{"total_number_of_episodes": 26422, "number_of_timesteps": 9537189, "per_episode_reward": 3.6, "episode_reward_trend_value": 0.002735007407059949, "biggest_recent_change": 0.10561024678602893},
{"total_number_of_episodes": 26432, "number_of_timesteps": 9539363, "per_episode_reward": 3.62, "episode_reward_trend_value": 0.0029139755080776226, "biggest_recent_change": 0.10561024678602893},
{"total_number_of_episodes": 26442, "number_of_timesteps": 9542457, "per_episode_reward": 3.66, "episode_reward_trend_value": 0.0032367888385931446, "biggest_recent_change": 0.10561024678602893},
{"total_number_of_episodes": 26452, "number_of_timesteps": 9545977, "per_episode_reward": 3.71, "episode_reward_trend_value": 0.0036672842906319966, "biggest_recent_change": 0.10561024678602893},
{"total_number_of_episodes": 26462, "number_of_timesteps": 9548874, "per_episode_reward": 3.68, "episode_reward_trend_value": 0.003263516057292229, "biggest_recent_change": 0.10561024678602893},
{"total_number_of_episodes": 26472, "number_of_timesteps": 9551091, "per_episode_reward": 3.7, "episode_reward_trend_value": 0.0032732762125718988, "biggest_recent_change": 0.10561024678602893},
{"total_number_of_episodes": 26483, "number_of_timesteps": 9556273, "per_episode_reward": 3.73, "episode_reward_trend_value": 0.0030793119015928095, "biggest_recent_change": 0.10561024678602893},
{"total_number_of_episodes": 26493, "number_of_timesteps": 9558359, "per_episode_reward": 3.74, "episode_reward_trend_value": 0.0019683319619823217, "biggest_recent_change": 0.04777160044063633},
{"total_number_of_episodes": 26504, "number_of_timesteps": 9560015, "per_episode_reward": 3.77, "episode_reward_trend_value": 0.0020415022804662897, "biggest_recent_change": 0.04777160044063633},
{"total_number_of_episodes": 26514, "number_of_timesteps": 9562803, "per_episode_reward": 3.78, "episode_reward_trend_value": 0.0020444929442756197, "biggest_recent_change": 0.04777160044063633},
{"total_number_of_episodes": 26525, "number_of_timesteps": 9567453, "per_episode_reward": 3.83, "episode_reward_trend_value": 0.002299110120680699, "biggest_recent_change": 0.05051112256664947},
{"total_number_of_episodes": 26535, "number_of_timesteps": 9570082, "per_episode_reward": 3.86, "episode_reward_trend_value": 0.0022377718991961172, "biggest_recent_change": 0.05051112256664947},
{"total_number_of_episodes": 26545, "number_of_timesteps": 9573808, "per_episode_reward": 3.9, "episode_reward_trend_value": 0.0020604436113588766, "biggest_recent_change": 0.05051112256664947},
{"total_number_of_episodes": 26555, "number_of_timesteps": 9578144, "per_episode_reward": 3.94, "episode_reward_trend_value": 0.002961015512856497, "biggest_recent_change": 0.05051112256664947},
{"total_number_of_episodes": 26565, "number_of_timesteps": 9580385, "per_episode_reward": 3.94, "episode_reward_trend_value": 0.0027530234411159227, "biggest_recent_change": 0.05051112256664947},
{"total_number_of_episodes": 26576, "number_of_timesteps": 9585197, "per_episode_reward": 3.95, "episode_reward_trend_value": 0.002390961046935327, "biggest_recent_change": 0.05051112256664947},
{"total_number_of_episodes": 26586, "number_of_timesteps": 9587184, "per_episode_reward": 3.93, "episode_reward_trend_value": 0.0021248564109498896, "biggest_recent_change": 0.05051112256664947},
{"total_number_of_episodes": 26596, "number_of_timesteps": 9588943, "per_episode_reward": 3.93, "episode_reward_trend_value": 0.0017859785882663212, "biggest_recent_change": 0.05051112256664947},
{"total_number_of_episodes": 26606, "number_of_timesteps": 9592370, "per_episode_reward": 3.96, "episode_reward_trend_value": 0.0019785049536469065, "biggest_recent_change": 0.05051112256664947},
{"total_number_of_episodes": 26616, "number_of_timesteps": 9594440, "per_episode_reward": 3.96, "episode_reward_trend_value": 0.0014020673177523079, "biggest_recent_change": 0.048132147076373144},
{"total_number_of_episodes": 26626, "number_of_timesteps": 9597148, "per_episode_reward": 3.95, "episode_reward_trend_value": 0.0009634337085983515, "biggest_recent_change": 0.048132147076373144},
{"total_number_of_episodes": 26636, "number_of_timesteps": 9599855, "per_episode_reward": 3.95, "episode_reward_trend_value": 0.0006336806866204142, "biggest_recent_change": 0.048132147076373144},
{"total_number_of_episodes": 26646, "number_of_timesteps": 9604827, "per_episode_reward": 3.99, "episode_reward_trend_value": 0.0005127175749140258, "biggest_recent_change": 0.037245467022798184},
{"total_number_of_episodes": 26656, "number_of_timesteps": 9607757, "per_episode_reward": 4.0, "episode_reward_trend_value": 0.0006478686413571053, "biggest_recent_change": 0.037245467022798184},
{"total_number_of_episodes": 26666, "number_of_timesteps": 9611761, "per_episode_reward": 4.02, "episode_reward_trend_value": 0.0007654596045157478, "biggest_recent_change": 0.037245467022798184},
{"total_number_of_episodes": 26676, "number_of_timesteps": 9614643, "per_episode_reward": 4.04, "episode_reward_trend_value": 0.0012002182528576396, "biggest_recent_change": 0.037245467022798184},
{"total_number_of_episodes": 26686, "number_of_timesteps": 9617503, "per_episode_reward": 4.03, "episode_reward_trend_value": 0.0011423144376959064, "biggest_recent_change": 0.037245467022798184},
{"total_number_of_episodes": 26696, "number_of_timesteps": 9619816, "per_episode_reward": 4.06, "episode_reward_trend_value": 0.0011618713779314818, "biggest_recent_change": 0.037245467022798184},
{"total_number_of_episodes": 26706, "number_of_timesteps": 9622867, "per_episode_reward": 4.13, "episode_reward_trend_value": 0.0019265701783406266, "biggest_recent_change": 0.0674546273729586},
{"total_number_of_episodes": 26717, "number_of_timesteps": 9626236, "per_episode_reward": 4.13, "episode_reward_trend_value": 0.001975451030597419, "biggest_recent_change": 0.0674546273729586},
{"total_number_of_episodes": 26727, "number_of_timesteps": 9628890, "per_episode_reward": 4.15, "episode_reward_trend_value": 0.002139083358767661, "biggest_recent_change": 0.0674546273729586},
{"total_number_of_episodes": 26737, "number_of_timesteps": 9632149, "per_episode_reward": 4.18, "episode_reward_trend_value": 0.0020719276947184797, "biggest_recent_change": 0.0674546273729586},
{"total_number_of_episodes": 26747, "number_of_timesteps": 9635241, "per_episode_reward": 4.19, "episode_reward_trend_value": 0.0020590602272679464, "biggest_recent_change": 0.0674546273729586},
{"total_number_of_episodes": 26757, "number_of_timesteps": 9637259, "per_episode_reward": 4.21, "episode_reward_trend_value": 0.0021472197861549325, "biggest_recent_change": 0.0674546273729586},
{"total_number_of_episodes": 26767, "number_of_timesteps": 9638977, "per_episode_reward": 4.22, "episode_reward_trend_value": 0.0020123201219189053, "biggest_recent_change": 0.0674546273729586},
{"total_number_of_episodes": 26777, "number_of_timesteps": 9642312, "per_episode_reward": 4.22, "episode_reward_trend_value": 0.0021470819731764026, "biggest_recent_change": 0.0674546273729586},
{"total_number_of_episodes": 26787, "number_of_timesteps": 9646880, "per_episode_reward": 4.24, "episode_reward_trend_value": 0.0019802149227683566, "biggest_recent_change": 0.0674546273729586},
{"total_number_of_episodes": 26798, "number_of_timesteps": 9651314, "per_episode_reward": 4.29, "episode_reward_trend_value": 0.001738080276616473, "biggest_recent_change": 0.04566250921928905},
{"total_number_of_episodes": 26808, "number_of_timesteps": 9654314, "per_episode_reward": 4.29, "episode_reward_trend_value": 0.0017620820165476542, "biggest_recent_change": 0.04566250921928905},
{"total_number_of_episodes": 26818, "number_of_timesteps": 9656966, "per_episode_reward": 4.32, "episode_reward_trend_value": 0.0019408218629865636, "biggest_recent_change": 0.04566250921928905},
{"total_number_of_episodes": 26828, "number_of_timesteps": 9659724, "per_episode_reward": 4.34, "episode_reward_trend_value": 0.0017604550438119974, "biggest_recent_change": 0.04566250921928905},
{"total_number_of_episodes": 26838, "number_of_timesteps": 9661583, "per_episode_reward": 4.36, "episode_reward_trend_value": 0.0018913181248600135, "biggest_recent_change": 0.04566250921928905},
{"total_number_of_episodes": 26848, "number_of_timesteps": 9665615, "per_episode_reward": 4.41, "episode_reward_trend_value": 0.002210407130158476, "biggest_recent_change": 0.049708068742636335},
{"total_number_of_episodes": 26858, "number_of_timesteps": 9667465, "per_episode_reward": 4.4, "episode_reward_trend_value": 0.0020610537007896587, "biggest_recent_change": 0.049708068742636335},
{"total_number_of_episodes": 26868, "number_of_timesteps": 9670903, "per_episode_reward": 4.43, "episode_reward_trend_value": 0.0023019924031200665, "biggest_recent_change": 0.049708068742636335},
{"total_number_of_episodes": 26878, "number_of_timesteps": 9673828, "per_episode_reward": 4.44, "episode_reward_trend_value": 0.002241660317850336, "biggest_recent_change": 0.049708068742636335},
{"total_number_of_episodes": 26888, "number_of_timesteps": 9677018, "per_episode_reward": 4.46, "episode_reward_trend_value": 0.001866279019118829, "biggest_recent_change": 0.049708068742636335},
{"total_number_of_episodes": 26899, "number_of_timesteps": 9681720, "per_episode_reward": 4.49, "episode_reward_trend_value": 0.0022327773727685634, "biggest_recent_change": 0.049708068742636335},
{"total_number_of_episodes": 26909, "number_of_timesteps": 9683132, "per_episode_reward": 4.51, "episode_reward_trend_value": 0.002157998161664951, "biggest_recent_change": 0.049708068742636335},
{"total_number_of_episodes": 26919, "number_of_timesteps": 9684863, "per_episode_reward": 4.54, "episode_reward_trend_value": 0.0023024625656650126, "biggest_recent_change": 0.049708068742636335},
{"total_number_of_episodes": 26929, "number_of_timesteps": 9686368, "per_episode_reward": 4.56, "episode_reward_trend_value": 0.0022914838413687815, "biggest_recent_change": 0.049708068742636335},
{"total_number_of_episodes": 26939, "number_of_timesteps": 9688041, "per_episode_reward": 4.56, "episode_reward_trend_value": 0.0016478548341372818, "biggest_recent_change": 0.03338738367091931},
{"total_number_of_episodes": 26949, "number_of_timesteps": 9691228, "per_episode_reward": 4.57, "episode_reward_trend_value": 0.0018207281964237945, "biggest_recent_change": 0.03338738367091931},
{"total_number_of_episodes": 26959, "number_of_timesteps": 9694615, "per_episode_reward": 4.59, "episode_reward_trend_value": 0.0018278615023683404, "biggest_recent_change": 0.03338738367091931},
{"total_number_of_episodes": 26969, "number_of_timesteps": 9699917, "per_episode_reward": 4.6, "episode_reward_trend_value": 0.001735883333765267, "biggest_recent_change": 0.03338738367091931},
{"total_number_of_episodes": 26979, "number_of_timesteps": 9702683, "per_episode_reward": 4.64, "episode_reward_trend_value": 0.002025071446987958, "biggest_recent_change": 0.03790512252349565},
{"total_number_of_episodes": 26989, "number_of_timesteps": 9704843, "per_episode_reward": 4.65, "episode_reward_trend_value": 0.001785656096012526, "biggest_recent_change": 0.03790512252349565},
{"total_number_of_episodes": 26999, "number_of_timesteps": 9706869, "per_episode_reward": 4.66, "episode_reward_trend_value": 0.0015704299962134428, "biggest_recent_change": 0.03790512252349565},
{"total_number_of_episodes": 27009, "number_of_timesteps": 9709961, "per_episode_reward": 4.67, "episode_reward_trend_value": 0.0013734815421881782, "biggest_recent_change": 0.03790512252349565},
{"total_number_of_episodes": 27019, "number_of_timesteps": 9712917, "per_episode_reward": 4.7, "episode_reward_trend_value": 0.0015284354718439511, "biggest_recent_change": 0.03790512252349565},
{"total_number_of_episodes": 27029, "number_of_timesteps": 9714724, "per_episode_reward": 4.73, "episode_reward_trend_value": 0.0019241538138560443, "biggest_recent_change": 0.03790512252349565},
{"total_number_of_episodes": 27040, "number_of_timesteps": 9717205, "per_episode_reward": 4.74, "episode_reward_trend_value": 0.0019181045598100372, "biggest_recent_change": 0.03790512252349565},
{"total_number_of_episodes": 27050, "number_of_timesteps": 9718849, "per_episode_reward": 4.77, "episode_reward_trend_value": 0.001968141941055151, "biggest_recent_change": 0.03790512252349565},
{"total_number_of_episodes": 27060, "number_of_timesteps": 9720615, "per_episode_reward": 4.84, "episode_reward_trend_value": 0.0026497790979828, "biggest_recent_change": 0.06667279809954163},
{"total_number_of_episodes": 27070, "number_of_timesteps": 9722415, "per_episode_reward": 4.87, "episode_reward_trend_value": 0.0025587077627400407, "biggest_recent_change": 0.06667279809954163},
{"total_number_of_episodes": 27080, "number_of_timesteps": 9724561, "per_episode_reward": 4.89, "episode_reward_trend_value": 0.0026304423137196845, "biggest_recent_change": 0.06667279809954163},
{"total_number_of_episodes": 27090, "number_of_timesteps": 9727176, "per_episode_reward": 4.9, "episode_reward_trend_value": 0.00265858582986193, "biggest_recent_change": 0.06667279809954163},
{"total_number_of_episodes": 27101, "number_of_timesteps": 9730253, "per_episode_reward": 4.92, "episode_reward_trend_value": 0.0028388281069069874, "biggest_recent_change": 0.06667279809954163},
{"total_number_of_episodes": 27111, "number_of_timesteps": 9732919, "per_episode_reward": 4.89, "episode_reward_trend_value": 0.002090699102329739, "biggest_recent_change": 0.06667279809954163},
{"total_number_of_episodes": 27121, "number_of_timesteps": 9735646, "per_episode_reward": 4.92, "episode_reward_trend_value": 0.0021138676320638853, "biggest_recent_change": 0.06667279809954163},
{"total_number_of_episodes": 27131, "number_of_timesteps": 9738988, "per_episode_reward": 4.94, "episode_reward_trend_value": 0.002263192249491613, "biggest_recent_change": 0.06667279809954163},
{"total_number_of_episodes": 27141, "number_of_timesteps": 9741784, "per_episode_reward": 4.95, "episode_reward_trend_value": 0.0020397387644355922, "biggest_recent_change": 0.06667279809954163},
{"total_number_of_episodes": 27151, "number_of_timesteps": 9746010, "per_episode_reward": 4.97, "episode_reward_trend_value": 0.0014833061310059175, "biggest_recent_change": 0.03142650515507217},
{"total_number_of_episodes": 27161, "number_of_timesteps": 9748720, "per_episode_reward": 4.99, "episode_reward_trend_value": 0.0013192942066058539, "biggest_recent_change": 0.03142650515507217},
{"total_number_of_episodes": 27171, "number_of_timesteps": 9753192, "per_episode_reward": 5.01, "episode_reward_trend_value": 0.0013689226863623184, "biggest_recent_change": 0.03142650515507217},
{"total_number_of_episodes": 27181, "number_of_timesteps": 9757484, "per_episode_reward": 5.02, "episode_reward_trend_value": 0.0013942201583268322, "biggest_recent_change": 0.03142650515507217},
{"total_number_of_episodes": 27191, "number_of_timesteps": 9761533, "per_episode_reward": 5.05, "episode_reward_trend_value": 0.0013947197470811387, "biggest_recent_change": 0.03142650515507217},
{"total_number_of_episodes": 27201, "number_of_timesteps": 9764359, "per_episode_reward": 5.04, "episode_reward_trend_value": 0.001651765048853547, "biggest_recent_change": 0.02948127654896293},
{"total_number_of_episodes": 27211, "number_of_timesteps": 9766287, "per_episode_reward": 5.06, "episode_reward_trend_value": 0.0015902847911456537, "biggest_recent_change": 0.026511646952335433},
{"total_number_of_episodes": 27221, "number_of_timesteps": 9770001, "per_episode_reward": 5.09, "episode_reward_trend_value": 0.0015801721802099502, "biggest_recent_change": 0.026511646952335433},
{"total_number_of_episodes": 27231, "number_of_timesteps": 9773875, "per_episode_reward": 5.11, "episode_reward_trend_value": 0.0017262516669544442, "biggest_recent_change": 0.026511646952335433},
{"total_number_of_episodes": 27241, "number_of_timesteps": 9776306, "per_episode_reward": 5.14, "episode_reward_trend_value": 0.0018822152092518546, "biggest_recent_change": 0.030630579897637844},
{"total_number_of_episodes": 27251, "number_of_timesteps": 9778094, "per_episode_reward": 5.17, "episode_reward_trend_value": 0.0020482182553602196, "biggest_recent_change": 0.030630579897637844},
{"total_number_of_episodes": 27261, "number_of_timesteps": 9779778, "per_episode_reward": 5.15, "episode_reward_trend_value": 0.001557269340129973, "biggest_recent_change": 0.030630579897637844},
{"total_number_of_episodes": 27271, "number_of_timesteps": 9782170, "per_episode_reward": 5.16, "episode_reward_trend_value": 0.0015136675287289335, "biggest_recent_change": 0.030630579897637844},
{"total_number_of_episodes": 27281, "number_of_timesteps": 9785324, "per_episode_reward": 5.17, "episode_reward_trend_value": 0.001345690279233875, "biggest_recent_change": 0.030630579897637844},
{"total_number_of_episodes": 27291, "number_of_timesteps": 9788346, "per_episode_reward": 5.19, "episode_reward_trend_value": 0.001658911462412021, "biggest_recent_change": 0.030630579897637844},
{"total_number_of_episodes": 27301, "number_of_timesteps": 9792439, "per_episode_reward": 5.22, "episode_reward_trend_value": 0.0017762815472396553, "biggest_recent_change": 0.034511360989739615},
{"total_number_of_episodes": 27311, "number_of_timesteps": 9795722, "per_episode_reward": 5.23, "episode_reward_trend_value": 0.0016369968765201867, "biggest_recent_change": 0.034511360989739615},
{"total_number_of_episodes": 27321, "number_of_timesteps": 9799631, "per_episode_reward": 5.26, "episode_reward_trend_value": 0.0016840944258050012, "biggest_recent_change": 0.034511360989739615},
{"total_number_of_episodes": 27331, "number_of_timesteps": 9804140, "per_episode_reward": 5.31, "episode_reward_trend_value": 0.001920642009589181, "biggest_recent_change": 0.051919862438214004},
{"total_number_of_episodes": 27341, "number_of_timesteps": 9807933, "per_episode_reward": 5.33, "episode_reward_trend_value": 0.0017251857541994652, "biggest_recent_change": 0.051919862438214004},
{"total_number_of_episodes": 27351, "number_of_timesteps": 9811108, "per_episode_reward": 5.35, "episode_reward_trend_value": 0.0022149994654140533, "biggest_recent_change": 0.051919862438214004},
{"total_number_of_episodes": 27361, "number_of_timesteps": 9813467, "per_episode_reward": 5.33, "episode_reward_trend_value": 0.0019341764860578553, "biggest_recent_change": 0.051919862438214004},
{"total_number_of_episodes": 27371, "number_of_timesteps": 9816612, "per_episode_reward": 5.32, "episode_reward_trend_value": 0.0017173773138885115, "biggest_recent_change": 0.051919862438214004},
{"total_number_of_episodes": 27381, "number_of_timesteps": 9819270, "per_episode_reward": 5.34, "episode_reward_trend_value": 0.0016840141375923895, "biggest_recent_change": 0.051919862438214004},
{"total_number_of_episodes": 27391, "number_of_timesteps": 9823717, "per_episode_reward": 5.33, "episode_reward_trend_value": 0.0011858548595261907, "biggest_recent_change": 0.051919862438214004},
{"total_number_of_episodes": 27401, "number_of_timesteps": 9826652, "per_episode_reward": 5.31, "episode_reward_trend_value": 0.0008508630480424569, "biggest_recent_change": 0.051919862438214004},
{"total_number_of_episodes": 27411, "number_of_timesteps": 9829346, "per_episode_reward": 5.32, "episode_reward_trend_value": 0.0006683645738154078, "biggest_recent_change": 0.051919862438214004},
{"total_number_of_episodes": 27421, "number_of_timesteps": 9831797, "per_episode_reward": 5.31, "episode_reward_trend_value": -3.874499149060363e-06, "biggest_recent_change": 0.0226605064879708},
{"total_number_of_episodes": 27431, "number_of_timesteps": 9833349, "per_episode_reward": 5.33, "episode_reward_trend_value": 3.718710176792644e-05, "biggest_recent_change": 0.0226605064879708},
{"total_number_of_episodes": 27441, "number_of_timesteps": 9835899, "per_episode_reward": 5.38, "episode_reward_trend_value": 0.0003324713903768995, "biggest_recent_change": 0.04923609246277838},
{"total_number_of_episodes": 27452, "number_of_timesteps": 9839427, "per_episode_reward": 5.41, "episode_reward_trend_value": 0.0008645878541993094, "biggest_recent_change": 0.04923609246277838},
{"total_number_of_episodes": 27462, "number_of_timesteps": 9843797, "per_episode_reward": 5.42, "episode_reward_trend_value": 0.001069377046454889, "biggest_recent_change": 0.04923609246277838},
{"total_number_of_episodes": 27472, "number_of_timesteps": 9846831, "per_episode_reward": 5.43, "episode_reward_trend_value": 0.0009926525131413713, "biggest_recent_change": 0.04923609246277838},
{"total_number_of_episodes": 27483, "number_of_timesteps": 9849082, "per_episode_reward": 5.44, "episode_reward_trend_value": 0.001262215068232712, "biggest_recent_change": 0.04923609246277838},
{"total_number_of_episodes": 27493, "number_of_timesteps": 9851445, "per_episode_reward": 5.45, "episode_reward_trend_value": 0.0015936402190517087, "biggest_recent_change": 0.04923609246277838},
{"total_number_of_episodes": 27503, "number_of_timesteps": 9853889, "per_episode_reward": 5.51, "episode_reward_trend_value": 0.0021105457147710775, "biggest_recent_change": 0.05880824953279973},
{"total_number_of_episodes": 27513, "number_of_timesteps": 9856082, "per_episode_reward": 5.56, "episode_reward_trend_value": 0.0027055317244872273, "biggest_recent_change": 0.05880824953279973},
{"total_number_of_episodes": 27523, "number_of_timesteps": 9858369, "per_episode_reward": 5.6, "episode_reward_trend_value": 0.0029566074091029195, "biggest_recent_change": 0.05880824953279973},
{"total_number_of_episodes": 27533, "number_of_timesteps": 9861948, "per_episode_reward": 5.64, "episode_reward_trend_value": 0.0029546396443632045, "biggest_recent_change": 0.05880824953279973},
{"total_number_of_episodes": 27544, "number_of_timesteps": 9864140, "per_episode_reward": 5.62, "episode_reward_trend_value": 0.0023501830930270314, "biggest_recent_change": 0.05880824953279973},
{"total_number_of_episodes": 27554, "number_of_timesteps": 9868546, "per_episode_reward": 5.69, "episode_reward_trend_value": 0.003003286365608885, "biggest_recent_change": 0.06909209083790824},
{"total_number_of_episodes": 27564, "number_of_timesteps": 9872817, "per_episode_reward": 5.71, "episode_reward_trend_value": 0.0030834746966738715, "biggest_recent_change": 0.06909209083790824},
{"total_number_of_episodes": 27574, "number_of_timesteps": 9876915, "per_episode_reward": 5.73, "episode_reward_trend_value": 0.003184224747360807, "biggest_recent_change": 0.06909209083790824},
{"total_number_of_episodes": 27585, "number_of_timesteps": 9879304, "per_episode_reward": 5.71, "episode_reward_trend_value": 0.002904725047325702, "biggest_recent_change": 0.06909209083790824},
{"total_number_of_episodes": 27595, "number_of_timesteps": 9882328, "per_episode_reward": 5.76, "episode_reward_trend_value": 0.002744170208764856, "biggest_recent_change": 0.06909209083790824},
{"total_number_of_episodes": 27605, "number_of_timesteps": 9883904, "per_episode_reward": 5.75, "episode_reward_trend_value": 0.0020931141886963447, "biggest_recent_change": 0.06909209083790824},
{"total_number_of_episodes": 27615, "number_of_timesteps": 9885379, "per_episode_reward": 5.78, "episode_reward_trend_value": 0.00202419163778164, "biggest_recent_change": 0.06909209083790824},
{"total_number_of_episodes": 27625, "number_of_timesteps": 9887897, "per_episode_reward": 5.74, "episode_reward_trend_value": 0.001083490477465807, "biggest_recent_change": 0.06909209083790824},
{"total_number_of_episodes": 27635, "number_of_timesteps": 9890822, "per_episode_reward": 5.78, "episode_reward_trend_value": 0.001745180020453861, "biggest_recent_change": 0.06909209083790824},
{"total_number_of_episodes": 27646, "number_of_timesteps": 9895343, "per_episode_reward": 5.8, "episode_reward_trend_value": 0.0012024796807138948, "biggest_recent_change": 0.0443583140623236},
{"total_number_of_episodes": 27656, "number_of_timesteps": 9897419, "per_episode_reward": 5.82, "episode_reward_trend_value": 0.0012246490654966142, "biggest_recent_change": 0.0443583140623236},
{"total_number_of_episodes": 27667, "number_of_timesteps": 9901741, "per_episode_reward": 5.81, "episode_reward_trend_value": 0.0009440239772091432, "biggest_recent_change": 0.0443583140623236},
{"total_number_of_episodes": 27678, "number_of_timesteps": 9904518, "per_episode_reward": 5.85, "episode_reward_trend_value": 0.0015124553095180952, "biggest_recent_change": 0.0443583140623236},
{"total_number_of_episodes": 27688, "number_of_timesteps": 9907897, "per_episode_reward": 5.84, "episode_reward_trend_value": 0.0009188941282215899, "biggest_recent_change": 0.0359086123147252},
{"total_number_of_episodes": 27698, "number_of_timesteps": 9915393, "per_episode_reward": 5.84, "episode_reward_trend_value": 0.0010847178786184328, "biggest_recent_change": 0.0359086123147252},
{"total_number_of_episodes": 27708, "number_of_timesteps": 9921053, "per_episode_reward": 5.85, "episode_reward_trend_value": 0.0008160040897071971, "biggest_recent_change": 0.0359086123147252},
{"total_number_of_episodes": 27719, "number_of_timesteps": 9924394, "per_episode_reward": 5.85, "episode_reward_trend_value": 0.0012085704907860576, "biggest_recent_change": 0.0359086123147252},
{"total_number_of_episodes": 27729, "number_of_timesteps": 9926531, "per_episode_reward": 5.86, "episode_reward_trend_value": 0.0009043339892325678, "biggest_recent_change": 0.0359086123147252},
{"total_number_of_episodes": 27739, "number_of_timesteps": 9929147, "per_episode_reward": 5.86, "episode_reward_trend_value": 0.0006771340577448154, "biggest_recent_change": 0.0359086123147252},
{"total_number_of_episodes": 27749, "number_of_timesteps": 9930508, "per_episode_reward": 5.87, "episode_reward_trend_value": 0.0006292892976716067, "biggest_recent_change": 0.0359086123147252},
{"total_number_of_episodes": 27759, "number_of_timesteps": 9933049, "per_episode_reward": 5.88, "episode_reward_trend_value": 0.0007630238890367143, "biggest_recent_change": 0.0359086123147252},
{"total_number_of_episodes": 27769, "number_of_timesteps": 9934653, "per_episode_reward": 5.9, "episode_reward_trend_value": 0.0005033082649681042, "biggest_recent_change": 0.014895750645314898},
{"total_number_of_episodes": 27779, "number_of_timesteps": 9938069, "per_episode_reward": 5.9, "episode_reward_trend_value": 0.0006045393576456565, "biggest_recent_change": 0.014895750645314898},
{"total_number_of_episodes": 27789, "number_of_timesteps": 9943514, "per_episode_reward": 5.91, "episode_reward_trend_value": 0.0007683413207939182, "biggest_recent_change": 0.01603835915875873},
{"total_number_of_episodes": 27799, "number_of_timesteps": 9946836, "per_episode_reward": 5.93, "episode_reward_trend_value": 0.0008574609947242055, "biggest_recent_change": 0.016222696087652366},
{"total_number_of_episodes": 27809, "number_of_timesteps": 9949571, "per_episode_reward": 5.93, "episode_reward_trend_value": 0.0008916342669386049, "biggest_recent_change": 0.016222696087652366},
{"total_number_of_episodes": 27819, "number_of_timesteps": 9953882, "per_episode_reward": 5.95, "episode_reward_trend_value": 0.0009836697375090173, "biggest_recent_change": 0.01640211625651755},
{"total_number_of_episodes": 27829, "number_of_timesteps": 9957486, "per_episode_reward": 5.96, "episode_reward_trend_value": 0.0010866958449663876, "biggest_recent_change": 0.01640211625651755},
{"total_number_of_episodes": 27839, "number_of_timesteps": 9959264, "per_episode_reward": 5.96, "episode_reward_trend_value": 0.000989627738649299, "biggest_recent_change": 0.01640211625651755},
{"total_number_of_episodes": 27849, "number_of_timesteps": 9962768, "per_episode_reward": 5.98, "episode_reward_trend_value": 0.001089338370545967, "biggest_recent_change": 0.018758972631514048},
{"total_number_of_episodes": 27859, "number_of_timesteps": 9965222, "per_episode_reward": 5.96, "episode_reward_trend_value": 0.0006957444881875219, "biggest_recent_change": 0.02288924326370978},
{"total_number_of_episodes": 27869, "number_of_timesteps": 9968617, "per_episode_reward": 5.97, "episode_reward_trend_value": 0.0008191700991780927, "biggest_recent_change": 0.02288924326370978},
{"total_number_of_episodes": 27879, "number_of_timesteps": 9970654, "per_episode_reward": 5.97, "episode_reward_trend_value": 0.0006898408560104584, "biggest_recent_change": 0.02288924326370978},
{"total_number_of_episodes": 27889, "number_of_timesteps": 9972521, "per_episode_reward": 5.96, "episode_reward_trend_value": 0.00039918851519500366, "biggest_recent_change": 0.02288924326370978},
{"total_number_of_episodes": 27899, "number_of_timesteps": 9974746, "per_episode_reward": 5.96, "episode_reward_trend_value": 0.00027979101119168543, "biggest_recent_change": 0.02288924326370978},
{"total_number_of_episodes": 27909, "number_of_timesteps": 9976934, "per_episode_reward": 5.96, "episode_reward_trend_value": 0.00018067609856349992, "biggest_recent_change": 0.02288924326370978},
{"total_number_of_episodes": 27919, "number_of_timesteps": 9979933, "per_episode_reward": 5.99, "episode_reward_trend_value": 0.0003346972132965161, "biggest_recent_change": 0.02293531642454827},
{"total_number_of_episodes": 27929, "number_of_timesteps": 9985700, "per_episode_reward": 6.0, "episode_reward_trend_value": 0.00042181564402987703, "biggest_recent_change": 0.02293531642454827},
{"total_number_of_episodes": 27939, "number_of_timesteps": 9989954, "per_episode_reward": 6.01, "episode_reward_trend_value": 0.00030844471320109356, "biggest_recent_change": 0.02293531642454827},
{"total_number_of_episodes": 27949, "number_of_timesteps": 9992303, "per_episode_reward": 6.04, "episode_reward_trend_value": 0.0008683373180719755, "biggest_recent_change": 0.02750109117466959},
{"total_number_of_episodes": 27959, "number_of_timesteps": 9998886, "per_episode_reward": 6.06, "episode_reward_trend_value": 0.0009722164830371484, "biggest_recent_change": 0.02750109117466959},
{"total_number_of_episodes": 27969, "number_of_timesteps": 10003804, "per_episode_reward": 6.08, "episode_reward_trend_value": 0.0011439050897553728, "biggest_recent_change": 0.02750109117466959},
{"total_number_of_episodes": 27979, "number_of_timesteps": 10010000, "per_episode_reward": 6.08, "episode_reward_trend_value": 0.001254080887411134, "biggest_recent_change": 0.02750109117466959},
{"total_number_of_episodes": 27989, "number_of_timesteps": 10013955, "per_episode_reward": 6.09, "episode_reward_trend_value": 0.0014825171205589548, "biggest_recent_change": 0.02750109117466959},
{"total_number_of_episodes": 28000, "number_of_timesteps": 10016433, "per_episode_reward": 6.11, "episode_reward_trend_value": 0.0016463026226708898, "biggest_recent_change": 0.02750109117466959},
{"total_number_of_episodes": 28010, "number_of_timesteps": 10018211, "per_episode_reward": 6.13, "episode_reward_trend_value": 0.001607911849612768, "biggest_recent_change": 0.02750109117466959},
{"total_number_of_episodes": 28020, "number_of_timesteps": 10021129, "per_episode_reward": 6.16, "episode_reward_trend_value": 0.0017448562173344325, "biggest_recent_change": 0.02750109117466959},
{"total_number_of_episodes": 28031, "number_of_timesteps": 10022567, "per_episode_reward": 6.17, "episode_reward_trend_value": 0.001768982296965089, "biggest_recent_change": 0.02750109117466959},
{"total_number_of_episodes": 28041, "number_of_timesteps": 10024365, "per_episode_reward": 6.18, "episode_reward_trend_value": 0.00161282187251077, "biggest_recent_change": 0.026325272937729238},
{"total_number_of_episodes": 28051, "number_of_timesteps": 10028470, "per_episode_reward": 6.2, "episode_reward_trend_value": 0.0015761479422678113, "biggest_recent_change": 0.026325272937729238},
{"total_number_of_episodes": 28061, "number_of_timesteps": 10033075, "per_episode_reward": 6.2, "episode_reward_trend_value": 0.0014039593248329238, "biggest_recent_change": 0.026325272937729238},
{"total_number_of_episodes": 28071, "number_of_timesteps": 10036041, "per_episode_reward": 6.2, "episode_reward_trend_value": 0.001373716970606341, "biggest_recent_change": 0.026325272937729238},
{"total_number_of_episodes": 28081, "number_of_timesteps": 10039329, "per_episode_reward": 6.27, "episode_reward_trend_value": 0.0019846868980313045, "biggest_recent_change": 0.06760323889542441},
{"total_number_of_episodes": 28091, "number_of_timesteps": 10044624, "per_episode_reward": 6.28, "episode_reward_trend_value": 0.0018427160073418588, "biggest_recent_change": 0.06760323889542441},
{"total_number_of_episodes": 28101, "number_of_timesteps": 10048301, "per_episode_reward": 6.36, "episode_reward_trend_value": 0.002589517665705079, "biggest_recent_change": 0.08669229610200713},
{"total_number_of_episodes": 28111, "number_of_timesteps": 10052049, "per_episode_reward": 6.37, "episode_reward_trend_value": 0.002370970606520828, "biggest_recent_change": 0.08669229610200713},
{"total_number_of_episodes": 28121, "number_of_timesteps": 10055229, "per_episode_reward": 6.37, "episode_reward_trend_value": 0.00227967261839049, "biggest_recent_change": 0.08669229610200713},
{"total_number_of_episodes": 28132, "number_of_timesteps": 10059113, "per_episode_reward": 6.36, "episode_reward_trend_value": 0.00201783845634051, "biggest_recent_change": 0.08669229610200713},
{"total_number_of_episodes": 28142, "number_of_timesteps": 10065191, "per_episode_reward": 6.38, "episode_reward_trend_value": 0.002005193488235661, "biggest_recent_change": 0.08669229610200713},
{"total_number_of_episodes": 28152, "number_of_timesteps": 10068086, "per_episode_reward": 6.39, "episode_reward_trend_value": 0.0020934334748319984, "biggest_recent_change": 0.08669229610200713},
{"total_number_of_episodes": 28162, "number_of_timesteps": 10072945, "per_episode_reward": 6.4, "episode_reward_trend_value": 0.0022162993903073708, "biggest_recent_change": 0.08669229610200713},
{"total_number_of_episodes": 28172, "number_of_timesteps": 10077481, "per_episode_reward": 6.41, "episode_reward_trend_value": 0.001619791941877728, "biggest_recent_change": 0.08669229610200713},
{"total_number_of_episodes": 28182, "number_of_timesteps": 10080344, "per_episode_reward": 6.44, "episode_reward_trend_value": 0.001770161487428743, "biggest_recent_change": 0.08669229610200713},
{"total_number_of_episodes": 28192, "number_of_timesteps": 10083120, "per_episode_reward": 6.44, "episode_reward_trend_value": 0.0007919236508157192, "biggest_recent_change": 0.02297834824759626},
{"total_number_of_episodes": 28202, "number_of_timesteps": 10086290, "per_episode_reward": 6.46, "episode_reward_trend_value": 0.0009410564329574002, "biggest_recent_change": 0.02297834824759626},
{"total_number_of_episodes": 28212, "number_of_timesteps": 10088385, "per_episode_reward": 6.49, "episode_reward_trend_value": 0.0012659943088401053, "biggest_recent_change": 0.031754525921395604},
{"total_number_of_episodes": 28222, "number_of_timesteps": 10091386, "per_episode_reward": 6.49, "episode_reward_trend_value": 0.0014605923971321901, "biggest_recent_change": 0.031754525921395604},
{"total_number_of_episodes": 28232, "number_of_timesteps": 10094430, "per_episode_reward": 6.5, "episode_reward_trend_value": 0.0012865485335058935, "biggest_recent_change": 0.031754525921395604},
{"total_number_of_episodes": 28242, "number_of_timesteps": 10097483, "per_episode_reward": 6.5, "episode_reward_trend_value": 0.0012295494106848417, "biggest_recent_change": 0.031754525921395604},
{"total_number_of_episodes": 28252, "number_of_timesteps": 10099656, "per_episode_reward": 6.51, "episode_reward_trend_value": 0.0012164700831012966, "biggest_recent_change": 0.031754525921395604},
{"total_number_of_episodes": 28263, "number_of_timesteps": 10102840, "per_episode_reward": 6.52, "episode_reward_trend_value": 0.0012067756878783302, "biggest_recent_change": 0.031754525921395604},
{"total_number_of_episodes": 28273, "number_of_timesteps": 10107431, "per_episode_reward": 6.53, "episode_reward_trend_value": 0.0010207583684366916, "biggest_recent_change": 0.031754525921395604},
{"total_number_of_episodes": 28283, "number_of_timesteps": 10113149, "per_episode_reward": 6.58, "episode_reward_trend_value": 0.0015921576069475405, "biggest_recent_change": 0.050076822272811405},
{"total_number_of_episodes": 28293, "number_of_timesteps": 10119721, "per_episode_reward": 6.57, "episode_reward_trend_value": 0.0013112230073999223, "biggest_recent_change": 0.050076822272811405},
{"total_number_of_episodes": 28304, "number_of_timesteps": 10122570, "per_episode_reward": 6.62, "episode_reward_trend_value": 0.0015067442791394134, "biggest_recent_change": 0.050076822272811405},
{"total_number_of_episodes": 28314, "number_of_timesteps": 10125953, "per_episode_reward": 6.62, "episode_reward_trend_value": 0.0014344182566678873, "biggest_recent_change": 0.050076822272811405},
{"total_number_of_episodes": 28324, "number_of_timesteps": 10129737, "per_episode_reward": 6.64, "episode_reward_trend_value": 0.0016179528862238317, "biggest_recent_change": 0.050076822272811405},
{"total_number_of_episodes": 28334, "number_of_timesteps": 10133667, "per_episode_reward": 6.68, "episode_reward_trend_value": 0.0019226188010505179, "biggest_recent_change": 0.050076822272811405},
{"total_number_of_episodes": 28345, "number_of_timesteps": 10137093, "per_episode_reward": 6.66, "episode_reward_trend_value": 0.0016370733786552033, "biggest_recent_change": 0.050076822272811405},
{"total_number_of_episodes": 28355, "number_of_timesteps": 10140412, "per_episode_reward": 6.73, "episode_reward_trend_value": 0.0022539631477826957, "biggest_recent_change": 0.06856515218816384},
{"total_number_of_episodes": 28365, "number_of_timesteps": 10143050, "per_episode_reward": 6.74, "episode_reward_trend_value": 0.002372181614893234, "biggest_recent_change": 0.06856515218816384},
{"total_number_of_episodes": 28375, "number_of_timesteps": 10146068, "per_episode_reward": 6.8, "episode_reward_trend_value": 0.0024780426816939124, "biggest_recent_change": 0.06856515218816384},
{"total_number_of_episodes": 28387, "number_of_timesteps": 10149545, "per_episode_reward": 6.81, "episode_reward_trend_value": 0.0026274874369799877, "biggest_recent_change": 0.06856515218816384},
{"total_number_of_episodes": 28398, "number_of_timesteps": 10152404, "per_episode_reward": 6.79, "episode_reward_trend_value": 0.001865075595057666, "biggest_recent_change": 0.06856515218816384},
{"total_number_of_episodes": 28408, "number_of_timesteps": 10156780, "per_episode_reward": 6.8, "episode_reward_trend_value": 0.0019098715691220273, "biggest_recent_change": 0.06856515218816384},
{"total_number_of_episodes": 28418, "number_of_timesteps": 10159434, "per_episode_reward": 6.81, "episode_reward_trend_value": 0.001893218212376298, "biggest_recent_change": 0.06856515218816384},
{"total_number_of_episodes": 28428, "number_of_timesteps": 10162202, "per_episode_reward": 6.82, "episode_reward_trend_value": 0.0016143320457165464, "biggest_recent_change": 0.06856515218816384},
{"total_number_of_episodes": 28438, "number_of_timesteps": 10165136, "per_episode_reward": 6.82, "episode_reward_trend_value": 0.00181083269875361, "biggest_recent_change": 0.06856515218816384},
{"total_number_of_episodes": 28448, "number_of_timesteps": 10168683, "per_episode_reward": 6.85, "episode_reward_trend_value": 0.0014000631947052652, "biggest_recent_change": 0.05960431828487245},
{"total_number_of_episodes": 28458, "number_of_timesteps": 10171803, "per_episode_reward": 6.88, "episode_reward_trend_value": 0.001526458984027881, "biggest_recent_change": 0.05960431828487245},
{"total_number_of_episodes": 28468, "number_of_timesteps": 10174884, "per_episode_reward": 6.91, "episode_reward_trend_value": 0.0012257449685380548, "biggest_recent_change": 0.032540056890788094},
{"total_number_of_episodes": 28478, "number_of_timesteps": 10177900, "per_episode_reward": 6.94, "episode_reward_trend_value": 0.0014001929722271497, "biggest_recent_change": 0.032540056890788094},
{"total_number_of_episodes": 28488, "number_of_timesteps": 10183110, "per_episode_reward": 7.0, "episode_reward_trend_value": 0.0022772057625787883, "biggest_recent_change": 0.05966552573658834},
{"total_number_of_episodes": 28498, "number_of_timesteps": 10186169, "per_episode_reward": 7.05, "episode_reward_trend_value": 0.0028233951706197876, "biggest_recent_change": 0.05966552573658834},
{"total_number_of_episodes": 28508, "number_of_timesteps": 10188917, "per_episode_reward": 7.04, "episode_reward_trend_value": 0.0025053655755387936, "biggest_recent_change": 0.05966552573658834},
{"total_number_of_episodes": 28518, "number_of_timesteps": 10193481, "per_episode_reward": 7.05, "episode_reward_trend_value": 0.00259612565157461, "biggest_recent_change": 0.05966552573658834},
{"total_number_of_episodes": 28528, "number_of_timesteps": 10198461, "per_episode_reward": 7.06, "episode_reward_trend_value": 0.002716116926983621, "biggest_recent_change": 0.05966552573658834},
{"total_number_of_episodes": 28539, "number_of_timesteps": 10203700, "per_episode_reward": 7.06, "episode_reward_trend_value": 0.0022726693449596188, "biggest_recent_change": 0.05966552573658834},

{"total_number_of_episodes": 28550, "number_of_timesteps": 10209600, "per_episode_reward": 7.07, "episode_reward_trend_value": 0.002062336884071048, "biggest_recent_change": 0.05966552573658834},
{"total_number_of_episodes": 28560, "number_of_timesteps": 10214279, "per_episode_reward": 7.04, "episode_reward_trend_value": 0.0014664956922258554, "biggest_recent_change": 0.05966552573658834},
{"total_number_of_episodes": 28570, "number_of_timesteps": 10218606, "per_episode_reward": 7.06, "episode_reward_trend_value": 0.001428087193716, "biggest_recent_change": 0.05966552573658834},
{"total_number_of_episodes": 28580, "number_of_timesteps": 10223255, "per_episode_reward": 7.11, "episode_reward_trend_value": 0.0012493633174568272, "biggest_recent_change": 0.054074748702615416},
{"total_number_of_episodes": 28590, "number_of_timesteps": 10227262, "per_episode_reward": 7.11, "episode_reward_trend_value": 0.0006775736581312191, "biggest_recent_change": 0.04358037687326277},
{"total_number_of_episodes": 28602, "number_of_timesteps": 10229289, "per_episode_reward": 7.12, "episode_reward_trend_value": 0.0008814230379708398, "biggest_recent_change": 0.04358037687326277},
{"total_number_of_episodes": 28612, "number_of_timesteps": 10233398, "per_episode_reward": 7.14, "episode_reward_trend_value": 0.000983904149357093, "biggest_recent_change": 0.04358037687326277},
{"total_number_of_episodes": 28622, "number_of_timesteps": 10238739, "per_episode_reward": 7.16, "episode_reward_trend_value": 0.0011050676219721803, "biggest_recent_change": 0.04358037687326277},
{"total_number_of_episodes": 28632, "number_of_timesteps": 10242853, "per_episode_reward": 7.19, "episode_reward_trend_value": 0.001522993988408435, "biggest_recent_change": 0.04358037687326277},
{"total_number_of_episodes": 28642, "number_of_timesteps": 10246650, "per_episode_reward": 7.24, "episode_reward_trend_value": 0.0019849332144054365, "biggest_recent_change": 0.05089668143659143},
{"total_number_of_episodes": 28652, "number_of_timesteps": 10248615, "per_episode_reward": 7.21, "episode_reward_trend_value": 0.0018483685672778115, "biggest_recent_change": 0.05089668143659143},
{"total_number_of_episodes": 28662, "number_of_timesteps": 10251578, "per_episode_reward": 7.26, "episode_reward_trend_value": 0.0021892989856238704, "biggest_recent_change": 0.051171195137635905},
{"total_number_of_episodes": 28672, "number_of_timesteps": 10256445, "per_episode_reward": 7.24, "episode_reward_trend_value": 0.0014660473070192816, "biggest_recent_change": 0.051171195137635905},
{"total_number_of_episodes": 28682, "number_of_timesteps": 10260400, "per_episode_reward": 7.23, "episode_reward_trend_value": 0.001279983795370507, "biggest_recent_change": 0.051171195137635905},
{"total_number_of_episodes": 28692, "number_of_timesteps": 10262765, "per_episode_reward": 7.26, "episode_reward_trend_value": 0.001633945172929548, "biggest_recent_change": 0.051171195137635905},
{"total_number_of_episodes": 28702, "number_of_timesteps": 10265974, "per_episode_reward": 7.27, "episode_reward_trend_value": 0.0014111371362956347, "biggest_recent_change": 0.051171195137635905},
{"total_number_of_episodes": 28712, "number_of_timesteps": 10268988, "per_episode_reward": 7.29, "episode_reward_trend_value": 0.0013641576869740804, "biggest_recent_change": 0.051171195137635905},
{"total_number_of_episodes": 28722, "number_of_timesteps": 10271153, "per_episode_reward": 7.32, "episode_reward_trend_value": 0.001424817035944622, "biggest_recent_change": 0.051171195137635905},
{"total_number_of_episodes": 28733, "number_of_timesteps": 10275882, "per_episode_reward": 7.35, "episode_reward_trend_value": 0.001226361693064278, "biggest_recent_change": 0.051171195137635905},
{"total_number_of_episodes": 28743, "number_of_timesteps": 10278944, "per_episode_reward": 7.33, "episode_reward_trend_value": 0.0012749113851467954, "biggest_recent_change": 0.051171195137635905},
{"total_number_of_episodes": 28753, "number_of_timesteps": 10281644, "per_episode_reward": 7.33, "episode_reward_trend_value": 0.0007866767935620899, "biggest_recent_change": 0.03700300650647481},

{"total_number_of_episodes": 28763, "number_of_timesteps": 10287407, "per_episode_reward": 7.37, "episode_reward_trend_value": 0.0014015122073278066, "biggest_recent_change": 0.03700300650647481},
{"total_number_of_episodes": 28773, "number_of_timesteps": 10292929, "per_episode_reward": 7.41, "episode_reward_trend_value": 0.002033520913551505, "biggest_recent_change": 0.04274874687505381},
{"total_number_of_episodes": 28783, "number_of_timesteps": 10296977, "per_episode_reward": 7.42, "episode_reward_trend_value": 0.0017127745717798269, "biggest_recent_change": 0.04274874687505381},
{"total_number_of_episodes": 28793, "number_of_timesteps": 10300533, "per_episode_reward": 7.44, "episode_reward_trend_value": 0.0019247154623040312, "biggest_recent_change": 0.04274874687505381},
{"total_number_of_episodes": 28803, "number_of_timesteps": 10303523, "per_episode_reward": 7.44, "episode_reward_trend_value": 0.0017253585529511284, "biggest_recent_change": 0.04274874687505381},
{"total_number_of_episodes": 28813, "number_of_timesteps": 10307783, "per_episode_reward": 7.46, "episode_reward_trend_value": 0.0015551530572832206, "biggest_recent_change": 0.04274874687505381},
{"total_number_of_episodes": 28824, "number_of_timesteps": 10311348, "per_episode_reward": 7.52, "episode_reward_trend_value": 0.0018326279368458408, "biggest_recent_change": 0.0580084397379963},
{"total_number_of_episodes": 28834, "number_of_timesteps": 10314127, "per_episode_reward": 7.55, "episode_reward_trend_value": 0.002454909158198997, "biggest_recent_change": 0.0580084397379963},
{"total_number_of_episodes": 28844, "number_of_timesteps": 10316356, "per_episode_reward": 7.56, "episode_reward_trend_value": 0.0025248577468986394, "biggest_recent_change": 0.0580084397379963},
{"total_number_of_episodes": 28854, "number_of_timesteps": 10318741, "per_episode_reward": 7.54, "episode_reward_trend_value": 0.0019144034091002342, "biggest_recent_change": 0.0580084397379963},
{"total_number_of_episodes": 28864, "number_of_timesteps": 10324209, "per_episode_reward": 7.53, "episode_reward_trend_value": 0.0013116754853803691, "biggest_recent_change": 0.0580084397379963},
{"total_number_of_episodes": 28875, "number_of_timesteps": 10329805, "per_episode_reward": 7.55, "episode_reward_trend_value": 0.001513347850434964, "biggest_recent_change": 0.0580084397379963},
{"total_number_of_episodes": 28886, "number_of_timesteps": 10333503, "per_episode_reward": 7.56, "episode_reward_trend_value": 0.0012484649676622736, "biggest_recent_change": 0.0580084397379963},
{"total_number_of_episodes": 28897, "number_of_timesteps": 10337530, "per_episode_reward": 7.55, "episode_reward_trend_value": 0.0012308912159133003, "biggest_recent_change": 0.0580084397379963},
{"total_number_of_episodes": 28907, "number_of_timesteps": 10340187, "per_episode_reward": 7.59, "episode_reward_trend_value": 0.0014083392021094297, "biggest_recent_change": 0.0580084397379963},
{"total_number_of_episodes": 28917, "number_of_timesteps": 10344247, "per_episode_reward": 7.56, "episode_reward_trend_value": 0.0004530296729947005, "biggest_recent_change": 0.03541015297580419},
{"total_number_of_episodes": 28927, "number_of_timesteps": 10348717, "per_episode_reward": 7.55, "episode_reward_trend_value": 3.2474631494810384e-05, "biggest_recent_change": 0.03541015297580419},
{"total_number_of_episodes": 28937, "number_of_timesteps": 10354431, "per_episode_reward": 7.58, "episode_reward_trend_value": 0.0002193975367622435, "biggest_recent_change": 0.03541015297580419},
{"total_number_of_episodes": 28947, "number_of_timesteps": 10358128, "per_episode_reward": 7.61, "episode_reward_trend_value": 0.0008383528596666738, "biggest_recent_change": 0.03541015297580419},
{"total_number_of_episodes": 28957, "number_of_timesteps": 10361104, "per_episode_reward": 7.62, "episode_reward_trend_value": 0.0010800223809627912, "biggest_recent_change": 0.03541015297580419},
{"total_number_of_episodes": 28967, "number_of_timesteps": 10363551, "per_episode_reward": 7.61, "episode_reward_trend_value": 0.0006791941010584089, "biggest_recent_change": 0.03541015297580419},
{"total_number_of_episodes": 28977, "number_of_timesteps": 10367436, "per_episode_reward": 7.64, "episode_reward_trend_value": 0.0008873120488007678, "biggest_recent_change": 0.03541015297580419},
{"total_number_of_episodes": 28987, "number_of_timesteps": 10370967, "per_episode_reward": 7.63, "episode_reward_trend_value": 0.0008087703116089331, "biggest_recent_change": 0.03541015297580419},
{"total_number_of_episodes": 28997, "number_of_timesteps": 10374097, "per_episode_reward": 7.64, "episode_reward_trend_value": 0.0005479611421212165, "biggest_recent_change": 0.03458800169730658},
{"total_number_of_episodes": 29007, "number_of_timesteps": 10378430, "per_episode_reward": 7.68, "episode_reward_trend_value": 0.0013287513646833165, "biggest_recent_change": 0.04230170214825968},
{"total_number_of_episodes": 29017, "number_of_timesteps": 10381128, "per_episode_reward": 7.7, "episode_reward_trend_value": 0.0016526030696303294, "biggest_recent_change": 0.04230170214825968},
{"total_number_of_episodes": 29027, "number_of_timesteps": 10385047, "per_episode_reward": 7.71, "episode_reward_trend_value": 0.0014012846924564195, "biggest_recent_change": 0.04230170214825968},
{"total_number_of_episodes": 29037, "number_of_timesteps": 10389015, "per_episode_reward": 7.72, "episode_reward_trend_value": 0.001173108708506248, "biggest_recent_change": 0.04230170214825968},
{"total_number_of_episodes": 29047, "number_of_timesteps": 10393530, "per_episode_reward": 7.73, "episode_reward_trend_value": 0.0012067203010420378, "biggest_recent_change": 0.04230170214825968},
{"total_number_of_episodes": 29057, "number_of_timesteps": 10397180, "per_episode_reward": 7.74, "episode_reward_trend_value": 0.0013811955433334195, "biggest_recent_change": 0.04230170214825968},
{"total_number_of_episodes": 29067, "number_of_timesteps": 10400128, "per_episode_reward": 7.78, "episode_reward_trend_value": 0.0016510072422172902, "biggest_recent_change": 0.04507345384890282},
{"total_number_of_episodes": 29077, "number_of_timesteps": 10403846, "per_episode_reward": 7.81, "episode_reward_trend_value": 0.002049791202935531, "biggest_recent_change": 0.04507345384890282},
{"total_number_of_episodes": 29087, "number_of_timesteps": 10406773, "per_episode_reward": 7.81, "episode_reward_trend_value": 0.001914314227640812, "biggest_recent_change": 0.04507345384890282},
{"total_number_of_episodes": 29097, "number_of_timesteps": 10409962, "per_episode_reward": 7.82, "episode_reward_trend_value": 0.0015962075792039835, "biggest_recent_change": 0.04507345384890282},
{"total_number_of_episodes": 29107, "number_of_timesteps": 10413369, "per_episode_reward": 7.83, "episode_reward_trend_value": 0.0014442143266768562, "biggest_recent_change": 0.04507345384890282},
{"total_number_of_episodes": 29117, "number_of_timesteps": 10416429, "per_episode_reward": 7.82, "episode_reward_trend_value": 0.001251320092605991, "biggest_recent_change": 0.04507345384890282},
{"total_number_of_episodes": 29127, "number_of_timesteps": 10422510, "per_episode_reward": 7.89, "episode_reward_trend_value": 0.001864297980096631, "biggest_recent_change": 0.06922017301594874},
{"total_number_of_episodes": 29137, "number_of_timesteps": 10426478, "per_episode_reward": 7.92, "episode_reward_trend_value": 0.0020669097691638507, "biggest_recent_change": 0.06922017301594874},
{"total_number_of_episodes": 29147, "number_of_timesteps": 10428848, "per_episode_reward": 7.97, "episode_reward_trend_value": 0.002593497927972314, "biggest_recent_change": 0.06922017301594874},
{"total_number_of_episodes": 29157, "number_of_timesteps": 10431556, "per_episode_reward": 7.99, "episode_reward_trend_value": 0.002242274292299731, "biggest_recent_change": 0.06922017301594874},
{"total_number_of_episodes": 29167, "number_of_timesteps": 10435463, "per_episode_reward": 7.99, "episode_reward_trend_value": 0.0020470803638412446, "biggest_recent_change": 0.06922017301594874},
{"total_number_of_episodes": 29177, "number_of_timesteps": 10438794, "per_episode_reward": 8.03, "episode_reward_trend_value": 0.002456958522728314, "biggest_recent_change": 0.06922017301594874},
{"total_number_of_episodes": 29187, "number_of_timesteps": 10441166, "per_episode_reward": 8.03, "episode_reward_trend_value": 0.002349545142699287, "biggest_recent_change": 0.06922017301594874},
{"total_number_of_episodes": 29197, "number_of_timesteps": 10443164, "per_episode_reward": 8.05, "episode_reward_trend_value": 0.002423881688188829, "biggest_recent_change": 0.06922017301594874},
{"total_number_of_episodes": 29207, "number_of_timesteps": 10446987, "per_episode_reward": 8.07, "episode_reward_trend_value": 0.002782575089782746, "biggest_recent_change": 0.06922017301594874},
{"total_number_of_episodes": 29217, "number_of_timesteps": 10449173, "per_episode_reward": 8.07, "episode_reward_trend_value": 0.0020353077524220093, "biggest_recent_change": 0.053307509509529005},
{"total_number_of_episodes": 29227, "number_of_timesteps": 10452268, "per_episode_reward": 8.09, "episode_reward_trend_value": 0.0018519627736820056, "biggest_recent_change": 0.053307509509529005},
{"total_number_of_episodes": 29237, "number_of_timesteps": 10455917, "per_episode_reward": 8.12, "episode_reward_trend_value": 0.0016079729173424657, "biggest_recent_change": 0.03663343424522125},
{"total_number_of_episodes": 29247, "number_of_timesteps": 10458041, "per_episode_reward": 8.1, "episode_reward_trend_value": 0.0012734056433549214, "biggest_recent_change": 0.03663343424522125},
{"total_number_of_episodes": 29257, "number_of_timesteps": 10462304, "per_episode_reward": 8.15, "episode_reward_trend_value": 0.0016765937848660626, "biggest_recent_change": 0.04461805566708499},
{"total_number_of_episodes": 29267, "number_of_timesteps": 10466395, "per_episode_reward": 8.18, "episode_reward_trend_value": 0.0016271454113789235, "biggest_recent_change": 0.04461805566708499},
{"total_number_of_episodes": 29277, "number_of_timesteps": 10468812, "per_episode_reward": 8.2, "episode_reward_trend_value": 0.0018013974308260967, "biggest_recent_change": 0.04461805566708499},
{"total_number_of_episodes": 29287, "number_of_timesteps": 10472572, "per_episode_reward": 8.23, "episode_reward_trend_value": 0.002069248290166333, "biggest_recent_change": 0.04461805566708499},
{"total_number_of_episodes": 29297, "number_of_timesteps": 10475892, "per_episode_reward": 8.25, "episode_reward_trend_value": 0.0020189645156741104, "biggest_recent_change": 0.04461805566708499},
{"total_number_of_episodes": 29307, "number_of_timesteps": 10480298, "per_episode_reward": 8.26, "episode_reward_trend_value": 0.002072161504862259, "biggest_recent_change": 0.04461805566708499},
{"total_number_of_episodes": 29317, "number_of_timesteps": 10483935, "per_episode_reward": 8.31, "episode_reward_trend_value": 0.002475235676914049, "biggest_recent_change": 0.05128922239924805},
{"total_number_of_episodes": 29327, "number_of_timesteps": 10488057, "per_episode_reward": 8.3, "episode_reward_trend_value": 0.001984603128183081, "biggest_recent_change": 0.05128922239924805},
{"total_number_of_episodes": 29337, "number_of_timesteps": 10490956, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.002087197427534646, "biggest_recent_change": 0.05128922239924805},
{"total_number_of_episodes": 29347, "number_of_timesteps": 10494521, "per_episode_reward": 8.26, "episode_reward_trend_value": 0.001308489183489926, "biggest_recent_change": 0.05128922239924805},
{"total_number_of_episodes": 29357, "number_of_timesteps": 10498946, "per_episode_reward": 8.3, "episode_reward_trend_value": 0.0013740653376311585, "biggest_recent_change": 0.05128922239924805},
{"total_number_of_episodes": 29367, "number_of_timesteps": 10503774, "per_episode_reward": 8.32, "episode_reward_trend_value": 0.001367847570643299, "biggest_recent_change": 0.05128922239924805},
{"total_number_of_episodes": 29377, "number_of_timesteps": 10509282, "per_episode_reward": 8.36, "episode_reward_trend_value": 0.0014411934262728069, "biggest_recent_change": 0.05128922239924805},
{"total_number_of_episodes": 29387, "number_of_timesteps": 10513686, "per_episode_reward": 8.38, "episode_reward_trend_value": 0.0014663566632089145, "biggest_recent_change": 0.05128922239924805},
{"total_number_of_episodes": 29397, "number_of_timesteps": 10518308, "per_episode_reward": 8.35, "episode_reward_trend_value": 0.001006858786110539, "biggest_recent_change": 0.05128922239924805},
{"total_number_of_episodes": 29407, "number_of_timesteps": 10524318, "per_episode_reward": 8.36, "episode_reward_trend_value": 0.0005385184824547788, "biggest_recent_change": 0.04201361401658055},
{"total_number_of_episodes": 29417, "number_of_timesteps": 10530897, "per_episode_reward": 8.35, "episode_reward_trend_value": 0.0006404866395096755, "biggest_recent_change": 0.04201361401658055},
{"total_number_of_episodes": 29427, "number_of_timesteps": 10536012, "per_episode_reward": 8.34, "episode_reward_trend_value": 0.0006209477287851446, "biggest_recent_change": 0.04201361401658055},
{"total_number_of_episodes": 29437, "number_of_timesteps": 10540978, "per_episode_reward": 8.38, "episode_reward_trend_value": 0.0013337705658917306, "biggest_recent_change": 0.04201361401658055},
{"total_number_of_episodes": 29447, "number_of_timesteps": 10547143, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0014303791651055775, "biggest_recent_change": 0.0467797084333359},
{"total_number_of_episodes": 29457, "number_of_timesteps": 10551689, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.001247792641929577, "biggest_recent_change": 0.0467797084333359},
{"total_number_of_episodes": 29467, "number_of_timesteps": 10556054, "per_episode_reward": 8.42, "episode_reward_trend_value": 0.0006450953265851804, "biggest_recent_change": 0.0467797084333359},
{"total_number_of_episodes": 29477, "number_of_timesteps": 10561665, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0005676302859141953, "biggest_recent_change": 0.0467797084333359},
{"total_number_of_episodes": 29487, "number_of_timesteps": 10564856, "per_episode_reward": 8.47, "episode_reward_trend_value": 0.001326767141823145, "biggest_recent_change": 0.0467797084333359},
{"total_number_of_episodes": 29497, "number_of_timesteps": 10567420, "per_episode_reward": 8.48, "episode_reward_trend_value": 0.0013384681960453627, "biggest_recent_change": 0.0467797084333359},
{"total_number_of_episodes": 29507, "number_of_timesteps": 10569819, "per_episode_reward": 8.48, "episode_reward_trend_value": 0.0014261925015477553, "biggest_recent_change": 0.0467797084333359},
{"total_number_of_episodes": 29517, "number_of_timesteps": 10572392, "per_episode_reward": 8.53, "episode_reward_trend_value": 0.002075133623320408, "biggest_recent_change": 0.0492319579154632},
{"total_number_of_episodes": 29527, "number_of_timesteps": 10575844, "per_episode_reward": 8.63, "episode_reward_trend_value": 0.002744233681098645, "biggest_recent_change": 0.09890737424269425},
{"total_number_of_episodes": 29537, "number_of_timesteps": 10581033, "per_episode_reward": 8.64, "episode_reward_trend_value": 0.00238549075639243, "biggest_recent_change": 0.09890737424269425},
{"total_number_of_episodes": 29547, "number_of_timesteps": 10586439, "per_episode_reward": 8.64, "episode_reward_trend_value": 0.002315050138274424, "biggest_recent_change": 0.09890737424269425},
{"total_number_of_episodes": 29557, "number_of_timesteps": 10589040, "per_episode_reward": 8.65, "episode_reward_trend_value": 0.0025178992647003975, "biggest_recent_change": 0.09890737424269425},
{"total_number_of_episodes": 29567, "number_of_timesteps": 10592718, "per_episode_reward": 8.66, "episode_reward_trend_value": 0.002484288572413027, "biggest_recent_change": 0.09890737424269425},
{"total_number_of_episodes": 29577, "number_of_timesteps": 10597746, "per_episode_reward": 8.69, "episode_reward_trend_value": 0.0024979297806223813, "biggest_recent_change": 0.09890737424269425},
{"total_number_of_episodes": 29587, "number_of_timesteps": 10601397, "per_episode_reward": 8.7, "episode_reward_trend_value": 0.002472167022859395, "biggest_recent_change": 0.09890737424269425},
{"total_number_of_episodes": 29597, "number_of_timesteps": 10603940, "per_episode_reward": 8.74, "episode_reward_trend_value": 0.002897639981985753, "biggest_recent_change": 0.09890737424269425},
{"total_number_of_episodes": 29608, "number_of_timesteps": 10607208, "per_episode_reward": 8.76, "episode_reward_trend_value": 0.0025623393270089384, "biggest_recent_change": 0.09890737424269425},
{"total_number_of_episodes": 29618, "number_of_timesteps": 10609600, "per_episode_reward": 8.79, "episode_reward_trend_value": 0.0017894520393442193, "biggest_recent_change": 0.042556381004711596},
{"total_number_of_episodes": 29628, "number_of_timesteps": 10611203, "per_episode_reward": 8.78, "episode_reward_trend_value": 0.0015372106222020085, "biggest_recent_change": 0.042556381004711596},
{"total_number_of_episodes": 29638, "number_of_timesteps": 10613028, "per_episode_reward": 8.79, "episode_reward_trend_value": 0.0016358332806352474, "biggest_recent_change": 0.042556381004711596},
{"total_number_of_episodes": 29648, "number_of_timesteps": 10616444, "per_episode_reward": 8.83, "episode_reward_trend_value": 0.0020559610058268046, "biggest_recent_change": 0.04383877228116262},
{"total_number_of_episodes": 29658, "number_of_timesteps": 10618782, "per_episode_reward": 8.85, "episode_reward_trend_value": 0.0021415440548045337, "biggest_recent_change": 0.04383877228116262},
{"total_number_of_episodes": 29668, "number_of_timesteps": 10621328, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0018698967814470692, "biggest_recent_change": 0.04383877228116262},
{"total_number_of_episodes": 29678, "number_of_timesteps": 10624484, "per_episode_reward": 8.87, "episode_reward_trend_value": 0.0018357915308781416, "biggest_recent_change": 0.04383877228116262},
{"total_number_of_episodes": 29688, "number_of_timesteps": 10626986, "per_episode_reward": 8.9, "episode_reward_trend_value": 0.0017405790950668829, "biggest_recent_change": 0.04383877228116262},
{"total_number_of_episodes": 29698, "number_of_timesteps": 10629291, "per_episode_reward": 8.89, "episode_reward_trend_value": 0.0014204509250325102, "biggest_recent_change": 0.04383877228116262},
{"total_number_of_episodes": 29710, "number_of_timesteps": 10632654, "per_episode_reward": 8.88, "episode_reward_trend_value": 0.0010226105635452577, "biggest_recent_change": 0.04383877228116262},
{"total_number_of_episodes": 29720, "number_of_timesteps": 10633977, "per_episode_reward": 8.91, "episode_reward_trend_value": 0.001424229500445071, "biggest_recent_change": 0.04383877228116262},
{"total_number_of_episodes": 29730, "number_of_timesteps": 10635914, "per_episode_reward": 8.91, "episode_reward_trend_value": 0.0013724072999271462, "biggest_recent_change": 0.04383877228116262},
{"total_number_of_episodes": 29740, "number_of_timesteps": 10638219, "per_episode_reward": 8.9, "episode_reward_trend_value": 0.00071955937886455, "biggest_recent_change": 0.03398726178169831},
{"total_number_of_episodes": 29750, "number_of_timesteps": 10640821, "per_episode_reward": 8.93, "episode_reward_trend_value": 0.0009038891453583078, "biggest_recent_change": 0.03468627652960343},
{"total_number_of_episodes": 29761, "number_of_timesteps": 10642815, "per_episode_reward": 8.95, "episode_reward_trend_value": 0.001035909640240994, "biggest_recent_change": 0.03468627652960343},
{"total_number_of_episodes": 29771, "number_of_timesteps": 10647415, "per_episode_reward": 8.99, "episode_reward_trend_value": 0.001409780020443326, "biggest_recent_change": 0.03845190341856686},
{"total_number_of_episodes": 29781, "number_of_timesteps": 10650989, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0011611867604603928, "biggest_recent_change": 0.03845190341856686},
{"total_number_of_episodes": 29791, "number_of_timesteps": 10654064, "per_episode_reward": 9.01, "episode_reward_trend_value": 0.0013083671258440391, "biggest_recent_change": 0.03845190341856686},
{"total_number_of_episodes": 29801, "number_of_timesteps": 10657256, "per_episode_reward": 8.96, "episode_reward_trend_value": 0.0009048620011568944, "biggest_recent_change": 0.042773575402826225},
{"total_number_of_episodes": 29811, "number_of_timesteps": 10660601, "per_episode_reward": 8.99, "episode_reward_trend_value": 0.0008901583177189131, "biggest_recent_change": 0.042773575402826225},
{"total_number_of_episodes": 29821, "number_of_timesteps": 10664291, "per_episode_reward": 9.02, "episode_reward_trend_value": 0.0012574306415140532, "biggest_recent_change": 0.042773575402826225},
{"total_number_of_episodes": 29831, "number_of_timesteps": 10666873, "per_episode_reward": 9.08, "episode_reward_trend_value": 0.0020211390468127905, "biggest_recent_change": 0.05381621586241536},
{"total_number_of_episodes": 29841, "number_of_timesteps": 10668465, "per_episode_reward": 9.11, "episode_reward_trend_value": 0.001962141259529698, "biggest_recent_change": 0.05381621586241536},
{"total_number_of_episodes": 29851, "number_of_timesteps": 10670939, "per_episode_reward": 9.15, "episode_reward_trend_value": 0.002143968887995504, "biggest_recent_change": 0.05381621586241536},
{"total_number_of_episodes": 29861, "number_of_timesteps": 10672918, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0016578257244187513, "biggest_recent_change": 0.05381621586241536},
{"total_number_of_episodes": 29871, "number_of_timesteps": 10674393, "per_episode_reward": 9.15, "episode_reward_trend_value": 0.0016532375651382952, "biggest_recent_change": 0.05381621586241536},
{"total_number_of_episodes": 29881, "number_of_timesteps": 10676352, "per_episode_reward": 9.17, "episode_reward_trend_value": 0.001763983064888445, "biggest_recent_change": 0.05381621586241536},

{"total_number_of_episodes": 29891, "number_of_timesteps": 10678940, "per_episode_reward": 9.16, "episode_reward_trend_value": 0.002155718360299592, "biggest_recent_change": 0.05381621586241536},
{"total_number_of_episodes": 29901, "number_of_timesteps": 10682402, "per_episode_reward": 9.17, "episode_reward_trend_value": 0.0019664471527634495, "biggest_recent_change": 0.05381621586241536},
{"total_number_of_episodes": 29911, "number_of_timesteps": 10686109, "per_episode_reward": 9.18, "episode_reward_trend_value": 0.0017386834283884965, "biggest_recent_change": 0.05381621586241536},
{"total_number_of_episodes": 29921, "number_of_timesteps": 10691137, "per_episode_reward": 9.17, "episode_reward_trend_value": 0.0010570626821268588, "biggest_recent_change": 0.03874713501140192},
{"total_number_of_episodes": 29931, "number_of_timesteps": 10694668, "per_episode_reward": 9.2, "episode_reward_trend_value": 0.0010103073549044062, "biggest_recent_change": 0.03874713501140192},
{"total_number_of_episodes": 29941, "number_of_timesteps": 10700489, "per_episode_reward": 9.2, "episode_reward_trend_value": 0.0006360283568064851, "biggest_recent_change": 0.02516849622410433},
{"total_number_of_episodes": 29951, "number_of_timesteps": 10705288, "per_episode_reward": 9.2, "episode_reward_trend_value": 0.000641986623786433, "biggest_recent_change": 0.02516849622410433},
{"total_number_of_episodes": 29963, "number_of_timesteps": 10710301, "per_episode_reward": 9.18, "episode_reward_trend_value": 0.0003102980578146052, "biggest_recent_change": 0.02516849622410433},
{"total_number_of_episodes": 29973, "number_of_timesteps": 10713651, "per_episode_reward": 9.17, "episode_reward_trend_value": -9.690087030161325e-06, "biggest_recent_change": 0.02516849622410433},
{"total_number_of_episodes": 29983, "number_of_timesteps": 10715929, "per_episode_reward": 9.2, "episode_reward_trend_value": 0.00041710059242215815, "biggest_recent_change": 0.03089376233488572},
{"total_number_of_episodes": 29993, "number_of_timesteps": 10718912, "per_episode_reward": 9.18, "episode_reward_trend_value": 0.00015968196343270807, "biggest_recent_change": 0.03089376233488572},
{"total_number_of_episodes": 30003, "number_of_timesteps": 10721263, "per_episode_reward": 9.21, "episode_reward_trend_value": 0.00029662230798946056, "biggest_recent_change": 0.03089376233488572},
{"total_number_of_episodes": 30013, "number_of_timesteps": 10724419, "per_episode_reward": 9.24, "episode_reward_trend_value": 0.0007339873016239235, "biggest_recent_change": 0.03183319812596963},
{"total_number_of_episodes": 30023, "number_of_timesteps": 10728610, "per_episode_reward": 9.25, "episode_reward_trend_value": 0.0005438626142451892, "biggest_recent_change": 0.03183319812596963},

{"total_number_of_episodes": 30033, "number_of_timesteps": 10731801, "per_episode_reward": 9.27, "episode_reward_trend_value": 0.0007432351365030362, "biggest_recent_change": 0.03183319812596963},
{"total_number_of_episodes": 30043, "number_of_timesteps": 10736108, "per_episode_reward": 9.27, "episode_reward_trend_value": 0.0007947641265130182, "biggest_recent_change": 0.03183319812596963},
{"total_number_of_episodes": 30053, "number_of_timesteps": 10738875, "per_episode_reward": 9.28, "episode_reward_trend_value": 0.001107828004828764, "biggest_recent_change": 0.03183319812596963},
{"total_number_of_episodes": 30063, "number_of_timesteps": 10740664, "per_episode_reward": 9.28, "episode_reward_trend_value": 0.0012591906662006971, "biggest_recent_change": 0.03183319812596963},
{"total_number_of_episodes": 30073, "number_of_timesteps": 10744343, "per_episode_reward": 9.35, "episode_reward_trend_value": 0.0016681541396176454, "biggest_recent_change": 0.06770047494241105},
{"total_number_of_episodes": 30083, "number_of_timesteps": 10746813, "per_episode_reward": 9.34, "episode_reward_trend_value": 0.0017552204284727638, "biggest_recent_change": 0.06770047494241105},
{"total_number_of_episodes": 30093, "number_of_timesteps": 10751008, "per_episode_reward": 9.36, "episode_reward_trend_value": 0.0016986875526693187, "biggest_recent_change": 0.06770047494241105},
{"total_number_of_episodes": 30103, "number_of_timesteps": 10754864, "per_episode_reward": 9.4, "episode_reward_trend_value": 0.001782550679365534, "biggest_recent_change": 0.06770047494241105},
{"total_number_of_episodes": 30113, "number_of_timesteps": 10759319, "per_episode_reward": 9.4, "episode_reward_trend_value": 0.0017111654815689548, "biggest_recent_change": 0.06770047494241105},
{"total_number_of_episodes": 30123, "number_of_timesteps": 10762029, "per_episode_reward": 9.41, "episode_reward_trend_value": 0.0015110850743268777, "biggest_recent_change": 0.06770047494241105},
{"total_number_of_episodes": 30133, "number_of_timesteps": 10764008, "per_episode_reward": 9.41, "episode_reward_trend_value": 0.0015534329933818548, "biggest_recent_change": 0.06770047494241105},
{"total_number_of_episodes": 30143, "number_of_timesteps": 10766794, "per_episode_reward": 9.42, "episode_reward_trend_value": 0.0015083200312869928, "biggest_recent_change": 0.06770047494241105},
{"total_number_of_episodes": 30153, "number_of_timesteps": 10769975, "per_episode_reward": 9.44, "episode_reward_trend_value": 0.001849425686438365, "biggest_recent_change": 0.06770047494241105},
{"total_number_of_episodes": 30163, "number_of_timesteps": 10773154, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0009505206690646004, "biggest_recent_change": 0.03938087952862901},
{"total_number_of_episodes": 30173, "number_of_timesteps": 10775759, "per_episode_reward": 9.44, "episode_reward_trend_value": 0.0011552644004829324, "biggest_recent_change": 0.03938087952862901},
{"total_number_of_episodes": 30184, "number_of_timesteps": 10780896, "per_episode_reward": 9.45, "episode_reward_trend_value": 0.001027838583246362, "biggest_recent_change": 0.03938087952862901},
{"total_number_of_episodes": 30194, "number_of_timesteps": 10783143, "per_episode_reward": 9.47, "episode_reward_trend_value": 0.0007804652438470406, "biggest_recent_change": 0.028979906977566472},
{"total_number_of_episodes": 30204, "number_of_timesteps": 10786340, "per_episode_reward": 9.48, "episode_reward_trend_value": 0.0008934874475861399, "biggest_recent_change": 0.028979906977566472},
{"total_number_of_episodes": 30214, "number_of_timesteps": 10790176, "per_episode_reward": 9.49, "episode_reward_trend_value": 0.0009623273291637306, "biggest_recent_change": 0.028979906977566472},
{"total_number_of_episodes": 30224, "number_of_timesteps": 10792471, "per_episode_reward": 9.52, "episode_reward_trend_value": 0.0012646032459101243, "biggest_recent_change": 0.030889017047876166},
{"total_number_of_episodes": 30234, "number_of_timesteps": 10794915, "per_episode_reward": 9.56, "episode_reward_trend_value": 0.0015801449413010832, "biggest_recent_change": 0.033863298155594634},
{"total_number_of_episodes": 30244, "number_of_timesteps": 10798860, "per_episode_reward": 9.55, "episode_reward_trend_value": 0.0012042139376220796, "biggest_recent_change": 0.033863298155594634},
{"total_number_of_episodes": 30254, "number_of_timesteps": 10800573, "per_episode_reward": 9.53, "episode_reward_trend_value": 0.0011312564069828883, "biggest_recent_change": 0.033863298155594634},
{"total_number_of_episodes": 30264, "number_of_timesteps": 10805781, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0013797223395778403, "biggest_recent_change": 0.03503624094939539},
{"total_number_of_episodes": 30274, "number_of_timesteps": 10810031, "per_episode_reward": 9.58, "episode_reward_trend_value": 0.0014241789134694946, "biggest_recent_change": 0.03503624094939539},
{"total_number_of_episodes": 30284, "number_of_timesteps": 10814384, "per_episode_reward": 9.58, "episode_reward_trend_value": 0.0012604709807265814, "biggest_recent_change": 0.03503624094939539},
{"total_number_of_episodes": 30294, "number_of_timesteps": 10817762, "per_episode_reward": 9.63, "episode_reward_trend_value": 0.001698178481640807, "biggest_recent_change": 0.05119827997712534},
{"total_number_of_episodes": 30304, "number_of_timesteps": 10820319, "per_episode_reward": 9.64, "episode_reward_trend_value": 0.0015979818311944172, "biggest_recent_change": 0.05119827997712534},
{"total_number_of_episodes": 30314, "number_of_timesteps": 10823513, "per_episode_reward": 9.65, "episode_reward_trend_value": 0.0014287436326381928, "biggest_recent_change": 0.05119827997712534},
{"total_number_of_episodes": 30324, "number_of_timesteps": 10827319, "per_episode_reward": 9.67, "episode_reward_trend_value": 0.0012020849314248257, "biggest_recent_change": 0.05119827997712534},
{"total_number_of_episodes": 30336, "number_of_timesteps": 10831245, "per_episode_reward": 9.68, "episode_reward_trend_value": 0.001444479338362016, "biggest_recent_change": 0.05119827997712534},
{"total_number_of_episodes": 30346, "number_of_timesteps": 10832985, "per_episode_reward": 9.69, "episode_reward_trend_value": 0.0017362568500537238, "biggest_recent_change": 0.05119827997712534},
{"total_number_of_episodes": 30356, "number_of_timesteps": 10835396, "per_episode_reward": 9.69, "episode_reward_trend_value": 0.0013118541726065303, "biggest_recent_change": 0.05119827997712534},
{"total_number_of_episodes": 30366, "number_of_timesteps": 10837513, "per_episode_reward": 9.69, "episode_reward_trend_value": 0.0011695101659306318, "biggest_recent_change": 0.05119827997712534},
{"total_number_of_episodes": 30376, "number_of_timesteps": 10839720, "per_episode_reward": 9.65, "episode_reward_trend_value": 0.0007322630859452851, "biggest_recent_change": 0.05119827997712534},
{"total_number_of_episodes": 30386, "number_of_timesteps": 10842092, "per_episode_reward": 9.66, "episode_reward_trend_value": 0.0002976873387358007, "biggest_recent_change": 0.03696867216285327},
{"total_number_of_episodes": 30396, "number_of_timesteps": 10845062, "per_episode_reward": 9.66, "episode_reward_trend_value": 0.00021894090845435698, "biggest_recent_change": 0.03696867216285327},
{"total_number_of_episodes": 30406, "number_of_timesteps": 10848501, "per_episode_reward": 9.66, "episode_reward_trend_value": 0.00012023215491762723, "biggest_recent_change": 0.03696867216285327},
{"total_number_of_episodes": 30416, "number_of_timesteps": 10853812, "per_episode_reward": 9.67, "episode_reward_trend_value": 3.697199634829691e-05, "biggest_recent_change": 0.03696867216285327},
{"total_number_of_episodes": 30426, "number_of_timesteps": 10858482, "per_episode_reward": 9.68, "episode_reward_trend_value": -3.668386202192329e-05, "biggest_recent_change": 0.03696867216285327},
{"total_number_of_episodes": 30436, "number_of_timesteps": 10863210, "per_episode_reward": 9.7, "episode_reward_trend_value": 0.00010569560355655483, "biggest_recent_change": 0.03696867216285327},
{"total_number_of_episodes": 30447, "number_of_timesteps": 10867915, "per_episode_reward": 9.74, "episode_reward_trend_value": 0.000612562271030232, "biggest_recent_change": 0.04245800005177891},
{"total_number_of_episodes": 30457, "number_of_timesteps": 10871747, "per_episode_reward": 9.74, "episode_reward_trend_value": 0.0005682900011938743, "biggest_recent_change": 0.04245800005177891},
{"total_number_of_episodes": 30467, "number_of_timesteps": 10875893, "per_episode_reward": 9.76, "episode_reward_trend_value": 0.0012334945165348031, "biggest_recent_change": 0.04245800005177891},
{"total_number_of_episodes": 30478, "number_of_timesteps": 10880244, "per_episode_reward": 9.77, "episode_reward_trend_value": 0.001216122882387596, "biggest_recent_change": 0.04245800005177891},
{"total_number_of_episodes": 30488, "number_of_timesteps": 10884024, "per_episode_reward": 9.79, "episode_reward_trend_value": 0.001451016599304802, "biggest_recent_change": 0.04245800005177891},
{"total_number_of_episodes": 30498, "number_of_timesteps": 10887257, "per_episode_reward": 9.77, "episode_reward_trend_value": 0.001146847605378376, "biggest_recent_change": 0.04245800005177891},

{"total_number_of_episodes": 30508, "number_of_timesteps": 10892663, "per_episode_reward": 9.77, "episode_reward_trend_value": 0.0010761762641424255, "biggest_recent_change": 0.04245800005177891},
{"total_number_of_episodes": 30518, "number_of_timesteps": 10897238, "per_episode_reward": 9.77, "episode_reward_trend_value": 0.001042698419051153, "biggest_recent_change": 0.04245800005177891},
{"total_number_of_episodes": 30528, "number_of_timesteps": 10902610, "per_episode_reward": 9.79, "episode_reward_trend_value": 0.0010630589137705549, "biggest_recent_change": 0.04245800005177891},
{"total_number_of_episodes": 30538, "number_of_timesteps": 10906551, "per_episode_reward": 9.8, "episode_reward_trend_value": 0.0006689470187025432, "biggest_recent_change": 0.022899734217830314},
{"total_number_of_episodes": 30548, "number_of_timesteps": 10908721, "per_episode_reward": 9.79, "episode_reward_trend_value": 0.0006173108371632886, "biggest_recent_change": 0.022899734217830314},
{"total_number_of_episodes": 30559, "number_of_timesteps": 10910611, "per_episode_reward": 9.81, "episode_reward_trend_value": 0.0005981548586103003, "biggest_recent_change": 0.021175696148061363},
{"total_number_of_episodes": 30570, "number_of_timesteps": 10913866, "per_episode_reward": 9.81, "episode_reward_trend_value": 0.0004812324624433767, "biggest_recent_change": 0.021175696148061363},
{"total_number_of_episodes": 30580, "number_of_timesteps": 10917703, "per_episode_reward": 9.81, "episode_reward_trend_value": 0.0002885462338372354, "biggest_recent_change": 0.021175696148061363},
{"total_number_of_episodes": 30590, "number_of_timesteps": 10921274, "per_episode_reward": 9.81, "episode_reward_trend_value": 0.00045004694171147324, "biggest_recent_change": 0.021175696148061363},
{"total_number_of_episodes": 30600, "number_of_timesteps": 10927072, "per_episode_reward": 9.83, "episode_reward_trend_value": 0.0006902485305444215, "biggest_recent_change": 0.02122832305888167},
{"total_number_of_episodes": 30610, "number_of_timesteps": 10931844, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0009940299669710761, "biggest_recent_change": 0.03465990923766782},
{"total_number_of_episodes": 30620, "number_of_timesteps": 10936331, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0011723917162441131, "biggest_recent_change": 0.037191975534881294},
{"total_number_of_episodes": 30630, "number_of_timesteps": 10939481, "per_episode_reward": 9.9, "episode_reward_trend_value": 0.0010894963019501978, "biggest_recent_change": 0.037191975534881294},
{"total_number_of_episodes": 30640, "number_of_timesteps": 10942631, "per_episode_reward": 9.91, "episode_reward_trend_value": 0.0012730960983075295, "biggest_recent_change": 0.037191975534881294},
{"total_number_of_episodes": 30650, "number_of_timesteps": 10945303, "per_episode_reward": 9.91, "episode_reward_trend_value": 0.0010702833648783597, "biggest_recent_change": 0.037191975534881294},
{"total_number_of_episodes": 30660, "number_of_timesteps": 10949433, "per_episode_reward": 9.95, "episode_reward_trend_value": 0.001464410699078754, "biggest_recent_change": 0.037191975534881294},
{"total_number_of_episodes": 30670, "number_of_timesteps": 10951684, "per_episode_reward": 9.95, "episode_reward_trend_value": 0.0015323716293098144, "biggest_recent_change": 0.037191975534881294},
{"total_number_of_episodes": 30681, "number_of_timesteps": 10955641, "per_episode_reward": 9.99, "episode_reward_trend_value": 0.0020242593555275493, "biggest_recent_change": 0.03820354097440948},
{"total_number_of_episodes": 30691, "number_of_timesteps": 10958181, "per_episode_reward": 10.01, "episode_reward_trend_value": 0.0019750765697701153, "biggest_recent_change": 0.03820354097440948},
{"total_number_of_episodes": 30701, "number_of_timesteps": 10964457, "per_episode_reward": 10.04, "episode_reward_trend_value": 0.002014006582409521, "biggest_recent_change": 0.03820354097440948},
{"total_number_of_episodes": 30711, "number_of_timesteps": 10968846, "per_episode_reward": 10.06, "episode_reward_trend_value": 0.0017618800154552774, "biggest_recent_change": 0.03820354097440948},
{"total_number_of_episodes": 30721, "number_of_timesteps": 10972194, "per_episode_reward": 10.08, "episode_reward_trend_value": 0.0020242873159611423, "biggest_recent_change": 0.03820354097440948},
{"total_number_of_episodes": 30731, "number_of_timesteps": 10976290, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0021466749523156043, "biggest_recent_change": 0.03820354097440948},
{"total_number_of_episodes": 30741, "number_of_timesteps": 10980866, "per_episode_reward": 10.13, "episode_reward_trend_value": 0.002440295772897056, "biggest_recent_change": 0.03820354097440948},
{"total_number_of_episodes": 30751, "number_of_timesteps": 10983537, "per_episode_reward": 10.15, "episode_reward_trend_value": 0.0022930358535441305, "biggest_recent_change": 0.03820354097440948},
{"total_number_of_episodes": 30761, "number_of_timesteps": 10985775, "per_episode_reward": 10.16, "episode_reward_trend_value": 0.0022973408588713834, "biggest_recent_change": 0.03820354097440948},
{"total_number_of_episodes": 30771, "number_of_timesteps": 10988708, "per_episode_reward": 10.17, "episode_reward_trend_value": 0.0019866449376138066, "biggest_recent_change": 0.03816361037521432},
{"total_number_of_episodes": 30782, "number_of_timesteps": 10990205, "per_episode_reward": 10.18, "episode_reward_trend_value": 0.0019235881973433265, "biggest_recent_change": 0.03816361037521432},
{"total_number_of_episodes": 30792, "number_of_timesteps": 10993237, "per_episode_reward": 10.2, "episode_reward_trend_value": 0.0017735784479587916, "biggest_recent_change": 0.029348423991766737},
{"total_number_of_episodes": 30802, "number_of_timesteps": 10997256, "per_episode_reward": 10.22, "episode_reward_trend_value": 0.0018119184968343701, "biggest_recent_change": 0.029348423991766737},
{"total_number_of_episodes": 30812, "number_of_timesteps": 11001389, "per_episode_reward": 10.21, "episode_reward_trend_value": 0.0014554922876120417, "biggest_recent_change": 0.029348423991766737},
{"total_number_of_episodes": 30822, "number_of_timesteps": 11004879, "per_episode_reward": 10.22, "episode_reward_trend_value": 0.0012718298164703355, "biggest_recent_change": 0.029348423991766737},
{"total_number_of_episodes": 30832, "number_of_timesteps": 11007594, "per_episode_reward": 10.23, "episode_reward_trend_value": 0.0011384949975165803, "biggest_recent_change": 0.024662732930606168},
{"total_number_of_episodes": 30842, "number_of_timesteps": 11009572, "per_episode_reward": 10.23, "episode_reward_trend_value": 0.0008936034404044533, "biggest_recent_change": 0.024662732930606168},
{"total_number_of_episodes": 30852, "number_of_timesteps": 11012133, "per_episode_reward": 10.21, "episode_reward_trend_value": 0.0005397846298140625, "biggest_recent_change": 0.026452057194404688},
{"total_number_of_episodes": 30862, "number_of_timesteps": 11013426, "per_episode_reward": 10.2, "episode_reward_trend_value": 0.0003847977866112807, "biggest_recent_change": 0.026452057194404688},
{"total_number_of_episodes": 30872, "number_of_timesteps": 11015239, "per_episode_reward": 10.22, "episode_reward_trend_value": 0.00047091530989325193, "biggest_recent_change": 0.026452057194404688},
{"total_number_of_episodes": 30882, "number_of_timesteps": 11017316, "per_episode_reward": 10.23, "episode_reward_trend_value": 0.00030416533212379213, "biggest_recent_change": 0.026452057194404688},
{"total_number_of_episodes": 30892, "number_of_timesteps": 11020572, "per_episode_reward": 10.24, "episode_reward_trend_value": 0.0001787316378437925, "biggest_recent_change": 0.026452057194404688},
{"total_number_of_episodes": 30902, "number_of_timesteps": 11022607, "per_episode_reward": 10.24, "episode_reward_trend_value": 0.00034384968294439095, "biggest_recent_change": 0.026452057194404688},
{"total_number_of_episodes": 30913, "number_of_timesteps": 11024274, "per_episode_reward": 10.25, "episode_reward_trend_value": 0.00043700386394110387, "biggest_recent_change": 0.026452057194404688},
{"total_number_of_episodes": 30923, "number_of_timesteps": 11027834, "per_episode_reward": 10.26, "episode_reward_trend_value": 0.0003529199190104748, "biggest_recent_change": 0.026452057194404688},
{"total_number_of_episodes": 30933, "number_of_timesteps": 11032337, "per_episode_reward": 10.27, "episode_reward_trend_value": 0.0004066682845576924, "biggest_recent_change": 0.026452057194404688},
{"total_number_of_episodes": 30943, "number_of_timesteps": 11037305, "per_episode_reward": 10.26, "episode_reward_trend_value": 0.0006349225398084357, "biggest_recent_change": 0.0188773428117468},
{"total_number_of_episodes": 30953, "number_of_timesteps": 11039932, "per_episode_reward": 10.27, "episode_reward_trend_value": 0.0007955952167734518, "biggest_recent_change": 0.0188773428117468},
{"total_number_of_episodes": 30963, "number_of_timesteps": 11044655, "per_episode_reward": 10.24, "episode_reward_trend_value": 0.0002558454894161165, "biggest_recent_change": 0.02970013265041338},
{"total_number_of_episodes": 30973, "number_of_timesteps": 11049341, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0006209511913005548, "biggest_recent_change": 0.042514748100954236},
{"total_number_of_episodes": 30984, "number_of_timesteps": 11052640, "per_episode_reward": 10.32, "episode_reward_trend_value": 0.0009074258806956732, "biggest_recent_change": 0.042514748100954236},
{"total_number_of_episodes": 30995, "number_of_timesteps": 11055867, "per_episode_reward": 10.32, "episode_reward_trend_value": 0.0008378372399176234, "biggest_recent_change": 0.042514748100954236},
{"total_number_of_episodes": 31005, "number_of_timesteps": 11062206, "per_episode_reward": 10.35, "episode_reward_trend_value": 0.001058547094347675, "biggest_recent_change": 0.042514748100954236},
{"total_number_of_episodes": 31015, "number_of_timesteps": 11066456, "per_episode_reward": 10.34, "episode_reward_trend_value": 0.0008049179836013288, "biggest_recent_change": 0.042514748100954236},
{"total_number_of_episodes": 31025, "number_of_timesteps": 11071208, "per_episode_reward": 10.35, "episode_reward_trend_value": 0.000897611499125143, "biggest_recent_change": 0.042514748100954236},
{"total_number_of_episodes": 31036, "number_of_timesteps": 11075839, "per_episode_reward": 10.36, "episode_reward_trend_value": 0.001048435120956073, "biggest_recent_change": 0.042514748100954236},
{"total_number_of_episodes": 31046, "number_of_timesteps": 11080157, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0013948803430471556, "biggest_recent_change": 0.042514748100954236},
{"total_number_of_episodes": 31056, "number_of_timesteps": 11084078, "per_episode_reward": 10.44, "episode_reward_trend_value": 0.0021723405856415253, "biggest_recent_change": 0.042514748100954236},
{"total_number_of_episodes": 31067, "number_of_timesteps": 11088023, "per_episode_reward": 10.46, "episode_reward_trend_value": 0.0018653689783614605, "biggest_recent_change": 0.0419327030880261},
{"total_number_of_episodes": 31078, "number_of_timesteps": 11091995, "per_episode_reward": 10.47, "episode_reward_trend_value": 0.0016485447284785022, "biggest_recent_change": 0.0419327030880261},
{"total_number_of_episodes": 31088, "number_of_timesteps": 11096807, "per_episode_reward": 10.47, "episode_reward_trend_value": 0.0016502927973865767, "biggest_recent_change": 0.0419327030880261},
{"total_number_of_episodes": 31098, "number_of_timesteps": 11101438, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0016621099895907914, "biggest_recent_change": 0.0419327030880261},
{"total_number_of_episodes": 31108, "number_of_timesteps": 11103783, "per_episode_reward": 10.54, "episode_reward_trend_value": 0.002249904978154582, "biggest_recent_change": 0.0419327030880261},
{"total_number_of_episodes": 31118, "number_of_timesteps": 11107408, "per_episode_reward": 10.55, "episode_reward_trend_value": 0.002233811733118587, "biggest_recent_change": 0.0419327030880261},
{"total_number_of_episodes": 31128, "number_of_timesteps": 11110742, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0023163093889614966, "biggest_recent_change": 0.0419327030880261},
{"total_number_of_episodes": 31138, "number_of_timesteps": 11113927, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.001932705743396114, "biggest_recent_change": 0.04027128918307987},
{"total_number_of_episodes": 31148, "number_of_timesteps": 11117545, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0014648224148698535, "biggest_recent_change": 0.03985566424574216},
{"total_number_of_episodes": 31158, "number_of_timesteps": 11122660, "per_episode_reward": 10.59, "episode_reward_trend_value": 0.0014962765244426438, "biggest_recent_change": 0.03985566424574216},
{"total_number_of_episodes": 31168, "number_of_timesteps": 11128665, "per_episode_reward": 10.61, "episode_reward_trend_value": 0.001580131751223806, "biggest_recent_change": 0.03985566424574216},
{"total_number_of_episodes": 31178, "number_of_timesteps": 11132770, "per_episode_reward": 10.63, "episode_reward_trend_value": 0.0017787811979272975, "biggest_recent_change": 0.03985566424574216},
{"total_number_of_episodes": 31188, "number_of_timesteps": 11136036, "per_episode_reward": 10.64, "episode_reward_trend_value": 0.0015787952273099235, "biggest_recent_change": 0.03985566424574216},
{"total_number_of_episodes": 31198, "number_of_timesteps": 11138914, "per_episode_reward": 10.65, "episode_reward_trend_value": 0.0011885049916803602, "biggest_recent_change": 0.020477666389000504},
{"total_number_of_episodes": 31208, "number_of_timesteps": 11143538, "per_episode_reward": 10.66, "episode_reward_trend_value": 0.0011838929000390803, "biggest_recent_change": 0.020477666389000504},
{"total_number_of_episodes": 31218, "number_of_timesteps": 11147197, "per_episode_reward": 10.66, "episode_reward_trend_value": 0.0009984234236366518, "biggest_recent_change": 0.020477666389000504},
{"total_number_of_episodes": 31228, "number_of_timesteps": 11151934, "per_episode_reward": 10.66, "episode_reward_trend_value": 0.000995960200930194, "biggest_recent_change": 0.020477666389000504},
{"total_number_of_episodes": 31238, "number_of_timesteps": 11154843, "per_episode_reward": 10.67, "episode_reward_trend_value": 0.0010646660106588138, "biggest_recent_change": 0.020477666389000504},
{"total_number_of_episodes": 31248, "number_of_timesteps": 11159789, "per_episode_reward": 10.68, "episode_reward_trend_value": 0.0009801017563015632, "biggest_recent_change": 0.020477666389000504},
{"total_number_of_episodes": 31258, "number_of_timesteps": 11163395, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0009815081817490543, "biggest_recent_change": 0.020604244679274686},
{"total_number_of_episodes": 31268, "number_of_timesteps": 11166217, "per_episode_reward": 10.7, "episode_reward_trend_value": 0.0007594401202708391, "biggest_recent_change": 0.020604244679274686},
{"total_number_of_episodes": 31278, "number_of_timesteps": 11168883, "per_episode_reward": 10.73, "episode_reward_trend_value": 0.0009971115048926016, "biggest_recent_change": 0.03516231810201553},
{"total_number_of_episodes": 31288, "number_of_timesteps": 11171884, "per_episode_reward": 10.75, "episode_reward_trend_value": 0.0011202879367158284, "biggest_recent_change": 0.03516231810201553},
{"total_number_of_episodes": 31298, "number_of_timesteps": 11175600, "per_episode_reward": 10.77, "episode_reward_trend_value": 0.0012832312215588005, "biggest_recent_change": 0.03516231810201553},
{"total_number_of_episodes": 31308, "number_of_timesteps": 11178660, "per_episode_reward": 10.79, "episode_reward_trend_value": 0.0015140375415479055, "biggest_recent_change": 0.03516231810201553},
{"total_number_of_episodes": 31319, "number_of_timesteps": 11182186, "per_episode_reward": 10.79, "episode_reward_trend_value": 0.0013635373525503407, "biggest_recent_change": 0.03516231810201553},
{"total_number_of_episodes": 31329, "number_of_timesteps": 11186110, "per_episode_reward": 10.82, "episode_reward_trend_value": 0.0016584213860682579, "biggest_recent_change": 0.03516231810201553},
{"total_number_of_episodes": 31339, "number_of_timesteps": 11190859, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.0013538964447025255, "biggest_recent_change": 0.03516231810201553},
{"total_number_of_episodes": 31350, "number_of_timesteps": 11196166, "per_episode_reward": 10.85, "episode_reward_trend_value": 0.001725628065919614, "biggest_recent_change": 0.05406009058881267},
{"total_number_of_episodes": 31361, "number_of_timesteps": 11198488, "per_episode_reward": 10.86, "episode_reward_trend_value": 0.0018336168725825292, "biggest_recent_change": 0.05406009058881267},
{"total_number_of_episodes": 31371, "number_of_timesteps": 11203789, "per_episode_reward": 10.89, "episode_reward_trend_value": 0.0017596640291936282, "biggest_recent_change": 0.05406009058881267},
{"total_number_of_episodes": 31381, "number_of_timesteps": 11206288, "per_episode_reward": 10.88, "episode_reward_trend_value": 0.001442950964645462, "biggest_recent_change": 0.05406009058881267},
{"total_number_of_episodes": 31391, "number_of_timesteps": 11208695, "per_episode_reward": 10.88, "episode_reward_trend_value": 0.0011605930038051917, "biggest_recent_change": 0.05406009058881267},
{"total_number_of_episodes": 31401, "number_of_timesteps": 11210963, "per_episode_reward": 10.88, "episode_reward_trend_value": 0.0009432124495276837, "biggest_recent_change": 0.05406009058881267},
{"total_number_of_episodes": 31411, "number_of_timesteps": 11215340, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0012258033330778142, "biggest_recent_change": 0.05406009058881267},
{"total_number_of_episodes": 31421, "number_of_timesteps": 11219481, "per_episode_reward": 10.94, "episode_reward_trend_value": 0.001317754713144639, "biggest_recent_change": 0.05406009058881267},
{"total_number_of_episodes": 31431, "number_of_timesteps": 11221414, "per_episode_reward": 10.93, "episode_reward_trend_value": 0.0014186730858117614, "biggest_recent_change": 0.05406009058881267},
{"total_number_of_episodes": 31441, "number_of_timesteps": 11222854, "per_episode_reward": 10.93, "episode_reward_trend_value": 0.0008126918806280395, "biggest_recent_change": 0.039160499713918995},
{"total_number_of_episodes": 31451, "number_of_timesteps": 11225720, "per_episode_reward": 10.94, "episode_reward_trend_value": 0.0009229852766113212, "biggest_recent_change": 0.039160499713918995},
{"total_number_of_episodes": 31461, "number_of_timesteps": 11228480, "per_episode_reward": 10.94, "episode_reward_trend_value": 0.0005507453410616808, "biggest_recent_change": 0.039160499713918995},
{"total_number_of_episodes": 31471, "number_of_timesteps": 11232498, "per_episode_reward": 10.97, "episode_reward_trend_value": 0.0010631129374046348, "biggest_recent_change": 0.039160499713918995},
{"total_number_of_episodes": 31481, "number_of_timesteps": 11235399, "per_episode_reward": 10.96, "episode_reward_trend_value": 0.0008828396569842431, "biggest_recent_change": 0.039160499713918995},
{"total_number_of_episodes": 31491, "number_of_timesteps": 11237078, "per_episode_reward": 10.95, "episode_reward_trend_value": 0.0007495501222945499, "biggest_recent_change": 0.039160499713918995},
{"total_number_of_episodes": 31501, "number_of_timesteps": 11239975, "per_episode_reward": 10.96, "episode_reward_trend_value": 0.0006987437050728375, "biggest_recent_change": 0.039160499713918995},
{"total_number_of_episodes": 31511, "number_of_timesteps": 11241809, "per_episode_reward": 10.98, "episode_reward_trend_value": 0.00046353011596258245, "biggest_recent_change": 0.033424329764702776},
{"total_number_of_episodes": 31521, "number_of_timesteps": 11245480, "per_episode_reward": 10.97, "episode_reward_trend_value": 0.0004450495173012609, "biggest_recent_change": 0.033424329764702776},
{"total_number_of_episodes": 31531, "number_of_timesteps": 11249113, "per_episode_reward": 11.01, "episode_reward_trend_value": 0.0009320249609617193, "biggest_recent_change": 0.043349572051718965},
{"total_number_of_episodes": 31541, "number_of_timesteps": 11253199, "per_episode_reward": 11.02, "episode_reward_trend_value": 0.0008738940271481057, "biggest_recent_change": 0.043349572051718965},
{"total_number_of_episodes": 31551, "number_of_timesteps": 11256794, "per_episode_reward": 11.05, "episode_reward_trend_value": 0.0011901691458416784, "biggest_recent_change": 0.043349572051718965},
{"total_number_of_episodes": 31562, "number_of_timesteps": 11259888, "per_episode_reward": 11.07, "episode_reward_trend_value": 0.0010974969470682635, "biggest_recent_change": 0.043349572051718965},
{"total_number_of_episodes": 31573, "number_of_timesteps": 11262984, "per_episode_reward": 11.08, "episode_reward_trend_value": 0.0013227630128499848, "biggest_recent_change": 0.043349572051718965},
{"total_number_of_episodes": 31583, "number_of_timesteps": 11266507, "per_episode_reward": 11.07, "episode_reward_trend_value": 0.001434461609396149, "biggest_recent_change": 0.043349572051718965},
{"total_number_of_episodes": 31593, "number_of_timesteps": 11269800, "per_episode_reward": 11.09, "episode_reward_trend_value": 0.0014046734690989777, "biggest_recent_change": 0.043349572051718965},
{"total_number_of_episodes": 31603, "number_of_timesteps": 11272107, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0013271604362593138, "biggest_recent_change": 0.043349572051718965},
{"total_number_of_episodes": 31613, "number_of_timesteps": 11276390, "per_episode_reward": 11.11, "episode_reward_trend_value": 0.0015612786638914066, "biggest_recent_change": 0.043349572051718965},
{"total_number_of_episodes": 31624, "number_of_timesteps": 11279754, "per_episode_reward": 11.13, "episode_reward_trend_value": 0.001323919684377787, "biggest_recent_change": 0.02508383187509544},
{"total_number_of_episodes": 31634, "number_of_timesteps": 11283296, "per_episode_reward": 11.16, "episode_reward_trend_value": 0.0015700130858131759, "biggest_recent_change": 0.034274958009872236},
{"total_number_of_episodes": 31644, "number_of_timesteps": 11285732, "per_episode_reward": 11.17, "episode_reward_trend_value": 0.0013270550447026567, "biggest_recent_change": 0.034274958009872236},
{"total_number_of_episodes": 31656, "number_of_timesteps": 11289273, "per_episode_reward": 11.18, "episode_reward_trend_value": 0.0012516302507163365, "biggest_recent_change": 0.034274958009872236},
{"total_number_of_episodes": 31666, "number_of_timesteps": 11292252, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0013710017113747715, "biggest_recent_change": 0.034274958009872236},
{"total_number_of_episodes": 31676, "number_of_timesteps": 11294639, "per_episode_reward": 11.23, "episode_reward_trend_value": 0.001751966033601329, "biggest_recent_change": 0.034274958009872236},
{"total_number_of_episodes": 31686, "number_of_timesteps": 11297822, "per_episode_reward": 11.27, "episode_reward_trend_value": 0.001999884426023356, "biggest_recent_change": 0.034274958009872236},
{"total_number_of_episodes": 31696, "number_of_timesteps": 11300641, "per_episode_reward": 11.29, "episode_reward_trend_value": 0.002152247563072329, "biggest_recent_change": 0.034274958009872236},
{"total_number_of_episodes": 31706, "number_of_timesteps": 11304045, "per_episode_reward": 11.31, "episode_reward_trend_value": 0.0022261410400495722, "biggest_recent_change": 0.034274958009872236},
{"total_number_of_episodes": 31717, "number_of_timesteps": 11307221, "per_episode_reward": 11.31, "episode_reward_trend_value": 0.0020453714046275964, "biggest_recent_change": 0.034274958009872236},
{"total_number_of_episodes": 31727, "number_of_timesteps": 11310584, "per_episode_reward": 11.34, "episode_reward_trend_value": 0.001902925646016149, "biggest_recent_change": 0.03413399259457428},
{"total_number_of_episodes": 31738, "number_of_timesteps": 11315165, "per_episode_reward": 11.42, "episode_reward_trend_value": 0.0028544410912980803, "biggest_recent_change": 0.08723989505539542},
{"total_number_of_episodes": 31748, "number_of_timesteps": 11320124, "per_episode_reward": 11.41, "episode_reward_trend_value": 0.002458129762242203, "biggest_recent_change": 0.08723989505539542},
{"total_number_of_episodes": 31758, "number_of_timesteps": 11324865, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.00220069962181532, "biggest_recent_change": 0.08723989505539542},
{"total_number_of_episodes": 31769, "number_of_timesteps": 11328739, "per_episode_reward": 11.44, "episode_reward_trend_value": 0.002262397185524397, "biggest_recent_change": 0.08723989505539542},
{"total_number_of_episodes": 31779, "number_of_timesteps": 11330776, "per_episode_reward": 11.47, "episode_reward_trend_value": 0.0022367309634412262, "biggest_recent_change": 0.08723989505539542},
{"total_number_of_episodes": 31789, "number_of_timesteps": 11333579, "per_episode_reward": 11.47, "episode_reward_trend_value": 0.002017125530928156, "biggest_recent_change": 0.08723989505539542},
{"total_number_of_episodes": 31799, "number_of_timesteps": 11338043, "per_episode_reward": 11.46, "episode_reward_trend_value": 0.0016461760066039152, "biggest_recent_change": 0.08723989505539542},
{"total_number_of_episodes": 31809, "number_of_timesteps": 11341330, "per_episode_reward": 11.48, "episode_reward_trend_value": 0.0018141460606981852, "biggest_recent_change": 0.08723989505539542},
{"total_number_of_episodes": 31819, "number_of_timesteps": 11344779, "per_episode_reward": 11.48, "episode_reward_trend_value": 0.0016114159296989783, "biggest_recent_change": 0.08723989505539542},
{"total_number_of_episodes": 31829, "number_of_timesteps": 11347510, "per_episode_reward": 11.46, "episode_reward_trend_value": 0.0004225650914731618, "biggest_recent_change": 0.03750219210792238},
{"total_number_of_episodes": 31839, "number_of_timesteps": 11351903, "per_episode_reward": 11.47, "episode_reward_trend_value": 0.0007560120039143648, "biggest_recent_change": 0.03750219210792238},
{"total_number_of_episodes": 31849, "number_of_timesteps": 11356814, "per_episode_reward": 11.49, "episode_reward_trend_value": 0.001023779902673283, "biggest_recent_change": 0.03750219210792238},
{"total_number_of_episodes": 31859, "number_of_timesteps": 11361969, "per_episode_reward": 11.47, "episode_reward_trend_value": 0.00039471947232340275, "biggest_recent_change": 0.03182403260708888},
{"total_number_of_episodes": 31869, "number_of_timesteps": 11365987, "per_episode_reward": 11.54, "episode_reward_trend_value": 0.0007592788452284715, "biggest_recent_change": 0.06463437616854506},
{"total_number_of_episodes": 31879, "number_of_timesteps": 11371310, "per_episode_reward": 11.55, "episode_reward_trend_value": 0.0008602478557598262, "biggest_recent_change": 0.06463437616854506},
{"total_number_of_episodes": 31889, "number_of_timesteps": 11375100, "per_episode_reward": 11.55, "episode_reward_trend_value": 0.001002970164232981, "biggest_recent_change": 0.06463437616854506},
{"total_number_of_episodes": 31899, "number_of_timesteps": 11380290, "per_episode_reward": 11.56, "episode_reward_trend_value": 0.0008812123450607877, "biggest_recent_change": 0.06463437616854506},
{"total_number_of_episodes": 31909, "number_of_timesteps": 11383762, "per_episode_reward": 11.58, "episode_reward_trend_value": 0.0011095436100544297, "biggest_recent_change": 0.06463437616854506},
{"total_number_of_episodes": 31920, "number_of_timesteps": 11388786, "per_episode_reward": 11.59, "episode_reward_trend_value": 0.0013866691725634558, "biggest_recent_change": 0.06463437616854506},
{"total_number_of_episodes": 31930, "number_of_timesteps": 11393582, "per_episode_reward": 11.59, "episode_reward_trend_value": 0.0012955494856327595, "biggest_recent_change": 0.06463437616854506},
{"total_number_of_episodes": 31940, "number_of_timesteps": 11397499, "per_episode_reward": 11.59, "episode_reward_trend_value": 0.001144642875120145, "biggest_recent_change": 0.06463437616854506},
{"total_number_of_episodes": 31950, "number_of_timesteps": 11402145, "per_episode_reward": 11.61, "episode_reward_trend_value": 0.0015557030518462986, "biggest_recent_change": 0.06463437616854506},
{"total_number_of_episodes": 31960, "number_of_timesteps": 11405427, "per_episode_reward": 11.62, "episode_reward_trend_value": 0.0009050412021314477, "biggest_recent_change": 0.023758941794341126},
{"total_number_of_episodes": 31970, "number_of_timesteps": 11410230, "per_episode_reward": 11.62, "episode_reward_trend_value": 0.0007483146647825716, "biggest_recent_change": 0.023758941794341126},
{"total_number_of_episodes": 31980, "number_of_timesteps": 11412979, "per_episode_reward": 11.63, "episode_reward_trend_value": 0.0009091156376185418, "biggest_recent_change": 0.023758941794341126},
{"total_number_of_episodes": 31990, "number_of_timesteps": 11417809, "per_episode_reward": 11.64, "episode_reward_trend_value": 0.0008963916765789214, "biggest_recent_change": 0.023758941794341126},
{"total_number_of_episodes": 32000, "number_of_timesteps": 11421924, "per_episode_reward": 11.64, "episode_reward_trend_value": 0.0007107840070690269, "biggest_recent_change": 0.017882169281786986},
{"total_number_of_episodes": 32010, "number_of_timesteps": 11426594, "per_episode_reward": 11.65, "episode_reward_trend_value": 0.0007232255361199573, "biggest_recent_change": 0.017882169281786986},
{"total_number_of_episodes": 32020, "number_of_timesteps": 11430176, "per_episode_reward": 11.65, "episode_reward_trend_value": 0.0006153326391774053, "biggest_recent_change": 0.017882169281786986},
{"total_number_of_episodes": 32030, "number_of_timesteps": 11432917, "per_episode_reward": 11.66, "episode_reward_trend_value": 0.0007825666465305088, "biggest_recent_change": 0.017939441459168037},
{"total_number_of_episodes": 32040, "number_of_timesteps": 11435472, "per_episode_reward": 11.69, "episode_reward_trend_value": 0.0008903869709588404, "biggest_recent_change": 0.027585998480336826},

{"total_number_of_episodes": 32050, "number_of_timesteps": 11439265, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.0010033769380220529, "biggest_recent_change": 0.027585998480336826},
{"total_number_of_episodes": 32060, "number_of_timesteps": 11441439, "per_episode_reward": 11.7, "episode_reward_trend_value": 0.000941126484383877, "biggest_recent_change": 0.027585998480336826},
{"total_number_of_episodes": 32070, "number_of_timesteps": 11443201, "per_episode_reward": 11.71, "episode_reward_trend_value": 0.000852524944380326, "biggest_recent_change": 0.027585998480336826},
{"total_number_of_episodes": 32080, "number_of_timesteps": 11447584, "per_episode_reward": 11.75, "episode_reward_trend_value": 0.0012452239011045308, "biggest_recent_change": 0.044074847462114874},
{"total_number_of_episodes": 32091, "number_of_timesteps": 11452161, "per_episode_reward": 11.74, "episode_reward_trend_value": 0.0010929000519768392, "biggest_recent_change": 0.044074847462114874},
{"total_number_of_episodes": 32101, "number_of_timesteps": 11454919, "per_episode_reward": 11.73, "episode_reward_trend_value": 0.0008929056472347973, "biggest_recent_change": 0.044074847462114874},
{"total_number_of_episodes": 32111, "number_of_timesteps": 11458059, "per_episode_reward": 11.76, "episode_reward_trend_value": 0.0012317621408489958, "biggest_recent_change": 0.044074847462114874},
{"total_number_of_episodes": 32121, "number_of_timesteps": 11463076, "per_episode_reward": 11.78, "episode_reward_trend_value": 0.00125742051105152, "biggest_recent_change": 0.044074847462114874},
{"total_number_of_episodes": 32131, "number_of_timesteps": 11465601, "per_episode_reward": 11.79, "episode_reward_trend_value": 0.0011411923701478896, "biggest_recent_change": 0.044074847462114874},
{"total_number_of_episodes": 32141, "number_of_timesteps": 11470611, "per_episode_reward": 11.78, "episode_reward_trend_value": 0.0008573473736065255, "biggest_recent_change": 0.044074847462114874},
{"total_number_of_episodes": 32151, "number_of_timesteps": 11475133, "per_episode_reward": 11.79, "episode_reward_trend_value": 0.0009957932780126713, "biggest_recent_change": 0.044074847462114874},
{"total_number_of_episodes": 32161, "number_of_timesteps": 11479731, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0010426210221376822, "biggest_recent_change": 0.044074847462114874},
{"total_number_of_episodes": 32172, "number_of_timesteps": 11485300, "per_episode_reward": 11.77, "episode_reward_trend_value": 0.0002813638017477989, "biggest_recent_change": 0.025223754797691456},
{"total_number_of_episodes": 32182, "number_of_timesteps": 11488469, "per_episode_reward": 11.77, "episode_reward_trend_value": 0.0003314466153832562, "biggest_recent_change": 0.025223754797691456},
{"total_number_of_episodes": 32192, "number_of_timesteps": 11491882, "per_episode_reward": 11.78, "episode_reward_trend_value": 0.0005137250822133332, "biggest_recent_change": 0.025223754797691456},
{"total_number_of_episodes": 32202, "number_of_timesteps": 11495220, "per_episode_reward": 11.77, "episode_reward_trend_value": 0.00017968222594456998, "biggest_recent_change": 0.02443830237297462},
{"total_number_of_episodes": 32212, "number_of_timesteps": 11499715, "per_episode_reward": 11.81, "episode_reward_trend_value": 0.0003683717112996495, "biggest_recent_change": 0.03723074845935237},
{"total_number_of_episodes": 32222, "number_of_timesteps": 11503959, "per_episode_reward": 11.8, "episode_reward_trend_value": 1.819679633850373e-05, "biggest_recent_change": 0.03723074845935237},
{"total_number_of_episodes": 32232, "number_of_timesteps": 11507584, "per_episode_reward": 11.79, "episode_reward_trend_value": 7.490742645417629e-05, "biggest_recent_change": 0.03723074845935237},
{"total_number_of_episodes": 32242, "number_of_timesteps": 11509900, "per_episode_reward": 11.79, "episode_reward_trend_value": -1.4839347315742657e-05, "biggest_recent_change": 0.03723074845935237},
{"total_number_of_episodes": 32252, "number_of_timesteps": 11513257, "per_episode_reward": 11.81, "episode_reward_trend_value": 9.367664501303984e-05, "biggest_recent_change": 0.03723074845935237},
{"total_number_of_episodes": 32262, "number_of_timesteps": 11517906, "per_episode_reward": 11.81, "episode_reward_trend_value": 0.00043052761788528774, "biggest_recent_change": 0.03723074845935237},
{"total_number_of_episodes": 32273, "number_of_timesteps": 11520640, "per_episode_reward": 11.81, "episode_reward_trend_value": 0.0004422715221937502, "biggest_recent_change": 0.03723074845935237},
{"total_number_of_episodes": 32283, "number_of_timesteps": 11522802, "per_episode_reward": 11.83, "episode_reward_trend_value": 0.0005430232134741549, "biggest_recent_change": 0.03723074845935237},
{"total_number_of_episodes": 32293, "number_of_timesteps": 11525356, "per_episode_reward": 11.84, "episode_reward_trend_value": 0.0007353274961399592, "biggest_recent_change": 0.03723074845935237},
{"total_number_of_episodes": 32303, "number_of_timesteps": 11531092, "per_episode_reward": 11.86, "episode_reward_trend_value": 0.0005015661033096524, "biggest_recent_change": 0.017779034576754782},
{"total_number_of_episodes": 32313, "number_of_timesteps": 11533469, "per_episode_reward": 11.85, "episode_reward_trend_value": 0.0006308316586651862, "biggest_recent_change": 0.017779034576754782},
{"total_number_of_episodes": 32323, "number_of_timesteps": 11537847, "per_episode_reward": 11.88, "episode_reward_trend_value": 0.001009173276021712, "biggest_recent_change": 0.0298525593136727},
{"total_number_of_episodes": 32333, "number_of_timesteps": 11541519, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0011668501796824574, "biggest_recent_change": 0.0298525593136727},
{"total_number_of_episodes": 32343, "number_of_timesteps": 11544649, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0010796257562504193, "biggest_recent_change": 0.0298525593136727},
{"total_number_of_episodes": 32353, "number_of_timesteps": 11547199, "per_episode_reward": 11.91, "episode_reward_trend_value": 0.001125338849899925, "biggest_recent_change": 0.0298525593136727},
{"total_number_of_episodes": 32363, "number_of_timesteps": 11548888, "per_episode_reward": 11.91, "episode_reward_trend_value": 0.0011204509965547635, "biggest_recent_change": 0.0298525593136727},
{"total_number_of_episodes": 32374, "number_of_timesteps": 11552840, "per_episode_reward": 11.93, "episode_reward_trend_value": 0.0011405833960774498, "biggest_recent_change": 0.0298525593136727},
{"total_number_of_episodes": 32385, "number_of_timesteps": 11554299, "per_episode_reward": 11.96, "episode_reward_trend_value": 0.0013548718126343887, "biggest_recent_change": 0.031753240663549676},
{"total_number_of_episodes": 32395, "number_of_timesteps": 11555755, "per_episode_reward": 11.94, "episode_reward_trend_value": 0.0009750769306177057, "biggest_recent_change": 0.031753240663549676},
{"total_number_of_episodes": 32405, "number_of_timesteps": 11558468, "per_episode_reward": 11.96, "episode_reward_trend_value": 0.0011893708058614808, "biggest_recent_change": 0.031753240663549676},
{"total_number_of_episodes": 32415, "number_of_timesteps": 11561074, "per_episode_reward": 11.95, "episode_reward_trend_value": 0.0008091620005648892, "biggest_recent_change": 0.031753240663549676},
{"total_number_of_episodes": 32425, "number_of_timesteps": 11563219, "per_episode_reward": 11.96, "episode_reward_trend_value": 0.0006791855907976757, "biggest_recent_change": 0.031753240663549676},
{"total_number_of_episodes": 32436, "number_of_timesteps": 11566549, "per_episode_reward": 11.94, "episode_reward_trend_value": 0.0003974885201104191, "biggest_recent_change": 0.031753240663549676},
{"total_number_of_episodes": 32446, "number_of_timesteps": 11570948, "per_episode_reward": 11.95, "episode_reward_trend_value": 0.0003588920845634607, "biggest_recent_change": 0.031753240663549676},
{"total_number_of_episodes": 32456, "number_of_timesteps": 11573575, "per_episode_reward": 11.96, "episode_reward_trend_value": 0.0005320270157441421, "biggest_recent_change": 0.031753240663549676},
{"total_number_of_episodes": 32466, "number_of_timesteps": 11576143, "per_episode_reward": 11.96, "episode_reward_trend_value": 0.00039180423568176473, "biggest_recent_change": 0.031753240663549676},
{"total_number_of_episodes": 32476, "number_of_timesteps": 11579140, "per_episode_reward": 11.99, "episode_reward_trend_value": 0.0002756437107669127, "biggest_recent_change": 0.02129879342121299},
{"total_number_of_episodes": 32486, "number_of_timesteps": 11582327, "per_episode_reward": 11.98, "episode_reward_trend_value": 0.00038513150641763773, "biggest_recent_change": 0.02129879342121299},
{"total_number_of_episodes": 32496, "number_of_timesteps": 11585561, "per_episode_reward": 11.98, "episode_reward_trend_value": 0.00026769900409594606, "biggest_recent_change": 0.02129879342121299},
{"total_number_of_episodes": 32507, "number_of_timesteps": 11589058, "per_episode_reward": 11.99, "episode_reward_trend_value": 0.0004241958338166146, "biggest_recent_change": 0.02129879342121299},
{"total_number_of_episodes": 32517, "number_of_timesteps": 11591844, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0004974676227769, "biggest_recent_change": 0.02129879342121299},
{"total_number_of_episodes": 32527, "number_of_timesteps": 11594418, "per_episode_reward": 12.01, "episode_reward_trend_value": 0.000717679859061704, "biggest_recent_change": 0.02129879342121299},
{"total_number_of_episodes": 32537, "number_of_timesteps": 11597210, "per_episode_reward": 12.02, "episode_reward_trend_value": 0.0007624966816087782, "biggest_recent_change": 0.02129879342121299},
{"total_number_of_episodes": 32547, "number_of_timesteps": 11601323, "per_episode_reward": 12.02, "episode_reward_trend_value": 0.0006498183794470967, "biggest_recent_change": 0.02129879342121299},
{"total_number_of_episodes": 32557, "number_of_timesteps": 11605127, "per_episode_reward": 12.04, "episode_reward_trend_value": 0.0007953902515390373, "biggest_recent_change": 0.02129879342121299},
{"total_number_of_episodes": 32567, "number_of_timesteps": 11607579, "per_episode_reward": 12.03, "episode_reward_trend_value": 0.0005203079298215643, "biggest_recent_change": 0.016070909898330044},
{"total_number_of_episodes": 32577, "number_of_timesteps": 11609541, "per_episode_reward": 12.03, "episode_reward_trend_value": 0.0005637922115727691, "biggest_recent_change": 0.016070909898330044},
{"total_number_of_episodes": 32587, "number_of_timesteps": 11612408, "per_episode_reward": 12.04, "episode_reward_trend_value": 0.000655575830820945, "biggest_recent_change": 0.016070909898330044},
{"total_number_of_episodes": 32597, "number_of_timesteps": 11615606, "per_episode_reward": 12.05, "episode_reward_trend_value": 0.0006817147820082938, "biggest_recent_change": 0.016070909898330044},
{"total_number_of_episodes": 32607, "number_of_timesteps": 11617569, "per_episode_reward": 12.05, "episode_reward_trend_value": 0.0005012540838637175, "biggest_recent_change": 0.016070909898330044},
{"total_number_of_episodes": 32617, "number_of_timesteps": 11622556, "per_episode_reward": 12.06, "episode_reward_trend_value": 0.0006386164983376001, "biggest_recent_change": 0.01675781867430004},
{"total_number_of_episodes": 32627, "number_of_timesteps": 11624807, "per_episode_reward": 12.06, "episode_reward_trend_value": 0.0004440356377340946, "biggest_recent_change": 0.01675781867430004},
{"total_number_of_episodes": 32637, "number_of_timesteps": 11627103, "per_episode_reward": 12.08, "episode_reward_trend_value": 0.0006521201812289077, "biggest_recent_change": 0.022638308457089806},
{"total_number_of_episodes": 32647, "number_of_timesteps": 11629285, "per_episode_reward": 12.08, "episode_reward_trend_value": 0.0004819203108112704, "biggest_recent_change": 0.022638308457089806},
{"total_number_of_episodes": 32657, "number_of_timesteps": 11632468, "per_episode_reward": 12.08, "episode_reward_trend_value": 0.0005345732843875221, "biggest_recent_change": 0.022638308457089806},
{"total_number_of_episodes": 32667, "number_of_timesteps": 11635693, "per_episode_reward": 12.08, "episode_reward_trend_value": 0.0005843439606623393, "biggest_recent_change": 0.022638308457089806},
{"total_number_of_episodes": 32677, "number_of_timesteps": 11638733, "per_episode_reward": 12.06, "episode_reward_trend_value": 0.0002232630438020738, "biggest_recent_change": 0.022638308457089806},
{"total_number_of_episodes": 32687, "number_of_timesteps": 11640515, "per_episode_reward": 12.06, "episode_reward_trend_value": 1.5148153090195471e-05, "biggest_recent_change": 0.022638308457089806},
{"total_number_of_episodes": 32697, "number_of_timesteps": 11642673, "per_episode_reward": 12.04, "episode_reward_trend_value": -2.64192045013366e-05, "biggest_recent_change": 0.022638308457089806},
{"total_number_of_episodes": 32707, "number_of_timesteps": 11645996, "per_episode_reward": 12.07, "episode_reward_trend_value": 5.860765039808294e-05, "biggest_recent_change": 0.0244102356152478},
{"total_number_of_episodes": 32717, "number_of_timesteps": 11650213, "per_episode_reward": 12.09, "episode_reward_trend_value": 0.0003236782729155902, "biggest_recent_change": 0.0244102356152478},
{"total_number_of_episodes": 32727, "number_of_timesteps": 11653554, "per_episode_reward": 12.11, "episode_reward_trend_value": 0.0002969385280990345, "biggest_recent_change": 0.0244102356152478},
{"total_number_of_episodes": 32737, "number_of_timesteps": 11657928, "per_episode_reward": 12.09, "episode_reward_trend_value": 0.00010066808943991231, "biggest_recent_change": 0.0244102356152478},
{"total_number_of_episodes": 32747, "number_of_timesteps": 11661311, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0001738554382098714, "biggest_recent_change": 0.0244102356152478},
{"total_number_of_episodes": 32757, "number_of_timesteps": 11663641, "per_episode_reward": 12.08, "episode_reward_trend_value": 1.764489842849394e-05, "biggest_recent_change": 0.0244102356152478},
{"total_number_of_episodes": 32767, "number_of_timesteps": 11667660, "per_episode_reward": 12.11, "episode_reward_trend_value": 0.0004839705438936193, "biggest_recent_change": 0.0244102356152478},
{"total_number_of_episodes": 32777, "number_of_timesteps": 11672239, "per_episode_reward": 12.12, "episode_reward_trend_value": 0.0006879009907979455, "biggest_recent_change": 0.0244102356152478},
{"total_number_of_episodes": 32787, "number_of_timesteps": 11678175, "per_episode_reward": 12.15, "episode_reward_trend_value": 0.0011270152459101409, "biggest_recent_change": 0.0273507640635966},
{"total_number_of_episodes": 32797, "number_of_timesteps": 11683319, "per_episode_reward": 12.18, "episode_reward_trend_value": 0.001226980170231822, "biggest_recent_change": 0.03340707880419913},
{"total_number_of_episodes": 32808, "number_of_timesteps": 11689502, "per_episode_reward": 12.18, "episode_reward_trend_value": 0.0010639460658376817, "biggest_recent_change": 0.03340707880419913},
{"total_number_of_episodes": 32818, "number_of_timesteps": 11692570, "per_episode_reward": 12.18, "episode_reward_trend_value": 0.0008730027009264063, "biggest_recent_change": 0.03340707880419913},
{"total_number_of_episodes": 32828, "number_of_timesteps": 11700357, "per_episode_reward": 12.21, "episode_reward_trend_value": 0.0013283371409291552, "biggest_recent_change": 0.03340707880419913},
{"total_number_of_episodes": 32838, "number_of_timesteps": 11703563, "per_episode_reward": 12.23, "episode_reward_trend_value": 0.0014379705316588658, "biggest_recent_change": 0.03340707880419913},
{"total_number_of_episodes": 32848, "number_of_timesteps": 11706853, "per_episode_reward": 12.24, "episode_reward_trend_value": 0.0017335036876912585, "biggest_recent_change": 0.03340707880419913},
{"total_number_of_episodes": 32858, "number_of_timesteps": 11711873, "per_episode_reward": 12.26, "episode_reward_trend_value": 0.00171653717023131, "biggest_recent_change": 0.03340707880419913},
{"total_number_of_episodes": 32868, "number_of_timesteps": 11716222, "per_episode_reward": 12.26, "episode_reward_trend_value": 0.0015660587274681878, "biggest_recent_change": 0.03340707880419913},
{"total_number_of_episodes": 32878, "number_of_timesteps": 11721517, "per_episode_reward": 12.27, "episode_reward_trend_value": 0.001350562475939733, "biggest_recent_change": 0.03340707880419913},
{"total_number_of_episodes": 32888, "number_of_timesteps": 11725168, "per_episode_reward": 12.27, "episode_reward_trend_value": 0.0010470699807354341, "biggest_recent_change": 0.02406868168166909},
{"total_number_of_episodes": 32898, "number_of_timesteps": 11729224, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0011947969970522128, "biggest_recent_change": 0.02406868168166909},
{"total_number_of_episodes": 32908, "number_of_timesteps": 11733391, "per_episode_reward": 12.29, "episode_reward_trend_value": 0.0011781943887357747, "biggest_recent_change": 0.02406868168166909},
{"total_number_of_episodes": 32918, "number_of_timesteps": 11737263, "per_episode_reward": 12.32, "episode_reward_trend_value": 0.001211455846445454, "biggest_recent_change": 0.027062212875540226},
{"total_number_of_episodes": 32928, "number_of_timesteps": 11741552, "per_episode_reward": 12.34, "episode_reward_trend_value": 0.0012971221633380973, "biggest_recent_change": 0.027062212875540226},
{"total_number_of_episodes": 32938, "number_of_timesteps": 11746015, "per_episode_reward": 12.35, "episode_reward_trend_value": 0.001217238388535612, "biggest_recent_change": 0.027062212875540226},
{"total_number_of_episodes": 32948, "number_of_timesteps": 11749280, "per_episode_reward": 12.35, "episode_reward_trend_value": 0.001010655709138892, "biggest_recent_change": 0.027062212875540226},
{"total_number_of_episodes": 32958, "number_of_timesteps": 11752424, "per_episode_reward": 12.35, "episode_reward_trend_value": 0.0010162020636124047, "biggest_recent_change": 0.027062212875540226},
{"total_number_of_episodes": 32969, "number_of_timesteps": 11756938, "per_episode_reward": 12.36, "episode_reward_trend_value": 0.0010840695829648873, "biggest_recent_change": 0.027062212875540226},
{"total_number_of_episodes": 32979, "number_of_timesteps": 11758923, "per_episode_reward": 12.37, "episode_reward_trend_value": 0.0010317032265771864, "biggest_recent_change": 0.027062212875540226},
{"total_number_of_episodes": 32989, "number_of_timesteps": 11761202, "per_episode_reward": 12.35, "episode_reward_trend_value": 0.0006641321368601972, "biggest_recent_change": 0.027062212875540226},
{"total_number_of_episodes": 32999, "number_of_timesteps": 11763924, "per_episode_reward": 12.36, "episode_reward_trend_value": 0.0007706547378494398, "biggest_recent_change": 0.027062212875540226},
{"total_number_of_episodes": 33009, "number_of_timesteps": 11767891, "per_episode_reward": 12.37, "episode_reward_trend_value": 0.00059432103766037, "biggest_recent_change": 0.025443987163811244},
{"total_number_of_episodes": 33019, "number_of_timesteps": 11770040, "per_episode_reward": 12.37, "episode_reward_trend_value": 0.0003367584284355413, "biggest_recent_change": 0.01756265898523779},
{"total_number_of_episodes": 33029, "number_of_timesteps": 11772704, "per_episode_reward": 12.37, "episode_reward_trend_value": 0.0002812253005588319, "biggest_recent_change": 0.01756265898523779},
{"total_number_of_episodes": 33039, "number_of_timesteps": 11774421, "per_episode_reward": 12.37, "episode_reward_trend_value": 0.00015925791923084237, "biggest_recent_change": 0.01756265898523779},
{"total_number_of_episodes": 33049, "number_of_timesteps": 11777371, "per_episode_reward": 12.37, "episode_reward_trend_value": 0.0002084509690338502, "biggest_recent_change": 0.01756265898523779},
{"total_number_of_episodes": 33059, "number_of_timesteps": 11779140, "per_episode_reward": 12.38, "episode_reward_trend_value": 0.00017040010046578402, "biggest_recent_change": 0.01756265898523779},
{"total_number_of_episodes": 33069, "number_of_timesteps": 11782571, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0003328521468438971, "biggest_recent_change": 0.01756265898523779},
{"total_number_of_episodes": 33079, "number_of_timesteps": 11785238, "per_episode_reward": 12.41, "episode_reward_trend_value": 0.0006792836769849468, "biggest_recent_change": 0.016000466334949337},
{"total_number_of_episodes": 33089, "number_of_timesteps": 11788696, "per_episode_reward": 12.42, "episode_reward_trend_value": 0.0006975619263264695, "biggest_recent_change": 0.016000466334949337},
{"total_number_of_episodes": 33099, "number_of_timesteps": 11790641, "per_episode_reward": 12.43, "episode_reward_trend_value": 0.0006291322209455114, "biggest_recent_change": 0.016000466334949337},
{"total_number_of_episodes": 33109, "number_of_timesteps": 11794141, "per_episode_reward": 12.44, "episode_reward_trend_value": 0.0007929768947407427, "biggest_recent_change": 0.017009372975147485},
{"total_number_of_episodes": 33119, "number_of_timesteps": 11797149, "per_episode_reward": 12.47, "episode_reward_trend_value": 0.0011160335914880983, "biggest_recent_change": 0.029684148482756356},
{"total_number_of_episodes": 33129, "number_of_timesteps": 11798956, "per_episode_reward": 12.47, "episode_reward_trend_value": 0.0011747851348211805, "biggest_recent_change": 0.029684148482756356},
{"total_number_of_episodes": 33139, "number_of_timesteps": 11802275, "per_episode_reward": 12.47, "episode_reward_trend_value": 0.0011286731134375887, "biggest_recent_change": 0.029684148482756356},
{"total_number_of_episodes": 33149, "number_of_timesteps": 11806888, "per_episode_reward": 12.48, "episode_reward_trend_value": 0.0011249922935403155, "biggest_recent_change": 0.029684148482756356},
{"total_number_of_episodes": 33159, "number_of_timesteps": 11808589, "per_episode_reward": 12.49, "episode_reward_trend_value": 0.0010990102010052954, "biggest_recent_change": 0.029684148482756356},
{"total_number_of_episodes": 33169, "number_of_timesteps": 11810833, "per_episode_reward": 12.51, "episode_reward_trend_value": 0.0011243248319920815, "biggest_recent_change": 0.029684148482756356},
{"total_number_of_episodes": 33179, "number_of_timesteps": 11813947, "per_episode_reward": 12.51, "episode_reward_trend_value": 0.0010323757885681553, "biggest_recent_change": 0.029684148482756356},
{"total_number_of_episodes": 33189, "number_of_timesteps": 11816837, "per_episode_reward": 12.52, "episode_reward_trend_value": 0.001013604901334908, "biggest_recent_change": 0.029684148482756356},
{"total_number_of_episodes": 33200, "number_of_timesteps": 11820178, "per_episode_reward": 12.56, "episode_reward_trend_value": 0.0012643742659545943, "biggest_recent_change": 0.03957861579091926},
{"total_number_of_episodes": 33210, "number_of_timesteps": 11821925, "per_episode_reward": 12.55, "episode_reward_trend_value": 0.0008372634086726826, "biggest_recent_change": 0.03957861579091926},
{"total_number_of_episodes": 33220, "number_of_timesteps": 11824554, "per_episode_reward": 12.55, "episode_reward_trend_value": 0.0008829763942201771, "biggest_recent_change": 0.03957861579091926},
{"total_number_of_episodes": 33230, "number_of_timesteps": 11827396, "per_episode_reward": 12.57, "episode_reward_trend_value": 0.0010710017207654508, "biggest_recent_change": 0.03957861579091926},
{"total_number_of_episodes": 33240, "number_of_timesteps": 11829865, "per_episode_reward": 12.59, "episode_reward_trend_value": 0.0012619363308847534, "biggest_recent_change": 0.03957861579091926},
{"total_number_of_episodes": 33251, "number_of_timesteps": 11834033, "per_episode_reward": 12.61, "episode_reward_trend_value": 0.0012515244689640505, "biggest_recent_change": 0.03957861579091926},
{"total_number_of_episodes": 33261, "number_of_timesteps": 11836975, "per_episode_reward": 12.62, "episode_reward_trend_value": 0.0011666149711457804, "biggest_recent_change": 0.03957861579091926},
{"total_number_of_episodes": 33271, "number_of_timesteps": 11839025, "per_episode_reward": 12.61, "episode_reward_trend_value": 0.0010547869725299345, "biggest_recent_change": 0.03957861579091926},
{"total_number_of_episodes": 33281, "number_of_timesteps": 11842010, "per_episode_reward": 12.62, "episode_reward_trend_value": 0.0011178972547499753, "biggest_recent_change": 0.03957861579091926},
{"total_number_of_episodes": 33291, "number_of_timesteps": 11844899, "per_episode_reward": 12.62, "episode_reward_trend_value": 0.0007274529990370087, "biggest_recent_change": 0.02749244111661575},
{"total_number_of_episodes": 33301, "number_of_timesteps": 11847052, "per_episode_reward": 12.61, "episode_reward_trend_value": 0.0006403526230979593, "biggest_recent_change": 0.02749244111661575},
{"total_number_of_episodes": 33312, "number_of_timesteps": 11851735, "per_episode_reward": 12.63, "episode_reward_trend_value": 0.0008769709140145053, "biggest_recent_change": 0.02749244111661575},
{"total_number_of_episodes": 33322, "number_of_timesteps": 11853540, "per_episode_reward": 12.64, "episode_reward_trend_value": 0.0007933405016641575, "biggest_recent_change": 0.02749244111661575},
{"total_number_of_episodes": 33332, "number_of_timesteps": 11855369, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0005711089148508424, "biggest_recent_change": 0.023294660049387517},
{"total_number_of_episodes": 33342, "number_of_timesteps": 11858092, "per_episode_reward": 12.63, "episode_reward_trend_value": 0.00026843285189080354, "biggest_recent_change": 0.023294660049387517},
{"total_number_of_episodes": 33352, "number_of_timesteps": 11861229, "per_episode_reward": 12.63, "episode_reward_trend_value": 0.00017148431359971362, "biggest_recent_change": 0.023294660049387517},
{"total_number_of_episodes": 33362, "number_of_timesteps": 11864763, "per_episode_reward": 12.66, "episode_reward_trend_value": 0.0006046940025863712, "biggest_recent_change": 0.03343360858809419},
{"total_number_of_episodes": 33372, "number_of_timesteps": 11867911, "per_episode_reward": 12.69, "episode_reward_trend_value": 0.0008128122196769481, "biggest_recent_change": 0.03343360858809419},
{"total_number_of_episodes": 33383, "number_of_timesteps": 11871316, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0009040990402733072, "biggest_recent_change": 0.03343360858809419},
{"total_number_of_episodes": 33393, "number_of_timesteps": 11874922, "per_episode_reward": 12.73, "episode_reward_trend_value": 0.0013809539104278044, "biggest_recent_change": 0.03343360858809419},
{"total_number_of_episodes": 33403, "number_of_timesteps": 11879154, "per_episode_reward": 12.74, "episode_reward_trend_value": 0.0011960327548951315, "biggest_recent_change": 0.03343360858809419},
{"total_number_of_episodes": 33413, "number_of_timesteps": 11881064, "per_episode_reward": 12.74, "episode_reward_trend_value": 0.001135223024828195, "biggest_recent_change": 0.03343360858809419},
{"total_number_of_episodes": 33423, "number_of_timesteps": 11884653, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.001157998934969346, "biggest_recent_change": 0.03343360858809419},
{"total_number_of_episodes": 33433, "number_of_timesteps": 11887641, "per_episode_reward": 12.77, "episode_reward_trend_value": 0.0014902555020346617, "biggest_recent_change": 0.03343360858809419},
{"total_number_of_episodes": 33443, "number_of_timesteps": 11890522, "per_episode_reward": 12.76, "episode_reward_trend_value": 0.0014288447938909995, "biggest_recent_change": 0.03343360858809419},
{"total_number_of_episodes": 33453, "number_of_timesteps": 11894456, "per_episode_reward": 12.79, "episode_reward_trend_value": 0.001433446844380152, "biggest_recent_change": 0.03384779313211794},
{"total_number_of_episodes": 33464, "number_of_timesteps": 11899407, "per_episode_reward": 12.83, "episode_reward_trend_value": 0.0015313806691789722, "biggest_recent_change": 0.03656873569309482},
{"total_number_of_episodes": 33474, "number_of_timesteps": 11904404, "per_episode_reward": 12.84, "episode_reward_trend_value": 0.0014707900267151076, "biggest_recent_change": 0.03656873569309482},
{"total_number_of_episodes": 33484, "number_of_timesteps": 11907779, "per_episode_reward": 12.83, "episode_reward_trend_value": 0.0011478141119046449, "biggest_recent_change": 0.03656873569309482},
{"total_number_of_episodes": 33494, "number_of_timesteps": 11912327, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0012593980604922055, "biggest_recent_change": 0.03656873569309482},
{"total_number_of_episodes": 33504, "number_of_timesteps": 11917370, "per_episode_reward": 12.87, "episode_reward_trend_value": 0.0014601549009783967, "biggest_recent_change": 0.03656873569309482},
{"total_number_of_episodes": 33514, "number_of_timesteps": 11920571, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0016472156110426777, "biggest_recent_change": 0.03656873569309482},
{"total_number_of_episodes": 33524, "number_of_timesteps": 11922847, "per_episode_reward": 12.92, "episode_reward_trend_value": 0.001713110472998183, "biggest_recent_change": 0.03656873569309482},
{"total_number_of_episodes": 33534, "number_of_timesteps": 11927139, "per_episode_reward": 12.94, "episode_reward_trend_value": 0.0019522106007521245, "biggest_recent_change": 0.03656873569309482},
{"total_number_of_episodes": 33545, "number_of_timesteps": 11931000, "per_episode_reward": 12.97, "episode_reward_trend_value": 0.0019257471291773242, "biggest_recent_change": 0.03656873569309482},
{"total_number_of_episodes": 33555, "number_of_timesteps": 11935236, "per_episode_reward": 12.97, "episode_reward_trend_value": 0.0015395069614177754, "biggest_recent_change": 0.03146608069038592},
{"total_number_of_episodes": 33567, "number_of_timesteps": 11938996, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0029355623236050317, "biggest_recent_change": 0.13284627140552985},
{"total_number_of_episodes": 33577, "number_of_timesteps": 11942605, "per_episode_reward": 13.08, "episode_reward_trend_value": 0.002771195476892983, "biggest_recent_change": 0.13284627140552985},
{"total_number_of_episodes": 33587, "number_of_timesteps": 11945517, "per_episode_reward": 13.11, "episode_reward_trend_value": 0.002850926461030036, "biggest_recent_change": 0.13284627140552985},
{"total_number_of_episodes": 33597, "number_of_timesteps": 11948599, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.002926098424050573, "biggest_recent_change": 0.13284627140552985},
{"total_number_of_episodes": 33607, "number_of_timesteps": 11951868, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0026791126245418596, "biggest_recent_change": 0.13284627140552985},
{"total_number_of_episodes": 33617, "number_of_timesteps": 11955043, "per_episode_reward": 13.17, "episode_reward_trend_value": 0.002788018063725575, "biggest_recent_change": 0.13284627140552985},
{"total_number_of_episodes": 33627, "number_of_timesteps": 11958820, "per_episode_reward": 13.18, "episode_reward_trend_value": 0.002702796280746493, "biggest_recent_change": 0.13284627140552985},
{"total_number_of_episodes": 33637, "number_of_timesteps": 11964599, "per_episode_reward": 13.17, "episode_reward_trend_value": 0.002307313316317621, "biggest_recent_change": 0.13284627140552985},
{"total_number_of_episodes": 33647, "number_of_timesteps": 11970485, "per_episode_reward": 13.19, "episode_reward_trend_value": 0.002412495269630514, "biggest_recent_change": 0.13284627140552985},
{"total_number_of_episodes": 33657, "number_of_timesteps": 11974448, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0010471274765615096, "biggest_recent_change": 0.031119282905939016},
{"total_number_of_episodes": 33667, "number_of_timesteps": 11977955, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0013125505737898871, "biggest_recent_change": 0.031119282905939016},
{"total_number_of_episodes": 33677, "number_of_timesteps": 11984428, "per_episode_reward": 13.21, "episode_reward_trend_value": 0.0011624424551173284, "biggest_recent_change": 0.031119282905939016},
{"total_number_of_episodes": 33687, "number_of_timesteps": 11989501, "per_episode_reward": 13.21, "episode_reward_trend_value": 0.0008615261901631754, "biggest_recent_change": 0.031119282905939016},
{"total_number_of_episodes": 33697, "number_of_timesteps": 11993779, "per_episode_reward": 13.23, "episode_reward_trend_value": 0.0009718658773819734, "biggest_recent_change": 0.031119282905939016},
{"total_number_of_episodes": 33707, "number_of_timesteps": 11997326, "per_episode_reward": 13.24, "episode_reward_trend_value": 0.0008214522173648339, "biggest_recent_change": 0.017582053504396455},
{"total_number_of_episodes": 33717, "number_of_timesteps": 12002296, "per_episode_reward": 13.25, "episode_reward_trend_value": 0.0007949596055816441, "biggest_recent_change": 0.017582053504396455},
{"total_number_of_episodes": 33727, "number_of_timesteps": 12007405, "per_episode_reward": 13.27, "episode_reward_trend_value": 0.001054297827626469, "biggest_recent_change": 0.01921305387582173},
{"total_number_of_episodes": 33737, "number_of_timesteps": 12013086, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0011149754408097893, "biggest_recent_change": 0.01921305387582173},
{"total_number_of_episodes": 33747, "number_of_timesteps": 12017133, "per_episode_reward": 13.28, "episode_reward_trend_value": 0.0009382414712541691, "biggest_recent_change": 0.01921305387582173},
{"total_number_of_episodes": 33757, "number_of_timesteps": 12021913, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0009527081887267426, "biggest_recent_change": 0.01921305387582173},

{"total_number_of_episodes": 33768, "number_of_timesteps": 12024846, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0009113913257863656, "biggest_recent_change": 0.01921305387582173},
{"total_number_of_episodes": 33778, "number_of_timesteps": 12029131, "per_episode_reward": 13.32, "episode_reward_trend_value": 0.0011438379110399034, "biggest_recent_change": 0.021521779501773253},
{"total_number_of_episodes": 33788, "number_of_timesteps": 12032061, "per_episode_reward": 13.32, "episode_reward_trend_value": 0.0010752022251381277, "biggest_recent_change": 0.021521779501773253},
{"total_number_of_episodes": 33798, "number_of_timesteps": 12034951, "per_episode_reward": 13.33, "episode_reward_trend_value": 0.000918859731327378, "biggest_recent_change": 0.021521779501773253},
{"total_number_of_episodes": 33809, "number_of_timesteps": 12038316, "per_episode_reward": 13.33, "episode_reward_trend_value": 0.0009180243817362586, "biggest_recent_change": 0.021521779501773253},
{"total_number_of_episodes": 33819, "number_of_timesteps": 12041791, "per_episode_reward": 13.37, "episode_reward_trend_value": 0.0011351525772785938, "biggest_recent_change": 0.038754591474631894},
{"total_number_of_episodes": 33829, "number_of_timesteps": 12045960, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0012620212079688998, "biggest_recent_change": 0.038754591474631894},
{"total_number_of_episodes": 33839, "number_of_timesteps": 12049128, "per_episode_reward": 13.41, "episode_reward_trend_value": 0.00139797224581319, "biggest_recent_change": 0.038754591474631894},
{"total_number_of_episodes": 33849, "number_of_timesteps": 12051954, "per_episode_reward": 13.44, "episode_reward_trend_value": 0.0016878638840394683, "biggest_recent_change": 0.038754591474631894},
{"total_number_of_episodes": 33860, "number_of_timesteps": 12055951, "per_episode_reward": 13.44, "episode_reward_trend_value": 0.0015935684872958847, "biggest_recent_change": 0.038754591474631894},
{"total_number_of_episodes": 33870, "number_of_timesteps": 12059372, "per_episode_reward": 13.45, "episode_reward_trend_value": 0.0015290772159828473, "biggest_recent_change": 0.038754591474631894},
{"total_number_of_episodes": 33880, "number_of_timesteps": 12066606, "per_episode_reward": 13.42, "episode_reward_trend_value": 0.0011180483374725251, "biggest_recent_change": 0.038754591474631894},
{"total_number_of_episodes": 33890, "number_of_timesteps": 12072436, "per_episode_reward": 13.46, "episode_reward_trend_value": 0.001434835786322234, "biggest_recent_change": 0.038754591474631894},
{"total_number_of_episodes": 33900, "number_of_timesteps": 12077012, "per_episode_reward": 13.44, "episode_reward_trend_value": 0.0011735774646953819, "biggest_recent_change": 0.038754591474631894},
{"total_number_of_episodes": 33910, "number_of_timesteps": 12081169, "per_episode_reward": 13.44, "episode_reward_trend_value": 0.0008056279481381089, "biggest_recent_change": 0.033741558033199226},
{"total_number_of_episodes": 33921, "number_of_timesteps": 12083105, "per_episode_reward": 13.46, "episode_reward_trend_value": 0.0006917707628326515, "biggest_recent_change": 0.033741558033199226},
{"total_number_of_episodes": 33931, "number_of_timesteps": 12088112, "per_episode_reward": 13.47, "episode_reward_trend_value": 0.0007572837318534396, "biggest_recent_change": 0.033741558033199226},
{"total_number_of_episodes": 33941, "number_of_timesteps": 12090688, "per_episode_reward": 13.48, "episode_reward_trend_value": 0.00039820526401014675, "biggest_recent_change": 0.0320220994579028},
{"total_number_of_episodes": 33951, "number_of_timesteps": 12094088, "per_episode_reward": 13.47, "episode_reward_trend_value": 0.0003153288998199876, "biggest_recent_change": 0.0320220994579028},
{"total_number_of_episodes": 33961, "number_of_timesteps": 12096663, "per_episode_reward": 13.49, "episode_reward_trend_value": 0.00035721903304486186, "biggest_recent_change": 0.0320220994579028},
{"total_number_of_episodes": 33972, "number_of_timesteps": 12100498, "per_episode_reward": 13.52, "episode_reward_trend_value": 0.0010693535347209367, "biggest_recent_change": 0.0350010383695718},
{"total_number_of_episodes": 33982, "number_of_timesteps": 12105024, "per_episode_reward": 13.56, "episode_reward_trend_value": 0.0011384023492207105, "biggest_recent_change": 0.038236492762882435},
{"total_number_of_episodes": 33992, "number_of_timesteps": 12109174, "per_episode_reward": 13.55, "episode_reward_trend_value": 0.001294458726246835, "biggest_recent_change": 0.038236492762882435},
{"total_number_of_episodes": 34002, "number_of_timesteps": 12113279, "per_episode_reward": 13.58, "episode_reward_trend_value": 0.001529436927484302, "biggest_recent_change": 0.038236492762882435},
{"total_number_of_episodes": 34012, "number_of_timesteps": 12117568, "per_episode_reward": 13.61, "episode_reward_trend_value": 0.0016218732727463978, "biggest_recent_change": 0.038236492762882435},
{"total_number_of_episodes": 34022, "number_of_timesteps": 12121475, "per_episode_reward": 13.63, "episode_reward_trend_value": 0.001779405278433879, "biggest_recent_change": 0.038236492762882435},
{"total_number_of_episodes": 34032, "number_of_timesteps": 12125064, "per_episode_reward": 13.64, "episode_reward_trend_value": 0.0017930928701160001, "biggest_recent_change": 0.038236492762882435},
{"total_number_of_episodes": 34042, "number_of_timesteps": 12129090, "per_episode_reward": 13.66, "episode_reward_trend_value": 0.0021353945098732414, "biggest_recent_change": 0.038236492762882435},
{"total_number_of_episodes": 34052, "number_of_timesteps": 12132023, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0024963203823163598, "biggest_recent_change": 0.051971005593719255},
{"total_number_of_episodes": 34062, "number_of_timesteps": 12134268, "per_episode_reward": 13.73, "episode_reward_trend_value": 0.0023046261439159505, "biggest_recent_change": 0.051971005593719255},
{"total_number_of_episodes": 34072, "number_of_timesteps": 12136603, "per_episode_reward": 13.71, "episode_reward_trend_value": 0.0016400725262235721, "biggest_recent_change": 0.051971005593719255},
{"total_number_of_episodes": 34082, "number_of_timesteps": 12139635, "per_episode_reward": 13.73, "episode_reward_trend_value": 0.0019070618186242388, "biggest_recent_change": 0.051971005593719255},
{"total_number_of_episodes": 34092, "number_of_timesteps": 12142645, "per_episode_reward": 13.76, "episode_reward_trend_value": 0.0019881281517034094, "biggest_recent_change": 0.051971005593719255},
{"total_number_of_episodes": 34102, "number_of_timesteps": 12146045, "per_episode_reward": 13.76, "episode_reward_trend_value": 0.0017319288878176035, "biggest_recent_change": 0.051971005593719255},
{"total_number_of_episodes": 34112, "number_of_timesteps": 12150063, "per_episode_reward": 13.76, "episode_reward_trend_value": 0.0014401616615980237, "biggest_recent_change": 0.051971005593719255},
{"total_number_of_episodes": 34122, "number_of_timesteps": 12154138, "per_episode_reward": 13.78, "episode_reward_trend_value": 0.0015664947058847173, "biggest_recent_change": 0.051971005593719255},
{"total_number_of_episodes": 34132, "number_of_timesteps": 12156323, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.0015989756985561598, "biggest_recent_change": 0.051971005593719255},
{"total_number_of_episodes": 34142, "number_of_timesteps": 12159171, "per_episode_reward": 13.83, "episode_reward_trend_value": 0.0012765229221091405, "biggest_recent_change": 0.034083143072974664},
{"total_number_of_episodes": 34152, "number_of_timesteps": 12161886, "per_episode_reward": 13.84, "episode_reward_trend_value": 0.0012064265185287187, "biggest_recent_change": 0.034083143072974664},
{"total_number_of_episodes": 34162, "number_of_timesteps": 12165130, "per_episode_reward": 13.84, "episode_reward_trend_value": 0.0015110522578604742, "biggest_recent_change": 0.034083143072974664},
{"total_number_of_episodes": 34172, "number_of_timesteps": 12167975, "per_episode_reward": 13.87, "episode_reward_trend_value": 0.0016397181813308057, "biggest_recent_change": 0.034083143072974664},
{"total_number_of_episodes": 34182, "number_of_timesteps": 12169568, "per_episode_reward": 13.87, "episode_reward_trend_value": 0.0012044528963547426, "biggest_recent_change": 0.031530637453869303},
{"total_number_of_episodes": 34192, "number_of_timesteps": 12173437, "per_episode_reward": 13.89, "episode_reward_trend_value": 0.001399973031669472, "biggest_recent_change": 0.031530637453869303},
{"total_number_of_episodes": 34202, "number_of_timesteps": 12175880, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0014651241602433313, "biggest_recent_change": 0.031530637453869303},
{"total_number_of_episodes": 34212, "number_of_timesteps": 12177812, "per_episode_reward": 13.91, "episode_reward_trend_value": 0.0014381713405286847, "biggest_recent_change": 0.031530637453869303},
{"total_number_of_episodes": 34222, "number_of_timesteps": 12179735, "per_episode_reward": 13.92, "episode_reward_trend_value": 0.0013009171317163591, "biggest_recent_change": 0.031530637453869303},
{"total_number_of_episodes": 34232, "number_of_timesteps": 12183527, "per_episode_reward": 13.93, "episode_reward_trend_value": 0.0011253368638895367, "biggest_recent_change": 0.031530637453869303},
{"total_number_of_episodes": 34243, "number_of_timesteps": 12188902, "per_episode_reward": 13.94, "episode_reward_trend_value": 0.001121359220240513, "biggest_recent_change": 0.031530637453869303},
{"total_number_of_episodes": 34253, "number_of_timesteps": 12190529, "per_episode_reward": 13.92, "episode_reward_trend_value": 0.0008836422505514542, "biggest_recent_change": 0.031530637453869303},
{"total_number_of_episodes": 34263, "number_of_timesteps": 12193881, "per_episode_reward": 13.92, "episode_reward_trend_value": 0.0004839208634856441, "biggest_recent_change": 0.020763661166222747},
{"total_number_of_episodes": 34273, "number_of_timesteps": 12195997, "per_episode_reward": 13.96, "episode_reward_trend_value": 0.0010077875047023277, "biggest_recent_change": 0.042057265134630484},
{"total_number_of_episodes": 34285, "number_of_timesteps": 12198404, "per_episode_reward": 13.98, "episode_reward_trend_value": 0.0009647356303521488, "biggest_recent_change": 0.042057265134630484},
{"total_number_of_episodes": 34295, "number_of_timesteps": 12200605, "per_episode_reward": 13.95, "episode_reward_trend_value": 0.0005784525756170487, "biggest_recent_change": 0.042057265134630484},
{"total_number_of_episodes": 34305, "number_of_timesteps": 12202223, "per_episode_reward": 13.96, "episode_reward_trend_value": 0.0006224093142041396, "biggest_recent_change": 0.042057265134630484},
{"total_number_of_episodes": 34315, "number_of_timesteps": 12205704, "per_episode_reward": 13.98, "episode_reward_trend_value": 0.0006784874829823669, "biggest_recent_change": 0.042057265134630484},
{"total_number_of_episodes": 34325, "number_of_timesteps": 12208822, "per_episode_reward": 13.98, "episode_reward_trend_value": 0.000600099404706415, "biggest_recent_change": 0.042057265134630484},
{"total_number_of_episodes": 34335, "number_of_timesteps": 12211046, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0006532797147365975, "biggest_recent_change": 0.042057265134630484},
{"total_number_of_episodes": 34345, "number_of_timesteps": 12214435, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0008467368860910361, "biggest_recent_change": 0.042057265134630484},
{"total_number_of_episodes": 34355, "number_of_timesteps": 12217816, "per_episode_reward": 14.02, "episode_reward_trend_value": 0.001084871216155017, "biggest_recent_change": 0.042057265134630484},
{"total_number_of_episodes": 34365, "number_of_timesteps": 12222427, "per_episode_reward": 14.02, "episode_reward_trend_value": 0.0006796439654039964, "biggest_recent_change": 0.028794169815229864},
{"total_number_of_episodes": 34376, "number_of_timesteps": 12226419, "per_episode_reward": 14.01, "episode_reward_trend_value": 0.00034053216667818807, "biggest_recent_change": 0.028794169815229864},
{"total_number_of_episodes": 34386, "number_of_timesteps": 12230300, "per_episode_reward": 14.01, "episode_reward_trend_value": 0.0007433584152056404, "biggest_recent_change": 0.017120986482973777},
{"total_number_of_episodes": 34396, "number_of_timesteps": 12232060, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0004651754393087317, "biggest_recent_change": 0.017120986482973777},
{"total_number_of_episodes": 34406, "number_of_timesteps": 12235064, "per_episode_reward": 14.02, "episode_reward_trend_value": 0.0004402365853615543, "biggest_recent_change": 0.01698780232370467},
{"total_number_of_episodes": 34416, "number_of_timesteps": 12236707, "per_episode_reward": 14.02, "episode_reward_trend_value": 0.00042764147624748793, "biggest_recent_change": 0.01698780232370467},
{"total_number_of_episodes": 34426, "number_of_timesteps": 12240122, "per_episode_reward": 14.03, "episode_reward_trend_value": 0.0004295919169564399, "biggest_recent_change": 0.01698780232370467},
{"total_number_of_episodes": 34436, "number_of_timesteps": 12245664, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0005906696829695888, "biggest_recent_change": 0.01698780232370467},
{"total_number_of_episodes": 34446, "number_of_timesteps": 12249732, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0004422648558740466, "biggest_recent_change": 0.016356600801493926},
{"total_number_of_episodes": 34456, "number_of_timesteps": 12252947, "per_episode_reward": 14.08, "episode_reward_trend_value": 0.0006628866714129581, "biggest_recent_change": 0.025442775965540676},
{"total_number_of_episodes": 34466, "number_of_timesteps": 12256232, "per_episode_reward": 14.09, "episode_reward_trend_value": 0.0009643976787619202, "biggest_recent_change": 0.025442775965540676},
{"total_number_of_episodes": 34476, "number_of_timesteps": 12259127, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.000932450812740409, "biggest_recent_change": 0.025442775965540676},
{"total_number_of_episodes": 34486, "number_of_timesteps": 12261704, "per_episode_reward": 14.12, "episode_reward_trend_value": 0.0012376660317378768, "biggest_recent_change": 0.025442775965540676},
{"total_number_of_episodes": 34496, "number_of_timesteps": 12265379, "per_episode_reward": 14.12, "episode_reward_trend_value": 0.0011118841198649242, "biggest_recent_change": 0.025442775965540676},
{"total_number_of_episodes": 34506, "number_of_timesteps": 12269494, "per_episode_reward": 14.13, "episode_reward_trend_value": 0.0012055311660082188, "biggest_recent_change": 0.025442775965540676},
{"total_number_of_episodes": 34516, "number_of_timesteps": 12274340, "per_episode_reward": 14.14, "episode_reward_trend_value": 0.0011333449901872288, "biggest_recent_change": 0.025442775965540676},
{"total_number_of_episodes": 34526, "number_of_timesteps": 12277126, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0010629381526454454, "biggest_recent_change": 0.025442775965540676},
{"total_number_of_episodes": 34537, "number_of_timesteps": 12281515, "per_episode_reward": 14.17, "episode_reward_trend_value": 0.0012248121397752478, "biggest_recent_change": 0.025442775965540676},
{"total_number_of_episodes": 34547, "number_of_timesteps": 12285046, "per_episode_reward": 14.16, "episode_reward_trend_value": 0.0009306174634926458, "biggest_recent_change": 0.01820002672678811},
{"total_number_of_episodes": 34557, "number_of_timesteps": 12287638, "per_episode_reward": 14.17, "episode_reward_trend_value": 0.0008381976890120768, "biggest_recent_change": 0.01820002672678811},
{"total_number_of_episodes": 34568, "number_of_timesteps": 12291197, "per_episode_reward": 14.19, "episode_reward_trend_value": 0.0009822953761785967, "biggest_recent_change": 0.01820002672678811},
{"total_number_of_episodes": 34579, "number_of_timesteps": 12294296, "per_episode_reward": 14.21, "episode_reward_trend_value": 0.0010741121818389487, "biggest_recent_change": 0.026253120251498174},
{"total_number_of_episodes": 34589, "number_of_timesteps": 12298430, "per_episode_reward": 14.24, "episode_reward_trend_value": 0.001360098809769856, "biggest_recent_change": 0.029294914072943712},
{"total_number_of_episodes": 34599, "number_of_timesteps": 12302459, "per_episode_reward": 14.25, "episode_reward_trend_value": 0.0013917024228120626, "biggest_recent_change": 0.029294914072943712},
{"total_number_of_episodes": 34609, "number_of_timesteps": 12308282, "per_episode_reward": 14.26, "episode_reward_trend_value": 0.0013340440796852113, "biggest_recent_change": 0.029294914072943712},
{"total_number_of_episodes": 34619, "number_of_timesteps": 12311451, "per_episode_reward": 14.27, "episode_reward_trend_value": 0.0013980399132785001, "biggest_recent_change": 0.029294914072943712},
{"total_number_of_episodes": 34630, "number_of_timesteps": 12315807, "per_episode_reward": 14.28, "episode_reward_trend_value": 0.0012874080265398134, "biggest_recent_change": 0.029294914072943712},
{"total_number_of_episodes": 34640, "number_of_timesteps": 12318295, "per_episode_reward": 14.28, "episode_reward_trend_value": 0.0013390643262633222, "biggest_recent_change": 0.029294914072943712},
{"total_number_of_episodes": 34650, "number_of_timesteps": 12320431, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.001321806245708659, "biggest_recent_change": 0.029294914072943712},
{"total_number_of_episodes": 34660, "number_of_timesteps": 12324227, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.001099798487606702, "biggest_recent_change": 0.029294914072943712},
{"total_number_of_episodes": 34670, "number_of_timesteps": 12326684, "per_episode_reward": 14.28, "episode_reward_trend_value": 0.0007165203629167789, "biggest_recent_change": 0.029294914072943712},
{"total_number_of_episodes": 34680, "number_of_timesteps": 12329903, "per_episode_reward": 14.28, "episode_reward_trend_value": 0.0004396630610213769, "biggest_recent_change": 0.01577961044612941},
{"total_number_of_episodes": 34690, "number_of_timesteps": 12333244, "per_episode_reward": 14.29, "episode_reward_trend_value": 0.00040361432285058486, "biggest_recent_change": 0.01577961044612941},
{"total_number_of_episodes": 34700, "number_of_timesteps": 12336587, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0004957870424755484, "biggest_recent_change": 0.01577961044612941},
{"total_number_of_episodes": 34710, "number_of_timesteps": 12340012, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.00034163833630971555, "biggest_recent_change": 0.012653198290347945},
{"total_number_of_episodes": 34720, "number_of_timesteps": 12343251, "per_episode_reward": 14.31, "episode_reward_trend_value": 0.0002980172962190232, "biggest_recent_change": 0.012653198290347945},
{"total_number_of_episodes": 34730, "number_of_timesteps": 12348327, "per_episode_reward": 14.35, "episode_reward_trend_value": 0.0007120591574903499, "biggest_recent_change": 0.040878089589641675},
{"total_number_of_episodes": 34740, "number_of_timesteps": 12351761, "per_episode_reward": 14.35, "episode_reward_trend_value": 0.0007147643221952727, "biggest_recent_change": 0.040878089589641675},
{"total_number_of_episodes": 34750, "number_of_timesteps": 12355952, "per_episode_reward": 14.37, "episode_reward_trend_value": 0.0009243230227091972, "biggest_recent_change": 0.040878089589641675},
{"total_number_of_episodes": 34760, "number_of_timesteps": 12360218, "per_episode_reward": 14.35, "episode_reward_trend_value": 0.0007947139235014728, "biggest_recent_change": 0.040878089589641675},
{"total_number_of_episodes": 34770, "number_of_timesteps": 12365420, "per_episode_reward": 14.34, "episode_reward_trend_value": 0.0006507394821051054, "biggest_recent_change": 0.040878089589641675},
{"total_number_of_episodes": 34780, "number_of_timesteps": 12370667, "per_episode_reward": 14.35, "episode_reward_trend_value": 0.0006656105961609802, "biggest_recent_change": 0.040878089589641675},
{"total_number_of_episodes": 34790, "number_of_timesteps": 12374033, "per_episode_reward": 14.38, "episode_reward_trend_value": 0.0008249063986589929, "biggest_recent_change": 0.040878089589641675},
{"total_number_of_episodes": 34800, "number_of_timesteps": 12376860, "per_episode_reward": 14.42, "episode_reward_trend_value": 0.001241485260501681, "biggest_recent_change": 0.040878089589641675},
{"total_number_of_episodes": 34810, "number_of_timesteps": 12380452, "per_episode_reward": 14.42, "episode_reward_trend_value": 0.00123437140898432, "biggest_recent_change": 0.040878089589641675},
{"total_number_of_episodes": 34820, "number_of_timesteps": 12383038, "per_episode_reward": 14.41, "episode_reward_trend_value": 0.0007216060223795395, "biggest_recent_change": 0.039398324457046385},
{"total_number_of_episodes": 34830, "number_of_timesteps": 12386727, "per_episode_reward": 14.43, "episode_reward_trend_value": 0.0008496899772127778, "biggest_recent_change": 0.039398324457046385},
{"total_number_of_episodes": 34840, "number_of_timesteps": 12390461, "per_episode_reward": 14.43, "episode_reward_trend_value": 0.0006500952072530097, "biggest_recent_change": 0.039398324457046385},
{"total_number_of_episodes": 34850, "number_of_timesteps": 12394877, "per_episode_reward": 14.42, "episode_reward_trend_value": 0.0007551836598686042, "biggest_recent_change": 0.039398324457046385},
{"total_number_of_episodes": 34860, "number_of_timesteps": 12397971, "per_episode_reward": 14.45, "episode_reward_trend_value": 0.0011738250685311869, "biggest_recent_change": 0.039398324457046385},
{"total_number_of_episodes": 34870, "number_of_timesteps": 12402598, "per_episode_reward": 14.45, "episode_reward_trend_value": 0.0011426035046411365, "biggest_recent_change": 0.039398324457046385},
{"total_number_of_episodes": 34880, "number_of_timesteps": 12405301, "per_episode_reward": 14.44, "episode_reward_trend_value": 0.0007247844054603548, "biggest_recent_change": 0.039398324457046385},
{"total_number_of_episodes": 34890, "number_of_timesteps": 12407973, "per_episode_reward": 14.43, "episode_reward_trend_value": 0.00021478404372208518, "biggest_recent_change": 0.029097783956316903},
{"total_number_of_episodes": 34900, "number_of_timesteps": 12409960, "per_episode_reward": 14.41, "episode_reward_trend_value": -4.810050371786032e-05, "biggest_recent_change": 0.029097783956316903},
{"total_number_of_episodes": 34910, "number_of_timesteps": 12413338, "per_episode_reward": 14.46, "episode_reward_trend_value": 0.0004680352911478478, "biggest_recent_change": 0.04118142633312516},
{"total_number_of_episodes": 34920, "number_of_timesteps": 12416237, "per_episode_reward": 14.45, "episode_reward_trend_value": 0.0002413445101810691, "biggest_recent_change": 0.04118142633312516},
{"total_number_of_episodes": 34930, "number_of_timesteps": 12420456, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.000766932594654494, "biggest_recent_change": 0.04577274957859778},
{"total_number_of_episodes": 34940, "number_of_timesteps": 12423997, "per_episode_reward": 14.51, "episode_reward_trend_value": 0.001031090107256263, "biggest_recent_change": 0.04577274957859778},
{"total_number_of_episodes": 34950, "number_of_timesteps": 12426636, "per_episode_reward": 14.53, "episode_reward_trend_value": 0.0009445144565775523, "biggest_recent_change": 0.04577274957859778},
{"total_number_of_episodes": 34960, "number_of_timesteps": 12431461, "per_episode_reward": 14.56, "episode_reward_trend_value": 0.0012462135769050618, "biggest_recent_change": 0.04577274957859778},

{"total_number_of_episodes": 34971, "number_of_timesteps": 12435552, "per_episode_reward": 14.57, "episode_reward_trend_value": 0.0014218259259542244, "biggest_recent_change": 0.04577274957859778},
{"total_number_of_episodes": 34981, "number_of_timesteps": 12438571, "per_episode_reward": 14.58, "episode_reward_trend_value": 0.0015886873886428968, "biggest_recent_change": 0.04577274957859778},
{"total_number_of_episodes": 34991, "number_of_timesteps": 12443695, "per_episode_reward": 14.59, "episode_reward_trend_value": 0.0019860993128581585, "biggest_recent_change": 0.04577274957859778},
{"total_number_of_episodes": 35001, "number_of_timesteps": 12447136, "per_episode_reward": 14.63, "episode_reward_trend_value": 0.001933647908385774, "biggest_recent_change": 0.04577274957859778},
{"total_number_of_episodes": 35011, "number_of_timesteps": 12449637, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.002235535622111071, "biggest_recent_change": 0.04577274957859778},
{"total_number_of_episodes": 35021, "number_of_timesteps": 12451098, "per_episode_reward": 14.64, "episode_reward_trend_value": 0.0016236056644392722, "biggest_recent_change": 0.03646079993061058},
{"total_number_of_episodes": 35031, "number_of_timesteps": 12452738, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.0015563334457140124, "biggest_recent_change": 0.03646079993061058},
{"total_number_of_episodes": 35041, "number_of_timesteps": 12458507, "per_episode_reward": 14.67, "episode_reward_trend_value": 0.0015449438744597858, "biggest_recent_change": 0.03646079993061058},
{"total_number_of_episodes": 35051, "number_of_timesteps": 12464067, "per_episode_reward": 14.68, "episode_reward_trend_value": 0.001316529318066332, "biggest_recent_change": 0.03646079993061058},
{"total_number_of_episodes": 35061, "number_of_timesteps": 12469120, "per_episode_reward": 14.69, "episode_reward_trend_value": 0.001330531895406237, "biggest_recent_change": 0.03646079993061058},
{"total_number_of_episodes": 35071, "number_of_timesteps": 12475053, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0013506068517754796, "biggest_recent_change": 0.03646079993061058},
{"total_number_of_episodes": 35081, "number_of_timesteps": 12479155, "per_episode_reward": 14.71, "episode_reward_trend_value": 0.0012892633709004088, "biggest_recent_change": 0.03646079993061058},
{"total_number_of_episodes": 35091, "number_of_timesteps": 12482919, "per_episode_reward": 14.72, "episode_reward_trend_value": 0.0010494068820848825, "biggest_recent_change": 0.02217265900432075},
{"total_number_of_episodes": 35101, "number_of_timesteps": 12488057, "per_episode_reward": 14.73, "episode_reward_trend_value": 0.0008350149855132827, "biggest_recent_change": 0.020280913982352544},
{"total_number_of_episodes": 35111, "number_of_timesteps": 12492833, "per_episode_reward": 14.78, "episode_reward_trend_value": 0.0014774724920326992, "biggest_recent_change": 0.048520228974883395},
{"total_number_of_episodes": 35121, "number_of_timesteps": 12496292, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.0016241125716320761, "biggest_recent_change": 0.048520228974883395},
{"total_number_of_episodes": 35131, "number_of_timesteps": 12499875, "per_episode_reward": 14.82, "episode_reward_trend_value": 0.0016616447764306486, "biggest_recent_change": 0.048520228974883395},
{"total_number_of_episodes": 35141, "number_of_timesteps": 12503788, "per_episode_reward": 14.84, "episode_reward_trend_value": 0.0017728507852472336, "biggest_recent_change": 0.048520228974883395},
{"total_number_of_episodes": 35151, "number_of_timesteps": 12506534, "per_episode_reward": 14.85, "episode_reward_trend_value": 0.0018121345969032711, "biggest_recent_change": 0.048520228974883395},
{"total_number_of_episodes": 35161, "number_of_timesteps": 12509899, "per_episode_reward": 14.87, "episode_reward_trend_value": 0.0018747953528789353, "biggest_recent_change": 0.048520228974883395},
{"total_number_of_episodes": 35171, "number_of_timesteps": 12514074, "per_episode_reward": 14.89, "episode_reward_trend_value": 0.001973684833411523, "biggest_recent_change": 0.048520228974883395},
{"total_number_of_episodes": 35181, "number_of_timesteps": 12515833, "per_episode_reward": 14.89, "episode_reward_trend_value": 0.0018683851412634746, "biggest_recent_change": 0.048520228974883395},
{"total_number_of_episodes": 35191, "number_of_timesteps": 12518009, "per_episode_reward": 14.89, "episode_reward_trend_value": 0.0018291878329668165, "biggest_recent_change": 0.048520228974883395},
{"total_number_of_episodes": 35201, "number_of_timesteps": 12520600, "per_episode_reward": 14.89, "episode_reward_trend_value": 0.0013244520607871538, "biggest_recent_change": 0.023658812414224073},
{"total_number_of_episodes": 35211, "number_of_timesteps": 12522020, "per_episode_reward": 14.88, "episode_reward_trend_value": 0.0009594148275889816, "biggest_recent_change": 0.023658812414224073},
{"total_number_of_episodes": 35221, "number_of_timesteps": 12525487, "per_episode_reward": 14.88, "episode_reward_trend_value": 0.0007172400390842487, "biggest_recent_change": 0.02212032869777758},
{"total_number_of_episodes": 35231, "number_of_timesteps": 12529000, "per_episode_reward": 14.89, "episode_reward_trend_value": 0.0005168401574923425, "biggest_recent_change": 0.019163620554536465},
{"total_number_of_episodes": 35241, "number_of_timesteps": 12531627, "per_episode_reward": 14.87, "episode_reward_trend_value": 0.0001661125015139733, "biggest_recent_change": 0.021578501025095065},
{"total_number_of_episodes": 35251, "number_of_timesteps": 12535536, "per_episode_reward": 14.88, "episode_reward_trend_value": 8.95439999517775e-05, "biggest_recent_change": 0.021578501025095065},
{"total_number_of_episodes": 35261, "number_of_timesteps": 12538720, "per_episode_reward": 14.88, "episode_reward_trend_value": -0.00011908002865901324, "biggest_recent_change": 0.021578501025095065},
{"total_number_of_episodes": 35271, "number_of_timesteps": 12540696, "per_episode_reward": 14.88, "episode_reward_trend_value": -0.00016001622686449618, "biggest_recent_change": 0.021578501025095065},
{"total_number_of_episodes": 35281, "number_of_timesteps": 12545193, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0001101735537856838, "biggest_recent_change": 0.023666710824693737},
{"total_number_of_episodes": 35291, "number_of_timesteps": 12547410, "per_episode_reward": 14.9, "episode_reward_trend_value": 5.296201828552208e-05, "biggest_recent_change": 0.023666710824693737},
{"total_number_of_episodes": 35301, "number_of_timesteps": 12550020, "per_episode_reward": 14.91, "episode_reward_trend_value": 0.0003222754600546946, "biggest_recent_change": 0.023666710824693737},
{"total_number_of_episodes": 35311, "number_of_timesteps": 12552561, "per_episode_reward": 14.91, "episode_reward_trend_value": 0.00031007169288539417, "biggest_recent_change": 0.023666710824693737},
{"total_number_of_episodes": 35321, "number_of_timesteps": 12554885, "per_episode_reward": 14.91, "episode_reward_trend_value": 0.00024991757965696517, "biggest_recent_change": 0.023666710824693737},
{"total_number_of_episodes": 35332, "number_of_timesteps": 12558200, "per_episode_reward": 14.92, "episode_reward_trend_value": 0.0006372347998706711, "biggest_recent_change": 0.023666710824693737},
{"total_number_of_episodes": 35344, "number_of_timesteps": 12561287, "per_episode_reward": 14.94, "episode_reward_trend_value": 0.000697687559026604, "biggest_recent_change": 0.023666710824693737},
{"total_number_of_episodes": 35354, "number_of_timesteps": 12563434, "per_episode_reward": 14.95, "episode_reward_trend_value": 0.0007855309201754245, "biggest_recent_change": 0.023666710824693737},
{"total_number_of_episodes": 35365, "number_of_timesteps": 12566320, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0013903628605091236, "biggest_recent_change": 0.05614736043542834},
{"total_number_of_episodes": 35375, "number_of_timesteps": 12571344, "per_episode_reward": 15.02, "episode_reward_trend_value": 0.001288210216722775, "biggest_recent_change": 0.05614736043542834},
{"total_number_of_episodes": 35385, "number_of_timesteps": 12573845, "per_episode_reward": 15.03, "episode_reward_trend_value": 0.0014121190895240924, "biggest_recent_change": 0.05614736043542834},
{"total_number_of_episodes": 35395, "number_of_timesteps": 12576598, "per_episode_reward": 15.04, "episode_reward_trend_value": 0.0013899093694489926, "biggest_recent_change": 0.05614736043542834},
{"total_number_of_episodes": 35406, "number_of_timesteps": 12580769, "per_episode_reward": 15.06, "episode_reward_trend_value": 0.0016638667138306259, "biggest_recent_change": 0.05614736043542834},
{"total_number_of_episodes": 35416, "number_of_timesteps": 12584308, "per_episode_reward": 15.07, "episode_reward_trend_value": 0.0017276933558587812, "biggest_recent_change": 0.05614736043542834},
{"total_number_of_episodes": 35426, "number_of_timesteps": 12588378, "per_episode_reward": 15.08, "episode_reward_trend_value": 0.0017137276455029692, "biggest_recent_change": 0.05614736043542834},
{"total_number_of_episodes": 35436, "number_of_timesteps": 12591933, "per_episode_reward": 15.08, "episode_reward_trend_value": 0.0015611871273182012, "biggest_recent_change": 0.05614736043542834},
{"total_number_of_episodes": 35446, "number_of_timesteps": 12595137, "per_episode_reward": 15.09, "episode_reward_trend_value": 0.0016036591061624052, "biggest_recent_change": 0.05614736043542834},
{"total_number_of_episodes": 35457, "number_of_timesteps": 12598251, "per_episode_reward": 15.12, "episode_reward_trend_value": 0.0012489569111166312, "biggest_recent_change": 0.025420903397908035},
{"total_number_of_episodes": 35467, "number_of_timesteps": 12602111, "per_episode_reward": 15.14, "episode_reward_trend_value": 0.0013166800297502747, "biggest_recent_change": 0.025420903397908035},
{"total_number_of_episodes": 35477, "number_of_timesteps": 12604685, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0013233539149064358, "biggest_recent_change": 0.025420903397908035},
{"total_number_of_episodes": 35487, "number_of_timesteps": 12607537, "per_episode_reward": 15.16, "episode_reward_trend_value": 0.001384233925833832, "biggest_recent_change": 0.025420903397908035},
{"total_number_of_episodes": 35497, "number_of_timesteps": 12609990, "per_episode_reward": 15.19, "episode_reward_trend_value": 0.0013791462534129156, "biggest_recent_change": 0.02496301288002556},
{"total_number_of_episodes": 35507, "number_of_timesteps": 12614000, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0014886471386188975, "biggest_recent_change": 0.02496301288002556},
{"total_number_of_episodes": 35517, "number_of_timesteps": 12618884, "per_episode_reward": 15.19, "episode_reward_trend_value": 0.0012921255830471482, "biggest_recent_change": 0.02496301288002556},
{"total_number_of_episodes": 35527, "number_of_timesteps": 12621874, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.001352314010809113, "biggest_recent_change": 0.02496301288002556},
{"total_number_of_episodes": 35537, "number_of_timesteps": 12625954, "per_episode_reward": 15.22, "episode_reward_trend_value": 0.0014216688078802363, "biggest_recent_change": 0.02496301288002556},
{"total_number_of_episodes": 35547, "number_of_timesteps": 12629484, "per_episode_reward": 15.24, "episode_reward_trend_value": 0.0013642085078396308, "biggest_recent_change": 0.02496301288002556},
{"total_number_of_episodes": 35557, "number_of_timesteps": 12632826, "per_episode_reward": 15.24, "episode_reward_trend_value": 0.0011173064837174272, "biggest_recent_change": 0.02496301288002556},
{"total_number_of_episodes": 35567, "number_of_timesteps": 12636324, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0012114884577852556, "biggest_recent_change": 0.02496301288002556},
{"total_number_of_episodes": 35577, "number_of_timesteps": 12642764, "per_episode_reward": 15.27, "episode_reward_trend_value": 0.0011567529929028097, "biggest_recent_change": 0.02496301288002556},
{"total_number_of_episodes": 35587, "number_of_timesteps": 12648649, "per_episode_reward": 15.27, "episode_reward_trend_value": 0.0009648951050610045, "biggest_recent_change": 0.019052735877654214},
{"total_number_of_episodes": 35597, "number_of_timesteps": 12652740, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0011472422273096762, "biggest_recent_change": 0.03068118761740024},
{"total_number_of_episodes": 35607, "number_of_timesteps": 12656278, "per_episode_reward": 15.31, "episode_reward_trend_value": 0.0012884198345698452, "biggest_recent_change": 0.03068118761740024},
{"total_number_of_episodes": 35617, "number_of_timesteps": 12659817, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0011104043386343163, "biggest_recent_change": 0.03068118761740024},
{"total_number_of_episodes": 35627, "number_of_timesteps": 12662539, "per_episode_reward": 15.31, "episode_reward_trend_value": 0.001052779540429939, "biggest_recent_change": 0.03068118761740024},
{"total_number_of_episodes": 35637, "number_of_timesteps": 12665115, "per_episode_reward": 15.34, "episode_reward_trend_value": 0.0010808891268007967, "biggest_recent_change": 0.03068118761740024},
{"total_number_of_episodes": 35647, "number_of_timesteps": 12669671, "per_episode_reward": 15.32, "episode_reward_trend_value": 0.0009724202206390587, "biggest_recent_change": 0.03068118761740024},
{"total_number_of_episodes": 35657, "number_of_timesteps": 12673418, "per_episode_reward": 15.36, "episode_reward_trend_value": 0.0011323476489982355, "biggest_recent_change": 0.03256726571830271},
{"total_number_of_episodes": 35667, "number_of_timesteps": 12677187, "per_episode_reward": 15.36, "episode_reward_trend_value": 0.0010991214549722233, "biggest_recent_change": 0.03256726571830271},
{"total_number_of_episodes": 35677, "number_of_timesteps": 12680366, "per_episode_reward": 15.34, "episode_reward_trend_value": 0.0007781167228216053, "biggest_recent_change": 0.03256726571830271},
{"total_number_of_episodes": 35687, "number_of_timesteps": 12683517, "per_episode_reward": 15.36, "episode_reward_trend_value": 0.0006608323787161375, "biggest_recent_change": 0.03256726571830271},
{"total_number_of_episodes": 35697, "number_of_timesteps": 12686620, "per_episode_reward": 15.36, "episode_reward_trend_value": 0.0005266350754333102, "biggest_recent_change": 0.03256726571830271},
{"total_number_of_episodes": 35707, "number_of_timesteps": 12688695, "per_episode_reward": 15.37, "episode_reward_trend_value": 0.0007374308217926086, "biggest_recent_change": 0.03256726571830271},
{"total_number_of_episodes": 35717, "number_of_timesteps": 12692258, "per_episode_reward": 15.37, "episode_reward_trend_value": 0.000629038887152965, "biggest_recent_change": 0.03256726571830271},
{"total_number_of_episodes": 35727, "number_of_timesteps": 12694001, "per_episode_reward": 15.41, "episode_reward_trend_value": 0.0007793781591614232, "biggest_recent_change": 0.03511313313179265},
{"total_number_of_episodes": 35737, "number_of_timesteps": 12697120, "per_episode_reward": 15.41, "episode_reward_trend_value": 0.0009388021985231711, "biggest_recent_change": 0.03511313313179265},
{"total_number_of_episodes": 35747, "number_of_timesteps": 12699102, "per_episode_reward": 15.41, "episode_reward_trend_value": 0.0006236560605120111, "biggest_recent_change": 0.03511313313179265},
{"total_number_of_episodes": 35757, "number_of_timesteps": 12702287, "per_episode_reward": 15.43, "episode_reward_trend_value": 0.0007067860954418531, "biggest_recent_change": 0.03511313313179265},
{"total_number_of_episodes": 35767, "number_of_timesteps": 12704262, "per_episode_reward": 15.44, "episode_reward_trend_value": 0.001040140638801448, "biggest_recent_change": 0.03511313313179265},
{"total_number_of_episodes": 35777, "number_of_timesteps": 12706401, "per_episode_reward": 15.42, "episode_reward_trend_value": 0.0006644753712348085, "biggest_recent_change": 0.03511313313179265},

{"total_number_of_episodes": 35787, "number_of_timesteps": 12709781, "per_episode_reward": 15.45, "episode_reward_trend_value": 0.0009728339262509896, "biggest_recent_change": 0.03511313313179265},
{"total_number_of_episodes": 35797, "number_of_timesteps": 12712722, "per_episode_reward": 15.45, "episode_reward_trend_value": 0.0009465036632307959, "biggest_recent_change": 0.03511313313179265},
{"total_number_of_episodes": 35807, "number_of_timesteps": 12716651, "per_episode_reward": 15.46, "episode_reward_trend_value": 0.000991050105535586, "biggest_recent_change": 0.03511313313179265},
{"total_number_of_episodes": 35817, "number_of_timesteps": 12719526, "per_episode_reward": 15.46, "episode_reward_trend_value": 0.0005811891547197511, "biggest_recent_change": 0.022716692170074992},
{"total_number_of_episodes": 35827, "number_of_timesteps": 12722875, "per_episode_reward": 15.47, "episode_reward_trend_value": 0.0007065764080700908, "biggest_recent_change": 0.022716692170074992},
{"total_number_of_episodes": 35837, "number_of_timesteps": 12725670, "per_episode_reward": 15.49, "episode_reward_trend_value": 0.000891949708456726, "biggest_recent_change": 0.022716692170074992},
{"total_number_of_episodes": 35847, "number_of_timesteps": 12728712, "per_episode_reward": 15.48, "episode_reward_trend_value": 0.0006355033707858048, "biggest_recent_change": 0.022716692170074992},
{"total_number_of_episodes": 35857, "number_of_timesteps": 12731773, "per_episode_reward": 15.51, "episode_reward_trend_value": 0.0007846109008044167, "biggest_recent_change": 0.022716692170074992},
{"total_number_of_episodes": 35867, "number_of_timesteps": 12733478, "per_episode_reward": 15.53, "episode_reward_trend_value": 0.0012129021523581566, "biggest_recent_change": 0.024861935206747177},
{"total_number_of_episodes": 35877, "number_of_timesteps": 12735250, "per_episode_reward": 15.51, "episode_reward_trend_value": 0.0007462290935794474, "biggest_recent_change": 0.024861935206747177},
{"total_number_of_episodes": 35887, "number_of_timesteps": 12739484, "per_episode_reward": 15.54, "episode_reward_trend_value": 0.001020408459584606, "biggest_recent_change": 0.03145657450579442},
{"total_number_of_episodes": 35897, "number_of_timesteps": 12742036, "per_episode_reward": 15.56, "episode_reward_trend_value": 0.0011090836918825175, "biggest_recent_change": 0.03145657450579442},
{"total_number_of_episodes": 35907, "number_of_timesteps": 12745392, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0012303302682971108, "biggest_recent_change": 0.03145657450579442},
{"total_number_of_episodes": 35917, "number_of_timesteps": 12748883, "per_episode_reward": 15.56, "episode_reward_trend_value": 0.000988183297182981, "biggest_recent_change": 0.03145657450579442},
{"total_number_of_episodes": 35927, "number_of_timesteps": 12751804, "per_episode_reward": 15.57, "episode_reward_trend_value": 0.0008649629141240962, "biggest_recent_change": 0.03145657450579442},
{"total_number_of_episodes": 35937, "number_of_timesteps": 12755858, "per_episode_reward": 15.58, "episode_reward_trend_value": 0.00102669018088631, "biggest_recent_change": 0.03145657450579442},
{"total_number_of_episodes": 35947, "number_of_timesteps": 12759174, "per_episode_reward": 15.59, "episode_reward_trend_value": 0.000962041822903201, "biggest_recent_change": 0.03145657450579442},
{"total_number_of_episodes": 35957, "number_of_timesteps": 12763234, "per_episode_reward": 15.61, "episode_reward_trend_value": 0.0008125875228883651, "biggest_recent_change": 0.03145657450579442},
{"total_number_of_episodes": 35967, "number_of_timesteps": 12765860, "per_episode_reward": 15.61, "episode_reward_trend_value": 0.001129218515760202, "biggest_recent_change": 0.03145657450579442},
{"total_number_of_episodes": 35977, "number_of_timesteps": 12769955, "per_episode_reward": 15.62, "episode_reward_trend_value": 0.0008392893591385607, "biggest_recent_change": 0.016408611466266265},
{"total_number_of_episodes": 35987, "number_of_timesteps": 12774875, "per_episode_reward": 15.63, "episode_reward_trend_value": 0.0007662865671231916, "biggest_recent_change": 0.016408611466266265},
{"total_number_of_episodes": 35997, "number_of_timesteps": 12778744, "per_episode_reward": 15.61, "episode_reward_trend_value": 0.00043862182820389884, "biggest_recent_change": 0.020351987067055433},
{"total_number_of_episodes": 36007, "number_of_timesteps": 12781400, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.00047273004109502634, "biggest_recent_change": 0.020351987067055433},
{"total_number_of_episodes": 36018, "number_of_timesteps": 12784110, "per_episode_reward": 15.61, "episode_reward_trend_value": 0.00040532040815514215, "biggest_recent_change": 0.020351987067055433},
{"total_number_of_episodes": 36028, "number_of_timesteps": 12788803, "per_episode_reward": 15.61, "episode_reward_trend_value": 0.00033707499055246615, "biggest_recent_change": 0.020351987067055433},
{"total_number_of_episodes": 36038, "number_of_timesteps": 12791173, "per_episode_reward": 15.63, "episode_reward_trend_value": 0.00043201116924538815, "biggest_recent_change": 0.024952867548629243},
{"total_number_of_episodes": 36048, "number_of_timesteps": 12794039, "per_episode_reward": 15.64, "episode_reward_trend_value": 0.0004275942054404662, "biggest_recent_change": 0.024952867548629243},
{"total_number_of_episodes": 36058, "number_of_timesteps": 12797155, "per_episode_reward": 15.65, "episode_reward_trend_value": 0.00042252539319138395, "biggest_recent_change": 0.024952867548629243},
{"total_number_of_episodes": 36068, "number_of_timesteps": 12802771, "per_episode_reward": 15.66, "episode_reward_trend_value": 0.000501190618492981, "biggest_recent_change": 0.024952867548629243},
{"total_number_of_episodes": 36079, "number_of_timesteps": 12808625, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0009293219301405229, "biggest_recent_change": 0.04736778184051538},
{"total_number_of_episodes": 36089, "number_of_timesteps": 12813792, "per_episode_reward": 15.74, "episode_reward_trend_value": 0.0014442848993444575, "biggest_recent_change": 0.04736778184051538},
{"total_number_of_episodes": 36099, "number_of_timesteps": 12818269, "per_episode_reward": 15.76, "episode_reward_trend_value": 0.0016938547090418273, "biggest_recent_change": 0.04736778184051538},
{"total_number_of_episodes": 36109, "number_of_timesteps": 12821452, "per_episode_reward": 15.75, "episode_reward_trend_value": 0.001564434316702348, "biggest_recent_change": 0.04736778184051538},
{"total_number_of_episodes": 36120, "number_of_timesteps": 12825629, "per_episode_reward": 15.78, "episode_reward_trend_value": 0.0018999175314552493, "biggest_recent_change": 0.04736778184051538},
{"total_number_of_episodes": 36130, "number_of_timesteps": 12829222, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0018301026841880444, "biggest_recent_change": 0.04736778184051538},
{"total_number_of_episodes": 36140, "number_of_timesteps": 12832957, "per_episode_reward": 15.82, "episode_reward_trend_value": 0.001957017420616817, "biggest_recent_change": 0.04736778184051538},

{"total_number_of_episodes": 36151, "number_of_timesteps": 12837589, "per_episode_reward": 15.83, "episode_reward_trend_value": 0.001969577146228849, "biggest_recent_change": 0.04736778184051538},
{"total_number_of_episodes": 36161, "number_of_timesteps": 12841949, "per_episode_reward": 15.83, "episode_reward_trend_value": 0.001871353620248427, "biggest_recent_change": 0.04736778184051538},
{"total_number_of_episodes": 36171, "number_of_timesteps": 12845199, "per_episode_reward": 15.82, "episode_reward_trend_value": 0.0012178894988249707, "biggest_recent_change": 0.030425538600701074},
{"total_number_of_episodes": 36181, "number_of_timesteps": 12849081, "per_episode_reward": 15.84, "episode_reward_trend_value": 0.0011283724148328862, "biggest_recent_change": 0.030425538600701074},
{"total_number_of_episodes": 36191, "number_of_timesteps": 12851449, "per_episode_reward": 15.85, "episode_reward_trend_value": 0.0010500034434540555, "biggest_recent_change": 0.030425538600701074},
{"total_number_of_episodes": 36201, "number_of_timesteps": 12853986, "per_episode_reward": 15.85, "episode_reward_trend_value": 0.0010800181308611872, "biggest_recent_change": 0.030425538600701074},
{"total_number_of_episodes": 36211, "number_of_timesteps": 12856124, "per_episode_reward": 15.85, "episode_reward_trend_value": 0.0008167454428119885, "biggest_recent_change": 0.02243584774155849},
{"total_number_of_episodes": 36221, "number_of_timesteps": 12858719, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0007076368483796989, "biggest_recent_change": 0.02243584774155849},
{"total_number_of_episodes": 36231, "number_of_timesteps": 12861655, "per_episode_reward": 15.87, "episode_reward_trend_value": 0.0005515107851319417, "biggest_recent_change": 0.017938142602011098},
{"total_number_of_episodes": 36242, "number_of_timesteps": 12865433, "per_episode_reward": 15.88, "episode_reward_trend_value": 0.0005228107466726565, "biggest_recent_change": 0.017938142602011098},
{"total_number_of_episodes": 36252, "number_of_timesteps": 12869830, "per_episode_reward": 15.88, "episode_reward_trend_value": 0.0005316138641545207, "biggest_recent_change": 0.017938142602011098},
{"total_number_of_episodes": 36262, "number_of_timesteps": 12871964, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0008303114211500428, "biggest_recent_change": 0.017938142602011098},
{"total_number_of_episodes": 36273, "number_of_timesteps": 12875428, "per_episode_reward": 15.91, "episode_reward_trend_value": 0.0008103740458126612, "biggest_recent_change": 0.016143778821646748},
{"total_number_of_episodes": 36283, "number_of_timesteps": 12879211, "per_episode_reward": 15.93, "episode_reward_trend_value": 0.0008883776606468885, "biggest_recent_change": 0.017922598723162153},
{"total_number_of_episodes": 36293, "number_of_timesteps": 12882318, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0011654798759999038, "biggest_recent_change": 0.019723694830066307},
{"total_number_of_episodes": 36303, "number_of_timesteps": 12884675, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0011310700489693835, "biggest_recent_change": 0.019723694830066307},
{"total_number_of_episodes": 36313, "number_of_timesteps": 12887607, "per_episode_reward": 15.96, "episode_reward_trend_value": 0.0010836066074378752, "biggest_recent_change": 0.019723694830066307},
{"total_number_of_episodes": 36323, "number_of_timesteps": 12891068, "per_episode_reward": 15.98, "episode_reward_trend_value": 0.0012140605906953736, "biggest_recent_change": 0.02012536054243519},
{"total_number_of_episodes": 36333, "number_of_timesteps": 12893996, "per_episode_reward": 15.99, "episode_reward_trend_value": 0.0012628467289963374, "biggest_recent_change": 0.02012536054243519},
{"total_number_of_episodes": 36343, "number_of_timesteps": 12896237, "per_episode_reward": 15.99, "episode_reward_trend_value": 0.0011976236020676842, "biggest_recent_change": 0.02012536054243519},
{"total_number_of_episodes": 36353, "number_of_timesteps": 12899855, "per_episode_reward": 16.01, "episode_reward_trend_value": 0.0012172426981163535, "biggest_recent_change": 0.02012536054243519},
{"total_number_of_episodes": 36363, "number_of_timesteps": 12902541, "per_episode_reward": 16.02, "episode_reward_trend_value": 0.0011843591513838328, "biggest_recent_change": 0.02012536054243519},
{"total_number_of_episodes": 36373, "number_of_timesteps": 12906180, "per_episode_reward": 16.04, "episode_reward_trend_value": 0.0012199687297680443, "biggest_recent_change": 0.02112746077774119},
{"total_number_of_episodes": 36383, "number_of_timesteps": 12909550, "per_episode_reward": 16.02, "episode_reward_trend_value": 0.0008168958476689723, "biggest_recent_change": 0.02112746077774119},
{"total_number_of_episodes": 36394, "number_of_timesteps": 12913355, "per_episode_reward": 16.03, "episode_reward_trend_value": 0.000831062026914352, "biggest_recent_change": 0.02112746077774119},
{"total_number_of_episodes": 36405, "number_of_timesteps": 12917733, "per_episode_reward": 16.04, "episode_reward_trend_value": 0.0008908607878783274, "biggest_recent_change": 0.02112746077774119},
{"total_number_of_episodes": 36415, "number_of_timesteps": 12921298, "per_episode_reward": 16.07, "episode_reward_trend_value": 0.0009667635313501874, "biggest_recent_change": 0.02695660745490258},
{"total_number_of_episodes": 36425, "number_of_timesteps": 12924963, "per_episode_reward": 16.07, "episode_reward_trend_value": 0.0008469420374590482, "biggest_recent_change": 0.02695660745490258},
{"total_number_of_episodes": 36435, "number_of_timesteps": 12930395, "per_episode_reward": 16.09, "episode_reward_trend_value": 0.0010687647184814569, "biggest_recent_change": 0.02695660745490258},
{"total_number_of_episodes": 36445, "number_of_timesteps": 12935248, "per_episode_reward": 16.08, "episode_reward_trend_value": 0.000781954265116506, "biggest_recent_change": 0.02695660745490258},
{"total_number_of_episodes": 36455, "number_of_timesteps": 12939360, "per_episode_reward": 16.09, "episode_reward_trend_value": 0.0007808937800560677, "biggest_recent_change": 0.02695660745490258},
{"total_number_of_episodes": 36466, "number_of_timesteps": 12943473, "per_episode_reward": 16.12, "episode_reward_trend_value": 0.0008686470564376868, "biggest_recent_change": 0.029025255652086912},
{"total_number_of_episodes": 36476, "number_of_timesteps": 12947505, "per_episode_reward": 16.12, "episode_reward_trend_value": 0.0011233090981624528, "biggest_recent_change": 0.029025255652086912},
{"total_number_of_episodes": 36487, "number_of_timesteps": 12950318, "per_episode_reward": 16.16, "episode_reward_trend_value": 0.0014608064059399419, "biggest_recent_change": 0.03528382607558456},
{"total_number_of_episodes": 36497, "number_of_timesteps": 12954637, "per_episode_reward": 16.19, "episode_reward_trend_value": 0.001677294969388083, "biggest_recent_change": 0.03528382607558456},
{"total_number_of_episodes": 36507, "number_of_timesteps": 12959291, "per_episode_reward": 16.18, "episode_reward_trend_value": 0.0012797841210270475, "biggest_recent_change": 0.03528382607558456},
{"total_number_of_episodes": 36517, "number_of_timesteps": 12964222, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0015224925801912074, "biggest_recent_change": 0.03528382607558456},
{"total_number_of_episodes": 36527, "number_of_timesteps": 12967369, "per_episode_reward": 16.21, "episode_reward_trend_value": 0.001403616565661202, "biggest_recent_change": 0.03528382607558456},
{"total_number_of_episodes": 36538, "number_of_timesteps": 12971729, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0018843802909783293, "biggest_recent_change": 0.03528382607558456},
{"total_number_of_episodes": 36548, "number_of_timesteps": 12976109, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0023356721226099196, "biggest_recent_change": 0.05370508080712355},
{"total_number_of_episodes": 36558, "number_of_timesteps": 12979388, "per_episode_reward": 16.32, "episode_reward_trend_value": 0.002203884049076403, "biggest_recent_change": 0.05370508080712355},
{"total_number_of_episodes": 36569, "number_of_timesteps": 12983709, "per_episode_reward": 16.33, "episode_reward_trend_value": 0.0022434813695526874, "biggest_recent_change": 0.05370508080712355},
{"total_number_of_episodes": 36579, "number_of_timesteps": 12986724, "per_episode_reward": 16.32, "episode_reward_trend_value": 0.0017325524852946472, "biggest_recent_change": 0.05370508080712355},
{"total_number_of_episodes": 36589, "number_of_timesteps": 12990904, "per_episode_reward": 16.31, "episode_reward_trend_value": 0.001286578163316834, "biggest_recent_change": 0.05370508080712355},
{"total_number_of_episodes": 36599, "number_of_timesteps": 12994059, "per_episode_reward": 16.33, "episode_reward_trend_value": 0.0016564874847788582, "biggest_recent_change": 0.05370508080712355},
{"total_number_of_episodes": 36609, "number_of_timesteps": 12998634, "per_episode_reward": 16.38, "episode_reward_trend_value": 0.0019584506488562344, "biggest_recent_change": 0.05370508080712355},
{"total_number_of_episodes": 36619, "number_of_timesteps": 13001100, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0021247569948919754, "biggest_recent_change": 0.05370508080712355},
{"total_number_of_episodes": 36629, "number_of_timesteps": 13004438, "per_episode_reward": 16.42, "episode_reward_trend_value": 0.0018924184350936062, "biggest_recent_change": 0.05370508080712355},
{"total_number_of_episodes": 36639, "number_of_timesteps": 13007269, "per_episode_reward": 16.42, "episode_reward_trend_value": 0.001321748453350698, "biggest_recent_change": 0.04993134906840879},
{"total_number_of_episodes": 36649, "number_of_timesteps": 13010784, "per_episode_reward": 16.42, "episode_reward_trend_value": 0.0011676569634038478, "biggest_recent_change": 0.04993134906840879},
{"total_number_of_episodes": 36659, "number_of_timesteps": 13013561, "per_episode_reward": 16.42, "episode_reward_trend_value": 0.001068320412901337, "biggest_recent_change": 0.04993134906840879},
{"total_number_of_episodes": 36669, "number_of_timesteps": 13017754, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.001244361445926935, "biggest_recent_change": 0.04993134906840879},
{"total_number_of_episodes": 36680, "number_of_timesteps": 13020034, "per_episode_reward": 16.42, "episode_reward_trend_value": 0.0012450602930421835, "biggest_recent_change": 0.04993134906840879},
{"total_number_of_episodes": 36691, "number_of_timesteps": 13024387, "per_episode_reward": 16.44, "episode_reward_trend_value": 0.0012483497743996709, "biggest_recent_change": 0.04993134906840879},
{"total_number_of_episodes": 36701, "number_of_timesteps": 13028728, "per_episode_reward": 16.48, "episode_reward_trend_value": 0.0010858349236705638, "biggest_recent_change": 0.03530501250278917},
{"total_number_of_episodes": 36711, "number_of_timesteps": 13032915, "per_episode_reward": 16.47, "episode_reward_trend_value": 0.0007258467593754148, "biggest_recent_change": 0.03530501250278917},
{"total_number_of_episodes": 36722, "number_of_timesteps": 13037162, "per_episode_reward": 16.48, "episode_reward_trend_value": 0.0007111082105143711, "biggest_recent_change": 0.03530501250278917},
{"total_number_of_episodes": 36732, "number_of_timesteps": 13040439, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0009306717904726172, "biggest_recent_change": 0.03530501250278917},
{"total_number_of_episodes": 36742, "number_of_timesteps": 13043227, "per_episode_reward": 16.52, "episode_reward_trend_value": 0.0010848802006645682, "biggest_recent_change": 0.03530501250278917},
{"total_number_of_episodes": 36753, "number_of_timesteps": 13045953, "per_episode_reward": 16.54, "episode_reward_trend_value": 0.0012777425168899014, "biggest_recent_change": 0.03530501250278917},
{"total_number_of_episodes": 36763, "number_of_timesteps": 13048208, "per_episode_reward": 16.54, "episode_reward_trend_value": 0.0012389663417597062, "biggest_recent_change": 0.03530501250278917},
{"total_number_of_episodes": 36773, "number_of_timesteps": 13050368, "per_episode_reward": 16.54, "episode_reward_trend_value": 0.0013400446121729934, "biggest_recent_change": 0.03530501250278917},
{"total_number_of_episodes": 36783, "number_of_timesteps": 13054419, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0011907378299265284, "biggest_recent_change": 0.03530501250278917},
{"total_number_of_episodes": 36793, "number_of_timesteps": 13055935, "per_episode_reward": 16.56, "episode_reward_trend_value": 0.0009394190342226081, "biggest_recent_change": 0.02210550464650396},
{"total_number_of_episodes": 36803, "number_of_timesteps": 13058778, "per_episode_reward": 16.56, "episode_reward_trend_value": 0.0010356580033938122, "biggest_recent_change": 0.02210550464650396},
{"total_number_of_episodes": 36813, "number_of_timesteps": 13063172, "per_episode_reward": 16.56, "episode_reward_trend_value": 0.0009153284743118285, "biggest_recent_change": 0.02210550464650396},
{"total_number_of_episodes": 36823, "number_of_timesteps": 13067667, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.0007621509185876995, "biggest_recent_change": 0.018347796954298445},
{"total_number_of_episodes": 36833, "number_of_timesteps": 13072987, "per_episode_reward": 16.58, "episode_reward_trend_value": 0.000669964230242057, "biggest_recent_change": 0.018347796954298445},
{"total_number_of_episodes": 36844, "number_of_timesteps": 13077780, "per_episode_reward": 16.58, "episode_reward_trend_value": 0.0004985416191366375, "biggest_recent_change": 0.012686320889436331},
{"total_number_of_episodes": 36854, "number_of_timesteps": 13081848, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0006288366987869646, "biggest_recent_change": 0.013380620871476623},
{"total_number_of_episodes": 36864, "number_of_timesteps": 13087296, "per_episode_reward": 16.59, "episode_reward_trend_value": 0.0006102020494627898, "biggest_recent_change": 0.013380620871476623},
{"total_number_of_episodes": 36874, "number_of_timesteps": 13092084, "per_episode_reward": 16.61, "episode_reward_trend_value": 0.0006541342079250019, "biggest_recent_change": 0.015284807215582674},
{"total_number_of_episodes": 36884, "number_of_timesteps": 13095707, "per_episode_reward": 16.62, "episode_reward_trend_value": 0.0006499544347216989, "biggest_recent_change": 0.015284807215582674},
{"total_number_of_episodes": 36894, "number_of_timesteps": 13099097, "per_episode_reward": 16.63, "episode_reward_trend_value": 0.0007240487254858547, "biggest_recent_change": 0.015284807215582674},
{"total_number_of_episodes": 36904, "number_of_timesteps": 13101588, "per_episode_reward": 16.64, "episode_reward_trend_value": 0.0008909280122192658, "biggest_recent_change": 0.016612842571358755},
{"total_number_of_episodes": 36914, "number_of_timesteps": 13104934, "per_episode_reward": 16.64, "episode_reward_trend_value": 0.0007450414640744658, "biggest_recent_change": 0.016612842571358755},
{"total_number_of_episodes": 36925, "number_of_timesteps": 13108142, "per_episode_reward": 16.65, "episode_reward_trend_value": 0.0007424540277388776, "biggest_recent_change": 0.016612842571358755},
{"total_number_of_episodes": 36935, "number_of_timesteps": 13110986, "per_episode_reward": 16.68, "episode_reward_trend_value": 0.0010606634838942123, "biggest_recent_change": 0.031558613008790815},
{"total_number_of_episodes": 36945, "number_of_timesteps": 13113949, "per_episode_reward": 16.69, "episode_reward_trend_value": 0.0010347495286286486, "biggest_recent_change": 0.031558613008790815},
{"total_number_of_episodes": 36955, "number_of_timesteps": 13116111, "per_episode_reward": 16.68, "episode_reward_trend_value": 0.001016955324588251, "biggest_recent_change": 0.031558613008790815},
{"total_number_of_episodes": 36965, "number_of_timesteps": 13119587, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0010119184271303934, "biggest_recent_change": 0.031558613008790815},
{"total_number_of_episodes": 36975, "number_of_timesteps": 13121500, "per_episode_reward": 16.69, "episode_reward_trend_value": 0.0007978289469756797, "biggest_recent_change": 0.031558613008790815},
{"total_number_of_episodes": 36985, "number_of_timesteps": 13123803, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0007920334105672487, "biggest_recent_change": 0.031558613008790815},
{"total_number_of_episodes": 36995, "number_of_timesteps": 13127393, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0006717589928177305, "biggest_recent_change": 0.031558613008790815},
{"total_number_of_episodes": 37005, "number_of_timesteps": 13131546, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.0008341768926728813, "biggest_recent_change": 0.031558613008790815},
{"total_number_of_episodes": 37015, "number_of_timesteps": 13136400, "per_episode_reward": 16.72, "episode_reward_trend_value": 0.0008351096292640549, "biggest_recent_change": 0.031558613008790815},
{"total_number_of_episodes": 37025, "number_of_timesteps": 13140753, "per_episode_reward": 16.73, "episode_reward_trend_value": 0.0005353907918493661, "biggest_recent_change": 0.014831486444375486},
{"total_number_of_episodes": 37035, "number_of_timesteps": 13143101, "per_episode_reward": 16.73, "episode_reward_trend_value": 0.0004919833434112065, "biggest_recent_change": 0.014831486444375486},
{"total_number_of_episodes": 37045, "number_of_timesteps": 13147429, "per_episode_reward": 16.74, "episode_reward_trend_value": 0.0006468781597699468, "biggest_recent_change": 0.014831486444375486},
{"total_number_of_episodes": 37056, "number_of_timesteps": 13151487, "per_episode_reward": 16.74, "episode_reward_trend_value": 0.00046081167778871826, "biggest_recent_change": 0.009807346285263918},
{"total_number_of_episodes": 37066, "number_of_timesteps": 13155706, "per_episode_reward": 16.73, "episode_reward_trend_value": 0.0004347772172465625, "biggest_recent_change": 0.009807346285263918},
{"total_number_of_episodes": 37076, "number_of_timesteps": 13159083, "per_episode_reward": 16.74, "episode_reward_trend_value": 0.00045628163049814914, "biggest_recent_change": 0.009807346285263918},
{"total_number_of_episodes": 37086, "number_of_timesteps": 13162391, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.0005710715294561118, "biggest_recent_change": 0.016119235880118765},
{"total_number_of_episodes": 37096, "number_of_timesteps": 13167371, "per_episode_reward": 16.76, "episode_reward_trend_value": 0.0004901987625860076, "biggest_recent_change": 0.016119235880118765},
{"total_number_of_episodes": 37106, "number_of_timesteps": 13170217, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.00036036205743366327, "biggest_recent_change": 0.016119235880118765},
{"total_number_of_episodes": 37116, "number_of_timesteps": 13174083, "per_episode_reward": 16.76, "episode_reward_trend_value": 0.0003987337779200178, "biggest_recent_change": 0.016119235880118765},
{"total_number_of_episodes": 37126, "number_of_timesteps": 13175963, "per_episode_reward": 16.77, "episode_reward_trend_value": 0.00043888300191960005, "biggest_recent_change": 0.016119235880118765},
{"total_number_of_episodes": 37136, "number_of_timesteps": 13180460, "per_episode_reward": 16.78, "episode_reward_trend_value": 0.00036076538551618064, "biggest_recent_change": 0.016119235880118765},
{"total_number_of_episodes": 37146, "number_of_timesteps": 13183919, "per_episode_reward": 16.76, "episode_reward_trend_value": 0.00026734569311269104, "biggest_recent_change": 0.016119235880118765},
{"total_number_of_episodes": 37157, "number_of_timesteps": 13186254, "per_episode_reward": 16.77, "episode_reward_trend_value": 0.00046146450143823693, "biggest_recent_change": 0.016119235880118765},

{"total_number_of_episodes": 37167, "number_of_timesteps": 13190519, "per_episode_reward": 16.78, "episode_reward_trend_value": 0.00045729139234265876, "biggest_recent_change": 0.016119235880118765},
{"total_number_of_episodes": 37177, "number_of_timesteps": 13194053, "per_episode_reward": 16.76, "episode_reward_trend_value": 0.00010986282577134273, "biggest_recent_change": 0.015149335111299678},
{"total_number_of_episodes": 37187, "number_of_timesteps": 13197013, "per_episode_reward": 16.76, "episode_reward_trend_value": 5.437476450411951e-06, "biggest_recent_change": 0.015149335111299678},
{"total_number_of_episodes": 37197, "number_of_timesteps": 13199276, "per_episode_reward": 16.78, "episode_reward_trend_value": 0.00031587429681469495, "biggest_recent_change": 0.02498313729709878},
{"total_number_of_episodes": 37207, "number_of_timesteps": 13201815, "per_episode_reward": 16.79, "episode_reward_trend_value": 0.00033596158885992444, "biggest_recent_change": 0.02498313729709878},
{"total_number_of_episodes": 37217, "number_of_timesteps": 13204762, "per_episode_reward": 16.81, "episode_reward_trend_value": 0.0003793086945194091, "biggest_recent_change": 0.02498313729709878},
{"total_number_of_episodes": 37227, "number_of_timesteps": 13209613, "per_episode_reward": 16.83, "episode_reward_trend_value": 0.000604489962123959, "biggest_recent_change": 0.02498313729709878},
{"total_number_of_episodes": 37237, "number_of_timesteps": 13214532, "per_episode_reward": 16.84, "episode_reward_trend_value": 0.0008591006452455474, "biggest_recent_change": 0.02498313729709878},
{"total_number_of_episodes": 37247, "number_of_timesteps": 13217601, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0009212906652620015, "biggest_recent_change": 0.02498313729709878},
{"total_number_of_episodes": 37257, "number_of_timesteps": 13220828, "per_episode_reward": 16.87, "episode_reward_trend_value": 0.0010134694885719695, "biggest_recent_change": 0.02498313729709878},
{"total_number_of_episodes": 37267, "number_of_timesteps": 13226580, "per_episode_reward": 16.89, "episode_reward_trend_value": 0.0013457166163185264, "biggest_recent_change": 0.02498313729709878},
{"total_number_of_episodes": 37277, "number_of_timesteps": 13230706, "per_episode_reward": 16.88, "episode_reward_trend_value": 0.0013583187645943597, "biggest_recent_change": 0.02498313729709878},
{"total_number_of_episodes": 37287, "number_of_timesteps": 13233940, "per_episode_reward": 16.89, "episode_reward_trend_value": 0.0011801115795676824, "biggest_recent_change": 0.022363824132071386},
{"total_number_of_episodes": 37297, "number_of_timesteps": 13235945, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.001174105773659938, "biggest_recent_change": 0.022363824132071386},
{"total_number_of_episodes": 37307, "number_of_timesteps": 13238855, "per_episode_reward": 16.89, "episode_reward_trend_value": 0.0009173237085995033, "biggest_recent_change": 0.022363824132071386},
{"total_number_of_episodes": 37318, "number_of_timesteps": 13241889, "per_episode_reward": 16.91, "episode_reward_trend_value": 0.0008931410799879322, "biggest_recent_change": 0.02018738755702998},
{"total_number_of_episodes": 37328, "number_of_timesteps": 13246267, "per_episode_reward": 16.91, "episode_reward_trend_value": 0.0007008019359457052, "biggest_recent_change": 0.02018738755702998},
{"total_number_of_episodes": 37338, "number_of_timesteps": 13249650, "per_episode_reward": 16.92, "episode_reward_trend_value": 0.0007191835978927388, "biggest_recent_change": 0.02018738755702998},
{"total_number_of_episodes": 37349, "number_of_timesteps": 13255023, "per_episode_reward": 16.94, "episode_reward_trend_value": 0.0007955365419844738, "biggest_recent_change": 0.021894810397128595},
{"total_number_of_episodes": 37359, "number_of_timesteps": 13260303, "per_episode_reward": 16.95, "episode_reward_trend_value": 0.0007436088884664589, "biggest_recent_change": 0.021894810397128595},
{"total_number_of_episodes": 37369, "number_of_timesteps": 13266417, "per_episode_reward": 16.96, "episode_reward_trend_value": 0.0009399195717937422, "biggest_recent_change": 0.021894810397128595},
{"total_number_of_episodes": 37379, "number_of_timesteps": 13269253, "per_episode_reward": 16.96, "episode_reward_trend_value": 0.0007727555077452782, "biggest_recent_change": 0.021894810397128595},
{"total_number_of_episodes": 37389, "number_of_timesteps": 13272805, "per_episode_reward": 16.96, "episode_reward_trend_value": 0.0007003242881066759, "biggest_recent_change": 0.021894810397128595},
{"total_number_of_episodes": 37400, "number_of_timesteps": 13277103, "per_episode_reward": 16.96, "episode_reward_trend_value": 0.0007873281129269808, "biggest_recent_change": 0.021894810397128595},
{"total_number_of_episodes": 37410, "number_of_timesteps": 13281509, "per_episode_reward": 16.96, "episode_reward_trend_value": 0.0005715521832367109, "biggest_recent_change": 0.021894810397128595},
{"total_number_of_episodes": 37420, "number_of_timesteps": 13286910, "per_episode_reward": 16.97, "episode_reward_trend_value": 0.000676879438882278, "biggest_recent_change": 0.021894810397128595},
{"total_number_of_episodes": 37430, "number_of_timesteps": 13293792, "per_episode_reward": 16.95, "episode_reward_trend_value": 0.00036490867115329055, "biggest_recent_change": 0.021894810397128595},
{"total_number_of_episodes": 37440, "number_of_timesteps": 13296409, "per_episode_reward": 16.94, "episode_reward_trend_value": -8.115131121297421e-05, "biggest_recent_change": 0.018250588015835234},
{"total_number_of_episodes": 37450, "number_of_timesteps": 13299478, "per_episode_reward": 16.92, "episode_reward_trend_value": -0.0003241228420689721, "biggest_recent_change": 0.018250588015835234},
{"total_number_of_episodes": 37460, "number_of_timesteps": 13301774, "per_episode_reward": 16.91, "episode_reward_trend_value": -0.0005777312064386326, "biggest_recent_change": 0.018250588015835234},
{"total_number_of_episodes": 37470, "number_of_timesteps": 13306536, "per_episode_reward": 16.9, "episode_reward_trend_value": -0.0006199668352684522, "biggest_recent_change": 0.018250588015835234},
{"total_number_of_episodes": 37480, "number_of_timesteps": 13309955, "per_episode_reward": 16.91, "episode_reward_trend_value": -0.0006047969613292359, "biggest_recent_change": 0.018250588015835234},
{"total_number_of_episodes": 37490, "number_of_timesteps": 13316010, "per_episode_reward": 16.91, "episode_reward_trend_value": -0.00055030919838804, "biggest_recent_change": 0.018250588015835234},
{"total_number_of_episodes": 37500, "number_of_timesteps": 13320982, "per_episode_reward": 16.91, "episode_reward_trend_value": -0.0005895573529583389, "biggest_recent_change": 0.018250588015835234},
{"total_number_of_episodes": 37511, "number_of_timesteps": 13324018, "per_episode_reward": 16.93, "episode_reward_trend_value": -0.00036462066126416757, "biggest_recent_change": 0.02500592452746986},
{"total_number_of_episodes": 37521, "number_of_timesteps": 13328918, "per_episode_reward": 16.95, "episode_reward_trend_value": -9.423650382574226e-05, "biggest_recent_change": 0.02500592452746986},
{"total_number_of_episodes": 37531, "number_of_timesteps": 13334362, "per_episode_reward": 16.93, "episode_reward_trend_value": -8.43911668072492e-05, "biggest_recent_change": 0.02500592452746986},
{"total_number_of_episodes": 37541, "number_of_timesteps": 13339791, "per_episode_reward": 16.95, "episode_reward_trend_value": 0.0002682740718466982, "biggest_recent_change": 0.02500592452746986},
{"total_number_of_episodes": 37551, "number_of_timesteps": 13343469, "per_episode_reward": 16.98, "episode_reward_trend_value": 0.0007652319055283542, "biggest_recent_change": 0.033834122910430864},
{"total_number_of_episodes": 37561, "number_of_timesteps": 13345713, "per_episode_reward": 16.96, "episode_reward_trend_value": 0.0006677586617967851, "biggest_recent_change": 0.033834122910430864},
{"total_number_of_episodes": 37571, "number_of_timesteps": 13349966, "per_episode_reward": 16.98, "episode_reward_trend_value": 0.0007983192359173726, "biggest_recent_change": 0.033834122910430864},
{"total_number_of_episodes": 37581, "number_of_timesteps": 13353342, "per_episode_reward": 16.97, "episode_reward_trend_value": 0.0007038347267502509, "biggest_recent_change": 0.033834122910430864},
{"total_number_of_episodes": 37591, "number_of_timesteps": 13357539, "per_episode_reward": 16.96, "episode_reward_trend_value": 0.0006095624879948265, "biggest_recent_change": 0.033834122910430864},
{"total_number_of_episodes": 37601, "number_of_timesteps": 13361065, "per_episode_reward": 16.99, "episode_reward_trend_value": 0.0006027957229406411, "biggest_recent_change": 0.033834122910430864},
{"total_number_of_episodes": 37611, "number_of_timesteps": 13366144, "per_episode_reward": 16.98, "episode_reward_trend_value": 0.00037533670460672874, "biggest_recent_change": 0.033834122910430864},
{"total_number_of_episodes": 37622, "number_of_timesteps": 13371076, "per_episode_reward": 16.99, "episode_reward_trend_value": 0.0007420850251562744, "biggest_recent_change": 0.033834122910430864},
{"total_number_of_episodes": 37632, "number_of_timesteps": 13374910, "per_episode_reward": 17.03, "episode_reward_trend_value": 0.0009399981664152395, "biggest_recent_change": 0.03776403398439143},
{"total_number_of_episodes": 37642, "number_of_timesteps": 13379342, "per_episode_reward": 17.03, "episode_reward_trend_value": 0.0004953168169159422, "biggest_recent_change": 0.03776403398439143},
{"total_number_of_episodes": 37652, "number_of_timesteps": 13383711, "per_episode_reward": 17.04, "episode_reward_trend_value": 0.0008969748966483357, "biggest_recent_change": 0.03776403398439143},
{"total_number_of_episodes": 37662, "number_of_timesteps": 13389702, "per_episode_reward": 17.05, "episode_reward_trend_value": 0.000808669022879924, "biggest_recent_change": 0.03776403398439143},
{"total_number_of_episodes": 37672, "number_of_timesteps": 13393518, "per_episode_reward": 17.03, "episode_reward_trend_value": 0.0005861561129823735, "biggest_recent_change": 0.03776403398439143},
{"total_number_of_episodes": 37682, "number_of_timesteps": 13396482, "per_episode_reward": 17.02, "episode_reward_trend_value": 0.0005999441061054335, "biggest_recent_change": 0.03776403398439143},
{"total_number_of_episodes": 37692, "number_of_timesteps": 13399223, "per_episode_reward": 17.03, "episode_reward_trend_value": 0.0004750912402716128, "biggest_recent_change": 0.03776403398439143},
{"total_number_of_episodes": 37702, "number_of_timesteps": 13403657, "per_episode_reward": 17.05, "episode_reward_trend_value": 0.0007731104335905157, "biggest_recent_change": 0.03776403398439143},
{"total_number_of_episodes": 37712, "number_of_timesteps": 13406364, "per_episode_reward": 17.04, "episode_reward_trend_value": 0.0005025738560801487, "biggest_recent_change": 0.03776403398439143},
{"total_number_of_episodes": 37722, "number_of_timesteps": 13410018, "per_episode_reward": 17.05, "episode_reward_trend_value": 0.00018966545676756634, "biggest_recent_change": 0.024249546465267002},
{"total_number_of_episodes": 37732, "number_of_timesteps": 13412747, "per_episode_reward": 17.05, "episode_reward_trend_value": 0.00028440556994190227, "biggest_recent_change": 0.024249546465267002},
{"total_number_of_episodes": 37742, "number_of_timesteps": 13415160, "per_episode_reward": 17.05, "episode_reward_trend_value": 7.877710462223951e-05, "biggest_recent_change": 0.024249546465267002},
{"total_number_of_episodes": 37753, "number_of_timesteps": 13419968, "per_episode_reward": 17.05, "episode_reward_trend_value": 1.6805776772186062e-05, "biggest_recent_change": 0.024249546465267002},
{"total_number_of_episodes": 37763, "number_of_timesteps": 13423436, "per_episode_reward": 17.06, "episode_reward_trend_value": 0.000368867402647963, "biggest_recent_change": 0.0180287515869324},
{"total_number_of_episodes": 37773, "number_of_timesteps": 13426253, "per_episode_reward": 17.05, "episode_reward_trend_value": 0.0004002031804784028, "biggest_recent_change": 0.0180287515869324},
{"total_number_of_episodes": 37783, "number_of_timesteps": 13429121, "per_episode_reward": 17.07, "episode_reward_trend_value": 0.00041579203278306273, "biggest_recent_change": 0.0180287515869324},
{"total_number_of_episodes": 37793, "number_of_timesteps": 13431854, "per_episode_reward": 17.07, "episode_reward_trend_value": 0.00020444286409878977, "biggest_recent_change": 0.014563154454968696},
{"total_number_of_episodes": 37803, "number_of_timesteps": 13434067, "per_episode_reward": 17.08, "episode_reward_trend_value": 0.00040828108970285054, "biggest_recent_change": 0.014563154454968696},
{"total_number_of_episodes": 37813, "number_of_timesteps": 13436578, "per_episode_reward": 17.09, "episode_reward_trend_value": 0.0004931306717006281, "biggest_recent_change": 0.017238740426058996},
{"total_number_of_episodes": 37823, "number_of_timesteps": 13439764, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0005485492912910672, "biggest_recent_change": 0.017238740426058996},
{"total_number_of_episodes": 37834, "number_of_timesteps": 13443462, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0005210133762168489, "biggest_recent_change": 0.017238740426058996},
{"total_number_of_episodes": 37844, "number_of_timesteps": 13445418, "per_episode_reward": 17.13, "episode_reward_trend_value": 0.000807568342062205, "biggest_recent_change": 0.028166635575942678},
{"total_number_of_episodes": 37854, "number_of_timesteps": 13448784, "per_episode_reward": 17.12, "episode_reward_trend_value": 0.0006811995846224445, "biggest_recent_change": 0.028166635575942678},
{"total_number_of_episodes": 37864, "number_of_timesteps": 13451537, "per_episode_reward": 17.13, "episode_reward_trend_value": 0.000857216590742935, "biggest_recent_change": 0.028166635575942678},
{"total_number_of_episodes": 37874, "number_of_timesteps": 13454433, "per_episode_reward": 17.15, "episode_reward_trend_value": 0.00091252200265212, "biggest_recent_change": 0.028166635575942678},
{"total_number_of_episodes": 37885, "number_of_timesteps": 13456919, "per_episode_reward": 17.13, "episode_reward_trend_value": 0.0007019804405474635, "biggest_recent_change": 0.028166635575942678},
{"total_number_of_episodes": 37895, "number_of_timesteps": 13458241, "per_episode_reward": 17.14, "episode_reward_trend_value": 0.0007003958011989732, "biggest_recent_change": 0.028166635575942678},
{"total_number_of_episodes": 37905, "number_of_timesteps": 13460181, "per_episode_reward": 17.16, "episode_reward_trend_value": 0.0006954655836794012, "biggest_recent_change": 0.028166635575942678},
{"total_number_of_episodes": 37915, "number_of_timesteps": 13462708, "per_episode_reward": 17.15, "episode_reward_trend_value": 0.0005148238804251785, "biggest_recent_change": 0.028166635575942678},
{"total_number_of_episodes": 37926, "number_of_timesteps": 13465292, "per_episode_reward": 17.15, "episode_reward_trend_value": 0.0006308135492037792, "biggest_recent_change": 0.028166635575942678},
{"total_number_of_episodes": 37936, "number_of_timesteps": 13468560, "per_episode_reward": 17.16, "episode_reward_trend_value": 0.0003781194781152032, "biggest_recent_change": 0.01994141418407125},
{"total_number_of_episodes": 37946, "number_of_timesteps": 13472122, "per_episode_reward": 17.18, "episode_reward_trend_value": 0.0006677056714932424, "biggest_recent_change": 0.02212556909799801},
{"total_number_of_episodes": 37956, "number_of_timesteps": 13474548, "per_episode_reward": 17.18, "episode_reward_trend_value": 0.0005633694004954195, "biggest_recent_change": 0.02212556909799801},
{"total_number_of_episodes": 37966, "number_of_timesteps": 13477889, "per_episode_reward": 17.19, "episode_reward_trend_value": 0.0004586631714036097, "biggest_recent_change": 0.02212556909799801},
{"total_number_of_episodes": 37976, "number_of_timesteps": 13480619, "per_episode_reward": 17.21, "episode_reward_trend_value": 0.000923145933127382, "biggest_recent_change": 0.02212556909799801},
{"total_number_of_episodes": 37986, "number_of_timesteps": 13482843, "per_episode_reward": 17.21, "episode_reward_trend_value": 0.0007454907824423805, "biggest_recent_change": 0.02212556909799801},
{"total_number_of_episodes": 37996, "number_of_timesteps": 13485932, "per_episode_reward": 17.21, "episode_reward_trend_value": 0.0005677321686512471, "biggest_recent_change": 0.02212556909799801},
{"total_number_of_episodes": 38006, "number_of_timesteps": 13490933, "per_episode_reward": 17.21, "episode_reward_trend_value": 0.000685682672323572, "biggest_recent_change": 0.02212556909799801},
{"total_number_of_episodes": 38016, "number_of_timesteps": 13494925, "per_episode_reward": 17.23, "episode_reward_trend_value": 0.0008285254255017015, "biggest_recent_change": 0.02212556909799801},
{"total_number_of_episodes": 38026, "number_of_timesteps": 13498689, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.001057263545663329, "biggest_recent_change": 0.026010599992517314},
{"total_number_of_episodes": 38036, "number_of_timesteps": 13503593, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.0007623962354263053, "biggest_recent_change": 0.026010599992517314},
{"total_number_of_episodes": 38046, "number_of_timesteps": 13507438, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.0008175031215219045, "biggest_recent_change": 0.026010599992517314},
{"total_number_of_episodes": 38057, "number_of_timesteps": 13512055, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.0006633241520501166, "biggest_recent_change": 0.026010599992517314},
{"total_number_of_episodes": 38067, "number_of_timesteps": 13515640, "per_episode_reward": 17.26, "episode_reward_trend_value": 0.0004827117664190676, "biggest_recent_change": 0.026010599992517314},
{"total_number_of_episodes": 38077, "number_of_timesteps": 13518320, "per_episode_reward": 17.27, "episode_reward_trend_value": 0.0007082093754729691, "biggest_recent_change": 0.026010599992517314},
{"total_number_of_episodes": 38087, "number_of_timesteps": 13523722, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.00046304665650305466, "biggest_recent_change": 0.026010599992517314},
{"total_number_of_episodes": 38097, "number_of_timesteps": 13527491, "per_episode_reward": 17.26, "episode_reward_trend_value": 0.0005159931841153783, "biggest_recent_change": 0.026010599992517314},
{"total_number_of_episodes": 38107, "number_of_timesteps": 13531279, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.00021116526389243338, "biggest_recent_change": 0.026010599992517314},
{"total_number_of_episodes": 38118, "number_of_timesteps": 13535489, "per_episode_reward": 17.25, "episode_reward_trend_value": -3.4815974794513397e-07, "biggest_recent_change": 0.021267899099196796},
{"total_number_of_episodes": 38128, "number_of_timesteps": 13538834, "per_episode_reward": 17.25, "episode_reward_trend_value": -8.303138051996623e-06, "biggest_recent_change": 0.021267899099196796},
{"total_number_of_episodes": 38138, "number_of_timesteps": 13542610, "per_episode_reward": 17.26, "episode_reward_trend_value": 8.985469888749265e-05, "biggest_recent_change": 0.021267899099196796},
{"total_number_of_episodes": 38148, "number_of_timesteps": 13545448, "per_episode_reward": 17.29, "episode_reward_trend_value": 0.00039649588702405465, "biggest_recent_change": 0.023838680588362138},
{"total_number_of_episodes": 38158, "number_of_timesteps": 13548660, "per_episode_reward": 17.29, "episode_reward_trend_value": 0.0004249032454269515, "biggest_recent_change": 0.023838680588362138},
{"total_number_of_episodes": 38168, "number_of_timesteps": 13552140, "per_episode_reward": 17.31, "episode_reward_trend_value": 0.00043649386075625467, "biggest_recent_change": 0.023838680588362138},

{"total_number_of_episodes": 38178, "number_of_timesteps": 13555835, "per_episode_reward": 17.31, "episode_reward_trend_value": 0.0006894698997702243, "biggest_recent_change": 0.023838680588362138},
{"total_number_of_episodes": 38188, "number_of_timesteps": 13559217, "per_episode_reward": 17.33, "episode_reward_trend_value": 0.0007919339860075623, "biggest_recent_change": 0.023838680588362138},
{"total_number_of_episodes": 38198, "number_of_timesteps": 13562400, "per_episode_reward": 17.33, "episode_reward_trend_value": 0.0009017421380235647, "biggest_recent_change": 0.023838680588362138},
{"total_number_of_episodes": 38208, "number_of_timesteps": 13565964, "per_episode_reward": 17.32, "episode_reward_trend_value": 0.0007349033390678273, "biggest_recent_change": 0.023838680588362138},

{"total_number_of_episodes": 38218, "number_of_timesteps": 13568006, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0006106044544666862, "biggest_recent_change": 0.023838680588362138},
{"total_number_of_episodes": 38228, "number_of_timesteps": 13569786, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.00040276913158119817, "biggest_recent_change": 0.023838680588362138},
{"total_number_of_episodes": 38238, "number_of_timesteps": 13573921, "per_episode_reward": 17.31, "episode_reward_trend_value": 0.0002782904095921326, "biggest_recent_change": 0.016315336484801435},
{"total_number_of_episodes": 38248, "number_of_timesteps": 13578143, "per_episode_reward": 17.31, "episode_reward_trend_value": 0.0001346525878901556, "biggest_recent_change": 0.016315336484801435},
{"total_number_of_episodes": 38258, "number_of_timesteps": 13580513, "per_episode_reward": 17.31, "episode_reward_trend_value": 1.115306549475608e-05, "biggest_recent_change": 0.016315336484801435},
{"total_number_of_episodes": 38268, "number_of_timesteps": 13582534, "per_episode_reward": 17.32, "episode_reward_trend_value": 0.00015146067729128435, "biggest_recent_change": 0.016315336484801435},

{"total_number_of_episodes": 38278, "number_of_timesteps": 13585106, "per_episode_reward": 17.32, "episode_reward_trend_value": -8.919691961438837e-05, "biggest_recent_change": 0.016315336484801435},
{"total_number_of_episodes": 38288, "number_of_timesteps": 13589043, "per_episode_reward": 17.33, "episode_reward_trend_value": -1.2549302715056697e-05, "biggest_recent_change": 0.016315336484801435},
{"total_number_of_episodes": 38298, "number_of_timesteps": 13591526, "per_episode_reward": 17.34, "episode_reward_trend_value": 0.00017648563069702698, "biggest_recent_change": 0.016315336484801435},
{"total_number_of_episodes": 38308, "number_of_timesteps": 13596094, "per_episode_reward": 17.33, "episode_reward_trend_value": 0.00025227557766247026, "biggest_recent_change": 0.014127629473748016},
{"total_number_of_episodes": 38318, "number_of_timesteps": 13599814, "per_episode_reward": 17.32, "episode_reward_trend_value": 0.00017761555565386623, "biggest_recent_change": 0.014127629473748016},
{"total_number_of_episodes": 38329, "number_of_timesteps": 13602665, "per_episode_reward": 17.33, "episode_reward_trend_value": 0.00017356868775533958, "biggest_recent_change": 0.014127629473748016},
{"total_number_of_episodes": 38339, "number_of_timesteps": 13605196, "per_episode_reward": 17.32, "episode_reward_trend_value": 0.00015974307725063536, "biggest_recent_change": 0.014127629473748016},
{"total_number_of_episodes": 38349, "number_of_timesteps": 13608561, "per_episode_reward": 17.33, "episode_reward_trend_value": 0.00021677000696425827, "biggest_recent_change": 0.014127629473748016},
{"total_number_of_episodes": 38359, "number_of_timesteps": 13612911, "per_episode_reward": 17.31, "episode_reward_trend_value": -0.00015786636358786017, "biggest_recent_change": 0.01958964387594264},
{"total_number_of_episodes": 38369, "number_of_timesteps": 13616216, "per_episode_reward": 17.31, "episode_reward_trend_value": -8.746359012867799e-05, "biggest_recent_change": 0.01958964387594264},
{"total_number_of_episodes": 38379, "number_of_timesteps": 13619001, "per_episode_reward": 17.32, "episode_reward_trend_value": -8.156081919467164e-05, "biggest_recent_change": 0.01958964387594264},
{"total_number_of_episodes": 38390, "number_of_timesteps": 13621473, "per_episode_reward": 17.31, "episode_reward_trend_value": -0.0002705463924540494, "biggest_recent_change": 0.01958964387594264},
{"total_number_of_episodes": 38400, "number_of_timesteps": 13623183, "per_episode_reward": 17.3, "episode_reward_trend_value": -0.00028937624831518367, "biggest_recent_change": 0.01958964387594264},
{"total_number_of_episodes": 38410, "number_of_timesteps": 13624710, "per_episode_reward": 17.31, "episode_reward_trend_value": -9.344208468462512e-05, "biggest_recent_change": 0.01958964387594264},
{"total_number_of_episodes": 38420, "number_of_timesteps": 13626999, "per_episode_reward": 17.29, "episode_reward_trend_value": -0.00036447905325454305, "biggest_recent_change": 0.01958964387594264},
{"total_number_of_episodes": 38430, "number_of_timesteps": 13630592, "per_episode_reward": 17.29, "episode_reward_trend_value": -0.00039237729462639795, "biggest_recent_change": 0.01958964387594264},
{"total_number_of_episodes": 38440, "number_of_timesteps": 13633420, "per_episode_reward": 17.29, "episode_reward_trend_value": -0.0004338308173995781, "biggest_recent_change": 0.01958964387594264},
{"total_number_of_episodes": 38450, "number_of_timesteps": 13635998, "per_episode_reward": 17.3, "episode_reward_trend_value": -0.00014582934669300743, "biggest_recent_change": 0.01212194967281377},
{"total_number_of_episodes": 38460, "number_of_timesteps": 13639862, "per_episode_reward": 17.31, "episode_reward_trend_value": -3.563229243432886e-05, "biggest_recent_change": 0.01212194967281377},
{"total_number_of_episodes": 38470, "number_of_timesteps": 13645036, "per_episode_reward": 17.32, "episode_reward_trend_value": -5.409358805081865e-05, "biggest_recent_change": 0.01212194967281377},
{"total_number_of_episodes": 38480, "number_of_timesteps": 13647333, "per_episode_reward": 17.33, "episode_reward_trend_value": 0.00016069543207824683, "biggest_recent_change": 0.01212194967281377},
{"total_number_of_episodes": 38490, "number_of_timesteps": 13652034, "per_episode_reward": 17.34, "episode_reward_trend_value": 0.00039449376292850503, "biggest_recent_change": 0.01212194967281377},
{"total_number_of_episodes": 38500, "number_of_timesteps": 13654669, "per_episode_reward": 17.34, "episode_reward_trend_value": 0.00034397225192799556, "biggest_recent_change": 0.01212194967281377},
{"total_number_of_episodes": 38510, "number_of_timesteps": 13658088, "per_episode_reward": 17.34, "episode_reward_trend_value": 0.0005402893300829782, "biggest_recent_change": 0.011294354184226307},
{"total_number_of_episodes": 38520, "number_of_timesteps": 13663844, "per_episode_reward": 17.35, "episode_reward_trend_value": 0.0007058364154330279, "biggest_recent_change": 0.011294354184226307},
{"total_number_of_episodes": 38530, "number_of_timesteps": 13667151, "per_episode_reward": 17.35, "episode_reward_trend_value": 0.0006587169993760177, "biggest_recent_change": 0.011294354184226307},
{"total_number_of_episodes": 38540, "number_of_timesteps": 13671060, "per_episode_reward": 17.35, "episode_reward_trend_value": 0.0006307259572344669, "biggest_recent_change": 0.011294354184226307},
{"total_number_of_episodes": 38550, "number_of_timesteps": 13674305, "per_episode_reward": 17.36, "episode_reward_trend_value": 0.0006343310944294621, "biggest_recent_change": 0.011294354184226307},
{"total_number_of_episodes": 38560, "number_of_timesteps": 13678015, "per_episode_reward": 17.36, "episode_reward_trend_value": 0.0005403119597872319, "biggest_recent_change": 0.011294354184226307},
{"total_number_of_episodes": 38570, "number_of_timesteps": 13680274, "per_episode_reward": 17.36, "episode_reward_trend_value": 0.0003454223245086041, "biggest_recent_change": 0.010591097809069083},
{"total_number_of_episodes": 38581, "number_of_timesteps": 13683702, "per_episode_reward": 17.36, "episode_reward_trend_value": 0.00027380836522515514, "biggest_recent_change": 0.010591097809069083},
{"total_number_of_episodes": 38591, "number_of_timesteps": 13686986, "per_episode_reward": 17.38, "episode_reward_trend_value": 0.0004201089035780352, "biggest_recent_change": 0.013886555253598942},
{"total_number_of_episodes": 38601, "number_of_timesteps": 13689046, "per_episode_reward": 17.37, "episode_reward_trend_value": 0.00028478015852897445, "biggest_recent_change": 0.013886555253598942},
{"total_number_of_episodes": 38611, "number_of_timesteps": 13692149, "per_episode_reward": 17.37, "episode_reward_trend_value": 0.00021398161936660008, "biggest_recent_change": 0.013886555253598942},
{"total_number_of_episodes": 38622, "number_of_timesteps": 13696558, "per_episode_reward": 17.36, "episode_reward_trend_value": 9.259931975790102e-05, "biggest_recent_change": 0.013886555253598942},
{"total_number_of_episodes": 38632, "number_of_timesteps": 13701615, "per_episode_reward": 17.38, "episode_reward_trend_value": 0.0002401750978950506, "biggest_recent_change": 0.017093114727252612},
{"total_number_of_episodes": 38642, "number_of_timesteps": 13704442, "per_episode_reward": 17.36, "episode_reward_trend_value": -6.563487462535199e-05, "biggest_recent_change": 0.017093114727252612},
{"total_number_of_episodes": 38652, "number_of_timesteps": 13708360, "per_episode_reward": 17.37, "episode_reward_trend_value": 8.962170951735496e-05, "biggest_recent_change": 0.017093114727252612},
{"total_number_of_episodes": 38662, "number_of_timesteps": 13711889, "per_episode_reward": 17.38, "episode_reward_trend_value": 0.00021001343272225703, "biggest_recent_change": 0.017093114727252612},
{"total_number_of_episodes": 38673, "number_of_timesteps": 13715549, "per_episode_reward": 17.37, "episode_reward_trend_value": 0.00012509939922702686, "biggest_recent_change": 0.017093114727252612},
{"total_number_of_episodes": 38683, "number_of_timesteps": 13718996, "per_episode_reward": 17.35, "episode_reward_trend_value": -0.0002741957752617294, "biggest_recent_change": 0.022050010450389124},
{"total_number_of_episodes": 38693, "number_of_timesteps": 13722288, "per_episode_reward": 17.35, "episode_reward_trend_value": -0.00020543655803674849, "biggest_recent_change": 0.022050010450389124},
{"total_number_of_episodes": 38703, "number_of_timesteps": 13726330, "per_episode_reward": 17.36, "episode_reward_trend_value": -7.32680033312505e-05, "biggest_recent_change": 0.022050010450389124},
{"total_number_of_episodes": 38713, "number_of_timesteps": 13728475, "per_episode_reward": 17.38, "episode_reward_trend_value": 0.00024042785766908992, "biggest_recent_change": 0.022050010450389124},
{"total_number_of_episodes": 38723, "number_of_timesteps": 13733693, "per_episode_reward": 17.39, "episode_reward_trend_value": 0.00019196855427239257, "biggest_recent_change": 0.022050010450389124},
{"total_number_of_episodes": 38733, "number_of_timesteps": 13738127, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0004800897262970949, "biggest_recent_change": 0.022050010450389124},
{"total_number_of_episodes": 38743, "number_of_timesteps": 13740836, "per_episode_reward": 17.39, "episode_reward_trend_value": 0.00023478974840421708, "biggest_recent_change": 0.022050010450389124},
{"total_number_of_episodes": 38753, "number_of_timesteps": 13743366, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.00023921955534065534, "biggest_recent_change": 0.022050010450389124},
{"total_number_of_episodes": 38763, "number_of_timesteps": 13745857, "per_episode_reward": 17.39, "episode_reward_trend_value": 0.00022827100796780382, "biggest_recent_change": 0.022050010450389124},
{"total_number_of_episodes": 38773, "number_of_timesteps": 13749883, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0005844854049365485, "biggest_recent_change": 0.018200471274365526},
{"total_number_of_episodes": 38783, "number_of_timesteps": 13753642, "per_episode_reward": 17.41, "episode_reward_trend_value": 0.0006599322379019255, "biggest_recent_change": 0.018200471274365526},
{"total_number_of_episodes": 38793, "number_of_timesteps": 13755918, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.00039705472413883075, "biggest_recent_change": 0.018200471274365526},
{"total_number_of_episodes": 38803, "number_of_timesteps": 13759328, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.00018407691650408094, "biggest_recent_change": 0.01273177742154985},
{"total_number_of_episodes": 38814, "number_of_timesteps": 13762802, "per_episode_reward": 17.41, "episode_reward_trend_value": 0.00013247005630386216, "biggest_recent_change": 0.011755405859826595},
{"total_number_of_episodes": 38824, "number_of_timesteps": 13767605, "per_episode_reward": 17.41, "episode_reward_trend_value": 6.229045719656768e-05, "biggest_recent_change": 0.011755405859826595},
{"total_number_of_episodes": 38835, "number_of_timesteps": 13771148, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.00010211084031810617, "biggest_recent_change": 0.011755405859826595},
{"total_number_of_episodes": 38845, "number_of_timesteps": 13773684, "per_episode_reward": 17.4, "episode_reward_trend_value": 2.2731317345482517e-05, "biggest_recent_change": 0.011755405859826595},
{"total_number_of_episodes": 38855, "number_of_timesteps": 13776130, "per_episode_reward": 17.42, "episode_reward_trend_value": 0.00028681165155334376, "biggest_recent_change": 0.018547262956179367},
{"total_number_of_episodes": 38866, "number_of_timesteps": 13780287, "per_episode_reward": 17.42, "episode_reward_trend_value": 0.0002203817819055271, "biggest_recent_change": 0.018547262956179367},
{"total_number_of_episodes": 38876, "number_of_timesteps": 13782984, "per_episode_reward": 17.44, "episode_reward_trend_value": 0.00028628534938511687, "biggest_recent_change": 0.018547262956179367},
{"total_number_of_episodes": 38886, "number_of_timesteps": 13785620, "per_episode_reward": 17.41, "episode_reward_trend_value": 8.156248385837728e-05, "biggest_recent_change": 0.030180463757233156},
{"total_number_of_episodes": 38896, "number_of_timesteps": 13787686, "per_episode_reward": 17.4, "episode_reward_trend_value": 8.441564957987819e-05, "biggest_recent_change": 0.030180463757233156},
{"total_number_of_episodes": 38906, "number_of_timesteps": 13790140, "per_episode_reward": 17.4, "episode_reward_trend_value": -6.531089143951224e-05, "biggest_recent_change": 0.030180463757233156},
{"total_number_of_episodes": 38916, "number_of_timesteps": 13793834, "per_episode_reward": 17.4, "episode_reward_trend_value": -4.448096161707345e-05, "biggest_recent_change": 0.030180463757233156},
{"total_number_of_episodes": 38927, "number_of_timesteps": 13795872, "per_episode_reward": 17.41, "episode_reward_trend_value": 0.00011493310218355646, "biggest_recent_change": 0.030180463757233156},
{"total_number_of_episodes": 38937, "number_of_timesteps": 13798376, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.0003126870764744025, "biggest_recent_change": 0.030180463757233156},
{"total_number_of_episodes": 38947, "number_of_timesteps": 13801921, "per_episode_reward": 17.44, "episode_reward_trend_value": 0.00017709483546314667, "biggest_recent_change": 0.030180463757233156},
{"total_number_of_episodes": 38957, "number_of_timesteps": 13806077, "per_episode_reward": 17.44, "episode_reward_trend_value": 0.00018594417726281638, "biggest_recent_change": 0.030180463757233156},
{"total_number_of_episodes": 38967, "number_of_timesteps": 13810923, "per_episode_reward": 17.42, "episode_reward_trend_value": -0.00011896189856111209, "biggest_recent_change": 0.030180463757233156},
{"total_number_of_episodes": 38977, "number_of_timesteps": 13815213, "per_episode_reward": 17.41, "episode_reward_trend_value": 9.187002590257029e-05, "biggest_recent_change": 0.015641925340510454},
{"total_number_of_episodes": 38987, "number_of_timesteps": 13818212, "per_episode_reward": 17.41, "episode_reward_trend_value": 5.412739542166713e-05, "biggest_recent_change": 0.015641925340510454},
{"total_number_of_episodes": 38998, "number_of_timesteps": 13822354, "per_episode_reward": 17.42, "episode_reward_trend_value": 0.00017747503226937214, "biggest_recent_change": 0.015641925340510454},
{"total_number_of_episodes": 39009, "number_of_timesteps": 13826097, "per_episode_reward": 17.41, "episode_reward_trend_value": 4.006676872923738e-05, "biggest_recent_change": 0.015641925340510454},
{"total_number_of_episodes": 39019, "number_of_timesteps": 13829265, "per_episode_reward": 17.42, "episode_reward_trend_value": 5.301641587259888e-05, "biggest_recent_change": 0.015641925340510454},
{"total_number_of_episodes": 39031, "number_of_timesteps": 13832106, "per_episode_reward": 17.41, "episode_reward_trend_value": -0.00016823972150206145, "biggest_recent_change": 0.015164680927139074},
{"total_number_of_episodes": 39041, "number_of_timesteps": 13834880, "per_episode_reward": 17.39, "episode_reward_trend_value": -0.0005155489585074946, "biggest_recent_change": 0.02491387006532264},
{"total_number_of_episodes": 39051, "number_of_timesteps": 13836865, "per_episode_reward": 17.39, "episode_reward_trend_value": -0.0005876156588633879, "biggest_recent_change": 0.02491387006532264},
{"total_number_of_episodes": 39061, "number_of_timesteps": 13842058, "per_episode_reward": 17.37, "episode_reward_trend_value": -0.0006158354435725421, "biggest_recent_change": 0.02491387006532264},
{"total_number_of_episodes": 39071, "number_of_timesteps": 13844988, "per_episode_reward": 17.39, "episode_reward_trend_value": -0.0002527070142423248, "biggest_recent_change": 0.02491387006532264},
{"total_number_of_episodes": 39081, "number_of_timesteps": 13847826, "per_episode_reward": 17.37, "episode_reward_trend_value": -0.00046193776861002, "biggest_recent_change": 0.02491387006532264},
{"total_number_of_episodes": 39091, "number_of_timesteps": 13852842, "per_episode_reward": 17.37, "episode_reward_trend_value": -0.000544174256352608, "biggest_recent_change": 0.02491387006532264},
{"total_number_of_episodes": 39101, "number_of_timesteps": 13860791, "per_episode_reward": 17.38, "episode_reward_trend_value": -0.00030274107135607804, "biggest_recent_change": 0.02491387006532264},
{"total_number_of_episodes": 39111, "number_of_timesteps": 13868244, "per_episode_reward": 17.39, "episode_reward_trend_value": -0.0002577116251253465, "biggest_recent_change": 0.02491387006532264},
{"total_number_of_episodes": 39121, "number_of_timesteps": 13874473, "per_episode_reward": 17.42, "episode_reward_trend_value": 6.411289003093796e-05, "biggest_recent_change": 0.02491387006532264},
{"total_number_of_episodes": 39132, "number_of_timesteps": 13878184, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.00043611926409181163, "biggest_recent_change": 0.024693079340856627},
{"total_number_of_episodes": 39142, "number_of_timesteps": 13880902, "per_episode_reward": 17.42, "episode_reward_trend_value": 0.00033930846431364295, "biggest_recent_change": 0.024693079340856627},
{"total_number_of_episodes": 39152, "number_of_timesteps": 13884742, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.000294150972564348, "biggest_recent_change": 0.024693079340856627},
{"total_number_of_episodes": 39162, "number_of_timesteps": 13887759, "per_episode_reward": 17.4, "episode_reward_trend_value": 8.391663162438729e-05, "biggest_recent_change": 0.024693079340856627},
{"total_number_of_episodes": 39172, "number_of_timesteps": 13890260, "per_episode_reward": 17.39, "episode_reward_trend_value": 0.00025366025120704524, "biggest_recent_change": 0.024693079340856627},
{"total_number_of_episodes": 39182, "number_of_timesteps": 13892817, "per_episode_reward": 17.39, "episode_reward_trend_value": 0.0002967300653871913, "biggest_recent_change": 0.024693079340856627},
{"total_number_of_episodes": 39192, "number_of_timesteps": 13895883, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0002584574246800031, "biggest_recent_change": 0.024693079340856627},
{"total_number_of_episodes": 39202, "number_of_timesteps": 13898335, "per_episode_reward": 17.43, "episode_reward_trend_value": 0.0004447666520352161, "biggest_recent_change": 0.03135293796059102},
{"total_number_of_episodes": 39212, "number_of_timesteps": 13899914, "per_episode_reward": 17.41, "episode_reward_trend_value": -9.753701990125782e-05, "biggest_recent_change": 0.03135293796059102},
{"total_number_of_episodes": 39222, "number_of_timesteps": 13901662, "per_episode_reward": 17.42, "episode_reward_trend_value": -7.586188410609256e-05, "biggest_recent_change": 0.03135293796059102},
{"total_number_of_episodes": 39232, "number_of_timesteps": 13904007, "per_episode_reward": 17.42, "episode_reward_trend_value": 3.732306376029726e-05, "biggest_recent_change": 0.03135293796059102},
{"total_number_of_episodes": 39242, "number_of_timesteps": 13908859, "per_episode_reward": 17.42, "episode_reward_trend_value": 0.00030309495147157076, "biggest_recent_change": 0.03135293796059102},
{"total_number_of_episodes": 39252, "number_of_timesteps": 13914815, "per_episode_reward": 17.44, "episode_reward_trend_value": 0.00041971715730239925, "biggest_recent_change": 0.03135293796059102},
{"total_number_of_episodes": 39262, "number_of_timesteps": 13919170, "per_episode_reward": 17.45, "episode_reward_trend_value": 0.0007070179349984724, "biggest_recent_change": 0.03135293796059102},
{"total_number_of_episodes": 39272, "number_of_timesteps": 13921893, "per_episode_reward": 17.48, "episode_reward_trend_value": 0.0009343497016328368, "biggest_recent_change": 0.03135293796059102},
{"total_number_of_episodes": 39282, "number_of_timesteps": 13925295, "per_episode_reward": 17.48, "episode_reward_trend_value": 0.0008661206210759312, "biggest_recent_change": 0.03135293796059102},
{"total_number_of_episodes": 39292, "number_of_timesteps": 13928017, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0007284468961089314, "biggest_recent_change": 0.024114251133426023},
{"total_number_of_episodes": 39303, "number_of_timesteps": 13933097, "per_episode_reward": 17.51, "episode_reward_trend_value": 0.0011340713238263491, "biggest_recent_change": 0.022647917004551488},
{"total_number_of_episodes": 39313, "number_of_timesteps": 13936965, "per_episode_reward": 17.53, "episode_reward_trend_value": 0.001168259878793205, "biggest_recent_change": 0.022647917004551488},
{"total_number_of_episodes": 39323, "number_of_timesteps": 13940168, "per_episode_reward": 17.54, "episode_reward_trend_value": 0.0012817412010036043, "biggest_recent_change": 0.022647917004551488},
{"total_number_of_episodes": 39333, "number_of_timesteps": 13943927, "per_episode_reward": 17.55, "episode_reward_trend_value": 0.0014535444761344016, "biggest_recent_change": 0.022647917004551488},
{"total_number_of_episodes": 39343, "number_of_timesteps": 13946865, "per_episode_reward": 17.57, "episode_reward_trend_value": 0.0014492021862270437, "biggest_recent_change": 0.022647917004551488},
{"total_number_of_episodes": 39353, "number_of_timesteps": 13949534, "per_episode_reward": 17.57, "episode_reward_trend_value": 0.001263009395694207, "biggest_recent_change": 0.022647917004551488},
{"total_number_of_episodes": 39363, "number_of_timesteps": 13956322, "per_episode_reward": 17.58, "episode_reward_trend_value": 0.001095252744878018, "biggest_recent_change": 0.01896230271356103},
{"total_number_of_episodes": 39373, "number_of_timesteps": 13961449, "per_episode_reward": 17.59, "episode_reward_trend_value": 0.0012480293499353065, "biggest_recent_change": 0.01896230271356103},
{"total_number_of_episodes": 39383, "number_of_timesteps": 13967075, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0011521083246481428, "biggest_recent_change": 0.018084618001282138},
{"total_number_of_episodes": 39393, "number_of_timesteps": 13970967, "per_episode_reward": 17.59, "episode_reward_trend_value": 0.0008756045956192319, "biggest_recent_change": 0.018084618001282138},
{"total_number_of_episodes": 39403, "number_of_timesteps": 13973929, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0008086561437915505, "biggest_recent_change": 0.018084618001282138},
{"total_number_of_episodes": 39413, "number_of_timesteps": 13980893, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0006725736092102055, "biggest_recent_change": 0.018084618001282138},
{"total_number_of_episodes": 39423, "number_of_timesteps": 13984320, "per_episode_reward": 17.61, "episode_reward_trend_value": 0.0006652915400693299, "biggest_recent_change": 0.018084618001282138},
{"total_number_of_episodes": 39433, "number_of_timesteps": 13989389, "per_episode_reward": 17.61, "episode_reward_trend_value": 0.0005290741907874658, "biggest_recent_change": 0.018084618001282138},
{"total_number_of_episodes": 39443, "number_of_timesteps": 13993004, "per_episode_reward": 17.62, "episode_reward_trend_value": 0.0005552137607021261, "biggest_recent_change": 0.018084618001282138},
{"total_number_of_episodes": 39453, "number_of_timesteps": 13997252, "per_episode_reward": 17.63, "episode_reward_trend_value": 0.0006382315142562649, "biggest_recent_change": 0.018084618001282138},
{"total_number_of_episodes": 39463, "number_of_timesteps": 14000969, "per_episode_reward": 17.65, "episode_reward_trend_value": 0.0006052758968189822, "biggest_recent_change": 0.01695774262470806},
{"total_number_of_episodes": 39474, "number_of_timesteps": 14004315, "per_episode_reward": 17.65, "episode_reward_trend_value": 0.000493112746984339, "biggest_recent_change": 0.01695774262470806},
{"total_number_of_episodes": 39484, "number_of_timesteps": 14009649, "per_episode_reward": 17.66, "episode_reward_trend_value": 0.0007792378105471126, "biggest_recent_change": 0.01695774262470806},
{"total_number_of_episodes": 39494, "number_of_timesteps": 14014678, "per_episode_reward": 17.67, "episode_reward_trend_value": 0.0007334511249689275, "biggest_recent_change": 0.01695774262470806},
{"total_number_of_episodes": 39504, "number_of_timesteps": 14018783, "per_episode_reward": 17.68, "episode_reward_trend_value": 0.0008814522627930267, "biggest_recent_change": 0.01695774262470806},
{"total_number_of_episodes": 39514, "number_of_timesteps": 14021488, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0009898452471835148, "biggest_recent_change": 0.02671311121985198},
{"total_number_of_episodes": 39524, "number_of_timesteps": 14025122, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0009809245065926495, "biggest_recent_change": 0.02671311121985198},
{"total_number_of_episodes": 39534, "number_of_timesteps": 14027736, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.0010157564901960982, "biggest_recent_change": 0.02671311121985198},
{"total_number_of_episodes": 39545, "number_of_timesteps": 14030626, "per_episode_reward": 17.72, "episode_reward_trend_value": 0.0009844157404576967, "biggest_recent_change": 0.02671311121985198},
{"total_number_of_episodes": 39555, "number_of_timesteps": 14034264, "per_episode_reward": 17.73, "episode_reward_trend_value": 0.0009291795322425066, "biggest_recent_change": 0.02671311121985198},
{"total_number_of_episodes": 39566, "number_of_timesteps": 14036283, "per_episode_reward": 17.74, "episode_reward_trend_value": 0.001023279216418279, "biggest_recent_change": 0.02671311121985198},
{"total_number_of_episodes": 39576, "number_of_timesteps": 14039718, "per_episode_reward": 17.75, "episode_reward_trend_value": 0.0009978862902496784, "biggest_recent_change": 0.02671311121985198},
{"total_number_of_episodes": 39586, "number_of_timesteps": 14043175, "per_episode_reward": 17.79, "episode_reward_trend_value": 0.0013377030599344883, "biggest_recent_change": 0.03403178267384277},
{"total_number_of_episodes": 39597, "number_of_timesteps": 14046758, "per_episode_reward": 17.79, "episode_reward_trend_value": 0.0012492980121830755, "biggest_recent_change": 0.03403178267384277},
{"total_number_of_episodes": 39609, "number_of_timesteps": 14052584, "per_episode_reward": 17.83, "episode_reward_trend_value": 0.0014143615712220658, "biggest_recent_change": 0.041568831533361106},
{"total_number_of_episodes": 39619, "number_of_timesteps": 14057291, "per_episode_reward": 17.84, "episode_reward_trend_value": 0.0015474842927845364, "biggest_recent_change": 0.041568831533361106},
{"total_number_of_episodes": 39630, "number_of_timesteps": 14060440, "per_episode_reward": 17.87, "episode_reward_trend_value": 0.001783829566248269, "biggest_recent_change": 0.041568831533361106},
{"total_number_of_episodes": 39641, "number_of_timesteps": 14064001, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.00203429030622707, "biggest_recent_change": 0.041568831533361106},
{"total_number_of_episodes": 39651, "number_of_timesteps": 14068460, "per_episode_reward": 17.91, "episode_reward_trend_value": 0.001929026693871489, "biggest_recent_change": 0.041568831533361106},
{"total_number_of_episodes": 39662, "number_of_timesteps": 14071769, "per_episode_reward": 17.91, "episode_reward_trend_value": 0.0018492644043234126, "biggest_recent_change": 0.041568831533361106},
{"total_number_of_episodes": 39673, "number_of_timesteps": 14074564, "per_episode_reward": 17.89, "episode_reward_trend_value": 0.0015810148065412873, "biggest_recent_change": 0.041568831533361106},
{"total_number_of_episodes": 39683, "number_of_timesteps": 14077538, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0013064292288159861, "biggest_recent_change": 0.041568831533361106},
{"total_number_of_episodes": 39693, "number_of_timesteps": 14080610, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.001256797483690322, "biggest_recent_change": 0.041568831533361106},
{"total_number_of_episodes": 39703, "number_of_timesteps": 14083471, "per_episode_reward": 17.91, "episode_reward_trend_value": 0.0008703272490082428, "biggest_recent_change": 0.034742215372602914},
{"total_number_of_episodes": 39713, "number_of_timesteps": 14087640, "per_episode_reward": 17.93, "episode_reward_trend_value": 0.0009970954459112768, "biggest_recent_change": 0.034742215372602914},
{"total_number_of_episodes": 39723, "number_of_timesteps": 14091145, "per_episode_reward": 17.92, "episode_reward_trend_value": 0.0005658525929553725, "biggest_recent_change": 0.034742215372602914},
{"total_number_of_episodes": 39733, "number_of_timesteps": 14094776, "per_episode_reward": 17.93, "episode_reward_trend_value": 0.00028598073715693475, "biggest_recent_change": 0.02298782440608349},
{"total_number_of_episodes": 39743, "number_of_timesteps": 14096601, "per_episode_reward": 17.94, "episode_reward_trend_value": 0.00039088520478887607, "biggest_recent_change": 0.02298782440608349},
{"total_number_of_episodes": 39753, "number_of_timesteps": 14098596, "per_episode_reward": 17.95, "episode_reward_trend_value": 0.00046308131466605104, "biggest_recent_change": 0.02298782440608349},
{"total_number_of_episodes": 39763, "number_of_timesteps": 14100999, "per_episode_reward": 17.96, "episode_reward_trend_value": 0.0007120204084577451, "biggest_recent_change": 0.02298782440608349},
{"total_number_of_episodes": 39774, "number_of_timesteps": 14102839, "per_episode_reward": 17.98, "episode_reward_trend_value": 0.0008125402630116222, "biggest_recent_change": 0.02298782440608349},
{"total_number_of_episodes": 39784, "number_of_timesteps": 14105303, "per_episode_reward": 17.98, "episode_reward_trend_value": 0.0008771374376366955, "biggest_recent_change": 0.02298782440608349},
{"total_number_of_episodes": 39794, "number_of_timesteps": 14107294, "per_episode_reward": 17.99, "episode_reward_trend_value": 0.0008597399643021852, "biggest_recent_change": 0.02298782440608349},
{"total_number_of_episodes": 39805, "number_of_timesteps": 14109994, "per_episode_reward": 17.99, "episode_reward_trend_value": 0.0006778659488458928, "biggest_recent_change": 0.01836586758841463},
{"total_number_of_episodes": 39815, "number_of_timesteps": 14112722, "per_episode_reward": 17.99, "episode_reward_trend_value": 0.0007700183492813453, "biggest_recent_change": 0.01836586758841463},
{"total_number_of_episodes": 39826, "number_of_timesteps": 14115569, "per_episode_reward": 17.99, "episode_reward_trend_value": 0.0006313791808732026, "biggest_recent_change": 0.01836586758841463},
{"total_number_of_episodes": 39836, "number_of_timesteps": 14117468, "per_episode_reward": 17.97, "episode_reward_trend_value": 0.0003619009647656984, "biggest_recent_change": 0.01836586758841463},
{"total_number_of_episodes": 39847, "number_of_timesteps": 14119466, "per_episode_reward": 17.98, "episode_reward_trend_value": 0.0003681383351963379, "biggest_recent_change": 0.01836586758841463},
{"total_number_of_episodes": 39857, "number_of_timesteps": 14121188, "per_episode_reward": 17.99, "episode_reward_trend_value": 0.0003849345851126568, "biggest_recent_change": 0.01836586758841463},
{"total_number_of_episodes": 39867, "number_of_timesteps": 14123821, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.0002913796649426025, "biggest_recent_change": 0.014138008782243361},
{"total_number_of_episodes": 39877, "number_of_timesteps": 14126772, "per_episode_reward": 18.03, "episode_reward_trend_value": 0.000545676238949729, "biggest_recent_change": 0.027377827375119068},
{"total_number_of_episodes": 39888, "number_of_timesteps": 14130254, "per_episode_reward": 18.02, "episode_reward_trend_value": 0.00040792266741884005, "biggest_recent_change": 0.027377827375119068},
{"total_number_of_episodes": 39898, "number_of_timesteps": 14132032, "per_episode_reward": 18.01, "episode_reward_trend_value": 0.0002379261681267132, "biggest_recent_change": 0.027377827375119068},
{"total_number_of_episodes": 39908, "number_of_timesteps": 14134228, "per_episode_reward": 18.01, "episode_reward_trend_value": 0.0001982039997794042, "biggest_recent_change": 0.027377827375119068},
{"total_number_of_episodes": 39918, "number_of_timesteps": 14135811, "per_episode_reward": 18.01, "episode_reward_trend_value": 0.0002865699525921331, "biggest_recent_change": 0.027377827375119068},
{"total_number_of_episodes": 39928, "number_of_timesteps": 14138216, "per_episode_reward": 18.01, "episode_reward_trend_value": 0.00042027172934015294, "biggest_recent_change": 0.027377827375119068},
{"total_number_of_episodes": 39938, "number_of_timesteps": 14140241, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.00020256378366695238, "biggest_recent_change": 0.027377827375119068},
{"total_number_of_episodes": 39948, "number_of_timesteps": 14143162, "per_episode_reward": 18.01, "episode_reward_trend_value": 0.00014289995301418736, "biggest_recent_change": 0.027377827375119068},
{"total_number_of_episodes": 39958, "number_of_timesteps": 14145107, "per_episode_reward": 18.01, "episode_reward_trend_value": 0.00010854955232851972, "biggest_recent_change": 0.027377827375119068},
{"total_number_of_episodes": 39968, "number_of_timesteps": 14148512, "per_episode_reward": 18.03, "episode_reward_trend_value": -3.771497463311846e-05, "biggest_recent_change": 0.014214019948571632},
{"total_number_of_episodes": 39978, "number_of_timesteps": 14151307, "per_episode_reward": 18.03, "episode_reward_trend_value": 0.00012587973138652824, "biggest_recent_change": 0.014214019948571632},
{"total_number_of_episodes": 39988, "number_of_timesteps": 14156629, "per_episode_reward": 18.05, "episode_reward_trend_value": 0.0004051664087483352, "biggest_recent_change": 0.016455279041288406},
{"total_number_of_episodes": 39998, "number_of_timesteps": 14162260, "per_episode_reward": 18.06, "episode_reward_trend_value": 0.0005722542911646163, "biggest_recent_change": 0.016455279041288406},
exited at all_updated_barrier.wait(): 5, error = 
None
exited at all_updated_barrier.wait(): 0, error = 
None
exited at all_updated_barrier.wait(): 6, error = 
None
exited at all_updated_barrier.wait(): 9, error = 
None
exited at all_updated_barrier.wait(): 8, error = 
None
exited at all_updated_barrier.wait(): 1, error = 
None
exited at all_updated_barrier.wait(): 7, error = 
None
exited at all_updated_barrier.wait(): 4, error = 
None
exited at all_updated_barrier.wait(): 3, error = 
None
[done calling async_.run_async()]
{"number_of_steps": 125000, "number_of_episodes": null, "mean": 148.37469631768516, "median": 208.5740279644834, "stdev": 131.7278087199217, "final_eval": true}
[starting train_a3c()]
[starting train_agent_async()]
[about to call async_.run_async()]
[starting run_func()]
[starting train_loop()]
{ "step": 0, "visits": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 0, "q_vals": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 1, "visits": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 0, "q_vals": [-7.901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 2, "visits": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 0, "q_vals": [-7.901, -7.901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 3, "visits": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 0, "q_vals": [-7.901, -7.901, -7.901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 4, "visits": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 0, "q_vals": [-7.901, -7.901, -7.901, -7.901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 5, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 0, "q_vals": [-7.901, -7.901, -7.901, -7.901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 6, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 0, "q_vals": [-7.901, -7.901, -7.901, -7.901, 0.0, -7.901, 0.0, 0.0, 0.0, 0.0] }
{ "step": 7, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0] , "episode_count": 3, "q_vals": [-7.901, -7.901, -7.901, -7.901, 0.0, -7.901, -7.901, 0.0, 0.0, 0.0] }
{ "step": 8, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0] , "episode_count": 4, "q_vals": [-7.901, -7.901, -7.901, -7.901, 0.0, -7.901, -7.901, -7.901, 0.0, 0.0] }
{ "step": 9, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0] , "episode_count": 6, "q_vals": [-7.901, -7.901, -7.901, -7.901, 0.0, -7.901, -7.901, -7.901, -7.901, 0.0] }
{ "step": 10, "visits": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 7, "q_vals": [-7.901, -7.901, -7.901, -7.901, 0.0, -7.901, -7.901, -7.901, -7.901, -19.753] }
{ "step": 11, "visits": [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 9, "q_vals": [-7.901, -7.901, -7.901, -7.901, -3.951, -7.901, -7.901, -7.901, -7.901, -19.753] }
{ "step": 12, "visits": [1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 9, "q_vals": [-7.901, -7.901, -7.901, -7.901, -5.267, -7.901, -7.901, -7.901, -7.901, -19.753] }
{ "step": 13, "visits": [1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 9, "q_vals": [-7.901, -7.901, -7.901, -7.901, -8.889, -7.901, -7.901, -7.901, -7.901, -19.753] }
{ "step": 14, "visits": [1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 9, "q_vals": [-7.901, -7.901, -7.901, -7.901, -8.889, -7.901, -7.901, -7.901, -7.901, -19.753] }
{ "step": 15, "visits": [1.0, 2.0, 1.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 9, "q_vals": [-7.901, -7.901, -7.901, -7.901, -8.889, -7.901, -7.901, -7.901, -7.901, -19.753] }
{ "step": 16, "visits": [1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 11, "q_vals": [-7.901, -7.901, -7.901, -7.901, -8.889, -13.827, -7.901, -7.901, -7.901, -19.753] }
{ "step": 17, "visits": [1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0] , "episode_count": 12, "q_vals": [-7.901, -7.901, -7.901, -7.901, -8.889, -13.827, -7.901, -7.901, -7.901, -19.753] }
{ "step": 18, "visits": [1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0] , "episode_count": 15, "q_vals": [-7.901, -7.901, -7.901, -7.901, -8.889, -13.827, -7.901, -7.901, -7.901, -19.753] }
{ "step": 19, "visits": [1.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0] , "episode_count": 17, "q_vals": [-7.901, -7.901, -7.901, -7.901, -8.889, -13.827, -7.901, -7.901, -7.901, -19.753] }
{ "step": 20, "visits": [2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0] , "episode_count": 18, "q_vals": [-7.901, -7.901, -7.901, -7.901, -8.889, -13.827, -7.901, -7.901, -7.901, -19.753] }
{ "step": 21, "visits": [2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0] , "episode_count": 18, "q_vals": [-7.901, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -7.901, -7.901, -19.753] }
{ "step": 22, "visits": [2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0] , "episode_count": 18, "q_vals": [-7.901, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -7.901, -7.901, -19.753] }
{ "step": 23, "visits": [2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 3.0, 1.0] , "episode_count": 18, "q_vals": [-7.901, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -7.901, -11.852, -19.753] }
{ "step": 24, "visits": [2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 1.0] , "episode_count": 18, "q_vals": [-7.901, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -5.267, -11.852, -19.753] }
{ "step": 25, "visits": [2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 4.0, 3.0, 1.0] , "episode_count": 20, "q_vals": [-7.901, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -5.334, -11.852, -19.753] }
{ "step": 26, "visits": [2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 5.0, 3.0, 1.0] , "episode_count": 21, "q_vals": [-7.901, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -4.267, -11.852, -19.753] }
{ "step": 27, "visits": [2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 6.0, 3.0, 1.0] , "episode_count": 21, "q_vals": [-7.901, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -4.873, -11.852, -19.753] }
{ "step": 28, "visits": [2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 7.0, 3.0, 1.0] , "episode_count": 23, "q_vals": [-7.901, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -5.306, -11.852, -19.753] }
{ "step": 29, "visits": [2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 8.0, 3.0, 1.0] , "episode_count": 24, "q_vals": [-7.901, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -5.63, -11.852, -19.753] }
{ "step": 30, "visits": [2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 9.0, 3.0, 1.0] , "episode_count": 25, "q_vals": [-7.901, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -5.514, -11.852, -19.753] }
{ "step": 31, "visits": [2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 10.0, 3.0, 1.0] , "episode_count": 28, "q_vals": [-7.901, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -5.753, -11.852, -19.753] }
{ "step": 32, "visits": [2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 11.0, 3.0, 1.0] , "episode_count": 28, "q_vals": [-7.901, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -7.026, -11.852, -19.753] }
{ "step": 33, "visits": [2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 12.0, 3.0, 1.0] , "episode_count": 29, "q_vals": [-7.901, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -8.086, -11.852, -19.753] }
{ "step": 34, "visits": [2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 12.0, 3.0, 1.0] , "episode_count": 30, "q_vals": [-7.901, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -8.086, -11.852, -19.753] }
{"total_number_of_episodes": 32, "number_of_timesteps": 3026, "per_episode_reward": -179.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{ "step": 35, "visits": [3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 12.0, 3.0, 1.0] , "episode_count": 32, "q_vals": [-11.852, -7.901, -7.901, -10.903, -8.889, -13.827, -7.901, -8.086, -11.852, -19.753] }
{ "step": 36, "visits": [3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 3.0, 12.0, 3.0, 1.0] , "episode_count": 32, "q_vals": [-11.852, -7.901, -11.852, -10.903, -8.889, -13.827, -7.901, -8.086, -11.852, -19.753] }
{ "step": 37, "visits": [3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 4.0, 12.0, 3.0, 1.0] , "episode_count": 32, "q_vals": [-11.852, -7.901, -11.852, -10.903, -8.889, -13.827, -7.901, -8.086, -11.852, -19.753] }
{ "step": 38, "visits": [3.0, 4.0, 3.0, 2.0, 4.0, 2.0, 4.0, 12.0, 3.0, 1.0] , "episode_count": 33, "q_vals": [-11.852, -7.901, -11.852, -10.903, -8.889, -13.827, -7.901, -8.086, -11.852, -19.753] }
{ "step": 39, "visits": [3.0, 4.0, 3.0, 2.0, 4.0, 2.0, 5.0, 12.0, 3.0, 1.0] , "episode_count": 34, "q_vals": [-11.852, -7.901, -11.852, -10.903, -8.889, -13.827, -10.272, -8.086, -11.852, -19.753] }
{ "step": 40, "visits": [3.0, 5.0, 3.0, 2.0, 4.0, 2.0, 5.0, 12.0, 3.0, 1.0] , "episode_count": 36, "q_vals": [-11.852, -7.901, -11.852, -10.903, -8.889, -13.827, -10.272, -8.086, -11.852, -19.753] }
{ "step": 41, "visits": [3.0, 6.0, 3.0, 2.0, 4.0, 2.0, 5.0, 12.0, 3.0, 1.0] , "episode_count": 37, "q_vals": [-11.852, -7.901, -11.852, -10.903, -8.889, -13.827, -10.272, -8.086, -11.852, -19.753] }
{ "step": 42, "visits": [3.0, 7.0, 3.0, 2.0, 4.0, 2.0, 5.0, 12.0, 3.0, 1.0] , "episode_count": 39, "q_vals": [-11.852, -7.901, -11.852, -10.903, -8.889, -13.827, -10.272, -8.086, -11.852, -19.753] }
{ "step": 43, "visits": [3.0, 8.0, 3.0, 2.0, 4.0, 2.0, 5.0, 12.0, 3.0, 1.0] , "episode_count": 39, "q_vals": [-11.852, -9.383, -11.852, -10.903, -8.889, -13.827, -10.272, -8.086, -11.852, -19.753] }
{ "step": 44, "visits": [3.0, 8.0, 3.0, 2.0, 4.0, 2.0, 5.0, 13.0, 3.0, 1.0] , "episode_count": 40, "q_vals": [-11.852, -9.383, -11.852, -10.903, -8.889, -13.827, -10.272, -7.464, -11.852, -19.753] }
{ "step": 45, "visits": [3.0, 8.0, 3.0, 2.0, 4.0, 2.0, 5.0, 14.0, 3.0, 1.0] , "episode_count": 41, "q_vals": [-11.852, -9.383, -11.852, -10.903, -8.889, -13.827, -10.272, -8.342, -11.852, -19.753] }
{"total_number_of_episodes": 43, "number_of_timesteps": 4057, "per_episode_reward": -178.01, "episode_reward_trend_value": 0.11307154395123291, "biggest_recent_change": NaN},
{ "step": 46, "visits": [3.0, 8.0, 3.0, 2.0, 4.0, 2.0, 5.0, 15.0, 3.0, 1.0] , "episode_count": 43, "q_vals": [-11.852, -9.383, -11.852, -10.903, -8.889, -13.827, -10.272, -8.313, -11.852, -19.753] }
{ "step": 47, "visits": [3.0, 8.0, 3.0, 2.0, 4.0, 2.0, 5.0, 16.0, 3.0, 1.0] , "episode_count": 43, "q_vals": [-11.852, -9.383, -11.852, -10.903, -8.889, -13.827, -10.272, -9.028, -11.852, -19.753] }
{ "step": 48, "visits": [3.0, 8.0, 3.0, 2.0, 5.0, 2.0, 5.0, 16.0, 3.0, 1.0] , "episode_count": 43, "q_vals": [-11.852, -9.383, -11.852, -10.903, -11.062, -13.827, -10.272, -9.028, -11.852, -19.753] }
{ "step": 49, "visits": [3.0, 8.0, 3.0, 2.0, 5.0, 2.0, 5.0, 17.0, 3.0, 1.0] , "episode_count": 44, "q_vals": [-11.852, -9.383, -11.852, -10.903, -11.062, -13.827, -10.272, -8.731, -11.852, -19.753] }
{ "step": 50, "visits": [3.0, 8.0, 3.0, 2.0, 5.0, 2.0, 5.0, 18.0, 3.0, 1.0] , "episode_count": 44, "q_vals": [-11.852, -9.383, -11.852, -10.903, -11.062, -13.827, -10.272, -8.246, -11.852, -19.753] }
{ "step": 51, "visits": [3.0, 8.0, 3.0, 2.0, 5.0, 2.0, 5.0, 19.0, 3.0, 1.0] , "episode_count": 47, "q_vals": [-11.852, -9.383, -11.852, -10.903, -11.062, -13.827, -10.272, -8.228, -11.852, -19.753] }
{ "step": 52, "visits": [3.0, 8.0, 3.0, 2.0, 5.0, 2.0, 5.0, 20.0, 3.0, 1.0] , "episode_count": 48, "q_vals": [-11.852, -9.383, -11.852, -10.903, -11.062, -13.827, -10.272, -8.804, -11.852, -19.753] }
{ "step": 53, "visits": [3.0, 8.0, 3.0, 2.0, 5.0, 2.0, 5.0, 21.0, 3.0, 1.0] , "episode_count": 51, "q_vals": [-11.852, -9.383, -11.852, -10.903, -11.062, -13.827, -10.272, -8.761, -11.852, -19.753] }
{ "step": 54, "visits": [3.0, 8.0, 3.0, 2.0, 5.0, 2.0, 5.0, 22.0, 3.0, 1.0] , "episode_count": 51, "q_vals": [-11.852, -9.383, -11.852, -10.903, -11.062, -13.827, -10.272, -8.558, -11.852, -19.753] }
{ "step": 55, "visits": [3.0, 8.0, 3.0, 2.0, 5.0, 2.0, 5.0, 23.0, 3.0, 1.0] , "episode_count": 51, "q_vals": [-11.852, -9.383, -11.852, -10.903, -11.062, -13.827, -10.272, -9.045, -11.852, -19.753] }
{ "step": 56, "visits": [3.0, 8.0, 3.0, 2.0, 5.0, 2.0, 5.0, 24.0, 3.0, 1.0] , "episode_count": 51, "q_vals": [-11.852, -9.383, -11.852, -10.903, -11.062, -13.827, -10.272, -8.668, -11.852, -19.753] }
{ "step": 57, "visits": [3.0, 8.0, 3.0, 2.0, 5.0, 2.0, 5.0, 25.0, 3.0, 1.0] , "episode_count": 51, "q_vals": [-11.852, -9.383, -11.852, -10.903, -11.062, -13.827, -10.272, -8.637, -11.852, -19.753] }
{"total_number_of_episodes": 54, "number_of_timesteps": 5119, "per_episode_reward": -172.48, "episode_reward_trend_value": 0.3329792551075698, "biggest_recent_change": NaN},
{ "step": 58, "visits": [3.0, 8.0, 3.0, 2.0, 5.0, 2.0, 5.0, 26.0, 3.0, 1.0] , "episode_count": 54, "q_vals": [-11.852, -9.383, -11.852, -10.903, -11.062, -13.827, -10.272, -8.305, -11.852, -19.753] }
{ "step": 59, "visits": [3.0, 8.0, 3.0, 2.0, 5.0, 2.0, 5.0, 27.0, 3.0, 1.0] , "episode_count": 54, "q_vals": [-11.852, -9.383, -11.852, -10.903, -11.062, -13.827, -10.272, -8.729, -11.852, -19.753] }
{ "step": 60, "visits": [3.0, 8.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 54, "q_vals": [-11.852, -9.383, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 61, "visits": [3.0, 9.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 55, "q_vals": [-11.852, -9.218, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 62, "visits": [3.0, 10.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 58, "q_vals": [-11.852, -9.086, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 63, "visits": [3.0, 11.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 59, "q_vals": [-11.852, -8.979, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 64, "visits": [3.0, 12.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 59, "q_vals": [-11.852, -8.889, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 65, "visits": [3.0, 13.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 59, "q_vals": [-11.852, -8.205, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 66, "visits": [3.0, 14.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 61, "q_vals": [-11.852, -8.183, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 67, "visits": [3.0, 15.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 61, "q_vals": [-11.852, -8.955, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 68, "visits": [3.0, 16.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 61, "q_vals": [-11.852, -8.889, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 69, "visits": [3.0, 17.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 62, "q_vals": [-11.852, -8.831, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 70, "visits": [3.0, 18.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 63, "q_vals": [-11.852, -8.779, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{"total_number_of_episodes": 65, "number_of_timesteps": 6327, "per_episode_reward": -176.86, "episode_reward_trend_value": 0.07594631477435977, "biggest_recent_change": NaN},
{ "step": 71, "visits": [3.0, 19.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 65, "q_vals": [-11.852, -8.733, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 72, "visits": [3.0, 20.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 66, "q_vals": [-11.852, -8.691, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 73, "visits": [3.0, 21.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 69, "q_vals": [-11.852, -8.654, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 74, "visits": [3.0, 22.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 69, "q_vals": [-11.852, -9.062, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 75, "visits": [3.0, 23.0, 3.0, 2.0, 5.0, 2.0, 5.0, 28.0, 3.0, 1.0] , "episode_count": 70, "q_vals": [-11.852, -9.527, -11.852, -10.903, -11.062, -13.827, -10.272, -9.123, -11.852, -19.753] }
{ "step": 76, "visits": [3.0, 23.0, 3.0, 2.0, 5.0, 2.0, 5.0, 29.0, 3.0, 1.0] , "episode_count": 70, "q_vals": [-11.852, -9.527, -11.852, -10.903, -11.062, -13.827, -10.272, -9.373, -11.852, -19.753] }
{ "step": 77, "visits": [3.0, 23.0, 3.0, 2.0, 5.0, 2.0, 5.0, 30.0, 3.0, 1.0] , "episode_count": 70, "q_vals": [-11.852, -9.527, -11.852, -10.903, -11.062, -13.827, -10.272, -9.324, -11.852, -19.753] }
{ "step": 78, "visits": [3.0, 23.0, 3.0, 2.0, 5.0, 2.0, 5.0, 31.0, 3.0, 1.0] , "episode_count": 72, "q_vals": [-11.852, -9.527, -11.852, -10.903, -11.062, -13.827, -10.272, -9.278, -11.852, -19.753] }
{ "step": 79, "visits": [3.0, 23.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 72, "q_vals": [-11.852, -9.527, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{ "step": 80, "visits": [3.0, 24.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 74, "q_vals": [-11.852, -9.459, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{"total_number_of_episodes": 75, "number_of_timesteps": 7295, "per_episode_reward": -195.51, "episode_reward_trend_value": -0.4093014907028028, "biggest_recent_change": NaN},
{ "step": 81, "visits": [3.0, 25.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 75, "q_vals": [-11.852, -9.397, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{ "step": 82, "visits": [3.0, 26.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 76, "q_vals": [-11.852, -9.339, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{ "step": 83, "visits": [3.0, 27.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 77, "q_vals": [-11.852, -9.286, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{ "step": 84, "visits": [3.0, 28.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 78, "q_vals": [-11.852, -9.236, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{ "step": 85, "visits": [3.0, 29.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 78, "q_vals": [-11.852, -9.599, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{ "step": 86, "visits": [3.0, 30.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 78, "q_vals": [-11.852, -9.279, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{ "step": 87, "visits": [3.0, 31.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 80, "q_vals": [-11.852, -9.235, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{ "step": 88, "visits": [3.0, 32.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 80, "q_vals": [-11.852, -9.177, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{ "step": 89, "visits": [3.0, 33.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 81, "q_vals": [-11.852, -9.138, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{ "step": 90, "visits": [3.0, 34.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 82, "q_vals": [-11.852, -9.102, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{ "step": 91, "visits": [3.0, 35.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 83, "q_vals": [-11.852, -9.067, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{ "step": 92, "visits": [3.0, 36.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 83, "q_vals": [-11.852, -9.364, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{"total_number_of_episodes": 86, "number_of_timesteps": 8477, "per_episode_reward": -193.5, "episode_reward_trend_value": -0.28716716335665127, "biggest_recent_change": NaN},
{ "step": 93, "visits": [3.0, 37.0, 3.0, 2.0, 5.0, 2.0, 5.0, 32.0, 3.0, 1.0] , "episode_count": 86, "q_vals": [-11.852, -9.645, -11.852, -10.903, -11.062, -13.827, -10.272, -9.605, -11.852, -19.753] }
{ "step": 94, "visits": [3.0, 37.0, 3.0, 2.0, 5.0, 2.0, 5.0, 33.0, 3.0, 1.0] , "episode_count": 87, "q_vals": [-11.852, -9.645, -11.852, -10.903, -11.062, -13.827, -10.272, -9.553, -11.852, -19.753] }
{ "step": 95, "visits": [3.0, 37.0, 3.0, 2.0, 5.0, 2.0, 5.0, 34.0, 3.0, 1.0] , "episode_count": 87, "q_vals": [-11.852, -9.645, -11.852, -10.903, -11.062, -13.827, -10.272, -9.853, -11.852, -19.753] }
{ "step": 96, "visits": [3.0, 38.0, 3.0, 2.0, 5.0, 2.0, 5.0, 34.0, 3.0, 1.0] , "episode_count": 89, "q_vals": [-11.852, -9.391, -11.852, -10.903, -11.062, -13.827, -10.272, -9.853, -11.852, -19.753] }
{ "step": 97, "visits": [3.0, 39.0, 3.0, 2.0, 5.0, 2.0, 5.0, 34.0, 3.0, 1.0] , "episode_count": 89, "q_vals": [-11.852, -9.657, -11.852, -10.903, -11.062, -13.827, -10.272, -9.853, -11.852, -19.753] }
{ "step": 98, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 5.0, 34.0, 3.0, 1.0] , "episode_count": 89, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -10.272, -9.853, -11.852, -19.753] }
{ "step": 99, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 6.0, 34.0, 3.0, 1.0] , "episode_count": 89, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.56, -9.853, -11.852, -19.753] }
{ "step": 100, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 7.0, 34.0, 3.0, 1.0] , "episode_count": 92, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.466, -9.853, -11.852, -19.753] }
{ "step": 101, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 8.0, 34.0, 3.0, 1.0] , "episode_count": 93, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.395, -9.853, -11.852, -19.753] }
{ "step": 102, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 9.0, 34.0, 3.0, 1.0] , "episode_count": 94, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.34, -9.853, -11.852, -19.753] }
{ "step": 103, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 10.0, 34.0, 3.0, 1.0] , "episode_count": 95, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -7.506, -9.853, -11.852, -19.753] }
{ "step": 104, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 11.0, 34.0, 3.0, 1.0] , "episode_count": 95, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -7.542, -9.853, -11.852, -19.753] }
{"total_number_of_episodes": 96, "number_of_timesteps": 9479, "per_episode_reward": -199.53, "episode_reward_trend_value": -0.33981005449861407, "biggest_recent_change": NaN},
{ "step": 105, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 12.0, 34.0, 3.0, 1.0] , "episode_count": 96, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -7.572, -9.853, -11.852, -19.753] }
{ "step": 106, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 13.0, 34.0, 3.0, 1.0] , "episode_count": 97, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.509, -9.853, -11.852, -19.753] }
{ "step": 107, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 14.0, 34.0, 3.0, 1.0] , "episode_count": 98, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.466, -9.853, -11.852, -19.753] }
{ "step": 108, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 15.0, 34.0, 3.0, 1.0] , "episode_count": 99, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.218, -9.853, -11.852, -19.753] }
{ "step": 109, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 16.0, 34.0, 3.0, 1.0] , "episode_count": 99, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.136, -9.853, -11.852, -19.753] }
{ "step": 110, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 17.0, 34.0, 3.0, 1.0] , "episode_count": 101, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.76, -9.853, -11.852, -19.753] }
{ "step": 111, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 18.0, 34.0, 3.0, 1.0] , "episode_count": 104, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.308, -9.853, -11.852, -19.753] }
{ "step": 112, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 19.0, 34.0, 3.0, 1.0] , "episode_count": 104, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.173, -9.853, -11.852, -19.753] }
{ "step": 113, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 20.0, 34.0, 3.0, 1.0] , "episode_count": 104, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.11, -9.853, -11.852, -19.753] }
{ "step": 114, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 21.0, 34.0, 3.0, 1.0] , "episode_count": 105, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.052, -9.853, -11.852, -19.753] }
{ "step": 115, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 22.0, 34.0, 3.0, 1.0] , "episode_count": 105, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.641, -9.853, -11.852, -19.753] }
{"total_number_of_episodes": 107, "number_of_timesteps": 10570, "per_episode_reward": -190.62, "episode_reward_trend_value": -0.16402897783299902, "biggest_recent_change": NaN},
{ "step": 116, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 23.0, 34.0, 3.0, 1.0] , "episode_count": 107, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.609, -9.853, -11.852, -19.753] }
{ "step": 117, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 24.0, 34.0, 3.0, 1.0] , "episode_count": 107, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.579, -9.853, -11.852, -19.753] }
{ "step": 118, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 25.0, 34.0, 3.0, 1.0] , "episode_count": 110, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.292, -9.853, -11.852, -19.753] }
{ "step": 119, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 26.0, 34.0, 3.0, 1.0] , "episode_count": 112, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.733, -9.853, -11.852, -19.753] }
{ "step": 120, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 27.0, 34.0, 3.0, 1.0] , "episode_count": 113, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.481, -9.853, -11.852, -19.753] }
{ "step": 121, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 28.0, 34.0, 3.0, 1.0] , "episode_count": 115, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.461, -9.853, -11.852, -19.753] }
{ "step": 122, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 29.0, 34.0, 3.0, 1.0] , "episode_count": 115, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.441, -9.853, -11.852, -19.753] }
{ "step": 123, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 30.0, 34.0, 3.0, 1.0] , "episode_count": 116, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -8.818, -9.853, -11.852, -19.753] }
{ "step": 124, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 31.0, 34.0, 3.0, 1.0] , "episode_count": 116, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.171, -9.853, -11.852, -19.753] }
{"total_number_of_episodes": 118, "number_of_timesteps": 11547, "per_episode_reward": -186.26, "episode_reward_trend_value": -0.08904952027251767, "biggest_recent_change": NaN},
{ "step": 125, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 32.0, 34.0, 3.0, 1.0] , "episode_count": 118, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.502, -9.853, -11.852, -19.753] }
{ "step": 126, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 33.0, 34.0, 3.0, 1.0] , "episode_count": 118, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.453, -9.853, -11.852, -19.753] }
{ "step": 127, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 34.0, 34.0, 3.0, 1.0] , "episode_count": 118, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.408, -9.853, -11.852, -19.753] }
{ "step": 128, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 35.0, 34.0, 3.0, 1.0] , "episode_count": 120, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.643, -9.853, -11.852, -19.753] }
{ "step": 129, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 36.0, 34.0, 3.0, 1.0] , "episode_count": 124, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.595, -9.853, -11.852, -19.753] }
{ "step": 130, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 37.0, 34.0, 3.0, 1.0] , "episode_count": 125, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.549, -9.853, -11.852, -19.753] }
{ "step": 131, "visits": [3.0, 40.0, 3.0, 2.0, 5.0, 2.0, 38.0, 34.0, 3.0, 1.0] , "episode_count": 126, "q_vals": [-11.852, -9.909, -11.852, -10.903, -11.062, -13.827, -9.817, -9.853, -11.852, -19.753] }
{ "step": 132, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 38.0, 34.0, 3.0, 1.0] , "episode_count": 126, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.817, -9.853, -11.852, -19.753] }
{"total_number_of_episodes": 128, "number_of_timesteps": 12404, "per_episode_reward": -186.58, "episode_reward_trend_value": -0.08272378870079378, "biggest_recent_change": 18.650449071342905},
{ "step": 133, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 39.0, 34.0, 3.0, 1.0] , "episode_count": 128, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.566, -9.853, -11.852, -19.753] }
{ "step": 134, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 40.0, 34.0, 3.0, 1.0] , "episode_count": 128, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.485, -9.853, -11.852, -19.753] }
{ "step": 135, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 41.0, 34.0, 3.0, 1.0] , "episode_count": 128, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.447, -9.853, -11.852, -19.753] }
{ "step": 136, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 42.0, 34.0, 3.0, 1.0] , "episode_count": 129, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.335, -9.853, -11.852, -19.753] }
{ "step": 137, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 43.0, 34.0, 3.0, 1.0] , "episode_count": 131, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.302, -9.853, -11.852, -19.753] }
{ "step": 138, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 44.0, 34.0, 3.0, 1.0] , "episode_count": 132, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.27, -9.853, -11.852, -19.753] }
{ "step": 139, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 45.0, 34.0, 3.0, 1.0] , "episode_count": 132, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.24, -9.853, -11.852, -19.753] }
{ "step": 140, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 46.0, 34.0, 3.0, 1.0] , "episode_count": 133, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.468, -9.853, -11.852, -19.753] }
{ "step": 141, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 47.0, 34.0, 3.0, 1.0] , "episode_count": 135, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.435, -9.853, -11.852, -19.753] }
{ "step": 142, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 48.0, 34.0, 3.0, 1.0] , "episode_count": 136, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.403, -9.853, -11.852, -19.753] }
{ "step": 143, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 49.0, 34.0, 3.0, 1.0] , "episode_count": 137, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.372, -9.853, -11.852, -19.753] }
{"total_number_of_episodes": 138, "number_of_timesteps": 13354, "per_episode_reward": -176.06, "episode_reward_trend_value": 0.021677886952171356, "biggest_recent_change": 18.650449071342905},
{ "step": 144, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 50.0, 34.0, 3.0, 1.0] , "episode_count": 138, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.343, -9.853, -11.852, -19.753] }
{ "step": 145, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 51.0, 34.0, 3.0, 1.0] , "episode_count": 140, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.315, -9.853, -11.852, -19.753] }
{ "step": 146, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 52.0, 34.0, 3.0, 1.0] , "episode_count": 142, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.287, -9.853, -11.852, -19.753] }
{ "step": 147, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 53.0, 34.0, 3.0, 1.0] , "episode_count": 142, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.21, -9.853, -11.852, -19.753] }
{ "step": 148, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 54.0, 34.0, 3.0, 1.0] , "episode_count": 143, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.336, -9.853, -11.852, -19.753] }
{ "step": 149, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 55.0, 34.0, 3.0, 1.0] , "episode_count": 143, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.525, -9.853, -11.852, -19.753] }
{ "step": 150, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 56.0, 34.0, 3.0, 1.0] , "episode_count": 146, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.391, -9.853, -11.852, -19.753] }
{ "step": 151, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 57.0, 34.0, 3.0, 1.0] , "episode_count": 147, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.365, -9.853, -11.852, -19.753] }
{"total_number_of_episodes": 150, "number_of_timesteps": 14281, "per_episode_reward": -160.29, "episode_reward_trend_value": 0.13541073673395784, "biggest_recent_change": 18.650449071342905},
{ "step": 152, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 58.0, 34.0, 3.0, 1.0] , "episode_count": 150, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.544, -9.853, -11.852, -19.753] }
{ "step": 153, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 59.0, 34.0, 3.0, 1.0] , "episode_count": 151, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.717, -9.853, -11.852, -19.753] }
{ "step": 154, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 60.0, 34.0, 3.0, 1.0] , "episode_count": 151, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.687, -9.853, -11.852, -19.753] }
{ "step": 155, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 61.0, 34.0, 3.0, 1.0] , "episode_count": 152, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.657, -9.853, -11.852, -19.753] }
{ "step": 156, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 62.0, 34.0, 3.0, 1.0] , "episode_count": 154, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.629, -9.853, -11.852, -19.753] }
{ "step": 157, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 63.0, 34.0, 3.0, 1.0] , "episode_count": 154, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.602, -9.853, -11.852, -19.753] }
{ "step": 158, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 64.0, 34.0, 3.0, 1.0] , "episode_count": 154, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.76, -9.853, -11.852, -19.753] }
{ "step": 159, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 64.0, 35.0, 3.0, 1.0] , "episode_count": 156, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.76, -9.572, -11.852, -19.753] }
{ "step": 160, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 64.0, 36.0, 3.0, 1.0] , "episode_count": 156, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.76, -9.526, -11.852, -19.753] }
{ "step": 161, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 64.0, 37.0, 3.0, 1.0] , "episode_count": 158, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.76, -9.482, -11.852, -19.753] }
{"total_number_of_episodes": 161, "number_of_timesteps": 15178, "per_episode_reward": -152.61, "episode_reward_trend_value": 0.26943994802084414, "biggest_recent_change": 18.650449071342905},
{ "step": 162, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 64.0, 38.0, 3.0, 1.0] , "episode_count": 161, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.76, -9.752, -11.852, -19.753] }
{ "step": 163, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 64.0, 39.0, 3.0, 1.0] , "episode_count": 163, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.76, -9.704, -11.852, -19.753] }
{ "step": 164, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 64.0, 40.0, 3.0, 1.0] , "episode_count": 163, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.76, -9.956, -11.852, -19.753] }
{ "step": 165, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 65.0, 40.0, 3.0, 1.0] , "episode_count": 164, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.732, -9.956, -11.852, -19.753] }
{ "step": 166, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 66.0, 40.0, 3.0, 1.0] , "episode_count": 164, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.642, -9.956, -11.852, -19.753] }
{ "step": 167, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 67.0, 40.0, 3.0, 1.0] , "episode_count": 165, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.793, -9.956, -11.852, -19.753] }
{ "step": 168, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 68.0, 40.0, 3.0, 1.0] , "episode_count": 168, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.649, -9.956, -11.852, -19.753] }
{"total_number_of_episodes": 171, "number_of_timesteps": 15903, "per_episode_reward": -154.08, "episode_reward_trend_value": 0.46034020272585013, "biggest_recent_change": 15.764826142999851},
{ "step": 169, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 69.0, 40.0, 3.0, 1.0] , "episode_count": 171, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.624, -9.956, -11.852, -19.753] }
{ "step": 170, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 70.0, 40.0, 3.0, 1.0] , "episode_count": 171, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.599, -9.956, -11.852, -19.753] }
{ "step": 171, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 71.0, 40.0, 3.0, 1.0] , "episode_count": 173, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.7, -9.956, -11.852, -19.753] }
{ "step": 172, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 72.0, 40.0, 3.0, 1.0] , "episode_count": 173, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.676, -9.956, -11.852, -19.753] }
{ "step": 173, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 73.0, 40.0, 3.0, 1.0] , "episode_count": 174, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.651, -9.956, -11.852, -19.753] }
{ "step": 174, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 74.0, 40.0, 3.0, 1.0] , "episode_count": 175, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.628, -9.956, -11.852, -19.753] }
{ "step": 175, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 75.0, 40.0, 3.0, 1.0] , "episode_count": 177, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.605, -9.956, -11.852, -19.753] }
{ "step": 176, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 76.0, 40.0, 3.0, 1.0] , "episode_count": 178, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.582, -9.956, -11.852, -19.753] }
{"total_number_of_episodes": 182, "number_of_timesteps": 16668, "per_episode_reward": -147.92, "episode_reward_trend_value": 0.5064108603876794, "biggest_recent_change": 15.764826142999851},
{ "step": 177, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 77.0, 40.0, 3.0, 1.0] , "episode_count": 182, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.714, -9.956, -11.852, -19.753] }
{ "step": 178, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 78.0, 40.0, 3.0, 1.0] , "episode_count": 183, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.691, -9.956, -11.852, -19.753] }
{ "step": 179, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 79.0, 40.0, 3.0, 1.0] , "episode_count": 183, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.763, -9.956, -11.852, -19.753] }
{ "step": 180, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 80.0, 40.0, 3.0, 1.0] , "episode_count": 184, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.665, -9.956, -11.852, -19.753] }
{ "step": 181, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 81.0, 40.0, 3.0, 1.0] , "episode_count": 186, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.643, -9.956, -11.852, -19.753] }
{ "step": 182, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 82.0, 40.0, 3.0, 1.0] , "episode_count": 186, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.622, -9.956, -11.852, -19.753] }
{ "step": 183, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 83.0, 40.0, 3.0, 1.0] , "episode_count": 190, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.601, -9.956, -11.852, -19.753] }
{ "step": 184, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 84.0, 40.0, 3.0, 1.0] , "episode_count": 190, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.581, -9.956, -11.852, -19.753] }
{ "step": 185, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 85.0, 40.0, 3.0, 1.0] , "episode_count": 190, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.561, -9.956, -11.852, -19.753] }
{"total_number_of_episodes": 192, "number_of_timesteps": 17354, "per_episode_reward": -145.02, "episode_reward_trend_value": 0.6056182827093851, "biggest_recent_change": 15.764826142999851},
{ "step": 186, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 86.0, 40.0, 3.0, 1.0] , "episode_count": 192, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.478, -9.956, -11.852, -19.753] }
{ "step": 187, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 87.0, 40.0, 3.0, 1.0] , "episode_count": 194, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.46, -9.956, -11.852, -19.753] }
{ "step": 188, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 88.0, 40.0, 3.0, 1.0] , "episode_count": 194, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.368, -9.956, -11.852, -19.753] }
{ "step": 189, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 89.0, 40.0, 3.0, 1.0] , "episode_count": 196, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.352, -9.956, -11.852, -19.753] }
{ "step": 190, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 90.0, 40.0, 3.0, 1.0] , "episode_count": 196, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.395, -9.956, -11.852, -19.753] }
{ "step": 191, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 91.0, 40.0, 3.0, 1.0] , "episode_count": 200, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.509, -9.956, -11.852, -19.753] }
{ "step": 192, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 92.0, 40.0, 3.0, 1.0] , "episode_count": 201, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.457, -9.956, -11.852, -19.753] }
{ "step": 193, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 93.0, 40.0, 3.0, 1.0] , "episode_count": 201, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.567, -9.956, -11.852, -19.753] }
{ "step": 194, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 94.0, 40.0, 3.0, 1.0] , "episode_count": 201, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.55, -9.956, -11.852, -19.753] }
{"total_number_of_episodes": 202, "number_of_timesteps": 18079, "per_episode_reward": -142.43, "episode_reward_trend_value": 0.5353887897906816, "biggest_recent_change": 15.764826142999851},
{ "step": 195, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 95.0, 40.0, 3.0, 1.0] , "episode_count": 202, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.657, -9.956, -11.852, -19.753] }
{ "step": 196, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 96.0, 40.0, 3.0, 1.0] , "episode_count": 204, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.762, -9.956, -11.852, -19.753] }
{ "step": 197, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 97.0, 40.0, 3.0, 1.0] , "episode_count": 205, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.662, -9.956, -11.852, -19.753] }
{ "step": 198, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 98.0, 40.0, 3.0, 1.0] , "episode_count": 207, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.764, -9.956, -11.852, -19.753] }
{ "step": 199, "visits": [3.0, 40.0, 3.0, 3.0, 5.0, 2.0, 99.0, 40.0, 3.0, 1.0] , "episode_count": 208, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -9.865, -9.956, -11.852, -19.753] }
{ "step": 200, "visits": [3.0, 41.0, 3.0, 3.0, 5.0, 2.0, 99.0, 40.0, 3.0, 1.0] , "episode_count": 209, "q_vals": [-11.852, -9.86, -11.852, -13.853, -11.062, -13.827, -9.865, -9.956, -11.852, -19.753] }
{ "step": 201, "visits": [3.0, 42.0, 3.0, 3.0, 5.0, 2.0, 99.0, 40.0, 3.0, 1.0] , "episode_count": 211, "q_vals": [-11.852, -10.096, -11.852, -13.853, -11.062, -13.827, -9.865, -9.956, -11.852, -19.753] }
{"total_number_of_episodes": 212, "number_of_timesteps": 18898, "per_episode_reward": -142.49, "episode_reward_trend_value": 0.48636308993288824, "biggest_recent_change": 15.764826142999851},
{ "step": 202, "visits": [3.0, 42.0, 3.0, 3.0, 5.0, 2.0, 99.0, 41.0, 3.0, 1.0] , "episode_count": 212, "q_vals": [-11.852, -10.096, -11.852, -13.853, -11.062, -13.827, -9.865, -9.906, -11.852, -19.753] }
{ "step": 203, "visits": [3.0, 42.0, 3.0, 3.0, 5.0, 2.0, 99.0, 42.0, 3.0, 1.0] , "episode_count": 212, "q_vals": [-11.852, -10.096, -11.852, -13.853, -11.062, -13.827, -9.865, -10.14, -11.852, -19.753] }
{ "step": 204, "visits": [3.0, 42.0, 3.0, 3.0, 5.0, 2.0, 100.0, 42.0, 3.0, 1.0] , "episode_count": 214, "q_vals": [-11.852, -10.096, -11.852, -13.853, -11.062, -13.827, -9.846, -10.14, -11.852, -19.753] }
{ "step": 205, "visits": [3.0, 42.0, 3.0, 3.0, 5.0, 2.0, 101.0, 42.0, 3.0, 1.0] , "episode_count": 217, "q_vals": [-11.852, -10.096, -11.852, -13.853, -11.062, -13.827, -9.944, -10.14, -11.852, -19.753] }
{ "step": 206, "visits": [3.0, 42.0, 3.0, 3.0, 5.0, 2.0, 102.0, 42.0, 3.0, 1.0] , "episode_count": 217, "q_vals": [-11.852, -10.096, -11.852, -13.853, -11.062, -13.827, -9.924, -10.14, -11.852, -19.753] }
{ "step": 207, "visits": [3.0, 42.0, 3.0, 3.0, 5.0, 2.0, 103.0, 42.0, 3.0, 1.0] , "episode_count": 218, "q_vals": [-11.852, -10.096, -11.852, -13.853, -11.062, -13.827, -9.904, -10.14, -11.852, -19.753] }
{ "step": 208, "visits": [3.0, 42.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 220, "q_vals": [-11.852, -10.096, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 209, "visits": [3.0, 43.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 220, "q_vals": [-11.852, -10.045, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 210, "visits": [3.0, 44.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 221, "q_vals": [-11.852, -9.996, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{"total_number_of_episodes": 224, "number_of_timesteps": 19774, "per_episode_reward": -139.01, "episode_reward_trend_value": 0.5286326706652734, "biggest_recent_change": 15.764826142999851},
{ "step": 211, "visits": [3.0, 45.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 224, "q_vals": [-11.852, -9.922, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 212, "visits": [3.0, 46.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 224, "q_vals": [-11.852, -9.878, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 213, "visits": [3.0, 47.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 226, "q_vals": [-11.852, -9.836, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 214, "visits": [3.0, 48.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 227, "q_vals": [-11.852, -10.043, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 215, "visits": [3.0, 49.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 228, "q_vals": [-11.852, -9.838, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 216, "visits": [3.0, 50.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 228, "q_vals": [-11.852, -9.799, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 217, "visits": [3.0, 51.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 230, "q_vals": [-11.852, -9.762, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 218, "visits": [3.0, 52.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 231, "q_vals": [-11.852, -9.954, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{"total_number_of_episodes": 234, "number_of_timesteps": 20541, "per_episode_reward": -137.82, "episode_reward_trend_value": 0.4248285687496917, "biggest_recent_change": 15.764826142999851},
{ "step": 219, "visits": [3.0, 53.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 234, "q_vals": [-11.852, -9.915, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 220, "visits": [3.0, 54.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 235, "q_vals": [-11.852, -9.878, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 221, "visits": [3.0, 55.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 237, "q_vals": [-11.852, -9.842, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 222, "visits": [3.0, 56.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 237, "q_vals": [-11.852, -9.807, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 223, "visits": [3.0, 57.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 238, "q_vals": [-11.852, -9.982, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 224, "visits": [3.0, 58.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 240, "q_vals": [-11.852, -9.81, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 225, "visits": [3.0, 59.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 240, "q_vals": [-11.852, -9.978, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 226, "visits": [3.0, 60.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 241, "q_vals": [-11.852, -9.944, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{ "step": 227, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 104.0, 42.0, 3.0, 1.0] , "episode_count": 243, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -9.999, -10.14, -11.852, -19.753] }
{"total_number_of_episodes": 245, "number_of_timesteps": 21337, "per_episode_reward": -136.68, "episode_reward_trend_value": 0.262327090351294, "biggest_recent_change": 7.681433356899163},
{ "step": 228, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 105.0, 42.0, 3.0, 1.0] , "episode_count": 245, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -9.979, -10.14, -11.852, -19.753] }
{ "step": 229, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 106.0, 42.0, 3.0, 1.0] , "episode_count": 247, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -9.959, -10.14, -11.852, -19.753] }
{ "step": 230, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 107.0, 42.0, 3.0, 1.0] , "episode_count": 248, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -9.94, -10.14, -11.852, -19.753] }
{ "step": 231, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 108.0, 42.0, 3.0, 1.0] , "episode_count": 248, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -9.921, -10.14, -11.852, -19.753] }
{ "step": 232, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 109.0, 42.0, 3.0, 1.0] , "episode_count": 249, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -9.903, -10.14, -11.852, -19.753] }
{ "step": 233, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 110.0, 42.0, 3.0, 1.0] , "episode_count": 252, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -9.992, -10.14, -11.852, -19.753] }
{ "step": 234, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 111.0, 42.0, 3.0, 1.0] , "episode_count": 253, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -9.973, -10.14, -11.852, -19.753] }
{ "step": 235, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 112.0, 42.0, 3.0, 1.0] , "episode_count": 253, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -9.955, -10.14, -11.852, -19.753] }
{"total_number_of_episodes": 255, "number_of_timesteps": 22064, "per_episode_reward": -135.9, "episode_reward_trend_value": 0.18564898026502147, "biggest_recent_change": 6.1600606498441834},
{ "step": 236, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 113.0, 42.0, 3.0, 1.0] , "episode_count": 255, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -9.937, -10.14, -11.852, -19.753] }
{ "step": 237, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 114.0, 42.0, 3.0, 1.0] , "episode_count": 258, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -9.85, -10.14, -11.852, -19.753] }
{ "step": 238, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 115.0, 42.0, 3.0, 1.0] , "episode_count": 258, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -9.936, -10.14, -11.852, -19.753] }
{ "step": 239, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 116.0, 42.0, 3.0, 1.0] , "episode_count": 258, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -10.02, -10.14, -11.852, -19.753] }
{ "step": 240, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 116.0, 43.0, 3.0, 1.0] , "episode_count": 259, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -10.02, -10.364, -11.852, -19.753] }
{ "step": 241, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 117.0, 43.0, 3.0, 1.0] , "episode_count": 262, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -10.002, -10.364, -11.852, -19.753] }
{ "step": 242, "visits": [3.0, 61.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 262, "q_vals": [-11.852, -10.104, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 265, "number_of_timesteps": 22789, "per_episode_reward": -134.96, "episode_reward_trend_value": 0.21243464049731403, "biggest_recent_change": 6.1600606498441834},
{ "step": 243, "visits": [3.0, 62.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 265, "q_vals": [-11.852, -10.069, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 244, "visits": [3.0, 63.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 265, "q_vals": [-11.852, -9.909, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 245, "visits": [3.0, 64.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 266, "q_vals": [-11.852, -10.063, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 246, "visits": [3.0, 65.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 268, "q_vals": [-11.852, -9.946, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 247, "visits": [3.0, 66.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 269, "q_vals": [-11.852, -9.915, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 248, "visits": [3.0, 67.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 270, "q_vals": [-11.852, -9.885, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 249, "visits": [3.0, 68.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 271, "q_vals": [-11.852, -9.807, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 275, "number_of_timesteps": 23533, "per_episode_reward": -134.67, "episode_reward_trend_value": 0.14724031009484345, "biggest_recent_change": 3.4830829046446468},
{ "step": 250, "visits": [3.0, 69.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 275, "q_vals": [-11.852, -9.779, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 251, "visits": [3.0, 70.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 275, "q_vals": [-11.852, -9.752, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 252, "visits": [3.0, 71.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 276, "q_vals": [-11.852, -9.615, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 253, "visits": [3.0, 72.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 278, "q_vals": [-11.852, -9.491, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 254, "visits": [3.0, 73.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 278, "q_vals": [-11.852, -9.632, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 255, "visits": [3.0, 74.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 279, "q_vals": [-11.852, -9.51, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 256, "visits": [3.0, 75.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 281, "q_vals": [-11.852, -9.647, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 257, "visits": [3.0, 76.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 282, "q_vals": [-11.852, -9.624, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 258, "visits": [3.0, 77.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 283, "q_vals": [-11.852, -9.499, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 286, "number_of_timesteps": 24332, "per_episode_reward": -133.97, "episode_reward_trend_value": 0.12274401858807411, "biggest_recent_change": 3.4830829046446468},
{ "step": 259, "visits": [3.0, 78.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 286, "q_vals": [-11.852, -9.478, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 260, "visits": [3.0, 79.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 288, "q_vals": [-11.852, -9.608, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 261, "visits": [3.0, 80.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 288, "q_vals": [-11.852, -9.587, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 262, "visits": [3.0, 81.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 289, "q_vals": [-11.852, -9.566, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 263, "visits": [3.0, 82.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 290, "q_vals": [-11.852, -9.469, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 264, "visits": [3.0, 83.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 290, "q_vals": [-11.852, -9.593, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 265, "visits": [3.0, 84.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 293, "q_vals": [-11.852, -9.572, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 266, "visits": [3.0, 85.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 295, "q_vals": [-11.852, -9.46, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 296, "number_of_timesteps": 25034, "per_episode_reward": -133.94, "episode_reward_trend_value": 0.09441529968527536, "biggest_recent_change": 3.4830829046446468},
{ "step": 267, "visits": [3.0, 86.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 296, "q_vals": [-11.852, -9.442, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 268, "visits": [3.0, 87.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 297, "q_vals": [-11.852, -9.424, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 269, "visits": [3.0, 88.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 297, "q_vals": [-11.852, -9.407, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 270, "visits": [3.0, 89.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 299, "q_vals": [-11.852, -9.523, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 271, "visits": [3.0, 90.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 299, "q_vals": [-11.852, -9.637, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 272, "visits": [3.0, 91.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 302, "q_vals": [-11.852, -9.618, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 273, "visits": [3.0, 92.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 304, "q_vals": [-11.852, -9.728, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 274, "visits": [3.0, 93.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 304, "q_vals": [-11.852, -9.836, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 275, "visits": [3.0, 94.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 305, "q_vals": [-11.852, -9.815, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 306, "number_of_timesteps": 25775, "per_episode_reward": -133.24, "episode_reward_trend_value": 0.10278666237992537, "biggest_recent_change": 3.4830829046446468},
{ "step": 276, "visits": [3.0, 95.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 306, "q_vals": [-11.852, -9.795, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 277, "visits": [3.0, 96.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 309, "q_vals": [-11.852, -9.775, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 278, "visits": [3.0, 97.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 312, "q_vals": [-11.852, -9.878, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 279, "visits": [3.0, 98.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 312, "q_vals": [-11.852, -9.858, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 280, "visits": [3.0, 99.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 312, "q_vals": [-11.852, -9.831, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 281, "visits": [3.0, 100.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 314, "q_vals": [-11.852, -9.812, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 282, "visits": [3.0, 101.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 314, "q_vals": [-11.852, -9.793, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 316, "number_of_timesteps": 26459, "per_episode_reward": -132.24, "episode_reward_trend_value": 0.07519363078824502, "biggest_recent_change": 1.184497075876834},
{ "step": 283, "visits": [3.0, 102.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 316, "q_vals": [-11.852, -9.775, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 284, "visits": [3.0, 103.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 317, "q_vals": [-11.852, -9.756, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 285, "visits": [3.0, 104.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 318, "q_vals": [-11.852, -9.739, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 286, "visits": [3.0, 105.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 318, "q_vals": [-11.852, -9.721, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 287, "visits": [3.0, 106.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 320, "q_vals": [-11.852, -9.657, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 288, "visits": [3.0, 107.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 321, "q_vals": [-11.852, -9.751, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 289, "visits": [3.0, 108.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 324, "q_vals": [-11.852, -9.661, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 326, "number_of_timesteps": 27293, "per_episode_reward": -132.83, "episode_reward_trend_value": 0.05545659572992336, "biggest_recent_change": 1.1396930871440532},
{ "step": 290, "visits": [3.0, 109.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 326, "q_vals": [-11.852, -9.645, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 291, "visits": [3.0, 110.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 328, "q_vals": [-11.852, -9.575, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 292, "visits": [3.0, 111.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 328, "q_vals": [-11.852, -9.489, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 293, "visits": [3.0, 112.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 328, "q_vals": [-11.852, -9.58, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 294, "visits": [3.0, 113.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 329, "q_vals": [-11.852, -9.565, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 295, "visits": [3.0, 114.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 331, "q_vals": [-11.852, -9.551, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 296, "visits": [3.0, 115.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 332, "q_vals": [-11.852, -9.64, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
Step 297 1 visits [starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[3.0, 116.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0]  episode_count: 335 q_vals: [-11.852, -9.604, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753]
{ "step": 298, "visits": [3.0, 117.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 335, "q_vals": [-11.852, -9.691, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 336, "number_of_timesteps": 27970, "per_episode_reward": -132.44, "episode_reward_trend_value": 0.04708587958989483, "biggest_recent_change": 0.9997100613934151},
{ "step": 299, "visits": [3.0, 118.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 336, "q_vals": [-11.852, -9.676, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 300, "visits": [3.0, 119.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 337, "q_vals": [-11.852, -9.761, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 301, "visits": [3.0, 120.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 337, "q_vals": [-11.852, -9.745, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 302, "visits": [3.0, 121.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 342, "q_vals": [-11.852, -9.828, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 303, "visits": [3.0, 122.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 342, "q_vals": [-11.852, -9.812, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 304, "visits": [3.0, 123.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 342, "q_vals": [-11.852, -9.797, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 305, "visits": [3.0, 124.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 343, "q_vals": [-11.852, -9.781, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 306, "visits": [3.0, 125.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 344, "q_vals": [-11.852, -9.766, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 346, "number_of_timesteps": 28738, "per_episode_reward": -133.55, "episode_reward_trend_value": 0.02611178323862128, "biggest_recent_change": 1.107265222479981},
{ "step": 307, "visits": [3.0, 126.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 346, "q_vals": [-11.852, -9.751, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 308, "visits": [3.0, 127.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 349, "q_vals": [-11.852, -9.737, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 309, "visits": [3.0, 128.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 349, "q_vals": [-11.852, -9.81, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 310, "visits": [3.0, 129.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 350, "q_vals": [-11.852, -9.795, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 311, "visits": [3.0, 130.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 351, "q_vals": [-11.852, -9.871, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 312, "visits": [3.0, 131.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 351, "q_vals": [-11.852, -9.856, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 313, "visits": [3.0, 132.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 351, "q_vals": [-11.852, -9.841, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 314, "visits": [3.0, 133.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 353, "q_vals": [-11.852, -9.916, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 356, "number_of_timesteps": 29533, "per_episode_reward": -133.89, "episode_reward_trend_value": 0.011827090826290349, "biggest_recent_change": 1.107265222479981},
{ "step": 315, "visits": [3.0, 134.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 356, "q_vals": [-11.852, -9.901, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 316, "visits": [3.0, 135.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 356, "q_vals": [-11.852, -9.886, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 317, "visits": [3.0, 136.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 357, "q_vals": [-11.852, -9.872, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 318, "visits": [3.0, 137.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 357, "q_vals": [-11.852, -9.857, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 319, "visits": [3.0, 138.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 359, "q_vals": [-11.852, -9.929, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 320, "visits": [3.0, 139.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 361, "q_vals": [-11.852, -9.857, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 321, "visits": [3.0, 140.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 363, "q_vals": [-11.852, -9.9, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 322, "visits": [3.0, 141.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 364, "q_vals": [-11.852, -9.885, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 323, "visits": [3.0, 142.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 365, "q_vals": [-11.852, -9.844, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 366, "number_of_timesteps": 30387, "per_episode_reward": -134.79, "episode_reward_trend_value": -0.0013919204191770026, "biggest_recent_change": 1.107265222479981},
{ "step": 324, "visits": [3.0, 143.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 366, "q_vals": [-11.852, -9.893, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 325, "visits": [3.0, 144.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 366, "q_vals": [-11.852, -9.879, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 326, "visits": [3.0, 145.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 366, "q_vals": [-11.852, -9.865, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 327, "visits": [3.0, 146.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 370, "q_vals": [-11.852, -9.852, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 328, "visits": [3.0, 147.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 371, "q_vals": [starting run_func()] }
[starting train_loop()]
[-11.852, -9.839, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753]
{ "step": 329, "visits": [3.0, 148.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 371, "q_vals": [-11.852, -9.772, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 330, "visits": [3.0, 149.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 374, "q_vals": [-11.852, -9.76, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 331, "visits": [3.0, 150.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 375, "q_vals": [-11.852, -9.747, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 332, "visits": [3.0, 151.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 375, "q_vals": [-11.852, -9.735, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 333, "visits": [3.0, 152.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 375, "q_vals": [-11.852, -9.723, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 377, "number_of_timesteps": 31274, "per_episode_reward": -134.18, "episode_reward_trend_value": -0.0023347209285895414, "biggest_recent_change": 1.107265222479981},
{ "step": 334, "visits": [3.0, 153.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 377, "q_vals": [-11.852, -9.789, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 335, "visits": [3.0, 154.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 378, "q_vals": [-11.852, -9.776, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 336, "visits": [3.0, 155.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 381, "q_vals": [-11.852, -9.735, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 337, "visits": [3.0, 156.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 384, "q_vals": [-11.852, -9.673, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 338, "visits": [3.0, 157.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 384, "q_vals": [-11.852, -9.662, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 339, "visits": [3.0, 158.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 384, "q_vals": [-11.852, -9.726, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 340, "visits": [3.0, 159.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 385, "q_vals": [-11.852, -9.714, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 341, "visits": [3.0, 160.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 386, "q_vals": [-11.852, -9.672, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 387, "number_of_timesteps": 32016, "per_episode_reward": -135.1, "episode_reward_trend_value": -0.012906073530819462, "biggest_recent_change": 1.107265222479981},
{ "step": 342, "visits": [3.0, 161.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 387, "q_vals": [-11.852, -9.661, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 343, "visits": [3.0, 162.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 388, "q_vals": [-11.852, -9.65, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 344, "visits": [3.0, 163.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 390, "q_vals": [-11.852, -9.639, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 345, "visits": [3.0, 164.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 391, "q_vals": [-11.852, -9.701, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 346, "visits": [3.0, 165.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 392, "q_vals": [-11.852, -9.762, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 347, "visits": [3.0, 166.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 392, "q_vals": [-11.852, -9.751, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 348, "visits": [3.0, 167.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 394, "q_vals": [-11.852, -9.74, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 349, "visits": [3.0, 168.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 394, "q_vals": [-11.852, -9.799, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 350, "visits": [3.0, 169.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 396, "q_vals": [-11.852, -9.788, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 399, "number_of_timesteps": 33035, "per_episode_reward": -136.52, "episode_reward_trend_value": -0.0364741717466264, "biggest_recent_change": 1.4219523575970072},
{ "step": 351, "visits": [3.0, 170.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 399, "q_vals": [-11.852, -9.777, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 352, "visits": [3.0, 171.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 400, "q_vals": [-11.852, -9.835, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 353, "visits": [3.0, 172.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 401, "q_vals": [-11.852, -9.824, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 354, "visits": [3.0, 173.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 402, "q_vals": [-11.852, -9.813, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 355, "visits": [3.0, 174.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 402, "q_vals": [-11.852, -9.802, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 356, "visits": [3.0, 175.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 404, "q_vals": [-11.852, -9.764, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 357, "visits": [3.0, 176.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 405, "q_vals": [-11.852, -9.753, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 358, "visits": [3.0, 177.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 406, "q_vals": [-11.852, -9.743, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 359, "visits": [3.0, 178.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 408, "q_vals": [-11.852, -9.733, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 409, "number_of_timesteps": 33792, "per_episode_reward": -136.58, "episode_reward_trend_value": -0.04830115672110556, "biggest_recent_change": 1.4219523575970072},
{ "step": 360, "visits": [3.0, 179.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 409, "q_vals": [-11.852, -9.789, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 361, "visits": [3.0, 180.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 411, "q_vals": [-11.852, -9.778, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 362, "visits": [3.0, 181.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 411, "q_vals": [-11.852, -9.768, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 363, "visits": [3.0, 182.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 411, "q_vals": [-11.852, -9.758, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 364, "visits": [3.0, 183.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 414, "q_vals": [-11.852, -9.747, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 365, "visits": [3.0, 184.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 415, "q_vals": [-11.852, -9.737, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 366, "visits": [3.0, 185.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 416, "q_vals": [-11.852, -9.727, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 419, "number_of_timesteps": 34566, "per_episode_reward": -136.89, "episode_reward_trend_value": -0.04514341375172661, "biggest_recent_change": 1.4219523575970072},
{ "step": 367, "visits": [3.0, 186.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 419, "q_vals": [-11.852, -9.718, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 368, "visits": [3.0, 187.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 419, "q_vals": [-11.852, -9.708, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 369, "visits": [3.0, 188.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 419, "q_vals": [-11.852, -9.678, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 370, "visits": [3.0, 189.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 420, "q_vals": [-11.852, -9.669, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 371, "visits": [3.0, 190.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 421, "q_vals": [-11.852, -9.659, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 372, "visits": [3.0, 191.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 423, "q_vals": [-11.852, -9.65, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 373, "visits": [3.0, 192.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 423, "q_vals": [-11.852, -9.703, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 374, "visits": [3.0, 193.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 425, "q_vals": [-11.852, -9.755, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 375, "visits": [3.0, 194.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 426, "q_vals": [-11.852, -9.745, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 376, "visits": [3.0, 195.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 427, "q_vals": [-11.852, -9.736, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 430, "number_of_timesteps": 35507, "per_episode_reward": -136.88, "episode_reward_trend_value": -0.04928725962209721, "biggest_recent_change": 1.4219523575970072},
{ "step": 377, "visits": [3.0, 196.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 430, "q_vals": [-11.852, -9.787, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 378, "visits": [3.0, 197.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 430, "q_vals": [-11.852, -9.777, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 379, "visits": [3.0, 198.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 430, "q_vals": [-11.852, -9.768, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 380, "visits": [3.0, 199.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 432, "q_vals": [-11.852, -9.818, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 381, "visits": [3.0, 200.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 433, "q_vals": [-11.852, -9.809, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 382, "visits": [3.0, 201.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 433, "q_vals": [-11.852, -9.799, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 383, "visits": [3.0, 202.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 435, "q_vals": [-11.852, -9.751, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 384, "visits": [3.0, 203.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 438, "q_vals": [-11.852, -9.741, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 385, "visits": [3.0, 204.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 438, "q_vals": [-11.852, -9.791, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 386, "visits": [3.0, 205.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 439, "q_vals": [-11.852, -9.781, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 440, "number_of_timesteps": 36336, "per_episode_reward": -137.64, "episode_reward_trend_value": -0.045492448667831316, "biggest_recent_change": 1.4219523575970072},
{ "step": 387, "visits": [3.0, 206.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 440, "q_vals": [-11.852, -9.772, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 388, "visits": [3.0, 207.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 440, "q_vals": [-11.852, -9.763, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 389, "visits": [3.0, 208.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 442, "q_vals": [-11.852, -9.754, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 390, "visits": [3.0, 209.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 443, "q_vals": [-11.852, -9.745, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 391, "visits": [3.0, 210.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 445, "q_vals": [-11.852, -9.737, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 392, "visits": [3.0, 211.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 446, "q_vals": [-11.852, -9.69, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 393, "visits": [3.0, 212.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 449, "q_vals": [-11.852, -9.682, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 450, "number_of_timesteps": 37128, "per_episode_reward": -137.76, "episode_reward_trend_value": -0.04292963964384266, "biggest_recent_change": 1.4219523575970072},
{ "step": 394, "visits": [3.0, 213.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 450, "q_vals": [-11.852, -9.674, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 395, "visits": [3.0, 214.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 450, "q_vals": [-11.852, -9.665, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 396, "visits": [3.0, 215.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 452, "q_vals": [-11.852, -9.657, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 397, "visits": [3.0, 216.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 453, "q_vals": [-11.852, -9.649, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 398, "visits": [3.0, 217.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 453, "q_vals": [-11.852, -9.696, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 399, "visits": [3.0, 218.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 455, "q_vals": [-11.852, -9.742, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 400, "visits": [3.0, 219.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 455, "q_vals": [-11.852, -9.733, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 401, "visits": [3.0, 220.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 457, "q_vals": [-11.852, -9.725, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 460, "number_of_timesteps": 37889, "per_episode_reward": -139.61, "episode_reward_trend_value": -0.053568217920443174, "biggest_recent_change": 1.8546121433642782},
{ "step": 402, "visits": [3.0, 221.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 460, "q_vals": [-11.852, -9.717, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 403, "visits": [3.0, 222.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 461, "q_vals": [-11.852, -9.709, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 404, "visits": [3.0, 223.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 461, "q_vals": [-11.852, -9.7, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 405, "visits": [3.0, 224.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 462, "q_vals": [-11.852, -9.745, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 406, "visits": [3.0, 225.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 464, "q_vals": [-11.852, -9.737, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 407, "visits": [3.0, 226.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 465, "q_vals": [-11.852, -9.729, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 408, "visits": [3.0, 227.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 467, "q_vals": [-11.852, -9.721, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 409, "visits": [3.0, 228.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 468, "q_vals": [-11.852, -9.713, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 410, "visits": [3.0, 229.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 469, "q_vals": [-11.852, -9.705, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 470, "number_of_timesteps": 38622, "per_episode_reward": -141.11, "episode_reward_trend_value": -0.07701817612510271, "biggest_recent_change": 1.8546121433642782},
{ "step": 411, "visits": [3.0, 230.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 470, "q_vals": [-11.852, -9.749, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 412, "visits": [3.0, 231.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 471, "q_vals": [-11.852, -9.741, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 413, "visits": [3.0, 232.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 471, "q_vals": [-11.852, -9.733, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 414, "visits": [3.0, 233.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 471, "q_vals": [-11.852, -9.725, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 415, "visits": [3.0, 234.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 474, "q_vals": [-11.852, -9.717, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 416, "visits": [3.0, 235.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 476, "q_vals": [-11.852, -9.709, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 417, "visits": [3.0, 236.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 477, "q_vals": [-11.852, -9.752, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 418, "visits": [3.0, 237.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 477, "q_vals": [-11.852, -9.744, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 481, "number_of_timesteps": 39549, "per_episode_reward": -143.75, "episode_reward_trend_value": -0.09608566837459623, "biggest_recent_change": 2.631160278983401},
{ "step": 419, "visits": [3.0, 238.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 481, "q_vals": [-11.852, -9.736, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 420, "visits": [3.0, 239.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 481, "q_vals": [-11.852, -9.729, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 421, "visits": [3.0, 240.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 481, "q_vals": [-11.852, -9.721, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 422, "visits": [3.0, 241.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 483, "q_vals": [-11.852, -9.714, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 423, "visits": [3.0, 242.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 486, "q_vals": [-11.852, -9.706, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 424, "visits": [3.0, 243.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 486, "q_vals": [-11.852, -9.699, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 425, "visits": [3.0, 244.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 487, "q_vals": [-11.852, -9.74, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 426, "visits": [3.0, 245.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 488, "q_vals": [-11.852, -9.732, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 427, "visits": [3.0, 246.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 489, "q_vals": [-11.852, -9.693, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 492, "number_of_timesteps": 40326, "per_episode_reward": -146.49, "episode_reward_trend_value": -0.11074493395790246, "biggest_recent_change": 2.7412862600945687},
{ "step": 428, "visits": [3.0, 247.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 492, "q_vals": [-11.852, -9.686, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 429, "visits": [3.0, 248.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 493, "q_vals": [-11.852, -9.678, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 430, "visits": [3.0, 249.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 493, "q_vals": [-11.852, -9.719, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 431, "visits": [3.0, 250.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 494, "q_vals": [-11.852, -9.712, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 432, "visits": [3.0, 251.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 495, "q_vals": [-11.852, -9.704, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 433, "visits": [3.0, 252.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 497, "q_vals": [-11.852, -9.697, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 434, "visits": [3.0, 253.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 498, "q_vals": [-11.852, -9.69, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 435, "visits": [3.0, 254.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 499, "q_vals": [-11.852, -9.683, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 436, "visits": [3.0, 255.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 501, "q_vals": [-11.852, -9.676, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 502, "number_of_timesteps": 41113, "per_episode_reward": -149.29, "episode_reward_trend_value": -0.14120150420193878, "biggest_recent_change": 2.805809908272977},
{ "step": 437, "visits": [3.0, 256.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 502, "q_vals": [-11.852, -9.715, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 438, "visits": [3.0, 257.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 502, "q_vals": [-11.852, -9.708, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 439, "visits": [3.0, 258.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 504, "q_vals": [-11.852, -9.671, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 440, "visits": [3.0, 259.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 505, "q_vals": [-11.852, -9.71, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 441, "visits": [3.0, 260.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 507, "q_vals": [-11.852, -9.703, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 442, "visits": [3.0, 261.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 509, "q_vals": [-11.852, -9.696, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 443, "visits": [3.0, 262.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 511, "q_vals": [-11.852, -9.689, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 512, "number_of_timesteps": 41858, "per_episode_reward": -150.03, "episode_reward_trend_value": -0.1460097038653168, "biggest_recent_change": 2.805809908272977},
{ "step": 444, "visits": [3.0, 263.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 512, "q_vals": [-11.852, -9.727, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 445, "visits": [3.0, 264.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 512, "q_vals": [-11.852, -9.72, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 446, "visits": [3.0, 265.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 513, "q_vals": [-11.852, -9.713, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 447, "visits": [3.0, 266.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 513, "q_vals": [-11.852, -9.707, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 448, "visits": [3.0, 267.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 514, "q_vals": [-11.852, -9.7, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 449, "visits": [3.0, 268.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 516, "q_vals": [-11.852, -9.737, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 450, "visits": [3.0, 269.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 517, "q_vals": [-11.852, -9.731, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 451, "visits": [3.0, 270.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 520, "q_vals": [-11.852, -9.709, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 452, "visits": [3.0, 271.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 521, "q_vals": [-11.852, -9.693, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 453, "visits": [3.0, 272.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 521, "q_vals": [-11.852, -9.686, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 522, "number_of_timesteps": 42668, "per_episode_reward": -152.65, "episode_reward_trend_value": -0.17522147297429583, "biggest_recent_change": 2.805809908272977},
{ "step": 454, "visits": [3.0, 273.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 522, "q_vals": [-11.852, -9.65, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 455, "visits": [3.0, 274.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 524, "q_vals": [-11.852, -9.644, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 456, "visits": [3.0, 275.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 525, "q_vals": [-11.852, -9.638, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 457, "visits": [3.0, 276.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 526, "q_vals": [-11.852, -9.613, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 458, "visits": [3.0, 277.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 529, "q_vals": [-11.852, -9.65, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 459, "visits": [3.0, 278.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 530, "q_vals": [-11.852, -9.643, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 460, "visits": [3.0, 279.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 530, "q_vals": [-11.852, -9.637, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 461, "visits": [3.0, 280.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 530, "q_vals": [-11.852, -9.631, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 462, "visits": [3.0, 281.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 530, "q_vals": [-11.852, -9.667, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 532, "number_of_timesteps": 43423, "per_episode_reward": -155.65, "episode_reward_trend_value": -0.20003670662997686, "biggest_recent_change": 2.9991032656073457},
{ "step": 463, "visits": [3.0, 282.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 532, "q_vals": [-11.852, -9.703, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 464, "visits": [3.0, 283.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 533, "q_vals": [-11.852, -9.696, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 465, "visits": [3.0, 284.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 537, "q_vals": [-11.852, -9.69, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 466, "visits": [3.0, 285.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 537, "q_vals": [-11.852, -9.684, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 467, "visits": [3.0, 286.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 538, "q_vals": [-11.852, -9.678, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 468, "visits": [3.0, 287.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 539, "q_vals": [-11.852, -9.713, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 469, "visits": [3.0, 288.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 540, "q_vals": [-11.852, -9.706, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 470, "visits": [3.0, 289.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 541, "q_vals": [-11.852, -9.741, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 542, "number_of_timesteps": 44253, "per_episode_reward": -158.0, "episode_reward_trend_value": -0.22489455186793475, "biggest_recent_change": 2.9991032656073457},
{ "step": 471, "visits": [3.0, 290.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 542, "q_vals": [-11.852, -9.708, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 472, "visits": [3.0, 291.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 544, "q_vals": [-11.852, -9.742, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 473, "visits": [3.0, 292.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 546, "q_vals": [-11.852, -9.709, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 474, "visits": [3.0, 293.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 548, "q_vals": [-11.852, -9.743, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 475, "visits": [3.0, 294.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 548, "q_vals": [-11.852, -9.737, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 476, "visits": [3.0, 295.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 548, "q_vals": [-11.852, -9.731, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 477, "visits": [3.0, 296.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 548, "q_vals": [-11.852, -9.724, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 478, "visits": [3.0, 297.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 551, "q_vals": [-11.852, -9.718, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 479, "visits": [3.0, 298.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 551, "q_vals": [-11.852, -9.712, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 552, "number_of_timesteps": 44999, "per_episode_reward": -159.47, "episode_reward_trend_value": -0.22062031934361337, "biggest_recent_change": 2.9991032656073457},
{ "step": 480, "visits": [3.0, 299.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 552, "q_vals": [-11.852, -9.746, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 481, "visits": [3.0, 300.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 553, "q_vals": [-11.852, -9.779, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 482, "visits": [3.0, 301.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 555, "q_vals": [-11.852, -9.773, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 483, "visits": [3.0, 302.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 557, "q_vals": [-11.852, -9.767, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 484, "visits": [3.0, 303.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 558, "q_vals": [-11.852, -9.8, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 485, "visits": [3.0, 304.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 559, "q_vals": [-11.852, -9.793, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 486, "visits": [3.0, 305.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 561, "q_vals": [-11.852, -9.826, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 562, "number_of_timesteps": 45849, "per_episode_reward": -162.6, "episode_reward_trend_value": -0.23875853725098467, "biggest_recent_change": 3.1340312246699114},
{ "step": 487, "visits": [3.0, 306.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 562, "q_vals": [-11.852, -9.82, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 488, "visits": [3.0, 307.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 562, "q_vals": [-11.852, -9.813, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 489, "visits": [3.0, 308.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 563, "q_vals": [-11.852, -9.807, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 490, "visits": [3.0, 309.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 566, "q_vals": [-11.852, -9.801, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 491, "visits": [3.0, 310.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 566, "q_vals": [-11.852, -9.795, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 492, "visits": [3.0, 311.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 567, "q_vals": [-11.852, -9.763, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 493, "visits": [3.0, 312.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 570, "q_vals": [-11.852, -9.757, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 494, "visits": [3.0, 313.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 570, "q_vals": [-11.852, -9.752, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 495, "visits": [3.0, 314.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 571, "q_vals": [-11.852, -9.746, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 572, "number_of_timesteps": 46625, "per_episode_reward": -165.85, "episode_reward_trend_value": -0.24555735777201101, "biggest_recent_change": 3.243054125875773},
{ "step": 496, "visits": [3.0, 315.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 572, "q_vals": [-11.852, -9.74, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 497, "visits": [3.0, 316.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 572, "q_vals": [-11.852, -9.734, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 498, "visits": [3.0, 317.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 572, "q_vals": [-11.852, -9.728, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 499, "visits": [3.0, 318.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 575, "q_vals": [-11.852, -9.76, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 500, "visits": [3.0, 319.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 576, "q_vals": [-11.852, -9.754, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 501, "visits": [3.0, 320.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 577, "q_vals": [-11.852, -9.748, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 502, "visits": [3.0, 321.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 578, "q_vals": [-11.852, -9.742, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 503, "visits": [3.0, 322.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 581, "q_vals": [-11.852, -9.737, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 582, "number_of_timesteps": 47514, "per_episode_reward": -167.94, "episode_reward_trend_value": -0.23835158463577893, "biggest_recent_change": 3.243054125875773},
{ "step": 504, "visits": [3.0, 323.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 582, "q_vals": [-11.852, -9.768, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 505, "visits": [3.0, 324.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 582, "q_vals": [-11.852, -9.738, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 506, "visits": [3.0, 325.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 583, "q_vals": [-11.852, -9.768, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 507, "visits": [3.0, 326.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 585, "q_vals": [-11.852, -9.763, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 508, "visits": [3.0, 327.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 585, "q_vals": [-11.852, -9.793, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 509, "visits": [3.0, 328.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 587, "q_vals": [-11.852, -9.824, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 510, "visits": [3.0, 329.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 589, "q_vals": [-11.852, -9.854, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 511, "visits": [3.0, 330.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 590, "q_vals": [-11.852, -9.848, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 512, "visits": [3.0, 331.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 591, "q_vals": [-11.852, -9.842, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 592, "number_of_timesteps": 48300, "per_episode_reward": -170.28, "episode_reward_trend_value": -0.23319217323497127, "biggest_recent_change": 3.243054125875773},
{ "step": 513, "visits": [3.0, 332.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 592, "q_vals": [-11.852, -9.836, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 514, "visits": [3.0, 333.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 593, "q_vals": [-11.852, -9.866, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 515, "visits": [3.0, 334.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 594, "q_vals": [-11.852, -9.86, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 516, "visits": [3.0, 335.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 594, "q_vals": [-11.852, -9.889, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 517, "visits": [3.0, 336.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 595, "q_vals": [-11.852, -9.884, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 518, "visits": [3.0, 337.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 599, "q_vals": [-11.852, -9.878, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 519, "visits": [3.0, 338.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 599, "q_vals": [-11.852, -9.872, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 520, "visits": [3.0, 339.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 599, "q_vals": [-11.852, -9.901, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 521, "visits": [3.0, 340.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 600, "q_vals": [-11.852, -9.872, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 602, "number_of_timesteps": 49100, "per_episode_reward": -173.44, "episode_reward_trend_value": -0.2601193053802869, "biggest_recent_change": 3.243054125875773},
{ "step": 522, "visits": [3.0, 341.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 602, "q_vals": [-11.852, -9.901, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 523, "visits": [3.0, 342.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 602, "q_vals": [-11.852, -9.895, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 524, "visits": [3.0, 343.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 603, "q_vals": [-11.852, -9.889, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 525, "visits": [3.0, 344.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 606, "q_vals": [-11.852, -9.918, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 526, "visits": [3.0, 345.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 608, "q_vals": [-11.852, -9.946, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 527, "visits": [3.0, 346.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 609, "q_vals": [-11.852, -9.94, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 528, "visits": [3.0, 347.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 610, "q_vals": [-11.852, -9.935, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 529, "visits": [3.0, 348.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 611, "q_vals": [-11.852, -9.929, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 530, "visits": [3.0, 349.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 611, "q_vals": [-11.852, -9.923, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 531, "visits": [3.0, 350.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 611, "q_vals": [-11.852, -9.917, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 612, "number_of_timesteps": 49931, "per_episode_reward": -176.45, "episode_reward_trend_value": -0.26441582834876715, "biggest_recent_change": 3.243054125875773},
{ "step": 532, "visits": [3.0, 351.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 612, "q_vals": [-11.852, -9.911, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 533, "visits": [3.0, 352.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 615, "q_vals": [-11.852, -9.939, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 534, "visits": [3.0, 353.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 617, "q_vals": [-11.852, -9.934, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 535, "visits": [3.0, 354.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 619, "q_vals": [-11.852, -9.928, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 536, "visits": [3.0, 355.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 620, "q_vals": [-11.852, -9.922, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 537, "visits": [3.0, 356.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 620, "q_vals": [-11.852, -9.916, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 538, "visits": [3.0, 357.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 621, "q_vals": [-11.852, -9.911, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 622, "number_of_timesteps": 50705, "per_episode_reward": -178.98, "episode_reward_trend_value": -0.259256165856088, "biggest_recent_change": 3.243054125875773},
{ "step": 539, "visits": [3.0, 358.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 622, "q_vals": [-11.852, -9.905, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 540, "visits": [3.0, 359.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 623, "q_vals": [-11.852, -9.9, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 541, "visits": [3.0, 360.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 627, "q_vals": [-11.852, -9.927, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 542, "visits": [3.0, 361.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 627, "q_vals": [-11.852, -9.921, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 543, "visits": [3.0, 362.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 628, "q_vals": [-11.852, -9.894, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 544, "visits": [3.0, 363.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 629, "q_vals": [-11.852, -9.921, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 545, "visits": [3.0, 364.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 631, "q_vals": [-11.852, -9.894, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 632, "number_of_timesteps": 51436, "per_episode_reward": -182.56, "episode_reward_trend_value": -0.2728967491455399, "biggest_recent_change": 3.5785447994037156},
{ "step": 546, "visits": [3.0, 365.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 632, "q_vals": [-11.852, -9.888, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 547, "visits": [3.0, 366.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 633, "q_vals": [-11.852, -9.883, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 548, "visits": [3.0, 367.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 633, "q_vals": [-11.852, -9.878, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 549, "visits": [3.0, 368.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 637, "q_vals": [-11.852, -9.851, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 550, "visits": [3.0, 369.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 638, "q_vals": [-11.852, -9.845, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 551, "visits": [3.0, 370.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 638, "q_vals": [-11.852, -9.872, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 552, "visits": [3.0, 371.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 639, "q_vals": [-11.852, -9.867, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 553, "visits": [3.0, 372.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 640, "q_vals": [-11.852, -9.862, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 554, "visits": [3.0, 373.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 640, "q_vals": [-11.852, -9.856, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 642, "number_of_timesteps": 52197, "per_episode_reward": -186.18, "episode_reward_trend_value": -0.29674657454576164, "biggest_recent_change": 3.6164155021953093},
{ "step": 555, "visits": [3.0, 374.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 642, "q_vals": [-11.852, -9.851, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 556, "visits": [3.0, 375.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 642, "q_vals": [-11.852, -9.846, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 557, "visits": [3.0, 376.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 645, "q_vals": [-11.852, -9.841, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 558, "visits": [3.0, 377.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 645, "q_vals": [-11.852, -9.867, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 559, "visits": [3.0, 378.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 646, "q_vals": [-11.852, -9.862, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 560, "visits": [3.0, 379.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 648, "q_vals": [-11.852, -9.857, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 561, "visits": [3.0, 380.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 648, "q_vals": [-11.852, -9.852, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 562, "visits": [3.0, 381.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 650, "q_vals": [-11.852, -9.846, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 563, "visits": [3.0, 382.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 650, "q_vals": [-11.852, -9.841, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 653, "number_of_timesteps": 53166, "per_episode_reward": -190.15, "episode_reward_trend_value": -0.3060879583257837, "biggest_recent_change": 3.974755764871901},
{ "step": 564, "visits": [3.0, 383.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 653, "q_vals": [-11.852, -9.816, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 565, "visits": [3.0, 384.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 653, "q_vals": [-11.852, -9.811, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 566, "visits": [3.0, 385.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 655, "q_vals": [-11.852, -9.806, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 567, "visits": [3.0, 386.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 655, "q_vals": [-11.852, -9.801, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 568, "visits": [3.0, 387.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 657, "q_vals": [-11.852, -9.796, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 569, "visits": [3.0, 388.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 658, "q_vals": [-11.852, -9.791, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 570, "visits": [3.0, 389.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 659, "q_vals": [-11.852, -9.766, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 571, "visits": [3.0, 390.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 659, "q_vals": [-11.852, -9.791, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 572, "visits": [3.0, 391.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 660, "q_vals": [-11.852, -9.817, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 573, "visits": [3.0, 392.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 661, "q_vals": [-11.852, -9.812, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 574, "visits": [3.0, 393.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 662, "q_vals": [-11.852, -9.807, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 667, "number_of_timesteps": 54335, "per_episode_reward": -196.3, "episode_reward_trend_value": -0.3383612239303365, "biggest_recent_change": 6.147648030285524},
{ "step": 575, "visits": [3.0, 394.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 667, "q_vals": [-11.852, -9.802, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 576, "visits": [3.0, 395.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 669, "q_vals": [-11.852, -9.798, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 577, "visits": [3.0, 396.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 669, "q_vals": [-11.852, -9.793, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 578, "visits": [3.0, 397.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 669, "q_vals": [-11.852, -9.818, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 579, "visits": [3.0, 398.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 670, "q_vals": [-11.852, -9.813, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 580, "visits": [3.0, 399.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 671, "q_vals": [-11.852, -9.808, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 581, "visits": [3.0, 400.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 673, "q_vals": [-11.852, -9.803, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
[-11.852, -9.799, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753]
{"total_number_of_episodes": 677, "number_of_timesteps": 54970, "per_episode_reward": -199.5, "episode_reward_trend_value": -0.35064107460688315, "biggest_recent_change": 6.147648030285524},
{ "step": 583, "visits": [3.0, 402.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 677, "q_vals": [-11.852, -9.823, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 584, "visits": [3.0, 403.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 679, "q_vals": [-11.852, -9.819, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 585, "visits": [3.0, 404.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 679, "q_vals": [-11.852, -9.814, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 586, "visits": [3.0, 405.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 679, "q_vals": [-11.852, -9.809, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 587, "visits": [3.0, 406.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 680, "q_vals": [-11.852, -9.805, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 588, "visits": [3.0, 407.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 682, "q_vals": [-11.852, -9.829, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 589, "visits": [3.0, 408.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 683, "q_vals": [-11.852, -9.853, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 590, "visits": [3.0, 409.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 686, "q_vals": [-11.852, -9.849, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 687, "number_of_timesteps": 55722, "per_episode_reward": -202.16, "episode_reward_trend_value": -0.3542243339881351, "biggest_recent_change": 6.147648030285524},
{ "step": 591, "visits": [3.0, 410.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 687, "q_vals": [-11.852, -9.873, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 592, "visits": [3.0, 411.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 688, "q_vals": [-11.852, -9.897, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 593, "visits": [3.0, 412.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 689, "q_vals": [-11.852, -9.892, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 594, "visits": [3.0, 413.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 689, "q_vals": [-11.852, -9.916, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 595, "visits": [3.0, 414.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 690, "q_vals": [-11.852, -9.939, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 596, "visits": [3.0, 415.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 690, "q_vals": [-11.852, -9.935, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 597, "visits": [3.0, 416.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 692, "q_vals": [-11.852, -9.93, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 598, "visits": [3.0, 417.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 695, "q_vals": [-11.852, -9.925, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 599, "visits": [3.0, 418.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 696, "q_vals": [-11.852, -9.92, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 697, "number_of_timesteps": 56536, "per_episode_reward": -205.05, "episode_reward_trend_value": -0.35118773567834327, "biggest_recent_change": 6.147648030285524},
{ "step": 600, "visits": [3.0, 419.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 697, "q_vals": [-11.852, -9.943, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 601, "visits": [3.0, 420.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 699, "q_vals": [-11.852, -9.939, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 602, "visits": [3.0, 421.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 700, "q_vals": [-11.852, -9.962, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 603, "visits": [3.0, 422.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 700, "q_vals": [-11.852, -9.957, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 604, "visits": [3.0, 423.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 701, "q_vals": [-11.852, -9.952, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 605, "visits": [3.0, 424.0, 3.0, 3.0, 5.0, 2.0, 118.0, 43.0, 3.0, 1.0] , "episode_count": 705, "q_vals": [-11.852, -9.975, -11.852, -13.853, -11.062, -13.827, -10.085, -10.364, -11.852, -19.753] }
{ "step": 606, "visits": [3.0, 424.0, 3.0, 3.0, 5.0, 2.0, 119.0, 43.0, 3.0, 1.0] , "episode_count": 705, "q_vals": [-11.852, -9.975, -11.852, -13.853, -11.062, -13.827, -10.066, -10.364, -11.852, -19.753] }
{ "step": 607, "visits": [3.0, 424.0, 3.0, 3.0, 5.0, 2.0, 120.0, 43.0, 3.0, 1.0] , "episode_count": 706, "q_vals": [-11.852, -9.975, -11.852, -13.853, -11.062, -13.827, -10.048, -10.364, -11.852, -19.753] }
{ "step": 608, "visits": [3.0, 424.0, 3.0, 3.0, 5.0, 2.0, 121.0, 43.0, 3.0, 1.0] , "episode_count": 706, "q_vals": [-11.852, -9.975, -11.852, -13.853, -11.062, -13.827, -10.031, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 707, "number_of_timesteps": 57277, "per_episode_reward": -207.76, "episode_reward_trend_value": -0.347881439625852, "biggest_recent_change": 6.147648030285524},
{ "step": 609, "visits": [3.0, 424.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 707, "q_vals": [-11.852, -9.975, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 610, "visits": [3.0, 425.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 708, "q_vals": [-11.852, -9.97, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 611, "visits": [3.0, 426.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 709, "q_vals": [-11.852, -9.966, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 612, "visits": [3.0, 427.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 712, "q_vals": [-11.852, -9.961, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 613, "visits": [3.0, 428.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 712, "q_vals": [-11.852, -9.984, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 614, "visits": [3.0, 429.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 714, "q_vals": [-11.852, -9.979, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 615, "visits": [3.0, 430.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 714, "q_vals": [-11.852, -9.974, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 616, "visits": [3.0, 431.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 716, "q_vals": [-11.852, -9.969, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 717, "number_of_timesteps": 58150, "per_episode_reward": -210.13, "episode_reward_trend_value": -0.3461392423806773, "biggest_recent_change": 6.147648030285524},
{ "step": 617, "visits": [3.0, 432.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 717, "q_vals": [-11.852, -9.964, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 618, "visits": [3.0, 433.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 719, "q_vals": [-11.852, -9.987, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 619, "visits": [3.0, 434.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 720, "q_vals": [-11.852, -9.982, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 620, "visits": [3.0, 435.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 722, "q_vals": [-11.852, -9.977, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 621, "visits": [3.0, 436.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 722, "q_vals": [-11.852, -10.0, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 622, "visits": [3.0, 437.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 722, "q_vals": [-11.852, -9.977, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 623, "visits": [3.0, 438.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 723, "q_vals": [-11.852, -9.972, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 624, "visits": [3.0, 439.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 726, "q_vals": [-11.852, -9.994, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 728, "number_of_timesteps": 58974, "per_episode_reward": -213.37, "episode_reward_trend_value": -0.34229053854657915, "biggest_recent_change": 6.147648030285524},
{ "step": 625, "visits": [3.0, 440.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 728, "q_vals": [-11.852, -9.972, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 626, "visits": [3.0, 441.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 729, "q_vals": [-11.852, -9.994, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 627, "visits": [3.0, 442.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 729, "q_vals": [-11.852, -9.989, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 628, "visits": [3.0, 443.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 731, "q_vals": [-11.852, -9.984, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 629, "visits": [3.0, 444.0, 3.0, 3.0, 5.0, 2.0, 122.0, 43.0, 3.0, 1.0] , "episode_count": 731, "q_vals": [-11.852, -10.006, -11.852, -13.853, -11.062, -13.827, -10.11, -10.364, -11.852, -19.753] }
{ "step": 630, "visits": [3.0, 444.0, 3.0, 3.0, 5.0, 2.0, 123.0, 43.0, 3.0, 1.0] , "episode_count": 733, "q_vals": [-11.852, -10.006, -11.852, -13.853, -11.062, -13.827, -10.092, -10.364, -11.852, -19.753] }
{ "step": 631, "visits": [3.0, 444.0, 3.0, 3.0, 5.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 733, "q_vals": [-11.852, -10.006, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 632, "visits": [3.0, 445.0, 3.0, 3.0, 5.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 734, "q_vals": [-11.852, -10.028, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 633, "visits": [3.0, 446.0, 3.0, 3.0, 5.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 737, "q_vals": [-11.852, -10.024, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 738, "number_of_timesteps": 59775, "per_episode_reward": -218.32, "episode_reward_trend_value": -0.3571578020952163, "biggest_recent_change": 6.147648030285524},
{ "step": 634, "visits": [3.0, 447.0, 3.0, 3.0, 5.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 738, "q_vals": [-11.852, -10.019, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 635, "visits": [3.0, 448.0, 3.0, 3.0, 5.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 740, "q_vals": [-11.852, -10.014, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 636, "visits": [3.0, 449.0, 3.0, 3.0, 5.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 741, "q_vals": [-11.852, -10.009, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 637, "visits": [3.0, 450.0, 3.0, 3.0, 5.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 741, "q_vals": [-11.852, -10.031, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 638, "visits": [3.0, 451.0, 3.0, 3.0, 5.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 742, "q_vals": [-11.852, -10.026, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 639, "visits": [3.0, 452.0, 3.0, 3.0, 5.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 743, "q_vals": [-11.852, -10.022, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 640, "visits": [3.0, 453.0, 3.0, 3.0, 5.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 743, "q_vals": [-11.852, -10.017, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 641, "visits": [3.0, 454.0, 3.0, 3.0, 5.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 745, "q_vals": [-11.852, -10.038, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 642, "visits": [3.0, 455.0, 3.0, 3.0, 5.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 747, "q_vals": [-11.852, -10.034, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 748, "number_of_timesteps": 60576, "per_episode_reward": -223.53, "episode_reward_trend_value": -0.3708848829136801, "biggest_recent_change": 6.147648030285524},
{ "step": 643, "visits": [3.0, 456.0, 3.0, 3.0, 5.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 748, "q_vals": [-11.852, -10.029, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 644, "visits": [3.0, 457.0, 3.0, 3.0, 5.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 749, "q_vals": [-11.852, -10.024, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753] }
[-11.852, -10.046, -11.852, -13.853, -11.062, -13.827, -10.17, -10.364, -11.852, -19.753]
{ "step": 646, "visits": [3.0, 458.0, 3.0, 3.0, 6.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 751, "q_vals": [-11.852, -10.046, -11.852, -13.853, -12.51, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 647, "visits": [3.0, 459.0, 3.0, 3.0, 6.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 752, "q_vals": [-11.852, -10.041, -11.852, -13.853, -12.51, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 648, "visits": [3.0, 460.0, 3.0, 3.0, 6.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 752, "q_vals": [-11.852, -10.036, -11.852, -13.853, -12.51, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 649, "visits": [3.0, 461.0, 3.0, 3.0, 6.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 754, "q_vals": [-11.852, -10.032, -11.852, -13.853, -12.51, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 650, "visits": [3.0, 462.0, 3.0, 3.0, 6.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 755, "q_vals": [-11.852, -10.027, -11.852, -13.853, -12.51, -13.827, -10.17, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 758, "number_of_timesteps": 61426, "per_episode_reward": -226.52, "episode_reward_trend_value": -0.33579038784139986, "biggest_recent_change": 5.210193038533646},
{ "step": 651, "visits": [3.0, 463.0, 3.0, 3.0, 6.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 758, "q_vals": [-11.852, -10.048, -11.852, -13.853, -12.51, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 652, "visits": [3.0, 464.0, 3.0, 3.0, 6.0, 2.0, 124.0, 43.0, 3.0, 1.0] , "episode_count": 758, "q_vals": [-11.852, -10.069, -11.852, -13.853, -12.51, -13.827, -10.17, -10.364, -11.852, -19.753] }
{ "step": 653, "visits": [3.0, 464.0, 3.0, 3.0, 6.0, 2.0, 125.0, 43.0, 3.0, 1.0] , "episode_count": 758, "q_vals": [-11.852, -10.069, -11.852, -13.853, -12.51, -13.827, -10.152, -10.364, -11.852, -19.753] }
{ "step": 654, "visits": [3.0, 464.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 758, "q_vals": [-11.852, -10.069, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 655, "visits": [3.0, 465.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 759, "q_vals": [-11.852, -10.047, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 656, "visits": [3.0, 466.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 760, "q_vals": [-11.852, -10.043, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 657, "visits": [3.0, 467.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 761, "q_vals": [-11.852, -10.038, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 658, "visits": [3.0, 468.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 765, "q_vals": [-11.852, -10.034, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 659, "visits": [3.0, 469.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 766, "q_vals": [-11.852, -10.029, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 768, "number_of_timesteps": 62338, "per_episode_reward": -229.18, "episode_reward_trend_value": -0.3298679203382155, "biggest_recent_change": 5.210193038533646},
{ "step": 660, "visits": [3.0, 470.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 768, "q_vals": [-11.852, -10.024, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 661, "visits": [3.0, 471.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 768, "q_vals": [-11.852, -10.02, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 662, "visits": [3.0, 472.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 768, "q_vals": [-11.852, -10.015, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 663, "visits": [3.0, 473.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 769, "q_vals": [-11.852, -10.011, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 664, "visits": [3.0, 474.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 769, "q_vals": [-11.852, -10.007, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 665, "visits": [3.0, 475.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 769, "q_vals": [-11.852, -10.002, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 666, "visits": [3.0, 476.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 772, "q_vals": [-11.852, -9.998, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 667, "visits": [3.0, 477.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 774, "q_vals": [-11.852, -9.993, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 778, "number_of_timesteps": 63157, "per_episode_reward": -235.74, "episode_reward_trend_value": -0.373122043776276, "biggest_recent_change": 6.556827335938408},
{ "step": 668, "visits": [3.0, 478.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 778, "q_vals": [-11.852, -9.989, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 669, "visits": [3.0, 479.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 778, "q_vals": [-11.852, -9.985, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 670, "visits": [3.0, 480.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 778, "q_vals": [-11.852, -9.98, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 671, "visits": [3.0, 481.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 778, "q_vals": [-11.852, -9.959, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 672, "visits": [3.0, 482.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 780, "q_vals": [-11.852, -9.955, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 673, "visits": [3.0, 483.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 781, "q_vals": [-11.852, -9.951, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 674, "visits": [3.0, 484.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 781, "q_vals": [-11.852, -9.947, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 675, "visits": [3.0, 485.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 784, "q_vals": [-11.852, -9.943, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 676, "visits": [3.0, 486.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 787, "q_vals": [-11.852, -9.922, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 788, "number_of_timesteps": 63927, "per_episode_reward": -242.28, "episode_reward_trend_value": -0.41370556062790564, "biggest_recent_change": 6.556827335938408},
{ "step": 677, "visits": [3.0, 487.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 788, "q_vals": [-11.852, -9.942, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 678, "visits": [3.0, 488.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 788, "q_vals": [-11.852, -9.938, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 679, "visits": [3.0, 489.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 788, "q_vals": [-11.852, -9.934, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 680, "visits": [3.0, 490.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 790, "q_vals": [-11.852, -9.93, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 681, "visits": [3.0, 491.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 791, "q_vals": [-11.852, -9.926, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 682, "visits": [3.0, 492.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 792, "q_vals": [-11.852, -9.921, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 683, "visits": [3.0, 493.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 793, "q_vals": [-11.852, -9.917, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 684, "visits": [3.0, 494.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 793, "q_vals": [-11.852, -9.913, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 685, "visits": [3.0, 495.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 795, "q_vals": [-11.852, -9.909, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 798, "number_of_timesteps": 64715, "per_episode_reward": -249.41, "episode_reward_trend_value": -0.46279361927698925, "biggest_recent_change": 7.122722414456518},
{ "step": 686, "visits": [3.0, 496.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 798, "q_vals": [-11.852, -9.929, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 687, "visits": [3.0, 497.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 799, "q_vals": [-11.852, -9.925, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 688, "visits": [3.0, 498.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 800, "q_vals": [-11.852, -9.945, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 689, "visits": [3.0, 499.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 801, "q_vals": [-11.852, -9.941, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 690, "visits": [3.0, 500.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 801, "q_vals": [-11.852, -9.96, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 691, "visits": [3.0, 501.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 801, "q_vals": [-11.852, -9.956, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 692, "visits": [3.0, 502.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 802, "q_vals": [-11.852, -9.952, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 693, "visits": [3.0, 503.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 802, "q_vals": [-11.852, -9.948, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 694, "visits": [3.0, 504.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 807, "q_vals": [-11.852, -9.967, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 695, "visits": [3.0, 505.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 807, "q_vals": [-11.852, -9.963, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 696, "visits": [3.0, 506.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 807, "q_vals": [-11.852, -9.959, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 697, "visits": [3.0, 507.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 807, "q_vals": [-11.852, -9.94, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 811, "number_of_timesteps": 65881, "per_episode_reward": -255.49, "episode_reward_trend_value": -0.5039886849454013, "biggest_recent_change": 7.122722414456518},
{ "step": 698, "visits": [3.0, 508.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 811, "q_vals": [-11.852, -9.959, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 699, "visits": [3.0, 509.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 812, "q_vals": [-11.852, -9.955, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 700, "visits": [3.0, 510.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 812, "q_vals": [-11.852, -9.974, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 701, "visits": [3.0, 511.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 812, "q_vals": [-11.852, -9.97, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 702, "visits": [3.0, 512.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 814, "q_vals": [-11.852, -9.989, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 703, "visits": [3.0, 513.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 814, "q_vals": [-11.852, -9.985, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 704, "visits": [3.0, 514.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 817, "q_vals": [-11.852, -9.981, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 705, "visits": [3.0, 515.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 818, "q_vals": [-11.852, -10.0, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 821, "number_of_timesteps": 66678, "per_episode_reward": -258.4, "episode_reward_trend_value": -0.500385050789975, "biggest_recent_change": 7.122722414456518},
{ "step": 706, "visits": [3.0, 516.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 821, "q_vals": [-11.852, -9.981, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 707, "visits": [3.0, 517.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 822, "q_vals": [-11.852, -9.977, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 708, "visits": [3.0, 518.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 822, "q_vals": [-11.852, -9.995, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 709, "visits": [3.0, 519.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 823, "q_vals": [-11.852, -9.991, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 710, "visits": [3.0, 520.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 824, "q_vals": [-11.852, -9.987, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 711, "visits": [3.0, 521.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 826, "q_vals": [-11.852, -9.983, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 712, "visits": [3.0, 522.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 826, "q_vals": [-11.852, -9.979, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 713, "visits": [3.0, 523.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 828, "q_vals": [-11.852, -9.975, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 714, "visits": [3.0, 524.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 828, "q_vals": [-11.852, -9.972, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 715, "visits": [3.0, 525.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 829, "q_vals": [-11.852, -9.968, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 831, "number_of_timesteps": 67458, "per_episode_reward": -258.83, "episode_reward_trend_value": -0.4501144879940632, "biggest_recent_change": 7.122722414456518},
{ "step": 716, "visits": [3.0, 526.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 831, "q_vals": [-11.852, -9.964, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 717, "visits": [3.0, 527.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 832, "q_vals": [-11.852, -9.945, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 718, "visits": [3.0, 528.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 833, "q_vals": [-11.852, -9.941, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 719, "visits": [3.0, 529.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 833, "q_vals": [-11.852, -9.937, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 720, "visits": [3.0, 530.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 834, "q_vals": [-11.852, -9.956, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 721, "visits": [3.0, 531.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 834, "q_vals": [-11.852, -9.974, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 722, "visits": [3.0, 532.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 836, "q_vals": [-11.852, -9.97, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 723, "visits": [3.0, 533.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 836, "q_vals": [-11.852, -9.988, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 724, "visits": [3.0, 534.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 836, "q_vals": [-11.852, -10.007, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 725, "visits": [3.0, 535.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 836, "q_vals": [-11.852, -9.988, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 726, "visits": [3.0, 536.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 838, "q_vals": [-11.852, -9.981, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 727, "visits": [3.0, 537.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 838, "q_vals": [-11.852, -9.978, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 728, "visits": [3.0, 538.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 840, "q_vals": [-11.852, -9.996, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 729, "visits": [3.0, 539.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 840, "q_vals": [-11.852, -9.992, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 730, "visits": [3.0, 540.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 840, "q_vals": [-11.852, -9.973, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 841, "number_of_timesteps": 68534, "per_episode_reward": -258.59, "episode_reward_trend_value": -0.38953379030746316, "biggest_recent_change": 7.122722414456518},
{ "step": 731, "visits": [3.0, 541.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 841, "q_vals": [-11.852, -9.969, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 732, "visits": [3.0, 542.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 841, "q_vals": [-11.852, -9.988, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 733, "visits": [3.0, 543.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 842, "q_vals": [-11.852, -9.984, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 734, "visits": [3.0, 544.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 843, "q_vals": [-11.852, -9.98, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 735, "visits": [3.0, 545.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 843, "q_vals": [-11.852, -9.962, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 736, "visits": [3.0, 546.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 844, "q_vals": [-11.852, -9.958, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 737, "visits": [3.0, 547.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 845, "q_vals": [-11.852, -9.954, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 738, "visits": [3.0, 548.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 846, "q_vals": [-11.852, -9.936, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 739, "visits": [3.0, 549.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 847, "q_vals": [-11.852, -9.932, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 740, "visits": [3.0, 550.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 848, "q_vals": [-11.852, -9.928, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 741, "visits": [3.0, 551.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 849, "q_vals": [-11.852, -9.925, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 851, "number_of_timesteps": 69932, "per_episode_reward": -262.66, "episode_reward_trend_value": -0.4015633553590659, "biggest_recent_change": 7.122722414456518},
{ "step": 742, "visits": [3.0, 552.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 851, "q_vals": [-11.852, -9.943, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 743, "visits": [3.0, 553.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 852, "q_vals": [-11.852, -9.939, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 744, "visits": [3.0, 554.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 852, "q_vals": [-11.852, -9.957, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 745, "visits": [3.0, 555.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 852, "q_vals": [-11.852, -9.953, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 746, "visits": [3.0, 556.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 853, "q_vals": [-11.852, -9.949, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 747, "visits": [3.0, 557.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 854, "q_vals": [-11.852, -9.946, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 748, "visits": [3.0, 558.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 855, "q_vals": [-11.852, -9.942, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 749, "visits": [3.0, 559.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 857, "q_vals": [-11.852, -9.959, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 750, "visits": [3.0, 560.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 857, "q_vals": [-11.852, -9.956, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 751, "visits": [3.0, 561.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 858, "q_vals": [-11.852, -9.952, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 752, "visits": [3.0, 562.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 858, "q_vals": [-11.852, -9.948, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 753, "visits": [3.0, 563.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 858, "q_vals": [-11.852, -9.945, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 754, "visits": [3.0, 564.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 858, "q_vals": [-11.852, -9.941, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 755, "visits": [3.0, 565.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 858, "q_vals": [-11.852, -9.924, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 756, "visits": [3.0, 566.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 859, "q_vals": [-11.852, -9.906, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 757, "visits": [3.0, 567.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 859, "q_vals": [-11.852, -9.903, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 758, "visits": [3.0, 568.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 860, "q_vals": [-11.852, -9.899, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 861, "number_of_timesteps": 71082, "per_episode_reward": -268.5, "episode_reward_trend_value": -0.4368638998868025, "biggest_recent_change": 7.122722414456518},
{ "step": 759, "visits": [3.0, 569.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 861, "q_vals": [-11.852, -9.895, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 760, "visits": [3.0, 570.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 862, "q_vals": [-11.852, -9.878, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 761, "visits": [3.0, 571.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 863, "q_vals": [-11.852, -9.895, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 762, "visits": [3.0, 572.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 864, "q_vals": [-11.852, -9.892, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 763, "visits": [3.0, 573.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 864, "q_vals": [-11.852, -9.888, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 764, "visits": [3.0, 574.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 867, "q_vals": [-11.852, -9.906, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 765, "visits": [3.0, 575.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 867, "q_vals": [-11.852, -9.923, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 766, "visits": [3.0, 576.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 868, "q_vals": [-11.852, -9.919, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 767, "visits": [3.0, 577.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 868, "q_vals": [-11.852, -9.916, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 768, "visits": [3.0, 578.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 869, "q_vals": [-11.852, -9.912, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 769, "visits": [3.0, 579.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 869, "q_vals": [-11.852, -9.909, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 770, "visits": [3.0, 580.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 869, "q_vals": [-11.852, -9.905, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 771, "visits": [3.0, 581.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 870, "q_vals": [-11.852, -9.902, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 871, "number_of_timesteps": 72510, "per_episode_reward": -274.48, "episode_reward_trend_value": -0.4304278120976631, "biggest_recent_change": 7.122722414456518},
{ "step": 772, "visits": [3.0, 582.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 871, "q_vals": [-11.852, -9.919, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 773, "visits": [3.0, 583.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 871, "q_vals": [-11.852, -9.915, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 774, "visits": [3.0, 584.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 871, "q_vals": [-11.852, -9.932, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 775, "visits": [3.0, 585.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 871, "q_vals": [-11.852, -9.949, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 776, "visits": [3.0, 586.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 872, "q_vals": [-11.852, -9.945, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 777, "visits": [3.0, 587.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 873, "q_vals": [-11.852, -9.942, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 778, "visits": [3.0, 588.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 873, "q_vals": [-11.852, -9.939, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 779, "visits": [3.0, 589.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 875, "q_vals": [-11.852, -9.935, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 780, "visits": [3.0, 590.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 877, "q_vals": [-11.852, -9.932, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 781, "visits": [3.0, 591.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 880, "q_vals": [-11.852, -9.948, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 782, "visits": [3.0, 592.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 880, "q_vals": [-11.852, -9.931, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 783, "visits": [3.0, 593.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 880, "q_vals": [-11.852, -9.948, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 784, "visits": [3.0, 594.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 880, "q_vals": [-11.852, -9.931, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 785, "visits": [3.0, 595.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 880, "q_vals": [-11.852, -9.928, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 881, "number_of_timesteps": 73936, "per_episode_reward": -277.49, "episode_reward_trend_value": -0.39120820617223667, "biggest_recent_change": 7.122722414456518},
{ "step": 786, "visits": [3.0, 596.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 881, "q_vals": [-11.852, -9.924, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 787, "visits": [3.0, 597.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 883, "q_vals": [-11.852, -9.921, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 788, "visits": [3.0, 598.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 883, "q_vals": [-11.852, -9.904, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 789, "visits": [3.0, 599.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 884, "q_vals": [-11.852, -9.888, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 790, "visits": [3.0, 600.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 886, "q_vals": [-11.852, -9.885, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 791, "visits": [3.0, 601.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 886, "q_vals": [-11.852, -9.868, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 792, "visits": [3.0, 602.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 886, "q_vals": [-11.852, -9.852, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 793, "visits": [3.0, 603.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 888, "q_vals": [-11.852, -9.849, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 794, "visits": [3.0, 604.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 888, "q_vals": [-11.852, -9.832, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 795, "visits": [3.0, 605.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 889, "q_vals": [-11.852, -9.816, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 796, "visits": [3.0, 606.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 889, "q_vals": [-11.852, -9.813, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 797, "visits": [3.0, 607.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 890, "q_vals": [-11.852, -9.797, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 892, "number_of_timesteps": 74955, "per_episode_reward": -281.62, "episode_reward_trend_value": -0.35789302133105677, "biggest_recent_change": 6.085491799357584},
{ "step": 798, "visits": [3.0, 608.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 892, "q_vals": [-11.852, -9.781, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 799, "visits": [3.0, 609.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 892, "q_vals": [-11.852, -9.777, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 800, "visits": [3.0, 610.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 893, "q_vals": [-11.852, -9.794, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 801, "visits": [3.0, 611.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 894, "q_vals": [-11.852, -9.778, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 802, "visits": [3.0, 612.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 895, "q_vals": [-11.852, -9.775, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 803, "visits": [3.0, 613.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 897, "q_vals": [-11.852, -9.772, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 804, "visits": [3.0, 614.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 897, "q_vals": [-11.852, -9.769, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 805, "visits": [3.0, 615.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 898, "q_vals": [-11.852, -9.753, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 806, "visits": [3.0, 616.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 899, "q_vals": [-11.852, -9.75, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 807, "visits": [3.0, 617.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 899, "q_vals": [-11.852, -9.766, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 808, "visits": [3.0, 618.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 900, "q_vals": [-11.852, -9.763, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 902, "number_of_timesteps": 76408, "per_episode_reward": -285.06, "episode_reward_trend_value": -0.32857678759025044, "biggest_recent_change": 5.977579434915867},
{ "step": 809, "visits": [3.0, 619.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 902, "q_vals": [-11.852, -9.779, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 810, "visits": [3.0, 620.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 902, "q_vals": [-11.852, -9.776, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 811, "visits": [3.0, 621.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 902, "q_vals": [-11.852, -9.792, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 812, "visits": [3.0, 622.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 903, "q_vals": [-11.852, -9.789, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 813, "visits": [3.0, 623.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 904, "q_vals": [-11.852, -9.805, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 814, "visits": [3.0, 624.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 905, "q_vals": [-11.852, -9.802, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 815, "visits": [3.0, 625.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 905, "q_vals": [-11.852, -9.799, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 816, "visits": [3.0, 626.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 905, "q_vals": [-11.852, -9.796, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 817, "visits": [3.0, 627.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 905, "q_vals": [-11.852, -9.812, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 818, "visits": [3.0, 628.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 907, "q_vals": [-11.852, -9.809, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 819, "visits": [3.0, 629.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 908, "q_vals": [-11.852, -9.825, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 820, "visits": [3.0, 630.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 910, "q_vals": [-11.852, -9.822, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 821, "visits": [3.0, 631.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 911, "q_vals": [-11.852, -9.818, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 912, "number_of_timesteps": 77600, "per_episode_reward": -290.49, "episode_reward_trend_value": -0.356532356078195, "biggest_recent_change": 5.977579434915867},
{ "step": 822, "visits": [3.0, 632.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 912, "q_vals": [-11.852, -9.815, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 823, "visits": [3.0, 633.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 912, "q_vals": [-11.852, -9.831, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 824, "visits": [3.0, 634.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 913, "q_vals": [-11.852, -9.828, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 825, "visits": [3.0, 635.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 913, "q_vals": [-11.852, -9.825, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 826, "visits": [3.0, 636.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 913, "q_vals": [-11.852, -9.822, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 827, "visits": [3.0, 637.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 915, "q_vals": [-11.852, -9.819, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 828, "visits": [3.0, 638.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 915, "q_vals": [-11.852, -9.835, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 829, "visits": [3.0, 639.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 916, "q_vals": [-11.852, -9.832, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 830, "visits": [3.0, 640.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 917, "q_vals": [-11.852, -9.847, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 831, "visits": [3.0, 641.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 919, "q_vals": [-11.852, -9.844, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 832, "visits": [3.0, 642.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 919, "q_vals": [-11.852, -9.841, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 833, "visits": [3.0, 643.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 920, "q_vals": [-11.852, -9.838, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 834, "visits": [3.0, 644.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 920, "q_vals": [-11.852, -9.835, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 922, "number_of_timesteps": 78855, "per_episode_reward": -299.99, "episode_reward_trend_value": -0.4573340870122403, "biggest_recent_change": 9.502274354004669},
{ "step": 835, "visits": [3.0, 645.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 922, "q_vals": [-11.852, -9.82, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 836, "visits": [3.0, 646.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 922, "q_vals": [-11.852, -9.835, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 837, "visits": [3.0, 647.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 922, "q_vals": [-11.852, -9.832, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 838, "visits": [3.0, 648.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 923, "q_vals": [-11.852, -9.829, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 839, "visits": [3.0, 649.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 923, "q_vals": [-11.852, -9.826, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 840, "visits": [3.0, 650.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 923, "q_vals": [-11.852, -9.823, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 841, "visits": [3.0, 651.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 923, "q_vals": [-11.852, -9.82, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 842, "visits": [3.0, 652.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 924, "q_vals": [-11.852, -9.817, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 843, "visits": [3.0, 653.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 925, "q_vals": [-11.852, -9.814, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 844, "visits": [3.0, 654.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 926, "q_vals": [-11.852, -9.811, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 845, "visits": [3.0, 655.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 927, "q_vals": [-11.852, -9.809, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 846, "visits": [3.0, 656.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 929, "q_vals": [-11.852, -9.806, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 847, "visits": [3.0, 657.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 929, "q_vals": [-11.852, -9.803, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 848, "visits": [3.0, 658.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 930, "q_vals": [-11.852, -9.8, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 849, "visits": [3.0, 659.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 930, "q_vals": [-11.852, -9.797, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 850, "visits": [3.0, 660.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 931, "q_vals": [-11.852, -9.794, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 851, "visits": [3.0, 661.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 931, "q_vals": [-11.852, -9.791, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 852, "visits": [3.0, 662.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 931, "q_vals": [-11.852, -9.788, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 932, "number_of_timesteps": 80216, "per_episode_reward": -305.31, "episode_reward_trend_value": -0.5191594620299775, "biggest_recent_change": 9.502274354004669},
{ "step": 853, "visits": [3.0, 663.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 932, "q_vals": [-11.852, -9.786, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 854, "visits": [3.0, 664.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 932, "q_vals": [-11.852, -9.771, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 855, "visits": [3.0, 665.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 932, "q_vals": [-11.852, -9.768, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 856, "visits": [3.0, 666.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 933, "q_vals": [-11.852, -9.765, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 857, "visits": [3.0, 667.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 936, "q_vals": [-11.852, -9.78, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 858, "visits": [3.0, 668.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 938, "q_vals": [-11.852, -9.777, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 859, "visits": [3.0, 669.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 938, "q_vals": [-11.852, -9.792, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 860, "visits": [3.0, 670.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 939, "q_vals": [-11.852, -9.807, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 861, "visits": [3.0, 671.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 940, "q_vals": [-11.852, -9.804, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 862, "visits": [3.0, 672.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 940, "q_vals": [-11.852, -9.819, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 863, "visits": [3.0, 673.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 941, "q_vals": [-11.852, -9.816, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 942, "number_of_timesteps": 81706, "per_episode_reward": -308.87, "episode_reward_trend_value": -0.5134588226420975, "biggest_recent_change": 9.502274354004669},
{ "step": 864, "visits": [3.0, 674.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 942, "q_vals": [-11.852, -9.831, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 865, "visits": [3.0, 675.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 942, "q_vals": [-11.852, -9.846, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 866, "visits": [3.0, 676.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 942, "q_vals": [-11.852, -9.86, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 867, "visits": [3.0, 677.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 942, "q_vals": [-11.852, -9.857, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 868, "visits": [3.0, 678.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 944, "q_vals": [-11.852, -9.855, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 869, "visits": [3.0, 679.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 946, "q_vals": [-11.852, -9.852, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 870, "visits": [3.0, 680.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 947, "q_vals": [-11.852, -9.866, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 871, "visits": [3.0, 681.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 947, "q_vals": [-11.852, -9.863, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 872, "visits": [3.0, 682.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 948, "q_vals": [-11.852, -9.86, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 873, "visits": [3.0, 683.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 948, "q_vals": [-11.852, -9.875, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 874, "visits": [3.0, 684.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 950, "q_vals": [-11.852, -9.872, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
[3.0, 685.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0]  episode_count: 951 q_vals: [-11.852, -9.869, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753]
{"total_number_of_episodes": 952, "number_of_timesteps": 82879, "per_episode_reward": -311.82, "episode_reward_trend_value": -0.48133774125427004, "biggest_recent_change": 9.502274354004669},
{ "step": 876, "visits": [3.0, 686.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 952, "q_vals": [-11.852, -9.866, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 877, "visits": [3.0, 687.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 953, "q_vals": [-11.852, -9.881, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 878, "visits": [3.0, 688.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 953, "q_vals": [-11.852, -9.878, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 879, "visits": [3.0, 689.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 955, "q_vals": [-11.852, -9.892, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 880, "visits": [3.0, 690.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 956, "q_vals": [-11.852, -9.889, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 881, "visits": [3.0, 691.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 959, "q_vals": [-11.852, -9.904, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 882, "visits": [3.0, 692.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 959, "q_vals": [-11.852, -9.901, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 883, "visits": [3.0, 693.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 959, "q_vals": [-11.852, -9.898, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 884, "visits": [3.0, 694.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 960, "q_vals": [-11.852, -9.895, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 885, "visits": [3.0, 695.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 961, "q_vals": [-11.852, -9.892, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 962, "number_of_timesteps": 83784, "per_episode_reward": -314.45, "episode_reward_trend_value": -0.44411009502803533, "biggest_recent_change": 9.502274354004669},
{ "step": 886, "visits": [3.0, 696.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 962, "q_vals": [-11.852, -9.889, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 887, "visits": [3.0, 697.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 964, "q_vals": [-11.852, -9.886, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 888, "visits": [3.0, 698.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 965, "q_vals": [-11.852, -9.883, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 889, "visits": [3.0, 699.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 967, "q_vals": [-11.852, -9.881, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 890, "visits": [3.0, 700.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 969, "q_vals": [-11.852, -9.895, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 891, "visits": [3.0, 701.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 970, "q_vals": [-11.852, -9.892, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 892, "visits": [3.0, 702.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 970, "q_vals": [-11.852, -9.889, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 972, "number_of_timesteps": 84574, "per_episode_reward": -319.6, "episode_reward_trend_value": -0.46788243730438683, "biggest_recent_change": 9.502274354004669},
{ "step": 893, "visits": [3.0, 703.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 972, "q_vals": [-11.852, -9.886, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 894, "visits": [3.0, 704.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 975, "q_vals": [-11.852, -9.9, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 895, "visits": [3.0, 705.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 975, "q_vals": [-11.852, -9.897, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 896, "visits": [3.0, 706.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 976, "q_vals": [-11.852, -9.895, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 897, "visits": [3.0, 707.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 976, "q_vals": [-11.852, -9.892, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 898, "visits": [3.0, 708.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 976, "q_vals": [-11.852, -9.878, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 899, "visits": [3.0, 709.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 980, "q_vals": [-11.852, -9.892, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 982, "number_of_timesteps": 85319, "per_episode_reward": -322.34, "episode_reward_trend_value": -0.4525239935559461, "biggest_recent_change": 9.502274354004669},
{ "step": 900, "visits": [3.0, 710.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 982, "q_vals": [-11.852, -9.906, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 901, "visits": [3.0, 711.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 983, "q_vals": [-11.852, -9.903, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 902, "visits": [3.0, 712.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 983, "q_vals": [-11.852, -9.889, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 903, "visits": [3.0, 713.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 985, "q_vals": [-11.852, -9.903, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 904, "visits": [3.0, 714.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 986, "q_vals": [-11.852, -9.9, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 905, "visits": [3.0, 715.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 986, "q_vals": [-11.852, -9.914, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 906, "visits": [3.0, 716.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 988, "q_vals": [-11.852, -9.911, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
visits [3.0, 717.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0]  episode_count: 989 q_vals: [-11.852, -9.897, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753]
{ "step": 908, "visits": [3.0, 718.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 990, "q_vals": [-11.852, -9.894, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 993, "number_of_timesteps": 86171, "per_episode_reward": -325.43, "episode_reward_trend_value": -0.4485264680128441, "biggest_recent_change": 9.502274354004669},
{ "step": 909, "visits": [3.0, 719.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 993, "q_vals": [-11.852, -9.892, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 910, "visits": [3.0, 720.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 993, "q_vals": [-11.852, -9.889, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 911, "visits": [3.0, 721.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 994, "q_vals": [-11.852, -9.902, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 912, "visits": [3.0, 722.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 996, "q_vals": [-11.852, -9.9, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 913, "visits": [3.0, 723.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 997, "q_vals": [-11.852, -9.897, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 914, "visits": [3.0, 724.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 999, "q_vals": [-11.852, -9.894, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 915, "visits": [3.0, 725.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1000, "q_vals": [-11.852, -9.908, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 916, "visits": [3.0, 726.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1001, "q_vals": [-11.852, -9.905, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 917, "visits": [3.0, 727.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1001, "q_vals": [-11.852, -9.919, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 918, "visits": [3.0, 728.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1002, "q_vals": [-11.852, -9.916, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 1003, "number_of_timesteps": 86899, "per_episode_reward": -327.82, "episode_reward_trend_value": -0.4147934350820145, "biggest_recent_change": 9.502274354004669},
{ "step": 919, "visits": [3.0, 729.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1003, "q_vals": [-11.852, -9.913, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 920, "visits": [3.0, 730.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1005, "q_vals": [-11.852, -9.91, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 921, "visits": [3.0, 731.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1007, "q_vals": [-11.852, -9.907, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 922, "visits": [3.0, 732.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1010, "q_vals": [-11.852, -9.921, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 923, "visits": [3.0, 733.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1010, "q_vals": [-11.852, -9.934, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 924, "visits": [3.0, 734.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1011, "q_vals": [-11.852, -9.932, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 925, "visits": [3.0, 735.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1012, "q_vals": [-11.852, -9.945, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 1014, "number_of_timesteps": 87686, "per_episode_reward": -332.48, "episode_reward_trend_value": -0.36103608203196635, "biggest_recent_change": 5.322213998335997},
{ "step": 926, "visits": [3.0, 736.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1014, "q_vals": [-11.852, -9.958, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 927, "visits": [3.0, 737.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1015, "q_vals": [-11.852, -9.955, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 928, "visits": [3.0, 738.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1016, "q_vals": [-11.852, -9.953, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 929, "visits": [3.0, 739.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1017, "q_vals": [-11.852, -9.95, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 930, "visits": [3.0, 740.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1017, "q_vals": [-11.852, -9.963, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 931, "visits": [3.0, 741.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1019, "q_vals": [-11.852, -9.96, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 932, "visits": [3.0, 742.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1022, "q_vals": [-11.852, -9.947, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 933, "visits": [3.0, 743.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1023, "q_vals": [-11.852, -9.944, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 934, "visits": [3.0, 744.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1023, "q_vals": [-11.852, -9.941, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 1025, "number_of_timesteps": 88537, "per_episode_reward": -335.81, "episode_reward_trend_value": -0.3388750005228834, "biggest_recent_change": 5.152788015259091},
{ "step": 935, "visits": [3.0, 745.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1025, "q_vals": [-11.852, -9.939, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 936, "visits": [3.0, 746.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1025, "q_vals": [-11.852, -9.936, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 937, "visits": [3.0, 747.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1026, "q_vals": [-11.852, -9.933, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
[-11.852, -9.931, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753]
{ "step": 939, "visits": [3.0, 749.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1029, "q_vals": [-11.852, -9.944, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 940, "visits": [3.0, 750.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1031, "q_vals": [-11.852, -9.941, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 941, "visits": [3.0, 751.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1034, "q_vals": [-11.852, -9.954, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 942, "visits": [3.0, 752.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1034, "q_vals": [-11.852, -9.951, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 943, "visits": [3.0, 753.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1034, "q_vals": [-11.852, -9.964, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 944, "visits": [3.0, 754.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1034, "q_vals": [-11.852, -9.962, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 1036, "number_of_timesteps": 89401, "per_episode_reward": -338.48, "episode_reward_trend_value": -0.3290007266324873, "biggest_recent_change": 5.152788015259091},
{ "step": 945, "visits": [3.0, 755.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1036, "q_vals": [-11.852, -9.959, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 946, "visits": [3.0, 756.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1038, "q_vals": [-11.852, -9.972, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 947, "visits": [3.0, 757.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1040, "q_vals": [-11.852, -9.969, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 948, "visits": [3.0, 758.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1040, "q_vals": [-11.852, -9.966, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 949, "visits": [3.0, 759.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1043, "q_vals": [-11.852, -9.964, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 950, "visits": [3.0, 760.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1043, "q_vals": [-11.852, -9.961, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 951, "visits": [3.0, 761.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1044, "q_vals": [-11.852, -9.958, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 952, "visits": [3.0, 762.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1044, "q_vals": [-11.852, -9.955, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 953, "visits": [3.0, 763.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1045, "q_vals": [-11.852, -9.968, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 954, "visits": [3.0, 764.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1045, "q_vals": [-11.852, -9.981, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 1048, "number_of_timesteps": 90342, "per_episode_reward": -343.7, "episode_reward_trend_value": -0.35422382217824283, "biggest_recent_change": 5.221161445146095},
{ "step": 955, "visits": [3.0, 765.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1048, "q_vals": [-11.852, -9.978, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 956, "visits": [3.0, 766.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1049, "q_vals": [-11.852, -9.976, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 957, "visits": [3.0, 767.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1050, "q_vals": [-11.852, -9.973, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 958, "visits": [3.0, 768.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1050, "q_vals": [-11.852, -9.986, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 959, "visits": [3.0, 769.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1051, "q_vals": [-11.852, -9.983, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 960, "visits": [3.0, 770.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1053, "q_vals": [-11.852, -9.98, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 961, "visits": [3.0, 771.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1054, "q_vals": [-11.852, -9.978, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 962, "visits": [3.0, 772.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1054, "q_vals": [-11.852, -9.99, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 963, "visits": [3.0, 773.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1055, "q_vals": [-11.852, -9.988, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 964, "visits": [3.0, 774.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1055, "q_vals": [-11.852, -9.985, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 965, "visits": [3.0, 775.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1057, "q_vals": [-11.852, -9.997, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 1059, "number_of_timesteps": 91403, "per_episode_reward": -345.89, "episode_reward_trend_value": -0.3493788377010762, "biggest_recent_change": 5.221161445146095},
{ "step": 966, "visits": [3.0, 776.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1059, "q_vals": [-11.852, -9.995, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 967, "visits": [3.0, 777.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1059, "q_vals": [-11.852, -10.007, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 968, "visits": [3.0, 778.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1059, "q_vals": [-11.852, -10.005, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 969, "visits": [3.0, 779.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1060, "q_vals": [-11.852, -10.017, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 970, "visits": [3.0, 780.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1061, "q_vals": [-11.852, -10.014, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 971, "visits": [3.0, 781.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1062, "q_vals": [-11.852, -10.012, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 972, "visits": [3.0, 782.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1062, "q_vals": [-11.852, -10.024, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 973, "visits": [3.0, 783.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1064, "q_vals": [-11.852, -10.037, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 974, "visits": [3.0, 784.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1064, "q_vals": [-11.852, -10.034, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 975, "visits": [3.0, 785.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1065, "q_vals": [-11.852, -10.031, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 976, "visits": [3.0, 786.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1066, "q_vals": [-11.852, -10.028, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 977, "visits": [3.0, 787.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1066, "q_vals": [-11.852, -10.041, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 1069, "number_of_timesteps": 92549, "per_episode_reward": -348.69, "episode_reward_trend_value": -0.32321366560656456, "biggest_recent_change": 5.221161445146095},
{ "step": 978, "visits": [3.0, 788.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1069, "q_vals": [-11.852, -10.028, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 979, "visits": [3.0, 789.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1070, "q_vals": [-11.852, -10.025, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 980, "visits": [3.0, 790.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1071, "q_vals": [-11.852, -10.023, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 981, "visits": [3.0, 791.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1072, "q_vals": [-11.852, -10.035, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 982, "visits": [3.0, 792.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1074, "q_vals": [-11.852, -10.032, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 983, "visits": [3.0, 793.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1075, "q_vals": [-11.852, -10.03, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 984, "visits": [3.0, 794.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1075, "q_vals": [-11.852, -10.017, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 985, "visits": [3.0, 795.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1075, "q_vals": [-11.852, -10.029, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 986, "visits": [3.0, 796.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1078, "q_vals": [-11.852, -10.027, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 1080, "number_of_timesteps": 93509, "per_episode_reward": -350.01, "episode_reward_trend_value": -0.3073691218521011, "biggest_recent_change": 5.221161445146095},
{ "step": 987, "visits": [3.0, 797.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1080, "q_vals": [-11.852, -10.024, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 988, "visits": [3.0, 798.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1081, "q_vals": [-11.852, -10.036, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 989, "visits": [3.0, 799.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1082, "q_vals": [-11.852, -10.033, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 990, "visits": [3.0, 800.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1082, "q_vals": [-11.852, -10.031, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 991, "visits": [3.0, 801.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1084, "q_vals": [-11.852, -10.028, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 992, "visits": [3.0, 802.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1086, "q_vals": [-11.852, -10.025, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 993, "visits": [3.0, 803.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1087, "q_vals": [-11.852, -10.023, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 994, "visits": [3.0, 804.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1087, "q_vals": [-11.852, -10.02, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 995, "visits": [3.0, 805.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1088, "q_vals": [-11.852, -10.008, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 1090, "number_of_timesteps": 94292, "per_episode_reward": -352.48, "episode_reward_trend_value": -0.3005327126438184, "biggest_recent_change": 5.221161445146095},
{ "step": 996, "visits": [3.0, 806.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1090, "q_vals": [-11.852, -10.02, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 997, "visits": [3.0, 807.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1091, "q_vals": [-11.852, -10.032, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 998, "visits": [3.0, 808.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1093, "q_vals": [-11.852, -10.029, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 999, "visits": [3.0, 809.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1095, "q_vals": [-11.852, -10.027, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1000, "visits": [3.0, 810.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1097, "q_vals": [-11.852, -10.024, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1001, "visits": [3.0, 811.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1097, "q_vals": [-11.852, -10.021, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1002, "visits": [3.0, 812.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1097, "q_vals": [-11.852, -10.019, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1003, "visits": [3.0, 813.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1098, "q_vals": [-11.852, -10.031, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1004, "visits": [3.0, 814.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1098, "q_vals": [-11.852, -10.043, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 1102, "number_of_timesteps": 95158, "per_episode_reward": -352.46, "episode_reward_trend_value": -0.27379973495914983, "biggest_recent_change": 5.221161445146095},
{ "step": 1005, "visits": [3.0, 815.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1102, "q_vals": [-11.852, -10.04, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1006, "visits": [3.0, 816.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1104, "q_vals": [-11.852, -10.052, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1007, "visits": [3.0, 817.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1104, "q_vals": [-11.852, -10.04, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1008, "visits": [3.0, 818.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1105, "q_vals": [-11.852, -10.037, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1009, "visits": [3.0, 819.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1107, "q_vals": [-11.852, -10.034, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1010, "visits": [3.0, 820.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1108, "q_vals": [-11.852, -10.032, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1011, "visits": [3.0, 821.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1109, "q_vals": [-11.852, -10.044, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1012, "visits": [3.0, 822.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1111, "q_vals": [-11.852, -10.041, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 1112, "number_of_timesteps": 95917, "per_episode_reward": -353.05, "episode_reward_trend_value": -0.2285087822631283, "biggest_recent_change": 5.221161445146095},
{ "step": 1013, "visits": [3.0, 823.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1112, "q_vals": [-11.852, -10.038, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1014, "visits": [3.0, 824.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1114, "q_vals": [-11.852, -10.036, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1015, "visits": [3.0, 825.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1116, "q_vals": [-11.852, -10.033, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1016, "visits": [3.0, 826.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1116, "q_vals": [-11.852, -10.045, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1017, "visits": [3.0, 827.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1116, "q_vals": [-11.852, -10.033, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1018, "visits": [3.0, 828.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1119, "q_vals": [-11.852, -10.03, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1019, "visits": [3.0, 829.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1121, "q_vals": [-11.852, -10.028, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 1123, "number_of_timesteps": 96682, "per_episode_reward": -354.41, "episode_reward_trend_value": -0.20660130353407138, "biggest_recent_change": 5.221161445146095},
{ "step": 1020, "visits": [3.0, 830.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1123, "q_vals": [-11.852, -10.025, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1021, "visits": [3.0, 831.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1125, "q_vals": [-11.852, -10.023, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1022, "visits": [3.0, 832.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1125, "q_vals": [-11.852, -10.011, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1023, "visits": [3.0, 833.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1125, "q_vals": [-11.852, -10.008, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1024, "visits": [3.0, 834.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1126, "q_vals": [-11.852, -10.02, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1025, "visits": [3.0, 835.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1126, "q_vals": [-11.852, -10.017, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1026, "visits": [3.0, 836.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1129, "q_vals": [-11.852, -10.029, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1027, "visits": [3.0, 837.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1131, "q_vals": [-11.852, -10.026, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1028, "visits": [3.0, 838.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1131, "q_vals": [-11.852, -10.024, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{"total_number_of_episodes": 1134, "number_of_timesteps": 97536, "per_episode_reward": -356.3, "episode_reward_trend_value": -0.19801242719274798, "biggest_recent_change": 5.221161445146095},
{ "step": 1029, "visits": [3.0, 839.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1134, "q_vals": [-11.852, -10.035, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1030, "visits": [3.0, 840.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1136, "q_vals": [-11.852, -10.047, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1031, "visits": [3.0, 841.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1136, "q_vals": [-11.852, -10.044, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1032, "visits": [3.0, 842.0, 3.0, 3.0, 6.0, 2.0, 126.0, 43.0, 3.0, 1.0] , "episode_count": 1136, "q_vals": [-11.852, -10.056, -11.852, -13.853, -12.51, -13.827, -10.228, -10.364, -11.852, -19.753] }
{ "step": 1033, "visits": [3.0, 842.0, 3.0, 3.0, 6.0, 2.0, 126.0, 44.0, 3.0, 1.0] , "episode_count": 1139, "q_vals": [-11.852, -10.056, -11.852, -13.853, -12.51, -13.827, -10.228, -10.128, -11.852, -19.753] }
{ "step": 1034, "visits": [3.0, 842.0, 3.0, 3.0, 6.0, 2.0, 126.0, 45.0, 3.0, 1.0] , "episode_count": 1140, "q_vals": [-11.852, -10.056, -11.852, -13.853, -12.51, -13.827, -10.228, -10.342, -11.852, -19.753] }
{ "step": 1035, "visits": [3.0, 842.0, 3.0, 3.0, 6.0, 2.0, 126.0, 46.0, 3.0, 1.0] , "episode_count": 1143, "q_vals": [-11.852, -10.056, -11.852, -13.853, -12.51, -13.827, -10.228, -10.289, -11.852, -19.753] }
{"total_number_of_episodes": 1144, "number_of_timesteps": 98173, "per_episode_reward": -358.03, "episode_reward_trend_value": -0.15922879963733294, "biggest_recent_change": 2.797922526753041},
{ "step": 1036, "visits": [3.0, 842.0, 3.0, 3.0, 6.0, 2.0, 126.0, 47.0, 3.0, 1.0] , "episode_count": 1144, "q_vals": [-11.852, -10.056, -11.852, -13.853, -12.51, -13.827, -10.228, -10.238, -11.852, -19.753] }
{ "step": 1037, "visits": [3.0, 842.0, 3.0, 3.0, 6.0, 2.0, 126.0, 48.0, 3.0, 1.0] , "episode_count": 1146, "q_vals": [-11.852, -10.056, -11.852, -13.853, -12.51, -13.827, -10.228, -10.189, -11.852, -19.753] }
{ "step": 1038, "visits": [3.0, 842.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1146, "q_vals": [-11.852, -10.056, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1039, "visits": [3.0, 843.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1149, "q_vals": [-11.852, -10.053, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1040, "visits": [3.0, 844.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1150, "q_vals": [-11.852, -10.051, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1041, "visits": [3.0, 845.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1151, "q_vals": [-11.852, -10.048, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1042, "visits": [3.0, 846.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1152, "q_vals": [-11.852, -10.06, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1155, "number_of_timesteps": 98883, "per_episode_reward": -359.27, "episode_reward_trend_value": -0.14861386022763554, "biggest_recent_change": 2.797922526753041},
{ "step": 1043, "visits": [3.0, 847.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1155, "q_vals": [-11.852, -10.048, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1044, "visits": [3.0, 848.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1156, "q_vals": [-11.852, -10.045, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1045, "visits": [3.0, 849.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1157, "q_vals": [-11.852, -10.043, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1046, "visits": [3.0, 850.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1160, "q_vals": [-11.852, -10.054, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1047, "visits": [3.0, 851.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1160, "q_vals": [-11.852, -10.052, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1048, "visits": [3.0, 852.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1161, "q_vals": [-11.852, -10.049, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1049, "visits": [3.0, 853.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1164, "q_vals": [-11.852, -10.047, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1050, "visits": [3.0, 854.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1164, "q_vals": [-11.852, -10.044, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1165, "number_of_timesteps": 99512, "per_episode_reward": -360.23, "episode_reward_trend_value": -0.12825180305194345, "biggest_recent_change": 2.4719766350604004},
{ "step": 1051, "visits": [3.0, 855.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1165, "q_vals": [-11.852, -10.055, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1052, "visits": [3.0, 856.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1165, "q_vals": [-11.852, -10.044, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1053, "visits": [3.0, 857.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1167, "q_vals": [-11.852, -10.055, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1054, "visits": [3.0, 858.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1169, "q_vals": [-11.852, -10.066, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1055, "visits": [3.0, 859.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1171, "q_vals": [-11.852, -10.064, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1056, "visits": [3.0, 860.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1173, "q_vals": [-11.852, -10.061, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1057, "visits": [3.0, 861.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1173, "q_vals": [-11.852, -10.05, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1058, "visits": [3.0, 862.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1174, "q_vals": [-11.852, -10.047, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1175, "number_of_timesteps": 100248, "per_episode_reward": -361.97, "episode_reward_trend_value": -0.13287361324339092, "biggest_recent_change": 2.4719766350604004},
{ "step": 1059, "visits": [3.0, 863.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1175, "q_vals": [-11.852, -10.045, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1060, "visits": [3.0, 864.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1176, "q_vals": [-11.852, -10.056, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1061, "visits": [3.0, 865.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1177, "q_vals": [-11.852, -10.053, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1062, "visits": [3.0, 866.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1179, "q_vals": [-11.852, -10.051, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1063, "visits": [3.0, 867.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1181, "q_vals": [-11.852, -10.048, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1064, "visits": [3.0, 868.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1182, "q_vals": [-11.852, -10.046, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1065, "visits": [3.0, 869.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1184, "q_vals": [-11.852, -10.057, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1185, "number_of_timesteps": 101010, "per_episode_reward": -364.09, "episode_reward_trend_value": -0.12905698631220477, "biggest_recent_change": 2.1284802112536454},
{ "step": 1066, "visits": [3.0, 870.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1185, "q_vals": [-11.852, -10.055, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1067, "visits": [3.0, 871.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1186, "q_vals": [-11.852, -10.052, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1068, "visits": [3.0, 872.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1188, "q_vals": [-11.852, -10.063, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1069, "visits": [3.0, 873.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1189, "q_vals": [-11.852, -10.061, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1070, "visits": [3.0, 874.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1190, "q_vals": [-11.852, -10.058, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1071, "visits": [3.0, 875.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1192, "q_vals": [-11.852, -10.069, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1072, "visits": [3.0, 876.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1193, "q_vals": [-11.852, -10.067, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1195, "number_of_timesteps": 101677, "per_episode_reward": -365.33, "episode_reward_trend_value": -0.1429762952342445, "biggest_recent_change": 2.1284802112536454},
{ "step": 1073, "visits": [3.0, 877.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1195, "q_vals": [-11.852, -10.078, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1074, "visits": [3.0, 878.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1197, "q_vals": [-11.852, -10.076, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1075, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 126.0, 49.0, 3.0, 1.0] , "episode_count": 1197, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.228, -10.385, -11.852, -19.753] }
{ "step": 1076, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 127.0, 49.0, 3.0, 1.0] , "episode_count": 1198, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.21, -10.385, -11.852, -19.753] }
{ "step": 1077, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 128.0, 49.0, 3.0, 1.0] , "episode_count": 1199, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.192, -10.385, -11.852, -19.753] }
{ "step": 1078, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 129.0, 49.0, 3.0, 1.0] , "episode_count": 1201, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.174, -10.385, -11.852, -19.753] }
{ "step": 1079, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 130.0, 49.0, 3.0, 1.0] , "episode_count": 1203, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.096, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1205, "number_of_timesteps": 102364, "per_episode_reward": -367.51, "episode_reward_trend_value": -0.16071084642053898, "biggest_recent_change": 2.1840364436249047},
{ "step": 1080, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 131.0, 49.0, 3.0, 1.0] , "episode_count": 1205, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.019, -10.385, -11.852, -19.753] }
{ "step": 1081, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 132.0, 49.0, 3.0, 1.0] , "episode_count": 1205, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.093, -10.385, -11.852, -19.753] }
{ "step": 1082, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 133.0, 49.0, 3.0, 1.0] , "episode_count": 1206, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.076, -10.385, -11.852, -19.753] }
{ "step": 1083, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 134.0, 49.0, 3.0, 1.0] , "episode_count": 1207, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.001, -10.385, -11.852, -19.753] }
{ "step": 1084, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 135.0, 49.0, 3.0, 1.0] , "episode_count": 1210, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.073, -10.385, -11.852, -19.753] }
{ "step": 1085, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 136.0, 49.0, 3.0, 1.0] , "episode_count": 1210, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.057, -10.385, -11.852, -19.753] }
{ "step": 1086, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 137.0, 49.0, 3.0, 1.0] , "episode_count": 1213, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.042, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1215, "number_of_timesteps": 103060, "per_episode_reward": -369.0, "episode_reward_trend_value": -0.1622093487691782, "biggest_recent_change": 2.1840364436249047},
{ "step": 1087, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 138.0, 49.0, 3.0, 1.0] , "episode_count": 1215, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.026, -10.385, -11.852, -19.753] }
{ "step": 1088, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 139.0, 49.0, 3.0, 1.0] , "episode_count": 1215, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.096, -10.385, -11.852, -19.753] }
{ "step": 1089, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 140.0, 49.0, 3.0, 1.0] , "episode_count": 1216, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.024, -10.385, -11.852, -19.753] }
{ "step": 1090, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 141.0, 49.0, 3.0, 1.0] , "episode_count": 1217, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.009, -10.385, -11.852, -19.753] }
{ "step": 1091, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 142.0, 49.0, 3.0, 1.0] , "episode_count": 1218, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -9.994, -10.385, -11.852, -19.753] }
{ "step": 1092, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 143.0, 49.0, 3.0, 1.0] , "episode_count": 1221, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -9.979, -10.385, -11.852, -19.753] }
{ "step": 1093, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 144.0, 49.0, 3.0, 1.0] , "episode_count": 1223, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.047, -10.385, -11.852, -19.753] }
{ "step": 1094, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 145.0, 49.0, 3.0, 1.0] , "episode_count": 1224, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.032, -10.385, -11.852, -19.753] }
{ "step": 1095, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 146.0, 49.0, 3.0, 1.0] , "episode_count": 1224, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.018, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1225, "number_of_timesteps": 103744, "per_episode_reward": -370.41, "episode_reward_trend_value": -0.15675366757615167, "biggest_recent_change": 2.1840364436249047},
{ "step": 1096, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 147.0, 49.0, 3.0, 1.0] , "episode_count": 1225, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.084, -10.385, -11.852, -19.753] }
{ "step": 1097, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 148.0, 49.0, 3.0, 1.0] , "episode_count": 1227, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.149, -10.385, -11.852, -19.753] }
{ "step": 1098, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 149.0, 49.0, 3.0, 1.0] , "episode_count": 1230, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.134, -10.385, -11.852, -19.753] }
{ "step": 1099, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 150.0, 49.0, 3.0, 1.0] , "episode_count": 1231, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.198, -10.385, -11.852, -19.753] }
{ "step": 1100, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 151.0, 49.0, 3.0, 1.0] , "episode_count": 1233, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.166, -10.385, -11.852, -19.753] }
{ "step": 1101, "visits": [3.0, 879.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1234, "q_vals": [-11.852, -10.087, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1102, "visits": [3.0, 880.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1234, "q_vals": [-11.852, -10.084, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1235, "number_of_timesteps": 104380, "per_episode_reward": -372.09, "episode_reward_trend_value": -0.15620589197577348, "biggest_recent_change": 2.1840364436249047},
{ "step": 1103, "visits": [3.0, 881.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1235, "q_vals": [-11.852, -10.082, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1104, "visits": [3.0, 882.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1237, "q_vals": [-11.852, -10.079, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1105, "visits": [3.0, 883.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1240, "q_vals": [-11.852, -10.077, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1106, "visits": [3.0, 884.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1241, "q_vals": [-11.852, -10.065, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1107, "visits": [3.0, 885.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1241, "q_vals": [-11.852, -10.063, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1108, "visits": [3.0, 886.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1242, "q_vals": [-11.852, -10.051, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1109, "visits": [3.0, 887.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1244, "q_vals": [-11.852, -10.049, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1110, "visits": [3.0, 888.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1244, "q_vals": [-11.852, -10.047, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1246, "number_of_timesteps": 105136, "per_episode_reward": -375.55, "episode_reward_trend_value": -0.18091044263431588, "biggest_recent_change": 3.459107684005801},
{ "step": 1111, "visits": [3.0, 889.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1246, "q_vals": [-11.852, -10.058, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1112, "visits": [3.0, 890.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1247, "q_vals": [-11.852, -10.055, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1113, "visits": [3.0, 891.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1249, "q_vals": [-11.852, -10.051, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1114, "visits": [3.0, 892.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1249, "q_vals": [-11.852, -10.048, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1115, "visits": [3.0, 893.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1253, "q_vals": [-11.852, -10.046, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1116, "visits": [3.0, 894.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1253, "q_vals": [-11.852, -10.057, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1117, "visits": [3.0, 895.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1254, "q_vals": [-11.852, -10.054, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1256, "number_of_timesteps": 105870, "per_episode_reward": -376.63, "episode_reward_trend_value": -0.18214214709590365, "biggest_recent_change": 3.459107684005801},
{ "step": 1118, "visits": [3.0, 896.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1256, "q_vals": [-11.852, -10.065, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1119, "visits": [3.0, 897.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1259, "q_vals": [-11.852, -10.076, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1120, "visits": [3.0, 898.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1260, "q_vals": [-11.852, -10.073, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1121, "visits": [3.0, 899.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1261, "q_vals": [-11.852, -10.084, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1122, "visits": [3.0, 900.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1261, "q_vals": [-11.852, -10.082, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1123, "visits": [3.0, 901.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1263, "q_vals": [-11.852, -10.079, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1124, "visits": [3.0, 902.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1263, "q_vals": [-11.852, -10.077, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1125, "visits": [3.0, 903.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1265, "q_vals": [-11.852, -10.075, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1268, "number_of_timesteps": 106638, "per_episode_reward": -377.6, "episode_reward_trend_value": -0.1736507356457259, "biggest_recent_change": 3.459107684005801},
{ "step": 1126, "visits": [3.0, 904.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1268, "q_vals": [-11.852, -10.072, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1127, "visits": [3.0, 905.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1268, "q_vals": [-11.852, -10.07, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1128, "visits": [3.0, 906.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1270, "q_vals": [-11.852, -10.067, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1129, "visits": [3.0, 907.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1270, "q_vals": [-11.852, -10.078, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1130, "visits": [3.0, 908.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1273, "q_vals": [-11.852, -10.076, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1131, "visits": [3.0, 909.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1274, "q_vals": [-11.852, -10.073, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1132, "visits": [3.0, 910.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1276, "q_vals": [-11.852, -10.062, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1133, "visits": [3.0, 911.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1277, "q_vals": [-11.852, -10.06, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1279, "number_of_timesteps": 107384, "per_episode_reward": -378.05, "episode_reward_trend_value": -0.15505511757956786, "biggest_recent_change": 3.459107684005801},
{ "step": 1134, "visits": [3.0, 912.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1279, "q_vals": [-11.852, -10.057, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1135, "visits": [3.0, 913.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1280, "q_vals": [-11.852, -10.055, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1136, "visits": [3.0, 914.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1280, "q_vals": [-11.852, -10.066, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1137, "visits": [3.0, 915.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1283, "q_vals": [-11.852, -10.063, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1138, "visits": [3.0, 916.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1285, "q_vals": [-11.852, -10.061, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1139, "visits": [3.0, 917.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1285, "q_vals": [-11.852, -10.071, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1140, "visits": [3.0, 918.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1287, "q_vals": [-11.852, -10.069, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1141, "visits": [3.0, 919.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1287, "q_vals": [-11.852, -10.08, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1142, "visits": [3.0, 920.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1287, "q_vals": [-11.852, -10.077, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1292, "number_of_timesteps": 108266, "per_episode_reward": -380.88, "episode_reward_trend_value": -0.17281952555931132, "biggest_recent_change": 3.459107684005801},
{ "step": 1143, "visits": [3.0, 921.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1292, "q_vals": [-11.852, -10.075, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1144, "visits": [3.0, 922.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1293, "q_vals": [-11.852, -10.073, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1145, "visits": [3.0, 923.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1293, "q_vals": [-11.852, -10.07, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1146, "visits": [3.0, 924.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1295, "q_vals": [-11.852, -10.059, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1147, "visits": [3.0, 925.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1296, "q_vals": [-11.852, -10.057, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1148, "visits": [3.0, 926.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1297, "q_vals": [-11.852, -10.055, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1149, "visits": [3.0, 927.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1298, "q_vals": [-11.852, -10.044, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1150, "visits": [3.0, 928.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1300, "q_vals": [-11.852, -10.042, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1303, "number_of_timesteps": 109041, "per_episode_reward": -382.16, "episode_reward_trend_value": -0.16272686879117815, "biggest_recent_change": 3.459107684005801},
{ "step": 1151, "visits": [3.0, 929.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1303, "q_vals": [-11.852, -10.039, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1152, "visits": [3.0, 930.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1304, "q_vals": [-11.852, -10.037, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1153, "visits": [3.0, 931.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1306, "q_vals": [-11.852, -10.047, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1154, "visits": [3.0, 932.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1307, "q_vals": [-11.852, -10.058, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1155, "visits": [3.0, 933.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1307, "q_vals": [-11.852, -10.055, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1156, "visits": [3.0, 934.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1307, "q_vals": [-11.852, -10.053, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1157, "visits": [3.0, 935.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1308, "q_vals": [-11.852, -10.051, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1158, "visits": [3.0, 936.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1310, "q_vals": [-11.852, -10.061, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1313, "number_of_timesteps": 109712, "per_episode_reward": -383.47, "episode_reward_trend_value": -0.16069457073119667, "biggest_recent_change": 3.459107684005801},
{ "step": 1159, "visits": [3.0, 937.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1313, "q_vals": [-11.852, -10.072, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1160, "visits": [3.0, 938.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1315, "q_vals": [-11.852, -10.069, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1161, "visits": [3.0, 939.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1316, "q_vals": [-11.852, -10.067, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1162, "visits": [3.0, 940.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1316, "q_vals": [-11.852, -10.056, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1163, "visits": [3.0, 941.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1317, "q_vals": [-11.852, -10.054, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1164, "visits": [3.0, 942.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1317, "q_vals": [-11.852, -10.052, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1165, "visits": [3.0, 943.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1319, "q_vals": [-11.852, -10.049, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1166, "visits": [3.0, 944.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1320, "q_vals": [-11.852, -10.047, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1167, "visits": [3.0, 945.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1320, "q_vals": [-11.852, -10.045, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1324, "number_of_timesteps": 110559, "per_episode_reward": -385.38, "episode_reward_trend_value": -0.16632106379251088, "biggest_recent_change": 3.459107684005801},
{ "step": 1168, "visits": [3.0, 946.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1324, "q_vals": [-11.852, -10.043, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1169, "visits": [3.0, 947.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1325, "q_vals": [-11.852, -10.04, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1170, "visits": [3.0, 948.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1326, "q_vals": [-11.852, -10.038, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1171, "visits": [3.0, 949.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1328, "q_vals": [-11.852, -10.036, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1172, "visits": [3.0, 950.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1328, "q_vals": [-11.852, -10.025, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1173, "visits": [3.0, 951.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1329, "q_vals": [-11.852, -10.023, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1174, "visits": [3.0, 952.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1330, "q_vals": [-11.852, -10.033, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1175, "visits": [3.0, 953.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1333, "q_vals": [-11.852, -10.031, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1334, "number_of_timesteps": 111286, "per_episode_reward": -386.15, "episode_reward_trend_value": -0.156247583350599, "biggest_recent_change": 3.459107684005801},
{ "step": 1176, "visits": [3.0, 954.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1334, "q_vals": [-11.852, -10.029, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1177, "visits": [3.0, 955.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1335, "q_vals": [-11.852, -10.026, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1178, "visits": [3.0, 956.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1336, "q_vals": [-11.852, -10.024, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1179, "visits": [3.0, 957.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1338, "q_vals": [-11.852, -10.022, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1180, "visits": [3.0, 958.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1338, "q_vals": [-11.852, -10.02, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1181, "visits": [3.0, 959.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1341, "q_vals": [-11.852, -10.018, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1182, "visits": [3.0, 960.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1341, "q_vals": [-11.852, -10.015, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1183, "visits": [3.0, 961.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1343, "q_vals": [-11.852, -10.026, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1184, "visits": [3.0, 962.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1343, "q_vals": [-11.852, -10.036, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1344, "number_of_timesteps": 112034, "per_episode_reward": -388.5, "episode_reward_trend_value": -0.14388211975231685, "biggest_recent_change": 2.8334291100271685},
{ "step": 1185, "visits": [3.0, 963.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1344, "q_vals": [-11.852, -10.033, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1186, "visits": [3.0, 964.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1346, "q_vals": [-11.852, -10.031, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1187, "visits": [3.0, 965.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1348, "q_vals": [-11.852, -10.029, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1188, "visits": [3.0, 966.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1349, "q_vals": [-11.852, -10.039, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1189, "visits": [3.0, 967.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1349, "q_vals": [-11.852, -10.037, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
[3.0, 968.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0]  episode_count: 1352 q_vals: [-11.852, -10.047, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753]
{ "step": 1191, "visits": [3.0, 969.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1353, "q_vals": [-11.852, -10.057, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1192, "visits": [3.0, 970.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1353, "q_vals": [-11.852, -10.055, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1355, "number_of_timesteps": 112842, "per_episode_reward": -391.57, "episode_reward_trend_value": -0.16602799074049698, "biggest_recent_change": 3.0693191714198633},
{ "step": 1193, "visits": [3.0, 971.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1355, "q_vals": [-11.852, -10.044, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1194, "visits": [3.0, 972.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1357, "q_vals": [-11.852, -10.054, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1195, "visits": [3.0, 973.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1358, "q_vals": [-11.852, -10.064, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1196, "visits": [3.0, 974.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1360, "q_vals": [-11.852, -10.062, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1197, "visits": [3.0, 975.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1360, "q_vals": [-11.852, -10.06, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1198, "visits": [3.0, 976.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1362, "q_vals": [-11.852, -10.058, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1199, "visits": [3.0, 977.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1362, "q_vals": [-11.852, -10.055, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1200, "visits": [3.0, 978.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1363, "q_vals": [-11.852, -10.065, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1366, "number_of_timesteps": 113644, "per_episode_reward": -393.43, "episode_reward_trend_value": -0.17597679408836103, "biggest_recent_change": 3.0693191714198633},
{ "step": 1201, "visits": [3.0, 979.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1366, "q_vals": [-11.852, -10.063, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1202, "visits": [3.0, 980.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1367, "q_vals": [-11.852, -10.061, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1203, "visits": [3.0, 981.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1369, "q_vals": [-11.852, -10.059, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1204, "visits": [3.0, 982.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1369, "q_vals": [-11.852, -10.057, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1205, "visits": [3.0, 983.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1369, "q_vals": [-11.852, -10.054, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1206, "visits": [3.0, 984.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1370, "q_vals": [-11.852, -10.052, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1207, "visits": [3.0, 985.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1370, "q_vals": [-11.852, -10.062, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1208, "visits": [3.0, 986.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1373, "q_vals": [-11.852, -10.06, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1376, "number_of_timesteps": 114419, "per_episode_reward": -395.42, "episode_reward_trend_value": -0.1929855009526471, "biggest_recent_change": 3.0693191714198633},
{ "step": 1209, "visits": [3.0, 987.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1376, "q_vals": [-11.852, -10.07, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1210, "visits": [3.0, 988.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1377, "q_vals": [-11.852, -10.067, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1211, "visits": [3.0, 989.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1379, "q_vals": [-11.852, -10.057, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1212, "visits": [3.0, 990.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1379, "q_vals": [-11.852, -10.055, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1213, "visits": [3.0, 991.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1379, "q_vals": [-11.852, -10.053, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1214, "visits": [3.0, 992.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1380, "q_vals": [-11.852, -10.051, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1215, "visits": [3.0, 993.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1382, "q_vals": [-11.852, -10.049, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1216, "visits": [3.0, 994.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1385, "q_vals": [-11.852, -10.046, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{"total_number_of_episodes": 1387, "number_of_timesteps": 115217, "per_episode_reward": -395.95, "episode_reward_trend_value": -0.16737704785775867, "biggest_recent_change": 3.0693191714198633},
{ "step": 1217, "visits": [3.0, 995.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1387, "q_vals": [-11.852, -10.056, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1218, "visits": [3.0, 996.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1387, "q_vals": [-11.852, -10.066, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1219, "visits": [3.0, 997.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1388, "q_vals": [-11.852, -10.064, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
{ "step": 1220, "visits": [3.0, 998.0, 3.0, 3.0, 6.0, 2.0, 152.0, 49.0, 3.0, 1.0] , "episode_count": 1388, "q_vals": [-11.852, -10.062, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753] }
1391 q_vals: [-11.852, -10.071, -11.852, -13.853, -12.51, -13.827, -10.229, -10.385, -11.852, -19.753]
{ "step": 1222, "visits": [0.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 1393, "q_vals": [0.0, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 1223, "visits": [1.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 1394, "q_vals": [0.0, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 1224, "visits": [1.0, 1000.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 1395, "q_vals": [0.0, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{"total_number_of_episodes": 1397, "number_of_timesteps": 115904, "per_episode_reward": -358.27, "episode_reward_trend_value": 0.2654254016350257, "biggest_recent_change": 37.67652311985768},
{ "step": 1225, "visits": [1.0, 1000.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 1397, "q_vals": [0.0, -inf, 0.0, -21.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 1226, "visits": [1.0, 1000.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 1398, "q_vals": [0.0, -inf, 0.0, -21.875, -21.875, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 1227, "visits": [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 1399, "q_vals": [0.0, -inf, 0.0, -21.875, -21.875, -8.75, 0.0, 0.0, 0.0, 0.0] }
{ "step": 1228, "visits": [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0] , "episode_count": 1401, "q_vals": [0.0, -inf, 0.0, -21.875, -21.875, -8.75, 0.0, 0.0, 0.0, 0.0] }
{ "step": 1229, "visits": [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0] , "episode_count": 1403, "q_vals": [0.0, -inf, 0.0, -21.875, -21.875, -8.75, 0.0, -8.75, 0.0, 0.0] }
{ "step": 1230, "visits": [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0] , "episode_count": 1403, "q_vals": [0.0, -inf, 0.0, -21.875, -21.875, -8.75, 0.0, -8.75, -8.75, 0.0] }
{ "step": 1231, "visits": [1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 1403, "q_vals": [0.0, -inf, 0.0, -21.875, -21.875, -8.75, 0.0, -8.75, -8.75, -8.75] }
{ "step": 1232, "visits": [2.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 1406, "q_vals": [-4.375, -inf, 0.0, -21.875, -21.875, -8.75, 0.0, -8.75, -8.75, -8.75] }
{"total_number_of_episodes": 1407, "number_of_timesteps": 116594, "per_episode_reward": -358.71, "episode_reward_trend_value": 0.27509552030219503, "biggest_recent_change": 37.67652311985768},
{ "step": 1233, "visits": [2.0, 1000.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 1407, "q_vals": [-4.375, -inf, -4.375, -21.875, -21.875, -8.75, 0.0, -8.75, -8.75, -8.75] }
{ "step": 1234, "visits": [2.0, 1000.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 1407, "q_vals": [-4.375, -inf, -4.375, -21.875, -21.875, -8.75, -4.375, -8.75, -8.75, -8.75] }
{ "step": 1235, "visits": [2.0, 1000.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 1407, "q_vals": [-4.375, -inf, -5.833, -21.875, -21.875, -8.75, -4.375, -8.75, -8.75, -8.75] }
{ "step": 1236, "visits": [3.0, 1000.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0] , "episode_count": 1409, "q_vals": [-5.833, -inf, -5.833, -21.875, -21.875, -8.75, -4.375, -8.75, -8.75, -8.75] }
{ "step": 1237, "visits": [3.0, 1000.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0] , "episode_count": 1411, "q_vals": [-5.833, -inf, -5.833, -21.875, -21.875, -8.75, -5.833, -8.75, -8.75, -8.75] }
{ "step": 1238, "visits": [3.0, 1000.0, 4.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0] , "episode_count": 1412, "q_vals": [-5.833, -inf, -6.562, -21.875, -21.875, -8.75, -5.833, -8.75, -8.75, -8.75] }
{ "step": 1239, "visits": [4.0, 1000.0, 4.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0] , "episode_count": 1415, "q_vals": [-6.562, -inf, -6.562, -21.875, -21.875, -8.75, -5.833, -8.75, -8.75, -8.75] }
{ "step": 1240, "visits": [4.0, 1000.0, 4.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0] , "episode_count": 1415, "q_vals": [-6.562, -inf, -6.562, -21.875, -21.875, -8.75, -9.844, -8.75, -8.75, -8.75] }
{ "step": 1241, "visits": [5.0, 1000.0, 4.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0] , "episode_count": 1415, "q_vals": [-7.0, -inf, -6.562, -21.875, -21.875, -8.75, -9.844, -8.75, -8.75, -8.75] }
{"total_number_of_episodes": 1417, "number_of_timesteps": 117415, "per_episode_reward": -360.12, "episode_reward_trend_value": 0.2806932347966488, "biggest_recent_change": 37.67652311985768},
{ "step": 1242, "visits": [5.0, 1000.0, 5.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0] , "episode_count": 1417, "q_vals": [-7.0, -inf, -5.25, -21.875, -21.875, -8.75, -9.844, -8.75, -8.75, -8.75] }
{ "step": 1243, "visits": [5.0, 1000.0, 6.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0] , "episode_count": 1417, "q_vals": [-7.0, -inf, -5.833, -21.875, -21.875, -8.75, -9.844, -8.75, -8.75, -8.75] }
{ "step": 1244, "visits": [5.0, 1000.0, 7.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0] , "episode_count": 1418, "q_vals": [-7.0, -inf, -6.25, -21.875, -21.875, -8.75, -9.844, -8.75, -8.75, -8.75] }
{ "step": 1245, "visits": [5.0, 1000.0, 8.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0] , "episode_count": 1419, "q_vals": [-7.0, -inf, -6.562, -21.875, -21.875, -8.75, -9.844, -8.75, -8.75, -8.75] }
{ "step": 1246, "visits": [5.0, 1000.0, 9.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0] , "episode_count": 1421, "q_vals": [-7.0, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -8.75, -8.75] }
{ "step": 1247, "visits": [6.0, 1000.0, 9.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0] , "episode_count": 1423, "q_vals": [-7.292, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -8.75, -8.75] }
{ "step": 1248, "visits": [7.0, 1000.0, 9.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0] , "episode_count": 1426, "q_vals": [-7.5, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -8.75, -8.75] }
{ "step": 1249, "visits": [8.0, 1000.0, 9.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0] , "episode_count": 1426, "q_vals": [-7.656, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -8.75, -8.75] }
{ "step": 1250, "visits": [8.0, 1000.0, 9.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0] , "episode_count": 1426, "q_vals": [-7.656, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -8.75, -8.75] }
{ "step": 1251, "visits": [8.0, 1000.0, 9.0, 1.0, 1.0, 2.0, 4.0, 1.0, 2.0, 1.0] , "episode_count": 1426, "q_vals": [-7.656, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -4.375, -8.75] }
{"total_number_of_episodes": 1427, "number_of_timesteps": 118237, "per_episode_reward": -361.1, "episode_reward_trend_value": 0.2784297339153505, "biggest_recent_change": 37.67652311985768},
{ "step": 1252, "visits": [8.0, 1000.0, 9.0, 1.0, 1.0, 2.0, 4.0, 1.0, 3.0, 1.0] , "episode_count": 1427, "q_vals": [-7.656, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -5.833, -8.75] }
{ "step": 1253, "visits": [8.0, 1000.0, 9.0, 1.0, 1.0, 2.0, 4.0, 1.0, 4.0, 1.0] , "episode_count": 1430, "q_vals": [-7.656, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -4.375, -8.75] }
{ "step": 1254, "visits": [8.0, 1000.0, 9.0, 1.0, 1.0, 2.0, 4.0, 1.0, 5.0, 1.0] , "episode_count": 1430, "q_vals": [-7.656, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -5.25, -8.75] }
[8.0, 1000.0, 9.0, 1.0, 1.0, 2.0, 4.0, 1.0, 6.0, 1.0]  episode_count: 1431 q_vals: [-7.656, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -5.833, -8.75]
{ "step": 1256, "visits": [8.0, 1000.0, 9.0, 1.0, 1.0, 2.0, 4.0, 1.0, 7.0, 1.0] , "episode_count": 1433, "q_vals": [-7.656, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -8.125, -8.75] }
{ "step": 1257, "visits": [8.0, 1000.0, 9.0, 1.0, 1.0, 2.0, 4.0, 2.0, 7.0, 1.0] , "episode_count": 1436, "q_vals": [-7.656, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -8.125, -8.75] }
{ "step": 1258, "visits": [8.0, 1000.0, 9.0, 1.0, 1.0, 2.0, 4.0, 2.0, 7.0, 2.0] , "episode_count": 1436, "q_vals": [-7.656, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -8.125, -8.75] }
{ "step": 1259, "visits": [9.0, 1000.0, 9.0, 1.0, 1.0, 2.0, 4.0, 2.0, 7.0, 2.0] , "episode_count": 1436, "q_vals": [-7.778, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -8.125, -8.75] }
{"total_number_of_episodes": 1437, "number_of_timesteps": 119044, "per_episode_reward": -362.63, "episode_reward_trend_value": 0.2874528007586409, "biggest_recent_change": 37.67652311985768},
{ "step": 1260, "visits": [10.0, 1000.0, 9.0, 1.0, 1.0, 2.0, 4.0, 2.0, 7.0, 2.0] , "episode_count": 1437, "q_vals": [-7.875, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -8.125, -8.75] }
{ "step": 1261, "visits": [11.0, 1000.0, 9.0, 1.0, 1.0, 2.0, 4.0, 2.0, 7.0, 2.0] , "episode_count": 1438, "q_vals": [-7.955, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -8.125, -8.75] }
{ "step": 1262, "visits": [12.0, 1000.0, 9.0, 1.0, 1.0, 2.0, 4.0, 2.0, 7.0, 2.0] , "episode_count": 1439, "q_vals": [-8.021, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -8.125, -8.75] }
{ "step": 1263, "visits": [12.0, 1000.0, 9.0, 1.0, 1.0, 2.0, 4.0, 3.0, 7.0, 2.0] , "episode_count": 1439, "q_vals": [-8.021, -inf, -8.264, -21.875, -21.875, -8.75, -9.844, -8.75, -8.125, -8.75] }
{ "step": 1264, "visits": [12.0, 1000.0, 9.0, 1.0, 1.0, 3.0, 4.0, 3.0, 7.0, 2.0] , "episode_count": 1442, "q_vals": [-8.021, -inf, -8.264, -21.875, -21.875, -13.125, -9.844, -8.75, -8.125, -8.75] }
{ "step": 1265, "visits": [12.0, 1000.0, 9.0, 1.0, 1.0, 3.0, 4.0, 3.0, 7.0, 3.0] , "episode_count": 1444, "q_vals": [-8.021, -inf, -8.264, -21.875, -21.875, -13.125, -9.844, -8.75, -8.125, -5.833] }
{ "step": 1266, "visits": [12.0, 1000.0, 9.0, 1.0, 1.0, 3.0, 4.0, 3.0, 7.0, 4.0] , "episode_count": 1445, "q_vals": [-8.021, -inf, -8.264, -21.875, -21.875, -13.125, -9.844, -8.75, -8.125, -6.563] }
{ "step": 1267, "visits": [12.0, 1000.0, 9.0, 1.0, 1.0, 3.0, 4.0, 3.0, 7.0, 5.0] , "episode_count": 1446, "q_vals": [-8.021, -inf, -8.264, -21.875, -21.875, -13.125, -9.844, -8.75, -8.125, -7.0] }
{"total_number_of_episodes": 1447, "number_of_timesteps": 119888, "per_episode_reward": -364.62, "episode_reward_trend_value": 0.299413757855325, "biggest_recent_change": 37.67652311985768},
{ "step": 1268, "visits": [12.0, 1000.0, 9.0, 1.0, 1.0, 3.0, 4.0, 3.0, 7.0, 6.0] , "episode_count": 1447, "q_vals": [-8.021, -inf, -8.264, -21.875, -21.875, -13.125, -9.844, -8.75, -8.125, -7.292] }
{ "step": 1269, "visits": [12.0, 1000.0, 9.0, 1.0, 1.0, 3.0, 4.0, 3.0, 7.0, 7.0] , "episode_count": 1449, "q_vals": [-8.021, -inf, -8.264, -21.875, -21.875, -13.125, -9.844, -8.75, -8.125, -9.375] }
{ "step": 1270, "visits": [12.0, 1000.0, 9.0, 1.0, 1.0, 3.0, 4.0, 3.0, 8.0, 7.0] , "episode_count": 1449, "q_vals": [-8.021, -inf, -8.264, -21.875, -21.875, -13.125, -9.844, -8.75, -7.109, -9.375] }
{ "step": 1271, "visits": [12.0, 1000.0, 9.0, 1.0, 1.0, 3.0, 4.0, 3.0, 9.0, 7.0] , "episode_count": 1449, "q_vals": [-8.021, -inf, -8.264, -21.875, -21.875, -13.125, -9.844, -8.75, -8.75, -9.375] }
{ "step": 1272, "visits": [13.0, 1000.0, 9.0, 1.0, 1.0, 3.0, 4.0, 3.0, 9.0, 7.0] , "episode_count": 1449, "q_vals": [-8.077, -inf, -8.264, -21.875, -21.875, -13.125, -9.844, -8.75, -8.75, -9.375] }
{ "step": 1273, "visits": [14.0, 1000.0, 9.0, 1.0, 1.0, 3.0, 4.0, 3.0, 9.0, 7.0] , "episode_count": 1451, "q_vals": [-9.062, -inf, -8.264, -21.875, -21.875, -13.125, -9.844, -8.75, -8.75, -9.375] }
{ "step": 1274, "visits": [14.0, 1000.0, 10.0, 1.0, 1.0, 3.0, 4.0, 3.0, 9.0, 7.0] , "episode_count": 1452, "q_vals": [-9.062, -inf, -7.437, -21.875, -21.875, -13.125, -9.844, -8.75, -8.75, -9.375] }
{ "step": 1275, "visits": [14.0, 1000.0, 11.0, 1.0, 1.0, 3.0, 4.0, 3.0, 9.0, 7.0] , "episode_count": 1455, "q_vals": [-9.062, -inf, -7.557, -21.875, -21.875, -13.125, -9.844, -8.75, -8.75, -9.375] }
{ "step": 1276, "visits": [14.0, 1000.0, 12.0, 1.0, 1.0, 3.0, 4.0, 3.0, 9.0, 7.0] , "episode_count": 1456, "q_vals": [-9.062, -inf, -8.75, -21.875, -21.875, -13.125, -9.844, -8.75, -8.75, -9.375] }
{"total_number_of_episodes": 1458, "number_of_timesteps": 120797, "per_episode_reward": -365.83, "episode_reward_trend_value": 0.3067338829959409, "biggest_recent_change": 37.67652311985768},
{ "step": 1277, "visits": [14.0, 1000.0, 12.0, 1.0, 1.0, 3.0, 4.0, 4.0, 9.0, 7.0] , "episode_count": 1458, "q_vals": [-9.062, -inf, -8.75, -21.875, -21.875, -13.125, -9.844, -6.563, -8.75, -9.375] }
{ "step": 1278, "visits": [14.0, 1000.0, 12.0, 1.0, 1.0, 3.0, 4.0, 5.0, 9.0, 7.0] , "episode_count": 1458, "q_vals": [-9.062, -inf, -8.75, -21.875, -21.875, -13.125, -9.844, -9.625, -8.75, -9.375] }
{ "step": 1279, "visits": [14.0, 1000.0, 12.0, 1.0, 1.0, 3.0, 4.0, 5.0, 10.0, 7.0] , "episode_count": 1459, "q_vals": [-9.062, -inf, -8.75, -21.875, -21.875, -13.125, -9.844, -9.625, -8.75, -9.375] }
{ "step": 1280, "visits": [14.0, 1000.0, 12.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1461, "q_vals": [-9.062, -inf, -8.75, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1281, "visits": [14.0, 1000.0, 13.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1461, "q_vals": [-9.062, -inf, -8.75, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1282, "visits": [14.0, 1000.0, 14.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1462, "q_vals": [-9.062, -inf, -8.125, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1283, "visits": [14.0, 1000.0, 15.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1462, "q_vals": [-9.062, -inf, -8.167, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1284, "visits": [14.0, 1000.0, 16.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1464, "q_vals": [-9.062, -inf, -8.203, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1285, "visits": [14.0, 1000.0, 17.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1466, "q_vals": [-9.062, -inf, -8.235, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1286, "visits": [14.0, 1000.0, 18.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1466, "q_vals": [-9.062, -inf, -8.264, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{"total_number_of_episodes": 1468, "number_of_timesteps": 121632, "per_episode_reward": -367.0, "episode_reward_trend_value": 0.31579362132256517, "biggest_recent_change": 37.67652311985768},
{ "step": 1287, "visits": [14.0, 1000.0, 19.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1468, "q_vals": [-9.062, -inf, -8.289, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1288, "visits": [14.0, 1000.0, 20.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1468, "q_vals": [-9.062, -inf, -8.313, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1289, "visits": [14.0, 1000.0, 21.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1471, "q_vals": [-9.062, -inf, -8.333, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1290, "visits": [14.0, 1000.0, 22.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1471, "q_vals": [-9.062, -inf, -7.955, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1291, "visits": [14.0, 1000.0, 23.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1472, "q_vals": [-9.062, -inf, -7.989, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1292, "visits": [14.0, 1000.0, 24.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1474, "q_vals": [-9.062, -inf, -8.021, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1293, "visits": [14.0, 1000.0, 25.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1475, "q_vals": [-9.062, -inf, -7.7, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1294, "visits": [14.0, 1000.0, 26.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1475, "q_vals": [-9.062, -inf, -7.74, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1295, "visits": [14.0, 1000.0, 27.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1477, "q_vals": [-9.062, -inf, -8.264, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{"total_number_of_episodes": 1479, "number_of_timesteps": 122552, "per_episode_reward": -368.71, "episode_reward_trend_value": 0.30262842095272807, "biggest_recent_change": 37.67652311985768},
{ "step": 1296, "visits": [14.0, 1000.0, 28.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1479, "q_vals": [-9.062, -inf, -8.281, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1297, "visits": [14.0, 1000.0, 29.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1480, "q_vals": [-9.062, -inf, -8.297, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1298, "visits": [14.0, 1000.0, 30.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1481, "q_vals": [-9.062, -inf, -8.313, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1299, "visits": [14.0, 1000.0, 31.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1482, "q_vals": [-9.062, -inf, -8.327, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1300, "visits": [14.0, 1000.0, 32.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1482, "q_vals": [-9.062, -inf, -8.066, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1301, "visits": [14.0, 1000.0, 33.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1484, "q_vals": [-9.062, -inf, -8.087, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1302, "visits": [14.0, 1000.0, 34.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1487, "q_vals": [-9.062, -inf, -8.107, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1303, "visits": [14.0, 1000.0, 35.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1487, "q_vals": [-9.062, -inf, -8.125, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1304, "visits": [14.0, 1000.0, 36.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1488, "q_vals": [-9.062, -inf, -8.507, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{"total_number_of_episodes": 1490, "number_of_timesteps": 123411, "per_episode_reward": -370.18, "episode_reward_trend_value": -0.13230847140895827, "biggest_recent_change": 1.9928330327182948},
{ "step": 1305, "visits": [14.0, 1000.0, 37.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1490, "q_vals": [-9.062, -inf, -8.868, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1306, "visits": [15.0, 1000.0, 37.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1490, "q_vals": [-9.042, -inf, -8.868, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1307, "visits": [16.0, 1000.0, 37.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1490, "q_vals": [-9.023, -inf, -8.868, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1308, "visits": [17.0, 1000.0, 37.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1491, "q_vals": [-9.779, -inf, -8.868, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1309, "visits": [17.0, 1000.0, 38.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1494, "q_vals": [-9.779, -inf, -8.865, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1310, "visits": [17.0, 1000.0, 39.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1494, "q_vals": [-9.779, -inf, -8.638, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1311, "visits": [17.0, 1000.0, 40.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1495, "q_vals": [-9.779, -inf, -8.641, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1312, "visits": [17.0, 1000.0, 41.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 7.0] , "episode_count": 1497, "q_vals": [-9.779, -inf, -8.963, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.375] }
{ "step": 1313, "visits": [17.0, 1000.0, 41.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 8.0] , "episode_count": 1498, "q_vals": [-9.779, -inf, -8.963, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -8.203] }
{ "step": 1314, "visits": [17.0, 1000.0, 41.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 9.0] , "episode_count": 1499, "q_vals": [-9.779, -inf, -8.963, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -8.264] }
{"total_number_of_episodes": 1500, "number_of_timesteps": 124296, "per_episode_reward": -371.61, "episode_reward_trend_value": -0.1433362118854436, "biggest_recent_change": 1.9928330327182948},
{ "step": 1315, "visits": [17.0, 1000.0, 41.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1500, "q_vals": [-9.779, -inf, -8.963, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1316, "visits": [17.0, 1000.0, 42.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1500, "q_vals": [-9.779, -inf, -8.958, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1317, "visits": [17.0, 1000.0, 43.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1502, "q_vals": [-9.779, -inf, -8.953, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1318, "visits": [17.0, 1000.0, 44.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1502, "q_vals": [-9.779, -inf, -8.949, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1319, "visits": [17.0, 1000.0, 45.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1504, "q_vals": [-9.779, -inf, -8.904, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1320, "visits": [17.0, 1000.0, 46.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1506, "q_vals": [-9.779, -inf, -8.9, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1321, "visits": [17.0, 1000.0, 47.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1506, "q_vals": [-9.779, -inf, -8.711, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1322, "visits": [17.0, 1000.0, 48.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1508, "q_vals": [-9.779, -inf, -8.712, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1323, "visits": [17.0, 1000.0, 49.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1509, "q_vals": [-9.779, -inf, -8.713, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1324, "visits": [17.0, 1000.0, 50.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1509, "q_vals": [-9.779, -inf, -8.713, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{"total_number_of_episodes": 1511, "number_of_timesteps": 125252, "per_episode_reward": -372.87, "episode_reward_trend_value": -0.14172778539005876, "biggest_recent_change": 1.9928330327182948},
{ "step": 1325, "visits": [17.0, 1000.0, 51.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1511, "q_vals": [-9.779, -inf, -8.714, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1326, "visits": [17.0, 1000.0, 52.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1511, "q_vals": [-9.779, -inf, -8.715, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1327, "visits": [17.0, 1000.0, 53.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1511, "q_vals": [-9.779, -inf, -8.55, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1328, "visits": [17.0, 1000.0, 54.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1512, "q_vals": [-9.779, -inf, -8.554, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1329, "visits": [17.0, 1000.0, 55.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1514, "q_vals": [-9.779, -inf, -8.796, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1330, "visits": [17.0, 1000.0, 56.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1515, "q_vals": [-9.779, -inf, -8.639, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1331, "visits": [17.0, 1000.0, 57.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1515, "q_vals": [-9.779, -inf, -8.641, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1332, "visits": [17.0, 1000.0, 58.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1515, "q_vals": [-9.779, -inf, -8.492, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1333, "visits": [17.0, 1000.0, 59.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1517, "q_vals": [-9.779, -inf, -8.497, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1334, "visits": [17.0, 1000.0, 60.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1517, "q_vals": [-9.779, -inf, -8.72, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1335, "visits": [17.0, 1000.0, 61.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1518, "q_vals": [-9.779, -inf, -8.577, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1336, "visits": [17.0, 1000.0, 62.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1520, "q_vals": [-9.779, -inf, -8.791, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{"total_number_of_episodes": 1521, "number_of_timesteps": 126259, "per_episode_reward": -374.69, "episode_reward_trend_value": -0.15102721654067308, "biggest_recent_change": 1.9928330327182948},
{ "step": 1337, "visits": [17.0, 1000.0, 63.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1521, "q_vals": [-9.779, -inf, -8.79, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1338, "visits": [17.0, 1000.0, 64.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1522, "q_vals": [-9.779, -inf, -8.79, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1339, "visits": [17.0, 1000.0, 65.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1522, "q_vals": [-9.779, -inf, -8.789, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1340, "visits": [17.0, 1000.0, 66.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1522, "q_vals": [-9.779, -inf, -8.789, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1341, "visits": [17.0, 1000.0, 67.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1522, "q_vals": [-9.779, -inf, -8.657, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1342, "visits": [17.0, 1000.0, 68.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1523, "q_vals": [-9.779, -inf, -8.659, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1343, "visits": [17.0, 1000.0, 69.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1524, "q_vals": [-9.779, -inf, -8.66, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1344, "visits": [17.0, 1000.0, 70.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1526, "q_vals": [-9.779, -inf, -8.849, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1345, "visits": [17.0, 1000.0, 71.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1528, "q_vals": [-9.779, -inf, -8.847, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1346, "visits": [17.0, 1000.0, 72.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1529, "q_vals": [-9.779, -inf, -8.725, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{"total_number_of_episodes": 1531, "number_of_timesteps": 127460, "per_episode_reward": -375.8, "episode_reward_trend_value": -0.14631888472050417, "biggest_recent_change": 1.9928330327182948},
{ "step": 1347, "visits": [17.0, 1000.0, 73.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1531, "q_vals": [-9.779, -inf, -8.725, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1348, "visits": [17.0, 1000.0, 74.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1531, "q_vals": [-9.779, -inf, -8.725, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1349, "visits": [17.0, 1000.0, 75.0, 1.0, 1.0, 3.0, 4.0, 5.0, 11.0, 10.0] , "episode_count": 1532, "q_vals": [-9.779, -inf, -8.901, -21.875, -21.875, -13.125, -9.844, -9.625, -9.943, -9.625] }
{ "step": 1350, "visits": [17.0, 1000.0, 75.0, 1.0, 1.0, 3.0, 4.0, 6.0, 11.0, 10.0] , "episode_count": 1532, "q_vals": [-9.779, -inf, -8.901, -21.875, -21.875, -13.125, -9.844, -8.021, -9.943, -9.625] }
{ "step": 1351, "visits": [17.0, 1000.0, 75.0, 1.0, 1.0, 3.0, 4.0, 7.0, 11.0, 10.0] , "episode_count": 1532, "q_vals": [-9.779, -inf, -8.901, -21.875, -21.875, -13.125, -9.844, -8.125, -9.943, -9.625] }
{ "step": 1352, "visits": [17.0, 1000.0, 75.0, 1.0, 1.0, 3.0, 4.0, 8.0, 11.0, 10.0] , "episode_count": 1532, "q_vals": [-9.779, -inf, -8.901, -21.875, -21.875, -13.125, -9.844, -7.109, -9.943, -9.625] }
{ "step": 1353, "visits": [17.0, 1000.0, 75.0, 1.0, 1.0, 3.0, 4.0, 9.0, 11.0, 10.0] , "episode_count": 1533, "q_vals": [-9.779, -inf, -8.901, -21.875, -21.875, -13.125, -9.844, -8.75, -9.943, -9.625] }
{ "step": 1354, "visits": [17.0, 1000.0, 75.0, 1.0, 1.0, 3.0, 4.0, 10.0, 11.0, 10.0] , "episode_count": 1536, "q_vals": [-9.779, -inf, -8.901, -21.875, -21.875, -13.125, -9.844, -7.875, -9.943, -9.625] }
{ "step": 1355, "visits": [17.0, 1000.0, 75.0, 1.0, 1.0, 3.0, 4.0, 11.0, 11.0, 10.0] , "episode_count": 1536, "q_vals": [-9.779, -inf, -8.901, -21.875, -21.875, -13.125, -9.844, -9.148, -9.943, -9.625] }
{ "step": 1356, "visits": [17.0, 1000.0, 75.0, 1.0, 1.0, 3.0, 4.0, 12.0, 11.0, 10.0] , "episode_count": 1539, "q_vals": [-9.779, -inf, -8.901, -21.875, -21.875, -13.125, -9.844, -9.115, -9.943, -9.625] }
{ "step": 1357, "visits": [17.0, 1000.0, 75.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1540, "q_vals": [-9.779, -inf, -8.901, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1358, "visits": [17.0, 1000.0, 76.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1540, "q_vals": [-9.779, -inf, -8.899, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1542, "number_of_timesteps": 128575, "per_episode_reward": -377.13, "episode_reward_trend_value": -0.13900190011566071, "biggest_recent_change": 1.8153858042247748},
{ "step": 1359, "visits": [17.0, 1000.0, 77.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1542, "q_vals": [-9.779, -inf, -8.897, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1360, "visits": [17.0, 1000.0, 78.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1542, "q_vals": [-9.779, -inf, -8.895, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1361, "visits": [17.0, 1000.0, 79.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1543, "q_vals": [-9.779, -inf, -8.782, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1362, "visits": [17.0, 1000.0, 80.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1545, "q_vals": [-9.779, -inf, -8.782, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1363, "visits": [17.0, 1000.0, 81.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1547, "q_vals": [-9.779, -inf, -8.781, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1364, "visits": [17.0, 1000.0, 82.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1548, "q_vals": [-9.779, -inf, -8.941, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1365, "visits": [17.0, 1000.0, 83.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1550, "q_vals": [-9.779, -inf, -8.833, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1366, "visits": [17.0, 1000.0, 84.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1550, "q_vals": [-9.779, -inf, -8.832, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1552, "number_of_timesteps": 129341, "per_episode_reward": -379.05, "episode_reward_trend_value": -0.14686898485677552, "biggest_recent_change": 1.9124414555558928},
{ "step": 1367, "visits": [17.0, 1000.0, 85.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1552, "q_vals": [-9.779, -inf, -8.728, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1368, "visits": [17.0, 1000.0, 86.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1553, "q_vals": [-9.779, -inf, -8.729, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1369, "visits": [17.0, 1000.0, 87.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1553, "q_vals": [-9.779, -inf, -8.729, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1370, "visits": [17.0, 1000.0, 88.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1555, "q_vals": [-9.779, -inf, -8.878, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1371, "visits": [17.0, 1000.0, 89.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1556, "q_vals": [-9.779, -inf, -8.833, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1372, "visits": [17.0, 1000.0, 90.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1558, "q_vals": [-9.779, -inf, -8.832, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1373, "visits": [17.0, 1000.0, 91.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1559, "q_vals": [-9.779, -inf, -8.831, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1374, "visits": [17.0, 1000.0, 92.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1560, "q_vals": [-9.779, -inf, -8.735, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1562, "number_of_timesteps": 130112, "per_episode_reward": -379.86, "episode_reward_trend_value": -0.14296567307617794, "biggest_recent_change": 1.9124414555558928},
{ "step": 1375, "visits": [17.0, 1000.0, 93.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1562, "q_vals": [-9.779, -inf, -8.641, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1376, "visits": [17.0, 1000.0, 94.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1564, "q_vals": [-9.779, -inf, -8.642, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1377, "visits": [17.0, 1000.0, 95.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1564, "q_vals": [-9.779, -inf, -8.644, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1378, "visits": [17.0, 1000.0, 96.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1565, "q_vals": [-9.779, -inf, -8.645, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1379, "visits": [17.0, 1000.0, 97.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1566, "q_vals": [-9.779, -inf, -8.556, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1380, "visits": [17.0, 1000.0, 98.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1566, "q_vals": [-9.779, -inf, -8.557, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1381, "visits": [17.0, 1000.0, 99.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1566, "q_vals": [-9.779, -inf, -8.559, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1382, "visits": [17.0, 1000.0, 100.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1568, "q_vals": [-9.779, -inf, -8.561, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1572, "number_of_timesteps": 130877, "per_episode_reward": -379.97, "episode_reward_trend_value": -0.1250729638877323, "biggest_recent_change": 1.9124414555558928},
{ "step": 1383, "visits": [17.0, 1000.0, 101.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1572, "q_vals": [-9.779, -inf, -8.563, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1384, "visits": [17.0, 1000.0, 102.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1573, "q_vals": [-9.779, -inf, -8.479, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1385, "visits": [17.0, 1000.0, 103.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1574, "q_vals": [-9.779, -inf, -8.482, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1386, "visits": [17.0, 1000.0, 104.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1575, "q_vals": [-9.779, -inf, -8.484, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1387, "visits": [17.0, 1000.0, 105.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1575, "q_vals": [-9.779, -inf, -8.487, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1388, "visits": [17.0, 1000.0, 106.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1577, "q_vals": [-9.779, -inf, -8.489, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1389, "visits": [17.0, 1000.0, 107.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1578, "q_vals": [-9.779, -inf, -8.41, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1390, "visits": [17.0, 1000.0, 108.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1581, "q_vals": [-9.779, -inf, -8.413, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1582, "number_of_timesteps": 131598, "per_episode_reward": -380.95, "episode_reward_trend_value": -0.11971280873685448, "biggest_recent_change": 1.9124414555558928},
{ "step": 1391, "visits": [17.0, 1000.0, 109.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1582, "q_vals": [-9.779, -inf, -8.416, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1392, "visits": [17.0, 1000.0, 110.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1584, "q_vals": [-9.779, -inf, -8.419, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1393, "visits": [17.0, 1000.0, 111.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1585, "q_vals": [-9.779, -inf, -8.422, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1394, "visits": [17.0, 1000.0, 112.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1586, "q_vals": [-9.779, -inf, -8.425, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1395, "visits": [17.0, 1000.0, 113.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1587, "q_vals": [-9.779, -inf, -8.544, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1396, "visits": [17.0, 1000.0, 114.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1588, "q_vals": [-9.779, -inf, -8.546, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1397, "visits": [17.0, 1000.0, 115.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1589, "q_vals": [-9.779, -inf, -8.548, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1398, "visits": [17.0, 1000.0, 116.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1591, "q_vals": [-9.779, -inf, -8.474, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1592, "number_of_timesteps": 132260, "per_episode_reward": -380.83, "episode_reward_trend_value": -0.1024462357955656, "biggest_recent_change": 1.9124414555558928},
{ "step": 1399, "visits": [17.0, 1000.0, 117.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1592, "q_vals": [-9.779, -inf, -8.477, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1400, "visits": [17.0, 1000.0, 118.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1594, "q_vals": [-9.779, -inf, -8.479, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1401, "visits": [17.0, 1000.0, 119.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1595, "q_vals": [-9.779, -inf, -8.481, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1402, "visits": [17.0, 1000.0, 120.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1596, "q_vals": [-9.779, -inf, -8.41, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1403, "visits": [17.0, 1000.0, 121.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1598, "q_vals": [-9.779, -inf, -8.413, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1404, "visits": [17.0, 1000.0, 122.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1599, "q_vals": [-9.779, -inf, -8.524, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1405, "visits": [17.0, 1000.0, 123.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1600, "q_vals": [-9.779, -inf, -8.525, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1602, "number_of_timesteps": 132994, "per_episode_reward": -380.72, "episode_reward_trend_value": -0.0871731882450471, "biggest_recent_change": 1.9124414555558928},
{ "step": 1406, "visits": [17.0, 1000.0, 124.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1602, "q_vals": [-9.779, -inf, -8.527, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1407, "visits": [17.0, 1000.0, 125.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1605, "q_vals": [-9.779, -inf, -8.529, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1408, "visits": [17.0, 1000.0, 126.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1606, "q_vals": [-9.779, -inf, -8.531, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1409, "visits": [17.0, 1000.0, 127.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1607, "q_vals": [-9.779, -inf, -8.533, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1410, "visits": [17.0, 1000.0, 128.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1607, "q_vals": [-9.779, -inf, -8.637, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1411, "visits": [17.0, 1000.0, 129.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1608, "q_vals": [-9.779, -inf, -8.638, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1412, "visits": [17.0, 1000.0, 130.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1611, "q_vals": [-9.779, -inf, -8.639, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1613, "number_of_timesteps": 133706, "per_episode_reward": -380.95, "episode_reward_trend_value": -0.06954251315793777, "biggest_recent_change": 1.9124414555558928},
{ "step": 1413, "visits": [17.0, 1000.0, 131.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1613, "q_vals": [-9.779, -inf, -8.639, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1414, "visits": [17.0, 1000.0, 132.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1614, "q_vals": [-9.779, -inf, -8.64, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1415, "visits": [17.0, 1000.0, 133.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1614, "q_vals": [-9.779, -inf, -8.641, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1416, "visits": [17.0, 1000.0, 134.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1615, "q_vals": [-9.779, -inf, -8.577, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1417, "visits": [17.0, 1000.0, 135.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1617, "q_vals": [-9.779, -inf, -8.675, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1418, "visits": [17.0, 1000.0, 136.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1618, "q_vals": [-9.779, -inf, -8.676, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1419, "visits": [17.0, 1000.0, 137.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1621, "q_vals": [-9.779, -inf, -8.612, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1623, "number_of_timesteps": 134403, "per_episode_reward": -382.13, "episode_reward_trend_value": -0.07034338760361152, "biggest_recent_change": 1.9124414555558928},
{ "step": 1420, "visits": [17.0, 1000.0, 138.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1623, "q_vals": [-9.779, -inf, -8.55, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1421, "visits": [17.0, 1000.0, 139.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1624, "q_vals": [-9.779, -inf, -8.646, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1422, "visits": [17.0, 1000.0, 140.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1624, "q_vals": [-9.779, -inf, -8.646, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1423, "visits": [17.0, 1000.0, 141.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1624, "q_vals": [-9.779, -inf, -8.647, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1424, "visits": [17.0, 1000.0, 142.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1626, "q_vals": [-9.779, -inf, -8.648, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1425, "visits": [17.0, 1000.0, 143.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1628, "q_vals": [-9.779, -inf, -8.74, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1426, "visits": [17.0, 1000.0, 144.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1631, "q_vals": [-9.779, -inf, -8.832, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1633, "number_of_timesteps": 135085, "per_episode_reward": -381.96, "episode_reward_trend_value": -0.05368342700996007, "biggest_recent_change": 1.9124414555558928},
{ "step": 1427, "visits": [17.0, 1000.0, 145.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1633, "q_vals": [-9.779, -inf, -8.771, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1428, "visits": [17.0, 1000.0, 146.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1633, "q_vals": [-9.779, -inf, -8.861, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1429, "visits": [17.0, 1000.0, 147.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1633, "q_vals": [-9.779, -inf, -8.86, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1430, "visits": [17.0, 1000.0, 148.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1635, "q_vals": [-9.779, -inf, -8.8, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1431, "visits": [17.0, 1000.0, 149.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1637, "q_vals": [-9.779, -inf, -8.8, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1432, "visits": [17.0, 1000.0, 150.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1639, "q_vals": [-9.779, -inf, -8.799, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1433, "visits": [17.0, 1000.0, 151.0, 1.0, 1.0, 3.0, 4.0, 13.0, 11.0, 10.0] , "episode_count": 1639, "q_vals": [-9.779, -inf, -8.886, -21.875, -21.875, -13.125, -9.844, -10.096, -9.943, -9.625] }
{ "step": 1434, "visits": [17.0, 1000.0, 151.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1640, "q_vals": [-9.779, -inf, -8.886, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1643, "number_of_timesteps": 135777, "per_episode_reward": -382.96, "episode_reward_trend_value": -0.04344985285779519, "biggest_recent_change": 1.1824687805597023},
{ "step": 1435, "visits": [17.0, 1000.0, 152.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1643, "q_vals": [-9.779, -inf, -8.885, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1436, "visits": [17.0, 1000.0, 153.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1643, "q_vals": [-9.779, -inf, -8.827, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1437, "visits": [17.0, 1000.0, 154.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1646, "q_vals": [-9.779, -inf, -8.826, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1438, "visits": [17.0, 1000.0, 155.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1646, "q_vals": [-9.779, -inf, -8.769, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1439, "visits": [17.0, 1000.0, 156.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1648, "q_vals": [-9.779, -inf, -8.769, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1440, "visits": [17.0, 1000.0, 157.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1648, "q_vals": [-9.779, -inf, -8.769, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1441, "visits": [17.0, 1000.0, 158.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1651, "q_vals": [-9.779, -inf, -8.852, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1442, "visits": [17.0, 1000.0, 159.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1652, "q_vals": [-9.779, -inf, -8.851, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1653, "number_of_timesteps": 136439, "per_episode_reward": -383.08, "episode_reward_trend_value": -0.035699669057379424, "biggest_recent_change": 1.1824687805597023},
{ "step": 1443, "visits": [17.0, 1000.0, 160.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1653, "q_vals": [-9.779, -inf, -8.796, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1444, "visits": [17.0, 1000.0, 161.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1654, "q_vals": [-9.779, -inf, -8.796, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1445, "visits": [17.0, 1000.0, 162.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1656, "q_vals": [-9.779, -inf, -8.877, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1446, "visits": [17.0, 1000.0, 163.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1657, "q_vals": [-9.779, -inf, -8.876, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1447, "visits": [17.0, 1000.0, 164.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1659, "q_vals": [-9.779, -inf, -8.955, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1448, "visits": [17.0, 1000.0, 165.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1661, "q_vals": [-9.779, -inf, -8.954, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1449, "visits": [17.0, 1000.0, 166.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1661, "q_vals": [-9.779, -inf, -8.953, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1663, "number_of_timesteps": 137144, "per_episode_reward": -384.27, "episode_reward_trend_value": -0.04776041861995976, "biggest_recent_change": 1.1886599984446775},
{ "step": 1450, "visits": [17.0, 1000.0, 167.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1663, "q_vals": [-9.779, -inf, -9.03, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1451, "visits": [17.0, 1000.0, 168.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1663, "q_vals": [-9.779, -inf, -9.028, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1452, "visits": [17.0, 1000.0, 169.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1664, "q_vals": [-9.779, -inf, -9.027, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1453, "visits": [17.0, 1000.0, 170.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1667, "q_vals": [-9.779, -inf, -9.025, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1454, "visits": [17.0, 1000.0, 171.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1669, "q_vals": [-9.779, -inf, -9.023, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1455, "visits": [17.0, 1000.0, 172.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1669, "q_vals": [-9.779, -inf, -9.022, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1456, "visits": [17.0, 1000.0, 173.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1671, "q_vals": [-9.779, -inf, -9.02, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1457, "visits": [17.0, 1000.0, 174.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1672, "q_vals": [-9.779, -inf, -9.019, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1673, "number_of_timesteps": 137863, "per_episode_reward": -385.53, "episode_reward_trend_value": -0.05084895874759669, "biggest_recent_change": 1.263351840602411},
{ "step": 1458, "visits": [17.0, 1000.0, 175.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1673, "q_vals": [-9.779, -inf, -9.017, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1459, "visits": [17.0, 1000.0, 176.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1674, "q_vals": [-9.779, -inf, -8.966, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1460, "visits": [17.0, 1000.0, 177.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1675, "q_vals": [-9.779, -inf, -8.965, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1461, "visits": [17.0, 1000.0, 178.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1677, "q_vals": [-9.779, -inf, -9.037, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1462, "visits": [17.0, 1000.0, 179.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1679, "q_vals": [-9.779, -inf, -9.036, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1463, "visits": [17.0, 1000.0, 180.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1680, "q_vals": [-9.779, -inf, -9.034, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1464, "visits": [17.0, 1000.0, 181.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1680, "q_vals": [-9.779, -inf, -9.033, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1465, "visits": [17.0, 1000.0, 182.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1680, "q_vals": [-9.779, -inf, -9.031, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{"total_number_of_episodes": 1683, "number_of_timesteps": 138613, "per_episode_reward": -386.17, "episode_reward_trend_value": -0.05931611167892028, "biggest_recent_change": 1.263351840602411},
{ "step": 1466, "visits": [17.0, 1000.0, 183.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 10.0] , "episode_count": 1683, "q_vals": [-9.779, -inf, -9.101, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.625] }
{ "step": 1467, "visits": [17.0, 1000.0, 183.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 11.0] , "episode_count": 1685, "q_vals": [-9.779, -inf, -9.101, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.545] }
{ "step": 1468, "visits": [17.0, 1000.0, 183.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 12.0] , "episode_count": 1686, "q_vals": [-9.779, -inf, -9.101, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.479] }
{ "step": 1469, "visits": [17.0, 1000.0, 183.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 13.0] , "episode_count": 1686, "q_vals": [-9.779, -inf, -9.101, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.423] }
{ "step": 1470, "visits": [17.0, 1000.0, 183.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 14.0] , "episode_count": 1688, "q_vals": [-9.779, -inf, -9.101, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.375] }
{ "step": 1471, "visits": [17.0, 1000.0, 183.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 15.0] , "episode_count": 1688, "q_vals": [-9.779, -inf, -9.101, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -9.333] }
{ "step": 1472, "visits": [17.0, 1000.0, 183.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1690, "q_vals": [-9.779, -inf, -9.101, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1473, "visits": [17.0, 1000.0, 184.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1690, "q_vals": [-9.779, -inf, -9.099, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1693, "number_of_timesteps": 139385, "per_episode_reward": -385.95, "episode_reward_trend_value": -0.05816234913636877, "biggest_recent_change": 1.263351840602411},
{ "step": 1474, "visits": [17.0, 1000.0, 185.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1693, "q_vals": [-9.779, -inf, -9.097, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1475, "visits": [17.0, 1000.0, 186.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1693, "q_vals": [-9.779, -inf, -9.095, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1476, "visits": [17.0, 1000.0, 187.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1694, "q_vals": [-9.779, -inf, -9.094, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1477, "visits": [17.0, 1000.0, 188.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1696, "q_vals": [-9.779, -inf, -9.045, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1478, "visits": [17.0, 1000.0, 189.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1697, "q_vals": [-9.779, -inf, -9.044, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1479, "visits": [17.0, 1000.0, 190.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1697, "q_vals": [-9.779, -inf, -9.042, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
[-9.779, -inf, -9.041, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117]
{ "step": 1481, "visits": [17.0, 1000.0, 192.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1699, "q_vals": [-9.779, -inf, -9.107, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1482, "visits": [17.0, 1000.0, 193.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1702, "q_vals": [-9.779, -inf, -9.106, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1483, "visits": [17.0, 1000.0, 194.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1702, "q_vals": [-9.779, -inf, -9.104, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1484, "visits": [17.0, 1000.0, 195.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1702, "q_vals": [-9.779, -inf, -9.169, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1704, "number_of_timesteps": 140362, "per_episode_reward": -386.91, "episode_reward_trend_value": -0.06623992987080415, "biggest_recent_change": 1.263351840602411},
{ "step": 1485, "visits": [17.0, 1000.0, 196.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1704, "q_vals": [-9.779, -inf, -9.122, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1486, "visits": [17.0, 1000.0, 197.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1705, "q_vals": [-9.779, -inf, -9.121, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1487, "visits": [17.0, 1000.0, 198.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1706, "q_vals": [-9.779, -inf, -9.075, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1488, "visits": [17.0, 1000.0, 199.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1706, "q_vals": [-9.779, -inf, -9.073, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1489, "visits": [17.0, 1000.0, 200.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1709, "q_vals": [-9.779, -inf, -9.071, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1490, "visits": [17.0, 1000.0, 201.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1711, "q_vals": [-9.779, -inf, -9.026, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1491, "visits": [17.0, 1000.0, 202.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1712, "q_vals": [-9.779, -inf, -9.025, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1492, "visits": [17.0, 1000.0, 203.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1713, "q_vals": [-9.779, -inf, -8.98, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1714, "number_of_timesteps": 141175, "per_episode_reward": -387.86, "episode_reward_trend_value": -0.06370247012418481, "biggest_recent_change": 1.263351840602411},
{ "step": 1493, "visits": [17.0, 1000.0, 204.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1714, "q_vals": [-9.779, -inf, -8.936, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1494, "visits": [17.0, 1000.0, 205.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1714, "q_vals": [-9.779, -inf, -8.935, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1495, "visits": [17.0, 1000.0, 206.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1714, "q_vals": [-9.779, -inf, -8.892, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1496, "visits": [17.0, 1000.0, 207.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1716, "q_vals": [-9.779, -inf, -8.891, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1497, "visits": [17.0, 1000.0, 208.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1717, "q_vals": [-9.779, -inf, -8.891, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1498, "visits": [17.0, 1000.0, 209.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1717, "q_vals": [-9.779, -inf, -8.953, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1499, "visits": [17.0, 1000.0, 210.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1718, "q_vals": [-9.779, -inf, -8.952, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1500, "visits": [17.0, 1000.0, 211.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1719, "q_vals": [-9.779, -inf, -9.013, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1501, "visits": [17.0, 1000.0, 212.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1721, "q_vals": [-9.779, -inf, -9.012, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1502, "visits": [17.0, 1000.0, 213.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1723, "q_vals": [-9.779, -inf, -9.011, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1724, "number_of_timesteps": 142135, "per_episode_reward": -389.57, "episode_reward_trend_value": -0.08447136020038784, "biggest_recent_change": 1.704108071712028},
{ "step": 1503, "visits": [17.0, 1000.0, 214.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1724, "q_vals": [-9.779, -inf, -9.071, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1504, "visits": [17.0, 1000.0, 215.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1725, "q_vals": [-9.779, -inf, -9.029, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1505, "visits": [17.0, 1000.0, 216.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1725, "q_vals": [-9.779, -inf, -9.027, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1506, "visits": [17.0, 1000.0, 217.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1725, "q_vals": [-9.779, -inf, -9.026, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1507, "visits": [17.0, 1000.0, 218.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1726, "q_vals": [-9.779, -inf, -9.025, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1508, "visits": [17.0, 1000.0, 219.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1727, "q_vals": [-9.779, -inf, -9.083, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1509, "visits": [17.0, 1000.0, 220.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1728, "q_vals": [-9.779, -inf, -9.082, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1510, "visits": [17.0, 1000.0, 221.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1729, "q_vals": [-9.779, -inf, -9.08, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1511, "visits": [17.0, 1000.0, 222.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1732, "q_vals": [-9.779, -inf, -9.079, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
[-9.779, -inf, -9.136, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117]
{"total_number_of_episodes": 1734, "number_of_timesteps": 143077, "per_episode_reward": -391.19, "episode_reward_trend_value": -0.09147420995582883, "biggest_recent_change": 1.704108071712028},
{ "step": 1513, "visits": [17.0, 1000.0, 224.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1734, "q_vals": [-9.779, -inf, -9.095, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1514, "visits": [17.0, 1000.0, 225.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1735, "q_vals": [-9.779, -inf, -9.094, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1515, "visits": [17.0, 1000.0, 226.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1735, "q_vals": [-9.779, -inf, -9.092, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1516, "visits": [17.0, 1000.0, 227.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1736, "q_vals": [-9.779, -inf, -9.091, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1517, "visits": [17.0, 1000.0, 228.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1738, "q_vals": [-9.779, -inf, -9.051, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1518, "visits": [17.0, 1000.0, 229.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1738, "q_vals": [-9.779, -inf, -9.05, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1519, "visits": [17.0, 1000.0, 230.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1739, "q_vals": [-9.779, -inf, -9.048, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1520, "visits": [17.0, 1000.0, 231.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1742, "q_vals": [-9.779, -inf, -9.047, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1744, "number_of_timesteps": 143924, "per_episode_reward": -391.5, "episode_reward_trend_value": -0.09353932935355007, "biggest_recent_change": 1.704108071712028},
{ "step": 1521, "visits": [17.0, 1000.0, 232.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1744, "q_vals": [-9.779, -inf, -9.046, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1522, "visits": [17.0, 1000.0, 233.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1744, "q_vals": [-9.779, -inf, -9.045, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1523, "visits": [17.0, 1000.0, 234.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1744, "q_vals": [-9.779, -inf, -9.043, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1524, "visits": [17.0, 1000.0, 235.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1745, "q_vals": [-9.779, -inf, -9.042, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1525, "visits": [17.0, 1000.0, 236.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1745, "q_vals": [-9.779, -inf, -9.041, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1526, "visits": [17.0, 1000.0, 237.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1747, "q_vals": [-9.779, -inf, -9.04, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1527, "visits": [17.0, 1000.0, 238.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1747, "q_vals": [-9.779, -inf, -9.038, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1528, "visits": [17.0, 1000.0, 239.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1750, "q_vals": [-9.779, -inf, -9.037, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1529, "visits": [17.0, 1000.0, 240.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1753, "q_vals": [-9.779, -inf, -9.0, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1754, "number_of_timesteps": 144802, "per_episode_reward": -393.01, "episode_reward_trend_value": -0.09710536356724775, "biggest_recent_change": 1.704108071712028},
{ "step": 1530, "visits": [17.0, 1000.0, 241.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1754, "q_vals": [-9.779, -inf, -8.998, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1531, "visits": [17.0, 1000.0, 242.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1754, "q_vals": [-9.779, -inf, -8.997, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1532, "visits": [17.0, 1000.0, 243.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1754, "q_vals": [-9.779, -inf, -8.996, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1533, "visits": [17.0, 1000.0, 244.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1754, "q_vals": [-9.779, -inf, -8.995, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1534, "visits": [17.0, 1000.0, 245.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1754, "q_vals": [-9.779, -inf, -8.994, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1535, "visits": [17.0, 1000.0, 246.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1756, "q_vals": [-9.779, -inf, -8.993, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1536, "visits": [17.0, 1000.0, 247.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1761, "q_vals": [-9.779, -inf, -8.992, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1537, "visits": [17.0, 1000.0, 248.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1761, "q_vals": [-9.779, -inf, -8.991, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1538, "visits": [17.0, 1000.0, 249.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1762, "q_vals": [-9.779, -inf, -9.043, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1539, "visits": [17.0, 1000.0, 250.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1762, "q_vals": [-9.779, -inf, -9.042, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1540, "visits": [17.0, 1000.0, 251.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1763, "q_vals": [-9.779, -inf, -9.041, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1764, "number_of_timesteps": 145687, "per_episode_reward": -394.18, "episode_reward_trend_value": -0.09616971740459992, "biggest_recent_change": 1.704108071712028},
{ "step": 1541, "visits": [17.0, 1000.0, 252.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1764, "q_vals": [-9.779, -inf, -9.04, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1542, "visits": [17.0, 1000.0, 253.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1764, "q_vals": [-9.779, -inf, -9.09, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
[-9.779, -inf, -9.089, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117]
{ "step": 1544, "visits": [17.0, 1000.0, 255.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1768, "q_vals": [-9.779, -inf, -9.088, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1545, "visits": [17.0, 1000.0, 256.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1770, "q_vals": [-9.779, -inf, -9.086, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1546, "visits": [17.0, 1000.0, 257.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1771, "q_vals": [-9.779, -inf, -9.085, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1547, "visits": [17.0, 1000.0, 258.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1772, "q_vals": [-9.779, -inf, -9.084, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1548, "visits": [17.0, 1000.0, 259.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1773, "q_vals": [-9.779, -inf, -9.083, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1774, "number_of_timesteps": 146502, "per_episode_reward": -394.46, "episode_reward_trend_value": -0.09212920821667771, "biggest_recent_change": 1.704108071712028},
{ "step": 1549, "visits": [17.0, 1000.0, 260.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1774, "q_vals": [-9.779, -inf, -9.081, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1550, "visits": [17.0, 1000.0, 261.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1774, "q_vals": [-9.779, -inf, -9.13, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1551, "visits": [17.0, 1000.0, 262.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1776, "q_vals": [-9.779, -inf, -9.095, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1552, "visits": [17.0, 1000.0, 263.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1776, "q_vals": [-9.779, -inf, -9.094, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1553, "visits": [17.0, 1000.0, 264.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1776, "q_vals": [-9.779, -inf, -9.093, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1554, "visits": [17.0, 1000.0, 265.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1781, "q_vals": [-9.779, -inf, -9.059, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1555, "visits": [17.0, 1000.0, 266.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1782, "q_vals": [-9.779, -inf, -9.057, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1784, "number_of_timesteps": 147301, "per_episode_reward": -394.4, "episode_reward_trend_value": -0.09390883425563049, "biggest_recent_change": 1.704108071712028},
{ "step": 1556, "visits": [17.0, 1000.0, 267.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1784, "q_vals": [-9.779, -inf, -9.105, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1557, "visits": [17.0, 1000.0, 268.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1784, "q_vals": [-9.779, -inf, -9.071, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1558, "visits": [17.0, 1000.0, 269.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1785, "q_vals": [-9.779, -inf, -9.07, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1559, "visits": [17.0, 1000.0, 270.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1785, "q_vals": [-9.779, -inf, -9.037, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1560, "visits": [17.0, 1000.0, 271.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1786, "q_vals": [-9.779, -inf, -9.003, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1561, "visits": [17.0, 1000.0, 272.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1786, "q_vals": [-9.779, -inf, -8.97, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1562, "visits": [17.0, 1000.0, 273.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1789, "q_vals": [-9.779, -inf, -8.937, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1563, "visits": [17.0, 1000.0, 274.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1789, "q_vals": [-9.779, -inf, -8.937, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1564, "visits": [17.0, 1000.0, 275.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1792, "q_vals": [-9.779, -inf, -8.936, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1565, "visits": [17.0, 1000.0, 276.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1792, "q_vals": [-9.779, -inf, -8.935, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1794, "number_of_timesteps": 148137, "per_episode_reward": -395.89, "episode_reward_trend_value": -0.09981005964560394, "biggest_recent_change": 1.704108071712028},
{ "step": 1566, "visits": [17.0, 1000.0, 277.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1794, "q_vals": [-9.779, -inf, -8.935, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1567, "visits": [17.0, 1000.0, 278.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1794, "q_vals": [-9.779, -inf, -8.902, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1568, "visits": [17.0, 1000.0, 279.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1794, "q_vals": [-9.779, -inf, -8.902, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1569, "visits": [17.0, 1000.0, 280.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1797, "q_vals": [-9.779, -inf, -8.901, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1570, "visits": [17.0, 1000.0, 281.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1797, "q_vals": [-9.779, -inf, -8.87, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1571, "visits": [17.0, 1000.0, 282.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1799, "q_vals": [-9.779, -inf, -8.869, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1572, "visits": [17.0, 1000.0, 283.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1799, "q_vals": [-9.779, -inf, -8.869, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1573, "visits": [17.0, 1000.0, 284.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1801, "q_vals": [-9.779, -inf, -8.868, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1574, "visits": [17.0, 1000.0, 285.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1803, "q_vals": [-9.779, -inf, -8.868, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1804, "number_of_timesteps": 148991, "per_episode_reward": -394.36, "episode_reward_trend_value": -0.07214399773309879, "biggest_recent_change": 1.704108071712028},
{ "step": 1575, "visits": [17.0, 1000.0, 286.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1804, "q_vals": [-9.779, -inf, -8.913, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1576, "visits": [17.0, 1000.0, 287.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1804, "q_vals": [-9.779, -inf, -8.913, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1577, "visits": [17.0, 1000.0, 288.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1805, "q_vals": [-9.779, -inf, -8.912, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1578, "visits": [17.0, 1000.0, 289.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1805, "q_vals": [-9.779, -inf, -8.912, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1579, "visits": [17.0, 1000.0, 290.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1806, "q_vals": [-9.779, -inf, -8.911, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1580, "visits": [17.0, 1000.0, 291.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1806, "q_vals": [-9.779, -inf, -8.956, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1581, "visits": [17.0, 1000.0, 292.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1808, "q_vals": [-9.779, -inf, -8.955, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1582, "visits": [17.0, 1000.0, 293.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1809, "q_vals": [-9.779, -inf, -8.954, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1583, "visits": [17.0, 1000.0, 294.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1811, "q_vals": [-9.779, -inf, -8.954, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1584, "visits": [17.0, 1000.0, 295.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1812, "q_vals": [-9.779, -inf, -8.997, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1585, "visits": [17.0, 1000.0, 296.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1813, "q_vals": [-9.779, -inf, -8.997, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1586, "visits": [17.0, 1000.0, 297.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1813, "q_vals": [-9.779, -inf, -8.996, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1814, "number_of_timesteps": 149999, "per_episode_reward": -394.84, "episode_reward_trend_value": -0.05864561389029492, "biggest_recent_change": 1.6216762598507444},
{ "step": 1587, "visits": [17.0, 1000.0, 298.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1814, "q_vals": [-9.779, -inf, -8.966, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1588, "visits": [17.0, 1000.0, 299.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1815, "q_vals": [-9.779, -inf, -8.965, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1589, "visits": [17.0, 1000.0, 300.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1817, "q_vals": [-9.779, -inf, -8.964, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1590, "visits": [17.0, 1000.0, 301.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1818, "q_vals": [-9.779, -inf, -8.963, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1591, "visits": [17.0, 1000.0, 302.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1818, "q_vals": [-9.779, -inf, -8.963, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1592, "visits": [17.0, 1000.0, 303.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1818, "q_vals": [-9.779, -inf, -8.962, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1593, "visits": [17.0, 1000.0, 304.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1818, "q_vals": [-9.779, -inf, -8.961, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1594, "visits": [17.0, 1000.0, 305.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1819, "q_vals": [-9.779, -inf, -9.004, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1595, "visits": [17.0, 1000.0, 306.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1819, "q_vals": [-9.779, -inf, -8.974, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1596, "visits": [17.0, 1000.0, 307.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1820, "q_vals": [-9.779, -inf, -8.974, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1597, "visits": [17.0, 1000.0, 308.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1822, "q_vals": [-9.779, -inf, -8.944, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1825, "number_of_timesteps": 151114, "per_episode_reward": -393.75, "episode_reward_trend_value": -0.02851572669704423, "biggest_recent_change": 1.535848168761504},
{ "step": 1598, "visits": [17.0, 1000.0, 309.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1825, "q_vals": [-9.779, -inf, -8.915, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1599, "visits": [17.0, 1000.0, 310.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1825, "q_vals": [-9.779, -inf, -8.915, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1600, "visits": [17.0, 1000.0, 311.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1826, "q_vals": [-9.779, -inf, -8.914, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1601, "visits": [17.0, 1000.0, 312.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1828, "q_vals": [-9.779, -inf, -8.914, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1602, "visits": [17.0, 1000.0, 313.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1829, "q_vals": [-9.779, -inf, -8.913, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1603, "visits": [17.0, 1000.0, 314.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1829, "q_vals": [-9.779, -inf, -8.885, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1604, "visits": [17.0, 1000.0, 315.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1831, "q_vals": [-9.779, -inf, -8.885, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1605, "visits": [17.0, 1000.0, 316.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1832, "q_vals": [-9.779, -inf, -8.884, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1606, "visits": [17.0, 1000.0, 317.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1834, "q_vals": [-9.779, -inf, -8.884, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1607, "visits": [17.0, 1000.0, 318.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1834, "q_vals": [-9.779, -inf, -8.883, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1836, "number_of_timesteps": 152087, "per_episode_reward": -394.01, "episode_reward_trend_value": -0.027961300318692865, "biggest_recent_change": 1.535848168761504},
{ "step": 1608, "visits": [17.0, 1000.0, 319.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1836, "q_vals": [-9.779, -inf, -8.883, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1609, "visits": [17.0, 1000.0, 320.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1836, "q_vals": [-9.779, -inf, -8.923, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1610, "visits": [17.0, 1000.0, 321.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1837, "q_vals": [-9.779, -inf, -8.923, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1611, "visits": [17.0, 1000.0, 322.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1838, "q_vals": [-9.779, -inf, -8.922, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1612, "visits": [17.0, 1000.0, 323.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1840, "q_vals": [-9.779, -inf, -8.922, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1613, "visits": [17.0, 1000.0, 324.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1840, "q_vals": [-9.779, -inf, -8.894, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1614, "visits": [17.0, 1000.0, 325.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1842, "q_vals": [-9.779, -inf, -8.894, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1615, "visits": [17.0, 1000.0, 326.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1845, "q_vals": [-9.779, -inf, -8.893, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1616, "visits": [17.0, 1000.0, 327.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1845, "q_vals": [-9.779, -inf, -8.893, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1846, "number_of_timesteps": 152955, "per_episode_reward": -391.69, "episode_reward_trend_value": 0.014603759765339596, "biggest_recent_change": 2.3212523298854535},
{ "step": 1617, "visits": [17.0, 1000.0, 328.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1846, "q_vals": [-9.779, -inf, -8.893, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1618, "visits": [17.0, 1000.0, 329.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1848, "q_vals": [-9.779, -inf, -8.892, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1619, "visits": [17.0, 1000.0, 330.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1848, "q_vals": [-9.779, -inf, -8.892, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1620, "visits": [17.0, 1000.0, 331.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1848, "q_vals": [-9.779, -inf, -8.865, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1621, "visits": [17.0, 1000.0, 332.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1848, "q_vals": [-9.779, -inf, -8.904, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1622, "visits": [17.0, 1000.0, 333.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1850, "q_vals": [-9.779, -inf, -8.904, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1623, "visits": [17.0, 1000.0, 334.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1852, "q_vals": [-9.779, -inf, -8.903, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1624, "visits": [17.0, 1000.0, 335.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1853, "q_vals": [-9.779, -inf, -8.877, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1625, "visits": [17.0, 1000.0, 336.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1854, "q_vals": [-9.779, -inf, -8.876, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1626, "visits": [17.0, 1000.0, 337.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1855, "q_vals": [-9.779, -inf, -8.876, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1856, "number_of_timesteps": 153835, "per_episode_reward": -389.51, "episode_reward_trend_value": 0.05189698604306474, "biggest_recent_change": 2.3212523298854535},
{ "step": 1627, "visits": [17.0, 1000.0, 338.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1856, "q_vals": [-9.779, -inf, -8.875, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1628, "visits": [17.0, 1000.0, 339.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1858, "q_vals": [-9.779, -inf, -8.875, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1629, "visits": [17.0, 1000.0, 340.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1858, "q_vals": [-9.779, -inf, -8.875, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1630, "visits": [17.0, 1000.0, 341.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1859, "q_vals": [-9.779, -inf, -8.913, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1631, "visits": [17.0, 1000.0, 342.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1859, "q_vals": [-9.779, -inf, -8.912, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1632, "visits": [17.0, 1000.0, 343.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1860, "q_vals": [-9.779, -inf, -8.912, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1633, "visits": [17.0, 1000.0, 344.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1863, "q_vals": [-9.779, -inf, -8.911, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1634, "visits": [17.0, 1000.0, 345.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1863, "q_vals": [-9.779, -inf, -8.911, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1635, "visits": [17.0, 1000.0, 346.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1864, "q_vals": [-9.779, -inf, -8.91, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1636, "visits": [17.0, 1000.0, 347.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1865, "q_vals": [-9.779, -inf, -8.91, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1866, "number_of_timesteps": 154771, "per_episode_reward": -390.67, "episode_reward_trend_value": 0.04214265031341458, "biggest_recent_change": 2.3212523298854535},
{ "step": 1637, "visits": [17.0, 1000.0, 348.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1866, "q_vals": [-9.779, -inf, -8.884, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1638, "visits": [17.0, 1000.0, 349.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1866, "q_vals": [-9.779, -inf, -8.859, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1639, "visits": [17.0, 1000.0, 350.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1868, "q_vals": [-9.779, -inf, -8.859, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1640, "visits": [17.0, 1000.0, 351.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1868, "q_vals": [-9.779, -inf, -8.858, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1641, "visits": [17.0, 1000.0, 352.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1868, "q_vals": [-9.779, -inf, -8.858, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1642, "visits": [17.0, 1000.0, 353.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1871, "q_vals": [-9.779, -inf, -8.858, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1643, "visits": [17.0, 1000.0, 354.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1873, "q_vals": [-9.779, -inf, -8.857, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1644, "visits": [17.0, 1000.0, 355.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1874, "q_vals": [-9.779, -inf, -8.857, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1645, "visits": [17.0, 1000.0, 356.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1874, "q_vals": [-9.779, -inf, -8.894, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1646, "visits": [17.0, 1000.0, 357.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1874, "q_vals": [-9.779, -inf, -8.893, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1647, "visits": [17.0, 1000.0, 358.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1875, "q_vals": [-9.779, -inf, -8.893, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1877, "number_of_timesteps": 155866, "per_episode_reward": -390.32, "episode_reward_trend_value": 0.04536303688255619, "biggest_recent_change": 2.3212523298854535},
{ "step": 1648, "visits": [17.0, 1000.0, 359.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1877, "q_vals": [-9.779, -inf, -8.892, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1649, "visits": [17.0, 1000.0, 360.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1877, "q_vals": [-9.779, -inf, -8.868, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1650, "visits": [17.0, 1000.0, 361.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1878, "q_vals": [-9.779, -inf, -8.904, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1651, "visits": [17.0, 1000.0, 362.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1878, "q_vals": [-9.779, -inf, -8.903, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1652, "visits": [17.0, 1000.0, 363.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1878, "q_vals": [-9.779, -inf, -8.903, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1653, "visits": [17.0, 1000.0, 364.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1880, "q_vals": [-9.779, -inf, -8.939, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1654, "visits": [17.0, 1000.0, 365.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1883, "q_vals": [-9.779, -inf, -8.938, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1655, "visits": [17.0, 1000.0, 366.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1884, "q_vals": [-9.779, -inf, -8.914, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1656, "visits": [17.0, 1000.0, 367.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1884, "q_vals": [-9.779, -inf, -8.913, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1657, "visits": [17.0, 1000.0, 368.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1886, "q_vals": [-9.779, -inf, -8.913, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1658, "visits": [17.0, 1000.0, 369.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1886, "q_vals": [-9.779, -inf, -8.912, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1659, "visits": [17.0, 1000.0, 370.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1886, "q_vals": [-9.779, -inf, -8.912, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1888, "number_of_timesteps": 157000, "per_episode_reward": -391.89, "episode_reward_trend_value": 0.04448780904416607, "biggest_recent_change": 2.3212523298854535},
{ "step": 1660, "visits": [17.0, 1000.0, 371.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1888, "q_vals": [-9.779, -inf, -8.911, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1661, "visits": [17.0, 1000.0, 372.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1888, "q_vals": [-9.779, -inf, -8.887, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1662, "visits": [17.0, 1000.0, 373.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1891, "q_vals": [-9.779, -inf, -8.887, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1663, "visits": [17.0, 1000.0, 374.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1892, "q_vals": [-9.779, -inf, -8.887, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1664, "visits": [17.0, 1000.0, 375.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1895, "q_vals": [-9.779, -inf, -8.886, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1665, "visits": [17.0, 1000.0, 376.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1895, "q_vals": [-9.779, -inf, -8.863, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1666, "visits": [17.0, 1000.0, 377.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1895, "q_vals": [-9.779, -inf, -8.862, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1667, "visits": [17.0, 1000.0, 378.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1896, "q_vals": [-9.779, -inf, -8.862, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1668, "visits": [17.0, 1000.0, 379.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1896, "q_vals": [-9.779, -inf, -8.862, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1898, "number_of_timesteps": 157840, "per_episode_reward": -391.88, "episode_reward_trend_value": 0.027560028149564965, "biggest_recent_change": 2.3212523298854535},
{ "step": 1669, "visits": [17.0, 1000.0, 380.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1898, "q_vals": [-9.779, -inf, -8.862, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1670, "visits": [17.0, 1000.0, 381.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1899, "q_vals": [-9.779, -inf, -8.861, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1671, "visits": [17.0, 1000.0, 382.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1899, "q_vals": [-9.779, -inf, -8.861, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1672, "visits": [17.0, 1000.0, 383.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1900, "q_vals": [-9.779, -inf, -8.838, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1673, "visits": [17.0, 1000.0, 384.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1900, "q_vals": [-9.779, -inf, -8.838, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1674, "visits": [17.0, 1000.0, 385.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1902, "q_vals": [-9.779, -inf, -8.815, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1675, "visits": [17.0, 1000.0, 386.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1903, "q_vals": [-9.779, -inf, -8.814, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1676, "visits": [17.0, 1000.0, 387.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1904, "q_vals": [-9.779, -inf, -8.814, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1677, "visits": [17.0, 1000.0, 388.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1905, "q_vals": [-9.779, -inf, -8.792, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1908, "number_of_timesteps": 158863, "per_episode_reward": -390.93, "episode_reward_trend_value": 0.04350236685865083, "biggest_recent_change": 2.3212523298854535},
{ "step": 1678, "visits": [17.0, 1000.0, 389.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1908, "q_vals": [-9.779, -inf, -8.791, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1679, "visits": [17.0, 1000.0, 390.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1909, "q_vals": [-9.779, -inf, -8.769, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1680, "visits": [17.0, 1000.0, 391.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1909, "q_vals": [-9.779, -inf, -8.802, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1681, "visits": [17.0, 1000.0, 392.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1909, "q_vals": [-9.779, -inf, -8.836, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1682, "visits": [17.0, 1000.0, 393.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1910, "q_vals": [-9.779, -inf, -8.836, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1683, "visits": [17.0, 1000.0, 394.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1910, "q_vals": [-9.779, -inf, -8.813, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1684, "visits": [17.0, 1000.0, 395.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1911, "q_vals": [-9.779, -inf, -8.813, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1685, "visits": [17.0, 1000.0, 396.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1913, "q_vals": [-9.779, -inf, -8.846, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1686, "visits": [17.0, 1000.0, 397.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1914, "q_vals": [-9.779, -inf, -8.846, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1687, "visits": [17.0, 1000.0, 398.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1915, "q_vals": [-9.779, -inf, -8.824, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1688, "visits": [17.0, 1000.0, 399.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1916, "q_vals": [-9.779, -inf, -8.856, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1689, "visits": [17.0, 1000.0, 400.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1917, "q_vals": [-9.779, -inf, -8.856, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1918, "number_of_timesteps": 159848, "per_episode_reward": -389.67, "episode_reward_trend_value": 0.0453625057933487, "biggest_recent_change": 2.3212523298854535},
{ "step": 1690, "visits": [17.0, 1000.0, 401.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1918, "q_vals": [-9.779, -inf, -8.888, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1691, "visits": [17.0, 1000.0, 402.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1918, "q_vals": [-9.779, -inf, -8.888, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1692, "visits": [17.0, 1000.0, 403.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1918, "q_vals": [-9.779, -inf, -8.888, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1693, "visits": [17.0, 1000.0, 404.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1920, "q_vals": [-9.779, -inf, -8.887, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1694, "visits": [17.0, 1000.0, 405.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1920, "q_vals": [-9.779, -inf, -8.887, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1695, "visits": [17.0, 1000.0, 406.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1920, "q_vals": [-9.779, -inf, -8.887, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1696, "visits": [17.0, 1000.0, 407.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1925, "q_vals": [-9.779, -inf, -8.886, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1697, "visits": [17.0, 1000.0, 408.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1925, "q_vals": [-9.779, -inf, -8.918, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1698, "visits": [17.0, 1000.0, 409.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1926, "q_vals": [-9.779, -inf, -8.918, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1699, "visits": [17.0, 1000.0, 410.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1926, "q_vals": [-9.779, -inf, -8.917, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1700, "visits": [17.0, 1000.0, 411.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1926, "q_vals": [-9.779, -inf, -8.949, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1701, "visits": [17.0, 1000.0, 412.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1927, "q_vals": [-9.779, -inf, -8.948, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1702, "visits": [17.0, 1000.0, 413.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1927, "q_vals": [-9.779, -inf, -8.927, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1928, "number_of_timesteps": 160886, "per_episode_reward": -391.72, "episode_reward_trend_value": 0.02550717966210464, "biggest_recent_change": 2.3212523298854535},
{ "step": 1703, "visits": [17.0, 1000.0, 414.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1928, "q_vals": [-9.779, -inf, -8.958, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1704, "visits": [17.0, 1000.0, 415.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1929, "q_vals": [-9.779, -inf, -8.958, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1705, "visits": [17.0, 1000.0, 416.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1929, "q_vals": [-9.779, -inf, -8.957, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1706, "visits": [17.0, 1000.0, 417.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1929, "q_vals": [-9.779, -inf, -8.957, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1707, "visits": [17.0, 1000.0, 418.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1931, "q_vals": [-9.779, -inf, -8.956, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1708, "visits": [17.0, 1000.0, 419.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1931, "q_vals": [-9.779, -inf, -8.987, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1709, "visits": [17.0, 1000.0, 420.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1931, "q_vals": [-9.779, -inf, -9.018, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1710, "visits": [17.0, 1000.0, 421.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1934, "q_vals": [-9.779, -inf, -8.996, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1711, "visits": [17.0, 1000.0, 422.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1934, "q_vals": [-9.779, -inf, -8.996, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1712, "visits": [17.0, 1000.0, 423.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1934, "q_vals": [-9.779, -inf, -8.974, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1713, "visits": [17.0, 1000.0, 424.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1935, "q_vals": [-9.779, -inf, -8.974, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1714, "visits": [17.0, 1000.0, 425.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1935, "q_vals": [-9.779, -inf, -8.973, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1938, "number_of_timesteps": 162134, "per_episode_reward": -392.77, "episode_reward_trend_value": -0.012029686778280773, "biggest_recent_change": 2.177246679031157},
{ "step": 1715, "visits": [17.0, 1000.0, 426.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1938, "q_vals": [-9.779, -inf, -8.973, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1716, "visits": [17.0, 1000.0, 427.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1939, "q_vals": [-9.779, -inf, -8.972, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1717, "visits": [17.0, 1000.0, 428.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1939, "q_vals": [-9.779, -inf, -8.972, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1718, "visits": [17.0, 1000.0, 429.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1939, "q_vals": [-9.779, -inf, -8.971, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1719, "visits": [17.0, 1000.0, 430.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1941, "q_vals": [-9.779, -inf, -8.971, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1720, "visits": [17.0, 1000.0, 431.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1941, "q_vals": [-9.779, -inf, -8.97, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1721, "visits": [17.0, 1000.0, 432.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1943, "q_vals": [-9.779, -inf, -8.949, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1722, "visits": [17.0, 1000.0, 433.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1943, "q_vals": [-9.779, -inf, -8.949, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1723, "visits": [17.0, 1000.0, 434.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1944, "q_vals": [-9.779, -inf, -8.928, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1724, "visits": [17.0, 1000.0, 435.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1944, "q_vals": [-9.779, -inf, -8.928, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1725, "visits": [17.0, 1000.0, 436.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1944, "q_vals": [-9.779, -inf, -8.927, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1726, "visits": [17.0, 1000.0, 437.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1947, "q_vals": [-9.779, -inf, -8.927, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1727, "visits": [17.0, 1000.0, 438.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1947, "q_vals": [-9.779, -inf, -8.957, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1948, "number_of_timesteps": 163356, "per_episode_reward": -393.41, "episode_reward_trend_value": -0.043262100604403664, "biggest_recent_change": 2.044408874953035},
{ "step": 1728, "visits": [17.0, 1000.0, 439.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1948, "q_vals": [-9.779, -inf, -8.956, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1729, "visits": [17.0, 1000.0, 440.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1949, "q_vals": [-9.779, -inf, -8.936, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1730, "visits": [17.0, 1000.0, 441.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1950, "q_vals": [-9.779, -inf, -8.965, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1731, "visits": [17.0, 1000.0, 442.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1950, "q_vals": [-9.779, -inf, -8.965, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1732, "visits": [17.0, 1000.0, 443.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1950, "q_vals": [-9.779, -inf, -8.944, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1733, "visits": [17.0, 1000.0, 444.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1950, "q_vals": [-9.779, -inf, -8.974, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1734, "visits": [17.0, 1000.0, 445.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1952, "q_vals": [-9.779, -inf, -8.973, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1735, "visits": [17.0, 1000.0, 446.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1955, "q_vals": [-9.779, -inf, -8.953, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1736, "visits": [17.0, 1000.0, 447.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1955, "q_vals": [-9.779, -inf, -8.982, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1737, "visits": [17.0, 1000.0, 448.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1956, "q_vals": [-9.779, -inf, -8.981, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1738, "visits": [17.0, 1000.0, 449.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1956, "q_vals": [-9.779, -inf, -8.981, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1739, "visits": [17.0, 1000.0, 450.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1956, "q_vals": [-9.779, -inf, -8.961, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1740, "visits": [17.0, 1000.0, 451.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1956, "q_vals": [-9.779, -inf, -8.96, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1958, "number_of_timesteps": 164524, "per_episode_reward": -395.25, "episode_reward_trend_value": -0.05098322754617975, "biggest_recent_change": 2.044408874953035},
{ "step": 1741, "visits": [17.0, 1000.0, 452.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1958, "q_vals": [-9.779, -inf, -8.941, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1742, "visits": [17.0, 1000.0, 453.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1959, "q_vals": [-9.779, -inf, -8.94, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1743, "visits": [17.0, 1000.0, 454.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1960, "q_vals": [-9.779, -inf, -8.94, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1744, "visits": [17.0, 1000.0, 455.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1961, "q_vals": [-9.779, -inf, -8.939, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1745, "visits": [17.0, 1000.0, 456.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1961, "q_vals": [-9.779, -inf, -8.968, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1746, "visits": [17.0, 1000.0, 457.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1962, "q_vals": [-9.779, -inf, -8.967, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1747, "visits": [17.0, 1000.0, 458.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1963, "q_vals": [-9.779, -inf, -8.995, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1748, "visits": [17.0, 1000.0, 459.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1963, "q_vals": [-9.779, -inf, -8.995, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1749, "visits": [17.0, 1000.0, 460.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1963, "q_vals": [-9.779, -inf, -8.994, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1750, "visits": [17.0, 1000.0, 461.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1963, "q_vals": [-9.779, -inf, -8.994, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1751, "visits": [17.0, 1000.0, 462.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1963, "q_vals": [-9.779, -inf, -8.993, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1752, "visits": [17.0, 1000.0, 463.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1964, "q_vals": [-9.779, -inf, -8.993, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1753, "visits": [17.0, 1000.0, 464.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1965, "q_vals": [-9.779, -inf, -8.992, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1754, "visits": [17.0, 1000.0, 465.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1966, "q_vals": [-9.779, -inf, -8.992, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1755, "visits": [17.0, 1000.0, 466.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1967, "q_vals": [-9.779, -inf, -8.991, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1969, "number_of_timesteps": 165941, "per_episode_reward": -396.52, "episode_reward_trend_value": -0.06886062568263784, "biggest_recent_change": 2.044408874953035},
{ "step": 1756, "visits": [17.0, 1000.0, 467.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1969, "q_vals": [-9.779, -inf, -8.991, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1757, "visits": [17.0, 1000.0, 468.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1970, "q_vals": [-9.779, -inf, -8.971, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1758, "visits": [17.0, 1000.0, 469.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1971, "q_vals": [-9.779, -inf, -8.952, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1759, "visits": [17.0, 1000.0, 470.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1972, "q_vals": [-9.779, -inf, -8.952, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1760, "visits": [17.0, 1000.0, 471.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1974, "q_vals": [-9.779, -inf, -8.951, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1761, "visits": [17.0, 1000.0, 472.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1974, "q_vals": [-9.779, -inf, -8.951, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1762, "visits": [17.0, 1000.0, 473.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1975, "q_vals": [-9.779, -inf, -8.951, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1763, "visits": [17.0, 1000.0, 474.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1975, "q_vals": [-9.779, -inf, -8.978, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1764, "visits": [17.0, 1000.0, 475.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1975, "q_vals": [-9.779, -inf, -8.977, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1765, "visits": [17.0, 1000.0, 476.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1975, "q_vals": [-9.779, -inf, -9.004, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1766, "visits": [17.0, 1000.0, 477.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1976, "q_vals": [-9.779, -inf, -9.004, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1767, "visits": [17.0, 1000.0, 478.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1977, "q_vals": [-9.779, -inf, -9.003, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1768, "visits": [17.0, 1000.0, 479.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1978, "q_vals": [-9.779, -inf, -8.985, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1979, "number_of_timesteps": 167185, "per_episode_reward": -397.0, "episode_reward_trend_value": -0.056801446925619656, "biggest_recent_change": 2.044408874953035},
{ "step": 1769, "visits": [17.0, 1000.0, 480.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1979, "q_vals": [-9.779, -inf, -9.011, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
q_vals: [-9.779, -inf, -8.993, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117]
{ "step": 1771, "visits": [17.0, 1000.0, 482.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1984, "q_vals": [-9.779, -inf, -8.992, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1772, "visits": [17.0, 1000.0, 483.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1985, "q_vals": [-9.779, -inf, -8.992, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1773, "visits": [17.0, 1000.0, 484.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1985, "q_vals": [-9.779, -inf, -8.991, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1774, "visits": [17.0, 1000.0, 485.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1985, "q_vals": [-9.779, -inf, -9.018, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1775, "visits": [17.0, 1000.0, 486.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1986, "q_vals": [-9.779, -inf, -8.999, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1776, "visits": [17.0, 1000.0, 487.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1986, "q_vals": [-9.779, -inf, -8.999, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1777, "visits": [17.0, 1000.0, 488.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1987, "q_vals": [-9.779, -inf, -8.998, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1778, "visits": [17.0, 1000.0, 489.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1987, "q_vals": [-9.779, -inf, -8.98, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1779, "visits": [17.0, 1000.0, 490.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1987, "q_vals": [-9.779, -inf, -8.979, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 1990, "number_of_timesteps": 168343, "per_episode_reward": -397.56, "episode_reward_trend_value": -0.06315587779953881, "biggest_recent_change": 2.044408874953035},
{ "step": 1780, "visits": [17.0, 1000.0, 491.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1990, "q_vals": [-9.779, -inf, -8.979, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1781, "visits": [17.0, 1000.0, 492.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1990, "q_vals": [-9.779, -inf, -9.005, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1782, "visits": [17.0, 1000.0, 493.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1990, "q_vals": [-9.779, -inf, -9.005, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1783, "visits": [17.0, 1000.0, 494.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1991, "q_vals": [-9.779, -inf, -9.031, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1784, "visits": [17.0, 1000.0, 495.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1991, "q_vals": [-9.779, -inf, -9.03, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1785, "visits": [17.0, 1000.0, 496.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1993, "q_vals": [-9.779, -inf, -9.012, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1786, "visits": [17.0, 1000.0, 497.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1993, "q_vals": [-9.779, -inf, -9.011, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1787, "visits": [17.0, 1000.0, 498.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1994, "q_vals": [-9.779, -inf, -9.037, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1788, "visits": [17.0, 1000.0, 499.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1995, "q_vals": [-9.779, -inf, -9.037, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1789, "visits": [17.0, 1000.0, 500.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1997, "q_vals": [-9.779, -inf, -9.036, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1790, "visits": [17.0, 1000.0, 501.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1998, "q_vals": [-9.779, -inf, -9.035, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1791, "visits": [17.0, 1000.0, 502.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1998, "q_vals": [-9.779, -inf, -9.061, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1792, "visits": [17.0, 1000.0, 503.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 1999, "q_vals": [-9.779, -inf, -9.06, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2001, "number_of_timesteps": 169738, "per_episode_reward": -397.9, "episode_reward_trend_value": -0.07744099401168493, "biggest_recent_change": 2.044408874953035},
{ "step": 1793, "visits": [17.0, 1000.0, 504.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2001, "q_vals": [-9.779, -inf, -9.06, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1794, "visits": [17.0, 1000.0, 505.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2001, "q_vals": [-9.779, -inf, -9.059, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1795, "visits": [17.0, 1000.0, 506.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2003, "q_vals": [-9.779, -inf, -9.059, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1796, "visits": [17.0, 1000.0, 507.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2004, "q_vals": [-9.779, -inf, -9.041, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1797, "visits": [17.0, 1000.0, 508.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2005, "q_vals": [-9.779, -inf, -9.023, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1798, "visits": [17.0, 1000.0, 509.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2005, "q_vals": [-9.779, -inf, -9.022, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1799, "visits": [17.0, 1000.0, 510.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2008, "q_vals": [-9.779, -inf, -9.022, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1800, "visits": [17.0, 1000.0, 511.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2008, "q_vals": [-9.779, -inf, -9.047, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1801, "visits": [17.0, 1000.0, 512.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2009, "q_vals": [-9.779, -inf, -9.029, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2012, "number_of_timesteps": 170747, "per_episode_reward": -397.69, "episode_reward_trend_value": -0.08912951283218844, "biggest_recent_change": 2.044408874953035},
{ "step": 1802, "visits": [17.0, 1000.0, 513.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2012, "q_vals": [-9.779, -inf, -9.054, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
visits [17.0, 1000.0, 514.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0]  episode_count: 2012 q_vals: [-9.779, -inf, -9.054, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117]
{ "step": 1804, "visits": [17.0, 1000.0, 515.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2014, "q_vals": [-9.779, -inf, -9.036, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1805, "visits": [17.0, 1000.0, 516.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2014, "q_vals": [-9.779, -inf, -9.061, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1806, "visits": [17.0, 1000.0, 517.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2015, "q_vals": [-9.779, -inf, -9.044, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1807, "visits": [17.0, 1000.0, 518.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2015, "q_vals": [-9.779, -inf, -9.043, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1808, "visits": [17.0, 1000.0, 519.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2017, "q_vals": [-9.779, -inf, -9.042, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1809, "visits": [17.0, 1000.0, 520.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2018, "q_vals": [-9.779, -inf, -9.067, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1810, "visits": [17.0, 1000.0, 521.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2019, "q_vals": [-9.779, -inf, -9.066, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1811, "visits": [17.0, 1000.0, 522.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2020, "q_vals": [-9.779, -inf, -9.066, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1812, "visits": [17.0, 1000.0, 523.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2020, "q_vals": [-9.779, -inf, -9.065, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2022, "number_of_timesteps": 171615, "per_episode_reward": -396.86, "episode_reward_trend_value": -0.05716107778430342, "biggest_recent_change": 1.847385938339528},
{ "step": 1813, "visits": [17.0, 1000.0, 524.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2022, "q_vals": [-9.779, -inf, -9.065, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1814, "visits": [17.0, 1000.0, 525.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2023, "q_vals": [-9.779, -inf, -9.064, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1815, "visits": [17.0, 1000.0, 526.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2024, "q_vals": [-9.779, -inf, -9.088, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1816, "visits": [17.0, 1000.0, 527.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2025, "q_vals": [-9.779, -inf, -9.113, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1817, "visits": [17.0, 1000.0, 528.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2026, "q_vals": [-9.779, -inf, -9.112, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1818, "visits": [17.0, 1000.0, 529.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2027, "q_vals": [-9.779, -inf, -9.111, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1819, "visits": [17.0, 1000.0, 530.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2029, "q_vals": [-9.779, -inf, -9.111, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1820, "visits": [17.0, 1000.0, 531.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2029, "q_vals": [-9.779, -inf, -9.11, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1821, "visits": [17.0, 1000.0, 532.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2031, "q_vals": [-9.779, -inf, -9.109, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1822, "visits": [17.0, 1000.0, 533.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2031, "q_vals": [-9.779, -inf, -9.109, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2032, "number_of_timesteps": 172556, "per_episode_reward": -397.79, "episode_reward_trend_value": -0.05572234745742245, "biggest_recent_change": 1.847385938339528},
{ "step": 1823, "visits": [17.0, 1000.0, 534.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2032, "q_vals": [-9.779, -inf, -9.108, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1824, "visits": [17.0, 1000.0, 535.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2033, "q_vals": [-9.779, -inf, -9.107, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1825, "visits": [17.0, 1000.0, 536.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2035, "q_vals": [-9.779, -inf, -9.107, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1826, "visits": [17.0, 1000.0, 537.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2036, "q_vals": [-9.779, -inf, -9.13, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1827, "visits": [17.0, 1000.0, 538.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2036, "q_vals": [-9.779, -inf, -9.13, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1828, "visits": [17.0, 1000.0, 539.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2038, "q_vals": [-9.779, -inf, -9.129, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1829, "visits": [17.0, 1000.0, 540.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2040, "q_vals": [-9.779, -inf, -9.128, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1830, "visits": [17.0, 1000.0, 541.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2041, "q_vals": [-9.779, -inf, -9.128, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2042, "number_of_timesteps": 173447, "per_episode_reward": -398.46, "episode_reward_trend_value": -0.05611995825979458, "biggest_recent_change": 1.847385938339528},
{ "step": 1831, "visits": [17.0, 1000.0, 542.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2042, "q_vals": [-9.779, -inf, -9.127, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1832, "visits": [17.0, 1000.0, 543.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2045, "q_vals": [-9.779, -inf, -9.126, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1833, "visits": [17.0, 1000.0, 544.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2045, "q_vals": [-9.779, -inf, -9.15, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1834, "visits": [17.0, 1000.0, 545.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2046, "q_vals": [-9.779, -inf, -9.149, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
[17.0, 1000.0, 546.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0]  episode_count: 2047 q_vals: [-9.779, -inf, -9.148, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117]
{ "step": 1836, "visits": [17.0, 1000.0, 547.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2049, "q_vals": [-9.779, -inf, -9.147, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1837, "visits": [17.0, 1000.0, 548.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2049, "q_vals": [-9.779, -inf, -9.171, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1838, "visits": [17.0, 1000.0, 549.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2051, "q_vals": [-9.779, -inf, -9.17, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2052, "number_of_timesteps": 174181, "per_episode_reward": -397.98, "episode_reward_trend_value": -0.030262020036445847, "biggest_recent_change": 1.2647681179089432},
{ "step": 1839, "visits": [17.0, 1000.0, 550.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2052, "q_vals": [-9.779, -inf, -9.169, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1840, "visits": [17.0, 1000.0, 551.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2053, "q_vals": [-9.779, -inf, -9.168, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1841, "visits": [17.0, 1000.0, 552.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2057, "q_vals": [-9.779, -inf, -9.168, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1842, "visits": [17.0, 1000.0, 553.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2059, "q_vals": [-9.779, -inf, -9.167, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1843, "visits": [17.0, 1000.0, 554.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2059, "q_vals": [-9.779, -inf, -9.166, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1844, "visits": [17.0, 1000.0, 555.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2060, "q_vals": [-9.779, -inf, -9.165, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2062, "number_of_timesteps": 174831, "per_episode_reward": -397.1, "episode_reward_trend_value": -0.00643729589111975, "biggest_recent_change": 0.9275799203299471},
{ "step": 1845, "visits": [17.0, 1000.0, 556.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2062, "q_vals": [-9.779, -inf, -9.188, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1846, "visits": [17.0, 1000.0, 557.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2062, "q_vals": [-9.779, -inf, -9.187, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1847, "visits": [17.0, 1000.0, 558.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2064, "q_vals": [-9.779, -inf, -9.187, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1848, "visits": [17.0, 1000.0, 559.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2065, "q_vals": [-9.779, -inf, -9.186, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1849, "visits": [17.0, 1000.0, 560.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2067, "q_vals": [-9.779, -inf, -9.208, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1850, "visits": [17.0, 1000.0, 561.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2069, "q_vals": [-9.779, -inf, -9.192, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1851, "visits": [17.0, 1000.0, 562.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2070, "q_vals": [-9.779, -inf, -9.176, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1852, "visits": [17.0, 1000.0, 563.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2070, "q_vals": [-9.779, -inf, -9.175, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1853, "visits": [17.0, 1000.0, 564.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2071, "q_vals": [-9.779, -inf, -9.174, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2073, "number_of_timesteps": 175602, "per_episode_reward": -397.1, "episode_reward_trend_value": -0.0011634100684324898, "biggest_recent_change": 0.9275799203299471},
{ "step": 1854, "visits": [17.0, 1000.0, 565.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2073, "q_vals": [-9.779, -inf, -9.173, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1855, "visits": [17.0, 1000.0, 566.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2075, "q_vals": [-9.779, -inf, -9.157, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1856, "visits": [17.0, 1000.0, 567.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2076, "q_vals": [-9.779, -inf, -9.157, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1857, "visits": [17.0, 1000.0, 568.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2078, "q_vals": [-9.779, -inf, -9.14, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1858, "visits": [17.0, 1000.0, 569.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2079, "q_vals": [-9.779, -inf, -9.14, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1859, "visits": [17.0, 1000.0, 570.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2079, "q_vals": [-9.779, -inf, -9.139, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1860, "visits": [17.0, 1000.0, 571.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2080, "q_vals": [-9.779, -inf, -9.138, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1861, "visits": [17.0, 1000.0, 572.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2081, "q_vals": [-9.779, -inf, -9.138, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2084, "number_of_timesteps": 176387, "per_episode_reward": -397.61, "episode_reward_trend_value": -0.0005507384570118272, "biggest_recent_change": 0.9275799203299471},
{ "step": 1862, "visits": [17.0, 1000.0, 573.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2084, "q_vals": [-9.779, -inf, -9.16, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1863, "visits": [17.0, 1000.0, 574.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2088, "q_vals": [-9.779, -inf, -9.159, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1864, "visits": [17.0, 1000.0, 575.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2088, "q_vals": [-9.779, -inf, -9.158, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1865, "visits": [17.0, 1000.0, 576.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2089, "q_vals": [-9.779, -inf, -9.158, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1866, "visits": [17.0, 1000.0, 577.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2089, "q_vals": [-9.779, -inf, -9.157, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1867, "visits": [17.0, 1000.0, 578.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2090, "q_vals": [-9.779, -inf, -9.156, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1868, "visits": [17.0, 1000.0, 579.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2092, "q_vals": [-9.779, -inf, -9.178, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2095, "number_of_timesteps": 177097, "per_episode_reward": -398.24, "episode_reward_trend_value": -0.0037718281383332746, "biggest_recent_change": 0.9275799203299471},
{ "step": 1869, "visits": [17.0, 1000.0, 580.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2095, "q_vals": [-9.779, -inf, -9.178, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1870, "visits": [17.0, 1000.0, 581.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2097, "q_vals": [-9.779, -inf, -9.177, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1871, "visits": [17.0, 1000.0, 582.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2098, "q_vals": [-9.779, -inf, -9.161, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1872, "visits": [17.0, 1000.0, 583.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2098, "q_vals": [-9.779, -inf, -9.16, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1873, "visits": [17.0, 1000.0, 584.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2098, "q_vals": [-9.779, -inf, -9.182, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1874, "visits": [17.0, 1000.0, 585.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2099, "q_vals": [-9.779, -inf, -9.181, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1875, "visits": [17.0, 1000.0, 586.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2101, "q_vals": [-9.779, -inf, -9.181, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1876, "visits": [17.0, 1000.0, 587.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2102, "q_vals": [-9.779, -inf, -9.202, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1877, "visits": [17.0, 1000.0, 588.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2104, "q_vals": [-9.779, -inf, -9.202, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2107, "number_of_timesteps": 177981, "per_episode_reward": -398.83, "episode_reward_trend_value": -0.012597405990307684, "biggest_recent_change": 0.9275799203299471},
{ "step": 1878, "visits": [17.0, 1000.0, 589.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2107, "q_vals": [-9.779, -inf, -9.201, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1879, "visits": [17.0, 1000.0, 590.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2108, "q_vals": [-9.779, -inf, -9.2, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1880, "visits": [17.0, 1000.0, 591.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2109, "q_vals": [-9.779, -inf, -9.184, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1881, "visits": [17.0, 1000.0, 592.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2109, "q_vals": [-9.779, -inf, -9.184, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1882, "visits": [17.0, 1000.0, 593.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2109, "q_vals": [-9.779, -inf, -9.168, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1883, "visits": [17.0, 1000.0, 594.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2112, "q_vals": [-9.779, -inf, -9.168, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1884, "visits": [17.0, 1000.0, 595.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2112, "q_vals": [-9.779, -inf, -9.167, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1885, "visits": [17.0, 1000.0, 596.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2114, "q_vals": [-9.779, -inf, -9.151, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1886, "visits": [17.0, 1000.0, 597.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2115, "q_vals": [-9.779, -inf, -9.136, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2117, "number_of_timesteps": 178727, "per_episode_reward": -398.91, "episode_reward_trend_value": -0.02280978241599819, "biggest_recent_change": 0.9275799203299471},
{ "step": 1887, "visits": [17.0, 1000.0, 598.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2117, "q_vals": [-9.779, -inf, -9.157, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1888, "visits": [17.0, 1000.0, 599.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2118, "q_vals": [-9.779, -inf, -9.157, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1889, "visits": [17.0, 1000.0, 600.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2119, "q_vals": [-9.779, -inf, -9.156, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1890, "visits": [17.0, 1000.0, 601.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2120, "q_vals": [-9.779, -inf, -9.155, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1891, "visits": [17.0, 1000.0, 602.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2121, "q_vals": [-9.779, -inf, -9.155, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1892, "visits": [17.0, 1000.0, 603.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2121, "q_vals": [-9.779, -inf, -9.154, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1893, "visits": [17.0, 1000.0, 604.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2123, "q_vals": [-9.779, -inf, -9.139, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1894, "visits": [17.0, 1000.0, 605.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2124, "q_vals": [-9.779, -inf, -9.138, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1895, "visits": [17.0, 1000.0, 606.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2124, "q_vals": [-9.779, -inf, -9.138, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1896, "visits": [17.0, 1000.0, 607.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2125, "q_vals": [-9.779, -inf, -9.123, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2127, "number_of_timesteps": 179581, "per_episode_reward": -397.86, "episode_reward_trend_value": -0.0007391943646148825, "biggest_recent_change": 1.058773004294551},
{ "step": 1897, "visits": [17.0, 1000.0, 608.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2127, "q_vals": [-9.779, -inf, -9.122, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1898, "visits": [17.0, 1000.0, 609.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2128, "q_vals": [-9.779, -inf, -9.121, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1899, "visits": [17.0, 1000.0, 610.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2128, "q_vals": [-9.779, -inf, -9.121, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1900, "visits": [17.0, 1000.0, 611.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2129, "q_vals": [-9.779, -inf, -9.142, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1901, "visits": [17.0, 1000.0, 612.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2130, "q_vals": [-9.779, -inf, -9.141, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1902, "visits": [17.0, 1000.0, 613.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2131, "q_vals": [-9.779, -inf, -9.126, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1903, "visits": [17.0, 1000.0, 614.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2133, "q_vals": [-9.779, -inf, -9.111, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1904, "visits": [17.0, 1000.0, 615.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2134, "q_vals": [-9.779, -inf, -9.096, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1905, "visits": [17.0, 1000.0, 616.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2134, "q_vals": [-9.779, -inf, -9.082, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1906, "visits": [17.0, 1000.0, 617.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2135, "q_vals": [-9.779, -inf, -9.081, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1907, "visits": [17.0, 1000.0, 618.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2136, "q_vals": [-9.779, -inf, -9.102, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2137, "number_of_timesteps": 180554, "per_episode_reward": -396.87, "episode_reward_trend_value": 0.017618335316717547, "biggest_recent_change": 1.058773004294551},
{ "step": 1908, "visits": [17.0, 1000.0, 619.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2137, "q_vals": [-9.779, -inf, -9.087, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1909, "visits": [17.0, 1000.0, 620.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2137, "q_vals": [-9.779, -inf, -9.072, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1910, "visits": [17.0, 1000.0, 621.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2138, "q_vals": [-9.779, -inf, -9.072, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1911, "visits": [17.0, 1000.0, 622.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2139, "q_vals": [-9.779, -inf, -9.071, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1912, "visits": [17.0, 1000.0, 623.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2139, "q_vals": [-9.779, -inf, -9.071, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1913, "visits": [17.0, 1000.0, 624.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2139, "q_vals": [-9.779, -inf, -9.07, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1914, "visits": [17.0, 1000.0, 625.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2139, "q_vals": [-9.779, -inf, -9.07, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1915, "visits": [17.0, 1000.0, 626.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2139, "q_vals": [-9.779, -inf, -9.055, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1916, "visits": [17.0, 1000.0, 627.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2140, "q_vals": [-9.779, -inf, -9.055, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1917, "visits": [17.0, 1000.0, 628.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2140, "q_vals": [-9.779, -inf, -9.054, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1918, "visits": [17.0, 1000.0, 629.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2143, "q_vals": [-9.779, -inf, -9.054, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1919, "visits": [17.0, 1000.0, 630.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2143, "q_vals": [-9.779, -inf, -9.053, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1920, "visits": [17.0, 1000.0, 631.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2143, "q_vals": [-9.779, -inf, -9.053, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1921, "visits": [17.0, 1000.0, 632.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2144, "q_vals": [-9.779, -inf, -9.052, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1922, "visits": [17.0, 1000.0, 633.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2144, "q_vals": [-9.779, -inf, -9.052, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1923, "visits": [17.0, 1000.0, 634.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2145, "q_vals": [-9.779, -inf, -9.051, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1924, "visits": [17.0, 1000.0, 635.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2146, "q_vals": [-9.779, -inf, -9.051, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2147, "number_of_timesteps": 181946, "per_episode_reward": -397.25, "episode_reward_trend_value": 0.008078988067256255, "biggest_recent_change": 1.058773004294551},
{ "step": 1925, "visits": [17.0, 1000.0, 636.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2147, "q_vals": [-9.779, -inf, -9.051, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1926, "visits": [17.0, 1000.0, 637.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2150, "q_vals": [-9.779, -inf, -9.05, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1927, "visits": [17.0, 1000.0, 638.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2150, "q_vals": [-9.779, -inf, -9.05, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1928, "visits": [17.0, 1000.0, 639.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2150, "q_vals": [-9.779, -inf, -9.035, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1929, "visits": [17.0, 1000.0, 640.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2150, "q_vals": [-9.779, -inf, -9.055, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1930, "visits": [17.0, 1000.0, 641.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2150, "q_vals": [-9.779, -inf, -9.055, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1931, "visits": [17.0, 1000.0, 642.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2151, "q_vals": [-9.779, -inf, -9.075, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1932, "visits": [17.0, 1000.0, 643.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2152, "q_vals": [-9.779, -inf, -9.061, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1933, "visits": [17.0, 1000.0, 644.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2152, "q_vals": [-9.779, -inf, -9.06, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1934, "visits": [17.0, 1000.0, 645.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2153, "q_vals": [-9.779, -inf, -9.06, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1935, "visits": [17.0, 1000.0, 646.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2156, "q_vals": [-9.779, -inf, -9.059, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1936, "visits": [17.0, 1000.0, 647.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2156, "q_vals": [-9.779, -inf, -9.045, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1937, "visits": [17.0, 1000.0, 648.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2156, "q_vals": [-9.779, -inf, -9.045, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1938, "visits": [17.0, 1000.0, 649.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2156, "q_vals": [-9.779, -inf, -9.065, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2158, "number_of_timesteps": 183335, "per_episode_reward": -397.34, "episode_reward_trend_value": -0.002635755363619789, "biggest_recent_change": 1.058773004294551},
{ "step": 1939, "visits": [17.0, 1000.0, 650.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2158, "q_vals": [-9.779, -inf, -9.064, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1940, "visits": [17.0, 1000.0, 651.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2159, "q_vals": [-9.779, -inf, -9.064, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1941, "visits": [17.0, 1000.0, 652.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2160, "q_vals": [-9.779, -inf, -9.063, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1942, "visits": [17.0, 1000.0, 653.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2160, "q_vals": [-9.779, -inf, -9.063, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1943, "visits": [17.0, 1000.0, 654.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2160, "q_vals": [-9.779, -inf, -9.062, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1944, "visits": [17.0, 1000.0, 655.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2160, "q_vals": [-9.779, -inf, -9.062, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1945, "visits": [17.0, 1000.0, 656.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2162, "q_vals": [-9.779, -inf, -9.061, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1946, "visits": [17.0, 1000.0, 657.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2163, "q_vals": [-9.779, -inf, -9.061, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1947, "visits": [17.0, 1000.0, 658.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2164, "q_vals": [-9.779, -inf, -9.06, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1948, "visits": [17.0, 1000.0, 659.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2164, "q_vals": [-9.779, -inf, -9.047, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1949, "visits": [17.0, 1000.0, 660.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2165, "q_vals": [-9.779, -inf, -9.066, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1950, "visits": [17.0, 1000.0, 661.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2166, "q_vals": [-9.779, -inf, -9.066, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1951, "visits": [17.0, 1000.0, 662.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2166, "q_vals": [-9.779, -inf, -9.065, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1952, "visits": [17.0, 1000.0, 663.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2167, "q_vals": [-9.779, -inf, -9.065, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2168, "number_of_timesteps": 184745, "per_episode_reward": -398.0, "episode_reward_trend_value": -0.009976060780835244, "biggest_recent_change": 1.058773004294551},
{ "step": 1953, "visits": [17.0, 1000.0, 664.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2168, "q_vals": [-9.779, -inf, -9.051, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1954, "visits": [17.0, 1000.0, 665.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2170, "q_vals": [-9.779, -inf, -9.051, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1955, "visits": [17.0, 1000.0, 666.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2171, "q_vals": [-9.779, -inf, -9.05, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1956, "visits": [17.0, 1000.0, 667.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2171, "q_vals": [-9.779, -inf, -9.05, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1957, "visits": [17.0, 1000.0, 668.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2171, "q_vals": [-9.779, -inf, -9.069, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1958, "visits": [17.0, 1000.0, 669.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2172, "q_vals": [-9.779, -inf, -9.068, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1959, "visits": [17.0, 1000.0, 670.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2172, "q_vals": [-9.779, -inf, -9.055, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1960, "visits": [17.0, 1000.0, 671.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2173, "q_vals": [-9.779, -inf, -9.054, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1961, "visits": [17.0, 1000.0, 672.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2174, "q_vals": [-9.779, -inf, -9.054, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1962, "visits": [17.0, 1000.0, 673.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2176, "q_vals": [-9.779, -inf, -9.054, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1963, "visits": [17.0, 1000.0, 674.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2177, "q_vals": [-9.779, -inf, -9.053, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1964, "visits": [17.0, 1000.0, 675.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2177, "q_vals": [-9.779, -inf, -9.04, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2178, "number_of_timesteps": 185938, "per_episode_reward": -398.48, "episode_reward_trend_value": -0.00971730614157625, "biggest_recent_change": 1.058773004294551},
{ "step": 1965, "visits": [17.0, 1000.0, 676.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2178, "q_vals": [-9.779, -inf, -9.038, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1966, "visits": [17.0, 1000.0, 677.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2178, "q_vals": [-9.779, -inf, -9.037, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1967, "visits": [17.0, 1000.0, 678.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2179, "q_vals": [-9.779, -inf, -9.056, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1968, "visits": [17.0, 1000.0, 679.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2179, "q_vals": [-9.779, -inf, -9.056, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1969, "visits": [17.0, 1000.0, 680.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2180, "q_vals": [-9.779, -inf, -9.055, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1970, "visits": [17.0, 1000.0, 681.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2181, "q_vals": [-9.779, -inf, -9.055, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1971, "visits": [17.0, 1000.0, 682.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2181, "q_vals": [-9.779, -inf, -9.054, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1972, "visits": [17.0, 1000.0, 683.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2181, "q_vals": [-9.779, -inf, -9.054, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1973, "visits": [17.0, 1000.0, 684.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2181, "q_vals": [-9.779, -inf, -9.053, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1974, "visits": [17.0, 1000.0, 685.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2182, "q_vals": [-9.779, -inf, -9.053, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1975, "visits": [17.0, 1000.0, 686.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2182, "q_vals": [-9.779, -inf, -9.072, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1976, "visits": [17.0, 1000.0, 687.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2184, "q_vals": [-9.779, -inf, -9.071, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1977, "visits": [17.0, 1000.0, 688.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2184, "q_vals": [-9.779, -inf, -9.058, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1978, "visits": [17.0, 1000.0, 689.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2184, "q_vals": [-9.779, -inf, -9.045, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1979, "visits": [17.0, 1000.0, 690.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2185, "q_vals": [-9.779, -inf, -9.044, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1980, "visits": [17.0, 1000.0, 691.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2185, "q_vals": [-9.779, -inf, -9.031, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1981, "visits": [17.0, 1000.0, 692.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2187, "q_vals": [-9.779, -inf, -9.031, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1982, "visits": [17.0, 1000.0, 693.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2187, "q_vals": [-9.779, -inf, -9.018, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1983, "visits": [17.0, 1000.0, 694.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2187, "q_vals": [-9.779, -inf, -9.018, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2188, "number_of_timesteps": 187539, "per_episode_reward": -399.48, "episode_reward_trend_value": -0.013784884147274726, "biggest_recent_change": 1.058773004294551},
{ "step": 1984, "visits": [17.0, 1000.0, 695.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2188, "q_vals": [-9.779, -inf, -9.017, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1985, "visits": [17.0, 1000.0, 696.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2189, "q_vals": [-9.779, -inf, -9.017, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1986, "visits": [17.0, 1000.0, 697.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2190, "q_vals": [-9.779, -inf, -9.016, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1987, "visits": [17.0, 1000.0, 698.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2190, "q_vals": [-9.779, -inf, -9.016, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1988, "visits": [17.0, 1000.0, 699.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2190, "q_vals": [-9.779, -inf, -9.016, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1989, "visits": [17.0, 1000.0, 700.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2191, "q_vals": [-9.779, -inf, -9.015, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1990, "visits": [17.0, 1000.0, 701.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2192, "q_vals": [-9.779, -inf, -9.015, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1991, "visits": [17.0, 1000.0, 702.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2195, "q_vals": [-9.779, -inf, -9.033, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1992, "visits": [17.0, 1000.0, 703.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2195, "q_vals": [-9.779, -inf, -9.033, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1993, "visits": [17.0, 1000.0, 704.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2196, "q_vals": [-9.779, -inf, -9.032, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1994, "visits": [17.0, 1000.0, 705.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2196, "q_vals": [-9.779, -inf, -9.032, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1995, "visits": [17.0, 1000.0, 706.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2196, "q_vals": [-9.779, -inf, -9.032, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1996, "visits": [17.0, 1000.0, 707.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2196, "q_vals": [-9.779, -inf, -9.031, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2198, "number_of_timesteps": 189026, "per_episode_reward": -400.48, "episode_reward_trend_value": -0.018321102245309678, "biggest_recent_change": 1.058773004294551},
{ "step": 1997, "visits": [17.0, 1000.0, 708.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2198, "q_vals": [-9.779, -inf, -9.018, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1998, "visits": [17.0, 1000.0, 709.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2198, "q_vals": [-9.779, -inf, -9.018, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 1999, "visits": [17.0, 1000.0, 710.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2198, "q_vals": [-9.779, -inf, -9.018, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2000, "visits": [17.0, 1000.0, 711.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2199, "q_vals": [-9.779, -inf, -9.017, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2001, "visits": [17.0, 1000.0, 712.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2200, "q_vals": [-9.779, -inf, -9.017, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2002, "visits": [17.0, 1000.0, 713.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2202, "q_vals": [-9.779, -inf, -9.017, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2003, "visits": [17.0, 1000.0, 714.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2202, "q_vals": [-9.779, -inf, -9.016, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2004, "visits": [17.0, 1000.0, 715.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2203, "q_vals": [-9.779, -inf, -9.016, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2005, "visits": [17.0, 1000.0, 716.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2204, "q_vals": [-9.779, -inf, -9.015, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2006, "visits": [17.0, 1000.0, 717.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2204, "q_vals": [-9.779, -inf, -9.003, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2007, "visits": [17.0, 1000.0, 718.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2205, "q_vals": [-9.779, -inf, -8.99, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2008, "visits": [17.0, 1000.0, 719.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2206, "q_vals": [-9.779, -inf, -8.99, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2009, "visits": [17.0, 1000.0, 720.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2207, "q_vals": [-9.779, -inf, -8.99, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2010, "visits": [17.0, 1000.0, 721.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2207, "q_vals": [-9.779, -inf, -8.989, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2011, "visits": [17.0, 1000.0, 722.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2207, "q_vals": [-9.779, -inf, -8.989, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2012, "visits": [17.0, 1000.0, 723.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2207, "q_vals": [-9.779, -inf, -8.989, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2208, "number_of_timesteps": 190350, "per_episode_reward": -399.82, "episode_reward_trend_value": -0.01002019983736899, "biggest_recent_change": 1.058773004294551},
{ "step": 2013, "visits": [17.0, 1000.0, 724.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2208, "q_vals": [-9.779, -inf, -9.006, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2014, "visits": [17.0, 1000.0, 725.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2209, "q_vals": [-9.779, -inf, -9.006, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2015, "visits": [17.0, 1000.0, 726.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2209, "q_vals": [-9.779, -inf, -9.024, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2016, "visits": [17.0, 1000.0, 727.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2210, "q_vals": [-9.779, -inf, -9.023, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2017, "visits": [17.0, 1000.0, 728.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2210, "q_vals": [-9.779, -inf, -9.011, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2018, "visits": [17.0, 1000.0, 729.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2212, "q_vals": [-9.779, -inf, -9.011, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2019, "visits": [17.0, 1000.0, 730.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2213, "q_vals": [-9.779, -inf, -9.01, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2020, "visits": [17.0, 1000.0, 731.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2214, "q_vals": [-9.779, -inf, -9.028, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2021, "visits": [17.0, 1000.0, 732.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2214, "q_vals": [-9.779, -inf, -9.028, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2022, "visits": [17.0, 1000.0, 733.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2216, "q_vals": [-9.779, -inf, -9.045, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2023, "visits": [17.0, 1000.0, 734.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2216, "q_vals": [-9.779, -inf, -9.033, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2024, "visits": [17.0, 1000.0, 735.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2216, "q_vals": [-9.779, -inf, -9.032, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2025, "visits": [17.0, 1000.0, 736.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2217, "q_vals": [-9.779, -inf, -9.032, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2218, "number_of_timesteps": 191818, "per_episode_reward": -400.03, "episode_reward_trend_value": -0.02419775359440703, "biggest_recent_change": 0.9971022376815313},
{ "step": 2026, "visits": [17.0, 1000.0, 737.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2218, "q_vals": [-9.779, -inf, -9.02, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2027, "visits": [17.0, 1000.0, 738.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2219, "q_vals": [-9.779, -inf, -9.008, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2028, "visits": [17.0, 1000.0, 739.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2219, "q_vals": [-9.779, -inf, -9.007, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2029, "visits": [17.0, 1000.0, 740.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2220, "q_vals": [-9.779, -inf, -8.995, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2030, "visits": [17.0, 1000.0, 741.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2220, "q_vals": [-9.779, -inf, -8.995, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2031, "visits": [17.0, 1000.0, 742.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2221, "q_vals": [-9.779, -inf, -8.994, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2032, "visits": [17.0, 1000.0, 743.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2222, "q_vals": [-9.779, -inf, -8.994, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2033, "visits": [17.0, 1000.0, 744.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2222, "q_vals": [-9.779, -inf, -8.982, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2034, "visits": [17.0, 1000.0, 745.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2222, "q_vals": [-9.779, -inf, -8.982, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2035, "visits": [17.0, 1000.0, 746.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2224, "q_vals": [-9.779, -inf, -8.981, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2036, "visits": [17.0, 1000.0, 747.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2225, "q_vals": [-9.779, -inf, -8.981, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2037, "visits": [17.0, 1000.0, 748.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2227, "q_vals": [-9.779, -inf, -8.981, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2038, "visits": [17.0, 1000.0, 749.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2227, "q_vals": [-9.779, -inf, -8.98, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2228, "number_of_timesteps": 193147, "per_episode_reward": -401.14, "episode_reward_trend_value": -0.04743981128778059, "biggest_recent_change": 1.109063058617096},
{ "step": 2039, "visits": [17.0, 1000.0, 750.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2228, "q_vals": [-9.779, -inf, -8.98, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2040, "visits": [17.0, 1000.0, 751.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2229, "q_vals": [-9.779, -inf, -8.98, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2041, "visits": [17.0, 1000.0, 752.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2230, "q_vals": [-9.779, -inf, -8.968, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2042, "visits": [17.0, 1000.0, 753.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2230, "q_vals": [-9.779, -inf, -8.968, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2043, "visits": [17.0, 1000.0, 754.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2230, "q_vals": [-9.779, -inf, -8.956, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2044, "visits": [17.0, 1000.0, 755.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2231, "q_vals": [-9.779, -inf, -8.955, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2045, "visits": [17.0, 1000.0, 756.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2231, "q_vals": [-9.779, -inf, -8.955, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2046, "visits": [17.0, 1000.0, 757.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2233, "q_vals": [-9.779, -inf, -8.955, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2047, "visits": [17.0, 1000.0, 758.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2233, "q_vals": [-9.779, -inf, -8.955, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2048, "visits": [17.0, 1000.0, 759.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2234, "q_vals": [-9.779, -inf, -8.972, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2049, "visits": [17.0, 1000.0, 760.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2235, "q_vals": [-9.779, -inf, -8.971, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2050, "visits": [17.0, 1000.0, 761.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2235, "q_vals": [-9.779, -inf, -8.971, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2051, "visits": [17.0, 1000.0, 762.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2236, "q_vals": [-9.779, -inf, -8.971, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2052, "visits": [17.0, 1000.0, 763.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2236, "q_vals": [-9.779, -inf, -8.97, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2053, "visits": [17.0, 1000.0, 764.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2236, "q_vals": [-9.779, -inf, -8.97, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2238, "number_of_timesteps": 194290, "per_episode_reward": -400.97, "episode_reward_trend_value": -0.04129257047529538, "biggest_recent_change": 1.109063058617096},
{ "step": 2054, "visits": [17.0, 1000.0, 765.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2238, "q_vals": [-9.779, -inf, -8.97, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2055, "visits": [17.0, 1000.0, 766.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2238, "q_vals": [-9.779, -inf, -8.97, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2056, "visits": [17.0, 1000.0, 767.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2239, "q_vals": [-9.779, -inf, -8.986, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2057, "visits": [17.0, 1000.0, 768.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2240, "q_vals": [-9.779, -inf, -8.986, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2058, "visits": [17.0, 1000.0, 769.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2240, "q_vals": [-9.779, -inf, -8.986, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2059, "visits": [17.0, 1000.0, 770.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2242, "q_vals": [-9.779, -inf, -8.985, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2060, "visits": [17.0, 1000.0, 771.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2243, "q_vals": [-9.779, -inf, -8.985, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2061, "visits": [17.0, 1000.0, 772.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2243, "q_vals": [-9.779, -inf, -8.985, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2062, "visits": [17.0, 1000.0, 773.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2243, "q_vals": [-9.779, -inf, -9.002, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2063, "visits": [17.0, 1000.0, 774.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2243, "q_vals": [-9.779, -inf, -9.001, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2064, "visits": [17.0, 1000.0, 775.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2244, "q_vals": [-9.779, -inf, -8.99, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2065, "visits": [17.0, 1000.0, 776.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2245, "q_vals": [-9.779, -inf, -9.006, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2066, "visits": [17.0, 1000.0, 777.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2245, "q_vals": [-9.779, -inf, -8.995, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2067, "visits": [17.0, 1000.0, 778.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2245, "q_vals": [-9.779, -inf, -8.994, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2068, "visits": [17.0, 1000.0, 779.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2245, "q_vals": [-9.779, -inf, -8.994, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2069, "visits": [17.0, 1000.0, 780.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2246, "q_vals": [-9.779, -inf, -8.994, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2248, "number_of_timesteps": 195557, "per_episode_reward": -400.69, "episode_reward_trend_value": -0.03727083666001805, "biggest_recent_change": 1.109063058617096},
{ "step": 2070, "visits": [17.0, 1000.0, 781.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2248, "q_vals": [-9.779, -inf, -8.993, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2071, "visits": [17.0, 1000.0, 782.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2249, "q_vals": [-9.779, -inf, -8.993, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2072, "visits": [17.0, 1000.0, 783.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2250, "q_vals": [-9.779, -inf, -8.993, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2073, "visits": [17.0, 1000.0, 784.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2252, "q_vals": [-9.779, -inf, -9.009, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2074, "visits": [17.0, 1000.0, 785.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2252, "q_vals": [-9.779, -inf, -9.009, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2075, "visits": [17.0, 1000.0, 786.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2252, "q_vals": [-9.779, -inf, -9.009, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2076, "visits": [17.0, 1000.0, 787.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2255, "q_vals": [-9.779, -inf, -9.008, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2077, "visits": [17.0, 1000.0, 788.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2257, "q_vals": [-9.779, -inf, -9.008, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2258, "number_of_timesteps": 197008, "per_episode_reward": -400.0, "episode_reward_trend_value": -0.02217144113805855, "biggest_recent_change": 1.109063058617096},
{ "step": 2078, "visits": [17.0, 1000.0, 789.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2258, "q_vals": [-9.779, -inf, -9.008, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2079, "visits": [17.0, 1000.0, 790.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2259, "q_vals": [-9.779, -inf, -8.996, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2080, "visits": [17.0, 1000.0, 791.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2260, "q_vals": [-9.779, -inf, -8.996, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2081, "visits": [17.0, 1000.0, 792.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2260, "q_vals": [-9.779, -inf, -8.996, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2082, "visits": [17.0, 1000.0, 793.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2262, "q_vals": [-9.779, -inf, -8.984, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2083, "visits": [17.0, 1000.0, 794.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2263, "q_vals": [-9.779, -inf, -8.984, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2084, "visits": [17.0, 1000.0, 795.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2263, "q_vals": [-9.779, -inf, -9.0, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2085, "visits": [17.0, 1000.0, 796.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2265, "q_vals": [-9.779, -inf, -9.0, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2086, "visits": [17.0, 1000.0, 797.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2267, "q_vals": [-9.779, -inf, -8.999, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2087, "visits": [17.0, 1000.0, 798.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2267, "q_vals": [-9.779, -inf, -8.999, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2270, "number_of_timesteps": 197891, "per_episode_reward": -400.19, "episode_reward_trend_value": -0.0189437183577013, "biggest_recent_change": 1.109063058617096},
{ "step": 2088, "visits": [17.0, 1000.0, 799.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2270, "q_vals": [-9.779, -inf, -8.999, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2089, "visits": [17.0, 1000.0, 800.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2271, "q_vals": [-9.779, -inf, -8.994, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2090, "visits": [17.0, 1000.0, 801.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2271, "q_vals": [-9.779, -inf, -8.983, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2091, "visits": [17.0, 1000.0, 802.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2272, "q_vals": [-9.779, -inf, -8.982, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
 q_vals: [-9.779, -inf, -8.982, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117]
{ "step": 2093, "visits": [17.0, 1000.0, 804.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2272, "q_vals": [-9.779, -inf, -8.982, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2094, "visits": [17.0, 1000.0, 805.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2274, "q_vals": [-9.779, -inf, -8.981, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2095, "visits": [17.0, 1000.0, 806.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2276, "q_vals": [-9.779, -inf, -8.981, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2096, "visits": [17.0, 1000.0, 807.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2279, "q_vals": [-9.779, -inf, -8.981, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2097, "visits": [17.0, 1000.0, 808.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2279, "q_vals": [-9.779, -inf, -8.981, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2280, "number_of_timesteps": 198682, "per_episode_reward": -400.31, "episode_reward_trend_value": -0.009195133944703254, "biggest_recent_change": 1.109063058617096},
{ "step": 2098, "visits": [17.0, 1000.0, 809.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2280, "q_vals": [-9.779, -inf, -8.98, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2099, "visits": [17.0, 1000.0, 810.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2280, "q_vals": [-9.779, -inf, -8.969, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2100, "visits": [17.0, 1000.0, 811.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2280, "q_vals": [-9.779, -inf, -8.969, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2101, "visits": [17.0, 1000.0, 812.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2281, "q_vals": [-9.779, -inf, -8.969, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2102, "visits": [17.0, 1000.0, 813.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2283, "q_vals": [-9.779, -inf, -8.958, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2103, "visits": [17.0, 1000.0, 814.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2285, "q_vals": [-9.779, -inf, -8.947, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2104, "visits": [17.0, 1000.0, 815.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2287, "q_vals": [-9.779, -inf, -8.946, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2105, "visits": [17.0, 1000.0, 816.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2288, "q_vals": [-9.779, -inf, -8.946, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2106, "visits": [17.0, 1000.0, 817.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2289, "q_vals": [-9.779, -inf, -8.946, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2107, "visits": [17.0, 1000.0, 818.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2289, "q_vals": [-9.779, -inf, -8.946, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2108, "visits": [17.0, 1000.0, 819.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2289, "q_vals": [-9.779, -inf, -8.945, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2290, "number_of_timesteps": 199464, "per_episode_reward": -399.81, "episode_reward_trend_value": 0.007375284068944489, "biggest_recent_change": 1.109063058617096},
{ "step": 2109, "visits": [17.0, 1000.0, 820.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2290, "q_vals": [-9.779, -inf, -8.945, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2110, "visits": [17.0, 1000.0, 821.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2291, "q_vals": [-9.779, -inf, -8.945, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2111, "visits": [17.0, 1000.0, 822.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2292, "q_vals": [-9.779, -inf, -8.945, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2112, "visits": [17.0, 1000.0, 823.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2295, "q_vals": [-9.779, -inf, -8.944, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2113, "visits": [17.0, 1000.0, 824.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2296, "q_vals": [-9.779, -inf, -8.944, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2114, "visits": [17.0, 1000.0, 825.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2296, "q_vals": [-9.779, -inf, -8.944, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2115, "visits": [17.0, 1000.0, 826.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2298, "q_vals": [-9.779, -inf, -8.944, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2116, "visits": [17.0, 1000.0, 827.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2299, "q_vals": [-9.779, -inf, -8.943, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2117, "visits": [17.0, 1000.0, 828.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2299, "q_vals": [-9.779, -inf, -8.938, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2301, "number_of_timesteps": 200355, "per_episode_reward": -399.92, "episode_reward_trend_value": -0.0011831787858644323, "biggest_recent_change": 1.109063058617096},
{ "step": 2118, "visits": [17.0, 1000.0, 829.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2301, "q_vals": [-9.779, -inf, -8.938, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2119, "visits": [17.0, 1000.0, 830.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2302, "q_vals": [-9.779, -inf, -8.938, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2120, "visits": [17.0, 1000.0, 831.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2302, "q_vals": [-9.779, -inf, -8.937, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2121, "visits": [17.0, 1000.0, 832.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2304, "q_vals": [-9.779, -inf, -8.937, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2122, "visits": [17.0, 1000.0, 833.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2304, "q_vals": [-9.779, -inf, -8.937, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2123, "visits": [17.0, 1000.0, 834.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2306, "q_vals": [-9.779, -inf, -8.937, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2124, "visits": [17.0, 1000.0, 835.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2306, "q_vals": [-9.779, -inf, -8.937, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2125, "visits": [17.0, 1000.0, 836.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2307, "q_vals": [-9.779, -inf, -8.936, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2126, "visits": [17.0, 1000.0, 837.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2308, "q_vals": [-9.779, -inf, -8.936, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2127, "visits": [17.0, 1000.0, 838.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2309, "q_vals": [-9.779, -inf, -8.936, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2311, "number_of_timesteps": 201177, "per_episode_reward": -400.17, "episode_reward_trend_value": -0.0014721650552972834, "biggest_recent_change": 1.109063058617096},
{ "step": 2128, "visits": [17.0, 1000.0, 839.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2311, "q_vals": [-9.779, -inf, -8.936, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2129, "visits": [17.0, 1000.0, 840.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2312, "q_vals": [-9.779, -inf, -8.935, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2130, "visits": [17.0, 1000.0, 841.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2314, "q_vals": [-9.779, -inf, -8.935, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2131, "visits": [17.0, 1000.0, 842.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2314, "q_vals": [-9.779, -inf, -8.935, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2132, "visits": [17.0, 1000.0, 843.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2314, "q_vals": [-9.779, -inf, -8.935, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2133, "visits": [17.0, 1000.0, 844.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2314, "q_vals": [-9.779, -inf, -8.935, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2134, "visits": [17.0, 1000.0, 845.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2314, "q_vals": [-9.779, -inf, -8.934, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2135, "visits": [17.0, 1000.0, 846.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2319, "q_vals": [-9.779, -inf, -8.934, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2136, "visits": [17.0, 1000.0, 847.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2319, "q_vals": [-9.779, -inf, -8.934, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2137, "visits": [17.0, 1000.0, 848.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2320, "q_vals": [-9.779, -inf, -8.934, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2138, "visits": [17.0, 1000.0, 849.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2320, "q_vals": [-9.779, -inf, -8.934, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2321, "number_of_timesteps": 202024, "per_episode_reward": -400.01, "episode_reward_trend_value": 0.012629696747652335, "biggest_recent_change": 0.6928058185636132},
{ "step": 2139, "visits": [17.0, 1000.0, 850.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2321, "q_vals": [-9.779, -inf, -8.933, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2140, "visits": [17.0, 1000.0, 851.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2322, "q_vals": [-9.779, -inf, -8.933, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2141, "visits": [17.0, 1000.0, 852.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2323, "q_vals": [-9.779, -inf, -8.933, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2142, "visits": [17.0, 1000.0, 853.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2323, "q_vals": [-9.779, -inf, -8.933, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2143, "visits": [17.0, 1000.0, 854.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2323, "q_vals": [-9.779, -inf, -8.932, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2144, "visits": [17.0, 1000.0, 855.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2325, "q_vals": [-9.779, -inf, -8.932, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2145, "visits": [17.0, 1000.0, 856.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2328, "q_vals": [-9.779, -inf, -8.932, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2146, "visits": [17.0, 1000.0, 857.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2329, "q_vals": [-9.779, -inf, -8.932, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2147, "visits": [17.0, 1000.0, 858.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2330, "q_vals": [-9.779, -inf, -8.932, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2148, "visits": [17.0, 1000.0, 859.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2330, "q_vals": [-9.779, -inf, -8.931, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2332, "number_of_timesteps": 203941, "per_episode_reward": -400.75, "episode_reward_trend_value": 0.0024181106914044096, "biggest_recent_change": 0.7445038226283032},
{ "step": 2149, "visits": [17.0, 1000.0, 860.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2332, "q_vals": [-9.779, -inf, -8.931, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2150, "visits": [17.0, 1000.0, 861.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2333, "q_vals": [-9.779, -inf, -8.931, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2151, "visits": [17.0, 1000.0, 862.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2335, "q_vals": [-9.779, -inf, -8.946, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2152, "visits": [17.0, 1000.0, 863.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2338, "q_vals": [-9.779, -inf, -8.946, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2153, "visits": [17.0, 1000.0, 864.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2339, "q_vals": [-9.779, -inf, -8.946, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2154, "visits": [17.0, 1000.0, 865.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2340, "q_vals": [-9.779, -inf, -8.96, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2155, "visits": [17.0, 1000.0, 866.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2340, "q_vals": [-9.779, -inf, -8.96, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2342, "number_of_timesteps": 204611, "per_episode_reward": -400.56, "episode_reward_trend_value": 0.0014953518512148397, "biggest_recent_change": 0.7445038226283032},
[-9.779, -inf, -8.96, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117]
{ "step": 2157, "visits": [17.0, 1000.0, 868.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2343, "q_vals": [-9.779, -inf, -8.975, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2158, "visits": [17.0, 1000.0, 869.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2346, "q_vals": [-9.779, -inf, -8.975, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2159, "visits": [17.0, 1000.0, 870.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2346, "q_vals": [-9.779, -inf, -8.964, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2160, "visits": [17.0, 1000.0, 871.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2347, "q_vals": [-9.779, -inf, -8.964, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2161, "visits": [17.0, 1000.0, 872.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2348, "q_vals": [-9.779, -inf, -8.954, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2162, "visits": [17.0, 1000.0, 873.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2350, "q_vals": [-9.779, -inf, -8.954, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2163, "visits": [17.0, 1000.0, 874.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2351, "q_vals": [-9.779, -inf, -8.953, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2353, "number_of_timesteps": 205367, "per_episode_reward": -401.88, "episode_reward_trend_value": -0.020912296131630606, "biggest_recent_change": 1.323882499892477},
{ "step": 2164, "visits": [17.0, 1000.0, 875.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2353, "q_vals": [-9.779, -inf, -8.953, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2165, "visits": [17.0, 1000.0, 876.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2356, "q_vals": [-9.779, -inf, -8.943, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2166, "visits": [17.0, 1000.0, 877.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2356, "q_vals": [-9.779, -inf, -8.943, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2167, "visits": [17.0, 1000.0, 878.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2358, "q_vals": [-9.779, -inf, -8.942, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2168, "visits": [17.0, 1000.0, 879.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2359, "q_vals": [-9.779, -inf, -8.942, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2169, "visits": [17.0, 1000.0, 880.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2360, "q_vals": [-9.779, -inf, -8.942, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2170, "visits": [17.0, 1000.0, 881.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2362, "q_vals": [-9.779, -inf, -8.942, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2364, "number_of_timesteps": 206055, "per_episode_reward": -402.58, "episode_reward_trend_value": -0.026578032831674946, "biggest_recent_change": 1.323882499892477},
{ "step": 2171, "visits": [17.0, 1000.0, 882.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2364, "q_vals": [-9.779, -inf, -8.956, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2172, "visits": [17.0, 1000.0, 883.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2365, "q_vals": [-9.779, -inf, -8.956, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2173, "visits": [17.0, 1000.0, 884.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2367, "q_vals": [-9.779, -inf, -8.956, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2174, "visits": [17.0, 1000.0, 885.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2368, "q_vals": [-9.779, -inf, -8.956, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2175, "visits": [17.0, 1000.0, 886.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2369, "q_vals": [-9.779, -inf, -8.955, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2176, "visits": [17.0, 1000.0, 887.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2369, "q_vals": [-9.779, -inf, -8.945, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2177, "visits": [17.0, 1000.0, 888.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2371, "q_vals": [-9.779, -inf, -8.945, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2178, "visits": [17.0, 1000.0, 889.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2372, "q_vals": [-9.779, -inf, -8.945, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2377, "number_of_timesteps": 206942, "per_episode_reward": -402.63, "episode_reward_trend_value": -0.025837684788552272, "biggest_recent_change": 1.323882499892477},
{ "step": 2179, "visits": [17.0, 1000.0, 890.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2377, "q_vals": [-9.779, -inf, -8.945, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2180, "visits": [17.0, 1000.0, 891.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2377, "q_vals": [-9.779, -inf, -8.944, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2181, "visits": [17.0, 1000.0, 892.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2378, "q_vals": [-9.779, -inf, -8.944, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2182, "visits": [17.0, 1000.0, 893.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2378, "q_vals": [-9.779, -inf, -8.959, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2183, "visits": [17.0, 1000.0, 894.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2379, "q_vals": [-9.779, -inf, -8.973, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2184, "visits": [17.0, 1000.0, 895.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2379, "q_vals": [-9.779, -inf, -8.973, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2185, "visits": [17.0, 1000.0, 896.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2381, "q_vals": [-9.779, -inf, -8.973, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2186, "visits": [17.0, 1000.0, 897.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2385, "q_vals": [-9.779, -inf, -8.972, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2387, "number_of_timesteps": 207630, "per_episode_reward": -402.72, "episode_reward_trend_value": -0.0322715347205278, "biggest_recent_change": 1.323882499892477},
[-9.779, -inf, -8.972, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117]
{ "step": 2188, "visits": [17.0, 1000.0, 899.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2387, "q_vals": [-9.779, -inf, -8.972, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2189, "visits": [17.0, 1000.0, 900.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2387, "q_vals": [-9.779, -inf, -8.972, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2190, "visits": [17.0, 1000.0, 901.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2388, "q_vals": [-9.779, -inf, -8.971, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2191, "visits": [17.0, 1000.0, 902.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2390, "q_vals": [-9.779, -inf, -8.986, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2192, "visits": [17.0, 1000.0, 903.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2391, "q_vals": [-9.779, -inf, -8.986, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2193, "visits": [17.0, 1000.0, 904.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2394, "q_vals": [-9.779, -inf, -8.985, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2194, "visits": [17.0, 1000.0, 905.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2396, "q_vals": [-9.779, -inf, -8.985, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2195, "visits": [17.0, 1000.0, 906.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2396, "q_vals": [-9.779, -inf, -8.985, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2398, "number_of_timesteps": 208405, "per_episode_reward": -402.68, "episode_reward_trend_value": -0.030596083275299356, "biggest_recent_change": 1.323882499892477},
{ "step": 2196, "visits": [17.0, 1000.0, 907.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2398, "q_vals": [-9.779, -inf, -8.984, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2197, "visits": [17.0, 1000.0, 908.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2399, "q_vals": [-9.779, -inf, -8.984, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2198, "visits": [17.0, 1000.0, 909.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2399, "q_vals": [-9.779, -inf, -8.984, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2199, "visits": [17.0, 1000.0, 910.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2401, "q_vals": [-9.779, -inf, -8.984, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2200, "visits": [17.0, 1000.0, 911.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2404, "q_vals": [-9.779, -inf, -8.983, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2201, "visits": [17.0, 1000.0, 912.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2404, "q_vals": [-9.779, -inf, -8.983, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2202, "visits": [17.0, 1000.0, 913.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2407, "q_vals": [-9.779, -inf, -8.983, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2408, "number_of_timesteps": 209046, "per_episode_reward": -402.69, "episode_reward_trend_value": -0.028084461683247734, "biggest_recent_change": 1.323882499892477},
{ "step": 2203, "visits": [17.0, 1000.0, 914.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2408, "q_vals": [-9.779, -inf, -8.983, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2204, "visits": [17.0, 1000.0, 915.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2409, "q_vals": [-9.779, -inf, -8.982, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2205, "visits": [17.0, 1000.0, 916.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2410, "q_vals": [-9.779, -inf, -8.982, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2206, "visits": [17.0, 1000.0, 917.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2412, "q_vals": [-9.779, -inf, -8.982, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2207, "visits": [17.0, 1000.0, 918.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2412, "q_vals": [-9.779, -inf, -8.972, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2208, "visits": [17.0, 1000.0, 919.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2414, "q_vals": [-9.779, -inf, -8.962, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2209, "visits": [17.0, 1000.0, 920.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2417, "q_vals": [-9.779, -inf, -8.962, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2418, "number_of_timesteps": 209712, "per_episode_reward": -403.4, "episode_reward_trend_value": -0.03770775957206133, "biggest_recent_change": 1.323882499892477},
{ "step": 2210, "visits": [17.0, 1000.0, 921.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2418, "q_vals": [-9.779, -inf, -8.976, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2211, "visits": [17.0, 1000.0, 922.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2419, "q_vals": [-9.779, -inf, -8.976, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2212, "visits": [17.0, 1000.0, 923.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2421, "q_vals": [-9.779, -inf, -8.99, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2213, "visits": [17.0, 1000.0, 924.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2423, "q_vals": [-9.779, -inf, -8.99, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2214, "visits": [17.0, 1000.0, 925.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2423, "q_vals": [-9.779, -inf, -8.98, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2215, "visits": [17.0, 1000.0, 926.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2427, "q_vals": [-9.779, -inf, -8.98, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2428, "number_of_timesteps": 210286, "per_episode_reward": -402.47, "episode_reward_trend_value": -0.019152246625000972, "biggest_recent_change": 1.323882499892477},
{ "step": 2216, "visits": [17.0, 1000.0, 927.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2428, "q_vals": [-9.779, -inf, -8.979, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2217, "visits": [17.0, 1000.0, 928.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2429, "q_vals": [-9.779, -inf, -8.979, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2218, "visits": [17.0, 1000.0, 929.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2430, "q_vals": [-9.779, -inf, -8.993, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2219, "visits": [17.0, 1000.0, 930.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2431, "q_vals": [-9.779, -inf, -8.993, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2220, "visits": [17.0, 1000.0, 931.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2432, "q_vals": [-9.779, -inf, -8.993, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2221, "visits": [17.0, 1000.0, 932.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2432, "q_vals": [-9.779, -inf, -8.983, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2222, "visits": [17.0, 1000.0, 933.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2434, "q_vals": [-9.779, -inf, -8.983, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2223, "visits": [17.0, 1000.0, 934.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2437, "q_vals": [-9.779, -inf, -8.982, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2439, "number_of_timesteps": 211101, "per_episode_reward": -403.45, "episode_reward_trend_value": -0.032188190189239345, "biggest_recent_change": 1.323882499892477},
{ "step": 2224, "visits": [17.0, 1000.0, 935.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2439, "q_vals": [-9.779, -inf, -8.982, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2225, "visits": [17.0, 1000.0, 936.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2439, "q_vals": [-9.779, -inf, -8.982, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2226, "visits": [17.0, 1000.0, 937.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2441, "q_vals": [-9.779, -inf, -8.982, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2227, "visits": [17.0, 1000.0, 938.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2441, "q_vals": [-9.779, -inf, -8.981, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2228, "visits": [17.0, 1000.0, 939.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2441, "q_vals": [-9.779, -inf, -8.972, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2229, "visits": [17.0, 1000.0, 940.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2443, "q_vals": [-9.779, -inf, -8.972, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2230, "visits": [17.0, 1000.0, 941.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2445, "q_vals": [-9.779, -inf, -8.971, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2231, "visits": [17.0, 1000.0, 942.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2446, "q_vals": [-9.779, -inf, -8.971, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2232, "visits": [17.0, 1000.0, 943.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2448, "q_vals": [-9.779, -inf, -8.971, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2449, "number_of_timesteps": 211859, "per_episode_reward": -404.3, "episode_reward_trend_value": -0.026940640492469786, "biggest_recent_change": 0.9791970266319936},
{ "step": 2233, "visits": [17.0, 1000.0, 944.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2449, "q_vals": [-9.779, -inf, -8.961, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2234, "visits": [17.0, 1000.0, 945.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2450, "q_vals": [-9.779, -inf, -8.961, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2235, "visits": [17.0, 1000.0, 946.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2453, "q_vals": [-9.779, -inf, -8.952, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2236, "visits": [17.0, 1000.0, 947.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2454, "q_vals": [-9.779, -inf, -8.951, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2237, "visits": [17.0, 1000.0, 948.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2455, "q_vals": [-9.779, -inf, -8.951, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2238, "visits": [17.0, 1000.0, 949.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2456, "q_vals": [-9.779, -inf, -8.951, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2239, "visits": [17.0, 1000.0, 950.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2456, "q_vals": [-9.779, -inf, -8.965, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2240, "visits": [17.0, 1000.0, 951.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2458, "q_vals": [-9.779, -inf, -8.978, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2460, "number_of_timesteps": 212587, "per_episode_reward": -404.31, "episode_reward_trend_value": -0.019239379173348604, "biggest_recent_change": 0.9791970266319936},
{ "step": 2241, "visits": [17.0, 1000.0, 952.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2460, "q_vals": [-9.779, -inf, -8.978, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2242, "visits": [17.0, 1000.0, 953.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2460, "q_vals": [-9.779, -inf, -8.978, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2243, "visits": [17.0, 1000.0, 954.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2464, "q_vals": [-9.779, -inf, -8.978, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2244, "visits": [17.0, 1000.0, 955.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2465, "q_vals": [-9.779, -inf, -8.968, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2245, "visits": [17.0, 1000.0, 956.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2465, "q_vals": [-9.779, -inf, -8.968, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2246, "visits": [17.0, 1000.0, 957.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2466, "q_vals": [-9.779, -inf, -8.968, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2247, "visits": [17.0, 1000.0, 958.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2469, "q_vals": [-9.779, -inf, -8.958, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2248, "visits": [17.0, 1000.0, 959.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2469, "q_vals": [-9.779, -inf, -8.958, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2473, "number_of_timesteps": 213462, "per_episode_reward": -404.72, "episode_reward_trend_value": -0.023203410698154257, "biggest_recent_change": 0.9791970266319936},
{ "step": 2249, "visits": [17.0, 1000.0, 960.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2473, "q_vals": [-9.779, -inf, -8.972, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2250, "visits": [17.0, 1000.0, 961.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2473, "q_vals": [-9.779, -inf, -8.971, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2251, "visits": [17.0, 1000.0, 962.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2474, "q_vals": [-9.779, -inf, -8.962, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2252, "visits": [17.0, 1000.0, 963.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2476, "q_vals": [-9.779, -inf, -8.953, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2253, "visits": [17.0, 1000.0, 964.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2477, "q_vals": [-9.779, -inf, -8.952, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2254, "visits": [17.0, 1000.0, 965.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2477, "q_vals": [-9.779, -inf, -8.952, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2255, "visits": [17.0, 1000.0, 966.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2477, "q_vals": [-9.779, -inf, -8.952, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2256, "visits": [17.0, 1000.0, 967.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2482, "q_vals": [-9.779, -inf, -8.952, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2484, "number_of_timesteps": 214225, "per_episode_reward": -405.18, "episode_reward_trend_value": -0.027417586688179403, "biggest_recent_change": 0.9791970266319936},
{ "step": 2257, "visits": [17.0, 1000.0, 968.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2484, "q_vals": [-9.779, -inf, -8.965, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2258, "visits": [17.0, 1000.0, 969.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2485, "q_vals": [-9.779, -inf, -8.965, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2259, "visits": [17.0, 1000.0, 970.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2485, "q_vals": [-9.779, -inf, -8.965, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2260, "visits": [17.0, 1000.0, 971.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2486, "q_vals": [-9.779, -inf, -8.965, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2261, "visits": [17.0, 1000.0, 972.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2488, "q_vals": [-9.779, -inf, -8.964, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2262, "visits": [17.0, 1000.0, 973.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2489, "q_vals": [-9.779, -inf, -8.964, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2263, "visits": [17.0, 1000.0, 974.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2492, "q_vals": [-9.779, -inf, -8.964, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2494, "number_of_timesteps": 214862, "per_episode_reward": -405.28, "episode_reward_trend_value": -0.02891071830463956, "biggest_recent_change": 0.9791970266319936},
{ "step": 2264, "visits": [17.0, 1000.0, 975.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2494, "q_vals": [-9.779, -inf, -8.964, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2265, "visits": [17.0, 1000.0, 976.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2494, "q_vals": [-9.779, -inf, -8.954, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2266, "visits": [17.0, 1000.0, 977.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2496, "q_vals": [-9.779, -inf, -8.954, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2267, "visits": [17.0, 1000.0, 978.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2497, "q_vals": [-9.779, -inf, -8.967, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2268, "visits": [17.0, 1000.0, 979.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2498, "q_vals": [-9.779, -inf, -8.967, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2269, "visits": [17.0, 1000.0, 980.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2499, "q_vals": [-9.779, -inf, -8.958, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2270, "visits": [17.0, 1000.0, 981.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2500, "q_vals": [-9.779, -inf, -8.958, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2271, "visits": [17.0, 1000.0, 982.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2503, "q_vals": [-9.779, -inf, -8.971, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2506, "number_of_timesteps": 215640, "per_episode_reward": -405.74, "episode_reward_trend_value": -0.033838158431572965, "biggest_recent_change": 0.9791970266319936},
{ "step": 2272, "visits": [17.0, 1000.0, 983.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2506, "q_vals": [-9.779, -inf, -8.971, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2273, "visits": [17.0, 1000.0, 984.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2507, "q_vals": [-9.779, -inf, -8.971, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2274, "visits": [17.0, 1000.0, 985.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2508, "q_vals": [-9.779, -inf, -8.984, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2275, "visits": [17.0, 1000.0, 986.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2508, "q_vals": [-9.779, -inf, -8.983, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2276, "visits": [17.0, 1000.0, 987.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2510, "q_vals": [-9.779, -inf, -8.983, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2277, "visits": [17.0, 1000.0, 988.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2511, "q_vals": [-9.779, -inf, -8.983, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2278, "visits": [17.0, 1000.0, 989.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2514, "q_vals": [-9.779, -inf, -8.974, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2279, "visits": [17.0, 1000.0, 990.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2515, "q_vals": [-9.779, -inf, -8.974, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2280, "visits": [17.0, 1000.0, 991.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2515, "q_vals": [-9.779, -inf, -8.973, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2517, "number_of_timesteps": 216337, "per_episode_reward": -405.35, "episode_reward_trend_value": -0.021708301372243947, "biggest_recent_change": 0.9791970266319936},
{ "step": 2281, "visits": [17.0, 1000.0, 992.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2517, "q_vals": [-9.779, -inf, -8.973, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2282, "visits": [17.0, 1000.0, 993.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2519, "q_vals": [-9.779, -inf, -8.973, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2283, "visits": [17.0, 1000.0, 994.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2520, "q_vals": [-9.779, -inf, -8.986, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2284, "visits": [17.0, 1000.0, 995.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2522, "q_vals": [-9.779, -inf, -8.986, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2285, "visits": [17.0, 1000.0, 996.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2523, "q_vals": [-9.779, -inf, -8.985, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2286, "visits": [17.0, 1000.0, 997.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2523, "q_vals": [-9.779, -inf, -8.998, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2287, "visits": [17.0, 1000.0, 998.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2526, "q_vals": [-9.779, -inf, -8.995, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{"total_number_of_episodes": 2528, "number_of_timesteps": 217068, "per_episode_reward": -405.35, "episode_reward_trend_value": -0.03198480102769913, "biggest_recent_change": 0.9791970266319936},
{ "step": 2288, "visits": [17.0, 1000.0, 999.0, 1.0, 1.0, 3.0, 5.0, 13.0, 11.0, 16.0] , "episode_count": 2528, "q_vals": [-9.779, -inf, -8.994, -21.875, -21.875, -13.125, -12.25, -10.096, -9.943, -10.117] }
{ "step": 2289, "visits": [0.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 2529, "q_vals": [0.0, -inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 2290, "visits": [1.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 2530, "q_vals": [0.0, -inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 2291, "visits": [1.0, 1000.0, 1000.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 2531, "q_vals": [0.0, -inf, -inf, -24.49, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 2292, "visits": [1.0, 1000.0, 1000.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 2532, "q_vals": [0.0, -inf, -inf, -24.49, -9.796, 0.0, 0.0, 0.0, 0.0, 0.0] }
{ "step": 2293, "visits": [1.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 2534, "q_vals": [0.0, -inf, -inf, -24.49, -9.796, -9.796, 0.0, 0.0, 0.0, 0.0] }
{ "step": 2294, "visits": [1.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0] , "episode_count": 2535, "q_vals": [0.0, -inf, -inf, -24.49, -9.796, -9.796, -9.796, 0.0, 0.0, 0.0] }
{ "step": 2295, "visits": [1.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0] , "episode_count": 2537, "q_vals": [0.0, -inf, -inf, -24.49, -9.796, -9.796, -9.796, 0.0, 0.0, 0.0] }
{"total_number_of_episodes": 2538, "number_of_timesteps": 217735, "per_episode_reward": -361.54, "episode_reward_trend_value": 0.4657033917815972, "biggest_recent_change": 43.812740326204676},
{ "step": 2296, "visits": [1.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0] , "episode_count": 2538, "q_vals": [0.0, -inf, -inf, -24.49, -9.796, -9.796, -9.796, 0.0, -9.796, 0.0] }
{ "step": 2297, "visits": [1.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 2539, "q_vals": [0.0, -inf, -inf, -24.49, -9.796, -9.796, -9.796, 0.0, -9.796, -9.796] }
{ "step": 2298, "visits": [2.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] , "episode_count": 2540, "q_vals": [-4.898, -inf, -inf, -24.49, -9.796, -9.796, -9.796, 0.0, -9.796, -9.796] }
{ "step": 2299, "visits": [2.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0] , "episode_count": 2542, "q_vals": [-4.898, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -4.898, -9.796, -9.796] }
{ "step": 2300, "visits": [2.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2542, "q_vals": [-4.898, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2301, "visits": [3.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2546, "q_vals": [-3.265, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2302, "visits": [4.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2546, "q_vals": [-2.449, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2303, "visits": [5.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2547, "q_vals": [-1.959, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{"total_number_of_episodes": 2548, "number_of_timesteps": 218457, "per_episode_reward": -361.8, "episode_reward_trend_value": 0.47230745376881045, "biggest_recent_change": 43.812740326204676},
{ "step": 2304, "visits": [6.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2548, "q_vals": [-3.265, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2305, "visits": [7.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2549, "q_vals": [-2.799, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2306, "visits": [8.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2552, "q_vals": [-3.673, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2307, "visits": [9.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2553, "q_vals": [-4.354, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2308, "visits": [10.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2555, "q_vals": [-3.918, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2309, "visits": [11.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2557, "q_vals": [-3.562, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2310, "visits": [12.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2557, "q_vals": [-3.265, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2311, "visits": [13.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2557, "q_vals": [-3.768, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{"total_number_of_episodes": 2560, "number_of_timesteps": 219244, "per_episode_reward": -362.12, "episode_reward_trend_value": 0.46874782023453276, "biggest_recent_change": 43.812740326204676},
{ "step": 2312, "visits": [14.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2560, "q_vals": [-4.198, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2313, "visits": [15.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2562, "q_vals": [-4.571, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2314, "visits": [16.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2563, "q_vals": [-4.286, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2315, "visits": [17.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2564, "q_vals": [-4.61, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2316, "visits": [18.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2565, "q_vals": [-4.354, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2317, "visits": [19.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2566, "q_vals": [-4.64, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2318, "visits": [20.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2568, "q_vals": [-4.898, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2319, "visits": [21.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2569, "q_vals": [-5.131, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{"total_number_of_episodes": 2570, "number_of_timesteps": 219931, "per_episode_reward": -362.36, "episode_reward_trend_value": 0.4706295277591443, "biggest_recent_change": 43.812740326204676},
{ "step": 2320, "visits": [22.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2570, "q_vals": [-5.343, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2321, "visits": [23.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2572, "q_vals": [-5.537, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2322, "visits": [24.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2573, "q_vals": [-5.714, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2323, "visits": [25.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0] , "episode_count": 2575, "q_vals": [-5.878, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2324, "visits": [25.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0] , "episode_count": 2577, "q_vals": [-5.878, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -4.898, -9.796, -9.796] }
{ "step": 2325, "visits": [25.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 5.0, 1.0, 1.0] , "episode_count": 2578, "q_vals": [-5.878, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -5.878, -9.796, -9.796] }
{ "step": 2326, "visits": [25.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 6.0, 1.0, 1.0] , "episode_count": 2579, "q_vals": [-5.878, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{"total_number_of_episodes": 2580, "number_of_timesteps": 220618, "per_episode_reward": -362.55, "episode_reward_trend_value": 0.4737357661360623, "biggest_recent_change": 43.812740326204676},
{ "step": 2327, "visits": [26.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 6.0, 1.0, 1.0] , "episode_count": 2580, "q_vals": [-6.028, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2328, "visits": [27.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 6.0, 1.0, 1.0] , "episode_count": 2582, "q_vals": [-6.168, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.531, -9.796, -9.796] }
{ "step": 2329, "visits": [27.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2582, "q_vals": [-6.168, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2330, "visits": [28.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2584, "q_vals": [-5.948, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2331, "visits": [29.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2586, "q_vals": [-6.08, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2332, "visits": [30.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2588, "q_vals": [-6.204, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{"total_number_of_episodes": 2590, "number_of_timesteps": 221286, "per_episode_reward": -362.74, "episode_reward_trend_value": 0.47261897530735836, "biggest_recent_change": 43.812740326204676},
{ "step": 2333, "visits": [31.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2590, "q_vals": [-6.004, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2334, "visits": [32.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2590, "q_vals": [-6.122, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2335, "visits": [33.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2590, "q_vals": [-6.234, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2336, "visits": [34.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2591, "q_vals": [-6.05, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2337, "visits": [35.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2593, "q_vals": [-6.157, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2338, "visits": [36.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2595, "q_vals": [-5.986, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2339, "visits": [37.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2597, "q_vals": [-5.825, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{"total_number_of_episodes": 2600, "number_of_timesteps": 222004, "per_episode_reward": -362.9, "episode_reward_trend_value": 0.475938069730481, "biggest_recent_change": 43.812740326204676},
{ "step": 2340, "visits": [38.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2600, "q_vals": [-5.929, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2341, "visits": [39.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2600, "q_vals": [-5.777, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2342, "visits": [40.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2601, "q_vals": [-5.878, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2343, "visits": [41.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2601, "q_vals": [-5.734, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2344, "visits": [42.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2602, "q_vals": [-5.598, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2345, "visits": [43.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2604, "q_vals": [-5.695, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2346, "visits": [44.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2607, "q_vals": [-5.788, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2347, "visits": [45.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2608, "q_vals": [-5.878, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
 visits [46.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0]  episode_count: 2609 q_vals: [-5.963, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796]
{"total_number_of_episodes": 2611, "number_of_timesteps": 222768, "per_episode_reward": -362.75, "episode_reward_trend_value": 0.4734131000495091, "biggest_recent_change": 43.812740326204676},
{ "step": 2349, "visits": [47.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2611, "q_vals": [-6.044, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2350, "visits": [48.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2612, "q_vals": [-6.122, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2351, "visits": [49.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2614, "q_vals": [-6.197, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2352, "visits": [50.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2614, "q_vals": [-6.073, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2353, "visits": [51.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2614, "q_vals": [-6.146, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2354, "visits": [52.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2618, "q_vals": [-6.217, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2355, "visits": [53.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2618, "q_vals": [-6.284, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2356, "visits": [54.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2619, "q_vals": [-6.349, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{"total_number_of_episodes": 2621, "number_of_timesteps": 223446, "per_episode_reward": -362.53, "episode_reward_trend_value": 0.4758417464703516, "biggest_recent_change": 43.812740326204676},
{ "step": 2357, "visits": [55.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2621, "q_vals": [-6.412, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2358, "visits": [56.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2624, "q_vals": [-6.472, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2359, "visits": [57.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2624, "q_vals": [-6.359, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2360, "visits": [58.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2625, "q_vals": [-6.249, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2361, "visits": [59.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2627, "q_vals": [-6.309, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2362, "visits": [60.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2627, "q_vals": [-6.367, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2363, "visits": [61.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2629, "q_vals": [-6.263, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{"total_number_of_episodes": 2632, "number_of_timesteps": 224182, "per_episode_reward": -362.06, "episode_reward_trend_value": -0.005795485090634303, "biggest_recent_change": 0.46538948571594574},
{ "step": 2364, "visits": [62.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2632, "q_vals": [-6.32, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2365, "visits": [63.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2632, "q_vals": [-6.22, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2366, "visits": [64.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2633, "q_vals": [-6.276, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2367, "visits": [65.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2635, "q_vals": [-6.33, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2368, "visits": [66.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2635, "q_vals": [-6.382, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2369, "visits": [67.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2636, "q_vals": [-6.433, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2370, "visits": [68.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2637, "q_vals": [-6.339, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2371, "visits": [69.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2639, "q_vals": [-6.389, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2372, "visits": [70.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2640, "q_vals": [-6.437, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{"total_number_of_episodes": 2643, "number_of_timesteps": 225034, "per_episode_reward": -362.33, "episode_reward_trend_value": -0.005936474045243914, "biggest_recent_change": 0.46538948571594574},
{ "step": 2373, "visits": [71.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2643, "q_vals": [-6.347, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2374, "visits": [72.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2643, "q_vals": [-6.395, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2375, "visits": [73.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2644, "q_vals": [-6.441, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2376, "visits": [74.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0] , "episode_count": 2645, "q_vals": [-6.486, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -6.997, -9.796, -9.796] }
{ "step": 2377, "visits": [74.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2647, "q_vals": [-6.486, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2378, "visits": [75.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2648, "q_vals": [-6.4, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2379, "visits": [76.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2649, "q_vals": [-6.316, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2380, "visits": [77.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2651, "q_vals": [-6.361, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2381, "visits": [78.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2652, "q_vals": [-6.405, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2382, "visits": [79.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2652, "q_vals": [-6.448, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{"total_number_of_episodes": 2654, "number_of_timesteps": 225867, "per_episode_reward": -362.08, "episode_reward_trend_value": 0.0004402862047691592, "biggest_recent_change": 0.46538948571594574},
{ "step": 2383, "visits": [80.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2654, "q_vals": [-6.49, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2384, "visits": [81.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2657, "q_vals": [-6.41, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2385, "visits": [82.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2658, "q_vals": [-6.332, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2386, "visits": [83.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2659, "q_vals": [-6.373, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2387, "visits": [84.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2662, "q_vals": [-6.414, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2388, "visits": [85.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2662, "q_vals": [-6.454, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2389, "visits": [86.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2663, "q_vals": [-6.493, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{"total_number_of_episodes": 2664, "number_of_timesteps": 226511, "per_episode_reward": -361.56, "episode_reward_trend_value": 0.008907395583362485, "biggest_recent_change": 0.5225510121398997},
{ "step": 2390, "visits": [87.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2664, "q_vals": [-6.418, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2391, "visits": [88.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2664, "q_vals": [-6.456, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2392, "visits": [89.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2665, "q_vals": [-6.494, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2393, "visits": [90.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2668, "q_vals": [-6.531, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2394, "visits": [91.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2670, "q_vals": [-6.566, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2395, "visits": [92.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2671, "q_vals": [-6.495, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2396, "visits": [93.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2672, "q_vals": [-6.425, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2397, "visits": [94.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2673, "q_vals": [-6.461, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2398, "visits": [95.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2673, "q_vals": [-6.496, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{"total_number_of_episodes": 2674, "number_of_timesteps": 227289, "per_episode_reward": -361.48, "episode_reward_trend_value": 0.011919478814201688, "biggest_recent_change": 0.5225510121398997},
{ "step": 2399, "visits": [96.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2674, "q_vals": [-6.531, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2400, "visits": [97.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2674, "q_vals": [-6.564, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2401, "visits": [98.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2675, "q_vals": [-6.597, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2402, "visits": [99.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2678, "q_vals": [-6.531, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2403, "visits": [100.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2680, "q_vals": [-6.465, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2404, "visits": [101.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2683, "q_vals": [-6.498, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2405, "visits": [102.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2683, "q_vals": [-6.531, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2406, "visits": [103.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2683, "q_vals": [-6.562, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{"total_number_of_episodes": 2684, "number_of_timesteps": 228112, "per_episode_reward": -360.93, "episode_reward_trend_value": 0.02018685851519864, "biggest_recent_change": 0.5504177439218552},
{ "step": 2407, "visits": [104.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2684, "q_vals": [-6.499, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2408, "visits": [105.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2684, "q_vals": [-6.531, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2409, "visits": [106.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2685, "q_vals": [-6.561, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2410, "visits": [107.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2689, "q_vals": [-6.592, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2411, "visits": [108.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2690, "q_vals": [-6.621, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2412, "visits": [109.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2692, "q_vals": [-6.65, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
[-6.679, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796]
{ "step": 2414, "visits": [111.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2693, "q_vals": [-6.619, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{"total_number_of_episodes": 2694, "number_of_timesteps": 228841, "per_episode_reward": -360.93, "episode_reward_trend_value": 0.021920861154003053, "biggest_recent_change": 0.5504177439218552},
{ "step": 2415, "visits": [112.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2694, "q_vals": [-6.647, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2416, "visits": [113.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2697, "q_vals": [-6.588, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2417, "visits": [114.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2698, "q_vals": [-6.617, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2418, "visits": [115.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2700, "q_vals": [-6.644, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2419, "visits": [116.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2702, "q_vals": [-6.671, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2420, "visits": [117.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2703, "q_vals": [-6.614, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2421, "visits": [118.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2703, "q_vals": [-6.558, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{"total_number_of_episodes": 2705, "number_of_timesteps": 229573, "per_episode_reward": -360.85, "episode_reward_trend_value": 0.021066637734543925, "biggest_recent_change": 0.5504177439218552},
{ "step": 2422, "visits": [119.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2705, "q_vals": [-6.585, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2423, "visits": [120.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2707, "q_vals": [-6.531, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2424, "visits": [121.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2707, "q_vals": [-6.558, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2425, "visits": [122.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2708, "q_vals": [-6.584, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2426, "visits": [123.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2711, "q_vals": [-6.61, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2427, "visits": [124.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2711, "q_vals": [-6.557, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2428, "visits": [125.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2713, "q_vals": [-6.583, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{"total_number_of_episodes": 2715, "number_of_timesteps": 230275, "per_episode_reward": -360.76, "episode_reward_trend_value": 0.01961562393535448, "biggest_recent_change": 0.5504177439218552},
{ "step": 2429, "visits": [126.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2715, "q_vals": [-6.531, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2430, "visits": [127.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2715, "q_vals": [-6.556, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2431, "visits": [128.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2715, "q_vals": [-6.582, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2432, "visits": [129.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2716, "q_vals": [-6.607, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2433, "visits": [130.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2718, "q_vals": [-6.631, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2434, "visits": [131.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2720, "q_vals": [-6.58, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2435, "visits": [132.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2723, "q_vals": [-6.605, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2436, "visits": [133.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2724, "q_vals": [-6.629, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{"total_number_of_episodes": 2725, "number_of_timesteps": 231031, "per_episode_reward": -360.89, "episode_reward_trend_value": 0.013022859568020647, "biggest_recent_change": 0.5504177439218552},
{ "step": 2437, "visits": [134.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2725, "q_vals": [-6.652, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2438, "visits": [135.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2725, "q_vals": [-6.603, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2439, "visits": [136.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2726, "q_vals": [-6.627, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2440, "visits": [137.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2726, "q_vals": [-6.65, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2441, "visits": [138.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2728, "q_vals": [-6.673, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2442, "visits": [139.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2731, "q_vals": [-6.625, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2443, "visits": [140.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2732, "q_vals": [-6.577, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2444, "visits": [141.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2733, "q_vals": [-6.531, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2445, "visits": [142.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2734, "q_vals": [-6.554, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }

{ "step": 2446, "visits": [143.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2734, "q_vals": [-6.576, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{"total_number_of_episodes": 2735, "number_of_timesteps": 231808, "per_episode_reward": -361.11, "episode_reward_trend_value": 0.013558874427798174, "biggest_recent_change": 0.5504177439218552},
{ "step": 2447, "visits": [144.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2735, "q_vals": [-6.599, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2448, "visits": [145.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2736, "q_vals": [-6.553, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2449, "visits": [146.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2736, "q_vals": [-6.575, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2450, "visits": [147.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2738, "q_vals": [-6.597, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2451, "visits": [148.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2742, "q_vals": [-6.619, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2452, "visits": [149.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2742, "q_vals": [-6.64, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2453, "visits": [150.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2742, "q_vals": [-6.661, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2454, "visits": [151.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2742, "q_vals": [-6.682, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2455, "visits": [152.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2744, "q_vals": [-6.702, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2456, "visits": [153.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2744, "q_vals": [-6.659, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2457, "visits": [154.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2744, "q_vals": [-6.679, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2458, "visits": [155.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2744, "q_vals": [-6.699, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{"total_number_of_episodes": 2745, "number_of_timesteps": 232659, "per_episode_reward": -361.55, "episode_reward_trend_value": 0.005925167959072218, "biggest_recent_change": 0.5504177439218552},
{ "step": 2459, "visits": [156.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2745, "q_vals": [-6.719, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2460, "visits": [157.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0, 1.0] , "episode_count": 2746, "q_vals": [-6.739, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.347, -9.796, -9.796] }
{ "step": 2461, "visits": [157.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2747, "q_vals": [-6.739, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2462, "visits": [158.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2747, "q_vals": [-6.758, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2463, "visits": [159.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2749, "q_vals": [-6.715, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2464, "visits": [160.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2751, "q_vals": [-6.735, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2465, "visits": [161.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2752, "q_vals": [-6.754, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2466, "visits": [162.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2754, "q_vals": [-6.772, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2467, "visits": [163.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2754, "q_vals": [-6.791, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2468, "visits": [164.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2754, "q_vals": [-6.809, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2755, "number_of_timesteps": 233840, "per_episode_reward": -362.09, "episode_reward_trend_value": -0.005899579160646656, "biggest_recent_change": 0.5504177439218552},
{ "step": 2469, "visits": [165.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2755, "q_vals": [-6.827, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2470, "visits": [166.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2755, "q_vals": [-6.845, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2471, "visits": [167.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2755, "q_vals": [-6.863, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2472, "visits": [168.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2755, "q_vals": [-6.822, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2473, "visits": [169.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2758, "q_vals": [-6.782, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2474, "visits": [170.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2759, "q_vals": [-6.742, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2475, "visits": [171.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2759, "q_vals": [-6.76, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2476, "visits": [172.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2761, "q_vals": [-6.777, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2477, "visits": [173.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2763, "q_vals": [-6.795, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2478, "visits": [174.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2764, "q_vals": [-6.812, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
[-6.773, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796]
{ "step": 2480, "visits": [176.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2764, "q_vals": [-6.735, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2481, "visits": [177.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2764, "q_vals": [-6.752, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2767, "number_of_timesteps": 235145, "per_episode_reward": -362.41, "episode_reward_trend_value": -0.01042476074826987, "biggest_recent_change": 0.5504177439218552},
{ "step": 2482, "visits": [178.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2767, "q_vals": [-6.769, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2483, "visits": [179.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2768, "q_vals": [-6.786, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2484, "visits": [180.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2769, "q_vals": [-6.803, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2485, "visits": [181.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2772, "q_vals": [-6.765, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2486, "visits": [182.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2772, "q_vals": [-6.782, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2487, "visits": [183.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2772, "q_vals": [-6.798, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2488, "visits": [184.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2773, "q_vals": [-6.815, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2489, "visits": [185.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2774, "q_vals": [-6.831, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2490, "visits": [186.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2775, "q_vals": [-6.847, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2491, "visits": [187.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2775, "q_vals": [-6.862, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2492, "visits": [188.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2776, "q_vals": [-6.878, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2777, "number_of_timesteps": 236026, "per_episode_reward": -362.46, "episode_reward_trend_value": -0.017045698995439, "biggest_recent_change": 0.5416762286347989},
{ "step": 2493, "visits": [189.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2777, "q_vals": [-6.893, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2494, "visits": [190.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2780, "q_vals": [-6.857, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2495, "visits": [191.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2780, "q_vals": [-6.873, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2496, "visits": [192.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2782, "q_vals": [-6.888, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2497, "visits": [193.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2783, "q_vals": [-6.903, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2498, "visits": [194.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2784, "q_vals": [-6.918, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2499, "visits": [195.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2785, "q_vals": [-6.882, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2500, "visits": [196.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2786, "q_vals": [-6.897, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2501, "visits": [197.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2786, "q_vals": [-6.912, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2787, "number_of_timesteps": 236969, "per_episode_reward": -362.83, "episode_reward_trend_value": -0.021073349508673622, "biggest_recent_change": 0.5416762286347989},
{ "step": 2502, "visits": [198.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2787, "q_vals": [-6.877, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2503, "visits": [199.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2791, "q_vals": [-6.892, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2504, "visits": [200.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2792, "q_vals": [-6.906, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2505, "visits": [201.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2792, "q_vals": [-6.92, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2506, "visits": [202.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2792, "q_vals": [-6.886, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2507, "visits": [203.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2795, "q_vals": [-6.901, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2508, "visits": [204.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2795, "q_vals": [-6.915, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2509, "visits": [205.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2795, "q_vals": [-6.881, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2798, "number_of_timesteps": 237875, "per_episode_reward": -362.94, "episode_reward_trend_value": -0.023245217715299304, "biggest_recent_change": 0.5416762286347989},
{ "step": 2510, "visits": [206.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2798, "q_vals": [-6.848, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
 episode_count: 2798 q_vals: [-6.862, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796]
{ "step": 2512, "visits": [208.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2801, "q_vals": [-6.829, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2513, "visits": [209.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2803, "q_vals": [-6.843, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2514, "visits": [210.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2803, "q_vals": [-6.857, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2515, "visits": [211.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2804, "q_vals": [-6.871, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2516, "visits": [212.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2805, "q_vals": [-6.839, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2517, "visits": [213.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2805, "q_vals": [-6.807, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2518, "visits": [214.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2807, "q_vals": [-6.775, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2809, "number_of_timesteps": 238746, "per_episode_reward": -363.06, "episode_reward_trend_value": -0.02551369260973186, "biggest_recent_change": 0.5416762286347989},
{ "step": 2519, "visits": [215.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2809, "q_vals": [-6.789, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2520, "visits": [216.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2811, "q_vals": [-6.757, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2521, "visits": [217.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2811, "q_vals": [-6.771, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2522, "visits": [218.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2813, "q_vals": [-6.785, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2523, "visits": [219.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2814, "q_vals": [-6.799, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2524, "visits": [220.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2814, "q_vals": [-6.768, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2525, "visits": [221.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2816, "q_vals": [-6.737, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2526, "visits": [222.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2816, "q_vals": [-6.751, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2527, "visits": [223.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2818, "q_vals": [-6.765, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2819, "number_of_timesteps": 239539, "per_episode_reward": -363.2, "episode_reward_trend_value": -0.025706406499390117, "biggest_recent_change": 0.5416762286347989},
{ "step": 2528, "visits": [224.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2819, "q_vals": [-6.735, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2529, "visits": [225.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2821, "q_vals": [-6.705, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2530, "visits": [226.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2821, "q_vals": [-6.718, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2531, "visits": [227.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2824, "q_vals": [-6.732, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2532, "visits": [228.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2824, "q_vals": [-6.745, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2533, "visits": [229.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2825, "q_vals": [-6.716, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2534, "visits": [230.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2827, "q_vals": [-6.729, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2829, "number_of_timesteps": 240305, "per_episode_reward": -363.5, "episode_reward_trend_value": -0.026544268126739073, "biggest_recent_change": 0.5416762286347989},
{ "step": 2535, "visits": [231.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2829, "q_vals": [-6.743, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2536, "visits": [232.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2829, "q_vals": [-6.714, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2537, "visits": [233.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2830, "q_vals": [-6.685, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2538, "visits": [234.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2831, "q_vals": [-6.656, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2539, "visits": [235.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2833, "q_vals": [-6.67, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2540, "visits": [236.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2835, "q_vals": [-6.641, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2541, "visits": [237.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2836, "q_vals": [-6.655, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2542, "visits": [238.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2838, "q_vals": [-6.668, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2543, "visits": [239.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2838, "q_vals": [-6.681, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2839, "number_of_timesteps": 241069, "per_episode_reward": -363.67, "episode_reward_trend_value": -0.023494283571500317, "biggest_recent_change": 0.5416762286347989},
{ "step": 2544, "visits": [240.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2839, "q_vals": [-6.653, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2545, "visits": [241.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2840, "q_vals": [-6.666, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2546, "visits": [242.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2842, "q_vals": [-6.679, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2547, "visits": [243.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2843, "q_vals": [-6.652, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2548, "visits": [244.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2844, "q_vals": [-6.664, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2549, "visits": [245.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2844, "q_vals": [-6.637, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2550, "visits": [246.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2847, "q_vals": [-6.65, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2551, "visits": [247.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2848, "q_vals": [-6.663, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2552, "visits": [248.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2848, "q_vals": [-6.675, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2850, "number_of_timesteps": 241959, "per_episode_reward": -363.75, "episode_reward_trend_value": -0.01836063235091135, "biggest_recent_change": 0.36834907684487916},
{ "step": 2553, "visits": [249.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2850, "q_vals": [-6.649, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2554, "visits": [250.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2851, "q_vals": [-6.661, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2555, "visits": [251.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2852, "q_vals": [-6.635, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2556, "visits": [252.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2853, "q_vals": [-6.608, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2557, "visits": [253.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2853, "q_vals": [-6.621, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2558, "visits": [254.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2855, "q_vals": [-6.633, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2559, "visits": [255.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2855, "q_vals": [-6.646, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2560, "visits": [256.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2855, "q_vals": [-6.658, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2561, "visits": [257.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2856, "q_vals": [-6.632, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2562, "visits": [258.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2856, "q_vals": [-6.645, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2563, "visits": [259.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2859, "q_vals": [-6.619, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2861, "number_of_timesteps": 243026, "per_episode_reward": -363.78, "episode_reward_trend_value": -0.015134351291709435, "biggest_recent_change": 0.36834907684487916},
{ "step": 2564, "visits": [260.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2861, "q_vals": [-6.631, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2565, "visits": [261.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2861, "q_vals": [-6.643, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2566, "visits": [262.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2862, "q_vals": [-6.618, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2567, "visits": [263.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2864, "q_vals": [-6.63, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2568, "visits": [264.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2865, "q_vals": [-6.642, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2569, "visits": [265.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2865, "q_vals": [-6.654, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2570, "visits": [266.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2865, "q_vals": [-6.666, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2571, "visits": [267.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2865, "q_vals": [-6.677, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2572, "visits": [268.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2866, "q_vals": [-6.652, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2573, "visits": [269.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2866, "q_vals": [-6.664, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2574, "visits": [270.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2867, "q_vals": [-6.676, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2575, "visits": [271.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2867, "q_vals": [-6.651, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2576, "visits": [272.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2867, "q_vals": [-6.627, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2577, "visits": [273.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2868, "q_vals": [-6.638, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2871, "number_of_timesteps": 244114, "per_episode_reward": -363.4, "episode_reward_trend_value": -0.01040039375348935, "biggest_recent_change": 0.38058948011644134},
{ "step": 2578, "visits": [274.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2871, "q_vals": [-6.65, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2579, "visits": [275.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2872, "q_vals": [-6.661, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2580, "visits": [276.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2872, "q_vals": [-6.673, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2581, "visits": [277.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2873, "q_vals": [-6.684, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2582, "visits": [278.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2873, "q_vals": [-6.695, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2583, "visits": [279.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2873, "q_vals": [-6.671, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2584, "visits": [280.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2874, "q_vals": [-6.682, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2585, "visits": [281.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2874, "q_vals": [-6.693, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2586, "visits": [282.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2874, "q_vals": [-6.704, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2587, "visits": [283.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2874, "q_vals": [-6.681, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2588, "visits": [284.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2874, "q_vals": [-6.692, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2589, "visits": [285.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2875, "q_vals": [-6.702, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2590, "visits": [286.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2875, "q_vals": [-6.713, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2591, "visits": [287.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2878, "q_vals": [-6.724, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2592, "visits": [288.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2880, "q_vals": [-6.735, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2593, "visits": [289.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2880, "q_vals": [-6.745, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2881, "number_of_timesteps": 245471, "per_episode_reward": -363.75, "episode_reward_trend_value": -0.01028313221886808, "biggest_recent_change": 0.38058948011644134},
{ "step": 2594, "visits": [290.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2881, "q_vals": [-6.756, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2595, "visits": [291.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2881, "q_vals": [-6.733, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2596, "visits": [292.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2883, "q_vals": [-6.743, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2597, "visits": [293.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2883, "q_vals": [-6.754, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2598, "visits": [294.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2884, "q_vals": [-6.764, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2599, "visits": [295.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2886, "q_vals": [-6.774, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2600, "visits": [296.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2887, "q_vals": [-6.784, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2601, "visits": [297.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2888, "q_vals": [-6.794, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2602, "visits": [298.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2890, "q_vals": [-6.805, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2892, "number_of_timesteps": 246873, "per_episode_reward": -363.87, "episode_reward_trend_value": -0.010274104113951427, "biggest_recent_change": 0.38058948011644134},
{ "step": 2603, "visits": [299.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2892, "q_vals": [-6.782, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2604, "visits": [300.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2893, "q_vals": [-6.792, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2605, "visits": [301.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2893, "q_vals": [-6.769, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2606, "visits": [302.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2893, "q_vals": [-6.779, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2607, "visits": [303.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2893, "q_vals": [-6.789, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2608, "visits": [304.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2893, "q_vals": [-6.799, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2609, "visits": [305.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2898, "q_vals": [-6.809, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2610, "visits": [306.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2901, "q_vals": [-6.819, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2902, "number_of_timesteps": 247714, "per_episode_reward": -364.53, "episode_reward_trend_value": -0.01637380449729196, "biggest_recent_change": 0.6645414654346382},
{ "step": 2611, "visits": [307.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2902, "q_vals": [-6.828, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2612, "visits": [308.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2902, "q_vals": [-6.838, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2613, "visits": [309.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2903, "q_vals": [-6.848, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2614, "visits": [310.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2903, "q_vals": [-6.857, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2615, "visits": [311.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2906, "q_vals": [-6.835, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2616, "visits": [312.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2907, "q_vals": [-6.845, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2617, "visits": [313.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2908, "q_vals": [-6.854, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2618, "visits": [314.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2909, "q_vals": [-6.863, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2619, "visits": [315.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2911, "q_vals": [-6.842, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2913, "number_of_timesteps": 248511, "per_episode_reward": -364.45, "episode_reward_trend_value": -0.013887211852477321, "biggest_recent_change": 0.6645414654346382},
{ "step": 2620, "visits": [316.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2913, "q_vals": [-6.851, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2621, "visits": [317.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2914, "q_vals": [-6.86, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2622, "visits": [318.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2917, "q_vals": [-6.869, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2623, "visits": [319.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2917, "q_vals": [-6.879, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2624, "visits": [320.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2918, "q_vals": [-6.888, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2625, "visits": [321.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2918, "q_vals": [-6.866, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2626, "visits": [322.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2920, "q_vals": [-6.875, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2627, "visits": [323.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2920, "q_vals": [-6.854, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2924, "number_of_timesteps": 249254, "per_episode_reward": -364.73, "episode_reward_trend_value": -0.013630089253542288, "biggest_recent_change": 0.6645414654346382},
{ "step": 2628, "visits": [324.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2924, "q_vals": [-6.833, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2629, "visits": [325.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2926, "q_vals": [-6.812, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2630, "visits": [326.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2926, "q_vals": [-6.821, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2631, "visits": [327.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2926, "q_vals": [-6.8, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2632, "visits": [328.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2928, "q_vals": [-6.809, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2633, "visits": [329.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2928, "q_vals": [-6.818, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2634, "visits": [330.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2930, "q_vals": [-6.827, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2635, "visits": [331.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2931, "q_vals": [-6.807, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2935, "number_of_timesteps": 250076, "per_episode_reward": -365.06, "episode_reward_trend_value": -0.015449680696449124, "biggest_recent_change": 0.6645414654346382},
{ "step": 2636, "visits": [332.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2935, "q_vals": [-6.816, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2637, "visits": [333.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2935, "q_vals": [-6.825, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2638, "visits": [334.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2936, "q_vals": [-6.834, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2639, "visits": [335.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2938, "q_vals": [-6.813, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2640, "visits": [336.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2939, "q_vals": [-6.793, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2641, "visits": [337.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2939, "q_vals": [-6.802, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2642, "visits": [338.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2940, "q_vals": [-6.782, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2643, "visits": [339.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2942, "q_vals": [-6.762, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2945, "number_of_timesteps": 250792, "per_episode_reward": -364.94, "episode_reward_trend_value": -0.01330350399311884, "biggest_recent_change": 0.6645414654346382},
{ "step": 2644, "visits": [340.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2945, "q_vals": [-6.771, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2645, "visits": [341.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2945, "q_vals": [-6.78, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2646, "visits": [342.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2946, "q_vals": [-6.788, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2647, "visits": [343.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2948, "q_vals": [-6.797, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2648, "visits": [344.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2948, "q_vals": [-6.777, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2649, "visits": [345.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2950, "q_vals": [-6.786, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2650, "visits": [346.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2951, "q_vals": [-6.795, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2651, "visits": [347.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2953, "q_vals": [-6.775, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2652, "visits": [348.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2954, "q_vals": [-6.784, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2956, "number_of_timesteps": 251597, "per_episode_reward": -365.19, "episode_reward_trend_value": -0.015679596108704015, "biggest_recent_change": 0.6645414654346382},
{ "step": 2653, "visits": [349.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2956, "q_vals": [-6.793, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2654, "visits": [350.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2957, "q_vals": [-6.801, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2655, "visits": [351.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2958, "q_vals": [-6.81, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2656, "visits": [352.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2959, "q_vals": [-6.79, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2657, "visits": [353.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2961, "q_vals": [-6.771, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2658, "visits": [354.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2961, "q_vals": [-6.78, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2659, "visits": [355.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2962, "q_vals": [-6.788, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2660, "visits": [356.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2963, "q_vals": [-6.769, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2661, "visits": [357.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2964, "q_vals": [-6.75, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2966, "number_of_timesteps": 252357, "per_episode_reward": -364.94, "episode_reward_trend_value": -0.01713863690322594, "biggest_recent_change": 0.6645414654346382},
{ "step": 2662, "visits": [358.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2966, "q_vals": [-6.759, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2663, "visits": [359.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2966, "q_vals": [-6.767, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2664, "visits": [360.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2968, "q_vals": [-6.776, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2665, "visits": [361.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2969, "q_vals": [-6.757, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2666, "visits": [362.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2970, "q_vals": [-6.765, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2667, "visits": [363.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2971, "q_vals": [-6.773, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2668, "visits": [364.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2972, "q_vals": [-6.755, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2669, "visits": [365.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2975, "q_vals": [-6.763, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2670, "visits": [366.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2975, "q_vals": [-6.745, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2671, "visits": [367.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2975, "q_vals": [-6.753, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2976, "number_of_timesteps": 253219, "per_episode_reward": -365.14, "episode_reward_trend_value": -0.015377519063105183, "biggest_recent_change": 0.6645414654346382},
{ "step": 2672, "visits": [368.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2976, "q_vals": [-6.761, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2673, "visits": [369.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2977, "q_vals": [-6.743, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2674, "visits": [370.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2978, "q_vals": [-6.751, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2675, "visits": [371.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2981, "q_vals": [-6.759, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2676, "visits": [372.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2982, "q_vals": [-6.768, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2677, "visits": [373.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2982, "q_vals": [-6.776, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2678, "visits": [374.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2983, "q_vals": [-6.784, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2679, "visits": [375.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2984, "q_vals": [-6.766, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2680, "visits": [376.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2984, "q_vals": [-6.748, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2681, "visits": [377.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2985, "q_vals": [-6.756, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2682, "visits": [378.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2985, "q_vals": [-6.764, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2986, "number_of_timesteps": 254127, "per_episode_reward": -364.94, "episode_reward_trend_value": -0.011930730553499164, "biggest_recent_change": 0.6645414654346382},
{ "step": 2683, "visits": [379.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2986, "q_vals": [-6.772, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2684, "visits": [380.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2990, "q_vals": [-6.78, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2685, "visits": [381.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2990, "q_vals": [-6.762, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2686, "visits": [382.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2991, "q_vals": [-6.77, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2687, "visits": [383.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2991, "q_vals": [-6.778, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2688, "visits": [384.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2992, "q_vals": [-6.786, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2689, "visits": [385.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2993, "q_vals": [-6.768, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2690, "visits": [386.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2994, "q_vals": [-6.776, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2691, "visits": [387.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2994, "q_vals": [-6.784, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 2996, "number_of_timesteps": 255143, "per_episode_reward": -365.35, "episode_reward_trend_value": -0.009117242975977685, "biggest_recent_change": 0.41132758345770526},
{ "step": 2692, "visits": [388.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2996, "q_vals": [-6.766, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2693, "visits": [389.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2996, "q_vals": [-6.774, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2694, "visits": [390.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2997, "q_vals": [-6.782, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2695, "visits": [391.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 2999, "q_vals": [-6.789, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2696, "visits": [392.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3000, "q_vals": [-6.772, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2697, "visits": [393.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3002, "q_vals": [-6.78, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2698, "visits": [394.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3002, "q_vals": [-6.788, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2699, "visits": [395.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3002, "q_vals": [-6.77, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2700, "visits": [396.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3004, "q_vals": [-6.753, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2701, "visits": [397.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3004, "q_vals": [-6.736, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2702, "visits": [398.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3005, "q_vals": [-6.744, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 3006, "number_of_timesteps": 256168, "per_episode_reward": -366.42, "episode_reward_trend_value": -0.021904388800055585, "biggest_recent_change": 1.0723533435470358},
{ "step": 2703, "visits": [399.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3006, "q_vals": [-6.752, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2704, "visits": [400.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3007, "q_vals": [-6.759, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2705, "visits": [401.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3008, "q_vals": [-6.767, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2706, "visits": [402.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3008, "q_vals": [-6.774, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2707, "visits": [403.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3010, "q_vals": [-6.757, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2708, "visits": [404.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3012, "q_vals": [-6.765, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2709, "visits": [405.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3013, "q_vals": [-6.748, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2710, "visits": [406.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3013, "q_vals": [-6.732, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2711, "visits": [407.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3014, "q_vals": [-6.739, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2712, "visits": [408.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3015, "q_vals": [-6.747, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 3016, "number_of_timesteps": 257123, "per_episode_reward": -365.73, "episode_reward_trend_value": -0.011118251104117387, "biggest_recent_change": 1.0723533435470358},
{ "step": 2713, "visits": [409.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3016, "q_vals": [-6.73, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2714, "visits": [410.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3017, "q_vals": [-6.738, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2715, "visits": [411.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3018, "q_vals": [-6.745, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2716, "visits": [412.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3020, "q_vals": [-6.753, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2717, "visits": [413.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3021, "q_vals": [-6.76, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2718, "visits": [414.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3023, "q_vals": [-6.744, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2719, "visits": [415.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3024, "q_vals": [-6.751, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 3026, "number_of_timesteps": 258024, "per_episode_reward": -365.88, "episode_reward_trend_value": -0.009095189899709213, "biggest_recent_change": 1.0723533435470358},
{ "step": 2720, "visits": [416.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3026, "q_vals": [-6.735, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2721, "visits": [417.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3027, "q_vals": [-6.719, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2722, "visits": [418.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3028, "q_vals": [-6.726, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2723, "visits": [419.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3028, "q_vals": [-6.733, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2724, "visits": [420.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3030, "q_vals": [-6.741, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2725, "visits": [421.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3030, "q_vals": [-6.748, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2726, "visits": [422.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3030, "q_vals": [-6.755, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2727, "visits": [423.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3032, "q_vals": [-6.762, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2728, "visits": [424.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3035, "q_vals": [-6.769, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 3037, "number_of_timesteps": 258903, "per_episode_reward": -365.64, "episode_reward_trend_value": -0.007738816963616399, "biggest_recent_change": 1.0723533435470358},
{ "step": 2729, "visits": [425.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3037, "q_vals": [-6.776, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2730, "visits": [426.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3038, "q_vals": [-6.784, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2731, "visits": [427.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3038, "q_vals": [-6.791, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2732, "visits": [428.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3038, "q_vals": [-6.798, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2733, "visits": [429.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3040, "q_vals": [-6.805, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2734, "visits": [430.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3040, "q_vals": [-6.812, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2735, "visits": [431.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3040, "q_vals": [-6.819, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2736, "visits": [432.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3044, "q_vals": [-6.825, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 3047, "number_of_timesteps": 259683, "per_episode_reward": -365.98, "episode_reward_trend_value": -0.008765921029364816, "biggest_recent_change": 1.0723533435470358},
{ "step": 2737, "visits": [433.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3047, "q_vals": [-6.832, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2738, "visits": [434.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3047, "q_vals": [-6.839, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2739, "visits": [435.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3048, "q_vals": [-6.823, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2740, "visits": [436.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3048, "q_vals": [-6.808, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
[-6.815, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796]
{ "step": 2742, "visits": [438.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3050, "q_vals": [-6.821, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2743, "visits": [439.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3053, "q_vals": [-6.828, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2744, "visits": [440.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3054, "q_vals": [-6.835, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2745, "visits": [441.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3054, "q_vals": [-6.819, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2746, "visits": [442.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3055, "q_vals": [-6.804, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2747, "visits": [443.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3055, "q_vals": [-6.811, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 3057, "number_of_timesteps": 260510, "per_episode_reward": -365.99, "episode_reward_trend_value": -0.011715276353056778, "biggest_recent_change": 1.0723533435470358},
{ "step": 2748, "visits": [444.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3057, "q_vals": [-6.817, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2749, "visits": [445.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3058, "q_vals": [-6.824, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2750, "visits": [446.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3058, "q_vals": [-6.831, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2751, "visits": [447.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3061, "q_vals": [-6.837, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2752, "visits": [448.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3061, "q_vals": [-6.844, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2753, "visits": [449.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3061, "q_vals": [-6.851, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2754, "visits": [450.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3063, "q_vals": [-6.857, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2755, "visits": [451.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3064, "q_vals": [-6.864, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2756, "visits": [452.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3064, "q_vals": [-6.87, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2757, "visits": [453.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3065, "q_vals": [-6.877, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{"total_number_of_episodes": 3067, "number_of_timesteps": 261464, "per_episode_reward": -365.79, "episode_reward_trend_value": -0.007295267041745825, "biggest_recent_change": 1.0723533435470358},
{ "step": 2758, "visits": [454.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3067, "q_vals": [-6.861, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2759, "visits": [455.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3067, "q_vals": [-6.868, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2760, "visits": [456.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3067, "q_vals": [-6.874, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2761, "visits": [457.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3070, "q_vals": [-6.881, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2762, "visits": [458.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3071, "q_vals": [-6.887, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2763, "visits": [459.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3072, "q_vals": [-6.893, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2764, "visits": [460.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3073, "q_vals": [-6.9, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2765, "visits": [461.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3073, "q_vals": [-6.906, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2766, "visits": [462.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0, 1.0] , "episode_count": 3073, "q_vals": [-6.912, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.619, -9.796, -9.796] }
{ "step": 2767, "visits": [462.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3074, "q_vals": [-6.912, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2768, "visits": [463.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3076, "q_vals": [-6.918, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2769, "visits": [464.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3076, "q_vals": [-6.904, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2770, "visits": [465.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3076, "q_vals": [-6.889, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3078, "number_of_timesteps": 262582, "per_episode_reward": -365.5, "episode_reward_trend_value": -0.006241718083550849, "biggest_recent_change": 1.0723533435470358},
{ "step": 2771, "visits": [466.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3078, "q_vals": [-6.895, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2772, "visits": [467.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3078, "q_vals": [-6.88, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2773, "visits": [468.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3079, "q_vals": [-6.886, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2774, "visits": [469.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3081, "q_vals": [-6.872, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
 2775 0 visits [470.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0]  episode_count: 3082 q_vals: [-6.878, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796]
{ "step": 2776, "visits": [471.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3082, "q_vals": [-6.884, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2777, "visits": [472.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3083, "q_vals": [-6.89, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2778, "visits": [473.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3084, "q_vals": [-6.896, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2779, "visits": [474.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3084, "q_vals": [-6.903, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2780, "visits": [475.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3084, "q_vals": [-6.909, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2781, "visits": [476.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3084, "q_vals": [-6.915, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2782, "visits": [477.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3086, "q_vals": [-6.921, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2783, "visits": [478.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3087, "q_vals": [-6.927, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3088, "number_of_timesteps": 263678, "per_episode_reward": -365.84, "episode_reward_trend_value": -0.005435971412608372, "biggest_recent_change": 1.0723533435470358},
{ "step": 2784, "visits": [479.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3088, "q_vals": [-6.933, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2785, "visits": [480.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3089, "q_vals": [-6.939, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2786, "visits": [481.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3090, "q_vals": [-6.945, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2787, "visits": [482.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3090, "q_vals": [-6.951, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2788, "visits": [483.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3091, "q_vals": [-6.957, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2789, "visits": [484.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3093, "q_vals": [-6.942, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2790, "visits": [485.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3093, "q_vals": [-6.948, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2791, "visits": [486.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3094, "q_vals": [-6.934, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2792, "visits": [487.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3094, "q_vals": [-6.919, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2793, "visits": [488.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3095, "q_vals": [-6.925, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2794, "visits": [489.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3095, "q_vals": [-6.931, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2795, "visits": [490.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3096, "q_vals": [-6.937, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2796, "visits": [491.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3096, "q_vals": [-6.943, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2797, "visits": [492.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3097, "q_vals": [-6.949, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3098, "number_of_timesteps": 265003, "per_episode_reward": -365.7, "episode_reward_trend_value": 0.00800907545530486, "biggest_recent_change": 0.6968007632082731},
{ "step": 2798, "visits": [493.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3098, "q_vals": [-6.955, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2799, "visits": [494.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3099, "q_vals": [-6.96, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2800, "visits": [495.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3099, "q_vals": [-6.966, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2801, "visits": [496.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3099, "q_vals": [-6.952, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2802, "visits": [497.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3099, "q_vals": [-6.958, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2803, "visits": [498.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3100, "q_vals": [-6.963, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2804, "visits": [499.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3101, "q_vals": [-6.969, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2805, "visits": [500.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3102, "q_vals": [-6.975, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2806, "visits": [501.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3102, "q_vals": [-6.98, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2807, "visits": [502.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3103, "q_vals": [-6.986, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
[503.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0]  episode_count: 3104 q_vals: [-6.992, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796]
{ "step": 2809, "visits": [504.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3105, "q_vals": [-6.978, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2810, "visits": [505.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3106, "q_vals": [-6.983, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3108, "number_of_timesteps": 266438, "per_episode_reward": -365.89, "episode_reward_trend_value": -0.0018554263042410133, "biggest_recent_change": 0.33881038307288236},
{ "step": 2811, "visits": [506.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3108, "q_vals": [-6.969, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2812, "visits": [507.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3108, "q_vals": [-6.956, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2813, "visits": [508.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3110, "q_vals": [-6.961, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2814, "visits": [509.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3112, "q_vals": [-6.967, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2815, "visits": [510.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3112, "q_vals": [-6.953, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2816, "visits": [511.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3112, "q_vals": [-6.959, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2817, "visits": [512.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3114, "q_vals": [-6.964, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2818, "visits": [513.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3116, "q_vals": [-6.97, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2819, "visits": [514.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3116, "q_vals": [-6.956, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2820, "visits": [515.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3116, "q_vals": [-6.962, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3118, "number_of_timesteps": 267502, "per_episode_reward": -365.55, "episode_reward_trend_value": 0.0036402428166588327, "biggest_recent_change": 0.34649866972335985},
{ "step": 2821, "visits": [516.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3118, "q_vals": [-6.948, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2822, "visits": [517.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3119, "q_vals": [-6.954, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2823, "visits": [518.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3121, "q_vals": [-6.94, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2824, "visits": [519.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3121, "q_vals": [-6.946, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2825, "visits": [520.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3121, "q_vals": [-6.951, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2826, "visits": [521.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3123, "q_vals": [-6.938, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2827, "visits": [522.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3123, "q_vals": [-6.943, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2828, "visits": [523.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3125, "q_vals": [-6.949, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2829, "visits": [524.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3126, "q_vals": [-6.954, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2830, "visits": [525.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3126, "q_vals": [-6.96, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3129, "number_of_timesteps": 268579, "per_episode_reward": -365.4, "episode_reward_trend_value": 0.00260766713117467, "biggest_recent_change": 0.34649866972335985},
{ "step": 2831, "visits": [526.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3129, "q_vals": [-6.965, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2832, "visits": [527.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3129, "q_vals": [-6.971, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2833, "visits": [528.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3131, "q_vals": [-6.976, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2834, "visits": [529.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3132, "q_vals": [-6.981, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2835, "visits": [530.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3132, "q_vals": [-6.987, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2836, "visits": [531.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3132, "q_vals": [-6.973, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2837, "visits": [532.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3132, "q_vals": [-6.979, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2838, "visits": [533.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3132, "q_vals": [-6.966, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2839, "visits": [534.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3133, "q_vals": [-6.971, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2840, "visits": [535.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3133, "q_vals": [-6.976, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
[536.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0]  episode_count: 3133 q_vals: [-6.963, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796]
{ "step": 2842, "visits": [537.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3134, "q_vals": [-6.95, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2843, "visits": [538.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3136, "q_vals": [-6.937, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2844, "visits": [539.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3138, "q_vals": [-6.943, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3140, "number_of_timesteps": 269916, "per_episode_reward": -365.62, "episode_reward_trend_value": 0.003978310446890671, "biggest_recent_change": 0.34649866972335985},
{ "step": 2845, "visits": [540.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3140, "q_vals": [-6.948, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2846, "visits": [541.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3141, "q_vals": [-6.953, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2847, "visits": [542.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3142, "q_vals": [-6.958, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2848, "visits": [543.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3142, "q_vals": [-6.964, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2849, "visits": [544.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3142, "q_vals": [-6.951, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2850, "visits": [545.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3142, "q_vals": [-6.956, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2851, "visits": [546.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3142, "q_vals": [-6.961, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2852, "visits": [547.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3142, "q_vals": [-6.966, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2853, "visits": [548.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3142, "q_vals": [-6.972, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2854, "visits": [549.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3144, "q_vals": [-6.959, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2855, "visits": [550.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3144, "q_vals": [-6.964, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2856, "visits": [551.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3145, "q_vals": [-6.969, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2857, "visits": [552.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3147, "q_vals": [-6.957, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2858, "visits": [553.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3148, "q_vals": [-6.962, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3150, "number_of_timesteps": 271154, "per_episode_reward": -365.64, "episode_reward_trend_value": 0.00389399862829565, "biggest_recent_change": 0.34649866972335985},
{ "step": 2859, "visits": [554.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3150, "q_vals": [-6.967, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2860, "visits": [555.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3150, "q_vals": [-6.972, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2861, "visits": [556.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3151, "q_vals": [-6.959, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2862, "visits": [557.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3151, "q_vals": [-6.947, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2863, "visits": [558.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3152, "q_vals": [-6.952, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2864, "visits": [559.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3153, "q_vals": [-6.957, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2865, "visits": [560.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3154, "q_vals": [-6.962, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2866, "visits": [561.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3155, "q_vals": [-6.967, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2867, "visits": [562.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3155, "q_vals": [-6.955, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2868, "visits": [563.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3156, "q_vals": [-6.96, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2869, "visits": [564.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3156, "q_vals": [-6.965, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2870, "visits": [565.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3159, "q_vals": [-6.97, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2871, "visits": [566.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3159, "q_vals": [-6.958, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3160, "number_of_timesteps": 272383, "per_episode_reward": -365.77, "episode_reward_trend_value": 0.00022362840773363737, "biggest_recent_change": 0.34649866972335985},
{ "step": 2872, "visits": [567.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3160, "q_vals": [-6.963, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2873, "visits": [568.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3161, "q_vals": [-6.968, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2874, "visits": [569.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3161, "q_vals": [-6.955, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2875, "visits": [570.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3161, "q_vals": [-6.943, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2876, "visits": [571.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3162, "q_vals": [-6.948, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2877, "visits": [572.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3164, "q_vals": [-6.936, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2878, "visits": [573.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3166, "q_vals": [-6.941, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2879, "visits": [574.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3166, "q_vals": [-6.946, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2880, "visits": [575.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3167, "q_vals": [-6.951, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2881, "visits": [576.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3168, "q_vals": [-6.956, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2882, "visits": [577.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3169, "q_vals": [-6.944, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2883, "visits": [578.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3169, "q_vals": [-6.949, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3170, "number_of_timesteps": 273486, "per_episode_reward": -366.01, "episode_reward_trend_value": -0.005675303120494214, "biggest_recent_change": 0.34649866972335985},
{ "step": 2884, "visits": [579.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3170, "q_vals": [-6.954, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2885, "visits": [580.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3170, "q_vals": [-6.958, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2886, "visits": [581.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3170, "q_vals": [-6.947, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2887, "visits": [582.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3172, "q_vals": [-6.935, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2888, "visits": [583.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3173, "q_vals": [-6.939, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2889, "visits": [584.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3174, "q_vals": [-6.928, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2890, "visits": [585.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3174, "q_vals": [-6.932, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2891, "visits": [586.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3175, "q_vals": [-6.937, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2892, "visits": [587.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3175, "q_vals": [-6.926, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2893, "visits": [588.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3175, "q_vals": [-6.93, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2894, "visits": [589.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3175, "q_vals": [-6.935, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2895, "visits": [590.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3175, "q_vals": [-6.94, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2896, "visits": [591.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3176, "q_vals": [-6.928, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2897, "visits": [592.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3176, "q_vals": [-6.933, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2898, "visits": [593.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3178, "q_vals": [-6.938, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2899, "visits": [594.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3179, "q_vals": [-6.926, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3181, "number_of_timesteps": 274929, "per_episode_reward": -366.16, "episode_reward_trend_value": -0.003585867970329875, "biggest_recent_change": 0.34649866972335985},
{ "step": 2900, "visits": [595.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3181, "q_vals": [-6.931, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2901, "visits": [596.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3182, "q_vals": [-6.936, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2902, "visits": [597.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3183, "q_vals": [-6.924, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2903, "visits": [598.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3184, "q_vals": [-6.929, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2904, "visits": [599.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3185, "q_vals": [-6.934, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2905, "visits": [600.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3185, "q_vals": [-6.922, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2906, "visits": [601.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3186, "q_vals": [-6.911, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2907, "visits": [602.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3186, "q_vals": [-6.899, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2908, "visits": [603.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3186, "q_vals": [-6.904, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2909, "visits": [604.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3186, "q_vals": [-6.909, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2910, "visits": [605.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3187, "q_vals": [-6.914, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2911, "visits": [606.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3189, "q_vals": [-6.902, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2912, "visits": [607.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3189, "q_vals": [-6.907, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3191, "number_of_timesteps": 276199, "per_episode_reward": -366.29, "episode_reward_trend_value": -0.00657690516551952, "biggest_recent_change": 0.34649866972335985},
{ "step": 2913, "visits": [608.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3191, "q_vals": [-6.912, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2914, "visits": [609.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3191, "q_vals": [-6.901, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2915, "visits": [610.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3195, "q_vals": [-6.905, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2916, "visits": [611.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3195, "q_vals": [-6.91, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2917, "visits": [612.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3195, "q_vals": [-6.915, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2918, "visits": [613.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3195, "q_vals": [-6.919, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2919, "visits": [614.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3196, "q_vals": [-6.908, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2920, "visits": [615.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3196, "q_vals": [-6.913, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2921, "visits": [616.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3196, "q_vals": [-6.918, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2922, "visits": [617.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3198, "q_vals": [-6.906, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2923, "visits": [618.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3199, "q_vals": [-6.895, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3201, "number_of_timesteps": 277400, "per_episode_reward": -365.98, "episode_reward_trend_value": -0.0010085892241249895, "biggest_recent_change": 0.34649866972335985},
{ "step": 2924, "visits": [619.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3201, "q_vals": [-6.9, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2925, "visits": [620.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3202, "q_vals": [-6.889, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2926, "visits": [621.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3203, "q_vals": [-6.893, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2927, "visits": [622.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3206, "q_vals": [-6.898, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2928, "visits": [623.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3206, "q_vals": [-6.887, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2929, "visits": [624.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3207, "q_vals": [-6.876, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2930, "visits": [625.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3207, "q_vals": [-6.881, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2931, "visits": [626.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3207, "q_vals": [-6.87, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2932, "visits": [627.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3207, "q_vals": [-6.874, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2933, "visits": [628.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3209, "q_vals": [-6.879, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2934, "visits": [629.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3210, "q_vals": [-6.868, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3213, "number_of_timesteps": 278592, "per_episode_reward": -365.76, "episode_reward_trend_value": -0.0023858596920989486, "biggest_recent_change": 0.3101440395746522},
{ "step": 2935, "visits": [630.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3213, "q_vals": [-6.873, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2936, "visits": [631.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3214, "q_vals": [-6.877, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2937, "visits": [632.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3216, "q_vals": [-6.866, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2938, "visits": [633.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3217, "q_vals": [-6.871, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2939, "visits": [634.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3218, "q_vals": [-6.876, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2940, "visits": [635.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3218, "q_vals": [-6.88, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2941, "visits": [636.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3219, "q_vals": [-6.885, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
[637.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0]  episode_count: 3219 q_vals: [-6.874, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796]
{ "step": 2943, "visits": [638.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3220, "q_vals": [-6.863, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2944, "visits": [639.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3222, "q_vals": [-6.868, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3224, "number_of_timesteps": 279539, "per_episode_reward": -365.82, "episode_reward_trend_value": -0.004573303328474291, "biggest_recent_change": 0.3101440395746522},
{ "step": 2945, "visits": [640.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3224, "q_vals": [-6.857, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2946, "visits": [641.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3226, "q_vals": [-6.862, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2947, "visits": [642.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3227, "q_vals": [-6.851, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2948, "visits": [643.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3227, "q_vals": [-6.856, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2949, "visits": [644.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3227, "q_vals": [-6.845, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2950, "visits": [645.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3228, "q_vals": [-6.834, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2951, "visits": [646.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3229, "q_vals": [-6.839, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2952, "visits": [647.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3231, "q_vals": [-6.844, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2953, "visits": [648.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3233, "q_vals": [-6.833, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2954, "visits": [649.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3233, "q_vals": [-6.838, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3236, "number_of_timesteps": 280583, "per_episode_reward": -366.24, "episode_reward_trend_value": -0.006917927138289315, "biggest_recent_change": 0.4242849530820081},
{ "step": 2955, "visits": [650.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3236, "q_vals": [-6.842, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2956, "visits": [651.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3236, "q_vals": [-6.847, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2957, "visits": [652.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3236, "q_vals": [-6.851, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2958, "visits": [653.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3237, "q_vals": [-6.856, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2959, "visits": [654.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3237, "q_vals": [-6.845, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2960, "visits": [655.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3240, "q_vals": [-6.85, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2961, "visits": [656.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3241, "q_vals": [-6.839, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2962, "visits": [657.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3242, "q_vals": [-6.844, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2963, "visits": [658.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3242, "q_vals": [-6.833, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2964, "visits": [659.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3243, "q_vals": [-6.838, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2965, "visits": [660.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3245, "q_vals": [-6.842, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2966, "visits": [661.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3245, "q_vals": [-6.847, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3246, "number_of_timesteps": 281489, "per_episode_reward": -366.03, "episode_reward_trend_value": -0.004359637270934197, "biggest_recent_change": 0.4242849530820081},
{ "step": 2967, "visits": [662.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3246, "q_vals": [-6.836, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2968, "visits": [663.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3246, "q_vals": [-6.841, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2969, "visits": [664.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3247, "q_vals": [-6.831, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2970, "visits": [665.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3248, "q_vals": [-6.835, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2971, "visits": [666.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3249, "q_vals": [-6.839, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2972, "visits": [667.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3252, "q_vals": [-6.844, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2973, "visits": [668.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3253, "q_vals": [-6.834, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2974, "visits": [669.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3253, "q_vals": [-6.838, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
[-6.843, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796]
{ "step": 2976, "visits": [671.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3253, "q_vals": [-6.832, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2977, "visits": [672.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3254, "q_vals": [-6.837, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2978, "visits": [673.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3254, "q_vals": [-6.841, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2979, "visits": [674.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3255, "q_vals": [-6.846, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3256, "number_of_timesteps": 282552, "per_episode_reward": -366.01, "episode_reward_trend_value": -0.0026571336859597576, "biggest_recent_change": 0.4242849530820081},
{ "step": 2980, "visits": [675.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3256, "q_vals": [-6.85, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2981, "visits": [676.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3256, "q_vals": [-6.84, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2982, "visits": [677.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3258, "q_vals": [-6.844, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2983, "visits": [678.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3259, "q_vals": [-6.848, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2984, "visits": [679.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3259, "q_vals": [-6.853, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2985, "visits": [680.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3260, "q_vals": [-6.857, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2986, "visits": [681.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3260, "q_vals": [-6.861, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2987, "visits": [682.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3260, "q_vals": [-6.866, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2988, "visits": [683.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3261, "q_vals": [-6.87, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2989, "visits": [684.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3261, "q_vals": [-6.874, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2990, "visits": [685.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3261, "q_vals": [-6.879, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2991, "visits": [686.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3263, "q_vals": [-6.883, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2992, "visits": [687.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3263, "q_vals": [-6.887, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2993, "visits": [688.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3264, "q_vals": [-6.891, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2994, "visits": [689.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3265, "q_vals": [-6.896, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3267, "number_of_timesteps": 284064, "per_episode_reward": -366.08, "episode_reward_trend_value": -0.0007347822868786757, "biggest_recent_change": 0.4242849530820081},
{ "step": 2995, "visits": [690.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3267, "q_vals": [-6.9, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2996, "visits": [691.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3268, "q_vals": [-6.904, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2997, "visits": [692.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3268, "q_vals": [-6.894, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2998, "visits": [693.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3268, "q_vals": [-6.898, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 2999, "visits": [694.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3268, "q_vals": [-6.902, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3000, "visits": [695.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3271, "q_vals": [-6.906, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3001, "visits": [696.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3272, "q_vals": [-6.911, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3002, "visits": [697.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3273, "q_vals": [-6.915, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3003, "visits": [698.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3274, "q_vals": [-6.919, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3004, "visits": [699.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3274, "q_vals": [-6.923, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3005, "visits": [700.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3275, "q_vals": [-6.927, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3006, "visits": [701.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3275, "q_vals": [-6.917, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3007, "visits": [702.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3275, "q_vals": [-6.921, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3279, "number_of_timesteps": 285593, "per_episode_reward": -365.67, "episode_reward_trend_value": 0.0055082970317079745, "biggest_recent_change": 0.4242849530820081},
{ "step": 3008, "visits": [703.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3279, "q_vals": [-6.911, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3009, "visits": [704.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3279, "q_vals": [-6.916, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3010, "visits": [705.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3280, "q_vals": [-6.92, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3011, "visits": [706.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3280, "q_vals": [-6.91, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3012, "visits": [707.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3282, "q_vals": [-6.914, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3013, "visits": [708.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3282, "q_vals": [-6.918, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3014, "visits": [709.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3283, "q_vals": [-6.922, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3015, "visits": [710.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3284, "q_vals": [-6.912, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3016, "visits": [711.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3285, "q_vals": [-6.916, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3017, "visits": [712.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3285, "q_vals": [-6.92, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3018, "visits": [713.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3285, "q_vals": [-6.911, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3019, "visits": [714.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3286, "q_vals": [-6.915, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3020, "visits": [715.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3286, "q_vals": [-6.919, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3021, "visits": [716.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3288, "q_vals": [-6.923, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3022, "visits": [717.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3288, "q_vals": [-6.927, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3289, "number_of_timesteps": 286640, "per_episode_reward": -365.64, "episode_reward_trend_value": 0.007309176269447132, "biggest_recent_change": 0.4242849530820081},
{ "step": 3023, "visits": [718.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3289, "q_vals": [-6.931, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3024, "visits": [719.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3292, "q_vals": [-6.921, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3025, "visits": [720.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3292, "q_vals": [-6.925, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3026, "visits": [721.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3292, "q_vals": [-6.929, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3027, "visits": [722.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3294, "q_vals": [-6.92, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3028, "visits": [723.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3294, "q_vals": [-6.91, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3029, "visits": [724.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3295, "q_vals": [-6.914, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3030, "visits": [725.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3296, "q_vals": [-6.918, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3031, "visits": [726.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3297, "q_vals": [-6.91, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3300, "number_of_timesteps": 287913, "per_episode_reward": -365.75, "episode_reward_trend_value": 0.0025940424256715587, "biggest_recent_change": 0.4242849530820081},
{ "step": 3032, "visits": [727.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3300, "q_vals": [-6.901, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3033, "visits": [728.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3301, "q_vals": [-6.905, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3034, "visits": [729.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3301, "q_vals": [-6.909, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3035, "visits": [730.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3304, "q_vals": [-6.913, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3036, "visits": [731.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3305, "q_vals": [-6.917, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3037, "visits": [732.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3305, "q_vals": [-6.921, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3038, "visits": [733.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3306, "q_vals": [-6.925, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3039, "visits": [734.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3308, "q_vals": [-6.915, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3040, "visits": [735.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3309, "q_vals": [-6.906, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3041, "visits": [736.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3309, "q_vals": [-6.91, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3311, "number_of_timesteps": 288826, "per_episode_reward": -365.68, "episode_reward_trend_value": 0.0009497009504248885, "biggest_recent_change": 0.4242849530820081},
{ "step": 3042, "visits": [737.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3311, "q_vals": [-6.9, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3043, "visits": [738.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3313, "q_vals": [-6.904, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3044, "visits": [739.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3314, "q_vals": [-6.908, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3045, "visits": [740.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3314, "q_vals": [-6.912, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3046, "visits": [741.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3315, "q_vals": [-6.916, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3047, "visits": [742.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3316, "q_vals": [-6.92, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3048, "visits": [743.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3316, "q_vals": [-6.91, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3049, "visits": [744.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3316, "q_vals": [-6.914, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3050, "visits": [745.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3317, "q_vals": [-6.918, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3051, "visits": [746.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3318, "q_vals": [-6.909, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3052, "visits": [747.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3318, "q_vals": [-6.913, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3053, "visits": [748.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3319, "q_vals": [-6.917, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3054, "visits": [749.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3319, "q_vals": [-6.92, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3055, "visits": [750.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3319, "q_vals": [-6.924, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3056, "visits": [751.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3319, "q_vals": [-6.915, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3057, "visits": [752.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3320, "q_vals": [-6.906, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3322, "number_of_timesteps": 290039, "per_episode_reward": -366.4, "episode_reward_trend_value": -0.006536158236679057, "biggest_recent_change": 0.7279472170404233},
{ "step": 3058, "visits": [753.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3322, "q_vals": [-6.897, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3059, "visits": [754.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3322, "q_vals": [-6.901, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3060, "visits": [755.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3322, "q_vals": [-6.904, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3061, "visits": [756.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3323, "q_vals": [-6.895, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3062, "visits": [757.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3324, "q_vals": [-6.899, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3063, "visits": [758.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3326, "q_vals": [-6.903, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3064, "visits": [759.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3327, "q_vals": [-6.907, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3065, "visits": [760.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3328, "q_vals": [-6.898, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3066, "visits": [761.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3328, "q_vals": [-6.889, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3067, "visits": [762.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3329, "q_vals": [-6.892, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3068, "visits": [763.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3330, "q_vals": [-6.883, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3069, "visits": [764.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3331, "q_vals": [-6.887, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3070, "visits": [765.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3331, "q_vals": [-6.891, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3332, "number_of_timesteps": 291352, "per_episode_reward": -366.21, "episode_reward_trend_value": 0.0003712318583691538, "biggest_recent_change": 0.7279472170404233},
{ "step": 3071, "visits": [766.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3332, "q_vals": [-6.895, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3072, "visits": [767.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3334, "q_vals": [-6.899, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3073, "visits": [768.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3334, "q_vals": [-6.902, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3074, "visits": [769.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3335, "q_vals": [-6.906, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3075, "visits": [770.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3337, "q_vals": [-6.91, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3076, "visits": [771.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3337, "q_vals": [-6.901, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3077, "visits": [772.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3340, "q_vals": [-6.892, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3078, "visits": [773.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3340, "q_vals": [-6.896, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3342, "number_of_timesteps": 292404, "per_episode_reward": -365.57, "episode_reward_trend_value": 0.005148583249372981, "biggest_recent_change": 0.7279472170404233},
{ "step": 3079, "visits": [774.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3342, "q_vals": [-6.899, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3080, "visits": [775.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3343, "q_vals": [-6.903, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3081, "visits": [776.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3344, "q_vals": [-6.907, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3082, "visits": [777.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3345, "q_vals": [-6.898, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3083, "visits": [778.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3346, "q_vals": [-6.902, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3084, "visits": [779.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3346, "q_vals": [-6.905, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3085, "visits": [780.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3347, "q_vals": [-6.909, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3086, "visits": [781.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3348, "q_vals": [-6.913, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3087, "visits": [782.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3349, "q_vals": [-6.917, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3088, "visits": [783.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3351, "q_vals": [-6.908, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3352, "number_of_timesteps": 293318, "per_episode_reward": -365.3, "episode_reward_trend_value": 0.007966623396276873, "biggest_recent_change": 0.7279472170404233},
{ "step": 3089, "visits": [784.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3352, "q_vals": [-6.911, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3090, "visits": [785.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3352, "q_vals": [-6.915, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3091, "visits": [786.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3353, "q_vals": [-6.919, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3092, "visits": [787.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3356, "q_vals": [-6.91, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3093, "visits": [788.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3357, "q_vals": [-6.914, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3094, "visits": [789.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3357, "q_vals": [-6.917, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3095, "visits": [790.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3358, "q_vals": [-6.921, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3096, "visits": [791.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3360, "q_vals": [-6.912, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3362, "number_of_timesteps": 294180, "per_episode_reward": -365.28, "episode_reward_trend_value": 0.008827340192994547, "biggest_recent_change": 0.7279472170404233},
{ "step": 3097, "visits": [792.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3362, "q_vals": [-6.916, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3098, "visits": [793.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3363, "q_vals": [-6.919, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3099, "visits": [794.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3363, "q_vals": [-6.923, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3100, "visits": [795.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3363, "q_vals": [-6.927, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3101, "visits": [796.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3365, "q_vals": [-6.918, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3102, "visits": [797.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3366, "q_vals": [-6.922, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3103, "visits": [798.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3366, "q_vals": [-6.913, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3104, "visits": [799.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3367, "q_vals": [-6.917, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3105, "visits": [800.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3368, "q_vals": [-6.92, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3106, "visits": [801.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3371, "q_vals": [-6.924, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3372, "number_of_timesteps": 295117, "per_episode_reward": -364.87, "episode_reward_trend_value": 0.00882799145055944, "biggest_recent_change": 0.7279472170404233},
{ "step": 3107, "visits": [802.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3372, "q_vals": [-6.927, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3108, "visits": [803.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3373, "q_vals": [-6.931, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3109, "visits": [804.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3374, "q_vals": [-6.934, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3110, "visits": [805.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3375, "q_vals": [-6.938, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3111, "visits": [806.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3376, "q_vals": [-6.942, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3112, "visits": [807.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3376, "q_vals": [-6.933, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3113, "visits": [808.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3377, "q_vals": [-6.924, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3114, "visits": [809.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3378, "q_vals": [-6.928, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3115, "visits": [810.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3380, "q_vals": [-6.931, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3382, "number_of_timesteps": 295969, "per_episode_reward": -364.64, "episode_reward_trend_value": 0.011077754224054262, "biggest_recent_change": 0.7279472170404233},
{ "step": 3116, "visits": [811.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3382, "q_vals": [-6.935, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3117, "visits": [812.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3383, "q_vals": [-6.939, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3118, "visits": [813.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3384, "q_vals": [-6.942, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3119, "visits": [814.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3385, "q_vals": [-6.946, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3120, "visits": [815.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3386, "q_vals": [-6.949, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3121, "visits": [816.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3386, "q_vals": [-6.941, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3122, "visits": [817.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3386, "q_vals": [-6.932, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3123, "visits": [818.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3390, "q_vals": [-6.936, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3124, "visits": [819.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3390, "q_vals": [-6.939, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3125, "visits": [820.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3391, "q_vals": [-6.942, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3393, "number_of_timesteps": 296921, "per_episode_reward": -364.25, "episode_reward_trend_value": 0.016681347562621972, "biggest_recent_change": 0.7279472170404233},
{ "step": 3126, "visits": [821.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3393, "q_vals": [-6.946, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3127, "visits": [822.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3393, "q_vals": [-6.949, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3128, "visits": [823.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3395, "q_vals": [-6.941, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3129, "visits": [824.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3395, "q_vals": [-6.933, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3130, "visits": [825.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3395, "q_vals": [-6.936, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3131, "visits": [826.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3396, "q_vals": [-6.928, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3132, "visits": [827.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3397, "q_vals": [-6.919, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3133, "visits": [828.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3398, "q_vals": [-6.918, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3134, "visits": [829.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3398, "q_vals": [-6.91, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3135, "visits": [830.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3399, "q_vals": [-6.913, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3136, "visits": [831.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3402, "q_vals": [-6.905, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3403, "number_of_timesteps": 297913, "per_episode_reward": -364.34, "episode_reward_trend_value": 0.014824285407823684, "biggest_recent_change": 0.7279472170404233},
{ "step": 3137, "visits": [832.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3403, "q_vals": [-6.897, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3138, "visits": [833.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3403, "q_vals": [-6.9, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3139, "visits": [834.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3403, "q_vals": [-6.904, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3140, "visits": [835.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3404, "q_vals": [-6.895, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3141, "visits": [836.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3405, "q_vals": [-6.899, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3142, "visits": [837.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3406, "q_vals": [-6.902, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3143, "visits": [838.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3406, "q_vals": [-6.894, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3144, "visits": [839.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3406, "q_vals": [-6.898, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3145, "visits": [840.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3409, "q_vals": [-6.901, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3146, "visits": [841.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3410, "q_vals": [-6.904, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3147, "visits": [842.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3410, "q_vals": [-6.908, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3148, "visits": [843.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3411, "q_vals": [-6.9, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3149, "visits": [844.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3412, "q_vals": [-6.903, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3414, "number_of_timesteps": 299140, "per_episode_reward": -364.53, "episode_reward_trend_value": 0.020808653989341667, "biggest_recent_change": 0.6364534790559446},
{ "step": 3150, "visits": [845.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3414, "q_vals": [-6.895, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3151, "visits": [846.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3414, "q_vals": [-6.898, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3152, "visits": [847.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3414, "q_vals": [-6.902, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3153, "visits": [848.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3415, "q_vals": [-6.905, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3154, "visits": [849.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3417, "q_vals": [-6.897, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3155, "visits": [850.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3418, "q_vals": [-6.901, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3156, "visits": [851.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3418, "q_vals": [-6.904, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3157, "visits": [852.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3420, "q_vals": [-6.907, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3158, "visits": [853.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3421, "q_vals": [-6.911, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3159, "visits": [854.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3422, "q_vals": [-6.914, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3424, "number_of_timesteps": 300206, "per_episode_reward": -364.63, "episode_reward_trend_value": 0.017485459815919865, "biggest_recent_change": 0.6364534790559446},
{ "step": 3160, "visits": [855.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3424, "q_vals": [-6.906, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3161, "visits": [856.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3424, "q_vals": [-6.898, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3162, "visits": [857.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3424, "q_vals": [-6.901, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3163, "visits": [858.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3425, "q_vals": [-6.905, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3164, "visits": [859.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3427, "q_vals": [-6.908, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3165, "visits": [860.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3428, "q_vals": [-6.9, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3166, "visits": [861.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3430, "q_vals": [-6.892, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3167, "visits": [862.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3431, "q_vals": [-6.895, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3168, "visits": [863.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3433, "q_vals": [-6.887, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3169, "visits": [864.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3433, "q_vals": [-6.891, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3170, "visits": [865.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3433, "q_vals": [-6.894, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3434, "number_of_timesteps": 301086, "per_episode_reward": -364.98, "episode_reward_trend_value": 0.006518263798159296, "biggest_recent_change": 0.4111745322955471},
{ "step": 3171, "visits": [866.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3434, "q_vals": [-6.886, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
[-6.878, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796]
{ "step": 3173, "visits": [868.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3436, "q_vals": [-6.882, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3174, "visits": [869.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3436, "q_vals": [-6.885, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3175, "visits": [870.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3436, "q_vals": [-6.888, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3176, "visits": [871.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3436, "q_vals": [-6.88, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3177, "visits": [872.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3436, "q_vals": [-6.884, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3178, "visits": [873.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3437, "q_vals": [-6.887, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3179, "visits": [874.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3438, "q_vals": [-6.879, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3180, "visits": [875.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3440, "q_vals": [-6.882, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3181, "visits": [876.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3440, "q_vals": [-6.886, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3182, "visits": [877.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3440, "q_vals": [-6.889, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3183, "visits": [878.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3442, "q_vals": [-6.892, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3184, "visits": [879.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3443, "q_vals": [-6.896, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3185, "visits": [880.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3443, "q_vals": [-6.899, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3186, "visits": [881.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3443, "q_vals": [-6.902, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3444, "number_of_timesteps": 302422, "per_episode_reward": -365.39, "episode_reward_trend_value": -0.0010161025164765961, "biggest_recent_change": 0.4111745322955471},
{ "step": 3187, "visits": [882.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3444, "q_vals": [-6.906, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3188, "visits": [883.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3445, "q_vals": [-6.898, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3189, "visits": [884.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3446, "q_vals": [-6.89, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3190, "visits": [885.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3446, "q_vals": [-6.882, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3191, "visits": [886.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3447, "q_vals": [-6.885, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3192, "visits": [887.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3450, "q_vals": [-6.878, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3193, "visits": [888.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3451, "q_vals": [-6.881, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3194, "visits": [889.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3451, "q_vals": [-6.884, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3195, "visits": [890.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3452, "q_vals": [-6.888, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3196, "visits": [891.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3452, "q_vals": [-6.891, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3455, "number_of_timesteps": 303698, "per_episode_reward": -365.49, "episode_reward_trend_value": -0.0022936958502365696, "biggest_recent_change": 0.4111745322955471},
{ "step": 3197, "visits": [892.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3455, "q_vals": [-6.894, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3198, "visits": [893.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3455, "q_vals": [-6.897, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3199, "visits": [894.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3456, "q_vals": [-6.901, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3200, "visits": [895.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3458, "q_vals": [-6.904, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3201, "visits": [896.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3458, "q_vals": [-6.896, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3202, "visits": [897.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3458, "q_vals": [-6.888, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3203, "visits": [898.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3459, "q_vals": [-6.892, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3204, "visits": [899.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3459, "q_vals": [-6.884, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3205, "visits": [900.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3463, "q_vals": [-6.876, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3206, "visits": [901.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3463, "q_vals": [-6.869, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3207, "visits": [902.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3463, "q_vals": [-6.861, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3208, "visits": [903.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3464, "q_vals": [-6.853, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3209, "visits": [904.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3464, "q_vals": [-6.846, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3466, "number_of_timesteps": 304703, "per_episode_reward": -364.89, "episode_reward_trend_value": -0.0001917532784407033, "biggest_recent_change": 0.6003493637571751},
{ "step": 3210, "visits": [905.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3466, "q_vals": [-6.838, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3211, "visits": [906.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3466, "q_vals": [-6.842, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3212, "visits": [907.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3468, "q_vals": [-6.845, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3213, "visits": [908.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3468, "q_vals": [-6.848, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3214, "visits": [909.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3468, "q_vals": [-6.841, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3215, "visits": [910.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3469, "q_vals": [-6.833, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3216, "visits": [911.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3469, "q_vals": [-6.826, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3217, "visits": [912.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3471, "q_vals": [-6.829, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3218, "visits": [913.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3471, "q_vals": [-6.821, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3219, "visits": [914.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3471, "q_vals": [-6.825, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3220, "visits": [915.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3473, "q_vals": [-6.828, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3221, "visits": [916.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3473, "q_vals": [-6.831, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3222, "visits": [917.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3473, "q_vals": [-6.834, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3223, "visits": [918.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3473, "q_vals": [-6.838, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3224, "visits": [919.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3475, "q_vals": [-6.841, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3225, "visits": [920.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3475, "q_vals": [-6.844, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3226, "visits": [921.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3475, "q_vals": [-6.847, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3227, "visits": [922.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3475, "q_vals": [-6.84, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3478, "number_of_timesteps": 306260, "per_episode_reward": -364.48, "episode_reward_trend_value": 0.0017594309994567285, "biggest_recent_change": 0.6003493637571751},
{ "step": 3228, "visits": [923.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3478, "q_vals": [-6.843, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3229, "visits": [924.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3479, "q_vals": [-6.846, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3230, "visits": [925.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3480, "q_vals": [-6.839, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3231, "visits": [926.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3481, "q_vals": [-6.831, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3232, "visits": [927.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3482, "q_vals": [-6.835, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3233, "visits": [928.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3482, "q_vals": [-6.827, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3234, "visits": [929.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3483, "q_vals": [-6.82, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3235, "visits": [930.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3483, "q_vals": [-6.813, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3236, "visits": [931.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3483, "q_vals": [-6.805, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3237, "visits": [932.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3483, "q_vals": [-6.808, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3238, "visits": [933.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3486, "q_vals": [-6.801, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3239, "visits": [934.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3487, "q_vals": [-6.794, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3240, "visits": [935.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3487, "q_vals": [-6.787, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3241, "visits": [936.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3487, "q_vals": [-6.779, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3489, "number_of_timesteps": 307635, "per_episode_reward": -364.93, "episode_reward_trend_value": -0.007549583368744885, "biggest_recent_change": 0.6003493637571751},
{ "step": 3242, "visits": [937.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3489, "q_vals": [-6.772, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3243, "visits": [938.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3490, "q_vals": [-6.765, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3244, "visits": [939.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3491, "q_vals": [-6.768, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3245, "visits": [940.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3492, "q_vals": [-6.771, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3246, "visits": [941.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3492, "q_vals": [-6.764, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3247, "visits": [942.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3495, "q_vals": [-6.757, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3248, "visits": [943.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3496, "q_vals": [-6.75, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3249, "visits": [944.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3497, "q_vals": [-6.753, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3250, "visits": [945.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3497, "q_vals": [-6.756, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3251, "visits": [946.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3498, "q_vals": [-6.759, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3499, "number_of_timesteps": 308944, "per_episode_reward": -365.67, "episode_reward_trend_value": -0.014774729508639617, "biggest_recent_change": 0.7428451516888686},
{ "step": 3252, "visits": [947.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3499, "q_vals": [-6.763, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3253, "visits": [948.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3502, "q_vals": [-6.766, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3254, "visits": [949.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3502, "q_vals": [-6.759, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3255, "visits": [950.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3502, "q_vals": [-6.762, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3256, "visits": [951.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3505, "q_vals": [-6.755, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3257, "visits": [952.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3507, "q_vals": [-6.758, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3258, "visits": [953.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3507, "q_vals": [-6.761, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3259, "visits": [954.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3507, "q_vals": [-6.764, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3260, "visits": [955.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3507, "q_vals": [-6.757, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3261, "visits": [956.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3508, "q_vals": [-6.76, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3510, "number_of_timesteps": 309873, "per_episode_reward": -365.72, "episode_reward_trend_value": -0.013184235433040689, "biggest_recent_change": 0.7428451516888686},
{ "step": 3262, "visits": [957.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3510, "q_vals": [-6.764, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3263, "visits": [958.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3511, "q_vals": [-6.767, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3264, "visits": [959.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3512, "q_vals": [-6.77, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3265, "visits": [960.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3513, "q_vals": [-6.773, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3266, "visits": [961.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3513, "q_vals": [-6.776, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3267, "visits": [962.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3515, "q_vals": [-6.779, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3268, "visits": [963.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3517, "q_vals": [-6.772, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3269, "visits": [964.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3518, "q_vals": [-6.775, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3270, "visits": [965.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3519, "q_vals": [-6.779, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3271, "visits": [966.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3519, "q_vals": [-6.782, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3272, "visits": [967.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3519, "q_vals": [-6.775, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3520, "number_of_timesteps": 310847, "per_episode_reward": -364.69, "episode_reward_trend_value": -0.0006544025000632954, "biggest_recent_change": 1.0259776438323343},
{ "step": 3273, "visits": [968.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3520, "q_vals": [-6.778, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
[969.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0]  episode_count: 3521 q_vals: [-6.781, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796]
{ "step": 3275, "visits": [970.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3522, "q_vals": [-6.784, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3276, "visits": [971.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3525, "q_vals": [-6.777, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3277, "visits": [972.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3526, "q_vals": [-6.78, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3278, "visits": [973.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3527, "q_vals": [-6.783, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3279, "visits": [974.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3527, "q_vals": [-6.786, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3280, "visits": [975.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3527, "q_vals": [-6.779, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3281, "visits": [976.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3528, "q_vals": [-6.783, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3282, "visits": [977.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3529, "q_vals": [-6.776, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3531, "number_of_timesteps": 311931, "per_episode_reward": -364.58, "episode_reward_trend_value": 0.004539051292160442, "biggest_recent_change": 1.0259776438323343},
{ "step": 3283, "visits": [978.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3531, "q_vals": [-6.779, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3284, "visits": [979.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3532, "q_vals": [-6.782, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3285, "visits": [980.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3532, "q_vals": [-6.785, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3286, "visits": [981.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3533, "q_vals": [-6.788, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3287, "visits": [982.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3534, "q_vals": [-6.791, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3288, "visits": [983.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3535, "q_vals": [-6.794, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3289, "visits": [984.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3536, "q_vals": [-6.797, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3290, "visits": [985.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3537, "q_vals": [-6.8, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3291, "visits": [986.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3537, "q_vals": [-6.803, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3292, "visits": [987.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3540, "q_vals": [-6.806, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{"total_number_of_episodes": 3541, "number_of_timesteps": 312958, "per_episode_reward": -364.71, "episode_reward_trend_value": 0.007549735900101319, "biggest_recent_change": 1.0259776438323343},
{ "step": 3293, "visits": [988.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3541, "q_vals": [-6.799, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3294, "visits": [989.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3542, "q_vals": [-6.792, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3295, "visits": [990.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3542, "q_vals": [-6.786, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3296, "visits": [991.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3543, "q_vals": [-6.789, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3297, "visits": [992.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3543, "q_vals": [-6.782, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3298, "visits": [993.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3545, "q_vals": [-6.785, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3299, "visits": [994.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3546, "q_vals": [-6.778, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3300, "visits": [995.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3546, "q_vals": [-6.781, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3301, "visits": [996.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3546, "q_vals": [-6.784, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3302, "visits": [997.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3546, "q_vals": [-6.787, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3303, "visits": [998.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3548, "q_vals": [-6.79, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3304, "visits": [999.0, 1000.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0, 1.0] , "episode_count": 3548, "q_vals": [-6.783, -inf, -inf, -24.49, -9.796, -9.796, -9.796, -7.837, -9.796, -9.796] }
{ "step": 3305, "visits": [1000.0, 1000.0, 1000.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] , "episode_count": 3549, "q_vals": [-inf, -inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] }
{"total_number_of_episodes": 3551, "number_of_timesteps": 313936, "per_episode_reward": -317.65, "episode_reward_trend_value": 0.5315672539583078, "biggest_recent_change": 47.05810773818581},
{"total_number_of_episodes": 3561, "number_of_timesteps": 315088, "per_episode_reward": -317.69, "episode_reward_trend_value": 0.5244633044943801, "biggest_recent_change": 47.05810773818581},
{"total_number_of_episodes": 3571, "number_of_timesteps": 316217, "per_episode_reward": -318.41, "episode_reward_trend_value": 0.511906350285704, "biggest_recent_change": 47.05810773818581},
{"total_number_of_episodes": 3581, "number_of_timesteps": 317332, "per_episode_reward": -318.63, "episode_reward_trend_value": 0.5143848331633187, "biggest_recent_change": 47.05810773818581},
{"total_number_of_episodes": 3591, "number_of_timesteps": 318406, "per_episode_reward": -318.39, "episode_reward_trend_value": 0.5253779705625321, "biggest_recent_change": 47.05810773818581},
{"total_number_of_episodes": 3602, "number_of_timesteps": 319855, "per_episode_reward": -318.11, "episode_reward_trend_value": 0.5289722723996527, "biggest_recent_change": 47.05810773818581},
{"total_number_of_episodes": 3612, "number_of_timesteps": 320861, "per_episode_reward": -318.17, "episode_reward_trend_value": 0.5168844331154799, "biggest_recent_change": 47.05810773818581},
{"total_number_of_episodes": 3622, "number_of_timesteps": 321812, "per_episode_reward": -318.38, "episode_reward_trend_value": 0.5132746480891525, "biggest_recent_change": 47.05810773818581},
{"total_number_of_episodes": 3634, "number_of_timesteps": 322702, "per_episode_reward": -318.54, "episode_reward_trend_value": 0.5129818265166086, "biggest_recent_change": 47.05810773818581},
{"total_number_of_episodes": 3645, "number_of_timesteps": 323581, "per_episode_reward": -318.81, "episode_reward_trend_value": -0.012840950724320363, "biggest_recent_change": 0.7214539857609452},
{"total_number_of_episodes": 3655, "number_of_timesteps": 324261, "per_episode_reward": -319.15, "episode_reward_trend_value": -0.016193813601455533, "biggest_recent_change": 0.7214539857609452},
{"total_number_of_episodes": 3665, "number_of_timesteps": 325007, "per_episode_reward": -319.58, "episode_reward_trend_value": -0.013025003819406165, "biggest_recent_change": 0.4362611053765022},
{"total_number_of_episodes": 3675, "number_of_timesteps": 325735, "per_episode_reward": -319.88, "episode_reward_trend_value": -0.013801978807583737, "biggest_recent_change": 0.4362611053765022},
{"total_number_of_episodes": 3686, "number_of_timesteps": 326570, "per_episode_reward": -320.14, "episode_reward_trend_value": -0.019430742364910554, "biggest_recent_change": 0.4362611053765022},
{"total_number_of_episodes": 3696, "number_of_timesteps": 327342, "per_episode_reward": -320.56, "episode_reward_trend_value": -0.027266719757523105, "biggest_recent_change": 0.4362611053765022},
{"total_number_of_episodes": 3706, "number_of_timesteps": 328070, "per_episode_reward": -320.78, "episode_reward_trend_value": -0.02898468958966747, "biggest_recent_change": 0.4362611053765022},
{"total_number_of_episodes": 3716, "number_of_timesteps": 328906, "per_episode_reward": -321.22, "episode_reward_trend_value": -0.03151737124340836, "biggest_recent_change": 0.4362611053765022},
{"total_number_of_episodes": 3726, "number_of_timesteps": 329750, "per_episode_reward": -321.57, "episode_reward_trend_value": -0.033715425984711875, "biggest_recent_change": 0.4362611053765022},
{"total_number_of_episodes": 3736, "number_of_timesteps": 330646, "per_episode_reward": -321.89, "episode_reward_trend_value": -0.03423044470468679, "biggest_recent_change": 0.4362611053765022},
{"total_number_of_episodes": 3746, "number_of_timesteps": 331675, "per_episode_reward": -322.13, "episode_reward_trend_value": -0.033103697808868696, "biggest_recent_change": 0.4362611053765022},
{"total_number_of_episodes": 3757, "number_of_timesteps": 332705, "per_episode_reward": -321.97, "episode_reward_trend_value": -0.026538187546381348, "biggest_recent_change": 0.43600532244852275},
{"total_number_of_episodes": 3768, "number_of_timesteps": 333710, "per_episode_reward": -321.81, "episode_reward_trend_value": -0.02151148183287748, "biggest_recent_change": 0.43600532244852275},
{"total_number_of_episodes": 3778, "number_of_timesteps": 334548, "per_episode_reward": -321.58, "episode_reward_trend_value": -0.01608764989783127, "biggest_recent_change": 0.43600532244852275},
{"total_number_of_episodes": 3789, "number_of_timesteps": 335550, "per_episode_reward": -320.98, "episode_reward_trend_value": -0.004566357156342822, "biggest_recent_change": 0.6089559688397799},
{"total_number_of_episodes": 3799, "number_of_timesteps": 336660, "per_episode_reward": -320.96, "episode_reward_trend_value": -0.0020213358279098275, "biggest_recent_change": 0.6089559688397799},
{"total_number_of_episodes": 3809, "number_of_timesteps": 337731, "per_episode_reward": -320.81, "episode_reward_trend_value": 0.004566269820792791, "biggest_recent_change": 0.6089559688397799},
{"total_number_of_episodes": 3821, "number_of_timesteps": 339678, "per_episode_reward": -320.82, "episode_reward_trend_value": 0.00832624963560041, "biggest_recent_change": 0.6089559688397799},
{"total_number_of_episodes": 3831, "number_of_timesteps": 341023, "per_episode_reward": -320.65, "episode_reward_trend_value": 0.013763809061259735, "biggest_recent_change": 0.6089559688397799},
{"total_number_of_episodes": 3841, "number_of_timesteps": 341988, "per_episode_reward": -320.28, "episode_reward_trend_value": 0.02049849742719832, "biggest_recent_change": 0.6089559688397799},
{"total_number_of_episodes": 3852, "number_of_timesteps": 342763, "per_episode_reward": -320.11, "episode_reward_trend_value": 0.020715967516861788, "biggest_recent_change": 0.6089559688397799},
{"total_number_of_episodes": 3862, "number_of_timesteps": 343550, "per_episode_reward": -319.76, "episode_reward_trend_value": 0.02279370850376065, "biggest_recent_change": 0.6089559688397799},
{"total_number_of_episodes": 3873, "number_of_timesteps": 344391, "per_episode_reward": -319.47, "episode_reward_trend_value": 0.02345568420602149, "biggest_recent_change": 0.6089559688397799},
{"total_number_of_episodes": 3885, "number_of_timesteps": 345320, "per_episode_reward": -319.15, "episode_reward_trend_value": 0.020295594501147384, "biggest_recent_change": 0.3667654266196223},
{"total_number_of_episodes": 3895, "number_of_timesteps": 346378, "per_episode_reward": -319.22, "episode_reward_trend_value": 0.01933885855528009, "biggest_recent_change": 0.3667654266196223},
{"total_number_of_episodes": 3906, "number_of_timesteps": 347766, "per_episode_reward": -319.18, "episode_reward_trend_value": 0.018047985080421665, "biggest_recent_change": 0.3667654266196223},
{"total_number_of_episodes": 3917, "number_of_timesteps": 348917, "per_episode_reward": -319.62, "episode_reward_trend_value": 0.013362250089733786, "biggest_recent_change": 0.43960666675968696},
{"total_number_of_episodes": 3927, "number_of_timesteps": 349981, "per_episode_reward": -319.63, "episode_reward_trend_value": 0.011349398739538528, "biggest_recent_change": 0.43960666675968696},
{"total_number_of_episodes": 3937, "number_of_timesteps": 351083, "per_episode_reward": -319.95, "episode_reward_trend_value": 0.003715984048411277, "biggest_recent_change": 0.43960666675968696},
{"total_number_of_episodes": 3947, "number_of_timesteps": 352471, "per_episode_reward": -319.79, "episode_reward_trend_value": 0.0035075151057242238, "biggest_recent_change": 0.43960666675968696},
{"total_number_of_episodes": 3957, "number_of_timesteps": 353491, "per_episode_reward": -319.58, "episode_reward_trend_value": 0.002068989180021516, "biggest_recent_change": 0.43960666675968696},
{"total_number_of_episodes": 3967, "number_of_timesteps": 354561, "per_episode_reward": -319.14, "episode_reward_trend_value": 0.003700581528345184, "biggest_recent_change": 0.43960666675968696},
{"total_number_of_episodes": 3977, "number_of_timesteps": 355626, "per_episode_reward": -318.95, "episode_reward_trend_value": 0.0022268755164007972, "biggest_recent_change": 0.43960666675968696},
{"total_number_of_episodes": 3987, "number_of_timesteps": 356517, "per_episode_reward": -319.38, "episode_reward_trend_value": -0.0017841537550547554, "biggest_recent_change": 0.43960666675968696},
{"total_number_of_episodes": 3997, "number_of_timesteps": 357522, "per_episode_reward": -319.56, "episode_reward_trend_value": -0.004144956219126547, "biggest_recent_change": 0.43960666675968696},
{"total_number_of_episodes": 4007, "number_of_timesteps": 358516, "per_episode_reward": -319.73, "episode_reward_trend_value": -0.001211034927336464, "biggest_recent_change": 0.4345921266362893},
{"total_number_of_episodes": 4017, "number_of_timesteps": 359957, "per_episode_reward": -319.7, "episode_reward_trend_value": -0.0007960410508354067, "biggest_recent_change": 0.4345921266362893},
{"total_number_of_episodes": 4027, "number_of_timesteps": 361114, "per_episode_reward": -319.03, "episode_reward_trend_value": 0.010196453579204798, "biggest_recent_change": 0.6690826211217882},
{"total_number_of_episodes": 4038, "number_of_timesteps": 362133, "per_episode_reward": -319.02, "episode_reward_trend_value": 0.008521143384202408, "biggest_recent_change": 0.6690826211217882},
{"total_number_of_episodes": 4048, "number_of_timesteps": 363212, "per_episode_reward": -318.74, "episode_reward_trend_value": 0.009283783987256634, "biggest_recent_change": 0.6690826211217882},
{"total_number_of_episodes": 4058, "number_of_timesteps": 364320, "per_episode_reward": -318.91, "episode_reward_trend_value": 0.002521291703514963, "biggest_recent_change": 0.6690826211217882},
{"total_number_of_episodes": 4068, "number_of_timesteps": 365434, "per_episode_reward": -319.08, "episode_reward_trend_value": -0.0015125109774828615, "biggest_recent_change": 0.6690826211217882},
{"total_number_of_episodes": 4078, "number_of_timesteps": 366643, "per_episode_reward": -318.86, "episode_reward_trend_value": 0.0057648952796543855, "biggest_recent_change": 0.6690826211217882},
{"total_number_of_episodes": 4088, "number_of_timesteps": 367701, "per_episode_reward": -318.74, "episode_reward_trend_value": 0.009018476405267645, "biggest_recent_change": 0.6690826211217882},
{"total_number_of_episodes": 4098, "number_of_timesteps": 368709, "per_episode_reward": -318.22, "episode_reward_trend_value": 0.01681661793719387, "biggest_recent_change": 0.6690826211217882},
{"total_number_of_episodes": 4109, "number_of_timesteps": 369892, "per_episode_reward": -318.02, "episode_reward_trend_value": 0.01865155049544569, "biggest_recent_change": 0.6690826211217882},
{"total_number_of_episodes": 4119, "number_of_timesteps": 370788, "per_episode_reward": -317.89, "episode_reward_trend_value": 0.012603720113740894, "biggest_recent_change": 0.5262789873747806},
{"total_number_of_episodes": 4129, "number_of_timesteps": 372596, "per_episode_reward": -317.43, "episode_reward_trend_value": 0.017744473643736887, "biggest_recent_change": 0.5262789873747806},
{"total_number_of_episodes": 4140, "number_of_timesteps": 373854, "per_episode_reward": -317.31, "episode_reward_trend_value": 0.015918593322304435, "biggest_recent_change": 0.5262789873747806},
{"total_number_of_episodes": 4150, "number_of_timesteps": 374747, "per_episode_reward": -317.29, "episode_reward_trend_value": 0.018096276725959922, "biggest_recent_change": 0.5262789873747806},
{"total_number_of_episodes": 4163, "number_of_timesteps": 375806, "per_episode_reward": -316.6, "episode_reward_trend_value": 0.02761073438953885, "biggest_recent_change": 0.6851733027584146},
{"total_number_of_episodes": 4173, "number_of_timesteps": 376571, "per_episode_reward": -315.23, "episode_reward_trend_value": 0.040399122231035436, "biggest_recent_change": 1.371329342240756},
{"total_number_of_episodes": 4183, "number_of_timesteps": 377515, "per_episode_reward": -315.47, "episode_reward_trend_value": 0.036342001105844526, "biggest_recent_change": 1.371329342240756},
{"total_number_of_episodes": 4194, "number_of_timesteps": 378409, "per_episode_reward": -315.05, "episode_reward_trend_value": 0.03516872991990251, "biggest_recent_change": 1.371329342240756},
{"total_number_of_episodes": 4204, "number_of_timesteps": 379127, "per_episode_reward": -315.6, "episode_reward_trend_value": 0.0268510329642475, "biggest_recent_change": 1.371329342240756},
{"total_number_of_episodes": 4214, "number_of_timesteps": 380019, "per_episode_reward": -316.11, "episode_reward_trend_value": 0.01978685949599834, "biggest_recent_change": 1.371329342240756},
{"total_number_of_episodes": 4224, "number_of_timesteps": 381131, "per_episode_reward": -316.25, "episode_reward_trend_value": 0.013125015023095127, "biggest_recent_change": 1.371329342240756},
{"total_number_of_episodes": 4235, "number_of_timesteps": 382214, "per_episode_reward": -315.83, "episode_reward_trend_value": 0.01642166754258483, "biggest_recent_change": 1.371329342240756},
{"total_number_of_episodes": 4246, "number_of_timesteps": 383218, "per_episode_reward": -315.54, "episode_reward_trend_value": 0.019392295315338336, "biggest_recent_change": 1.371329342240756},
{"total_number_of_episodes": 4256, "number_of_timesteps": 384195, "per_episode_reward": -315.24, "episode_reward_trend_value": 0.015075314947022711, "biggest_recent_change": 1.371329342240756},
{"total_number_of_episodes": 4266, "number_of_timesteps": 384992, "per_episode_reward": -315.23, "episode_reward_trend_value": -2.6734202828038177e-05, "biggest_recent_change": 0.550169518384962},
{"total_number_of_episodes": 4276, "number_of_timesteps": 385810, "per_episode_reward": -315.1, "episode_reward_trend_value": 0.004104933769031681, "biggest_recent_change": 0.550169518384962},
{"total_number_of_episodes": 4286, "number_of_timesteps": 386751, "per_episode_reward": -315.23, "episode_reward_trend_value": -0.0019219520818340799, "biggest_recent_change": 0.550169518384962},
{"total_number_of_episodes": 4296, "number_of_timesteps": 387644, "per_episode_reward": -315.35, "episode_reward_trend_value": 0.0027684902606893045, "biggest_recent_change": 0.5109977253740681},
{"total_number_of_episodes": 4307, "number_of_timesteps": 388902, "per_episode_reward": -315.1, "episode_reward_trend_value": 0.01125309641992342, "biggest_recent_change": 0.41636983284018925},
{"total_number_of_episodes": 4318, "number_of_timesteps": 390286, "per_episode_reward": -315.21, "episode_reward_trend_value": 0.011518986758822949, "biggest_recent_change": 0.41636983284018925},
{"total_number_of_episodes": 4328, "number_of_timesteps": 391582, "per_episode_reward": -315.29, "episode_reward_trend_value": 0.006015610987288432, "biggest_recent_change": 0.29664506961000825},
{"total_number_of_episodes": 4338, "number_of_timesteps": 392762, "per_episode_reward": -315.2, "episode_reward_trend_value": 0.0037846786776021364, "biggest_recent_change": 0.29664506961000825},
{"total_number_of_episodes": 4348, "number_of_timesteps": 393999, "per_episode_reward": -315.02, "episode_reward_trend_value": 0.0024572984393608347, "biggest_recent_change": 0.2526168289570023},
{"total_number_of_episodes": 4358, "number_of_timesteps": 395048, "per_episode_reward": -314.98, "episode_reward_trend_value": 0.0027936049274198166, "biggest_recent_change": 0.2526168289570023},
{"total_number_of_episodes": 4368, "number_of_timesteps": 396538, "per_episode_reward": -315.01, "episode_reward_trend_value": 0.0009876240303874006, "biggest_recent_change": 0.2526168289570023},
{"total_number_of_episodes": 4378, "number_of_timesteps": 397543, "per_episode_reward": -314.98, "episode_reward_trend_value": 0.0027575117878516015, "biggest_recent_change": 0.2526168289570023},
{"total_number_of_episodes": 4388, "number_of_timesteps": 398639, "per_episode_reward": -314.93, "episode_reward_trend_value": 0.004740051400714643, "biggest_recent_change": 0.2526168289570023},
{"total_number_of_episodes": 4398, "number_of_timesteps": 399809, "per_episode_reward": -314.58, "episode_reward_trend_value": 0.005829372562122141, "biggest_recent_change": 0.35065573348367707},
{"total_number_of_episodes": 4408, "number_of_timesteps": 400893, "per_episode_reward": -314.19, "episode_reward_trend_value": 0.011367561677200735, "biggest_recent_change": 0.39013596992140265},
{"total_number_of_episodes": 4418, "number_of_timesteps": 401891, "per_episode_reward": -313.74, "episode_reward_trend_value": 0.017200972747157393, "biggest_recent_change": 0.446073009698182},
{"total_number_of_episodes": 4428, "number_of_timesteps": 402801, "per_episode_reward": -313.37, "episode_reward_trend_value": 0.020273831591207957, "biggest_recent_change": 0.446073009698182},
{"total_number_of_episodes": 4438, "number_of_timesteps": 403788, "per_episode_reward": -313.39, "episode_reward_trend_value": 0.018179646198598853, "biggest_recent_change": 0.446073009698182},
{"total_number_of_episodes": 4449, "number_of_timesteps": 405100, "per_episode_reward": -313.24, "episode_reward_trend_value": 0.019292754607401243, "biggest_recent_change": 0.446073009698182},
{"total_number_of_episodes": 4460, "number_of_timesteps": 406721, "per_episode_reward": -313.34, "episode_reward_trend_value": 0.018583034218589648, "biggest_recent_change": 0.446073009698182},
{"total_number_of_episodes": 4471, "number_of_timesteps": 407679, "per_episode_reward": -313.36, "episode_reward_trend_value": 0.017963808787950106, "biggest_recent_change": 0.446073009698182},
{"total_number_of_episodes": 4482, "number_of_timesteps": 408525, "per_episode_reward": -313.54, "episode_reward_trend_value": 0.015359973637083612, "biggest_recent_change": 0.446073009698182},
{"total_number_of_episodes": 4494, "number_of_timesteps": 409552, "per_episode_reward": -313.65, "episode_reward_trend_value": 0.010237607099550258, "biggest_recent_change": 0.446073009698182},
{"total_number_of_episodes": 4504, "number_of_timesteps": 410498, "per_episode_reward": -313.73, "episode_reward_trend_value": 0.005080976201228774, "biggest_recent_change": 0.446073009698182},
{"total_number_of_episodes": 4515, "number_of_timesteps": 411939, "per_episode_reward": -313.69, "episode_reward_trend_value": 0.0005738057385782566, "biggest_recent_change": 0.36501158122052857},
{"total_number_of_episodes": 4526, "number_of_timesteps": 413150, "per_episode_reward": -313.77, "episode_reward_trend_value": -0.00436908268384602, "biggest_recent_change": 0.18394630597816786},
{"total_number_of_episodes": 4536, "number_of_timesteps": 414203, "per_episode_reward": -313.93, "episode_reward_trend_value": -0.006070067837637478, "biggest_recent_change": 0.18394630597816786},
{"total_number_of_episodes": 4546, "number_of_timesteps": 415306, "per_episode_reward": -314.05, "episode_reward_trend_value": -0.008992764278615242, "biggest_recent_change": 0.18394630597816786},
{"total_number_of_episodes": 4556, "number_of_timesteps": 416393, "per_episode_reward": -314.21, "episode_reward_trend_value": -0.00968161711738023, "biggest_recent_change": 0.18394630597816786},
{"total_number_of_episodes": 4566, "number_of_timesteps": 417667, "per_episode_reward": -314.67, "episode_reward_trend_value": -0.014579737888489161, "biggest_recent_change": 0.4590064059235033},
{"total_number_of_episodes": 4576, "number_of_timesteps": 418606, "per_episode_reward": -314.22, "episode_reward_trend_value": -0.007558520457257601, "biggest_recent_change": 0.4590064059235033},
{"total_number_of_episodes": 4586, "number_of_timesteps": 419416, "per_episode_reward": -314.05, "episode_reward_trend_value": -0.004370023056648935, "biggest_recent_change": 0.4590064059235033},
{"total_number_of_episodes": 4596, "number_of_timesteps": 420181, "per_episode_reward": -313.73, "episode_reward_trend_value": 8.850623470380014e-06, "biggest_recent_change": 0.4590064059235033},
{"total_number_of_episodes": 4606, "number_of_timesteps": 421128, "per_episode_reward": -313.47, "episode_reward_trend_value": 0.0023672841674024564, "biggest_recent_change": 0.4590064059235033},
{"total_number_of_episodes": 4616, "number_of_timesteps": 422411, "per_episode_reward": -313.48, "episode_reward_trend_value": 0.003242047015280352, "biggest_recent_change": 0.4590064059235033},
{"total_number_of_episodes": 4628, "number_of_timesteps": 423721, "per_episode_reward": -313.43, "episode_reward_trend_value": 0.005593349757855195, "biggest_recent_change": 0.4590064059235033},
{"total_number_of_episodes": 4638, "number_of_timesteps": 424561, "per_episode_reward": -313.4, "episode_reward_trend_value": 0.007291568154684886, "biggest_recent_change": 0.4590064059235033},
{"total_number_of_episodes": 4648, "number_of_timesteps": 425480, "per_episode_reward": -313.13, "episode_reward_trend_value": 0.012023858205911135, "biggest_recent_change": 0.4590064059235033},
{"total_number_of_episodes": 4658, "number_of_timesteps": 426412, "per_episode_reward": -312.82, "episode_reward_trend_value": 0.020606426751694093, "biggest_recent_change": 0.4479632628326726},
{"total_number_of_episodes": 4669, "number_of_timesteps": 427650, "per_episode_reward": -312.71, "episode_reward_trend_value": 0.01680297318475002, "biggest_recent_change": 0.3201378202832075},
{"total_number_of_episodes": 4683, "number_of_timesteps": 428763, "per_episode_reward": -312.65, "episode_reward_trend_value": 0.015489483497860747, "biggest_recent_change": 0.3201378202832075},
{"total_number_of_episodes": 4694, "number_of_timesteps": 429685, "per_episode_reward": -312.52, "episode_reward_trend_value": 0.013386805039633978, "biggest_recent_change": 0.3134247631969629},
{"total_number_of_episodes": 4704, "number_of_timesteps": 430663, "per_episode_reward": -312.49, "episode_reward_trend_value": 0.010963361021527538, "biggest_recent_change": 0.3134247631969629},
{"total_number_of_episodes": 4714, "number_of_timesteps": 431715, "per_episode_reward": -312.46, "episode_reward_trend_value": 0.011300900860341774, "biggest_recent_change": 0.3134247631969629},
{"total_number_of_episodes": 4725, "number_of_timesteps": 432821, "per_episode_reward": -312.27, "episode_reward_trend_value": 0.012896258494667892, "biggest_recent_change": 0.3134247631969629},
{"total_number_of_episodes": 4735, "number_of_timesteps": 434114, "per_episode_reward": -312.57, "episode_reward_trend_value": 0.009193861355328813, "biggest_recent_change": 0.3134247631969629},
{"total_number_of_episodes": 4745, "number_of_timesteps": 435375, "per_episode_reward": -312.48, "episode_reward_trend_value": 0.00718521360592111, "biggest_recent_change": 0.3134247631969629},
{"total_number_of_episodes": 4755, "number_of_timesteps": 436646, "per_episode_reward": -312.23, "episode_reward_trend_value": 0.006512577334936193, "biggest_recent_change": 0.30082650704213165},
{"total_number_of_episodes": 4766, "number_of_timesteps": 437806, "per_episode_reward": -312.06, "episode_reward_trend_value": 0.007261486774560429, "biggest_recent_change": 0.30082650704213165},
{"total_number_of_episodes": 4778, "number_of_timesteps": 439144, "per_episode_reward": -311.92, "episode_reward_trend_value": 0.008169359033798982, "biggest_recent_change": 0.30082650704213165},
{"total_number_of_episodes": 4788, "number_of_timesteps": 440107, "per_episode_reward": -312.22, "episode_reward_trend_value": 0.0034034555398862825, "biggest_recent_change": 0.30082650704213165},
{"total_number_of_episodes": 4798, "number_of_timesteps": 441043, "per_episode_reward": -312.3, "episode_reward_trend_value": 0.0021150676855616743, "biggest_recent_change": 0.30082650704213165},
{"total_number_of_episodes": 4808, "number_of_timesteps": 441844, "per_episode_reward": -312.31, "episode_reward_trend_value": 0.001698660606467052, "biggest_recent_change": 0.30082650704213165},
{"total_number_of_episodes": 4818, "number_of_timesteps": 442699, "per_episode_reward": -312.46, "episode_reward_trend_value": -0.002117250753353675, "biggest_recent_change": 0.30082650704213165},
{"total_number_of_episodes": 4828, "number_of_timesteps": 443713, "per_episode_reward": -313.05, "episode_reward_trend_value": -0.005325355060757727, "biggest_recent_change": 0.5895558947084965},
{"total_number_of_episodes": 4838, "number_of_timesteps": 444658, "per_episode_reward": -313.3, "episode_reward_trend_value": -0.009027677477397826, "biggest_recent_change": 0.5895558947084965},
{"total_number_of_episodes": 4848, "number_of_timesteps": 445776, "per_episode_reward": -313.32, "episode_reward_trend_value": -0.012124344708452858, "biggest_recent_change": 0.5895558947084965},
{"total_number_of_episodes": 4859, "number_of_timesteps": 446954, "per_episode_reward": -313.17, "episode_reward_trend_value": -0.012349436349778545, "biggest_recent_change": 0.5895558947084965},
{"total_number_of_episodes": 4869, "number_of_timesteps": 448025, "per_episode_reward": -312.93, "episode_reward_trend_value": -0.011247913658089853, "biggest_recent_change": 0.5895558947084965},
{"total_number_of_episodes": 4879, "number_of_timesteps": 448897, "per_episode_reward": -312.6, "episode_reward_trend_value": -0.004255361214240515, "biggest_recent_change": 0.5895558947084965},
{"total_number_of_episodes": 4889, "number_of_timesteps": 450033, "per_episode_reward": -312.66, "episode_reward_trend_value": -0.004059695417806905, "biggest_recent_change": 0.5895558947084965},
{"total_number_of_episodes": 4899, "number_of_timesteps": 451041, "per_episode_reward": -312.43, "episode_reward_trend_value": -0.001395395079763754, "biggest_recent_change": 0.5895558947084965},
{"total_number_of_episodes": 4909, "number_of_timesteps": 452016, "per_episode_reward": -312.27, "episode_reward_trend_value": 0.002091089006653293, "biggest_recent_change": 0.5895558947084965},
{"total_number_of_episodes": 4920, "number_of_timesteps": 452920, "per_episode_reward": -312.2, "episode_reward_trend_value": 0.009371146846003991, "biggest_recent_change": 0.33129516453709584},
{"total_number_of_episodes": 4932, "number_of_timesteps": 454105, "per_episode_reward": -312.31, "episode_reward_trend_value": 0.010918154734848588, "biggest_recent_change": 0.33129516453709584},
{"total_number_of_episodes": 4943, "number_of_timesteps": 455330, "per_episode_reward": -311.87, "episode_reward_trend_value": 0.016113076759160728, "biggest_recent_change": 0.44173043020145997},
{"total_number_of_episodes": 4953, "number_of_timesteps": 456585, "per_episode_reward": -311.94, "episode_reward_trend_value": 0.013719623762876961, "biggest_recent_change": 0.44173043020145997},
{"total_number_of_episodes": 4963, "number_of_timesteps": 457754, "per_episode_reward": -311.66, "episode_reward_trend_value": 0.014151827425855698, "biggest_recent_change": 0.44173043020145997},
{"total_number_of_episodes": 4973, "number_of_timesteps": 458851, "per_episode_reward": -311.33, "episode_reward_trend_value": 0.014140478963213354, "biggest_recent_change": 0.44173043020145997},
{"total_number_of_episodes": 4983, "number_of_timesteps": 459852, "per_episode_reward": -311.2, "episode_reward_trend_value": 0.0162319208287272, "biggest_recent_change": 0.44173043020145997},
{"total_number_of_episodes": 4993, "number_of_timesteps": 460956, "per_episode_reward": -310.95, "episode_reward_trend_value": 0.01647107239765104, "biggest_recent_change": 0.44173043020145997},
{"total_number_of_episodes": 5003, "number_of_timesteps": 462044, "per_episode_reward": -310.99, "episode_reward_trend_value": 0.014185924288959009, "biggest_recent_change": 0.44173043020145997},
{"total_number_of_episodes": 5013, "number_of_timesteps": 463061, "per_episode_reward": -310.97, "episode_reward_trend_value": 0.01367690201731572, "biggest_recent_change": 0.44173043020145997},
{"total_number_of_episodes": 5023, "number_of_timesteps": 464027, "per_episode_reward": -311.0, "episode_reward_trend_value": 0.014549843664495812, "biggest_recent_change": 0.44173043020145997},
{"total_number_of_episodes": 5033, "number_of_timesteps": 465132, "per_episode_reward": -310.85, "episode_reward_trend_value": 0.011389297861911826, "biggest_recent_change": 0.3302738028992849},
{"total_number_of_episodes": 5043, "number_of_timesteps": 466256, "per_episode_reward": -310.77, "episode_reward_trend_value": 0.012958877666598787, "biggest_recent_change": 0.3302738028992849},
{"total_number_of_episodes": 5054, "number_of_timesteps": 467448, "per_episode_reward": -310.49, "episode_reward_trend_value": 0.012938276274016086, "biggest_recent_change": 0.3302738028992849},
{"total_number_of_episodes": 5064, "number_of_timesteps": 468397, "per_episode_reward": -310.66, "episode_reward_trend_value": 0.007394992049004007, "biggest_recent_change": 0.2762831892595159},
{"total_number_of_episodes": 5074, "number_of_timesteps": 469370, "per_episode_reward": -310.55, "episode_reward_trend_value": 0.00727522537045186, "biggest_recent_change": 0.2762831892595159},
{"total_number_of_episodes": 5084, "number_of_timesteps": 470342, "per_episode_reward": -310.52, "episode_reward_trend_value": 0.004768633941269703, "biggest_recent_change": 0.2762831892595159},
{"total_number_of_episodes": 5097, "number_of_timesteps": 471714, "per_episode_reward": -310.84, "episode_reward_trend_value": 0.0017636804779069988, "biggest_recent_change": 0.3149426631779306},
{"total_number_of_episodes": 5107, "number_of_timesteps": 472793, "per_episode_reward": -310.85, "episode_reward_trend_value": 0.0014113624027541189, "biggest_recent_change": 0.3149426631779306},
{"total_number_of_episodes": 5118, "number_of_timesteps": 473884, "per_episode_reward": -310.71, "episode_reward_trend_value": 0.003254990760938073, "biggest_recent_change": 0.3149426631779306},
{"total_number_of_episodes": 5128, "number_of_timesteps": 474855, "per_episode_reward": -310.71, "episode_reward_trend_value": 0.0015790224126192242, "biggest_recent_change": 0.3149426631779306},
{"total_number_of_episodes": 5138, "number_of_timesteps": 475763, "per_episode_reward": -310.51, "episode_reward_trend_value": 0.002899845800210541, "biggest_recent_change": 0.3149426631779306},
{"total_number_of_episodes": 5148, "number_of_timesteps": 476720, "per_episode_reward": -310.4, "episode_reward_trend_value": 0.0010641388668653285, "biggest_recent_change": 0.3149426631779306},
{"total_number_of_episodes": 5158, "number_of_timesteps": 477900, "per_episode_reward": -310.4, "episode_reward_trend_value": 0.0028780267029648913, "biggest_recent_change": 0.3149426631779306},
{"total_number_of_episodes": 5168, "number_of_timesteps": 479042, "per_episode_reward": -310.05, "episode_reward_trend_value": 0.005507220412029786, "biggest_recent_change": 0.3503099408161461},
{"total_number_of_episodes": 5179, "number_of_timesteps": 480212, "per_episode_reward": -309.69, "episode_reward_trend_value": 0.0091956049267651, "biggest_recent_change": 0.359454277212933},
{"total_number_of_episodes": 5189, "number_of_timesteps": 481293, "per_episode_reward": -309.9, "episode_reward_trend_value": 0.010383588927589926, "biggest_recent_change": 0.359454277212933},
{"total_number_of_episodes": 5199, "number_of_timesteps": 482372, "per_episode_reward": -310.13, "episode_reward_trend_value": 0.00801445327408285, "biggest_recent_change": 0.359454277212933},
{"total_number_of_episodes": 5209, "number_of_timesteps": 483671, "per_episode_reward": -309.79, "episode_reward_trend_value": 0.010263127125072439, "biggest_recent_change": 0.359454277212933},
{"total_number_of_episodes": 5219, "number_of_timesteps": 484657, "per_episode_reward": -309.52, "episode_reward_trend_value": 0.013189029188380472, "biggest_recent_change": 0.359454277212933},
{"total_number_of_episodes": 5229, "number_of_timesteps": 485839, "per_episode_reward": -309.57, "episode_reward_trend_value": 0.010446542855476082, "biggest_recent_change": 0.359454277212933},
{"total_number_of_episodes": 5240, "number_of_timesteps": 486896, "per_episode_reward": -309.51, "episode_reward_trend_value": 0.009906733978388298, "biggest_recent_change": 0.359454277212933},
{"total_number_of_episodes": 5250, "number_of_timesteps": 487844, "per_episode_reward": -309.22, "episode_reward_trend_value": 0.013163948964872437, "biggest_recent_change": 0.359454277212933},
{"total_number_of_episodes": 5260, "number_of_timesteps": 488774, "per_episode_reward": -309.05, "episode_reward_trend_value": 0.011086527782699956, "biggest_recent_change": 0.359454277212933},
{"total_number_of_episodes": 5270, "number_of_timesteps": 489759, "per_episode_reward": -308.74, "episode_reward_trend_value": 0.010633906817313726, "biggest_recent_change": 0.33737144445547074},
{"total_number_of_episodes": 5280, "number_of_timesteps": 490682, "per_episode_reward": -308.81, "episode_reward_trend_value": 0.012097593497626097, "biggest_recent_change": 0.33737144445547074},
{"total_number_of_episodes": 5291, "number_of_timesteps": 491705, "per_episode_reward": -309.16, "episode_reward_trend_value": 0.010736375585319518, "biggest_recent_change": 0.3476031413018177},
{"total_number_of_episodes": 5302, "number_of_timesteps": 492830, "per_episode_reward": -308.87, "episode_reward_trend_value": 0.01016657069778704, "biggest_recent_change": 0.3476031413018177},
{"total_number_of_episodes": 5312, "number_of_timesteps": 493865, "per_episode_reward": -308.73, "episode_reward_trend_value": 0.008718289614685976, "biggest_recent_change": 0.3476031413018177},
{"total_number_of_episodes": 5324, "number_of_timesteps": 494978, "per_episode_reward": -308.79, "episode_reward_trend_value": 0.008683352581894293, "biggest_recent_change": 0.3476031413018177},
{"total_number_of_episodes": 5335, "number_of_timesteps": 496162, "per_episode_reward": -308.7, "episode_reward_trend_value": 0.008924006202506184, "biggest_recent_change": 0.3476031413018177},
{"total_number_of_episodes": 5346, "number_of_timesteps": 497403, "per_episode_reward": -308.84, "episode_reward_trend_value": 0.004148823595354795, "biggest_recent_change": 0.3476031413018177},
{"total_number_of_episodes": 5357, "number_of_timesteps": 498599, "per_episode_reward": -308.58, "episode_reward_trend_value": 0.005267158602477669, "biggest_recent_change": 0.3476031413018177},
{"total_number_of_episodes": 5367, "number_of_timesteps": 499430, "per_episode_reward": -308.54, "episode_reward_trend_value": 0.002123714899136707, "biggest_recent_change": 0.3476031413018177},
{"total_number_of_episodes": 5377, "number_of_timesteps": 500166, "per_episode_reward": -308.67, "episode_reward_trend_value": 0.0016163956991262138, "biggest_recent_change": 0.3476031413018177},
{"total_number_of_episodes": 5387, "number_of_timesteps": 500889, "per_episode_reward": -308.89, "episode_reward_trend_value": 0.0029560962874313644, "biggest_recent_change": 0.2860890045775477},
{"total_number_of_episodes": 5399, "number_of_timesteps": 501689, "per_episode_reward": -308.98, "episode_reward_trend_value": -0.0011653939289014185, "biggest_recent_change": 0.26399218506168154},
{"total_number_of_episodes": 5410, "number_of_timesteps": 502514, "per_episode_reward": -309.18, "episode_reward_trend_value": -0.004910373009655208, "biggest_recent_change": 0.26399218506168154},
{"total_number_of_episodes": 5421, "number_of_timesteps": 503310, "per_episode_reward": -309.48, "episode_reward_trend_value": -0.007656454901775254, "biggest_recent_change": 0.2995939119093691},
{"total_number_of_episodes": 5431, "number_of_timesteps": 504053, "per_episode_reward": -309.38, "episode_reward_trend_value": -0.007542149132184603, "biggest_recent_change": 0.2995939119093691},
{"total_number_of_episodes": 5441, "number_of_timesteps": 504709, "per_episode_reward": -309.08, "episode_reward_trend_value": -0.00260411695356816, "biggest_recent_change": 0.30243393811258557},
{"total_number_of_episodes": 5451, "number_of_timesteps": 505336, "per_episode_reward": -308.94, "episode_reward_trend_value": -0.004030573713883238, "biggest_recent_change": 0.30243393811258557},
{"total_number_of_episodes": 5461, "number_of_timesteps": 506035, "per_episode_reward": -308.74, "episode_reward_trend_value": -0.0021377721980728537, "biggest_recent_change": 0.30243393811258557},
{"total_number_of_episodes": 5471, "number_of_timesteps": 506744, "per_episode_reward": -308.53, "episode_reward_trend_value": 0.0014598739947391296, "biggest_recent_change": 0.30243393811258557},
{"total_number_of_episodes": 5481, "number_of_timesteps": 507442, "per_episode_reward": -307.83, "episode_reward_trend_value": 0.011867256560993963, "biggest_recent_change": 0.7096343426085809},
{"total_number_of_episodes": 5491, "number_of_timesteps": 508159, "per_episode_reward": -307.78, "episode_reward_trend_value": 0.013264960782040211, "biggest_recent_change": 0.7096343426085809},
{"total_number_of_episodes": 5501, "number_of_timesteps": 508900, "per_episode_reward": -307.39, "episode_reward_trend_value": 0.01984840286994035, "biggest_recent_change": 0.7096343426085809},
{"total_number_of_episodes": 5512, "number_of_timesteps": 509834, "per_episode_reward": -306.83, "episode_reward_trend_value": 0.02942560690032615, "biggest_recent_change": 0.7096343426085809},
{"total_number_of_episodes": 5522, "number_of_timesteps": 510746, "per_episode_reward": -306.88, "episode_reward_trend_value": 0.027807744855910716, "biggest_recent_change": 0.7096343426085809},
{"total_number_of_episodes": 5533, "number_of_timesteps": 512046, "per_episode_reward": -306.65, "episode_reward_trend_value": 0.027005921954630214, "biggest_recent_change": 0.7096343426085809},
{"total_number_of_episodes": 5543, "number_of_timesteps": 513325, "per_episode_reward": -306.7, "episode_reward_trend_value": 0.02489947118297222, "biggest_recent_change": 0.7096343426085809},
{"total_number_of_episodes": 5554, "number_of_timesteps": 514568, "per_episode_reward": -306.65, "episode_reward_trend_value": 0.02317109817917387, "biggest_recent_change": 0.7096343426085809},
{"total_number_of_episodes": 5564, "number_of_timesteps": 515785, "per_episode_reward": -306.73, "episode_reward_trend_value": 0.020081677882638538, "biggest_recent_change": 0.7096343426085809},
{"total_number_of_episodes": 5574, "number_of_timesteps": 516807, "per_episode_reward": -306.63, "episode_reward_trend_value": 0.013284666095915377, "biggest_recent_change": 0.5623544508253531},
{"total_number_of_episodes": 5584, "number_of_timesteps": 518081, "per_episode_reward": -306.28, "episode_reward_trend_value": 0.0166653597347186, "biggest_recent_change": 0.5623544508253531},
{"total_number_of_episodes": 5594, "number_of_timesteps": 519040, "per_episode_reward": -305.81, "episode_reward_trend_value": 0.017589844620612086, "biggest_recent_change": 0.5623544508253531},
{"total_number_of_episodes": 5604, "number_of_timesteps": 520088, "per_episode_reward": -305.67, "episode_reward_trend_value": 0.01286389007163267, "biggest_recent_change": 0.4780953552124174},
{"total_number_of_episodes": 5615, "number_of_timesteps": 521185, "per_episode_reward": -305.5, "episode_reward_trend_value": 0.015295279208406657, "biggest_recent_change": 0.4780953552124174},
{"total_number_of_episodes": 5625, "number_of_timesteps": 522158, "per_episode_reward": -305.71, "episode_reward_trend_value": 0.010384596812522457, "biggest_recent_change": 0.4780953552124174},
{"total_number_of_episodes": 5635, "number_of_timesteps": 523160, "per_episode_reward": -305.49, "episode_reward_trend_value": 0.01351139891400079, "biggest_recent_change": 0.4780953552124174},
{"total_number_of_episodes": 5646, "number_of_timesteps": 524214, "per_episode_reward": -305.38, "episode_reward_trend_value": 0.014110376327876869, "biggest_recent_change": 0.4780953552124174},
{"total_number_of_episodes": 5657, "number_of_timesteps": 525371, "per_episode_reward": -305.12, "episode_reward_trend_value": 0.01782194224140817, "biggest_recent_change": 0.4780953552124174},
{"total_number_of_episodes": 5667, "number_of_timesteps": 526516, "per_episode_reward": -305.41, "episode_reward_trend_value": 0.013512646249427007, "biggest_recent_change": 0.4780953552124174},
{"total_number_of_episodes": 5677, "number_of_timesteps": 527735, "per_episode_reward": -305.31, "episode_reward_trend_value": 0.010847116830031684, "biggest_recent_change": 0.4780953552124174},
{"total_number_of_episodes": 5687, "number_of_timesteps": 528903, "per_episode_reward": -305.15, "episode_reward_trend_value": 0.007298648222364238, "biggest_recent_change": 0.2899333574748084},
{"total_number_of_episodes": 5697, "number_of_timesteps": 529967, "per_episode_reward": -305.02, "episode_reward_trend_value": 0.007264817369579962, "biggest_recent_change": 0.2899333574748084},
{"total_number_of_episodes": 5707, "number_of_timesteps": 531089, "per_episode_reward": -304.95, "episode_reward_trend_value": 0.0060963682215123705, "biggest_recent_change": 0.2899333574748084},
{"total_number_of_episodes": 5717, "number_of_timesteps": 532597, "per_episode_reward": -305.14, "episode_reward_trend_value": 0.006335407873012224, "biggest_recent_change": 0.2899333574748084},
{"total_number_of_episodes": 5727, "number_of_timesteps": 533550, "per_episode_reward": -305.14, "episode_reward_trend_value": 0.003887868319987496, "biggest_recent_change": 0.2899333574748084},
{"total_number_of_episodes": 5738, "number_of_timesteps": 534756, "per_episode_reward": -304.68, "episode_reward_trend_value": 0.007813603172969074, "biggest_recent_change": 0.4578311271257576},
{"total_number_of_episodes": 5748, "number_of_timesteps": 535742, "per_episode_reward": -304.46, "episode_reward_trend_value": 0.007331762131927791, "biggest_recent_change": 0.4578311271257576},
{"total_number_of_episodes": 5758, "number_of_timesteps": 536779, "per_episode_reward": -304.29, "episode_reward_trend_value": 0.012453562940032093, "biggest_recent_change": 0.4578311271257576},
{"total_number_of_episodes": 5770, "number_of_timesteps": 537929, "per_episode_reward": -303.79, "episode_reward_trend_value": 0.01684973942768061, "biggest_recent_change": 0.5009689286368371},
{"total_number_of_episodes": 5781, "number_of_timesteps": 538784, "per_episode_reward": -303.59, "episode_reward_trend_value": 0.017342267297458296, "biggest_recent_change": 0.5009689286368371},
{"total_number_of_episodes": 5791, "number_of_timesteps": 539749, "per_episode_reward": -303.33, "episode_reward_trend_value": 0.0186762615540052, "biggest_recent_change": 0.5009689286368371},
{"total_number_of_episodes": 5802, "number_of_timesteps": 540796, "per_episode_reward": -303.46, "episode_reward_trend_value": 0.016623405771671033, "biggest_recent_change": 0.5009689286368371},
{"total_number_of_episodes": 5812, "number_of_timesteps": 541779, "per_episode_reward": -303.21, "episode_reward_trend_value": 0.021468549078528236, "biggest_recent_change": 0.5009689286368371},
{"total_number_of_episodes": 5822, "number_of_timesteps": 542784, "per_episode_reward": -303.23, "episode_reward_trend_value": 0.02115572327611643, "biggest_recent_change": 0.5009689286368371},
{"total_number_of_episodes": 5833, "number_of_timesteps": 544124, "per_episode_reward": -303.5, "episode_reward_trend_value": 0.013143613331341283, "biggest_recent_change": 0.5009689286368371},
{"total_number_of_episodes": 5843, "number_of_timesteps": 545125, "per_episode_reward": -303.99, "episode_reward_trend_value": 0.005238617905177989, "biggest_recent_change": 0.5009689286368371},
{"total_number_of_episodes": 5853, "number_of_timesteps": 546099, "per_episode_reward": -304.37, "episode_reward_trend_value": -0.0008306708284067099, "biggest_recent_change": 0.5009689286368371},
{"total_number_of_episodes": 5864, "number_of_timesteps": 547339, "per_episode_reward": -304.74, "episode_reward_trend_value": -0.0105657026269916, "biggest_recent_change": 0.4969850490422232},
{"total_number_of_episodes": 5874, "number_of_timesteps": 548250, "per_episode_reward": -304.69, "episode_reward_trend_value": -0.01224981557821694, "biggest_recent_change": 0.4969850490422232},
{"total_number_of_episodes": 5884, "number_of_timesteps": 549319, "per_episode_reward": -304.66, "episode_reward_trend_value": -0.014733122433482196, "biggest_recent_change": 0.4969850490422232},
{"total_number_of_episodes": 5894, "number_of_timesteps": 550516, "per_episode_reward": -304.6, "episode_reward_trend_value": -0.012701963535219976, "biggest_recent_change": 0.4969850490422232},
{"total_number_of_episodes": 5905, "number_of_timesteps": 551594, "per_episode_reward": -304.47, "episode_reward_trend_value": -0.01401670151896105, "biggest_recent_change": 0.4969850490422232},
{"total_number_of_episodes": 5915, "number_of_timesteps": 552887, "per_episode_reward": -304.35, "episode_reward_trend_value": -0.012456177033585113, "biggest_recent_change": 0.4969850490422232},
{"total_number_of_episodes": 5925, "number_of_timesteps": 553870, "per_episode_reward": -304.29, "episode_reward_trend_value": -0.008814489445841091, "biggest_recent_change": 0.4969850490422232},
{"total_number_of_episodes": 5935, "number_of_timesteps": 554815, "per_episode_reward": -304.4, "episode_reward_trend_value": -0.0044906486903964074, "biggest_recent_change": 0.37520727076804405},
{"total_number_of_episodes": 5947, "number_of_timesteps": 555972, "per_episode_reward": -304.1, "episode_reward_trend_value": 0.0029696232772923594, "biggest_recent_change": 0.3751839332358031},
{"total_number_of_episodes": 5961, "number_of_timesteps": 557172, "per_episode_reward": -303.81, "episode_reward_trend_value": 0.01040561232540161, "biggest_recent_change": 0.296217206323945},
{"total_number_of_episodes": 5971, "number_of_timesteps": 558154, "per_episode_reward": -304.05, "episode_reward_trend_value": 0.007167968790330154, "biggest_recent_change": 0.296217206323945},
{"total_number_of_episodes": 5983, "number_of_timesteps": 559636, "per_episode_reward": -303.7, "episode_reward_trend_value": 0.010720504688243359, "biggest_recent_change": 0.3502638615941578},
{"total_number_of_episodes": 5993, "number_of_timesteps": 560747, "per_episode_reward": -303.87, "episode_reward_trend_value": 0.008118512624104016, "biggest_recent_change": 0.3502638615941578},
{"total_number_of_episodes": 6003, "number_of_timesteps": 561705, "per_episode_reward": -303.68, "episode_reward_trend_value": 0.008772748458956255, "biggest_recent_change": 0.3502638615941578},
{"total_number_of_episodes": 6013, "number_of_timesteps": 562802, "per_episode_reward": -303.53, "episode_reward_trend_value": 0.009141368932688465, "biggest_recent_change": 0.3502638615941578},
{"total_number_of_episodes": 6023, "number_of_timesteps": 563645, "per_episode_reward": -303.55, "episode_reward_trend_value": 0.008231233677040943, "biggest_recent_change": 0.3502638615941578},
{"total_number_of_episodes": 6033, "number_of_timesteps": 564370, "per_episode_reward": -303.39, "episode_reward_trend_value": 0.0112097744511598, "biggest_recent_change": 0.3502638615941578},
{"total_number_of_episodes": 6043, "number_of_timesteps": 565083, "per_episode_reward": -303.17, "episode_reward_trend_value": 0.010310309192474658, "biggest_recent_change": 0.3502638615941578},
{"total_number_of_episodes": 6053, "number_of_timesteps": 566027, "per_episode_reward": -302.79, "episode_reward_trend_value": 0.011281453998681298, "biggest_recent_change": 0.38145811365262716},
{"total_number_of_episodes": 6064, "number_of_timesteps": 567004, "per_episode_reward": -302.53, "episode_reward_trend_value": 0.01680173673534821, "biggest_recent_change": 0.38145811365262716},
{"total_number_of_episodes": 6075, "number_of_timesteps": 568396, "per_episode_reward": -302.21, "episode_reward_trend_value": 0.01653561708991068, "biggest_recent_change": 0.38145811365262716},
{"total_number_of_episodes": 6085, "number_of_timesteps": 569511, "per_episode_reward": -302.51, "episode_reward_trend_value": 0.015066250614888255, "biggest_recent_change": 0.38145811365262716},
{"total_number_of_episodes": 6095, "number_of_timesteps": 570401, "per_episode_reward": -302.28, "episode_reward_trend_value": 0.015619942203085834, "biggest_recent_change": 0.38145811365262716},
{"total_number_of_episodes": 6105, "number_of_timesteps": 571201, "per_episode_reward": -302.25, "episode_reward_trend_value": 0.01421897117424401, "biggest_recent_change": 0.38145811365262716},
{"total_number_of_episodes": 6115, "number_of_timesteps": 572246, "per_episode_reward": -302.07, "episode_reward_trend_value": 0.01641288399924608, "biggest_recent_change": 0.38145811365262716},
{"total_number_of_episodes": 6126, "number_of_timesteps": 573611, "per_episode_reward": -302.4, "episode_reward_trend_value": 0.010941394244921791, "biggest_recent_change": 0.38145811365262716},
{"total_number_of_episodes": 6136, "number_of_timesteps": 574732, "per_episode_reward": -302.52, "episode_reward_trend_value": 0.007218101742356946, "biggest_recent_change": 0.38145811365262716},
{"total_number_of_episodes": 6146, "number_of_timesteps": 575891, "per_episode_reward": -302.36, "episode_reward_trend_value": 0.004756137157814541, "biggest_recent_change": 0.3322047892706905},
{"total_number_of_episodes": 6156, "number_of_timesteps": 577100, "per_episode_reward": -302.33, "episode_reward_trend_value": 0.0022551393390187967, "biggest_recent_change": 0.3322047892706905},
{"total_number_of_episodes": 6166, "number_of_timesteps": 578392, "per_episode_reward": -302.26, "episode_reward_trend_value": -0.0005942434496445357, "biggest_recent_change": 0.3322047892706905},
{"total_number_of_episodes": 6176, "number_of_timesteps": 579530, "per_episode_reward": -302.26, "episode_reward_trend_value": 0.002764011069072896, "biggest_recent_change": 0.3322047892706905},
{"total_number_of_episodes": 6187, "number_of_timesteps": 581028, "per_episode_reward": -302.29, "episode_reward_trend_value": -0.00013651834217145938, "biggest_recent_change": 0.3322047892706905},
{"total_number_of_episodes": 6198, "number_of_timesteps": 582096, "per_episode_reward": -302.07, "episode_reward_trend_value": 0.0020234251335668634, "biggest_recent_change": 0.3322047892706905},
{"total_number_of_episodes": 6209, "number_of_timesteps": 583385, "per_episode_reward": -301.96, "episode_reward_trend_value": 0.0012601350271514396, "biggest_recent_change": 0.3322047892706905},
{"total_number_of_episodes": 6220, "number_of_timesteps": 584711, "per_episode_reward": -302.09, "episode_reward_trend_value": 0.00346501695158218, "biggest_recent_change": 0.22094038086828505},
{"total_number_of_episodes": 6230, "number_of_timesteps": 585708, "per_episode_reward": -302.35, "episode_reward_trend_value": 0.0019492277389714572, "biggest_recent_change": 0.2562520213235189},
{"total_number_of_episodes": 6240, "number_of_timesteps": 586644, "per_episode_reward": -302.42, "episode_reward_trend_value": -0.0006821662303991616, "biggest_recent_change": 0.2562520213235189},
{"total_number_of_episodes": 6250, "number_of_timesteps": 587539, "per_episode_reward": -302.41, "episode_reward_trend_value": -0.0009280124361225716, "biggest_recent_change": 0.2562520213235189},
{"total_number_of_episodes": 6261, "number_of_timesteps": 588467, "per_episode_reward": -302.42, "episode_reward_trend_value": -0.0017656227222251648, "biggest_recent_change": 0.2562520213235189},
{"total_number_of_episodes": 6271, "number_of_timesteps": 589642, "per_episode_reward": -302.34, "episode_reward_trend_value": -0.0008871073785333769, "biggest_recent_change": 0.2562520213235189},
{"total_number_of_episodes": 6281, "number_of_timesteps": 590956, "per_episode_reward": -302.41, "episode_reward_trend_value": -0.0013308810288359988, "biggest_recent_change": 0.2562520213235189},
{"total_number_of_episodes": 6292, "number_of_timesteps": 592161, "per_episode_reward": -302.22, "episode_reward_trend_value": -0.0017250804654698488, "biggest_recent_change": 0.2562520213235189},
{"total_number_of_episodes": 6303, "number_of_timesteps": 593083, "per_episode_reward": -301.92, "episode_reward_trend_value": 0.0004678172022863691, "biggest_recent_change": 0.3086977767555368},
{"total_number_of_episodes": 6314, "number_of_timesteps": 594118, "per_episode_reward": -301.53, "episode_reward_trend_value": 0.006248243389797558, "biggest_recent_change": 0.386472940804083},
{"total_number_of_episodes": 6324, "number_of_timesteps": 595299, "per_episode_reward": -301.79, "episode_reward_trend_value": 0.006143220783518347, "biggest_recent_change": 0.386472940804083},
{"total_number_of_episodes": 6335, "number_of_timesteps": 596535, "per_episode_reward": -301.73, "episode_reward_trend_value": 0.0076904137516212116, "biggest_recent_change": 0.386472940804083},
{"total_number_of_episodes": 6345, "number_of_timesteps": 597408, "per_episode_reward": -301.68, "episode_reward_trend_value": 0.008178514606873933, "biggest_recent_change": 0.386472940804083},
{"total_number_of_episodes": 6355, "number_of_timesteps": 598428, "per_episode_reward": -301.99, "episode_reward_trend_value": 0.004752278141198632, "biggest_recent_change": 0.386472940804083},
{"total_number_of_episodes": 6365, "number_of_timesteps": 599512, "per_episode_reward": -302.09, "episode_reward_trend_value": 0.0028363642708680143, "biggest_recent_change": 0.386472940804083},
{"total_number_of_episodes": 6375, "number_of_timesteps": 600396, "per_episode_reward": -302.33, "episode_reward_trend_value": 0.0009195881162087163, "biggest_recent_change": 0.386472940804083},
{"total_number_of_episodes": 6386, "number_of_timesteps": 601597, "per_episode_reward": -302.3, "episode_reward_trend_value": -0.0008334447257355906, "biggest_recent_change": 0.386472940804083},
{"total_number_of_episodes": 6396, "number_of_timesteps": 602614, "per_episode_reward": -302.13, "episode_reward_trend_value": -0.002432306289260093, "biggest_recent_change": 0.386472940804083},
{"total_number_of_episodes": 6407, "number_of_timesteps": 603542, "per_episode_reward": -302.02, "episode_reward_trend_value": -0.005515088562735097, "biggest_recent_change": 0.3138775651349306},
{"total_number_of_episodes": 6417, "number_of_timesteps": 604473, "per_episode_reward": -302.07, "episode_reward_trend_value": -0.0030408994111471403, "biggest_recent_change": 0.3138775651349306},
{"total_number_of_episodes": 6427, "number_of_timesteps": 605493, "per_episode_reward": -301.66, "episode_reward_trend_value": 0.0007708388918653479, "biggest_recent_change": 0.40535965820083675},
{"total_number_of_episodes": 6437, "number_of_timesteps": 606618, "per_episode_reward": -301.91, "episode_reward_trend_value": -0.002608348268857223, "biggest_recent_change": 0.40535965820083675},
{"total_number_of_episodes": 6448, "number_of_timesteps": 607768, "per_episode_reward": -301.81, "episode_reward_trend_value": 0.0019947413545903852, "biggest_recent_change": 0.40535965820083675},
{"total_number_of_episodes": 6459, "number_of_timesteps": 609021, "per_episode_reward": -301.67, "episode_reward_trend_value": 0.004674424525644048, "biggest_recent_change": 0.40535965820083675},
{"total_number_of_episodes": 6469, "number_of_timesteps": 610098, "per_episode_reward": -301.82, "episode_reward_trend_value": 0.005584115746453714, "biggest_recent_change": 0.40535965820083675},
{"total_number_of_episodes": 6480, "number_of_timesteps": 611667, "per_episode_reward": -302.02, "episode_reward_trend_value": 0.003047816216926296, "biggest_recent_change": 0.40535965820083675},
{"total_number_of_episodes": 6490, "number_of_timesteps": 612589, "per_episode_reward": -301.92, "episode_reward_trend_value": 0.002387987109076069, "biggest_recent_change": 0.40535965820083675},
{"total_number_of_episodes": 6501, "number_of_timesteps": 613826, "per_episode_reward": -301.98, "episode_reward_trend_value": 0.00047233213786120764, "biggest_recent_change": 0.40535965820083675},
{"total_number_of_episodes": 6511, "number_of_timesteps": 614998, "per_episode_reward": -301.96, "episode_reward_trend_value": 0.0011614292953109069, "biggest_recent_change": 0.40535965820083675},
{"total_number_of_episodes": 6522, "number_of_timesteps": 615971, "per_episode_reward": -301.84, "episode_reward_trend_value": -0.0019568057189151963, "biggest_recent_change": 0.25048567836336133},
{"total_number_of_episodes": 6532, "number_of_timesteps": 616969, "per_episode_reward": -301.8, "episode_reward_trend_value": 0.001307095946233024, "biggest_recent_change": 0.2005774818612167},
{"total_number_of_episodes": 6542, "number_of_timesteps": 618327, "per_episode_reward": -301.95, "episode_reward_trend_value": -0.0014986837520451798, "biggest_recent_change": 0.2005774818612167},
{"total_number_of_episodes": 6552, "number_of_timesteps": 619228, "per_episode_reward": -301.71, "episode_reward_trend_value": -0.0004225227962257981, "biggest_recent_change": 0.24101814903957575},
{"total_number_of_episodes": 6562, "number_of_timesteps": 620247, "per_episode_reward": -301.62, "episode_reward_trend_value": 0.002267127078968972, "biggest_recent_change": 0.24101814903957575},
{"total_number_of_episodes": 6572, "number_of_timesteps": 621308, "per_episode_reward": -301.5, "episode_reward_trend_value": 0.005848203631296024, "biggest_recent_change": 0.24101814903957575},
{"total_number_of_episodes": 6582, "number_of_timesteps": 622192, "per_episode_reward": -301.6, "episode_reward_trend_value": 0.003546961587785012, "biggest_recent_change": 0.24101814903957575},
{"total_number_of_episodes": 6592, "number_of_timesteps": 622935, "per_episode_reward": -301.73, "episode_reward_trend_value": 0.0027832932662432896, "biggest_recent_change": 0.24101814903957575},
{"total_number_of_episodes": 6602, "number_of_timesteps": 623807, "per_episode_reward": -301.92, "episode_reward_trend_value": 0.0004746401988572618, "biggest_recent_change": 0.24101814903957575},
{"total_number_of_episodes": 6614, "number_of_timesteps": 624664, "per_episode_reward": -301.86, "episode_reward_trend_value": -0.00020237873071285626, "biggest_recent_change": 0.24101814903957575},
{"total_number_of_episodes": 6625, "number_of_timesteps": 625418, "per_episode_reward": -301.97, "episode_reward_trend_value": -0.00190658208131822, "biggest_recent_change": 0.24101814903957575},
{"total_number_of_episodes": 6635, "number_of_timesteps": 626238, "per_episode_reward": -301.85, "episode_reward_trend_value": 0.001130644065537783, "biggest_recent_change": 0.24101814903957575},
{"total_number_of_episodes": 6645, "number_of_timesteps": 627103, "per_episode_reward": -301.48, "episode_reward_trend_value": 0.0024704081609583125, "biggest_recent_change": 0.3615969176274234},
{"total_number_of_episodes": 6655, "number_of_timesteps": 627917, "per_episode_reward": -301.17, "episode_reward_trend_value": 0.005000518672974547, "biggest_recent_change": 0.3615969176274234},
{"total_number_of_episodes": 6666, "number_of_timesteps": 628970, "per_episode_reward": -300.99, "episode_reward_trend_value": 0.005695871872354196, "biggest_recent_change": 0.3615969176274234},
{"total_number_of_episodes": 6676, "number_of_timesteps": 630323, "per_episode_reward": -301.13, "episode_reward_trend_value": 0.005225474729643212, "biggest_recent_change": 0.3615969176274234},
{"total_number_of_episodes": 6687, "number_of_timesteps": 631680, "per_episode_reward": -301.08, "episode_reward_trend_value": 0.007259977292045505, "biggest_recent_change": 0.3615969176274234},
{"total_number_of_episodes": 6697, "number_of_timesteps": 632914, "per_episode_reward": -300.91, "episode_reward_trend_value": 0.011185454429088774, "biggest_recent_change": 0.3615969176274234},
{"total_number_of_episodes": 6707, "number_of_timesteps": 634131, "per_episode_reward": -300.82, "episode_reward_trend_value": 0.011475866716945877, "biggest_recent_change": 0.3615969176274234},
{"total_number_of_episodes": 6717, "number_of_timesteps": 635445, "per_episode_reward": -301.01, "episode_reward_trend_value": 0.010629091966114857, "biggest_recent_change": 0.3615969176274234},
{"total_number_of_episodes": 6728, "number_of_timesteps": 636614, "per_episode_reward": -301.51, "episode_reward_trend_value": 0.0037101999414681413, "biggest_recent_change": 0.5014696008708484},
{"total_number_of_episodes": 6738, "number_of_timesteps": 637557, "per_episode_reward": -301.61, "episode_reward_trend_value": -0.0014482782544910657, "biggest_recent_change": 0.5014696008708484},
{"total_number_of_episodes": 6748, "number_of_timesteps": 638525, "per_episode_reward": -301.89, "episode_reward_trend_value": -0.007996452649841659, "biggest_recent_change": 0.5014696008708484},
{"total_number_of_episodes": 6758, "number_of_timesteps": 639583, "per_episode_reward": -301.9, "episode_reward_trend_value": -0.010193493180870898, "biggest_recent_change": 0.5014696008708484},
{"total_number_of_episodes": 6768, "number_of_timesteps": 640936, "per_episode_reward": -301.75, "episode_reward_trend_value": -0.006886963933015977, "biggest_recent_change": 0.5014696008708484},
{"total_number_of_episodes": 6778, "number_of_timesteps": 642495, "per_episode_reward": -301.71, "episode_reward_trend_value": -0.007065381548897499, "biggest_recent_change": 0.5014696008708484},
{"total_number_of_episodes": 6788, "number_of_timesteps": 643292, "per_episode_reward": -301.44, "episode_reward_trend_value": -0.005840981439572109, "biggest_recent_change": 0.5014696008708484},
{"total_number_of_episodes": 6798, "number_of_timesteps": 644178, "per_episode_reward": -301.12, "episode_reward_trend_value": -0.0032648912008002955, "biggest_recent_change": 0.5014696008708484},
{"total_number_of_episodes": 6808, "number_of_timesteps": 645146, "per_episode_reward": -301.02, "episode_reward_trend_value": -7.991613223781416e-05, "biggest_recent_change": 0.5014696008708484},
{"total_number_of_episodes": 6821, "number_of_timesteps": 646369, "per_episode_reward": -301.24, "episode_reward_trend_value": 0.003038954124956364, "biggest_recent_change": 0.3217720306557794},
{"total_number_of_episodes": 6832, "number_of_timesteps": 647405, "per_episode_reward": -301.29, "episode_reward_trend_value": 0.003641123815864628, "biggest_recent_change": 0.3217720306557794},
{"total_number_of_episodes": 6844, "number_of_timesteps": 648643, "per_episode_reward": -301.09, "episode_reward_trend_value": 0.008839443146382565, "biggest_recent_change": 0.3217720306557794},
{"total_number_of_episodes": 6854, "number_of_timesteps": 649640, "per_episode_reward": -300.72, "episode_reward_trend_value": 0.013094463340399898, "biggest_recent_change": 0.3695193654613149},
{"total_number_of_episodes": 6865, "number_of_timesteps": 650990, "per_episode_reward": -300.73, "episode_reward_trend_value": 0.011368678225987121, "biggest_recent_change": 0.3695193654613149},
{"total_number_of_episodes": 6877, "number_of_timesteps": 652610, "per_episode_reward": -300.56, "episode_reward_trend_value": 0.012775420671205337, "biggest_recent_change": 0.3695193654613149},
{"total_number_of_episodes": 6887, "number_of_timesteps": 653516, "per_episode_reward": -300.57, "episode_reward_trend_value": 0.009682307202218807, "biggest_recent_change": 0.3695193654613149},
{"total_number_of_episodes": 6897, "number_of_timesteps": 654297, "per_episode_reward": -300.55, "episode_reward_trend_value": 0.006332187989228385, "biggest_recent_change": 0.3695193654613149},
{"total_number_of_episodes": 6909, "number_of_timesteps": 655456, "per_episode_reward": -299.81, "episode_reward_trend_value": 0.013449592862869193, "biggest_recent_change": 0.7408916371689998},
{"total_number_of_episodes": 6919, "number_of_timesteps": 656438, "per_episode_reward": -299.75, "episode_reward_trend_value": 0.016534078032195035, "biggest_recent_change": 0.7408916371689998},
{"total_number_of_episodes": 6929, "number_of_timesteps": 657399, "per_episode_reward": -299.94, "episode_reward_trend_value": 0.014918276286368205, "biggest_recent_change": 0.7408916371689998},
{"total_number_of_episodes": 6939, "number_of_timesteps": 658650, "per_episode_reward": -300.11, "episode_reward_trend_value": 0.010966409072163213, "biggest_recent_change": 0.7408916371689998},
{"total_number_of_episodes": 6950, "number_of_timesteps": 659873, "per_episode_reward": -300.02, "episode_reward_trend_value": 0.007771448564871737, "biggest_recent_change": 0.7408916371689998},
{"total_number_of_episodes": 6961, "number_of_timesteps": 660986, "per_episode_reward": -300.39, "episode_reward_trend_value": 0.0037122841693777294, "biggest_recent_change": 0.7408916371689998},
{"total_number_of_episodes": 6971, "number_of_timesteps": 662006, "per_episode_reward": -300.17, "episode_reward_trend_value": 0.004373178019690411, "biggest_recent_change": 0.7408916371689998},
{"total_number_of_episodes": 6981, "number_of_timesteps": 663251, "per_episode_reward": -300.3, "episode_reward_trend_value": 0.0030117677511889776, "biggest_recent_change": 0.7408916371689998},
{"total_number_of_episodes": 6991, "number_of_timesteps": 664137, "per_episode_reward": -300.38, "episode_reward_trend_value": 0.0018746258149058628, "biggest_recent_change": 0.7408916371689998},
{"total_number_of_episodes": 7001, "number_of_timesteps": 664976, "per_episode_reward": -300.69, "episode_reward_trend_value": -0.0098242489932962, "biggest_recent_change": 0.3670897340128363},
{"total_number_of_episodes": 7011, "number_of_timesteps": 666137, "per_episode_reward": -300.75, "episode_reward_trend_value": -0.011062919474094064, "biggest_recent_change": 0.3670897340128363},
{"total_number_of_episodes": 7022, "number_of_timesteps": 667202, "per_episode_reward": -300.66, "episode_reward_trend_value": -0.007966223908159816, "biggest_recent_change": 0.3670897340128363},
{"total_number_of_episodes": 7033, "number_of_timesteps": 668418, "per_episode_reward": -300.87, "episode_reward_trend_value": -0.008523281575882417, "biggest_recent_change": 0.3670897340128363},
{"total_number_of_episodes": 7043, "number_of_timesteps": 669532, "per_episode_reward": -301.16, "episode_reward_trend_value": -0.012601883275280872, "biggest_recent_change": 0.3670897340128363},
{"total_number_of_episodes": 7053, "number_of_timesteps": 670604, "per_episode_reward": -301.59, "episode_reward_trend_value": -0.0133220082908205, "biggest_recent_change": 0.43190098541140287},
{"total_number_of_episodes": 7063, "number_of_timesteps": 671573, "per_episode_reward": -301.23, "episode_reward_trend_value": -0.011736879300624675, "biggest_recent_change": 0.43190098541140287},
{"total_number_of_episodes": 7074, "number_of_timesteps": 672746, "per_episode_reward": -301.0, "episode_reward_trend_value": -0.007862841796752996, "biggest_recent_change": 0.43190098541140287},
{"total_number_of_episodes": 7084, "number_of_timesteps": 673720, "per_episode_reward": -301.01, "episode_reward_trend_value": -0.007014360686508149, "biggest_recent_change": 0.43190098541140287},
{"total_number_of_episodes": 7094, "number_of_timesteps": 674668, "per_episode_reward": -300.94, "episode_reward_trend_value": -0.0027673552371930378, "biggest_recent_change": 0.43190098541140287},
{"total_number_of_episodes": 7105, "number_of_timesteps": 675970, "per_episode_reward": -301.07, "episode_reward_trend_value": -0.0035924959557841396, "biggest_recent_change": 0.43190098541140287},
{"total_number_of_episodes": 7115, "number_of_timesteps": 676805, "per_episode_reward": -300.93, "episode_reward_trend_value": -0.0029370912224648137, "biggest_recent_change": 0.43190098541140287},
{"total_number_of_episodes": 7126, "number_of_timesteps": 677766, "per_episode_reward": -300.89, "episode_reward_trend_value": -0.00016019502184134478, "biggest_recent_change": 0.43190098541140287},
{"total_number_of_episodes": 7136, "number_of_timesteps": 678709, "per_episode_reward": -301.09, "episode_reward_trend_value": 0.0008043854856212975, "biggest_recent_change": 0.43190098541140287},
{"total_number_of_episodes": 7146, "number_of_timesteps": 679616, "per_episode_reward": -301.63, "episode_reward_trend_value": -0.00046034235790304794, "biggest_recent_change": 0.545726491328594},
{"total_number_of_episodes": 7156, "number_of_timesteps": 680502, "per_episode_reward": -301.95, "episode_reward_trend_value": -0.008034501242128853, "biggest_recent_change": 0.545726491328594},

{"total_number_of_episodes": 7166, "number_of_timesteps": 681375, "per_episode_reward": -302.19, "episode_reward_trend_value": -0.013148674784304782, "biggest_recent_change": 0.545726491328594},
{"total_number_of_episodes": 7177, "number_of_timesteps": 682244, "per_episode_reward": -302.28, "episode_reward_trend_value": -0.014139997133875998, "biggest_recent_change": 0.545726491328594},
{"total_number_of_episodes": 7189, "number_of_timesteps": 683100, "per_episode_reward": -302.39, "episode_reward_trend_value": -0.01612933312356151, "biggest_recent_change": 0.545726491328594},
{"total_number_of_episodes": 7199, "number_of_timesteps": 683869, "per_episode_reward": -302.52, "episode_reward_trend_value": -0.016169720871998076, "biggest_recent_change": 0.545726491328594},
{"total_number_of_episodes": 7210, "number_of_timesteps": 684696, "per_episode_reward": -302.6, "episode_reward_trend_value": -0.018641335140472393, "biggest_recent_change": 0.545726491328594},
{"total_number_of_episodes": 7220, "number_of_timesteps": 685560, "per_episode_reward": -302.7, "episode_reward_trend_value": -0.020133624267343622, "biggest_recent_change": 0.545726491328594},
{"total_number_of_episodes": 7230, "number_of_timesteps": 686482, "per_episode_reward": -302.81, "episode_reward_trend_value": -0.019181518435545462, "biggest_recent_change": 0.545726491328594},
{"total_number_of_episodes": 7240, "number_of_timesteps": 687568, "per_episode_reward": -302.88, "episode_reward_trend_value": -0.013860177081292908, "biggest_recent_change": 0.3179943388348079},
{"total_number_of_episodes": 7250, "number_of_timesteps": 688488, "per_episode_reward": -302.82, "episode_reward_trend_value": -0.009682216882575607, "biggest_recent_change": 0.23781749178812106},
{"total_number_of_episodes": 7262, "number_of_timesteps": 689511, "per_episode_reward": -302.61, "episode_reward_trend_value": -0.004712804927387045, "biggest_recent_change": 0.20942958417884938},
{"total_number_of_episodes": 7272, "number_of_timesteps": 690439, "per_episode_reward": -302.56, "episode_reward_trend_value": -0.0030674190609955884, "biggest_recent_change": 0.20942958417884938},
{"total_number_of_episodes": 7282, "number_of_timesteps": 691432, "per_episode_reward": -302.54, "episode_reward_trend_value": -0.0016937884030205116, "biggest_recent_change": 0.20942958417884938},
{"total_number_of_episodes": 7292, "number_of_timesteps": 692249, "per_episode_reward": -302.11, "episode_reward_trend_value": 0.0046067720099402885, "biggest_recent_change": 0.43450491937812785},
{"total_number_of_episodes": 7303, "number_of_timesteps": 693353, "per_episode_reward": -301.89, "episode_reward_trend_value": 0.007885645987479645, "biggest_recent_change": 0.43450491937812785},
{"total_number_of_episodes": 7313, "number_of_timesteps": 694325, "per_episode_reward": -301.64, "episode_reward_trend_value": 0.011752739093143798, "biggest_recent_change": 0.43450491937812785},
{"total_number_of_episodes": 7326, "number_of_timesteps": 695657, "per_episode_reward": -301.44, "episode_reward_trend_value": 0.01521145800906475, "biggest_recent_change": 0.43450491937812785},
{"total_number_of_episodes": 7336, "number_of_timesteps": 696597, "per_episode_reward": -301.3, "episode_reward_trend_value": 0.01756349585624106, "biggest_recent_change": 0.43450491937812785},
{"total_number_of_episodes": 7347, "number_of_timesteps": 697758, "per_episode_reward": -301.42, "episode_reward_trend_value": 0.015623823056730796, "biggest_recent_change": 0.43450491937812785},
{"total_number_of_episodes": 7357, "number_of_timesteps": 698796, "per_episode_reward": -301.11, "episode_reward_trend_value": 0.016674145110070843, "biggest_recent_change": 0.43450491937812785},
{"total_number_of_episodes": 7367, "number_of_timesteps": 700062, "per_episode_reward": -301.3, "episode_reward_trend_value": 0.013937509233169798, "biggest_recent_change": 0.43450491937812785},
{"total_number_of_episodes": 7377, "number_of_timesteps": 701096, "per_episode_reward": -301.2, "episode_reward_trend_value": 0.014983055462286326, "biggest_recent_change": 0.43450491937812785},
{"total_number_of_episodes": 7387, "number_of_timesteps": 702214, "per_episode_reward": -301.01, "episode_reward_trend_value": 0.0122587065071899, "biggest_recent_change": 0.3039585689794535},
{"total_number_of_episodes": 7397, "number_of_timesteps": 703218, "per_episode_reward": -301.33, "episode_reward_trend_value": 0.006302438914231818, "biggest_recent_change": 0.31961468756912836},
{"total_number_of_episodes": 7408, "number_of_timesteps": 704727, "per_episode_reward": -301.22, "episode_reward_trend_value": 0.004706716806263481, "biggest_recent_change": 0.31961468756912836},
{"total_number_of_episodes": 7418, "number_of_timesteps": 706072, "per_episode_reward": -301.12, "episode_reward_trend_value": 0.0036236494246837643, "biggest_recent_change": 0.31961468756912836},
{"total_number_of_episodes": 7430, "number_of_timesteps": 707346, "per_episode_reward": -300.9, "episode_reward_trend_value": 0.004457606275351762, "biggest_recent_change": 0.31961468756912836},
{"total_number_of_episodes": 7441, "number_of_timesteps": 708192, "per_episode_reward": -300.61, "episode_reward_trend_value": 0.008951137941999655, "biggest_recent_change": 0.31961468756912836},
{"total_number_of_episodes": 7452, "number_of_timesteps": 709080, "per_episode_reward": -300.37, "episode_reward_trend_value": 0.008241810296306716, "biggest_recent_change": 0.31961468756912836},
{"total_number_of_episodes": 7462, "number_of_timesteps": 709840, "per_episode_reward": -300.21, "episode_reward_trend_value": 0.012137288539322652, "biggest_recent_change": 0.31961468756912836},
{"total_number_of_episodes": 7472, "number_of_timesteps": 711127, "per_episode_reward": -300.22, "episode_reward_trend_value": 0.010809499312523485, "biggest_recent_change": 0.31961468756912836},
{"total_number_of_episodes": 7482, "number_of_timesteps": 712260, "per_episode_reward": -300.09, "episode_reward_trend_value": 0.010154899710092497, "biggest_recent_change": 0.31961468756912836},
{"total_number_of_episodes": 7492, "number_of_timesteps": 713354, "per_episode_reward": -300.03, "episode_reward_trend_value": 0.014402633114681545, "biggest_recent_change": 0.2878693770921359},
{"total_number_of_episodes": 7502, "number_of_timesteps": 714456, "per_episode_reward": -299.92, "episode_reward_trend_value": 0.014421550592092242, "biggest_recent_change": 0.2878693770921359},
{"total_number_of_episodes": 7512, "number_of_timesteps": 715406, "per_episode_reward": -299.99, "episode_reward_trend_value": 0.012521880654383543, "biggest_recent_change": 0.2878693770921359},
{"total_number_of_episodes": 7522, "number_of_timesteps": 716320, "per_episode_reward": -299.95, "episode_reward_trend_value": 0.010524904031779494, "biggest_recent_change": 0.2878693770921359},
{"total_number_of_episodes": 7532, "number_of_timesteps": 717491, "per_episode_reward": -299.79, "episode_reward_trend_value": 0.009132855965936592, "biggest_recent_change": 0.240119080867089},
{"total_number_of_episodes": 7542, "number_of_timesteps": 718616, "per_episode_reward": -299.59, "episode_reward_trend_value": 0.008717954406965116, "biggest_recent_change": 0.20277794055965614},
{"total_number_of_episodes": 7552, "number_of_timesteps": 719554, "per_episode_reward": -299.56, "episode_reward_trend_value": 0.007242224585560406, "biggest_recent_change": 0.20277794055965614},
{"total_number_of_episodes": 7562, "number_of_timesteps": 720344, "per_episode_reward": -299.44, "episode_reward_trend_value": 0.008694567667003463, "biggest_recent_change": 0.20277794055965614},
{"total_number_of_episodes": 7572, "number_of_timesteps": 721219, "per_episode_reward": -299.32, "episode_reward_trend_value": 0.008635511348673693, "biggest_recent_change": 0.20277794055965614},
{"total_number_of_episodes": 7582, "number_of_timesteps": 722163, "per_episode_reward": -299.06, "episode_reward_trend_value": 0.010795711776628043, "biggest_recent_change": 0.2570993573597775},
{"total_number_of_episodes": 7592, "number_of_timesteps": 723118, "per_episode_reward": -298.84, "episode_reward_trend_value": 0.012025909010191072, "biggest_recent_change": 0.2570993573597775},
{"total_number_of_episodes": 7602, "number_of_timesteps": 724074, "per_episode_reward": -298.7, "episode_reward_trend_value": 0.014349608484930818, "biggest_recent_change": 0.2570993573597775},
{"total_number_of_episodes": 7613, "number_of_timesteps": 725342, "per_episode_reward": -298.87, "episode_reward_trend_value": 0.01204806995092819, "biggest_recent_change": 0.2570993573597775},
{"total_number_of_episodes": 7623, "number_of_timesteps": 726519, "per_episode_reward": -298.73, "episode_reward_trend_value": 0.011785830790209199, "biggest_recent_change": 0.2570993573597775},
{"total_number_of_episodes": 7635, "number_of_timesteps": 728097, "per_episode_reward": -298.81, "episode_reward_trend_value": 0.008578181635606875, "biggest_recent_change": 0.2570993573597775},
{"total_number_of_episodes": 7646, "number_of_timesteps": 729073, "per_episode_reward": -299.08, "episode_reward_trend_value": 0.005313872148406694, "biggest_recent_change": 0.26916018116708074},
{"total_number_of_episodes": 7656, "number_of_timesteps": 730217, "per_episode_reward": -299.15, "episode_reward_trend_value": 0.0032024958051465545, "biggest_recent_change": 0.26916018116708074},
{"total_number_of_episodes": 7668, "number_of_timesteps": 731550, "per_episode_reward": -299.13, "episode_reward_trend_value": 0.0020299334540223096, "biggest_recent_change": 0.26916018116708074},
{"total_number_of_episodes": 7678, "number_of_timesteps": 732370, "per_episode_reward": -298.94, "episode_reward_trend_value": 0.0012827125067227977, "biggest_recent_change": 0.26916018116708074},
{"total_number_of_episodes": 7688, "number_of_timesteps": 733211, "per_episode_reward": -298.68, "episode_reward_trend_value": 0.0017469331416003168, "biggest_recent_change": 0.26916018116708074},
{"total_number_of_episodes": 7698, "number_of_timesteps": 734144, "per_episode_reward": -298.59, "episode_reward_trend_value": 0.0012029040539592493, "biggest_recent_change": 0.26916018116708074},
{"total_number_of_episodes": 7709, "number_of_timesteps": 735067, "per_episode_reward": -298.6, "episode_reward_trend_value": 0.002940967343765679, "biggest_recent_change": 0.26916018116708074},
{"total_number_of_episodes": 7721, "number_of_timesteps": 736018, "per_episode_reward": -298.53, "episode_reward_trend_value": 0.0021953010496714694, "biggest_recent_change": 0.26916018116708074},
{"total_number_of_episodes": 7731, "number_of_timesteps": 736891, "per_episode_reward": -298.46, "episode_reward_trend_value": 0.003887088037417167, "biggest_recent_change": 0.26916018116708074},
{"total_number_of_episodes": 7741, "number_of_timesteps": 737817, "per_episode_reward": -298.66, "episode_reward_trend_value": 0.004691962658541292, "biggest_recent_change": 0.2613735047694945},
{"total_number_of_episodes": 7751, "number_of_timesteps": 739609, "per_episode_reward": -298.68, "episode_reward_trend_value": 0.005193990168961212, "biggest_recent_change": 0.2613735047694945},
{"total_number_of_episodes": 7762, "number_of_timesteps": 740914, "per_episode_reward": -298.78, "episode_reward_trend_value": 0.003963388592841158, "biggest_recent_change": 0.2613735047694945},
{"total_number_of_episodes": 7772, "number_of_timesteps": 742113, "per_episode_reward": -298.65, "episode_reward_trend_value": 0.003279647912053937, "biggest_recent_change": 0.2613735047694945},
{"total_number_of_episodes": 7783, "number_of_timesteps": 743177, "per_episode_reward": -298.49, "episode_reward_trend_value": 0.002105559267321016, "biggest_recent_change": 0.1967214652659095},
{"total_number_of_episodes": 7793, "number_of_timesteps": 744367, "per_episode_reward": -298.31, "episode_reward_trend_value": 0.00310411019042552, "biggest_recent_change": 0.1967214652659095},
{"total_number_of_episodes": 7804, "number_of_timesteps": 745513, "per_episode_reward": -298.16, "episode_reward_trend_value": 0.004868912837350889, "biggest_recent_change": 0.1967214652659095},
{"total_number_of_episodes": 7814, "number_of_timesteps": 746431, "per_episode_reward": -297.75, "episode_reward_trend_value": 0.00864982047125851, "biggest_recent_change": 0.4121552472847725},
{"total_number_of_episodes": 7824, "number_of_timesteps": 747371, "per_episode_reward": -297.43, "episode_reward_trend_value": 0.011466863259204273, "biggest_recent_change": 0.4121552472847725},
{"total_number_of_episodes": 7836, "number_of_timesteps": 748753, "per_episode_reward": -297.06, "episode_reward_trend_value": 0.01777235534454841, "biggest_recent_change": 0.4121552472847725},
{"total_number_of_episodes": 7846, "number_of_timesteps": 749887, "per_episode_reward": -296.9, "episode_reward_trend_value": 0.019850551161403652, "biggest_recent_change": 0.4121552472847725},
{"total_number_of_episodes": 7858, "number_of_timesteps": 751363, "per_episode_reward": -296.9, "episode_reward_trend_value": 0.020848701352966577, "biggest_recent_change": 0.4121552472847725},
{"total_number_of_episodes": 7869, "number_of_timesteps": 752232, "per_episode_reward": -296.66, "episode_reward_trend_value": 0.0220902290448502, "biggest_recent_change": 0.4121552472847725},
{"total_number_of_episodes": 7879, "number_of_timesteps": 752982, "per_episode_reward": -296.69, "episode_reward_trend_value": 0.019971529999385337, "biggest_recent_change": 0.4121552472847725},
{"total_number_of_episodes": 7889, "number_of_timesteps": 753785, "per_episode_reward": -296.56, "episode_reward_trend_value": 0.01945515959095335, "biggest_recent_change": 0.4121552472847725},
{"total_number_of_episodes": 7899, "number_of_timesteps": 754733, "per_episode_reward": -296.27, "episode_reward_trend_value": 0.020991191469875048, "biggest_recent_change": 0.4121552472847725},
{"total_number_of_episodes": 7909, "number_of_timesteps": 755829, "per_episode_reward": -296.36, "episode_reward_trend_value": 0.015486156806155626, "biggest_recent_change": 0.3707728224150628},
{"total_number_of_episodes": 7919, "number_of_timesteps": 756896, "per_episode_reward": -296.23, "episode_reward_trend_value": 0.013362997022095317, "biggest_recent_change": 0.3707728224150628},
{"total_number_of_episodes": 7929, "number_of_timesteps": 757833, "per_episode_reward": -296.07, "episode_reward_trend_value": 0.010961400995677195, "biggest_recent_change": 0.28656819267433775},
{"total_number_of_episodes": 7940, "number_of_timesteps": 758992, "per_episode_reward": -296.02, "episode_reward_trend_value": 0.009761356053736058, "biggest_recent_change": 0.28656819267433775},
{"total_number_of_episodes": 7952, "number_of_timesteps": 760243, "per_episode_reward": -295.94, "episode_reward_trend_value": 0.0106764883924086, "biggest_recent_change": 0.28656819267433775},
{"total_number_of_episodes": 7963, "number_of_timesteps": 761284, "per_episode_reward": -295.86, "episode_reward_trend_value": 0.008842760666968591, "biggest_recent_change": 0.28656819267433775},
{"total_number_of_episodes": 7973, "number_of_timesteps": 762250, "per_episode_reward": -295.91, "episode_reward_trend_value": 0.008736302150427061, "biggest_recent_change": 0.28656819267433775},
{"total_number_of_episodes": 7983, "number_of_timesteps": 763163, "per_episode_reward": -295.74, "episode_reward_trend_value": 0.009084884702840175, "biggest_recent_change": 0.28656819267433775},
{"total_number_of_episodes": 7995, "number_of_timesteps": 764206, "per_episode_reward": -295.63, "episode_reward_trend_value": 0.00719351865717815, "biggest_recent_change": 0.16517789196620924},
{"total_number_of_episodes": 8005, "number_of_timesteps": 765080, "per_episode_reward": -295.6, "episode_reward_trend_value": 0.008449806358056044, "biggest_recent_change": 0.16517789196620924},
{"total_number_of_episodes": 8015, "number_of_timesteps": 766102, "per_episode_reward": -295.7, "episode_reward_trend_value": 0.005906896309591679, "biggest_recent_change": 0.16517789196620924},
{"total_number_of_episodes": 8027, "number_of_timesteps": 767607, "per_episode_reward": -295.75, "episode_reward_trend_value": 0.0035629602173009463, "biggest_recent_change": 0.16517789196620924},
{"total_number_of_episodes": 8037, "number_of_timesteps": 768907, "per_episode_reward": -295.59, "episode_reward_trend_value": 0.004760433147923651, "biggest_recent_change": 0.16517789196620924},
{"total_number_of_episodes": 8047, "number_of_timesteps": 770320, "per_episode_reward": -295.72, "episode_reward_trend_value": 0.002461266278414895, "biggest_recent_change": 0.16517789196620924},
{"total_number_of_episodes": 8058, "number_of_timesteps": 771394, "per_episode_reward": -295.74, "episode_reward_trend_value": 0.001332589166275966, "biggest_recent_change": 0.16517789196620924},
{"total_number_of_episodes": 8068, "number_of_timesteps": 772301, "per_episode_reward": -296.01, "episode_reward_trend_value": -0.0011451453980056512, "biggest_recent_change": 0.26755476462238903},
{"total_number_of_episodes": 8078, "number_of_timesteps": 773409, "per_episode_reward": -296.47, "episode_reward_trend_value": -0.008117750971468416, "biggest_recent_change": 0.4623566096454397},
{"total_number_of_episodes": 8088, "number_of_timesteps": 774512, "per_episode_reward": -296.49, "episode_reward_trend_value": -0.009544747149138605, "biggest_recent_change": 0.4623566096454397},
{"total_number_of_episodes": 8099, "number_of_timesteps": 775674, "per_episode_reward": -296.55, "episode_reward_trend_value": -0.01056198405313214, "biggest_recent_change": 0.4623566096454397},
{"total_number_of_episodes": 8109, "number_of_timesteps": 776556, "per_episode_reward": -296.84, "episode_reward_trend_value": -0.0126511168257884, "biggest_recent_change": 0.4623566096454397},
{"total_number_of_episodes": 8119, "number_of_timesteps": 777708, "per_episode_reward": -296.84, "episode_reward_trend_value": -0.012120243674693635, "biggest_recent_change": 0.4623566096454397},
{"total_number_of_episodes": 8129, "number_of_timesteps": 778637, "per_episode_reward": -296.69, "episode_reward_trend_value": -0.012172108018585783, "biggest_recent_change": 0.4623566096454397},
{"total_number_of_episodes": 8139, "number_of_timesteps": 779614, "per_episode_reward": -296.84, "episode_reward_trend_value": -0.012512719575821368, "biggest_recent_change": 0.4623566096454397},
{"total_number_of_episodes": 8149, "number_of_timesteps": 780792, "per_episode_reward": -296.91, "episode_reward_trend_value": -0.012915601972962853, "biggest_recent_change": 0.4623566096454397},
{"total_number_of_episodes": 8159, "number_of_timesteps": 781889, "per_episode_reward": -296.78, "episode_reward_trend_value": -0.008501081916453284, "biggest_recent_change": 0.4623566096454397},
{"total_number_of_episodes": 8169, "number_of_timesteps": 782743, "per_episode_reward": -296.66, "episode_reward_trend_value": -0.0020279421890184797, "biggest_recent_change": 0.2880840380086056},
{"total_number_of_episodes": 8180, "number_of_timesteps": 783667, "per_episode_reward": -296.55, "episode_reward_trend_value": -0.0007092635584222585, "biggest_recent_change": 0.2880840380086056},
{"total_number_of_episodes": 8190, "number_of_timesteps": 784597, "per_episode_reward": -296.38, "episode_reward_trend_value": 0.001862218395951408, "biggest_recent_change": 0.2880840380086056},
{"total_number_of_episodes": 8200, "number_of_timesteps": 785495, "per_episode_reward": -296.28, "episode_reward_trend_value": 0.0062276863905759055, "biggest_recent_change": 0.16965007516324704},
{"total_number_of_episodes": 8210, "number_of_timesteps": 786474, "per_episode_reward": -296.13, "episode_reward_trend_value": 0.007992795767903418, "biggest_recent_change": 0.16965007516324704},
{"total_number_of_episodes": 8221, "number_of_timesteps": 787711, "per_episode_reward": -295.99, "episode_reward_trend_value": 0.007761161921774828, "biggest_recent_change": 0.16965007516324704},
{"total_number_of_episodes": 8231, "number_of_timesteps": 788970, "per_episode_reward": -295.95, "episode_reward_trend_value": 0.009940171191524566, "biggest_recent_change": 0.16965007516324704},
{"total_number_of_episodes": 8241, "number_of_timesteps": 789993, "per_episode_reward": -295.85, "episode_reward_trend_value": 0.01172753519087703, "biggest_recent_change": 0.16965007516324704},
{"total_number_of_episodes": 8252, "number_of_timesteps": 791337, "per_episode_reward": -295.73, "episode_reward_trend_value": 0.011637076537725003, "biggest_recent_change": 0.16965007516324704},
{"total_number_of_episodes": 8263, "number_of_timesteps": 792501, "per_episode_reward": -295.63, "episode_reward_trend_value": 0.0113876630697708, "biggest_recent_change": 0.16965007516324704},
{"total_number_of_episodes": 8274, "number_of_timesteps": 793675, "per_episode_reward": -295.69, "episode_reward_trend_value": 0.00950039196817632, "biggest_recent_change": 0.16965007516324704},
{"total_number_of_episodes": 8284, "number_of_timesteps": 795025, "per_episode_reward": -295.57, "episode_reward_trend_value": 0.008964946197412853, "biggest_recent_change": 0.15031335928927092},
{"total_number_of_episodes": 8294, "number_of_timesteps": 795978, "per_episode_reward": -295.62, "episode_reward_trend_value": 0.007286493825554569, "biggest_recent_change": 0.15031335928927092},

{"total_number_of_episodes": 8305, "number_of_timesteps": 797243, "per_episode_reward": -295.71, "episode_reward_trend_value": 0.004620229552224625, "biggest_recent_change": 0.13656883299449873},
{"total_number_of_episodes": 8315, "number_of_timesteps": 798573, "per_episode_reward": -295.7, "episode_reward_trend_value": 0.0032410771808025, "biggest_recent_change": 0.1216107616797899},
{"total_number_of_episodes": 8325, "number_of_timesteps": 799616, "per_episode_reward": -295.8, "episode_reward_trend_value": 0.0016957174645805633, "biggest_recent_change": 0.1216107616797899},
{"total_number_of_episodes": 8335, "number_of_timesteps": 800709, "per_episode_reward": -296.08, "episode_reward_trend_value": -0.0025334116259734347, "biggest_recent_change": 0.2825844062314786},
{"total_number_of_episodes": 8345, "number_of_timesteps": 801779, "per_episode_reward": -296.04, "episode_reward_trend_value": -0.003428386707968735, "biggest_recent_change": 0.2825844062314786},
{"total_number_of_episodes": 8355, "number_of_timesteps": 802630, "per_episode_reward": -296.07, "episode_reward_trend_value": -0.004862332794558218, "biggest_recent_change": 0.2825844062314786},
{"total_number_of_episodes": 8366, "number_of_timesteps": 803683, "per_episode_reward": -296.08, "episode_reward_trend_value": -0.0042829780633060945, "biggest_recent_change": 0.2825844062314786},
{"total_number_of_episodes": 8376, "number_of_timesteps": 804598, "per_episode_reward": -296.05, "episode_reward_trend_value": -0.005259231542611234, "biggest_recent_change": 0.2825844062314786},
{"total_number_of_episodes": 8386, "number_of_timesteps": 805429, "per_episode_reward": -295.83, "episode_reward_trend_value": -0.002380191672376163, "biggest_recent_change": 0.2825844062314786},
{"total_number_of_episodes": 8399, "number_of_timesteps": 806492, "per_episode_reward": -295.52, "episode_reward_trend_value": 0.002071862053401219, "biggest_recent_change": 0.31103441000954035},
{"total_number_of_episodes": 8409, "number_of_timesteps": 807479, "per_episode_reward": -295.46, "episode_reward_trend_value": 0.0025958051976109195, "biggest_recent_change": 0.31103441000954035},
{"total_number_of_episodes": 8419, "number_of_timesteps": 808396, "per_episode_reward": -295.23, "episode_reward_trend_value": 0.006293132382805627, "biggest_recent_change": 0.31103441000954035},
{"total_number_of_episodes": 8429, "number_of_timesteps": 809349, "per_episode_reward": -294.99, "episode_reward_trend_value": 0.012092483028404407, "biggest_recent_change": 0.31103441000954035},
{"total_number_of_episodes": 8440, "number_of_timesteps": 810594, "per_episode_reward": -294.94, "episode_reward_trend_value": 0.012239381712247324, "biggest_recent_change": 0.31103441000954035},
{"total_number_of_episodes": 8451, "number_of_timesteps": 811974, "per_episode_reward": -294.84, "episode_reward_trend_value": 0.013638481556235624, "biggest_recent_change": 0.31103441000954035},
{"total_number_of_episodes": 8461, "number_of_timesteps": 813100, "per_episode_reward": -294.69, "episode_reward_trend_value": 0.01539746414047348, "biggest_recent_change": 0.31103441000954035},
{"total_number_of_episodes": 8471, "number_of_timesteps": 813924, "per_episode_reward": -294.54, "episode_reward_trend_value": 0.016771834805645845, "biggest_recent_change": 0.31103441000954035},
{"total_number_of_episodes": 8481, "number_of_timesteps": 814956, "per_episode_reward": -294.3, "episode_reward_trend_value": 0.017018332893174677, "biggest_recent_change": 0.31103441000954035},
{"total_number_of_episodes": 8491, "number_of_timesteps": 816561, "per_episode_reward": -294.27, "episode_reward_trend_value": 0.013896444317998658, "biggest_recent_change": 0.23935715187241158},
{"total_number_of_episodes": 8503, "number_of_timesteps": 817891, "per_episode_reward": -294.22, "episode_reward_trend_value": 0.01382998569052284, "biggest_recent_change": 0.23935715187241158},
{"total_number_of_episodes": 8513, "number_of_timesteps": 819057, "per_episode_reward": -294.13, "episode_reward_trend_value": 0.012236685399974728, "biggest_recent_change": 0.23935715187241158},
{"total_number_of_episodes": 8523, "number_of_timesteps": 820231, "per_episode_reward": -294.29, "episode_reward_trend_value": 0.007739138737510605, "biggest_recent_change": 0.23504578423910516},
{"total_number_of_episodes": 8534, "number_of_timesteps": 821071, "per_episode_reward": -294.22, "episode_reward_trend_value": 0.007943749792205936, "biggest_recent_change": 0.23504578423910516},
{"total_number_of_episodes": 8544, "number_of_timesteps": 821998, "per_episode_reward": -294.02, "episode_reward_trend_value": 0.009084216175829675, "biggest_recent_change": 0.23504578423910516},
{"total_number_of_episodes": 8554, "number_of_timesteps": 823163, "per_episode_reward": -294.09, "episode_reward_trend_value": 0.006747967839776771, "biggest_recent_change": 0.23504578423910516},
{"total_number_of_episodes": 8564, "number_of_timesteps": 825120, "per_episode_reward": -294.0, "episode_reward_trend_value": 0.005984997576141874, "biggest_recent_change": 0.23504578423910516},
{"total_number_of_episodes": 8574, "number_of_timesteps": 826254, "per_episode_reward": -293.61, "episode_reward_trend_value": 0.007686487067080508, "biggest_recent_change": 0.38817983842358217},
{"total_number_of_episodes": 8585, "number_of_timesteps": 827224, "per_episode_reward": -293.32, "episode_reward_trend_value": 0.010620370477902775, "biggest_recent_change": 0.38817983842358217},
{"total_number_of_episodes": 8595, "number_of_timesteps": 828225, "per_episode_reward": -292.78, "episode_reward_trend_value": 0.015941971313124744, "biggest_recent_change": 0.5325628012425341},
{"total_number_of_episodes": 8605, "number_of_timesteps": 829104, "per_episode_reward": -292.61, "episode_reward_trend_value": 0.01690470330307979, "biggest_recent_change": 0.5325628012425341},
{"total_number_of_episodes": 8615, "number_of_timesteps": 830283, "per_episode_reward": -292.67, "episode_reward_trend_value": 0.018095527266958948, "biggest_recent_change": 0.5325628012425341},
{"total_number_of_episodes": 8625, "number_of_timesteps": 831407, "per_episode_reward": -292.68, "episode_reward_trend_value": 0.01716406620937063, "biggest_recent_change": 0.5325628012425341},
{"total_number_of_episodes": 8635, "number_of_timesteps": 832512, "per_episode_reward": -292.44, "episode_reward_trend_value": 0.01759785965862951, "biggest_recent_change": 0.5325628012425341},
{"total_number_of_episodes": 8645, "number_of_timesteps": 833454, "per_episode_reward": -292.29, "episode_reward_trend_value": 0.020018989483922826, "biggest_recent_change": 0.5325628012425341},
{"total_number_of_episodes": 8655, "number_of_timesteps": 834401, "per_episode_reward": -292.45, "episode_reward_trend_value": 0.01721927673779836, "biggest_recent_change": 0.5325628012425341},
{"total_number_of_episodes": 8665, "number_of_timesteps": 835252, "per_episode_reward": -292.18, "episode_reward_trend_value": 0.015909078826549856, "biggest_recent_change": 0.5325628012425341},
{"total_number_of_episodes": 8675, "number_of_timesteps": 836155, "per_episode_reward": -292.17, "episode_reward_trend_value": 0.01278613644291037, "biggest_recent_change": 0.5325628012425341},
{"total_number_of_episodes": 8685, "number_of_timesteps": 837149, "per_episode_reward": -291.9, "episode_reward_trend_value": 0.009853875541146332, "biggest_recent_change": 0.270262026411217},
{"total_number_of_episodes": 8695, "number_of_timesteps": 838224, "per_episode_reward": -291.5, "episode_reward_trend_value": 0.012281342619434098, "biggest_recent_change": 0.3949238928907448},
{"total_number_of_episodes": 8707, "number_of_timesteps": 839219, "per_episode_reward": -291.47, "episode_reward_trend_value": 0.013282141474192915, "biggest_recent_change": 0.3949238928907448},
{"total_number_of_episodes": 8717, "number_of_timesteps": 840147, "per_episode_reward": -291.22, "episode_reward_trend_value": 0.01623759429199178, "biggest_recent_change": 0.3949238928907448},
{"total_number_of_episodes": 8727, "number_of_timesteps": 841002, "per_episode_reward": -290.68, "episode_reward_trend_value": 0.019543568329177356, "biggest_recent_change": 0.5338636401798453},
{"total_number_of_episodes": 8739, "number_of_timesteps": 841910, "per_episode_reward": -290.47, "episode_reward_trend_value": 0.020178141605644996, "biggest_recent_change": 0.5338636401798453},
{"total_number_of_episodes": 8749, "number_of_timesteps": 842689, "per_episode_reward": -290.3, "episode_reward_trend_value": 0.023828071033250353, "biggest_recent_change": 0.5338636401798453},
{"total_number_of_episodes": 8759, "number_of_timesteps": 843525, "per_episode_reward": -290.16, "episode_reward_trend_value": 0.022464424716279532, "biggest_recent_change": 0.5338636401798453},
{"total_number_of_episodes": 8769, "number_of_timesteps": 844248, "per_episode_reward": -289.95, "episode_reward_trend_value": 0.02457798705790234, "biggest_recent_change": 0.5338636401798453},
{"total_number_of_episodes": 8779, "number_of_timesteps": 844990, "per_episode_reward": -289.78, "episode_reward_trend_value": 0.023573410867013284, "biggest_recent_change": 0.5338636401798453},
{"total_number_of_episodes": 8789, "number_of_timesteps": 845748, "per_episode_reward": -289.62, "episode_reward_trend_value": 0.020918649667748923, "biggest_recent_change": 0.5338636401798453},
{"total_number_of_episodes": 8799, "number_of_timesteps": 846557, "per_episode_reward": -289.46, "episode_reward_trend_value": 0.02230677869943065, "biggest_recent_change": 0.5338636401798453},
{"total_number_of_episodes": 8809, "number_of_timesteps": 847328, "per_episode_reward": -289.33, "episode_reward_trend_value": 0.02098873841104528, "biggest_recent_change": 0.5338636401798453},
{"total_number_of_episodes": 8820, "number_of_timesteps": 848238, "per_episode_reward": -288.93, "episode_reward_trend_value": 0.019492321177780367, "biggest_recent_change": 0.39918608918600285},
{"total_number_of_episodes": 8831, "number_of_timesteps": 849201, "per_episode_reward": -288.71, "episode_reward_trend_value": 0.019522164079189174, "biggest_recent_change": 0.39918608918600285},
{"total_number_of_episodes": 8841, "number_of_timesteps": 850048, "per_episode_reward": -288.5, "episode_reward_trend_value": 0.020039928696013475, "biggest_recent_change": 0.39918608918600285},
{"total_number_of_episodes": 8853, "number_of_timesteps": 851062, "per_episode_reward": -288.1, "episode_reward_trend_value": 0.022897582397368093, "biggest_recent_change": 0.40472269100575886},
{"total_number_of_episodes": 8863, "number_of_timesteps": 851933, "per_episode_reward": -287.82, "episode_reward_trend_value": 0.023716757191076316, "biggest_recent_change": 0.40472269100575886},
{"total_number_of_episodes": 8873, "number_of_timesteps": 852702, "per_episode_reward": -287.52, "episode_reward_trend_value": 0.025034803113178822, "biggest_recent_change": 0.40472269100575886},
{"total_number_of_episodes": 8884, "number_of_timesteps": 853629, "per_episode_reward": -287.38, "episode_reward_trend_value": 0.024852531217894443, "biggest_recent_change": 0.40472269100575886},
{"total_number_of_episodes": 8894, "number_of_timesteps": 854330, "per_episode_reward": -287.28, "episode_reward_trend_value": 0.024296129109166665, "biggest_recent_change": 0.40472269100575886},
{"total_number_of_episodes": 8905, "number_of_timesteps": 855213, "per_episode_reward": -287.1, "episode_reward_trend_value": 0.024731595528575984, "biggest_recent_change": 0.40472269100575886},
{"total_number_of_episodes": 8916, "number_of_timesteps": 856101, "per_episode_reward": -286.87, "episode_reward_trend_value": 0.022907271861875085, "biggest_recent_change": 0.40472269100575886},
{"total_number_of_episodes": 8926, "number_of_timesteps": 856925, "per_episode_reward": -286.66, "episode_reward_trend_value": 0.022807099105785433, "biggest_recent_change": 0.40472269100575886},
{"total_number_of_episodes": 8936, "number_of_timesteps": 857753, "per_episode_reward": -286.58, "episode_reward_trend_value": 0.02131208408589171, "biggest_recent_change": 0.40472269100575886},
{"total_number_of_episodes": 8946, "number_of_timesteps": 858590, "per_episode_reward": -286.49, "episode_reward_trend_value": 0.017880572592495505, "biggest_recent_change": 0.2968715958929806},
{"total_number_of_episodes": 8956, "number_of_timesteps": 859503, "per_episode_reward": -286.37, "episode_reward_trend_value": 0.016094352452677818, "biggest_recent_change": 0.2968715958929806},
{"total_number_of_episodes": 8967, "number_of_timesteps": 860361, "per_episode_reward": -286.23, "episode_reward_trend_value": 0.014363514903225096, "biggest_recent_change": 0.23499695918292218},
{"total_number_of_episodes": 8977, "number_of_timesteps": 861184, "per_episode_reward": -286.08, "episode_reward_trend_value": 0.014464060487490039, "biggest_recent_change": 0.23499695918292218},
{"total_number_of_episodes": 8989, "number_of_timesteps": 862249, "per_episode_reward": -285.69, "episode_reward_trend_value": 0.017592405545650537, "biggest_recent_change": 0.3882304842283588},
{"total_number_of_episodes": 8999, "number_of_timesteps": 863063, "per_episode_reward": -285.2, "episode_reward_trend_value": 0.021091977040756167, "biggest_recent_change": 0.4903879255392667},
{"total_number_of_episodes": 9009, "number_of_timesteps": 863947, "per_episode_reward": -285.02, "episode_reward_trend_value": 0.020486991445012058, "biggest_recent_change": 0.4903879255392667},
{"total_number_of_episodes": 9019, "number_of_timesteps": 864749, "per_episode_reward": -284.95, "episode_reward_trend_value": 0.018988076747170148, "biggest_recent_change": 0.4903879255392667},
{"total_number_of_episodes": 9029, "number_of_timesteps": 865585, "per_episode_reward": -284.84, "episode_reward_trend_value": 0.01937462533539739, "biggest_recent_change": 0.4903879255392667},
{"total_number_of_episodes": 9039, "number_of_timesteps": 866478, "per_episode_reward": -284.78, "episode_reward_trend_value": 0.018964756971252605, "biggest_recent_change": 0.4903879255392667},
{"total_number_of_episodes": 9049, "number_of_timesteps": 867412, "per_episode_reward": -284.56, "episode_reward_trend_value": 0.020155319456160392, "biggest_recent_change": 0.4903879255392667},
{"total_number_of_episodes": 9060, "number_of_timesteps": 868426, "per_episode_reward": -284.41, "episode_reward_trend_value": 0.02019210369953473, "biggest_recent_change": 0.4903879255392667},
{"total_number_of_episodes": 9070, "number_of_timesteps": 869292, "per_episode_reward": -284.4, "episode_reward_trend_value": 0.018680527338408283, "biggest_recent_change": 0.4903879255392667},
{"total_number_of_episodes": 9080, "number_of_timesteps": 870387, "per_episode_reward": -284.3, "episode_reward_trend_value": 0.015449282910127395, "biggest_recent_change": 0.4903879255392667},
{"total_number_of_episodes": 9091, "number_of_timesteps": 871718, "per_episode_reward": -284.21, "episode_reward_trend_value": 0.010989398552993634, "biggest_recent_change": 0.2233862839280505},
{"total_number_of_episodes": 9101, "number_of_timesteps": 872733, "per_episode_reward": -284.24, "episode_reward_trend_value": 0.008698021196249784, "biggest_recent_change": 0.2233862839280505},
{"total_number_of_episodes": 9112, "number_of_timesteps": 873902, "per_episode_reward": -284.21, "episode_reward_trend_value": 0.008267212074576315, "biggest_recent_change": 0.2233862839280505},
{"total_number_of_episodes": 9122, "number_of_timesteps": 874880, "per_episode_reward": -284.31, "episode_reward_trend_value": 0.005822449847347065, "biggest_recent_change": 0.2233862839280505},
{"total_number_of_episodes": 9132, "number_of_timesteps": 875949, "per_episode_reward": -284.36, "episode_reward_trend_value": 0.0046958525044879535, "biggest_recent_change": 0.2233862839280505},
{"total_number_of_episodes": 9142, "number_of_timesteps": 877172, "per_episode_reward": -284.41, "episode_reward_trend_value": 0.001590955121857481, "biggest_recent_change": 0.1444067983459263},
{"total_number_of_episodes": 9152, "number_of_timesteps": 878404, "per_episode_reward": -284.42, "episode_reward_trend_value": -0.00012387324456994975, "biggest_recent_change": 0.10804908365770416},
{"total_number_of_episodes": 9163, "number_of_timesteps": 879586, "per_episode_reward": -284.38, "episode_reward_trend_value": 0.0001775418374639533, "biggest_recent_change": 0.10804908365770416},
{"total_number_of_episodes": 9173, "number_of_timesteps": 880761, "per_episode_reward": -284.31, "episode_reward_trend_value": -0.00012496742988585334, "biggest_recent_change": 0.10804908365770416},
{"total_number_of_episodes": 9184, "number_of_timesteps": 882073, "per_episode_reward": -284.36, "episode_reward_trend_value": -0.0016248589039719263, "biggest_recent_change": 0.10804908365770416},
{"total_number_of_episodes": 9195, "number_of_timesteps": 883022, "per_episode_reward": -284.48, "episode_reward_trend_value": -0.0026520612849986317, "biggest_recent_change": 0.11812392083339773},
{"total_number_of_episodes": 9205, "number_of_timesteps": 883946, "per_episode_reward": -284.62, "episode_reward_trend_value": -0.004538327920893911, "biggest_recent_change": 0.13782527041581716},
{"total_number_of_episodes": 9216, "number_of_timesteps": 885186, "per_episode_reward": -284.68, "episode_reward_trend_value": -0.004019520756871645, "biggest_recent_change": 0.13782527041581716},
{"total_number_of_episodes": 9226, "number_of_timesteps": 886097, "per_episode_reward": -284.72, "episode_reward_trend_value": -0.0040601863525327846, "biggest_recent_change": 0.13782527041581716},
{"total_number_of_episodes": 9238, "number_of_timesteps": 887496, "per_episode_reward": -284.74, "episode_reward_trend_value": -0.0036593163040063497, "biggest_recent_change": 0.13782527041581716},
{"total_number_of_episodes": 9250, "number_of_timesteps": 888616, "per_episode_reward": -284.83, "episode_reward_trend_value": -0.004557845473015555, "biggest_recent_change": 0.13782527041581716},
{"total_number_of_episodes": 9260, "number_of_timesteps": 889453, "per_episode_reward": -284.85, "episode_reward_trend_value": -0.005181562307273503, "biggest_recent_change": 0.13782527041581716},
{"total_number_of_episodes": 9270, "number_of_timesteps": 890296, "per_episode_reward": -284.87, "episode_reward_trend_value": -0.006221216921946709, "biggest_recent_change": 0.13782527041581716},
{"total_number_of_episodes": 9281, "number_of_timesteps": 891432, "per_episode_reward": -284.88, "episode_reward_trend_value": -0.005795134124863605, "biggest_recent_change": 0.13782527041581716},
{"total_number_of_episodes": 9292, "number_of_timesteps": 892492, "per_episode_reward": -284.96, "episode_reward_trend_value": -0.00533502107547987, "biggest_recent_change": 0.13782527041581716},
{"total_number_of_episodes": 9302, "number_of_timesteps": 893276, "per_episode_reward": -285.03, "episode_reward_trend_value": -0.004587663707824655, "biggest_recent_change": 0.09079537984337094},
{"total_number_of_episodes": 9312, "number_of_timesteps": 894163, "per_episode_reward": -284.91, "episode_reward_trend_value": -0.002642577508028252, "biggest_recent_change": 0.11370131908597614},
{"total_number_of_episodes": 9322, "number_of_timesteps": 895178, "per_episode_reward": -284.82, "episode_reward_trend_value": -0.0010513196233148392, "biggest_recent_change": 0.11370131908597614},
{"total_number_of_episodes": 9332, "number_of_timesteps": 896409, "per_episode_reward": -284.85, "episode_reward_trend_value": -0.001213209856999558, "biggest_recent_change": 0.11370131908597614},
{"total_number_of_episodes": 9342, "number_of_timesteps": 897362, "per_episode_reward": -284.93, "episode_reward_trend_value": -0.0010928831915615925, "biggest_recent_change": 0.11370131908597614},
{"total_number_of_episodes": 9354, "number_of_timesteps": 898500, "per_episode_reward": -284.91, "episode_reward_trend_value": -0.0006500117778178567, "biggest_recent_change": 0.11370131908597614},
{"total_number_of_episodes": 9364, "number_of_timesteps": 899550, "per_episode_reward": -284.92, "episode_reward_trend_value": -0.0004829890107430401, "biggest_recent_change": 0.11370131908597614},
{"total_number_of_episodes": 9374, "number_of_timesteps": 900710, "per_episode_reward": -285.04, "episode_reward_trend_value": -0.0017789758439783379, "biggest_recent_change": 0.12428326252421584},
{"total_number_of_episodes": 9384, "number_of_timesteps": 902006, "per_episode_reward": -285.09, "episode_reward_trend_value": -0.0014786219311752626, "biggest_recent_change": 0.12428326252421584},
{"total_number_of_episodes": 9394, "number_of_timesteps": 903195, "per_episode_reward": -285.16, "episode_reward_trend_value": -0.001512495021633716, "biggest_recent_change": 0.12428326252421584},
{"total_number_of_episodes": 9404, "number_of_timesteps": 904263, "per_episode_reward": -285.15, "episode_reward_trend_value": -0.0025658971589974855, "biggest_recent_change": 0.12428326252421584},
{"total_number_of_episodes": 9414, "number_of_timesteps": 905287, "per_episode_reward": -285.22, "episode_reward_trend_value": -0.004485102007099487, "biggest_recent_change": 0.12428326252421584},
{"total_number_of_episodes": 9424, "number_of_timesteps": 906225, "per_episode_reward": -285.22, "episode_reward_trend_value": -0.0040416239208430705, "biggest_recent_change": 0.12428326252421584},
{"total_number_of_episodes": 9434, "number_of_timesteps": 907252, "per_episode_reward": -285.29, "episode_reward_trend_value": -0.003955137622949678, "biggest_recent_change": 0.12428326252421584},
{"total_number_of_episodes": 9445, "number_of_timesteps": 908233, "per_episode_reward": -285.21, "episode_reward_trend_value": -0.003316765900879975, "biggest_recent_change": 0.12428326252421584},

{"total_number_of_episodes": 9457, "number_of_timesteps": 909382, "per_episode_reward": -285.1, "episode_reward_trend_value": -0.0019882169712679516, "biggest_recent_change": 0.12428326252421584},
{"total_number_of_episodes": 9467, "number_of_timesteps": 910460, "per_episode_reward": -285.12, "episode_reward_trend_value": -0.0008963818276767042, "biggest_recent_change": 0.1112251890028233},
{"total_number_of_episodes": 9477, "number_of_timesteps": 911559, "per_episode_reward": -285.14, "episode_reward_trend_value": -0.0004994962834271317, "biggest_recent_change": 0.1112251890028233},
{"total_number_of_episodes": 9487, "number_of_timesteps": 912717, "per_episode_reward": -285.18, "episode_reward_trend_value": -0.0001660207034104941, "biggest_recent_change": 0.1112251890028233},
{"total_number_of_episodes": 9497, "number_of_timesteps": 913703, "per_episode_reward": -285.26, "episode_reward_trend_value": -0.001264116181548363, "biggest_recent_change": 0.1112251890028233},
{"total_number_of_episodes": 9507, "number_of_timesteps": 914839, "per_episode_reward": -285.36, "episode_reward_trend_value": -0.001516913889998427, "biggest_recent_change": 0.1112251890028233},
{"total_number_of_episodes": 9519, "number_of_timesteps": 916025, "per_episode_reward": -285.47, "episode_reward_trend_value": -0.002861925798559797, "biggest_recent_change": 0.1156843411803834},
{"total_number_of_episodes": 9531, "number_of_timesteps": 916916, "per_episode_reward": -285.49, "episode_reward_trend_value": -0.0022351392266980637, "biggest_recent_change": 0.1156843411803834},
{"total_number_of_episodes": 9543, "number_of_timesteps": 917898, "per_episode_reward": -286.01, "episode_reward_trend_value": -0.008976476535092894, "biggest_recent_change": 0.5258174887686664},
{"total_number_of_episodes": 9553, "number_of_timesteps": 918690, "per_episode_reward": -286.38, "episode_reward_trend_value": -0.014322400774996899, "biggest_recent_change": 0.5258174887686664},
{"total_number_of_episodes": 9563, "number_of_timesteps": 919515, "per_episode_reward": -286.41, "episode_reward_trend_value": -0.0142882014167526, "biggest_recent_change": 0.5258174887686664},
{"total_number_of_episodes": 9573, "number_of_timesteps": 920456, "per_episode_reward": -286.59, "episode_reward_trend_value": -0.0161593193280876, "biggest_recent_change": 0.5258174887686664},
{"total_number_of_episodes": 9583, "number_of_timesteps": 921444, "per_episode_reward": -286.66, "episode_reward_trend_value": -0.016477111102641277, "biggest_recent_change": 0.5258174887686664},
{"total_number_of_episodes": 9593, "number_of_timesteps": 922358, "per_episode_reward": -286.78, "episode_reward_trend_value": -0.01685697499372433, "biggest_recent_change": 0.5258174887686664},
{"total_number_of_episodes": 9605, "number_of_timesteps": 923478, "per_episode_reward": -286.8, "episode_reward_trend_value": -0.016061886735880965, "biggest_recent_change": 0.5258174887686664},
{"total_number_of_episodes": 9615, "number_of_timesteps": 924531, "per_episode_reward": -286.79, "episode_reward_trend_value": -0.014591371676621317, "biggest_recent_change": 0.5258174887686664},
{"total_number_of_episodes": 9625, "number_of_timesteps": 925664, "per_episode_reward": -286.8, "episode_reward_trend_value": -0.014575559501418589, "biggest_recent_change": 0.5258174887686664},
{"total_number_of_episodes": 9635, "number_of_timesteps": 927020, "per_episode_reward": -286.79, "episode_reward_trend_value": -0.00855960188329795, "biggest_recent_change": 0.3699079925885371},
{"total_number_of_episodes": 9645, "number_of_timesteps": 928145, "per_episode_reward": -286.75, "episode_reward_trend_value": -0.004027619165421785, "biggest_recent_change": 0.18236280727427356},
{"total_number_of_episodes": 9655, "number_of_timesteps": 928925, "per_episode_reward": -286.54, "episode_reward_trend_value": -0.0014659995750914985, "biggest_recent_change": 0.2076056057707092},
{"total_number_of_episodes": 9665, "number_of_timesteps": 929868, "per_episode_reward": -286.24, "episode_reward_trend_value": 0.003908100905891211, "biggest_recent_change": 0.3013062360141703},
{"total_number_of_episodes": 9675, "number_of_timesteps": 930938, "per_episode_reward": -286.47, "episode_reward_trend_value": 0.0021316224789693985, "biggest_recent_change": 0.3013062360141703},
{"total_number_of_episodes": 9685, "number_of_timesteps": 931874, "per_episode_reward": -286.68, "episode_reward_trend_value": 0.0010576400820872954, "biggest_recent_change": 0.3013062360141703},
{"total_number_of_episodes": 9696, "number_of_timesteps": 933033, "per_episode_reward": -286.58, "episode_reward_trend_value": 0.0025067765954380167, "biggest_recent_change": 0.3013062360141703},
{"total_number_of_episodes": 9706, "number_of_timesteps": 933942, "per_episode_reward": -286.44, "episode_reward_trend_value": 0.0038519603597421794, "biggest_recent_change": 0.3013062360141703},
{"total_number_of_episodes": 9716, "number_of_timesteps": 935214, "per_episode_reward": -286.39, "episode_reward_trend_value": 0.004533586595206569, "biggest_recent_change": 0.3013062360141703},
{"total_number_of_episodes": 9727, "number_of_timesteps": 936327, "per_episode_reward": -286.3, "episode_reward_trend_value": 0.005339509220452657, "biggest_recent_change": 0.3013062360141703},
{"total_number_of_episodes": 9737, "number_of_timesteps": 937497, "per_episode_reward": -286.37, "episode_reward_trend_value": 0.004237327039360631, "biggest_recent_change": 0.3013062360141703},
{"total_number_of_episodes": 9747, "number_of_timesteps": 938724, "per_episode_reward": -286.21, "episode_reward_trend_value": 0.003654895243868042, "biggest_recent_change": 0.3013062360141703},
{"total_number_of_episodes": 9757, "number_of_timesteps": 939823, "per_episode_reward": -286.31, "episode_reward_trend_value": -0.0007962038112528566, "biggest_recent_change": 0.23208320139940497},
{"total_number_of_episodes": 9768, "number_of_timesteps": 940945, "per_episode_reward": -286.33, "episode_reward_trend_value": 0.001535814703365506, "biggest_recent_change": 0.21077963222603557},
{"total_number_of_episodes": 9778, "number_of_timesteps": 941875, "per_episode_reward": -286.28, "episode_reward_trend_value": 0.004419484665028348, "biggest_recent_change": 0.15518674417637612},
{"total_number_of_episodes": 9788, "number_of_timesteps": 943217, "per_episode_reward": -286.34, "episode_reward_trend_value": 0.0026574435614375286, "biggest_recent_change": 0.15518674417637612},
{"total_number_of_episodes": 9798, "number_of_timesteps": 944173, "per_episode_reward": -286.24, "episode_reward_trend_value": 0.002246077652682743, "biggest_recent_change": 0.15518674417637612},
{"total_number_of_episodes": 9810, "number_of_timesteps": 945375, "per_episode_reward": -286.06, "episode_reward_trend_value": 0.003710961916958569, "biggest_recent_change": 0.1788376190688723},
{"total_number_of_episodes": 9821, "number_of_timesteps": 946246, "per_episode_reward": -285.88, "episode_reward_trend_value": 0.0047624961332246585, "biggest_recent_change": 0.18278981259828697},
{"total_number_of_episodes": 9831, "number_of_timesteps": 947066, "per_episode_reward": -285.88, "episode_reward_trend_value": 0.005386345687694908, "biggest_recent_change": 0.18278981259828697},
{"total_number_of_episodes": 9841, "number_of_timesteps": 947977, "per_episode_reward": -285.92, "episode_reward_trend_value": 0.003177375801512502, "biggest_recent_change": 0.18278981259828697},
{"total_number_of_episodes": 9851, "number_of_timesteps": 948898, "per_episode_reward": -285.97, "episode_reward_trend_value": 0.003812661071297422, "biggest_recent_change": 0.18278981259828697},
{"total_number_of_episodes": 9861, "number_of_timesteps": 950039, "per_episode_reward": -285.87, "episode_reward_trend_value": 0.00513628883411204, "biggest_recent_change": 0.18278981259828697},
{"total_number_of_episodes": 9872, "number_of_timesteps": 951195, "per_episode_reward": -285.79, "episode_reward_trend_value": 0.005427431447910496, "biggest_recent_change": 0.18278981259828697},
{"total_number_of_episodes": 9883, "number_of_timesteps": 952043, "per_episode_reward": -285.69, "episode_reward_trend_value": 0.007209392540899115, "biggest_recent_change": 0.18278981259828697},
{"total_number_of_episodes": 9893, "number_of_timesteps": 953125, "per_episode_reward": -285.51, "episode_reward_trend_value": 0.008107122140744296, "biggest_recent_change": 0.18278981259828697},
{"total_number_of_episodes": 9903, "number_of_timesteps": 954046, "per_episode_reward": -285.52, "episode_reward_trend_value": 0.006007503076777868, "biggest_recent_change": 0.18278981259828697},
{"total_number_of_episodes": 9914, "number_of_timesteps": 955248, "per_episode_reward": -285.46, "episode_reward_trend_value": 0.004592891486807579, "biggest_recent_change": 0.18150128513849495},
{"total_number_of_episodes": 9924, "number_of_timesteps": 956396, "per_episode_reward": -285.5, "episode_reward_trend_value": 0.004180850521458347, "biggest_recent_change": 0.18150128513849495},
{"total_number_of_episodes": 9934, "number_of_timesteps": 957521, "per_episode_reward": -285.41, "episode_reward_trend_value": 0.005754013209303821, "biggest_recent_change": 0.18150128513849495},
{"total_number_of_episodes": 9946, "number_of_timesteps": 958688, "per_episode_reward": -285.32, "episode_reward_trend_value": 0.007142292973641259, "biggest_recent_change": 0.18150128513849495},
{"total_number_of_episodes": 9958, "number_of_timesteps": 959894, "per_episode_reward": -285.28, "episode_reward_trend_value": 0.006509383516967343, "biggest_recent_change": 0.18150128513849495},
{"total_number_of_episodes": 9969, "number_of_timesteps": 960996, "per_episode_reward": -285.14, "episode_reward_trend_value": 0.007256368679024188, "biggest_recent_change": 0.18150128513849495},
{"total_number_of_episodes": 9979, "number_of_timesteps": 962107, "per_episode_reward": -285.09, "episode_reward_trend_value": 0.006654140594669242, "biggest_recent_change": 0.18150128513849495},
{"total_number_of_episodes": 9989, "number_of_timesteps": 963282, "per_episode_reward": -285.09, "episode_reward_trend_value": 0.004634963165325542, "biggest_recent_change": 0.14218216415059715},
{"total_number_of_episodes": 9999, "number_of_timesteps": 964304, "per_episode_reward": -285.01, "episode_reward_trend_value": 0.005699840688818843, "biggest_recent_change": 0.14218216415059715},
{"total_number_of_episodes": 10009, "number_of_timesteps": 965389, "per_episode_reward": -284.93, "episode_reward_trend_value": 0.005882590114801663, "biggest_recent_change": 0.14218216415059715},
{"total_number_of_episodes": 10019, "number_of_timesteps": 966475, "per_episode_reward": -284.62, "episode_reward_trend_value": 0.009790281299191544, "biggest_recent_change": 0.30952903533801646},
{"total_number_of_episodes": 10029, "number_of_timesteps": 967367, "per_episode_reward": -284.36, "episode_reward_trend_value": 0.011617914473847829, "biggest_recent_change": 0.30952903533801646},
{"total_number_of_episodes": 10041, "number_of_timesteps": 968608, "per_episode_reward": -284.1, "episode_reward_trend_value": 0.01357118663829245, "biggest_recent_change": 0.30952903533801646},
{"total_number_of_episodes": 10052, "number_of_timesteps": 969669, "per_episode_reward": -283.92, "episode_reward_trend_value": 0.015116270368614298, "biggest_recent_change": 0.30952903533801646},
{"total_number_of_episodes": 10062, "number_of_timesteps": 970637, "per_episode_reward": -283.76, "episode_reward_trend_value": 0.015384434404632608, "biggest_recent_change": 0.30952903533801646},
{"total_number_of_episodes": 10074, "number_of_timesteps": 971824, "per_episode_reward": -283.69, "episode_reward_trend_value": 0.015604739581664261, "biggest_recent_change": 0.30952903533801646},
{"total_number_of_episodes": 10084, "number_of_timesteps": 972934, "per_episode_reward": -283.55, "episode_reward_trend_value": 0.017170386722889612, "biggest_recent_change": 0.30952903533801646},
{"total_number_of_episodes": 10094, "number_of_timesteps": 974164, "per_episode_reward": -283.4, "episode_reward_trend_value": 0.01787632129936393, "biggest_recent_change": 0.30952903533801646},
{"total_number_of_episodes": 10104, "number_of_timesteps": 975218, "per_episode_reward": -283.3, "episode_reward_trend_value": 0.018154353756756968, "biggest_recent_change": 0.30952903533801646},
{"total_number_of_episodes": 10116, "number_of_timesteps": 976602, "per_episode_reward": -283.19, "episode_reward_trend_value": 0.015914752526220533, "biggest_recent_change": 0.2624510820451178},
{"total_number_of_episodes": 10127, "number_of_timesteps": 977774, "per_episode_reward": -283.15, "episode_reward_trend_value": 0.013463248419233447, "biggest_recent_change": 0.2586226689243176},
{"total_number_of_episodes": 10137, "number_of_timesteps": 978928, "per_episode_reward": -283.12, "episode_reward_trend_value": 0.010935882986888776, "biggest_recent_change": 0.1790206481978771},
{"total_number_of_episodes": 10148, "number_of_timesteps": 980043, "per_episode_reward": -283.07, "episode_reward_trend_value": 0.009517983683597702, "biggest_recent_change": 0.1663169273922449},
{"total_number_of_episodes": 10158, "number_of_timesteps": 981181, "per_episode_reward": -282.87, "episode_reward_trend_value": 0.009861634082900788, "biggest_recent_change": 0.19724546332952286},
{"total_number_of_episodes": 10170, "number_of_timesteps": 982553, "per_episode_reward": -282.38, "episode_reward_trend_value": 0.014486493582950288, "biggest_recent_change": 0.4873151406933971},
{"total_number_of_episodes": 10181, "number_of_timesteps": 983753, "per_episode_reward": -282.26, "episode_reward_trend_value": 0.014310552904569502, "biggest_recent_change": 0.4873151406933971},
{"total_number_of_episodes": 10192, "number_of_timesteps": 984845, "per_episode_reward": -282.08, "episode_reward_trend_value": 0.014588725813760878, "biggest_recent_change": 0.4873151406933971},
{"total_number_of_episodes": 10203, "number_of_timesteps": 985940, "per_episode_reward": -281.96, "episode_reward_trend_value": 0.01491527866405704, "biggest_recent_change": 0.4873151406933971},
{"total_number_of_episodes": 10213, "number_of_timesteps": 986968, "per_episode_reward": -281.91, "episode_reward_trend_value": 0.014186250010075379, "biggest_recent_change": 0.4873151406933971},
{"total_number_of_episodes": 10223, "number_of_timesteps": 988116, "per_episode_reward": -281.79, "episode_reward_trend_value": 0.015119763597064979, "biggest_recent_change": 0.4873151406933971},
{"total_number_of_episodes": 10233, "number_of_timesteps": 989397, "per_episode_reward": -281.66, "episode_reward_trend_value": 0.016157505776586985, "biggest_recent_change": 0.4873151406933971},
{"total_number_of_episodes": 10243, "number_of_timesteps": 990453, "per_episode_reward": -281.59, "episode_reward_trend_value": 0.01641633556771593, "biggest_recent_change": 0.4873151406933971},
{"total_number_of_episodes": 10254, "number_of_timesteps": 991589, "per_episode_reward": -281.41, "episode_reward_trend_value": 0.016232879662797788, "biggest_recent_change": 0.4873151406933971},
{"total_number_of_episodes": 10265, "number_of_timesteps": 992916, "per_episode_reward": -281.24, "episode_reward_trend_value": 0.012729218911161095, "biggest_recent_change": 0.18073443188688998},
{"total_number_of_episodes": 10275, "number_of_timesteps": 994466, "per_episode_reward": -281.03, "episode_reward_trend_value": 0.013602785360337244, "biggest_recent_change": 0.20346987857942622},
{"total_number_of_episodes": 10286, "number_of_timesteps": 995994, "per_episode_reward": -280.82, "episode_reward_trend_value": 0.014034160793134257, "biggest_recent_change": 0.21310434308793447},
{"total_number_of_episodes": 10296, "number_of_timesteps": 997013, "per_episode_reward": -280.79, "episode_reward_trend_value": 0.012983659783152588, "biggest_recent_change": 0.21310434308793447},
{"total_number_of_episodes": 10306, "number_of_timesteps": 997980, "per_episode_reward": -280.86, "episode_reward_trend_value": 0.011755133307807203, "biggest_recent_change": 0.21310434308793447},
{"total_number_of_episodes": 10317, "number_of_timesteps": 999097, "per_episode_reward": -280.89, "episode_reward_trend_value": 0.010020735489557512, "biggest_recent_change": 0.21310434308793447},
{"total_number_of_episodes": 10327, "number_of_timesteps": 1000048, "per_episode_reward": -280.84, "episode_reward_trend_value": 0.009174253209718269, "biggest_recent_change": 0.21310434308793447},
{"total_number_of_episodes": 10337, "number_of_timesteps": 1000967, "per_episode_reward": -280.72, "episode_reward_trend_value": 0.009641044001944642, "biggest_recent_change": 0.21310434308793447},
{"total_number_of_episodes": 10349, "number_of_timesteps": 1002071, "per_episode_reward": -280.52, "episode_reward_trend_value": 0.009823970683104715, "biggest_recent_change": 0.21310434308793447},
{"total_number_of_episodes": 10360, "number_of_timesteps": 1003306, "per_episode_reward": -280.62, "episode_reward_trend_value": 0.0068464364250265435, "biggest_recent_change": 0.21310434308793447},
{"total_number_of_episodes": 10370, "number_of_timesteps": 1004298, "per_episode_reward": -280.51, "episode_reward_trend_value": 0.00577517990069383, "biggest_recent_change": 0.21310434308793447},
{"total_number_of_episodes": 10380, "number_of_timesteps": 1005367, "per_episode_reward": -280.57, "episode_reward_trend_value": 0.002775376020703233, "biggest_recent_change": 0.19719783319129647},
{"total_number_of_episodes": 10391, "number_of_timesteps": 1006533, "per_episode_reward": -280.78, "episode_reward_trend_value": 0.00012498904981031147, "biggest_recent_change": 0.20674502274727047},
{"total_number_of_episodes": 10401, "number_of_timesteps": 1007606, "per_episode_reward": -280.85, "episode_reward_trend_value": 8.653469506359417e-05, "biggest_recent_change": 0.20674502274727047},
{"total_number_of_episodes": 10411, "number_of_timesteps": 1008371, "per_episode_reward": -280.98, "episode_reward_trend_value": -0.0010348030434821946, "biggest_recent_change": 0.20674502274727047},
{"total_number_of_episodes": 10422, "number_of_timesteps": 1009243, "per_episode_reward": -281.13, "episode_reward_trend_value": -0.003201214248015402, "biggest_recent_change": 0.20674502274727047},
{"total_number_of_episodes": 10432, "number_of_timesteps": 1010046, "per_episode_reward": -280.96, "episode_reward_trend_value": -0.002620580539271739, "biggest_recent_change": 0.20674502274727047},
{"total_number_of_episodes": 10442, "number_of_timesteps": 1010978, "per_episode_reward": -280.82, "episode_reward_trend_value": -0.00324029917987395, "biggest_recent_change": 0.20674502274727047},
{"total_number_of_episodes": 10453, "number_of_timesteps": 1012161, "per_episode_reward": -280.76, "episode_reward_trend_value": -0.0015106632895146453, "biggest_recent_change": 0.20674502274727047},
{"total_number_of_episodes": 10463, "number_of_timesteps": 1013187, "per_episode_reward": -280.72, "episode_reward_trend_value": -0.002257554147847587, "biggest_recent_change": 0.20674502274727047},
{"total_number_of_episodes": 10474, "number_of_timesteps": 1014453, "per_episode_reward": -280.75, "episode_reward_trend_value": -0.0020200509278077384, "biggest_recent_change": 0.20674502274727047},
{"total_number_of_episodes": 10484, "number_of_timesteps": 1015531, "per_episode_reward": -280.82, "episode_reward_trend_value": -0.0005085914069746245, "biggest_recent_change": 0.16897259719058866},
{"total_number_of_episodes": 10494, "number_of_timesteps": 1016653, "per_episode_reward": -280.94, "episode_reward_trend_value": -0.0010575785586512312, "biggest_recent_change": 0.16897259719058866},
{"total_number_of_episodes": 10504, "number_of_timesteps": 1017761, "per_episode_reward": -281.06, "episode_reward_trend_value": -0.0009173476175110155, "biggest_recent_change": 0.16897259719058866},
{"total_number_of_episodes": 10514, "number_of_timesteps": 1018738, "per_episode_reward": -281.14, "episode_reward_trend_value": -0.00011966791278597258, "biggest_recent_change": 0.16897259719058866},
{"total_number_of_episodes": 10525, "number_of_timesteps": 1019818, "per_episode_reward": -281.23, "episode_reward_trend_value": -0.003040082933021419, "biggest_recent_change": 0.1414231555370975},
{"total_number_of_episodes": 10535, "number_of_timesteps": 1021320, "per_episode_reward": -281.16, "episode_reward_trend_value": -0.0037875598472263995, "biggest_recent_change": 0.12108477262779616},
{"total_number_of_episodes": 10545, "number_of_timesteps": 1022482, "per_episode_reward": -281.33, "episode_reward_trend_value": -0.006416121617399363, "biggest_recent_change": 0.1768957393641699},
{"total_number_of_episodes": 10555, "number_of_timesteps": 1023249, "per_episode_reward": -281.35, "episode_reward_trend_value": -0.007045894074691558, "biggest_recent_change": 0.1768957393641699},
{"total_number_of_episodes": 10565, "number_of_timesteps": 1024054, "per_episode_reward": -281.16, "episode_reward_trend_value": -0.004508505705436821, "biggest_recent_change": 0.19286223692529347},
{"total_number_of_episodes": 10575, "number_of_timesteps": 1025305, "per_episode_reward": -281.41, "episode_reward_trend_value": -0.006492179880746107, "biggest_recent_change": 0.249244341650126},
{"total_number_of_episodes": 10585, "number_of_timesteps": 1026472, "per_episode_reward": -281.36, "episode_reward_trend_value": -0.004648785589082157, "biggest_recent_change": 0.249244341650126},
{"total_number_of_episodes": 10595, "number_of_timesteps": 1027515, "per_episode_reward": -281.39, "episode_reward_trend_value": -0.0036796355920374587, "biggest_recent_change": 0.249244341650126},
{"total_number_of_episodes": 10606, "number_of_timesteps": 1028618, "per_episode_reward": -281.58, "episode_reward_trend_value": -0.0049251007494698715, "biggest_recent_change": 0.249244341650126},
{"total_number_of_episodes": 10616, "number_of_timesteps": 1029482, "per_episode_reward": -281.65, "episode_reward_trend_value": -0.004697096653851278, "biggest_recent_change": 0.249244341650126},
{"total_number_of_episodes": 10626, "number_of_timesteps": 1030475, "per_episode_reward": -281.75, "episode_reward_trend_value": -0.006550147625504603, "biggest_recent_change": 0.249244341650126},
{"total_number_of_episodes": 10636, "number_of_timesteps": 1031661, "per_episode_reward": -281.8, "episode_reward_trend_value": -0.005226077960351303, "biggest_recent_change": 0.249244341650126},
{"total_number_of_episodes": 10646, "number_of_timesteps": 1032682, "per_episode_reward": -281.71, "episode_reward_trend_value": -0.004029316930229419, "biggest_recent_change": 0.249244341650126},
{"total_number_of_episodes": 10657, "number_of_timesteps": 1033498, "per_episode_reward": -281.63, "episode_reward_trend_value": -0.005204892299029021, "biggest_recent_change": 0.249244341650126},
{"total_number_of_episodes": 10669, "number_of_timesteps": 1034519, "per_episode_reward": -281.92, "episode_reward_trend_value": -0.0056853305027623775, "biggest_recent_change": 0.29248377998612796},
{"total_number_of_episodes": 10680, "number_of_timesteps": 1035490, "per_episode_reward": -282.05, "episode_reward_trend_value": -0.007608011557198956, "biggest_recent_change": 0.29248377998612796},
{"total_number_of_episodes": 10690, "number_of_timesteps": 1036536, "per_episode_reward": -282.12, "episode_reward_trend_value": -0.008084052723726625, "biggest_recent_change": 0.29248377998612796},
{"total_number_of_episodes": 10700, "number_of_timesteps": 1037919, "per_episode_reward": -282.22, "episode_reward_trend_value": -0.007107269812606394, "biggest_recent_change": 0.29248377998612796},
{"total_number_of_episodes": 10710, "number_of_timesteps": 1038919, "per_episode_reward": -282.11, "episode_reward_trend_value": -0.005020009834722967, "biggest_recent_change": 0.29248377998612796},
{"total_number_of_episodes": 10721, "number_of_timesteps": 1039863, "per_episode_reward": -282.03, "episode_reward_trend_value": -0.003184451228159762, "biggest_recent_change": 0.29248377998612796},
{"total_number_of_episodes": 10732, "number_of_timesteps": 1040809, "per_episode_reward": -282.06, "episode_reward_trend_value": -0.0028754314573297456, "biggest_recent_change": 0.29248377998612796},
{"total_number_of_episodes": 10743, "number_of_timesteps": 1042043, "per_episode_reward": -281.83, "episode_reward_trend_value": -0.0012594945285608597, "biggest_recent_change": 0.29248377998612796},
{"total_number_of_episodes": 10753, "number_of_timesteps": 1042995, "per_episode_reward": -281.71, "episode_reward_trend_value": -0.0009185357556873441, "biggest_recent_change": 0.29248377998612796},
{"total_number_of_episodes": 10763, "number_of_timesteps": 1043863, "per_episode_reward": -281.81, "episode_reward_trend_value": 0.0012371787190172908, "biggest_recent_change": 0.23629990928338884},
{"total_number_of_episodes": 10773, "number_of_timesteps": 1044894, "per_episode_reward": -281.68, "episode_reward_trend_value": 0.004089682970127089, "biggest_recent_change": 0.23629990928338884},
{"total_number_of_episodes": 10784, "number_of_timesteps": 1045941, "per_episode_reward": -281.64, "episode_reward_trend_value": 0.00531143367300236, "biggest_recent_change": 0.23629990928338884},
{"total_number_of_episodes": 10795, "number_of_timesteps": 1047046, "per_episode_reward": -281.54, "episode_reward_trend_value": 0.007528552646874687, "biggest_recent_change": 0.23629990928338884},
{"total_number_of_episodes": 10806, "number_of_timesteps": 1048204, "per_episode_reward": -281.24, "episode_reward_trend_value": 0.009624889724826365, "biggest_recent_change": 0.30317934900023147},
{"total_number_of_episodes": 10816, "number_of_timesteps": 1049450, "per_episode_reward": -281.14, "episode_reward_trend_value": 0.009935222535119692, "biggest_recent_change": 0.30317934900023147},
{"total_number_of_episodes": 10826, "number_of_timesteps": 1050726, "per_episode_reward": -281.24, "episode_reward_trend_value": 0.00919481810536177, "biggest_recent_change": 0.30317934900023147},
{"total_number_of_episodes": 10837, "number_of_timesteps": 1051911, "per_episode_reward": -281.39, "episode_reward_trend_value": 0.004870908543962413, "biggest_recent_change": 0.30317934900023147},
{"total_number_of_episodes": 10847, "number_of_timesteps": 1053223, "per_episode_reward": -281.34, "episode_reward_trend_value": 0.004143424455633572, "biggest_recent_change": 0.30317934900023147},
{"total_number_of_episodes": 10857, "number_of_timesteps": 1054430, "per_episode_reward": -281.37, "episode_reward_trend_value": 0.004823428305943228, "biggest_recent_change": 0.30317934900023147},
{"total_number_of_episodes": 10867, "number_of_timesteps": 1055807, "per_episode_reward": -281.65, "episode_reward_trend_value": 0.00030111917452712883, "biggest_recent_change": 0.30317934900023147},
{"total_number_of_episodes": 10877, "number_of_timesteps": 1057013, "per_episode_reward": -281.61, "episode_reward_trend_value": 0.0003756300439527472, "biggest_recent_change": 0.30317934900023147},
{"total_number_of_episodes": 10887, "number_of_timesteps": 1058194, "per_episode_reward": -281.79, "episode_reward_trend_value": -0.0027183436662887236, "biggest_recent_change": 0.30317934900023147},
{"total_number_of_episodes": 10897, "number_of_timesteps": 1059619, "per_episode_reward": -281.83, "episode_reward_trend_value": -0.006523729757903614, "biggest_recent_change": 0.2785030205048997},
{"total_number_of_episodes": 10908, "number_of_timesteps": 1060992, "per_episode_reward": -281.95, "episode_reward_trend_value": -0.00905044511646022, "biggest_recent_change": 0.2785030205048997},
{"total_number_of_episodes": 10919, "number_of_timesteps": 1062329, "per_episode_reward": -282.11, "episode_reward_trend_value": -0.0096804713924314, "biggest_recent_change": 0.2785030205048997},
{"total_number_of_episodes": 10929, "number_of_timesteps": 1063609, "per_episode_reward": -282.14, "episode_reward_trend_value": -0.008400034780789965, "biggest_recent_change": 0.2785030205048997},
{"total_number_of_episodes": 10940, "number_of_timesteps": 1064927, "per_episode_reward": -282.26, "episode_reward_trend_value": -0.010299825338830716, "biggest_recent_change": 0.2785030205048997},
{"total_number_of_episodes": 10950, "number_of_timesteps": 1065900, "per_episode_reward": -282.14, "episode_reward_trend_value": -0.00852020638964935, "biggest_recent_change": 0.2785030205048997},
{"total_number_of_episodes": 10961, "number_of_timesteps": 1067147, "per_episode_reward": -282.04, "episode_reward_trend_value": -0.0043115301169229445, "biggest_recent_change": 0.1779109924393083},
{"total_number_of_episodes": 10971, "number_of_timesteps": 1068623, "per_episode_reward": -282.08, "episode_reward_trend_value": -0.00527836901073897, "biggest_recent_change": 0.1779109924393083},
{"total_number_of_episodes": 10981, "number_of_timesteps": 1070223, "per_episode_reward": -282.17, "episode_reward_trend_value": -0.004219490664567931, "biggest_recent_change": 0.1532564536412906},
{"total_number_of_episodes": 10991, "number_of_timesteps": 1071348, "per_episode_reward": -282.26, "episode_reward_trend_value": -0.004780643871696258, "biggest_recent_change": 0.1532564536412906},
{"total_number_of_episodes": 11001, "number_of_timesteps": 1072611, "per_episode_reward": -282.22, "episode_reward_trend_value": -0.002925751009771855, "biggest_recent_change": 0.1532564536412906},
{"total_number_of_episodes": 11012, "number_of_timesteps": 1073824, "per_episode_reward": -282.01, "episode_reward_trend_value": 0.001062268007694911, "biggest_recent_change": 0.20566525793071833},
{"total_number_of_episodes": 11022, "number_of_timesteps": 1075206, "per_episode_reward": -281.88, "episode_reward_trend_value": 0.0029144235810917964, "biggest_recent_change": 0.20566525793071833},
{"total_number_of_episodes": 11032, "number_of_timesteps": 1076352, "per_episode_reward": -281.99, "episode_reward_trend_value": 0.0030237859098507314, "biggest_recent_change": 0.20566525793071833},
{"total_number_of_episodes": 11043, "number_of_timesteps": 1077625, "per_episode_reward": -281.99, "episode_reward_trend_value": 0.0016595696231358186, "biggest_recent_change": 0.20566525793071833},
{"total_number_of_episodes": 11053, "number_of_timesteps": 1078644, "per_episode_reward": -281.95, "episode_reward_trend_value": 0.000971296772315908, "biggest_recent_change": 0.20566525793071833},
{"total_number_of_episodes": 11063, "number_of_timesteps": 1079672, "per_episode_reward": -281.48, "episode_reward_trend_value": 0.00675037113974655, "biggest_recent_change": 0.4755810487152985},
{"total_number_of_episodes": 11073, "number_of_timesteps": 1080802, "per_episode_reward": -281.29, "episode_reward_trend_value": 0.009706559364189439, "biggest_recent_change": 0.4755810487152985},
{"total_number_of_episodes": 11083, "number_of_timesteps": 1082193, "per_episode_reward": -281.37, "episode_reward_trend_value": 0.00988853887830664, "biggest_recent_change": 0.4755810487152985},
{"total_number_of_episodes": 11093, "number_of_timesteps": 1083564, "per_episode_reward": -281.32, "episode_reward_trend_value": 0.009941067993130697, "biggest_recent_change": 0.4755810487152985},
{"total_number_of_episodes": 11103, "number_of_timesteps": 1084979, "per_episode_reward": -281.2, "episode_reward_trend_value": 0.00896596092247061, "biggest_recent_change": 0.4755810487152985},
{"total_number_of_episodes": 11113, "number_of_timesteps": 1086616, "per_episode_reward": -281.03, "episode_reward_trend_value": 0.009430842562935342, "biggest_recent_change": 0.4755810487152985},
{"total_number_of_episodes": 11123, "number_of_timesteps": 1088343, "per_episode_reward": -281.09, "episode_reward_trend_value": 0.009989527508312473, "biggest_recent_change": 0.4755810487152985},
{"total_number_of_episodes": 11134, "number_of_timesteps": 1089851, "per_episode_reward": -280.7, "episode_reward_trend_value": 0.0143863275603135, "biggest_recent_change": 0.4755810487152985},
{"total_number_of_episodes": 11144, "number_of_timesteps": 1090969, "per_episode_reward": -280.42, "episode_reward_trend_value": 0.01702879998642667, "biggest_recent_change": 0.4755810487152985},
{"total_number_of_episodes": 11155, "number_of_timesteps": 1092518, "per_episode_reward": -280.15, "episode_reward_trend_value": 0.01476569818488479, "biggest_recent_change": 0.39582911356723116},
{"total_number_of_episodes": 11165, "number_of_timesteps": 1094094, "per_episode_reward": -280.11, "episode_reward_trend_value": 0.013116669914660406, "biggest_recent_change": 0.39582911356723116},
{"total_number_of_episodes": 11175, "number_of_timesteps": 1095323, "per_episode_reward": -279.91, "episode_reward_trend_value": 0.01615162962046952, "biggest_recent_change": 0.39582911356723116},
{"total_number_of_episodes": 11185, "number_of_timesteps": 1096481, "per_episode_reward": -279.84, "episode_reward_trend_value": 0.016443056104505634, "biggest_recent_change": 0.39582911356723116},
{"total_number_of_episodes": 11195, "number_of_timesteps": 1097698, "per_episode_reward": -279.45, "episode_reward_trend_value": 0.019506486616389415, "biggest_recent_change": 0.39582911356723116},
{"total_number_of_episodes": 11205, "number_of_timesteps": 1099133, "per_episode_reward": -279.28, "episode_reward_trend_value": 0.01946565009887738, "biggest_recent_change": 0.39582911356723116},
{"total_number_of_episodes": 11215, "number_of_timesteps": 1100693, "per_episode_reward": -279.06, "episode_reward_trend_value": 0.022569387153357136, "biggest_recent_change": 0.39582911356723116},
{"total_number_of_episodes": 11225, "number_of_timesteps": 1102101, "per_episode_reward": -278.98, "episode_reward_trend_value": 0.019040007550744854, "biggest_recent_change": 0.39361436764085056},
{"total_number_of_episodes": 11235, "number_of_timesteps": 1103584, "per_episode_reward": -278.82, "episode_reward_trend_value": 0.017734004687072986, "biggest_recent_change": 0.39361436764085056},
{"total_number_of_episodes": 11245, "number_of_timesteps": 1104792, "per_episode_reward": -278.68, "episode_reward_trend_value": 0.01632119061766275, "biggest_recent_change": 0.39361436764085056},
{"total_number_of_episodes": 11255, "number_of_timesteps": 1105938, "per_episode_reward": -278.62, "episode_reward_trend_value": 0.016624869086061582, "biggest_recent_change": 0.39361436764085056},
{"total_number_of_episodes": 11265, "number_of_timesteps": 1107149, "per_episode_reward": -278.43, "episode_reward_trend_value": 0.01642486005614311, "biggest_recent_change": 0.39361436764085056},
{"total_number_of_episodes": 11277, "number_of_timesteps": 1108648, "per_episode_reward": -278.35, "episode_reward_trend_value": 0.016604506665731832, "biggest_recent_change": 0.39361436764085056},
{"total_number_of_episodes": 11287, "number_of_timesteps": 1109567, "per_episode_reward": -278.37, "episode_reward_trend_value": 0.01196626630110005, "biggest_recent_change": 0.22075261469410634},
{"total_number_of_episodes": 11297, "number_of_timesteps": 1110308, "per_episode_reward": -278.22, "episode_reward_trend_value": 0.011769828251138708, "biggest_recent_change": 0.22075261469410634},
{"total_number_of_episodes": 11307, "number_of_timesteps": 1111174, "per_episode_reward": -278.09, "episode_reward_trend_value": 0.010807052572183314, "biggest_recent_change": 0.18171452921404807},
{"total_number_of_episodes": 11317, "number_of_timesteps": 1111918, "per_episode_reward": -277.89, "episode_reward_trend_value": 0.012179583743183129, "biggest_recent_change": 0.20171275472210937},
{"total_number_of_episodes": 11327, "number_of_timesteps": 1112878, "per_episode_reward": -277.68, "episode_reward_trend_value": 0.012719402591616497, "biggest_recent_change": 0.20719924444540538},
{"total_number_of_episodes": 11337, "number_of_timesteps": 1114019, "per_episode_reward": -277.56, "episode_reward_trend_value": 0.012422736247474909, "biggest_recent_change": 0.20719924444540538},
{"total_number_of_episodes": 11347, "number_of_timesteps": 1115346, "per_episode_reward": -277.27, "episode_reward_trend_value": 0.014920512960875007, "biggest_recent_change": 0.2871634209576541},
{"total_number_of_episodes": 11357, "number_of_timesteps": 1116778, "per_episode_reward": -277.26, "episode_reward_trend_value": 0.013105492961587592, "biggest_recent_change": 0.2871634209576541},
{"total_number_of_episodes": 11368, "number_of_timesteps": 1118022, "per_episode_reward": -276.97, "episode_reward_trend_value": 0.01535289172690884, "biggest_recent_change": 0.28943193626935226},
{"total_number_of_episodes": 11378, "number_of_timesteps": 1118979, "per_episode_reward": -276.83, "episode_reward_trend_value": 0.017074075082758277, "biggest_recent_change": 0.28943193626935226},
{"total_number_of_episodes": 11388, "number_of_timesteps": 1120061, "per_episode_reward": -276.73, "episode_reward_trend_value": 0.016543909442229835, "biggest_recent_change": 0.28943193626935226},
{"total_number_of_episodes": 11398, "number_of_timesteps": 1121426, "per_episode_reward": -276.63, "episode_reward_trend_value": 0.016174688983718648, "biggest_recent_change": 0.28943193626935226},
{"total_number_of_episodes": 11408, "number_of_timesteps": 1122940, "per_episode_reward": -276.49, "episode_reward_trend_value": 0.015460703433135829, "biggest_recent_change": 0.28943193626935226},
{"total_number_of_episodes": 11419, "number_of_timesteps": 1124820, "per_episode_reward": -276.22, "episode_reward_trend_value": 0.016235008869796907, "biggest_recent_change": 0.28943193626935226},
{"total_number_of_episodes": 11429, "number_of_timesteps": 1126159, "per_episode_reward": -276.02, "episode_reward_trend_value": 0.01710314787180904, "biggest_recent_change": 0.28943193626935226},
{"total_number_of_episodes": 11439, "number_of_timesteps": 1127358, "per_episode_reward": -275.99, "episode_reward_trend_value": 0.014235431362246549, "biggest_recent_change": 0.28943193626935226},
{"total_number_of_episodes": 11450, "number_of_timesteps": 1128976, "per_episode_reward": -275.59, "episode_reward_trend_value": 0.01853557193281922, "biggest_recent_change": 0.4053753806297209},
{"total_number_of_episodes": 11461, "number_of_timesteps": 1130378, "per_episode_reward": -275.5, "episode_reward_trend_value": 0.016285342251755867, "biggest_recent_change": 0.4053753806297209},
{"total_number_of_episodes": 11472, "number_of_timesteps": 1131639, "per_episode_reward": -275.35, "episode_reward_trend_value": 0.01651238903838753, "biggest_recent_change": 0.4053753806297209},
{"total_number_of_episodes": 11482, "number_of_timesteps": 1132910, "per_episode_reward": -275.19, "episode_reward_trend_value": 0.01716113528305085, "biggest_recent_change": 0.4053753806297209},
{"total_number_of_episodes": 11492, "number_of_timesteps": 1134022, "per_episode_reward": -275.07, "episode_reward_trend_value": 0.017411895425100788, "biggest_recent_change": 0.4053753806297209},
{"total_number_of_episodes": 11502, "number_of_timesteps": 1135185, "per_episode_reward": -274.95, "episode_reward_trend_value": 0.017181646793093502, "biggest_recent_change": 0.4053753806297209},
{"total_number_of_episodes": 11512, "number_of_timesteps": 1136388, "per_episode_reward": -274.84, "episode_reward_trend_value": 0.015297866711630881, "biggest_recent_change": 0.4053753806297209},
{"total_number_of_episodes": 11523, "number_of_timesteps": 1137797, "per_episode_reward": -274.78, "episode_reward_trend_value": 0.01383161450886329, "biggest_recent_change": 0.4053753806297209},
{"total_number_of_episodes": 11533, "number_of_timesteps": 1139612, "per_episode_reward": -274.61, "episode_reward_trend_value": 0.015395546285463978, "biggest_recent_change": 0.4053753806297209},
{"total_number_of_episodes": 11544, "number_of_timesteps": 1141380, "per_episode_reward": -274.57, "episode_reward_trend_value": 0.011309592507187619, "biggest_recent_change": 0.16982279499109154},
{"total_number_of_episodes": 11555, "number_of_timesteps": 1142297, "per_episode_reward": -274.63, "episode_reward_trend_value": 0.009700803789301441, "biggest_recent_change": 0.16982279499109154},
{"total_number_of_episodes": 11567, "number_of_timesteps": 1143145, "per_episode_reward": -274.26, "episode_reward_trend_value": 0.012074997480448246, "biggest_recent_change": 0.3651908798505019},
{"total_number_of_episodes": 11578, "number_of_timesteps": 1143911, "per_episode_reward": -274.21, "episode_reward_trend_value": 0.010887856555662741, "biggest_recent_change": 0.3651908798505019},
{"total_number_of_episodes": 11588, "number_of_timesteps": 1144588, "per_episode_reward": -274.09, "episode_reward_trend_value": 0.010853521267860818, "biggest_recent_change": 0.3651908798505019},
{"total_number_of_episodes": 11599, "number_of_timesteps": 1145405, "per_episode_reward": -273.94, "episode_reward_trend_value": 0.0112334766131514, "biggest_recent_change": 0.3651908798505019},
{"total_number_of_episodes": 11610, "number_of_timesteps": 1146302, "per_episode_reward": -273.8, "episode_reward_trend_value": 0.01155140198549955, "biggest_recent_change": 0.3651908798505019},
{"total_number_of_episodes": 11620, "number_of_timesteps": 1147203, "per_episode_reward": -273.64, "episode_reward_trend_value": 0.01261223962320249, "biggest_recent_change": 0.3651908798505019},
{"total_number_of_episodes": 11630, "number_of_timesteps": 1148369, "per_episode_reward": -273.48, "episode_reward_trend_value": 0.012546819159109646, "biggest_recent_change": 0.3651908798505019},
{"total_number_of_episodes": 11641, "number_of_timesteps": 1149822, "per_episode_reward": -273.24, "episode_reward_trend_value": 0.014762183722964058, "biggest_recent_change": 0.3651908798505019},
{"total_number_of_episodes": 11651, "number_of_timesteps": 1151006, "per_episode_reward": -272.99, "episode_reward_trend_value": 0.018155006883386525, "biggest_recent_change": 0.3651908798505019},
{"total_number_of_episodes": 11661, "number_of_timesteps": 1152200, "per_episode_reward": -272.9, "episode_reward_trend_value": 0.0151606702701934, "biggest_recent_change": 0.2474743648019171},
{"total_number_of_episodes": 11672, "number_of_timesteps": 1153640, "per_episode_reward": -272.56, "episode_reward_trend_value": 0.018342598848127206, "biggest_recent_change": 0.33976912513560364},
{"total_number_of_episodes": 11682, "number_of_timesteps": 1155031, "per_episode_reward": -272.43, "episode_reward_trend_value": 0.018413121954893717, "biggest_recent_change": 0.33976912513560364},
{"total_number_of_episodes": 11692, "number_of_timesteps": 1156016, "per_episode_reward": -272.28, "episode_reward_trend_value": 0.018465772282971533, "biggest_recent_change": 0.33976912513560364},
{"total_number_of_episodes": 11702, "number_of_timesteps": 1157104, "per_episode_reward": -272.17, "episode_reward_trend_value": 0.018152779554957178, "biggest_recent_change": 0.33976912513560364},
{"total_number_of_episodes": 11713, "number_of_timesteps": 1158215, "per_episode_reward": -271.86, "episode_reward_trend_value": 0.019784661144409986, "biggest_recent_change": 0.33976912513560364},
{"total_number_of_episodes": 11723, "number_of_timesteps": 1160221, "per_episode_reward": -271.77, "episode_reward_trend_value": 0.01899370343245247, "biggest_recent_change": 0.33976912513560364},
{"total_number_of_episodes": 11733, "number_of_timesteps": 1161287, "per_episode_reward": -271.7, "episode_reward_trend_value": 0.017174778238957186, "biggest_recent_change": 0.33976912513560364},
{"total_number_of_episodes": 11743, "number_of_timesteps": 1162379, "per_episode_reward": -271.6, "episode_reward_trend_value": 0.015465529527188614, "biggest_recent_change": 0.33976912513560364},
{"total_number_of_episodes": 11754, "number_of_timesteps": 1163749, "per_episode_reward": -271.32, "episode_reward_trend_value": 0.017508693963935684, "biggest_recent_change": 0.33976912513560364},
{"total_number_of_episodes": 11765, "number_of_timesteps": 1164859, "per_episode_reward": -271.17, "episode_reward_trend_value": 0.01542023346771657, "biggest_recent_change": 0.3065631917328915},
{"total_number_of_episodes": 11775, "number_of_timesteps": 1166127, "per_episode_reward": -271.02, "episode_reward_trend_value": 0.0157335564699603, "biggest_recent_change": 0.3065631917328915},
{"total_number_of_episodes": 11786, "number_of_timesteps": 1168525, "per_episode_reward": -270.79, "episode_reward_trend_value": 0.016479388632551363, "biggest_recent_change": 0.3065631917328915},
{"total_number_of_episodes": 11797, "number_of_timesteps": 1170052, "per_episode_reward": -270.51, "episode_reward_trend_value": 0.018366582332269368, "biggest_recent_change": 0.3065631917328915},
{"total_number_of_episodes": 11807, "number_of_timesteps": 1171300, "per_episode_reward": -270.34, "episode_reward_trend_value": 0.016922962118590273, "biggest_recent_change": 0.2795853839703568},
{"total_number_of_episodes": 11818, "number_of_timesteps": 1172681, "per_episode_reward": -270.09, "episode_reward_trend_value": 0.01864553909694943, "biggest_recent_change": 0.2795853839703568},
{"total_number_of_episodes": 11828, "number_of_timesteps": 1174063, "per_episode_reward": -269.88, "episode_reward_trend_value": 0.0202051989967174, "biggest_recent_change": 0.2795853839703568},
{"total_number_of_episodes": 11839, "number_of_timesteps": 1175439, "per_episode_reward": -269.39, "episode_reward_trend_value": 0.0246176848091112, "biggest_recent_change": 0.4907657038581874},
{"total_number_of_episodes": 11849, "number_of_timesteps": 1176710, "per_episode_reward": -268.94, "episode_reward_trend_value": 0.026451737214089617, "biggest_recent_change": 0.4907657038581874},
{"total_number_of_episodes": 11859, "number_of_timesteps": 1177980, "per_episode_reward": -268.71, "episode_reward_trend_value": 0.02734013247340638, "biggest_recent_change": 0.4907657038581874},
{"total_number_of_episodes": 11870, "number_of_timesteps": 1179146, "per_episode_reward": -268.63, "episode_reward_trend_value": 0.02655124038148402, "biggest_recent_change": 0.4907657038581874},
{"total_number_of_episodes": 11881, "number_of_timesteps": 1180311, "per_episode_reward": -268.56, "episode_reward_trend_value": 0.02480854076260799, "biggest_recent_change": 0.4907657038581874},
{"total_number_of_episodes": 11891, "number_of_timesteps": 1181465, "per_episode_reward": -268.47, "episode_reward_trend_value": 0.022697631644835306, "biggest_recent_change": 0.4907657038581874},
{"total_number_of_episodes": 11901, "number_of_timesteps": 1182438, "per_episode_reward": -268.35, "episode_reward_trend_value": 0.022040059720886043, "biggest_recent_change": 0.4907657038581874},
{"total_number_of_episodes": 11911, "number_of_timesteps": 1183354, "per_episode_reward": -268.28, "episode_reward_trend_value": 0.020151861483762128, "biggest_recent_change": 0.4907657038581874},
{"total_number_of_episodes": 11922, "number_of_timesteps": 1184484, "per_episode_reward": -268.2, "episode_reward_trend_value": 0.01864738915980979, "biggest_recent_change": 0.4907657038581874},
{"total_number_of_episodes": 11934, "number_of_timesteps": 1186006, "per_episode_reward": -268.05, "episode_reward_trend_value": 0.01484269036994874, "biggest_recent_change": 0.44465010041841424},
{"total_number_of_episodes": 11944, "number_of_timesteps": 1187408, "per_episode_reward": -267.93, "episode_reward_trend_value": 0.011249413783448542, "biggest_recent_change": 0.23176325381439256},
{"total_number_of_episodes": 11954, "number_of_timesteps": 1188832, "per_episode_reward": -267.8, "episode_reward_trend_value": 0.01011601720493584, "biggest_recent_change": 0.14834281277069294},
{"total_number_of_episodes": 11964, "number_of_timesteps": 1190191, "per_episode_reward": -267.69, "episode_reward_trend_value": 0.010408075773050187, "biggest_recent_change": 0.14834281277069294},
{"total_number_of_episodes": 11974, "number_of_timesteps": 1191405, "per_episode_reward": -267.4, "episode_reward_trend_value": 0.012853089236096415, "biggest_recent_change": 0.28599932950066886},
{"total_number_of_episodes": 11984, "number_of_timesteps": 1193097, "per_episode_reward": -267.32, "episode_reward_trend_value": 0.012820990385949926, "biggest_recent_change": 0.28599932950066886},
{"total_number_of_episodes": 11995, "number_of_timesteps": 1194671, "per_episode_reward": -267.12, "episode_reward_trend_value": 0.013753202710654477, "biggest_recent_change": 0.28599932950066886},
{"total_number_of_episodes": 12006, "number_of_timesteps": 1195675, "per_episode_reward": -266.81, "episode_reward_trend_value": 0.01626356678681999, "biggest_recent_change": 0.3037756127126272},
{"total_number_of_episodes": 12017, "number_of_timesteps": 1196810, "per_episode_reward": -266.7, "episode_reward_trend_value": 0.01664810065126719, "biggest_recent_change": 0.3037756127126272},
{"total_number_of_episodes": 12027, "number_of_timesteps": 1197963, "per_episode_reward": -266.61, "episode_reward_trend_value": 0.01597933073122325, "biggest_recent_change": 0.3037756127126272},
{"total_number_of_episodes": 12037, "number_of_timesteps": 1199308, "per_episode_reward": -266.51, "episode_reward_trend_value": 0.015714721373879255, "biggest_recent_change": 0.3037756127126272},
{"total_number_of_episodes": 12047, "number_of_timesteps": 1200787, "per_episode_reward": -266.38, "episode_reward_trend_value": 0.015738411539499945, "biggest_recent_change": 0.3037756127126272},
{"total_number_of_episodes": 12058, "number_of_timesteps": 1202303, "per_episode_reward": -266.28, "episode_reward_trend_value": 0.015689013185741865, "biggest_recent_change": 0.3037756127126272},
{"total_number_of_episodes": 12068, "number_of_timesteps": 1203769, "per_episode_reward": -266.14, "episode_reward_trend_value": 0.013990081570624271, "biggest_recent_change": 0.3037756127126272},
{"total_number_of_episodes": 12078, "number_of_timesteps": 1204915, "per_episode_reward": -266.02, "episode_reward_trend_value": 0.014417313731922832, "biggest_recent_change": 0.3037756127126272},
{"total_number_of_episodes": 12088, "number_of_timesteps": 1206212, "per_episode_reward": -265.94, "episode_reward_trend_value": 0.013093083036621541, "biggest_recent_change": 0.3037756127126272},
{"total_number_of_episodes": 12098, "number_of_timesteps": 1207457, "per_episode_reward": -265.57, "episode_reward_trend_value": 0.013813281239913522, "biggest_recent_change": 0.3685934510089055},
{"total_number_of_episodes": 12108, "number_of_timesteps": 1210517, "per_episode_reward": -265.32, "episode_reward_trend_value": 0.015341665600249143, "biggest_recent_change": 0.3685934510089055},
{"total_number_of_episodes": 12119, "number_of_timesteps": 1211558, "per_episode_reward": -265.16, "episode_reward_trend_value": 0.016112279965131572, "biggest_recent_change": 0.3685934510089055},
{"total_number_of_episodes": 12129, "number_of_timesteps": 1212795, "per_episode_reward": -265.02, "episode_reward_trend_value": 0.01662349958561625, "biggest_recent_change": 0.3685934510089055},
{"total_number_of_episodes": 12139, "number_of_timesteps": 1215164, "per_episode_reward": -264.82, "episode_reward_trend_value": 0.017378418390398387, "biggest_recent_change": 0.3685934510089055},
{"total_number_of_episodes": 12149, "number_of_timesteps": 1216494, "per_episode_reward": -264.57, "episode_reward_trend_value": 0.018911925092841862, "biggest_recent_change": 0.3685934510089055},
{"total_number_of_episodes": 12159, "number_of_timesteps": 1217573, "per_episode_reward": -264.4, "episode_reward_trend_value": 0.019422499477534907, "biggest_recent_change": 0.3685934510089055},
{"total_number_of_episodes": 12169, "number_of_timesteps": 1218614, "per_episode_reward": -264.3, "episode_reward_trend_value": 0.01913297397440235, "biggest_recent_change": 0.3685934510089055},
{"total_number_of_episodes": 12179, "number_of_timesteps": 1219670, "per_episode_reward": -264.19, "episode_reward_trend_value": 0.019446573561529908, "biggest_recent_change": 0.3685934510089055},
{"total_number_of_episodes": 12189, "number_of_timesteps": 1220944, "per_episode_reward": -264.05, "episode_reward_trend_value": 0.01693277600990781, "biggest_recent_change": 0.25044860597103025},
{"total_number_of_episodes": 12200, "number_of_timesteps": 1222575, "per_episode_reward": -263.94, "episode_reward_trend_value": 0.015301483332786525, "biggest_recent_change": 0.2437520832543214},
{"total_number_of_episodes": 12210, "number_of_timesteps": 1223816, "per_episode_reward": -263.87, "episode_reward_trend_value": 0.014302816026069979, "biggest_recent_change": 0.2437520832543214},
{"total_number_of_episodes": 12220, "number_of_timesteps": 1224826, "per_episode_reward": -263.7, "episode_reward_trend_value": 0.014610048368393158, "biggest_recent_change": 0.2437520832543214},
{"total_number_of_episodes": 12232, "number_of_timesteps": 1225865, "per_episode_reward": -263.49, "episode_reward_trend_value": 0.014721373021411133, "biggest_recent_change": 0.2437520832543214},
{"total_number_of_episodes": 12243, "number_of_timesteps": 1226998, "per_episode_reward": -263.07, "episode_reward_trend_value": 0.01675172787325007, "biggest_recent_change": 0.4264840199198261},
{"total_number_of_episodes": 12253, "number_of_timesteps": 1228478, "per_episode_reward": -262.94, "episode_reward_trend_value": 0.016172503144441762, "biggest_recent_change": 0.4264840199198261},
{"total_number_of_episodes": 12264, "number_of_timesteps": 1229789, "per_episode_reward": -262.78, "episode_reward_trend_value": 0.01687262610886301, "biggest_recent_change": 0.4264840199198261},
{"total_number_of_episodes": 12274, "number_of_timesteps": 1231009, "per_episode_reward": -262.61, "episode_reward_trend_value": 0.01748764775547392, "biggest_recent_change": 0.4264840199198261},
{"total_number_of_episodes": 12287, "number_of_timesteps": 1232517, "per_episode_reward": -262.43, "episode_reward_trend_value": 0.017965597929211676, "biggest_recent_change": 0.4264840199198261},
{"total_number_of_episodes": 12297, "number_of_timesteps": 1233442, "per_episode_reward": -262.29, "episode_reward_trend_value": 0.018399784494986686, "biggest_recent_change": 0.4264840199198261},
{"total_number_of_episodes": 12308, "number_of_timesteps": 1235042, "per_episode_reward": -262.12, "episode_reward_trend_value": 0.019441753769613494, "biggest_recent_change": 0.4264840199198261},
{"total_number_of_episodes": 12318, "number_of_timesteps": 1236314, "per_episode_reward": -262.03, "episode_reward_trend_value": 0.018610817396437874, "biggest_recent_change": 0.4264840199198261},
{"total_number_of_episodes": 12328, "number_of_timesteps": 1238012, "per_episode_reward": -261.88, "episode_reward_trend_value": 0.017895110733613568, "biggest_recent_change": 0.4264840199198261},
{"total_number_of_episodes": 12338, "number_of_timesteps": 1239202, "per_episode_reward": -261.69, "episode_reward_trend_value": 0.015247967433770604, "biggest_recent_change": 0.18824112293395956},
{"total_number_of_episodes": 12348, "number_of_timesteps": 1240162, "per_episode_reward": -261.47, "episode_reward_trend_value": 0.016378160246259515, "biggest_recent_change": 0.2286343062937135},
{"total_number_of_episodes": 12359, "number_of_timesteps": 1241232, "per_episode_reward": -261.24, "episode_reward_trend_value": 0.01707741080290298, "biggest_recent_change": 0.2286343062937135},
{"total_number_of_episodes": 12369, "number_of_timesteps": 1242306, "per_episode_reward": -261.01, "episode_reward_trend_value": 0.017787468070691956, "biggest_recent_change": 0.2296553111301023},
{"total_number_of_episodes": 12379, "number_of_timesteps": 1243366, "per_episode_reward": -260.82, "episode_reward_trend_value": 0.017918295873295798, "biggest_recent_change": 0.2296553111301023},
{"total_number_of_episodes": 12389, "number_of_timesteps": 1245094, "per_episode_reward": -260.71, "episode_reward_trend_value": 0.017517908678527445, "biggest_recent_change": 0.2296553111301023},
{"total_number_of_episodes": 12402, "number_of_timesteps": 1246525, "per_episode_reward": -260.51, "episode_reward_trend_value": 0.017982766774165763, "biggest_recent_change": 0.2296553111301023},
{"total_number_of_episodes": 12413, "number_of_timesteps": 1247903, "per_episode_reward": -260.31, "episode_reward_trend_value": 0.019126108272205202, "biggest_recent_change": 0.2296553111301023},
{"total_number_of_episodes": 12423, "number_of_timesteps": 1249364, "per_episode_reward": -260.22, "episode_reward_trend_value": 0.01842471678886063, "biggest_recent_change": 0.2296553111301023},
{"total_number_of_episodes": 12433, "number_of_timesteps": 1250695, "per_episode_reward": -260.15, "episode_reward_trend_value": 0.01711250390923548, "biggest_recent_change": 0.2296553111301023},
{"total_number_of_episodes": 12443, "number_of_timesteps": 1252254, "per_episode_reward": -260.09, "episode_reward_trend_value": 0.015317753738860221, "biggest_recent_change": 0.2296553111301023},
{"total_number_of_episodes": 12453, "number_of_timesteps": 1253895, "per_episode_reward": -260.01, "episode_reward_trend_value": 0.013701474528062363, "biggest_recent_change": 0.2296553111301023},
{"total_number_of_episodes": 12463, "number_of_timesteps": 1255277, "per_episode_reward": -259.94, "episode_reward_trend_value": 0.011892492061201033, "biggest_recent_change": 0.20324321852552885},
{"total_number_of_episodes": 12473, "number_of_timesteps": 1256450, "per_episode_reward": -259.85, "episode_reward_trend_value": 0.01068470982045066, "biggest_recent_change": 0.20324321852552885},
{"total_number_of_episodes": 12484, "number_of_timesteps": 1258168, "per_episode_reward": -259.53, "episode_reward_trend_value": 0.01314396444094099, "biggest_recent_change": 0.32800712426484324},
{"total_number_of_episodes": 12495, "number_of_timesteps": 1260387, "per_episode_reward": -259.08, "episode_reward_trend_value": 0.015864939626446688, "biggest_recent_change": 0.44813098522104156},
{"total_number_of_episodes": 12506, "number_of_timesteps": 1261735, "per_episode_reward": -258.93, "episode_reward_trend_value": 0.01531824861440959, "biggest_recent_change": 0.44813098522104156},
{"total_number_of_episodes": 12516, "number_of_timesteps": 1262770, "per_episode_reward": -258.78, "episode_reward_trend_value": 0.016015104514181328, "biggest_recent_change": 0.44813098522104156},
{"total_number_of_episodes": 12527, "number_of_timesteps": 1264168, "per_episode_reward": -258.58, "episode_reward_trend_value": 0.01746402772551695, "biggest_recent_change": 0.44813098522104156},
{"total_number_of_episodes": 12538, "number_of_timesteps": 1265487, "per_episode_reward": -258.43, "episode_reward_trend_value": 0.018431435855691486, "biggest_recent_change": 0.44813098522104156},
{"total_number_of_episodes": 12548, "number_of_timesteps": 1266990, "per_episode_reward": -258.26, "episode_reward_trend_value": 0.019393810518753045, "biggest_recent_change": 0.44813098522104156},
{"total_number_of_episodes": 12559, "number_of_timesteps": 1268461, "per_episode_reward": -258.13, "episode_reward_trend_value": 0.020101662753618636, "biggest_recent_change": 0.44813098522104156},
{"total_number_of_episodes": 12569, "number_of_timesteps": 1269603, "per_episode_reward": -258.0, "episode_reward_trend_value": 0.020562064343411318, "biggest_recent_change": 0.44813098522104156},
{"total_number_of_episodes": 12579, "number_of_timesteps": 1271116, "per_episode_reward": -257.85, "episode_reward_trend_value": 0.018669338077122826, "biggest_recent_change": 0.44813098522104156},
{"total_number_of_episodes": 12589, "number_of_timesteps": 1272798, "per_episode_reward": -257.68, "episode_reward_trend_value": 0.015516619360043175, "biggest_recent_change": 0.20054505278790202},
{"total_number_of_episodes": 12600, "number_of_timesteps": 1274068, "per_episode_reward": -257.49, "episode_reward_trend_value": 0.01599452077420551, "biggest_recent_change": 0.20054505278790202},
{"total_number_of_episodes": 12611, "number_of_timesteps": 1274925, "per_episode_reward": -257.33, "episode_reward_trend_value": 0.016162636688430133, "biggest_recent_change": 0.20054505278790202},
{"total_number_of_episodes": 12621, "number_of_timesteps": 1275804, "per_episode_reward": -257.16, "episode_reward_trend_value": 0.015854904608040166, "biggest_recent_change": 0.19302643955415988},
{"total_number_of_episodes": 12631, "number_of_timesteps": 1277188, "per_episode_reward": -256.6, "episode_reward_trend_value": 0.020265876945491198, "biggest_recent_change": 0.5511610330462418},
{"total_number_of_episodes": 12641, "number_of_timesteps": 1278549, "per_episode_reward": -256.43, "episode_reward_trend_value": 0.020354549358779016, "biggest_recent_change": 0.5511610330462418},
{"total_number_of_episodes": 12651, "number_of_timesteps": 1279699, "per_episode_reward": -256.33, "episode_reward_trend_value": 0.020020697785044048, "biggest_recent_change": 0.5511610330462418},
{"total_number_of_episodes": 12661, "number_of_timesteps": 1280729, "per_episode_reward": -256.14, "episode_reward_trend_value": 0.0207025966838709, "biggest_recent_change": 0.5511610330462418},
{"total_number_of_episodes": 12671, "number_of_timesteps": 1282212, "per_episode_reward": -255.94, "episode_reward_trend_value": 0.021202462882379473, "biggest_recent_change": 0.5511610330462418},
{"total_number_of_episodes": 12681, "number_of_timesteps": 1283525, "per_episode_reward": -255.74, "episode_reward_trend_value": 0.021539415021979695, "biggest_recent_change": 0.5511610330462418},
{"total_number_of_episodes": 12692, "number_of_timesteps": 1284756, "per_episode_reward": -255.56, "episode_reward_trend_value": 0.021425868667085977, "biggest_recent_change": 0.5511610330462418},
{"total_number_of_episodes": 12702, "number_of_timesteps": 1286083, "per_episode_reward": -255.43, "episode_reward_trend_value": 0.021065797235193095, "biggest_recent_change": 0.5511610330462418},
{"total_number_of_episodes": 12712, "number_of_timesteps": 1287061, "per_episode_reward": -255.29, "episode_reward_trend_value": 0.020745239706775147, "biggest_recent_change": 0.5511610330462418},
{"total_number_of_episodes": 12722, "number_of_timesteps": 1288159, "per_episode_reward": -255.13, "episode_reward_trend_value": 0.016419884270370253, "biggest_recent_change": 0.2026497181646505},
{"total_number_of_episodes": 12732, "number_of_timesteps": 1289254, "per_episode_reward": -255.04, "episode_reward_trend_value": 0.015497159563225043, "biggest_recent_change": 0.2026497181646505},
{"total_number_of_episodes": 12742, "number_of_timesteps": 1290606, "per_episode_reward": -254.9, "episode_reward_trend_value": 0.015930539196908296, "biggest_recent_change": 0.2026497181646505},
{"total_number_of_episodes": 12752, "number_of_timesteps": 1291971, "per_episode_reward": -254.83, "episode_reward_trend_value": 0.014619395626995888, "biggest_recent_change": 0.2026497181646505},
{"total_number_of_episodes": 12764, "number_of_timesteps": 1293719, "per_episode_reward": -254.31, "episode_reward_trend_value": 0.018130285528855615, "biggest_recent_change": 0.5186298093320261},
{"total_number_of_episodes": 12774, "number_of_timesteps": 1294629, "per_episode_reward": -254.22, "episode_reward_trend_value": 0.016955483776027968, "biggest_recent_change": 0.5186298093320261},
{"total_number_of_episodes": 12784, "number_of_timesteps": 1295661, "per_episode_reward": -254.09, "episode_reward_trend_value": 0.016309291888701852, "biggest_recent_change": 0.5186298093320261},
{"total_number_of_episodes": 12795, "number_of_timesteps": 1297272, "per_episode_reward": -253.84, "episode_reward_trend_value": 0.01765362877652276, "biggest_recent_change": 0.5186298093320261},
{"total_number_of_episodes": 12805, "number_of_timesteps": 1298657, "per_episode_reward": -253.77, "episode_reward_trend_value": 0.01688190553305257, "biggest_recent_change": 0.5186298093320261},
{"total_number_of_episodes": 12815, "number_of_timesteps": 1299806, "per_episode_reward": -253.67, "episode_reward_trend_value": 0.016196172127928954, "biggest_recent_change": 0.5186298093320261},
{"total_number_of_episodes": 12825, "number_of_timesteps": 1301326, "per_episode_reward": -253.59, "episode_reward_trend_value": 0.01609606045635196, "biggest_recent_change": 0.5186298093320261},
{"total_number_of_episodes": 12836, "number_of_timesteps": 1302677, "per_episode_reward": -253.46, "episode_reward_trend_value": 0.01595696728016094, "biggest_recent_change": 0.5186298093320261},
{"total_number_of_episodes": 12846, "number_of_timesteps": 1303822, "per_episode_reward": -253.42, "episode_reward_trend_value": 0.01565660436056899, "biggest_recent_change": 0.5186298093320261},
{"total_number_of_episodes": 12856, "number_of_timesteps": 1305128, "per_episode_reward": -253.36, "episode_reward_trend_value": 0.010470043193791096, "biggest_recent_change": 0.24874410899411714},
{"total_number_of_episodes": 12866, "number_of_timesteps": 1306430, "per_episode_reward": -253.24, "episode_reward_trend_value": 0.010849255143484192, "biggest_recent_change": 0.24874410899411714},
{"total_number_of_episodes": 12876, "number_of_timesteps": 1308023, "per_episode_reward": -253.06, "episode_reward_trend_value": 0.011459262577483286, "biggest_recent_change": 0.24874410899411714},
{"total_number_of_episodes": 12886, "number_of_timesteps": 1309350, "per_episode_reward": -252.65, "episode_reward_trend_value": 0.013233445468293008, "biggest_recent_change": 0.4084205691669922},
{"total_number_of_episodes": 12896, "number_of_timesteps": 1310457, "per_episode_reward": -252.51, "episode_reward_trend_value": 0.014046175710867224, "biggest_recent_change": 0.4084205691669922},
{"total_number_of_episodes": 12906, "number_of_timesteps": 1311616, "per_episode_reward": -252.29, "episode_reward_trend_value": 0.015297453356845065, "biggest_recent_change": 0.4084205691669922},
{"total_number_of_episodes": 12916, "number_of_timesteps": 1312955, "per_episode_reward": -252.08, "episode_reward_trend_value": 0.01676161663332449, "biggest_recent_change": 0.4084205691669922},
{"total_number_of_episodes": 12926, "number_of_timesteps": 1314086, "per_episode_reward": -251.99, "episode_reward_trend_value": 0.01631131732762899, "biggest_recent_change": 0.4084205691669922},
{"total_number_of_episodes": 12937, "number_of_timesteps": 1315855, "per_episode_reward": -251.82, "episode_reward_trend_value": 0.01772335050645779, "biggest_recent_change": 0.4084205691669922},
{"total_number_of_episodes": 12947, "number_of_timesteps": 1317264, "per_episode_reward": -251.69, "episode_reward_trend_value": 0.018557985953716778, "biggest_recent_change": 0.4084205691669922},
{"total_number_of_episodes": 12957, "number_of_timesteps": 1318118, "per_episode_reward": -251.48, "episode_reward_trend_value": 0.019619751921647183, "biggest_recent_change": 0.4084205691669922},
{"total_number_of_episodes": 12967, "number_of_timesteps": 1319038, "per_episode_reward": -251.24, "episode_reward_trend_value": 0.020281148925132518, "biggest_recent_change": 0.4084205691669922},
{"total_number_of_episodes": 12977, "number_of_timesteps": 1320369, "per_episode_reward": -251.18, "episode_reward_trend_value": 0.016412210372994375, "biggest_recent_change": 0.2390763971279739},
{"total_number_of_episodes": 12988, "number_of_timesteps": 1321898, "per_episode_reward": -251.04, "episode_reward_trend_value": 0.016264603992772207, "biggest_recent_change": 0.2390763971279739},
{"total_number_of_episodes": 12998, "number_of_timesteps": 1323028, "per_episode_reward": -250.91, "episode_reward_trend_value": 0.015324395376018807, "biggest_recent_change": 0.2390763971279739},
{"total_number_of_episodes": 13008, "number_of_timesteps": 1324643, "per_episode_reward": -250.82, "episode_reward_trend_value": 0.014003626120221371, "biggest_recent_change": 0.2390763971279739},
{"total_number_of_episodes": 13018, "number_of_timesteps": 1326038, "per_episode_reward": -250.75, "episode_reward_trend_value": 0.013824042354948083, "biggest_recent_change": 0.2390763971279739},
{"total_number_of_episodes": 13029, "number_of_timesteps": 1327528, "per_episode_reward": -250.7, "episode_reward_trend_value": 0.012436101375801121, "biggest_recent_change": 0.2390763971279739},
{"total_number_of_episodes": 13040, "number_of_timesteps": 1328782, "per_episode_reward": -250.65, "episode_reward_trend_value": 0.011640174116904076, "biggest_recent_change": 0.2390763971279739},
{"total_number_of_episodes": 13051, "number_of_timesteps": 1329916, "per_episode_reward": -250.44, "episode_reward_trend_value": 0.011557372557392556, "biggest_recent_change": 0.2390763971279739},
{"total_number_of_episodes": 13061, "number_of_timesteps": 1331093, "per_episode_reward": -250.22, "episode_reward_trend_value": 0.011255843303877416, "biggest_recent_change": 0.2119387643116113},
{"total_number_of_episodes": 13071, "number_of_timesteps": 1332126, "per_episode_reward": -250.14, "episode_reward_trend_value": 0.01151666070379349, "biggest_recent_change": 0.2119387643116113},
{"total_number_of_episodes": 13081, "number_of_timesteps": 1333191, "per_episode_reward": -250.02, "episode_reward_trend_value": 0.011313441681261655, "biggest_recent_change": 0.2119387643116113},
{"total_number_of_episodes": 13091, "number_of_timesteps": 1334211, "per_episode_reward": -249.89, "episode_reward_trend_value": 0.011355874399891126, "biggest_recent_change": 0.2119387643116113},
{"total_number_of_episodes": 13101, "number_of_timesteps": 1335141, "per_episode_reward": -249.79, "episode_reward_trend_value": 0.011433518650602853, "biggest_recent_change": 0.2119387643116113},
{"total_number_of_episodes": 13111, "number_of_timesteps": 1336114, "per_episode_reward": -249.6, "episode_reward_trend_value": 0.012762581983712884, "biggest_recent_change": 0.2119387643116113},
{"total_number_of_episodes": 13121, "number_of_timesteps": 1337242, "per_episode_reward": -249.48, "episode_reward_trend_value": 0.013563321201552802, "biggest_recent_change": 0.2119387643116113},
{"total_number_of_episodes": 13131, "number_of_timesteps": 1338572, "per_episode_reward": -249.37, "episode_reward_trend_value": 0.014127638385315323, "biggest_recent_change": 0.2119387643116113},
{"total_number_of_episodes": 13141, "number_of_timesteps": 1340121, "per_episode_reward": -249.21, "episode_reward_trend_value": 0.013665268053419924, "biggest_recent_change": 0.2119387643116113},
{"total_number_of_episodes": 13151, "number_of_timesteps": 1341582, "per_episode_reward": -249.1, "episode_reward_trend_value": 0.01243359509280866, "biggest_recent_change": 0.18991895338135123},
{"total_number_of_episodes": 13161, "number_of_timesteps": 1342724, "per_episode_reward": -249.0, "episode_reward_trend_value": 0.012637567516855736, "biggest_recent_change": 0.18991895338135123},
{"total_number_of_episodes": 13171, "number_of_timesteps": 1343938, "per_episode_reward": -248.88, "episode_reward_trend_value": 0.01265819042882615, "biggest_recent_change": 0.18991895338135123},
{"total_number_of_episodes": 13182, "number_of_timesteps": 1345483, "per_episode_reward": -248.56, "episode_reward_trend_value": 0.014821707136510062, "biggest_recent_change": 0.32669469830707953},
{"total_number_of_episodes": 13193, "number_of_timesteps": 1346794, "per_episode_reward": -248.31, "episode_reward_trend_value": 0.016480246532719255, "biggest_recent_change": 0.32669469830707953},
{"total_number_of_episodes": 13203, "number_of_timesteps": 1347785, "per_episode_reward": -248.16, "episode_reward_trend_value": 0.01599260245458222, "biggest_recent_change": 0.32669469830707953},
{"total_number_of_episodes": 13213, "number_of_timesteps": 1348856, "per_episode_reward": -248.04, "episode_reward_trend_value": 0.015984841837374437, "biggest_recent_change": 0.32669469830707953},
{"total_number_of_episodes": 13225, "number_of_timesteps": 1350392, "per_episode_reward": -247.91, "episode_reward_trend_value": 0.016245518813462922, "biggest_recent_change": 0.32669469830707953},
{"total_number_of_episodes": 13235, "number_of_timesteps": 1351562, "per_episode_reward": -247.75, "episode_reward_trend_value": 0.016119866825124833, "biggest_recent_change": 0.32669469830707953},
{"total_number_of_episodes": 13246, "number_of_timesteps": 1353133, "per_episode_reward": -247.58, "episode_reward_trend_value": 0.01692132034884758, "biggest_recent_change": 0.32669469830707953},
{"total_number_of_episodes": 13256, "number_of_timesteps": 1354624, "per_episode_reward": -247.47, "episode_reward_trend_value": 0.017072676140452676, "biggest_recent_change": 0.32669469830707953},
{"total_number_of_episodes": 13266, "number_of_timesteps": 1355853, "per_episode_reward": -247.35, "episode_reward_trend_value": 0.017048563957044394, "biggest_recent_change": 0.32669469830707953},
{"total_number_of_episodes": 13279, "number_of_timesteps": 1357521, "per_episode_reward": -246.95, "episode_reward_trend_value": 0.01783289208910743, "biggest_recent_change": 0.39728423019275283},
{"total_number_of_episodes": 13289, "number_of_timesteps": 1358741, "per_episode_reward": -246.65, "episode_reward_trend_value": 0.018394104555358125, "biggest_recent_change": 0.39728423019275283},
{"total_number_of_episodes": 13299, "number_of_timesteps": 1359988, "per_episode_reward": -246.35, "episode_reward_trend_value": 0.020081288385503625, "biggest_recent_change": 0.39728423019275283},
{"total_number_of_episodes": 13309, "number_of_timesteps": 1361150, "per_episode_reward": -246.1, "episode_reward_trend_value": 0.02163117159838287, "biggest_recent_change": 0.39728423019275283},
{"total_number_of_episodes": 13319, "number_of_timesteps": 1362612, "per_episode_reward": -245.96, "episode_reward_trend_value": 0.02168218323886669, "biggest_recent_change": 0.39728423019275283},
{"total_number_of_episodes": 13330, "number_of_timesteps": 1364183, "per_episode_reward": -245.85, "episode_reward_trend_value": 0.02117361737049224, "biggest_recent_change": 0.39728423019275283},
{"total_number_of_episodes": 13340, "number_of_timesteps": 1365780, "per_episode_reward": -245.78, "episode_reward_trend_value": 0.020024855847847474, "biggest_recent_change": 0.39728423019275283},
{"total_number_of_episodes": 13350, "number_of_timesteps": 1367274, "per_episode_reward": -245.68, "episode_reward_trend_value": 0.019815689067544894, "biggest_recent_change": 0.39728423019275283},
{"total_number_of_episodes": 13360, "number_of_timesteps": 1368669, "per_episode_reward": -245.5, "episode_reward_trend_value": 0.02053289824799328, "biggest_recent_change": 0.39728423019275283},
{"total_number_of_episodes": 13371, "number_of_timesteps": 1370256, "per_episode_reward": -245.25, "episode_reward_trend_value": 0.018933273896117462, "biggest_recent_change": 0.2998493422574313},
{"total_number_of_episodes": 13381, "number_of_timesteps": 1371573, "per_episode_reward": -245.07, "episode_reward_trend_value": 0.01762805510675681, "biggest_recent_change": 0.2978775310621131},
{"total_number_of_episodes": 13391, "number_of_timesteps": 1372660, "per_episode_reward": -244.92, "episode_reward_trend_value": 0.015918818107481848, "biggest_recent_change": 0.2592386086738827},
{"total_number_of_episodes": 13402, "number_of_timesteps": 1373719, "per_episode_reward": -244.51, "episode_reward_trend_value": 0.01757117902137395, "biggest_recent_change": 0.4079510909241719},
{"total_number_of_episodes": 13412, "number_of_timesteps": 1374867, "per_episode_reward": -244.35, "episode_reward_trend_value": 0.01789601594026572, "biggest_recent_change": 0.4079510909241719},
{"total_number_of_episodes": 13422, "number_of_timesteps": 1376082, "per_episode_reward": -244.2, "episode_reward_trend_value": 0.01834802626488473, "biggest_recent_change": 0.4079510909241719},
{"total_number_of_episodes": 13432, "number_of_timesteps": 1377664, "per_episode_reward": -244.15, "episode_reward_trend_value": 0.018131027811937706, "biggest_recent_change": 0.4079510909241719},
{"total_number_of_episodes": 13442, "number_of_timesteps": 1378893, "per_episode_reward": -244.08, "episode_reward_trend_value": 0.017827122879137708, "biggest_recent_change": 0.4079510909241719},
{"total_number_of_episodes": 13452, "number_of_timesteps": 1380061, "per_episode_reward": -243.78, "episode_reward_trend_value": 0.019083968707522242, "biggest_recent_change": 0.4079510909241719},
{"total_number_of_episodes": 13462, "number_of_timesteps": 1381729, "per_episode_reward": -243.63, "episode_reward_trend_value": 0.017991422416948743, "biggest_recent_change": 0.4079510909241719},
{"total_number_of_episodes": 13472, "number_of_timesteps": 1383012, "per_episode_reward": -243.51, "episode_reward_trend_value": 0.01726237750132624, "biggest_recent_change": 0.4079510909241719},
{"total_number_of_episodes": 13482, "number_of_timesteps": 1384590, "per_episode_reward": -243.41, "episode_reward_trend_value": 0.016744943289649605, "biggest_recent_change": 0.4079510909241719},
{"total_number_of_episodes": 13492, "number_of_timesteps": 1385835, "per_episode_reward": -243.3, "episode_reward_trend_value": 0.013438429995171142, "biggest_recent_change": 0.29346624803224586},
{"total_number_of_episodes": 13503, "number_of_timesteps": 1387498, "per_episode_reward": -243.15, "episode_reward_trend_value": 0.013387528719605118, "biggest_recent_change": 0.29346624803224586},
{"total_number_of_episodes": 13513, "number_of_timesteps": 1388708, "per_episode_reward": -242.94, "episode_reward_trend_value": 0.013975274113337516, "biggest_recent_change": 0.29346624803224586},
{"total_number_of_episodes": 13523, "number_of_timesteps": 1390664, "per_episode_reward": -242.83, "episode_reward_trend_value": 0.014625023513034486, "biggest_recent_change": 0.29346624803224586},
{"total_number_of_episodes": 13533, "number_of_timesteps": 1392511, "per_episode_reward": -242.56, "episode_reward_trend_value": 0.016842770212694327, "biggest_recent_change": 0.29346624803224586},
{"total_number_of_episodes": 13544, "number_of_timesteps": 1394190, "per_episode_reward": -242.4, "episode_reward_trend_value": 0.015386110445590222, "biggest_recent_change": 0.26908995366585486},
{"total_number_of_episodes": 13554, "number_of_timesteps": 1395588, "per_episode_reward": -242.25, "episode_reward_trend_value": 0.015337280290772684, "biggest_recent_change": 0.26908995366585486},
{"total_number_of_episodes": 13564, "number_of_timesteps": 1397124, "per_episode_reward": -242.04, "episode_reward_trend_value": 0.01641344454414448, "biggest_recent_change": 0.26908995366585486},
{"total_number_of_episodes": 13574, "number_of_timesteps": 1398602, "per_episode_reward": -241.81, "episode_reward_trend_value": 0.017785614062568633, "biggest_recent_change": 0.26908995366585486},
{"total_number_of_episodes": 13584, "number_of_timesteps": 1400276, "per_episode_reward": -241.69, "episode_reward_trend_value": 0.01796993195450259, "biggest_recent_change": 0.26908995366585486},
{"total_number_of_episodes": 13594, "number_of_timesteps": 1401984, "per_episode_reward": -241.53, "episode_reward_trend_value": 0.017998635446555354, "biggest_recent_change": 0.26908995366585486},
{"total_number_of_episodes": 13604, "number_of_timesteps": 1403248, "per_episode_reward": -241.35, "episode_reward_trend_value": 0.01762401241503129, "biggest_recent_change": 0.26908995366585486},
{"total_number_of_episodes": 13614, "number_of_timesteps": 1404620, "per_episode_reward": -241.21, "episode_reward_trend_value": 0.01802762859076002, "biggest_recent_change": 0.26908995366585486},
{"total_number_of_episodes": 13627, "number_of_timesteps": 1406347, "per_episode_reward": -240.98, "episode_reward_trend_value": 0.01759982484602871, "biggest_recent_change": 0.23058761664003669},
{"total_number_of_episodes": 13638, "number_of_timesteps": 1407884, "per_episode_reward": -240.79, "episode_reward_trend_value": 0.01792492113627399, "biggest_recent_change": 0.23058761664003669},
{"total_number_of_episodes": 13649, "number_of_timesteps": 1409334, "per_episode_reward": -240.62, "episode_reward_trend_value": 0.01804418681858364, "biggest_recent_change": 0.23058761664003669},
{"total_number_of_episodes": 13661, "number_of_timesteps": 1410588, "per_episode_reward": -240.51, "episode_reward_trend_value": 0.01695604436322829, "biggest_recent_change": 0.23058761664003669},
{"total_number_of_episodes": 13671, "number_of_timesteps": 1411559, "per_episode_reward": -240.4, "episode_reward_trend_value": 0.01573012101371805, "biggest_recent_change": 0.23058761664003669},
{"total_number_of_episodes": 13681, "number_of_timesteps": 1412368, "per_episode_reward": -240.26, "episode_reward_trend_value": 0.015803814408174806, "biggest_recent_change": 0.23058761664003669},
{"total_number_of_episodes": 13691, "number_of_timesteps": 1413326, "per_episode_reward": -240.11, "episode_reward_trend_value": 0.01577489295741543, "biggest_recent_change": 0.23058761664003669},
{"total_number_of_episodes": 13701, "number_of_timesteps": 1414332, "per_episode_reward": -239.83, "episode_reward_trend_value": 0.016881693814420375, "biggest_recent_change": 0.2719967896936737},
{"total_number_of_episodes": 13711, "number_of_timesteps": 1415656, "per_episode_reward": -239.69, "episode_reward_trend_value": 0.016830898683925788, "biggest_recent_change": 0.2719967896936737},
{"total_number_of_episodes": 13722, "number_of_timesteps": 1417079, "per_episode_reward": -239.56, "episode_reward_trend_value": 0.01574955371927034, "biggest_recent_change": 0.2719967896936737},
{"total_number_of_episodes": 13733, "number_of_timesteps": 1418311, "per_episode_reward": -239.43, "episode_reward_trend_value": 0.015112280647070975, "biggest_recent_change": 0.2719967896936737},
{"total_number_of_episodes": 13743, "number_of_timesteps": 1419393, "per_episode_reward": -239.29, "episode_reward_trend_value": 0.014795756707779458, "biggest_recent_change": 0.2719967896936737},
{"total_number_of_episodes": 13753, "number_of_timesteps": 1420608, "per_episode_reward": -239.16, "episode_reward_trend_value": 0.014938501484729727, "biggest_recent_change": 0.2719967896936737},
{"total_number_of_episodes": 13765, "number_of_timesteps": 1422448, "per_episode_reward": -239.05, "episode_reward_trend_value": 0.01502124506524025, "biggest_recent_change": 0.2719967896936737},
{"total_number_of_episodes": 13775, "number_of_timesteps": 1424412, "per_episode_reward": -238.85, "episode_reward_trend_value": 0.01569243788500848, "biggest_recent_change": 0.2719967896936737},
{"total_number_of_episodes": 13785, "number_of_timesteps": 1426080, "per_episode_reward": -238.75, "episode_reward_trend_value": 0.015103306051285395, "biggest_recent_change": 0.2719967896936737},
{"total_number_of_episodes": 13795, "number_of_timesteps": 1427622, "per_episode_reward": -238.25, "episode_reward_trend_value": 0.017588970385762397, "biggest_recent_change": 0.4957065797966038},
{"total_number_of_episodes": 13805, "number_of_timesteps": 1429521, "per_episode_reward": -238.13, "episode_reward_trend_value": 0.017395101436301276, "biggest_recent_change": 0.4957065797966038},
{"total_number_of_episodes": 13815, "number_of_timesteps": 1431087, "per_episode_reward": -237.84, "episode_reward_trend_value": 0.019106117035273464, "biggest_recent_change": 0.4957065797966038},
{"total_number_of_episodes": 13825, "number_of_timesteps": 1432738, "per_episode_reward": -237.69, "episode_reward_trend_value": 0.019272144190217784, "biggest_recent_change": 0.4957065797966038},
{"total_number_of_episodes": 13836, "number_of_timesteps": 1434340, "per_episode_reward": -237.41, "episode_reward_trend_value": 0.020921902048534786, "biggest_recent_change": 0.4957065797966038},
{"total_number_of_episodes": 13847, "number_of_timesteps": 1436350, "per_episode_reward": -237.17, "episode_reward_trend_value": 0.022160651861541206, "biggest_recent_change": 0.4957065797966038},
{"total_number_of_episodes": 13857, "number_of_timesteps": 1438390, "per_episode_reward": -237.04, "episode_reward_trend_value": 0.022348787196789507, "biggest_recent_change": 0.4957065797966038},
{"total_number_of_episodes": 13867, "number_of_timesteps": 1440186, "per_episode_reward": -236.95, "episode_reward_trend_value": 0.021110159425759258, "biggest_recent_change": 0.4957065797966038},
{"total_number_of_episodes": 13878, "number_of_timesteps": 1442240, "per_episode_reward": -236.78, "episode_reward_trend_value": 0.021890636864430414, "biggest_recent_change": 0.4957065797966038},
{"total_number_of_episodes": 13889, "number_of_timesteps": 1444356, "per_episode_reward": -236.64, "episode_reward_trend_value": 0.017867422154006996, "biggest_recent_change": 0.28725797372854345},
{"total_number_of_episodes": 13899, "number_of_timesteps": 1446114, "per_episode_reward": -236.36, "episode_reward_trend_value": 0.019682869842600325, "biggest_recent_change": 0.28725797372854345},
{"total_number_of_episodes": 13909, "number_of_timesteps": 1448481, "per_episode_reward": -236.25, "episode_reward_trend_value": 0.01769944052122096, "biggest_recent_change": 0.28647404375408314},
{"total_number_of_episodes": 13919, "number_of_timesteps": 1450408, "per_episode_reward": -236.07, "episode_reward_trend_value": 0.017995502398618315, "biggest_recent_change": 0.28647404375408314},
{"total_number_of_episodes": 13929, "number_of_timesteps": 1451870, "per_episode_reward": -235.86, "episode_reward_trend_value": 0.017182210153379174, "biggest_recent_change": 0.28647404375408314},
{"total_number_of_episodes": 13939, "number_of_timesteps": 1453297, "per_episode_reward": -235.73, "episode_reward_trend_value": 0.015980487599445484, "biggest_recent_change": 0.28647404375408314},
{"total_number_of_episodes": 13950, "number_of_timesteps": 1454845, "per_episode_reward": -235.59, "episode_reward_trend_value": 0.016036705247712904, "biggest_recent_change": 0.28647404375408314},
{"total_number_of_episodes": 13960, "number_of_timesteps": 1456540, "per_episode_reward": -235.47, "episode_reward_trend_value": 0.01646877851579013, "biggest_recent_change": 0.28647404375408314},
{"total_number_of_episodes": 13970, "number_of_timesteps": 1458448, "per_episode_reward": -235.4, "episode_reward_trend_value": 0.015277539554505715, "biggest_recent_change": 0.28647404375408314},
{"total_number_of_episodes": 13981, "number_of_timesteps": 1460359, "per_episode_reward": -235.3, "episode_reward_trend_value": 0.014911541765218316, "biggest_recent_change": 0.28647404375408314},
{"total_number_of_episodes": 13992, "number_of_timesteps": 1461791, "per_episode_reward": -235.02, "episode_reward_trend_value": 0.014861771968091691, "biggest_recent_change": 0.2819947620126868},
{"total_number_of_episodes": 14002, "number_of_timesteps": 1463866, "per_episode_reward": -234.94, "episode_reward_trend_value": 0.014501789999816753, "biggest_recent_change": 0.2819947620126868},
{"total_number_of_episodes": 14012, "number_of_timesteps": 1465987, "per_episode_reward": -234.86, "episode_reward_trend_value": 0.01350036642867849, "biggest_recent_change": 0.2819947620126868},
{"total_number_of_episodes": 14022, "number_of_timesteps": 1467373, "per_episode_reward": -234.74, "episode_reward_trend_value": 0.01254176445040274, "biggest_recent_change": 0.2819947620126868},
{"total_number_of_episodes": 14033, "number_of_timesteps": 1468959, "per_episode_reward": -234.57, "episode_reward_trend_value": 0.01293044646811331, "biggest_recent_change": 0.2819947620126868},
{"total_number_of_episodes": 14044, "number_of_timesteps": 1470152, "per_episode_reward": -234.37, "episode_reward_trend_value": 0.013553457438324142, "biggest_recent_change": 0.2819947620126868},
{"total_number_of_episodes": 14054, "number_of_timesteps": 1471473, "per_episode_reward": -234.07, "episode_reward_trend_value": 0.015609699097826201, "biggest_recent_change": 0.3064651080648275},
{"total_number_of_episodes": 14064, "number_of_timesteps": 1474124, "per_episode_reward": -233.88, "episode_reward_trend_value": 0.016936650981188312, "biggest_recent_change": 0.3064651080648275},
{"total_number_of_episodes": 14074, "number_of_timesteps": 1475766, "per_episode_reward": -233.69, "episode_reward_trend_value": 0.017905503489912336, "biggest_recent_change": 0.3064651080648275},
{"total_number_of_episodes": 14086, "number_of_timesteps": 1477251, "per_episode_reward": -233.4, "episode_reward_trend_value": 0.017973292424999145, "biggest_recent_change": 0.3064651080648275},
{"total_number_of_episodes": 14096, "number_of_timesteps": 1478625, "per_episode_reward": -233.06, "episode_reward_trend_value": 0.020929146332422495, "biggest_recent_change": 0.34237780932775763},
{"total_number_of_episodes": 14106, "number_of_timesteps": 1481195, "per_episode_reward": -232.85, "episode_reward_trend_value": 0.022302893639887127, "biggest_recent_change": 0.34237780932775763},
{"total_number_of_episodes": 14116, "number_of_timesteps": 1482637, "per_episode_reward": -232.71, "episode_reward_trend_value": 0.022462246171118888, "biggest_recent_change": 0.34237780932775763},
{"total_number_of_episodes": 14126, "number_of_timesteps": 1485170, "per_episode_reward": -232.51, "episode_reward_trend_value": 0.022872306138095332, "biggest_recent_change": 0.34237780932775763},
{"total_number_of_episodes": 14136, "number_of_timesteps": 1487136, "per_episode_reward": -232.41, "episode_reward_trend_value": 0.021756875836942097, "biggest_recent_change": 0.34237780932775763},
{"total_number_of_episodes": 14146, "number_of_timesteps": 1489274, "per_episode_reward": -232.3, "episode_reward_trend_value": 0.019625641949682894, "biggest_recent_change": 0.34237780932775763},
{"total_number_of_episodes": 14156, "number_of_timesteps": 1491698, "per_episode_reward": -232.18, "episode_reward_trend_value": 0.018886193515491024, "biggest_recent_change": 0.34237780932775763},
{"total_number_of_episodes": 14166, "number_of_timesteps": 1494666, "per_episode_reward": -232.0, "episode_reward_trend_value": 0.018765251905058573, "biggest_recent_change": 0.34237780932775763},
{"total_number_of_episodes": 14176, "number_of_timesteps": 1496418, "per_episode_reward": -231.91, "episode_reward_trend_value": 0.016528895913414013, "biggest_recent_change": 0.34237780932775763},
{"total_number_of_episodes": 14186, "number_of_timesteps": 1498259, "per_episode_reward": -231.57, "episode_reward_trend_value": 0.01654674227997393, "biggest_recent_change": 0.3439839823181501},
{"total_number_of_episodes": 14196, "number_of_timesteps": 1499651, "per_episode_reward": -231.41, "episode_reward_trend_value": 0.016040491241262896, "biggest_recent_change": 0.3439839823181501},
{"total_number_of_episodes": 14207, "number_of_timesteps": 1503356, "per_episode_reward": -231.26, "episode_reward_trend_value": 0.016152163569111304, "biggest_recent_change": 0.3439839823181501},
{"total_number_of_episodes": 14218, "number_of_timesteps": 1506229, "per_episode_reward": -231.03, "episode_reward_trend_value": 0.016408486975627547, "biggest_recent_change": 0.3439839823181501},
{"total_number_of_episodes": 14228, "number_of_timesteps": 1509275, "per_episode_reward": -230.78, "episode_reward_trend_value": 0.018156476200083992, "biggest_recent_change": 0.3439839823181501},
{"total_number_of_episodes": 14238, "number_of_timesteps": 1511906, "per_episode_reward": -230.59, "episode_reward_trend_value": 0.019020790328993877, "biggest_recent_change": 0.3439839823181501},
{"total_number_of_episodes": 14248, "number_of_timesteps": 1514190, "per_episode_reward": -230.36, "episode_reward_trend_value": 0.02014102845638206, "biggest_recent_change": 0.3439839823181501},
{"total_number_of_episodes": 14258, "number_of_timesteps": 1515747, "per_episode_reward": -230.08, "episode_reward_trend_value": 0.021377844930739482, "biggest_recent_change": 0.3439839823181501},
{"total_number_of_episodes": 14268, "number_of_timesteps": 1518375, "per_episode_reward": -229.84, "episode_reward_trend_value": 0.022995463497153423, "biggest_recent_change": 0.3439839823181501},
{"total_number_of_episodes": 14278, "number_of_timesteps": 1519979, "per_episode_reward": -229.61, "episode_reward_trend_value": 0.02179511040906606, "biggest_recent_change": 0.2883029183610404},
{"total_number_of_episodes": 14288, "number_of_timesteps": 1521148, "per_episode_reward": -229.43, "episode_reward_trend_value": 0.021942286862587125, "biggest_recent_change": 0.2883029183610404},
{"total_number_of_episodes": 14298, "number_of_timesteps": 1522519, "per_episode_reward": -229.39, "episode_reward_trend_value": 0.020809214759385478, "biggest_recent_change": 0.2883029183610404},
{"total_number_of_episodes": 14308, "number_of_timesteps": 1524000, "per_episode_reward": -229.2, "episode_reward_trend_value": 0.020403637308581322, "biggest_recent_change": 0.2883029183610404},
{"total_number_of_episodes": 14320, "number_of_timesteps": 1526136, "per_episode_reward": -229.11, "episode_reward_trend_value": 0.018607590120230257, "biggest_recent_change": 0.2883029183610404},
{"total_number_of_episodes": 14330, "number_of_timesteps": 1527707, "per_episode_reward": -228.91, "episode_reward_trend_value": 0.01858738336266141, "biggest_recent_change": 0.2883029183610404},
{"total_number_of_episodes": 14340, "number_of_timesteps": 1530151, "per_episode_reward": -228.81, "episode_reward_trend_value": 0.01730328083388031, "biggest_recent_change": 0.2883029183610404},
{"total_number_of_episodes": 14350, "number_of_timesteps": 1531807, "per_episode_reward": -228.6, "episode_reward_trend_value": 0.016363301387523656, "biggest_recent_change": 0.23595220439028708},
{"total_number_of_episodes": 14360, "number_of_timesteps": 1534301, "per_episode_reward": -228.42, "episode_reward_trend_value": 0.01577843567087566, "biggest_recent_change": 0.23595220439028708},
{"total_number_of_episodes": 14370, "number_of_timesteps": 1537224, "per_episode_reward": -228.29, "episode_reward_trend_value": 0.014665220290701894, "biggest_recent_change": 0.2037047681889419},
{"total_number_of_episodes": 14380, "number_of_timesteps": 1539017, "per_episode_reward": -228.17, "episode_reward_trend_value": 0.014008165774422801, "biggest_recent_change": 0.2037047681889419},
{"total_number_of_episodes": 14390, "number_of_timesteps": 1541965, "per_episode_reward": -228.12, "episode_reward_trend_value": 0.014104035549024414, "biggest_recent_change": 0.2037047681889419},
{"total_number_of_episodes": 14400, "number_of_timesteps": 1544203, "per_episode_reward": -228.05, "episode_reward_trend_value": 0.012728453122075697, "biggest_recent_change": 0.2037047681889419},
{"total_number_of_episodes": 14410, "number_of_timesteps": 1546231, "per_episode_reward": -227.95, "episode_reward_trend_value": 0.012875791975914947, "biggest_recent_change": 0.2037047681889419},
{"total_number_of_episodes": 14421, "number_of_timesteps": 1550247, "per_episode_reward": -227.85, "episode_reward_trend_value": 0.011839146553312377, "biggest_recent_change": 0.2037047681889419},
{"total_number_of_episodes": 14431, "number_of_timesteps": 1552272, "per_episode_reward": -227.57, "episode_reward_trend_value": 0.013761186727675559, "biggest_recent_change": 0.2799188828428214},
{"total_number_of_episodes": 14441, "number_of_timesteps": 1555433, "per_episode_reward": -227.12, "episode_reward_trend_value": 0.016467736962587447, "biggest_recent_change": 0.4472942893310119},
{"total_number_of_episodes": 14451, "number_of_timesteps": 1557591, "per_episode_reward": -226.98, "episode_reward_trend_value": 0.016016750574792443, "biggest_recent_change": 0.4472942893310119},
{"total_number_of_episodes": 14461, "number_of_timesteps": 1561288, "per_episode_reward": -226.8, "episode_reward_trend_value": 0.01651905958356268, "biggest_recent_change": 0.4472942893310119},
{"total_number_of_episodes": 14471, "number_of_timesteps": 1564333, "per_episode_reward": -226.61, "episode_reward_trend_value": 0.017319118992583073, "biggest_recent_change": 0.4472942893310119},
{"total_number_of_episodes": 14481, "number_of_timesteps": 1566037, "per_episode_reward": -226.48, "episode_reward_trend_value": 0.01817639587756427, "biggest_recent_change": 0.4472942893310119},
{"total_number_of_episodes": 14491, "number_of_timesteps": 1567659, "per_episode_reward": -226.38, "episode_reward_trend_value": 0.018530633179538035, "biggest_recent_change": 0.4472942893310119},
{"total_number_of_episodes": 14501, "number_of_timesteps": 1569545, "per_episode_reward": -226.29, "episode_reward_trend_value": 0.018427402550368142, "biggest_recent_change": 0.4472942893310119},
{"total_number_of_episodes": 14511, "number_of_timesteps": 1571783, "per_episode_reward": -226.1, "episode_reward_trend_value": 0.01943048697405882, "biggest_recent_change": 0.4472942893310119},
{"total_number_of_episodes": 14521, "number_of_timesteps": 1574778, "per_episode_reward": -226.0, "episode_reward_trend_value": 0.017435707432508073, "biggest_recent_change": 0.4472942893310119},
{"total_number_of_episodes": 14531, "number_of_timesteps": 1576911, "per_episode_reward": -225.92, "episode_reward_trend_value": 0.013340835726005983, "biggest_recent_change": 0.18992183547675268},
{"total_number_of_episodes": 14541, "number_of_timesteps": 1579152, "per_episode_reward": -225.79, "episode_reward_trend_value": 0.013220499903871996, "biggest_recent_change": 0.18992183547675268},
{"total_number_of_episodes": 14551, "number_of_timesteps": 1581447, "per_episode_reward": -225.66, "episode_reward_trend_value": 0.012691239813460698, "biggest_recent_change": 0.18992183547675268},
{"total_number_of_episodes": 14561, "number_of_timesteps": 1583494, "per_episode_reward": -225.52, "episode_reward_trend_value": 0.01209243001131439, "biggest_recent_change": 0.1876032317301224},
{"total_number_of_episodes": 14571, "number_of_timesteps": 1585170, "per_episode_reward": -225.43, "episode_reward_trend_value": 0.011738518804719118, "biggest_recent_change": 0.1876032317301224},
{"total_number_of_episodes": 14581, "number_of_timesteps": 1588839, "per_episode_reward": -225.34, "episode_reward_trend_value": 0.011633633594419103, "biggest_recent_change": 0.1876032317301224},
{"total_number_of_episodes": 14591, "number_of_timesteps": 1590374, "per_episode_reward": -225.13, "episode_reward_trend_value": 0.012912197545464701, "biggest_recent_change": 0.21047550732009768},
{"total_number_of_episodes": 14601, "number_of_timesteps": 1592559, "per_episode_reward": -224.78, "episode_reward_trend_value": 0.014638020161981697, "biggest_recent_change": 0.3429272672166519},
{"total_number_of_episodes": 14611, "number_of_timesteps": 1595431, "per_episode_reward": -224.68, "episode_reward_trend_value": 0.01471870111485537, "biggest_recent_change": 0.3429272672166519},
{"total_number_of_episodes": 14621, "number_of_timesteps": 1596545, "per_episode_reward": -224.48, "episode_reward_trend_value": 0.015986816600891667, "biggest_recent_change": 0.3429272672166519},
{"total_number_of_episodes": 14632, "number_of_timesteps": 1598327, "per_episode_reward": -224.33, "episode_reward_trend_value": 0.016249234219746868, "biggest_recent_change": 0.3429272672166519},
{"total_number_of_episodes": 14643, "number_of_timesteps": 1600217, "per_episode_reward": -224.23, "episode_reward_trend_value": 0.015926569553616966, "biggest_recent_change": 0.3429272672166519},
{"total_number_of_episodes": 14653, "number_of_timesteps": 1601529, "per_episode_reward": -224.08, "episode_reward_trend_value": 0.01600980064828137, "biggest_recent_change": 0.3429272672166519},
{"total_number_of_episodes": 14663, "number_of_timesteps": 1603167, "per_episode_reward": -223.95, "episode_reward_trend_value": 0.0163496149800652, "biggest_recent_change": 0.3429272672166519},
{"total_number_of_episodes": 14674, "number_of_timesteps": 1606079, "per_episode_reward": -223.87, "episode_reward_trend_value": 0.0163086939342239, "biggest_recent_change": 0.3429272672166519},
{"total_number_of_episodes": 14685, "number_of_timesteps": 1608722, "per_episode_reward": -223.71, "episode_reward_trend_value": 0.015720813267906426, "biggest_recent_change": 0.3429272672166519},
{"total_number_of_episodes": 14695, "number_of_timesteps": 1610249, "per_episode_reward": -223.54, "episode_reward_trend_value": 0.013832903443042393, "biggest_recent_change": 0.1928862294890905},
{"total_number_of_episodes": 14707, "number_of_timesteps": 1612116, "per_episode_reward": -223.11, "episode_reward_trend_value": 0.017407466637215898, "biggest_recent_change": 0.4293606973375006},
{"total_number_of_episodes": 14717, "number_of_timesteps": 1614577, "per_episode_reward": -222.97, "episode_reward_trend_value": 0.016752244845306703, "biggest_recent_change": 0.4293606973375006},
{"total_number_of_episodes": 14727, "number_of_timesteps": 1616657, "per_episode_reward": -222.9, "episode_reward_trend_value": 0.01593693444156846, "biggest_recent_change": 0.4293606973375006},
{"total_number_of_episodes": 14737, "number_of_timesteps": 1617891, "per_episode_reward": -222.75, "episode_reward_trend_value": 0.016451561292851125, "biggest_recent_change": 0.4293606973375006},
{"total_number_of_episodes": 14748, "number_of_timesteps": 1619863, "per_episode_reward": -222.54, "episode_reward_trend_value": 0.017154293481621608, "biggest_recent_change": 0.4293606973375006},
{"total_number_of_episodes": 14758, "number_of_timesteps": 1621652, "per_episode_reward": -222.41, "episode_reward_trend_value": 0.0171585476215796, "biggest_recent_change": 0.4293606973375006},
{"total_number_of_episodes": 14768, "number_of_timesteps": 1623452, "per_episode_reward": -222.12, "episode_reward_trend_value": 0.019444712264672148, "biggest_recent_change": 0.4293606973375006},
{"total_number_of_episodes": 14778, "number_of_timesteps": 1626142, "per_episode_reward": -221.78, "episode_reward_trend_value": 0.02143001276400961, "biggest_recent_change": 0.4293606973375006},
{"total_number_of_episodes": 14788, "number_of_timesteps": 1628128, "per_episode_reward": -221.66, "episode_reward_trend_value": 0.020870536236094812, "biggest_recent_change": 0.4293606973375006},
{"total_number_of_episodes": 14798, "number_of_timesteps": 1631302, "per_episode_reward": -221.52, "episode_reward_trend_value": 0.017678589393261113, "biggest_recent_change": 0.336243292291897},
{"total_number_of_episodes": 14808, "number_of_timesteps": 1636301, "per_episode_reward": -221.35, "episode_reward_trend_value": 0.01807834403696644, "biggest_recent_change": 0.336243292291897},
{"total_number_of_episodes": 14818, "number_of_timesteps": 1640352, "per_episode_reward": -221.16, "episode_reward_trend_value": 0.019291474886620426, "biggest_recent_change": 0.336243292291897},
{"total_number_of_episodes": 14828, "number_of_timesteps": 1644386, "per_episode_reward": -220.81, "episode_reward_trend_value": 0.0215525981562602, "biggest_recent_change": 0.35411491375828064},
{"total_number_of_episodes": 14838, "number_of_timesteps": 1646100, "per_episode_reward": -220.7, "episode_reward_trend_value": 0.02040844433878514, "biggest_recent_change": 0.35411491375828064},
{"total_number_of_episodes": 14848, "number_of_timesteps": 1651882, "per_episode_reward": -220.4, "episode_reward_trend_value": 0.022321875176018264, "biggest_recent_change": 0.35411491375828064},
{"total_number_of_episodes": 14858, "number_of_timesteps": 1654564, "per_episode_reward": -220.19, "episode_reward_trend_value": 0.02141904635865741, "biggest_recent_change": 0.35411491375828064},
{"total_number_of_episodes": 14868, "number_of_timesteps": 1657971, "per_episode_reward": -220.07, "episode_reward_trend_value": 0.019065918711067477, "biggest_recent_change": 0.35411491375828064},
{"total_number_of_episodes": 14878, "number_of_timesteps": 1659946, "per_episode_reward": -219.92, "episode_reward_trend_value": 0.019381113537222442, "biggest_recent_change": 0.35411491375828064},
{"total_number_of_episodes": 14888, "number_of_timesteps": 1662295, "per_episode_reward": -219.75, "episode_reward_trend_value": 0.019607568034604762, "biggest_recent_change": 0.35411491375828064},
{"total_number_of_episodes": 14898, "number_of_timesteps": 1665183, "per_episode_reward": -219.64, "episode_reward_trend_value": 0.018929460821870393, "biggest_recent_change": 0.35411491375828064},
{"total_number_of_episodes": 14908, "number_of_timesteps": 1669188, "per_episode_reward": -219.42, "episode_reward_trend_value": 0.0193786562148931, "biggest_recent_change": 0.35411491375828064},
{"total_number_of_episodes": 14918, "number_of_timesteps": 1672317, "per_episode_reward": -219.36, "episode_reward_trend_value": 0.01610775371201751, "biggest_recent_change": 0.3013705190482483},
{"total_number_of_episodes": 14928, "number_of_timesteps": 1673867, "per_episode_reward": -219.26, "episode_reward_trend_value": 0.016032625430940407, "biggest_recent_change": 0.3013705190482483},
{"total_number_of_episodes": 14938, "number_of_timesteps": 1677321, "per_episode_reward": -219.15, "episode_reward_trend_value": 0.013905073634170938, "biggest_recent_change": 0.22820149570924286},
{"total_number_of_episodes": 14948, "number_of_timesteps": 1679085, "per_episode_reward": -219.07, "episode_reward_trend_value": 0.012464789527591493, "biggest_recent_change": 0.22820149570924286},
{"total_number_of_episodes": 14958, "number_of_timesteps": 1682485, "per_episode_reward": -218.62, "episode_reward_trend_value": 0.01608083376499015, "biggest_recent_change": 0.44990578537468195},
{"total_number_of_episodes": 14969, "number_of_timesteps": 1685561, "per_episode_reward": -218.37, "episode_reward_trend_value": 0.017119626077662056, "biggest_recent_change": 0.44990578537468195},
{"total_number_of_episodes": 14979, "number_of_timesteps": 1688779, "per_episode_reward": -218.24, "episode_reward_trend_value": 0.016783884470924212, "biggest_recent_change": 0.44990578537468195},
{"total_number_of_episodes": 14989, "number_of_timesteps": 1690766, "per_episode_reward": -217.93, "episode_reward_trend_value": 0.0190959120982566, "biggest_recent_change": 0.44990578537468195},
{"total_number_of_episodes": 14999, "number_of_timesteps": 1693590, "per_episode_reward": -217.6, "episode_reward_trend_value": 0.020180217028865223, "biggest_recent_change": 0.44990578537468195},
{"total_number_of_episodes": 15010, "number_of_timesteps": 1697895, "per_episode_reward": -217.36, "episode_reward_trend_value": 0.022131866721911957, "biggest_recent_change": 0.44990578537468195},
{"total_number_of_episodes": 15020, "number_of_timesteps": 1701794, "per_episode_reward": -217.13, "episode_reward_trend_value": 0.023692838559074718, "biggest_recent_change": 0.44990578537468195},
{"total_number_of_episodes": 15030, "number_of_timesteps": 1707547, "per_episode_reward": -216.99, "episode_reward_trend_value": 0.024012266149305284, "biggest_recent_change": 0.44990578537468195},
{"total_number_of_episodes": 15040, "number_of_timesteps": 1715139, "per_episode_reward": -216.82, "episode_reward_trend_value": 0.02499884589149417, "biggest_recent_change": 0.44990578537468195},
{"total_number_of_episodes": 15050, "number_of_timesteps": 1718826, "per_episode_reward": -216.58, "episode_reward_trend_value": 0.0227028521789587, "biggest_recent_change": 0.32578893946401877},
{"total_number_of_episodes": 15060, "number_of_timesteps": 1720626, "per_episode_reward": -216.47, "episode_reward_trend_value": 0.021154876521311886, "biggest_recent_change": 0.32578893946401877},
{"total_number_of_episodes": 15070, "number_of_timesteps": 1725713, "per_episode_reward": -216.34, "episode_reward_trend_value": 0.02117792469078602, "biggest_recent_change": 0.32578893946401877},
{"total_number_of_episodes": 15080, "number_of_timesteps": 1730192, "per_episode_reward": -216.08, "episode_reward_trend_value": 0.020556236513389888, "biggest_recent_change": 0.32578893946401877},
{"total_number_of_episodes": 15091, "number_of_timesteps": 1733395, "per_episode_reward": -215.79, "episode_reward_trend_value": 0.020121874147528095, "biggest_recent_change": 0.2866963265364575},
{"total_number_of_episodes": 15103, "number_of_timesteps": 1735715, "per_episode_reward": -215.5, "episode_reward_trend_value": 0.02070696063810134, "biggest_recent_change": 0.2880399450252753},
{"total_number_of_episodes": 15114, "number_of_timesteps": 1738208, "per_episode_reward": -215.29, "episode_reward_trend_value": 0.020371086345618513, "biggest_recent_change": 0.2880399450252753},
{"total_number_of_episodes": 15124, "number_of_timesteps": 1740242, "per_episode_reward": -215.23, "episode_reward_trend_value": 0.019587667386888243, "biggest_recent_change": 0.2880399450252753},
{"total_number_of_episodes": 15134, "number_of_timesteps": 1743569, "per_episode_reward": -215.14, "episode_reward_trend_value": 0.018678248808190447, "biggest_recent_change": 0.2880399450252753},
{"total_number_of_episodes": 15144, "number_of_timesteps": 1746957, "per_episode_reward": -215.09, "episode_reward_trend_value": 0.016556780325441244, "biggest_recent_change": 0.2880399450252753},
{"total_number_of_episodes": 15156, "number_of_timesteps": 1751345, "per_episode_reward": -214.96, "episode_reward_trend_value": 0.0167458321031723, "biggest_recent_change": 0.2880399450252753},
{"total_number_of_episodes": 15166, "number_of_timesteps": 1753984, "per_episode_reward": -214.91, "episode_reward_trend_value": 0.015901537334322154, "biggest_recent_change": 0.2880399450252753},
{"total_number_of_episodes": 15176, "number_of_timesteps": 1756471, "per_episode_reward": -214.81, "episode_reward_trend_value": 0.01407573344320604, "biggest_recent_change": 0.2880399450252753},
{"total_number_of_episodes": 15186, "number_of_timesteps": 1758443, "per_episode_reward": -214.67, "episode_reward_trend_value": 0.012405708942653366, "biggest_recent_change": 0.2880399450252753},
{"total_number_of_episodes": 15197, "number_of_timesteps": 1761673, "per_episode_reward": -214.49, "episode_reward_trend_value": 0.011266214462391606, "biggest_recent_change": 0.207289038944225},
{"total_number_of_episodes": 15208, "number_of_timesteps": 1763688, "per_episode_reward": -214.36, "episode_reward_trend_value": 0.010321038653761308, "biggest_recent_change": 0.1854854418017169},
{"total_number_of_episodes": 15218, "number_of_timesteps": 1765364, "per_episode_reward": -214.16, "episode_reward_trend_value": 0.011818245446338931, "biggest_recent_change": 0.2028802455060088},
{"total_number_of_episodes": 15229, "number_of_timesteps": 1767118, "per_episode_reward": -213.7, "episode_reward_trend_value": 0.015924755043966836, "biggest_recent_change": 0.45668236743236434},
{"total_number_of_episodes": 15239, "number_of_timesteps": 1768532, "per_episode_reward": -213.56, "episode_reward_trend_value": 0.016925618307135754, "biggest_recent_change": 0.45668236743236434},
{"total_number_of_episodes": 15250, "number_of_timesteps": 1770640, "per_episode_reward": -213.4, "episode_reward_trend_value": 0.01737204428190182, "biggest_recent_change": 0.45668236743236434},
{"total_number_of_episodes": 15260, "number_of_timesteps": 1772921, "per_episode_reward": -213.32, "episode_reward_trend_value": 0.017559107095120728, "biggest_recent_change": 0.45668236743236434},
{"total_number_of_episodes": 15270, "number_of_timesteps": 1779298, "per_episode_reward": -213.12, "episode_reward_trend_value": 0.018719208654089433, "biggest_recent_change": 0.45668236743236434},
{"total_number_of_episodes": 15280, "number_of_timesteps": 1788633, "per_episode_reward": -212.91, "episode_reward_trend_value": 0.019524954308572103, "biggest_recent_change": 0.45668236743236434},
{"total_number_of_episodes": 15290, "number_of_timesteps": 1796554, "per_episode_reward": -212.75, "episode_reward_trend_value": 0.019249331493326357, "biggest_recent_change": 0.45668236743236434},
{"total_number_of_episodes": 15300, "number_of_timesteps": 1800610, "per_episode_reward": -212.53, "episode_reward_trend_value": 0.020350700166478455, "biggest_recent_change": 0.45668236743236434},
{"total_number_of_episodes": 15310, "number_of_timesteps": 1804710, "per_episode_reward": -212.36, "episode_reward_trend_value": 0.019982287968578146, "biggest_recent_change": 0.45668236743236434},
{"total_number_of_episodes": 15320, "number_of_timesteps": 1809251, "per_episode_reward": -212.09, "episode_reward_trend_value": 0.01795969202472255, "biggest_recent_change": 0.27464873248536037},
{"total_number_of_episodes": 15330, "number_of_timesteps": 1812835, "per_episode_reward": -211.91, "episode_reward_trend_value": 0.01832357193754635, "biggest_recent_change": 0.27464873248536037},
{"total_number_of_episodes": 15340, "number_of_timesteps": 1816139, "per_episode_reward": -211.84, "episode_reward_trend_value": 0.017339375088453342, "biggest_recent_change": 0.27464873248536037},
{"total_number_of_episodes": 15350, "number_of_timesteps": 1818733, "per_episode_reward": -211.75, "episode_reward_trend_value": 0.017521335353159705, "biggest_recent_change": 0.27464873248536037},
{"total_number_of_episodes": 15360, "number_of_timesteps": 1821717, "per_episode_reward": -211.58, "episode_reward_trend_value": 0.017202773069887677, "biggest_recent_change": 0.27464873248536037},
{"total_number_of_episodes": 15371, "number_of_timesteps": 1823561, "per_episode_reward": -211.42, "episode_reward_trend_value": 0.01665054158458822, "biggest_recent_change": 0.27464873248536037},
{"total_number_of_episodes": 15381, "number_of_timesteps": 1825494, "per_episode_reward": -211.21, "episode_reward_trend_value": 0.017191398571392506, "biggest_recent_change": 0.27464873248536037},
{"total_number_of_episodes": 15391, "number_of_timesteps": 1828050, "per_episode_reward": -211.03, "episode_reward_trend_value": 0.016696628234453847, "biggest_recent_change": 0.27464873248536037},
{"total_number_of_episodes": 15401, "number_of_timesteps": 1837366, "per_episode_reward": -210.83, "episode_reward_trend_value": 0.01708469425484035, "biggest_recent_change": 0.27464873248536037},
{"total_number_of_episodes": 15411, "number_of_timesteps": 1843687, "per_episode_reward": -210.54, "episode_reward_trend_value": 0.01725642807343427, "biggest_recent_change": 0.29010477615881314},
{"total_number_of_episodes": 15421, "number_of_timesteps": 1847361, "per_episode_reward": -210.43, "episode_reward_trend_value": 0.016467718506434734, "biggest_recent_change": 0.29010477615881314},
{"total_number_of_episodes": 15431, "number_of_timesteps": 1850142, "per_episode_reward": -210.25, "episode_reward_trend_value": 0.017672906030910616, "biggest_recent_change": 0.29010477615881314},
{"total_number_of_episodes": 15441, "number_of_timesteps": 1852659, "per_episode_reward": -210.13, "episode_reward_trend_value": 0.017972839443021055, "biggest_recent_change": 0.29010477615881314},
{"total_number_of_episodes": 15451, "number_of_timesteps": 1855119, "per_episode_reward": -209.73, "episode_reward_trend_value": 0.02050355349549401, "biggest_recent_change": 0.40017553683372853},
{"total_number_of_episodes": 15461, "number_of_timesteps": 1856886, "per_episode_reward": -209.46, "episode_reward_trend_value": 0.021736687573409578, "biggest_recent_change": 0.40017553683372853},
{"total_number_of_episodes": 15471, "number_of_timesteps": 1859097, "per_episode_reward": -209.36, "episode_reward_trend_value": 0.02047124802430618, "biggest_recent_change": 0.40017553683372853},
{"total_number_of_episodes": 15481, "number_of_timesteps": 1861680, "per_episode_reward": -209.15, "episode_reward_trend_value": 0.020916140894739026, "biggest_recent_change": 0.40017553683372853},
{"total_number_of_episodes": 15491, "number_of_timesteps": 1868258, "per_episode_reward": -209.02, "episode_reward_trend_value": 0.020013855159517865, "biggest_recent_change": 0.40017553683372853},
{"total_number_of_episodes": 15501, "number_of_timesteps": 1873158, "per_episode_reward": -208.85, "episode_reward_trend_value": 0.018677954885191007, "biggest_recent_change": 0.40017553683372853},
{"total_number_of_episodes": 15511, "number_of_timesteps": 1877530, "per_episode_reward": -208.61, "episode_reward_trend_value": 0.0201942195657144, "biggest_recent_change": 0.40017553683372853},
{"total_number_of_episodes": 15521, "number_of_timesteps": 1879810, "per_episode_reward": -208.26, "episode_reward_trend_value": 0.022047571085444258, "biggest_recent_change": 0.40017553683372853},
{"total_number_of_episodes": 15531, "number_of_timesteps": 1882116, "per_episode_reward": -207.93, "episode_reward_trend_value": 0.024469881357275212, "biggest_recent_change": 0.40017553683372853},
{"total_number_of_episodes": 15541, "number_of_timesteps": 1887056, "per_episode_reward": -207.7, "episode_reward_trend_value": 0.022598401982376812, "biggest_recent_change": 0.3490873240576491},
{"total_number_of_episodes": 15551, "number_of_timesteps": 1894122, "per_episode_reward": -207.64, "episode_reward_trend_value": 0.020245634749435405, "biggest_recent_change": 0.3490873240576491},
{"total_number_of_episodes": 15561, "number_of_timesteps": 1900207, "per_episode_reward": -207.52, "episode_reward_trend_value": 0.02046762377611281, "biggest_recent_change": 0.3490873240576491},
{"total_number_of_episodes": 15571, "number_of_timesteps": 1905181, "per_episode_reward": -207.21, "episode_reward_trend_value": 0.021564174351447227, "biggest_recent_change": 0.3490873240576491},
{"total_number_of_episodes": 15581, "number_of_timesteps": 1911633, "per_episode_reward": -207.03, "episode_reward_trend_value": 0.022182521886405324, "biggest_recent_change": 0.3490873240576491},
{"total_number_of_episodes": 15591, "number_of_timesteps": 1916984, "per_episode_reward": -206.75, "episode_reward_trend_value": 0.02336478534675987, "biggest_recent_change": 0.3490873240576491},
{"total_number_of_episodes": 15601, "number_of_timesteps": 1920718, "per_episode_reward": -206.57, "episode_reward_trend_value": 0.02274134717632579, "biggest_recent_change": 0.3490873240576491},
{"total_number_of_episodes": 15611, "number_of_timesteps": 1927488, "per_episode_reward": -205.98, "episode_reward_trend_value": 0.025343708228129775, "biggest_recent_change": 0.5832998187200076},
{"total_number_of_episodes": 15621, "number_of_timesteps": 1930071, "per_episode_reward": -205.78, "episode_reward_trend_value": 0.023867523021779864, "biggest_recent_change": 0.5832998187200076},
{"total_number_of_episodes": 15631, "number_of_timesteps": 1934310, "per_episode_reward": -205.57, "episode_reward_trend_value": 0.023601083864187446, "biggest_recent_change": 0.5832998187200076},
{"total_number_of_episodes": 15641, "number_of_timesteps": 1937935, "per_episode_reward": -205.42, "episode_reward_trend_value": 0.024624782881097453, "biggest_recent_change": 0.5832998187200076},
{"total_number_of_episodes": 15651, "number_of_timesteps": 1939930, "per_episode_reward": -205.33, "episode_reward_trend_value": 0.02431497783509384, "biggest_recent_change": 0.5832998187200076},
{"total_number_of_episodes": 15662, "number_of_timesteps": 1941875, "per_episode_reward": -205.22, "episode_reward_trend_value": 0.022043155082598295, "biggest_recent_change": 0.5832998187200076},
{"total_number_of_episodes": 15672, "number_of_timesteps": 1943750, "per_episode_reward": -205.08, "episode_reward_trend_value": 0.02164135468605208, "biggest_recent_change": 0.5832998187200076},
{"total_number_of_episodes": 15682, "number_of_timesteps": 1946656, "per_episode_reward": -204.97, "episode_reward_trend_value": 0.019810494362794393, "biggest_recent_change": 0.5832998187200076},
{"total_number_of_episodes": 15692, "number_of_timesteps": 1948553, "per_episode_reward": -204.84, "episode_reward_trend_value": 0.01922152016007538, "biggest_recent_change": 0.5832998187200076},
{"total_number_of_episodes": 15702, "number_of_timesteps": 1950916, "per_episode_reward": -204.6, "episode_reward_trend_value": 0.015402881445674175, "biggest_recent_change": 0.23962233442389902},
{"total_number_of_episodes": 15712, "number_of_timesteps": 1958463, "per_episode_reward": -204.43, "episode_reward_trend_value": 0.015034502545045963, "biggest_recent_change": 0.23962233442389902},
{"total_number_of_episodes": 15722, "number_of_timesteps": 1964865, "per_episode_reward": -204.19, "episode_reward_trend_value": 0.015382212768051318, "biggest_recent_change": 0.23962233442389902},
{"total_number_of_episodes": 15732, "number_of_timesteps": 1972791, "per_episode_reward": -203.99, "episode_reward_trend_value": 0.01588737870299326, "biggest_recent_change": 0.23962233442389902},
{"total_number_of_episodes": 15743, "number_of_timesteps": 1977763, "per_episode_reward": -203.83, "episode_reward_trend_value": 0.016675893773479326, "biggest_recent_change": 0.23962233442389902},
{"total_number_of_episodes": 15753, "number_of_timesteps": 1979725, "per_episode_reward": -203.59, "episode_reward_trend_value": 0.018092560546642746, "biggest_recent_change": 0.23962233442389902},
{"total_number_of_episodes": 15763, "number_of_timesteps": 1983519, "per_episode_reward": -203.46, "episode_reward_trend_value": 0.01804805478589881, "biggest_recent_change": 0.23962233442389902},
{"total_number_of_episodes": 15773, "number_of_timesteps": 1985738, "per_episode_reward": -203.23, "episode_reward_trend_value": 0.0193415781396349, "biggest_recent_change": 0.23962233442389902},
{"total_number_of_episodes": 15783, "number_of_timesteps": 1991818, "per_episode_reward": -203.09, "episode_reward_trend_value": 0.019368782707447785, "biggest_recent_change": 0.23962233442389902},

{"total_number_of_episodes": 15793, "number_of_timesteps": 1993927, "per_episode_reward": -202.97, "episode_reward_trend_value": 0.018076537572290854, "biggest_recent_change": 0.23905678898003657},
{"total_number_of_episodes": 15803, "number_of_timesteps": 1996176, "per_episode_reward": -202.8, "episode_reward_trend_value": 0.01805025883425849, "biggest_recent_change": 0.23905678898003657},
{"total_number_of_episodes": 15814, "number_of_timesteps": 2005620, "per_episode_reward": -202.4, "episode_reward_trend_value": 0.019882173489078368, "biggest_recent_change": 0.4039291079138252},
{"total_number_of_episodes": 15824, "number_of_timesteps": 2008911, "per_episode_reward": -202.27, "episode_reward_trend_value": 0.01918394634079606, "biggest_recent_change": 0.4039291079138252},
{"total_number_of_episodes": 15834, "number_of_timesteps": 2016125, "per_episode_reward": -201.88, "episode_reward_trend_value": 0.021750802982464595, "biggest_recent_change": 0.4039291079138252},
{"total_number_of_episodes": 15844, "number_of_timesteps": 2024393, "per_episode_reward": -201.71, "episode_reward_trend_value": 0.020921318793655056, "biggest_recent_change": 0.4039291079138252},
{"total_number_of_episodes": 15854, "number_of_timesteps": 2028906, "per_episode_reward": -201.53, "episode_reward_trend_value": 0.021435459701039702, "biggest_recent_change": 0.4039291079138252},
{"total_number_of_episodes": 15864, "number_of_timesteps": 2032531, "per_episode_reward": -201.39, "episode_reward_trend_value": 0.02037509481884475, "biggest_recent_change": 0.4039291079138252},
{"total_number_of_episodes": 15874, "number_of_timesteps": 2035443, "per_episode_reward": -201.29, "episode_reward_trend_value": 0.020017929088636935, "biggest_recent_change": 0.4039291079138252},
{"total_number_of_episodes": 15885, "number_of_timesteps": 2039918, "per_episode_reward": -201.06, "episode_reward_trend_value": 0.021249152308215318, "biggest_recent_change": 0.4039291079138252},
{"total_number_of_episodes": 15895, "number_of_timesteps": 2041659, "per_episode_reward": -200.91, "episode_reward_trend_value": 0.021038205301065382, "biggest_recent_change": 0.4039291079138252},
{"total_number_of_episodes": 15905, "number_of_timesteps": 2044276, "per_episode_reward": -200.64, "episode_reward_trend_value": 0.01948565118432176, "biggest_recent_change": 0.3895469701772356},
{"total_number_of_episodes": 15915, "number_of_timesteps": 2046345, "per_episode_reward": -200.5, "episode_reward_trend_value": 0.019630742777072087, "biggest_recent_change": 0.3895469701772356},
{"total_number_of_episodes": 15926, "number_of_timesteps": 2053878, "per_episode_reward": -200.35, "episode_reward_trend_value": 0.01696828568367847, "biggest_recent_change": 0.2641992374068991},
{"total_number_of_episodes": 15936, "number_of_timesteps": 2057776, "per_episode_reward": -200.28, "episode_reward_trend_value": 0.015956524496894532, "biggest_recent_change": 0.2641992374068991},
{"total_number_of_episodes": 15946, "number_of_timesteps": 2062370, "per_episode_reward": -200.0, "episode_reward_trend_value": 0.01697328783666876, "biggest_recent_change": 0.27670847959427647},
{"total_number_of_episodes": 15957, "number_of_timesteps": 2071175, "per_episode_reward": -199.88, "episode_reward_trend_value": 0.016849030893216207, "biggest_recent_change": 0.27670847959427647},
{"total_number_of_episodes": 15967, "number_of_timesteps": 2075113, "per_episode_reward": -199.64, "episode_reward_trend_value": 0.01831363240348733, "biggest_recent_change": 0.27670847959427647},
{"total_number_of_episodes": 15977, "number_of_timesteps": 2082060, "per_episode_reward": -199.44, "episode_reward_trend_value": 0.01797671140882421, "biggest_recent_change": 0.27670847959427647},
{"total_number_of_episodes": 15987, "number_of_timesteps": 2086213, "per_episode_reward": -199.41, "episode_reward_trend_value": 0.01668200323159807, "biggest_recent_change": 0.27670847959427647},
{"total_number_of_episodes": 15997, "number_of_timesteps": 2094398, "per_episode_reward": -199.17, "episode_reward_trend_value": 0.016341923488859163, "biggest_recent_change": 0.27670847959427647},
{"total_number_of_episodes": 16007, "number_of_timesteps": 2100195, "per_episode_reward": -198.99, "episode_reward_trend_value": 0.01672825063926603, "biggest_recent_change": 0.27670847959427647},
{"total_number_of_episodes": 16017, "number_of_timesteps": 2108032, "per_episode_reward": -198.79, "episode_reward_trend_value": 0.01735872896657769, "biggest_recent_change": 0.27670847959427647},
{"total_number_of_episodes": 16027, "number_of_timesteps": 2116135, "per_episode_reward": -198.7, "episode_reward_trend_value": 0.017491610362624657, "biggest_recent_change": 0.27670847959427647},
{"total_number_of_episodes": 16037, "number_of_timesteps": 2123210, "per_episode_reward": -198.51, "episode_reward_trend_value": 0.01656899263168883, "biggest_recent_change": 0.23364155158063227},
{"total_number_of_episodes": 16047, "number_of_timesteps": 2129434, "per_episode_reward": -198.26, "episode_reward_trend_value": 0.0179594989417729, "biggest_recent_change": 0.2464467392436518},
{"total_number_of_episodes": 16057, "number_of_timesteps": 2133224, "per_episode_reward": -198.05, "episode_reward_trend_value": 0.017703085010553978, "biggest_recent_change": 0.2464467392436518},
{"total_number_of_episodes": 16067, "number_of_timesteps": 2135939, "per_episode_reward": -197.9, "episode_reward_trend_value": 0.0171033245691534, "biggest_recent_change": 0.2464467392436518},
{"total_number_of_episodes": 16077, "number_of_timesteps": 2138787, "per_episode_reward": -197.77, "episode_reward_trend_value": 0.018241718359860215, "biggest_recent_change": 0.2464467392436518},
{"total_number_of_episodes": 16087, "number_of_timesteps": 2142741, "per_episode_reward": -197.68, "episode_reward_trend_value": 0.01664496944170095, "biggest_recent_change": 0.2464467392436518},
{"total_number_of_episodes": 16097, "number_of_timesteps": 2147138, "per_episode_reward": -197.52, "episode_reward_trend_value": 0.016411770736518998, "biggest_recent_change": 0.2464467392436518},
{"total_number_of_episodes": 16107, "number_of_timesteps": 2152446, "per_episode_reward": -197.4, "episode_reward_trend_value": 0.015451059373791686, "biggest_recent_change": 0.2464467392436518},
{"total_number_of_episodes": 16117, "number_of_timesteps": 2160833, "per_episode_reward": -197.23, "episode_reward_trend_value": 0.0163960440471344, "biggest_recent_change": 0.2464467392436518},
{"total_number_of_episodes": 16127, "number_of_timesteps": 2167626, "per_episode_reward": -197.1, "episode_reward_trend_value": 0.015605951898003432, "biggest_recent_change": 0.2464467392436518},
{"total_number_of_episodes": 16137, "number_of_timesteps": 2173109, "per_episode_reward": -196.83, "episode_reward_trend_value": 0.015954641901036362, "biggest_recent_change": 0.27782883951661574},
{"total_number_of_episodes": 16147, "number_of_timesteps": 2178446, "per_episode_reward": -196.61, "episode_reward_trend_value": 0.015988255265806904, "biggest_recent_change": 0.27782883951661574},
{"total_number_of_episodes": 16157, "number_of_timesteps": 2181311, "per_episode_reward": -196.35, "episode_reward_trend_value": 0.01719992779123313, "biggest_recent_change": 0.27782883951661574},
{"total_number_of_episodes": 16167, "number_of_timesteps": 2185031, "per_episode_reward": -196.02, "episode_reward_trend_value": 0.019384373226373933, "biggest_recent_change": 0.3317221639461252},
{"total_number_of_episodes": 16178, "number_of_timesteps": 2190404, "per_episode_reward": -195.72, "episode_reward_trend_value": 0.021759999196127762, "biggest_recent_change": 0.3317221639461252},
{"total_number_of_episodes": 16188, "number_of_timesteps": 2193098, "per_episode_reward": -195.55, "episode_reward_trend_value": 0.02179195826612512, "biggest_recent_change": 0.3317221639461252},
{"total_number_of_episodes": 16199, "number_of_timesteps": 2198313, "per_episode_reward": -195.44, "episode_reward_trend_value": 0.021685267266879135, "biggest_recent_change": 0.3317221639461252},
{"total_number_of_episodes": 16209, "number_of_timesteps": 2200188, "per_episode_reward": -195.32, "episode_reward_trend_value": 0.02118663166029396, "biggest_recent_change": 0.3317221639461252},
{"total_number_of_episodes": 16219, "number_of_timesteps": 2202004, "per_episode_reward": -195.16, "episode_reward_trend_value": 0.021606848796933302, "biggest_recent_change": 0.3317221639461252},
{"total_number_of_episodes": 16229, "number_of_timesteps": 2203763, "per_episode_reward": -195.02, "episode_reward_trend_value": 0.02002695607357339, "biggest_recent_change": 0.3317221639461252},
{"total_number_of_episodes": 16240, "number_of_timesteps": 2206513, "per_episode_reward": -194.62, "episode_reward_trend_value": 0.022134904067845834, "biggest_recent_change": 0.4033048200847986},
{"total_number_of_episodes": 16250, "number_of_timesteps": 2208374, "per_episode_reward": -194.4, "episode_reward_trend_value": 0.0217521759100126, "biggest_recent_change": 0.4033048200847986},

{"total_number_of_episodes": 16260, "number_of_timesteps": 2211869, "per_episode_reward": -194.27, "episode_reward_trend_value": 0.01947523706816191, "biggest_recent_change": 0.4033048200847986},
{"total_number_of_episodes": 16270, "number_of_timesteps": 2215325, "per_episode_reward": -194.04, "episode_reward_trend_value": 0.018649858764322857, "biggest_recent_change": 0.4033048200847986},
{"total_number_of_episodes": 16280, "number_of_timesteps": 2218962, "per_episode_reward": -193.91, "episode_reward_trend_value": 0.01828495113324967, "biggest_recent_change": 0.4033048200847986},
{"total_number_of_episodes": 16290, "number_of_timesteps": 2227169, "per_episode_reward": -193.76, "episode_reward_trend_value": 0.018694540158984474, "biggest_recent_change": 0.4033048200847986},
{"total_number_of_episodes": 16300, "number_of_timesteps": 2232546, "per_episode_reward": -193.72, "episode_reward_trend_value": 0.017733181153680118, "biggest_recent_change": 0.4033048200847986},
{"total_number_of_episodes": 16310, "number_of_timesteps": 2237849, "per_episode_reward": -193.64, "episode_reward_trend_value": 0.016925988739220722, "biggest_recent_change": 0.4033048200847986},
{"total_number_of_episodes": 16320, "number_of_timesteps": 2242959, "per_episode_reward": -193.54, "episode_reward_trend_value": 0.01647876089602739, "biggest_recent_change": 0.4033048200847986},
{"total_number_of_episodes": 16330, "number_of_timesteps": 2247319, "per_episode_reward": -193.39, "episode_reward_trend_value": 0.013630049878641002, "biggest_recent_change": 0.22940694785839355},
{"total_number_of_episodes": 16340, "number_of_timesteps": 2254007, "per_episode_reward": -193.32, "episode_reward_trend_value": 0.011970077068228748, "biggest_recent_change": 0.22940694785839355},
{"total_number_of_episodes": 16351, "number_of_timesteps": 2259188, "per_episode_reward": -193.14, "episode_reward_trend_value": 0.012575215917144394, "biggest_recent_change": 0.22940694785839355},
{"total_number_of_episodes": 16361, "number_of_timesteps": 2260805, "per_episode_reward": -193.05, "episode_reward_trend_value": 0.01101074059893108, "biggest_recent_change": 0.18126016458197114},
{"total_number_of_episodes": 16371, "number_of_timesteps": 2262560, "per_episode_reward": -192.93, "episode_reward_trend_value": 0.010864673591315308, "biggest_recent_change": 0.18126016458197114},
{"total_number_of_episodes": 16381, "number_of_timesteps": 2264255, "per_episode_reward": -192.7, "episode_reward_trend_value": 0.011800232848544409, "biggest_recent_change": 0.2316660141190141},
{"total_number_of_episodes": 16391, "number_of_timesteps": 2266828, "per_episode_reward": -192.63, "episode_reward_trend_value": 0.012123863647124405, "biggest_recent_change": 0.2316660141190141},
{"total_number_of_episodes": 16403, "number_of_timesteps": 2271676, "per_episode_reward": -192.42, "episode_reward_trend_value": 0.013529282149724509, "biggest_recent_change": 0.2316660141190141},
{"total_number_of_episodes": 16413, "number_of_timesteps": 2273464, "per_episode_reward": -192.23, "episode_reward_trend_value": 0.014572063675635783, "biggest_recent_change": 0.2316660141190141},
{"total_number_of_episodes": 16423, "number_of_timesteps": 2278593, "per_episode_reward": -192.16, "episode_reward_trend_value": 0.013684472688391087, "biggest_recent_change": 0.2316660141190141},
{"total_number_of_episodes": 16433, "number_of_timesteps": 2282777, "per_episode_reward": -192.02, "episode_reward_trend_value": 0.014396826750198797, "biggest_recent_change": 0.2316660141190141},
{"total_number_of_episodes": 16444, "number_of_timesteps": 2288148, "per_episode_reward": -191.9, "episode_reward_trend_value": 0.013769081569462096, "biggest_recent_change": 0.2316660141190141},
{"total_number_of_episodes": 16454, "number_of_timesteps": 2296381, "per_episode_reward": -191.76, "episode_reward_trend_value": 0.014298787869217714, "biggest_recent_change": 0.2316660141190141},
{"total_number_of_episodes": 16464, "number_of_timesteps": 2302278, "per_episode_reward": -191.54, "episode_reward_trend_value": 0.015508382162073847, "biggest_recent_change": 0.2316660141190141},
{"total_number_of_episodes": 16475, "number_of_timesteps": 2308493, "per_episode_reward": -191.31, "episode_reward_trend_value": 0.01539055138475918, "biggest_recent_change": 0.2257927036747276},
{"total_number_of_episodes": 16485, "number_of_timesteps": 2315195, "per_episode_reward": -191.1, "episode_reward_trend_value": 0.01697100432618994, "biggest_recent_change": 0.2257927036747276},
{"total_number_of_episodes": 16495, "number_of_timesteps": 2321303, "per_episode_reward": -190.95, "episode_reward_trend_value": 0.016267024660476182, "biggest_recent_change": 0.2257927036747276},
{"total_number_of_episodes": 16505, "number_of_timesteps": 2328033, "per_episode_reward": -190.88, "episode_reward_trend_value": 0.014936962632530835, "biggest_recent_change": 0.2257927036747276},
{"total_number_of_episodes": 16515, "number_of_timesteps": 2329701, "per_episode_reward": -190.54, "episode_reward_trend_value": 0.018052401542467088, "biggest_recent_change": 0.34742714156226384},
{"total_number_of_episodes": 16525, "number_of_timesteps": 2333123, "per_episode_reward": -190.37, "episode_reward_trend_value": 0.018348428928357585, "biggest_recent_change": 0.34742714156226384},
{"total_number_of_episodes": 16535, "number_of_timesteps": 2340138, "per_episode_reward": -190.3, "episode_reward_trend_value": 0.017770341051405264, "biggest_recent_change": 0.34742714156226384},
{"total_number_of_episodes": 16545, "number_of_timesteps": 2347697, "per_episode_reward": -190.16, "episode_reward_trend_value": 0.017818968981524425, "biggest_recent_change": 0.34742714156226384},
{"total_number_of_episodes": 16555, "number_of_timesteps": 2356086, "per_episode_reward": -189.88, "episode_reward_trend_value": 0.018340626518907596, "biggest_recent_change": 0.34742714156226384},
{"total_number_of_episodes": 16565, "number_of_timesteps": 2362601, "per_episode_reward": -189.63, "episode_reward_trend_value": 0.018683013134626787, "biggest_recent_change": 0.34742714156226384},
{"total_number_of_episodes": 16575, "number_of_timesteps": 2368664, "per_episode_reward": -189.5, "episode_reward_trend_value": 0.01780862825952233, "biggest_recent_change": 0.34742714156226384},
{"total_number_of_episodes": 16585, "number_of_timesteps": 2375461, "per_episode_reward": -189.37, "episode_reward_trend_value": 0.017622173948227113, "biggest_recent_change": 0.34742714156226384},
{"total_number_of_episodes": 16595, "number_of_timesteps": 2383833, "per_episode_reward": -189.16, "episode_reward_trend_value": 0.019144407364083803, "biggest_recent_change": 0.34742714156226384},
{"total_number_of_episodes": 16605, "number_of_timesteps": 2389324, "per_episode_reward": -189.02, "episode_reward_trend_value": 0.016874136657304462, "biggest_recent_change": 0.2727418820392131},
{"total_number_of_episodes": 16615, "number_of_timesteps": 2393609, "per_episode_reward": -188.83, "episode_reward_trend_value": 0.017092265991984355, "biggest_recent_change": 0.2727418820392131},
{"total_number_of_episodes": 16625, "number_of_timesteps": 2398112, "per_episode_reward": -188.69, "episode_reward_trend_value": 0.01782716047345932, "biggest_recent_change": 0.2727418820392131},
{"total_number_of_episodes": 16635, "number_of_timesteps": 2400412, "per_episode_reward": -188.41, "episode_reward_trend_value": 0.019462911408551362, "biggest_recent_change": 0.287871834066209},
{"total_number_of_episodes": 16645, "number_of_timesteps": 2401945, "per_episode_reward": -188.15, "episode_reward_trend_value": 0.019267314377398433, "biggest_recent_change": 0.287871834066209},
{"total_number_of_episodes": 16655, "number_of_timesteps": 2403510, "per_episode_reward": -187.61, "episode_reward_trend_value": 0.02251812361155222, "biggest_recent_change": 0.5444488706492621},
{"total_number_of_episodes": 16665, "number_of_timesteps": 2405076, "per_episode_reward": -187.36, "episode_reward_trend_value": 0.02374957081591573, "biggest_recent_change": 0.5444488706492621},
{"total_number_of_episodes": 16675, "number_of_timesteps": 2407525, "per_episode_reward": -187.13, "episode_reward_trend_value": 0.024874378910915755, "biggest_recent_change": 0.5444488706492621},
{"total_number_of_episodes": 16685, "number_of_timesteps": 2409447, "per_episode_reward": -186.93, "episode_reward_trend_value": 0.024763782159505532, "biggest_recent_change": 0.5444488706492621},
{"total_number_of_episodes": 16695, "number_of_timesteps": 2416173, "per_episode_reward": -186.67, "episode_reward_trend_value": 0.026056671408208054, "biggest_recent_change": 0.5444488706492621},
{"total_number_of_episodes": 16705, "number_of_timesteps": 2423099, "per_episode_reward": -186.45, "episode_reward_trend_value": 0.026480741830318445, "biggest_recent_change": 0.5444488706492621},
{"total_number_of_episodes": 16715, "number_of_timesteps": 2429969, "per_episode_reward": -186.06, "episode_reward_trend_value": 0.029304732907735342, "biggest_recent_change": 0.5444488706492621},
{"total_number_of_episodes": 16726, "number_of_timesteps": 2433296, "per_episode_reward": -185.85, "episode_reward_trend_value": 0.028425791288826004, "biggest_recent_change": 0.5444488706492621},
{"total_number_of_episodes": 16736, "number_of_timesteps": 2438865, "per_episode_reward": -185.67, "episode_reward_trend_value": 0.02761800479261025, "biggest_recent_change": 0.5444488706492621},
{"total_number_of_episodes": 16746, "number_of_timesteps": 2444109, "per_episode_reward": -185.53, "episode_reward_trend_value": 0.023057715600455393, "biggest_recent_change": 0.3930348896902274},
{"total_number_of_episodes": 16756, "number_of_timesteps": 2452595, "per_episode_reward": -185.21, "episode_reward_trend_value": 0.023961243619221605, "biggest_recent_change": 0.3930348896902274},
{"total_number_of_episodes": 16766, "number_of_timesteps": 2457100, "per_episode_reward": -185.06, "episode_reward_trend_value": 0.022957983622438543, "biggest_recent_change": 0.3930348896902274},
{"total_number_of_episodes": 16776, "number_of_timesteps": 2464347, "per_episode_reward": -184.76, "episode_reward_trend_value": 0.024190378604664727, "biggest_recent_change": 0.3930348896902274},
{"total_number_of_episodes": 16786, "number_of_timesteps": 2471750, "per_episode_reward": -184.21, "episode_reward_trend_value": 0.027348643862237055, "biggest_recent_change": 0.5437066835168594},
{"total_number_of_episodes": 16796, "number_of_timesteps": 2478991, "per_episode_reward": -184.03, "episode_reward_trend_value": 0.02693286719160521, "biggest_recent_change": 0.5437066835168594},
{"total_number_of_episodes": 16806, "number_of_timesteps": 2482500, "per_episode_reward": -183.89, "episode_reward_trend_value": 0.024110416521775667, "biggest_recent_change": 0.5437066835168594},
{"total_number_of_episodes": 16817, "number_of_timesteps": 2489467, "per_episode_reward": -183.49, "episode_reward_trend_value": 0.02621023925806551, "biggest_recent_change": 0.5437066835168594},
{"total_number_of_episodes": 16827, "number_of_timesteps": 2495401, "per_episode_reward": -183.22, "episode_reward_trend_value": 0.027156258099179174, "biggest_recent_change": 0.5437066835168594},
{"total_number_of_episodes": 16837, "number_of_timesteps": 2500024, "per_episode_reward": -183.05, "episode_reward_trend_value": 0.027531067385412354, "biggest_recent_change": 0.5437066835168594},
{"total_number_of_episodes": 16847, "number_of_timesteps": 2505978, "per_episode_reward": -182.81, "episode_reward_trend_value": 0.026607132486242017, "biggest_recent_change": 0.5437066835168594},
{"total_number_of_episodes": 16857, "number_of_timesteps": 2511097, "per_episode_reward": -182.69, "episode_reward_trend_value": 0.026379814980209127, "biggest_recent_change": 0.5437066835168594},
{"total_number_of_episodes": 16867, "number_of_timesteps": 2518703, "per_episode_reward": -182.5, "episode_reward_trend_value": 0.02505149225868719, "biggest_recent_change": 0.5437066835168594},
{"total_number_of_episodes": 16877, "number_of_timesteps": 2526354, "per_episode_reward": -182.31, "episode_reward_trend_value": 0.021125433955764883, "biggest_recent_change": 0.39775113463045386},
{"total_number_of_episodes": 16887, "number_of_timesteps": 2528751, "per_episode_reward": -182.11, "episode_reward_trend_value": 0.021242702125547276, "biggest_recent_change": 0.39775113463045386},
{"total_number_of_episodes": 16897, "number_of_timesteps": 2534753, "per_episode_reward": -181.8, "episode_reward_trend_value": 0.023233531838825015, "biggest_recent_change": 0.39775113463045386},
{"total_number_of_episodes": 16907, "number_of_timesteps": 2541515, "per_episode_reward": -181.27, "episode_reward_trend_value": 0.024686895053067322, "biggest_recent_change": 0.5285538239122616},
{"total_number_of_episodes": 16917, "number_of_timesteps": 2544205, "per_episode_reward": -181.05, "episode_reward_trend_value": 0.02415716374416029, "biggest_recent_change": 0.5285538239122616},
{"total_number_of_episodes": 16927, "number_of_timesteps": 2550101, "per_episode_reward": -180.94, "episode_reward_trend_value": 0.02348673046445021, "biggest_recent_change": 0.5285538239122616},
{"total_number_of_episodes": 16937, "number_of_timesteps": 2555310, "per_episode_reward": -180.82, "episode_reward_trend_value": 0.02216399853313299, "biggest_recent_change": 0.5285538239122616},
{"total_number_of_episodes": 16947, "number_of_timesteps": 2560864, "per_episode_reward": -180.76, "episode_reward_trend_value": 0.021435666778001582, "biggest_recent_change": 0.5285538239122616},
{"total_number_of_episodes": 16957, "number_of_timesteps": 2568473, "per_episode_reward": -180.56, "episode_reward_trend_value": 0.021568448354663084, "biggest_recent_change": 0.5285538239122616},
{"total_number_of_episodes": 16967, "number_of_timesteps": 2575944, "per_episode_reward": -180.28, "episode_reward_trend_value": 0.022608073909555694, "biggest_recent_change": 0.5285538239122616},
{"total_number_of_episodes": 16977, "number_of_timesteps": 2581370, "per_episode_reward": -180.23, "episode_reward_trend_value": 0.020979050498639316, "biggest_recent_change": 0.5285538239122616},
{"total_number_of_episodes": 16987, "number_of_timesteps": 2587371, "per_episode_reward": -179.99, "episode_reward_trend_value": 0.020112160121506246, "biggest_recent_change": 0.5285538239122616},
{"total_number_of_episodes": 16997, "number_of_timesteps": 2591596, "per_episode_reward": -179.8, "episode_reward_trend_value": 0.016292804488959846, "biggest_recent_change": 0.28392773619418676},
{"total_number_of_episodes": 17008, "number_of_timesteps": 2595893, "per_episode_reward": -179.61, "episode_reward_trend_value": 0.016020082783966435, "biggest_recent_change": 0.28392773619418676},

{"total_number_of_episodes": 17020, "number_of_timesteps": 2599706, "per_episode_reward": -179.34, "episode_reward_trend_value": 0.017802115378624864, "biggest_recent_change": 0.28392773619418676},
{"total_number_of_episodes": 17030, "number_of_timesteps": 2602090, "per_episode_reward": -179.21, "episode_reward_trend_value": 0.017816763624099646, "biggest_recent_change": 0.28392773619418676},
{"total_number_of_episodes": 17040, "number_of_timesteps": 2604334, "per_episode_reward": -178.75, "episode_reward_trend_value": 0.022341540930668202, "biggest_recent_change": 0.466246275613571},
{"total_number_of_episodes": 17050, "number_of_timesteps": 2610736, "per_episode_reward": -178.67, "episode_reward_trend_value": 0.021009066768456503, "biggest_recent_change": 0.466246275613571},
{"total_number_of_episodes": 17060, "number_of_timesteps": 2613704, "per_episode_reward": -178.46, "episode_reward_trend_value": 0.020178889808264305, "biggest_recent_change": 0.466246275613571},
{"total_number_of_episodes": 17070, "number_of_timesteps": 2618725, "per_episode_reward": -178.12, "episode_reward_trend_value": 0.023363130966360283, "biggest_recent_change": 0.466246275613571},
{"total_number_of_episodes": 17080, "number_of_timesteps": 2623967, "per_episode_reward": -177.76, "episode_reward_trend_value": 0.02468150374427959, "biggest_recent_change": 0.466246275613571},
{"total_number_of_episodes": 17090, "number_of_timesteps": 2629127, "per_episode_reward": -177.4, "episode_reward_trend_value": 0.026667630984030348, "biggest_recent_change": 0.466246275613571},
{"total_number_of_episodes": 17100, "number_of_timesteps": 2636719, "per_episode_reward": -177.2, "episode_reward_trend_value": 0.026681729802471132, "biggest_recent_change": 0.466246275613571},
{"total_number_of_episodes": 17110, "number_of_timesteps": 2644523, "per_episode_reward": -177.02, "episode_reward_trend_value": 0.025703638544748563, "biggest_recent_change": 0.466246275613571},

{"total_number_of_episodes": 17120, "number_of_timesteps": 2652167, "per_episode_reward": -176.85, "episode_reward_trend_value": 0.026306782115323953, "biggest_recent_change": 0.466246275613571},
{"total_number_of_episodes": 17130, "number_of_timesteps": 2659318, "per_episode_reward": -176.65, "episode_reward_trend_value": 0.023332293551031728, "biggest_recent_change": 0.3635632685606538},
{"total_number_of_episodes": 17141, "number_of_timesteps": 2665197, "per_episode_reward": -176.59, "episode_reward_trend_value": 0.023115661849940416, "biggest_recent_change": 0.3635632685606538},
{"total_number_of_episodes": 17152, "number_of_timesteps": 2675617, "per_episode_reward": -176.47, "episode_reward_trend_value": 0.02215003854672154, "biggest_recent_change": 0.3635632685606538},
{"total_number_of_episodes": 17162, "number_of_timesteps": 2680488, "per_episode_reward": -176.21, "episode_reward_trend_value": 0.021263473149592628, "biggest_recent_change": 0.3635632685606538},
{"total_number_of_episodes": 17172, "number_of_timesteps": 2688179, "per_episode_reward": -176.14, "episode_reward_trend_value": 0.018072686206627647, "biggest_recent_change": 0.3635632685606538},
{"total_number_of_episodes": 17182, "number_of_timesteps": 2694189, "per_episode_reward": -176.06, "episode_reward_trend_value": 0.014899100293733467, "biggest_recent_change": 0.256901727754439},
{"total_number_of_episodes": 17193, "number_of_timesteps": 2698217, "per_episode_reward": -175.75, "episode_reward_trend_value": 0.016125235258720887, "biggest_recent_change": 0.3069793295337604},
{"total_number_of_episodes": 17203, "number_of_timesteps": 2703027, "per_episode_reward": -175.49, "episode_reward_trend_value": 0.01708424680201214, "biggest_recent_change": 0.3069793295337604},
{"total_number_of_episodes": 17213, "number_of_timesteps": 2706616, "per_episode_reward": -175.32, "episode_reward_trend_value": 0.01699896439973385, "biggest_recent_change": 0.3069793295337604},
{"total_number_of_episodes": 17223, "number_of_timesteps": 2710858, "per_episode_reward": -174.97, "episode_reward_trend_value": 0.01864359628314958, "biggest_recent_change": 0.3465591743346863},
{"total_number_of_episodes": 17233, "number_of_timesteps": 2714984, "per_episode_reward": -174.78, "episode_reward_trend_value": 0.020105119144909624, "biggest_recent_change": 0.3465591743346863},
{"total_number_of_episodes": 17243, "number_of_timesteps": 2717740, "per_episode_reward": -174.58, "episode_reward_trend_value": 0.020959794832532137, "biggest_recent_change": 0.3465591743346863},
{"total_number_of_episodes": 17253, "number_of_timesteps": 2721251, "per_episode_reward": -174.05, "episode_reward_trend_value": 0.024014265498198344, "biggest_recent_change": 0.5318040876643977},
{"total_number_of_episodes": 17263, "number_of_timesteps": 2725100, "per_episode_reward": -173.74, "episode_reward_trend_value": 0.026682471361815868, "biggest_recent_change": 0.5318040876643977},
{"total_number_of_episodes": 17273, "number_of_timesteps": 2731772, "per_episode_reward": -173.61, "episode_reward_trend_value": 0.027251496236840467, "biggest_recent_change": 0.5318040876643977},
{"total_number_of_episodes": 17283, "number_of_timesteps": 2736814, "per_episode_reward": -173.34, "episode_reward_trend_value": 0.02677715350612352, "biggest_recent_change": 0.5318040876643977},
{"total_number_of_episodes": 17293, "number_of_timesteps": 2742876, "per_episode_reward": -173.11, "episode_reward_trend_value": 0.026428296503417593, "biggest_recent_change": 0.5318040876643977},
{"total_number_of_episodes": 17303, "number_of_timesteps": 2746270, "per_episode_reward": -172.48, "episode_reward_trend_value": 0.0314891088661786, "biggest_recent_change": 0.6244988988447915},
{"total_number_of_episodes": 17313, "number_of_timesteps": 2751499, "per_episode_reward": -172.37, "episode_reward_trend_value": 0.02892626690840814, "biggest_recent_change": 0.6244988988447915},
{"total_number_of_episodes": 17323, "number_of_timesteps": 2755808, "per_episode_reward": -172.15, "episode_reward_trend_value": 0.029162290504187165, "biggest_recent_change": 0.6244988988447915},
{"total_number_of_episodes": 17333, "number_of_timesteps": 2757502, "per_episode_reward": -171.95, "episode_reward_trend_value": 0.029195871060057103, "biggest_recent_change": 0.6244988988447915},
{"total_number_of_episodes": 17343, "number_of_timesteps": 2759244, "per_episode_reward": -171.69, "episode_reward_trend_value": 0.026148356662804732, "biggest_recent_change": 0.6244988988447915},
{"total_number_of_episodes": 17353, "number_of_timesteps": 2761621, "per_episode_reward": -171.47, "episode_reward_trend_value": 0.025189696860063136, "biggest_recent_change": 0.6244988988447915},
{"total_number_of_episodes": 17363, "number_of_timesteps": 2763005, "per_episode_reward": -171.25, "episode_reward_trend_value": 0.02616168784811824, "biggest_recent_change": 0.6244988988447915},
{"total_number_of_episodes": 17373, "number_of_timesteps": 2765401, "per_episode_reward": -171.09, "episode_reward_trend_value": 0.024995928669829935, "biggest_recent_change": 0.6244988988447915},

{"total_number_of_episodes": 17383, "number_of_timesteps": 2768879, "per_episode_reward": -171.05, "episode_reward_trend_value": 0.02283726682001625, "biggest_recent_change": 0.6244988988447915},
{"total_number_of_episodes": 17393, "number_of_timesteps": 2773963, "per_episode_reward": -170.87, "episode_reward_trend_value": 0.017971125090231035, "biggest_recent_change": 0.2575277919116843},
{"total_number_of_episodes": 17403, "number_of_timesteps": 2780152, "per_episode_reward": -170.78, "episode_reward_trend_value": 0.01768164407230396, "biggest_recent_change": 0.2575277919116843},
{"total_number_of_episodes": 17413, "number_of_timesteps": 2786882, "per_episode_reward": -170.71, "episode_reward_trend_value": 0.016086699088103274, "biggest_recent_change": 0.2575277919116843},
{"total_number_of_episodes": 17423, "number_of_timesteps": 2789433, "per_episode_reward": -170.58, "episode_reward_trend_value": 0.015296178538078051, "biggest_recent_change": 0.2575277919116843},
{"total_number_of_episodes": 17433, "number_of_timesteps": 2792817, "per_episode_reward": -170.18, "episode_reward_trend_value": 0.01677752259968991, "biggest_recent_change": 0.3908487574567516},
{"total_number_of_episodes": 17443, "number_of_timesteps": 2797048, "per_episode_reward": -170.14, "episode_reward_trend_value": 0.014732710482363765, "biggest_recent_change": 0.3908487574567516},
{"total_number_of_episodes": 17453, "number_of_timesteps": 2801264, "per_episode_reward": -170.0, "episode_reward_trend_value": 0.013914134027000577, "biggest_recent_change": 0.3908487574567516},
{"total_number_of_episodes": 17463, "number_of_timesteps": 2807377, "per_episode_reward": -169.85, "episode_reward_trend_value": 0.01382553592597699, "biggest_recent_change": 0.3908487574567516},
{"total_number_of_episodes": 17473, "number_of_timesteps": 2812489, "per_episode_reward": -169.65, "episode_reward_trend_value": 0.015551634234451387, "biggest_recent_change": 0.3908487574567516},

{"total_number_of_episodes": 17483, "number_of_timesteps": 2817356, "per_episode_reward": -169.51, "episode_reward_trend_value": 0.015037184550174564, "biggest_recent_change": 0.3908487574567516},
{"total_number_of_episodes": 17493, "number_of_timesteps": 2823633, "per_episode_reward": -169.38, "episode_reward_trend_value": 0.015551511851408073, "biggest_recent_change": 0.3908487574567516},
{"total_number_of_episodes": 17503, "number_of_timesteps": 2828557, "per_episode_reward": -169.28, "episode_reward_trend_value": 0.015882687997726443, "biggest_recent_change": 0.3908487574567516},
{"total_number_of_episodes": 17513, "number_of_timesteps": 2834013, "per_episode_reward": -169.19, "episode_reward_trend_value": 0.015434528035831997, "biggest_recent_change": 0.3908487574567516},
{"total_number_of_episodes": 17523, "number_of_timesteps": 2839285, "per_episode_reward": -169.1, "episode_reward_trend_value": 0.012020707693352822, "biggest_recent_change": 0.1957545941987746},
{"total_number_of_episodes": 17533, "number_of_timesteps": 2844559, "per_episode_reward": -168.94, "episode_reward_trend_value": 0.01331638250357072, "biggest_recent_change": 0.1957545941987746},
{"total_number_of_episodes": 17543, "number_of_timesteps": 2847111, "per_episode_reward": -168.76, "episode_reward_trend_value": 0.013733395987699421, "biggest_recent_change": 0.1957545941987746},
{"total_number_of_episodes": 17553, "number_of_timesteps": 2851499, "per_episode_reward": -168.64, "episode_reward_trend_value": 0.013428984009767771, "biggest_recent_change": 0.1957545941987746},
{"total_number_of_episodes": 17563, "number_of_timesteps": 2857978, "per_episode_reward": -168.59, "episode_reward_trend_value": 0.011823557650409574, "biggest_recent_change": 0.18049129666624708},
{"total_number_of_episodes": 17573, "number_of_timesteps": 2862387, "per_episode_reward": -168.41, "episode_reward_trend_value": 0.012214189614153131, "biggest_recent_change": 0.18049129666624708},
{"total_number_of_episodes": 17583, "number_of_timesteps": 2865750, "per_episode_reward": -168.33, "episode_reward_trend_value": 0.011613553327863239, "biggest_recent_change": 0.18049129666624708},
{"total_number_of_episodes": 17593, "number_of_timesteps": 2870098, "per_episode_reward": -168.22, "episode_reward_trend_value": 0.011769424990422156, "biggest_recent_change": 0.18049129666624708},
{"total_number_of_episodes": 17603, "number_of_timesteps": 2878138, "per_episode_reward": -168.05, "episode_reward_trend_value": 0.012672496638379962, "biggest_recent_change": 0.18049129666624708},
{"total_number_of_episodes": 17613, "number_of_timesteps": 2884958, "per_episode_reward": -167.67, "episode_reward_trend_value": 0.01591794056978731, "biggest_recent_change": 0.3756948804602871},
{"total_number_of_episodes": 17623, "number_of_timesteps": 2889837, "per_episode_reward": -167.38, "episode_reward_trend_value": 0.017384671132005123, "biggest_recent_change": 0.3756948804602871},
{"total_number_of_episodes": 17634, "number_of_timesteps": 2897208, "per_episode_reward": -167.29, "episode_reward_trend_value": 0.01634920744695939, "biggest_recent_change": 0.3756948804602871},
{"total_number_of_episodes": 17644, "number_of_timesteps": 2902089, "per_episode_reward": -167.08, "episode_reward_trend_value": 0.01735692039908372, "biggest_recent_change": 0.3756948804602871},
{"total_number_of_episodes": 17654, "number_of_timesteps": 2907385, "per_episode_reward": -166.8, "episode_reward_trend_value": 0.019927465032029724, "biggest_recent_change": 0.3756948804602871},
{"total_number_of_episodes": 17664, "number_of_timesteps": 2912803, "per_episode_reward": -166.58, "episode_reward_trend_value": 0.020387918549738832, "biggest_recent_change": 0.3756948804602871},
{"total_number_of_episodes": 17674, "number_of_timesteps": 2920372, "per_episode_reward": -166.28, "episode_reward_trend_value": 0.02281392423416959, "biggest_recent_change": 0.3756948804602871},
{"total_number_of_episodes": 17684, "number_of_timesteps": 2928840, "per_episode_reward": -165.78, "episode_reward_trend_value": 0.027044049788344814, "biggest_recent_change": 0.4942570960847661},
{"total_number_of_episodes": 17694, "number_of_timesteps": 2935632, "per_episode_reward": -165.68, "episode_reward_trend_value": 0.026272078504831282, "biggest_recent_change": 0.4942570960847661},
{"total_number_of_episodes": 17704, "number_of_timesteps": 2942976, "per_episode_reward": -165.54, "episode_reward_trend_value": 0.02367357105447733, "biggest_recent_change": 0.4942570960847661},
{"total_number_of_episodes": 17714, "number_of_timesteps": 2950107, "per_episode_reward": -165.4, "episode_reward_trend_value": 0.021953863337562517, "biggest_recent_change": 0.4942570960847661},
{"total_number_of_episodes": 17724, "number_of_timesteps": 2956035, "per_episode_reward": -165.22, "episode_reward_trend_value": 0.02302780001362742, "biggest_recent_change": 0.4942570960847661},
{"total_number_of_episodes": 17734, "number_of_timesteps": 2963669, "per_episode_reward": -165.06, "episode_reward_trend_value": 0.02245367927425611, "biggest_recent_change": 0.4942570960847661},
{"total_number_of_episodes": 17745, "number_of_timesteps": 2970769, "per_episode_reward": -164.78, "episode_reward_trend_value": 0.022438142513969535, "biggest_recent_change": 0.4942570960847661},
{"total_number_of_episodes": 17756, "number_of_timesteps": 2977220, "per_episode_reward": -164.48, "episode_reward_trend_value": 0.023268319056203128, "biggest_recent_change": 0.4942570960847661},
{"total_number_of_episodes": 17767, "number_of_timesteps": 2984871, "per_episode_reward": -164.22, "episode_reward_trend_value": 0.022836424779289485, "biggest_recent_change": 0.4942570960847661},
{"total_number_of_episodes": 17777, "number_of_timesteps": 2991899, "per_episode_reward": -164.06, "episode_reward_trend_value": 0.019169114571902117, "biggest_recent_change": 0.2915592537109717},
{"total_number_of_episodes": 17787, "number_of_timesteps": 2998052, "per_episode_reward": -163.92, "episode_reward_trend_value": 0.019621832062088628, "biggest_recent_change": 0.2915592537109717},
{"total_number_of_episodes": 17797, "number_of_timesteps": 3004433, "per_episode_reward": -163.87, "episode_reward_trend_value": 0.018548681660781264, "biggest_recent_change": 0.2915592537109717},
{"total_number_of_episodes": 17807, "number_of_timesteps": 3010848, "per_episode_reward": -163.68, "episode_reward_trend_value": 0.019114427546184882, "biggest_recent_change": 0.2915592537109717},
{"total_number_of_episodes": 17817, "number_of_timesteps": 3017059, "per_episode_reward": -163.6, "episode_reward_trend_value": 0.017959065904038438, "biggest_recent_change": 0.2915592537109717},
{"total_number_of_episodes": 17827, "number_of_timesteps": 3023509, "per_episode_reward": -163.0, "episode_reward_trend_value": 0.022834008954102262, "biggest_recent_change": 0.6017674242708324},
{"total_number_of_episodes": 17837, "number_of_timesteps": 3030345, "per_episode_reward": -162.73, "episode_reward_trend_value": 0.02271503756770383, "biggest_recent_change": 0.6017674242708324},
{"total_number_of_episodes": 17847, "number_of_timesteps": 3036377, "per_episode_reward": -162.65, "episode_reward_trend_value": 0.020384941557227244, "biggest_recent_change": 0.6017674242708324},
{"total_number_of_episodes": 17857, "number_of_timesteps": 3042654, "per_episode_reward": -162.47, "episode_reward_trend_value": 0.019422569251374158, "biggest_recent_change": 0.6017674242708324},
{"total_number_of_episodes": 17868, "number_of_timesteps": 3049807, "per_episode_reward": -162.35, "episode_reward_trend_value": 0.018948531912582212, "biggest_recent_change": 0.6017674242708324},

{"total_number_of_episodes": 17878, "number_of_timesteps": 3057709, "per_episode_reward": -162.15, "episode_reward_trend_value": 0.019561851991250025, "biggest_recent_change": 0.6017674242708324},
{"total_number_of_episodes": 17888, "number_of_timesteps": 3064377, "per_episode_reward": -161.76, "episode_reward_trend_value": 0.023418343587080257, "biggest_recent_change": 0.6017674242708324},
{"total_number_of_episodes": 17899, "number_of_timesteps": 3068691, "per_episode_reward": -161.62, "episode_reward_trend_value": 0.022982332205062208, "biggest_recent_change": 0.6017674242708324},
{"total_number_of_episodes": 17909, "number_of_timesteps": 3073100, "per_episode_reward": -161.56, "episode_reward_trend_value": 0.0226632680037808, "biggest_recent_change": 0.6017674242708324},
{"total_number_of_episodes": 17919, "number_of_timesteps": 3077726, "per_episode_reward": -161.49, "episode_reward_trend_value": 0.016852812777617666, "biggest_recent_change": 0.3923299174354895},
{"total_number_of_episodes": 17929, "number_of_timesteps": 3081987, "per_episode_reward": -161.23, "episode_reward_trend_value": 0.016637594937886194, "biggest_recent_change": 0.3923299174354895},
{"total_number_of_episodes": 17939, "number_of_timesteps": 3088339, "per_episode_reward": -161.09, "episode_reward_trend_value": 0.017380988863066844, "biggest_recent_change": 0.3923299174354895},
{"total_number_of_episodes": 17949, "number_of_timesteps": 3095060, "per_episode_reward": -160.84, "episode_reward_trend_value": 0.01812093701407491, "biggest_recent_change": 0.3923299174354895},
{"total_number_of_episodes": 17959, "number_of_timesteps": 3101800, "per_episode_reward": -160.51, "episode_reward_trend_value": 0.020511632069804542, "biggest_recent_change": 0.3923299174354895},
{"total_number_of_episodes": 17969, "number_of_timesteps": 3108383, "per_episode_reward": -160.39, "episode_reward_trend_value": 0.019555001804441634, "biggest_recent_change": 0.3923299174354895},
{"total_number_of_episodes": 17979, "number_of_timesteps": 3116782, "per_episode_reward": -160.1, "episode_reward_trend_value": 0.018420370574805313, "biggest_recent_change": 0.3366983719442942},
{"total_number_of_episodes": 17989, "number_of_timesteps": 3121963, "per_episode_reward": -159.97, "episode_reward_trend_value": 0.018260423256944276, "biggest_recent_change": 0.3366983719442942},
{"total_number_of_episodes": 17999, "number_of_timesteps": 3127941, "per_episode_reward": -159.74, "episode_reward_trend_value": 0.020247435612326902, "biggest_recent_change": 0.3366983719442942},
{"total_number_of_episodes": 18009, "number_of_timesteps": 3131677, "per_episode_reward": -159.62, "episode_reward_trend_value": 0.02075865485201468, "biggest_recent_change": 0.3366983719442942},
{"total_number_of_episodes": 18019, "number_of_timesteps": 3137757, "per_episode_reward": -159.31, "episode_reward_trend_value": 0.021366248493538048, "biggest_recent_change": 0.3366983719442942},
{"total_number_of_episodes": 18029, "number_of_timesteps": 3144255, "per_episode_reward": -159.2, "episode_reward_trend_value": 0.020966434090580795, "biggest_recent_change": 0.3366983719442942},
{"total_number_of_episodes": 18040, "number_of_timesteps": 3150928, "per_episode_reward": -158.96, "episode_reward_trend_value": 0.020885790935228795, "biggest_recent_change": 0.3366983719442942},
{"total_number_of_episodes": 18050, "number_of_timesteps": 3155943, "per_episode_reward": -158.88, "episode_reward_trend_value": 0.01810842075195246, "biggest_recent_change": 0.3058233277812974},
{"total_number_of_episodes": 18060, "number_of_timesteps": 3160904, "per_episode_reward": -158.71, "episode_reward_trend_value": 0.01876331162015706, "biggest_recent_change": 0.3058233277812974},
{"total_number_of_episodes": 18071, "number_of_timesteps": 3165439, "per_episode_reward": -158.46, "episode_reward_trend_value": 0.018288653392156424, "biggest_recent_change": 0.3058233277812974},
{"total_number_of_episodes": 18081, "number_of_timesteps": 3169680, "per_episode_reward": -158.23, "episode_reward_trend_value": 0.019401493035975804, "biggest_recent_change": 0.3058233277812974},
{"total_number_of_episodes": 18091, "number_of_timesteps": 3173540, "per_episode_reward": -158.13, "episode_reward_trend_value": 0.01786916856664978, "biggest_recent_change": 0.3058233277812974},
{"total_number_of_episodes": 18101, "number_of_timesteps": 3179142, "per_episode_reward": -157.59, "episode_reward_trend_value": 0.022548234311532963, "biggest_recent_change": 0.5459521025275365},
{"total_number_of_episodes": 18111, "number_of_timesteps": 3186049, "per_episode_reward": -157.5, "episode_reward_trend_value": 0.02006860283572425, "biggest_recent_change": 0.5459521025275365},
{"total_number_of_episodes": 18121, "number_of_timesteps": 3192717, "per_episode_reward": -157.04, "episode_reward_trend_value": 0.02400700066112683, "biggest_recent_change": 0.5459521025275365},
{"total_number_of_episodes": 18131, "number_of_timesteps": 3200435, "per_episode_reward": -156.93, "episode_reward_trend_value": 0.02256313812826281, "biggest_recent_change": 0.5459521025275365},
{"total_number_of_episodes": 18141, "number_of_timesteps": 3205444, "per_episode_reward": -156.71, "episode_reward_trend_value": 0.024074558529499905, "biggest_recent_change": 0.5459521025275365},
{"total_number_of_episodes": 18151, "number_of_timesteps": 3210437, "per_episode_reward": -156.53, "episode_reward_trend_value": 0.024174258121707086, "biggest_recent_change": 0.5459521025275365},
{"total_number_of_episodes": 18161, "number_of_timesteps": 3213763, "per_episode_reward": -156.37, "episode_reward_trend_value": 0.02316453928805705, "biggest_recent_change": 0.5459521025275365},
{"total_number_of_episodes": 18171, "number_of_timesteps": 3215313, "per_episode_reward": -156.28, "episode_reward_trend_value": 0.021669308103852182, "biggest_recent_change": 0.5459521025275365},
{"total_number_of_episodes": 18181, "number_of_timesteps": 3219774, "per_episode_reward": -156.11, "episode_reward_trend_value": 0.022525234487602575, "biggest_recent_change": 0.5459521025275365},
{"total_number_of_episodes": 18191, "number_of_timesteps": 3225177, "per_episode_reward": -155.84, "episode_reward_trend_value": 0.019439395249858334, "biggest_recent_change": 0.46722857405441687},
{"total_number_of_episodes": 18201, "number_of_timesteps": 3232102, "per_episode_reward": -155.66, "episode_reward_trend_value": 0.020481439131047965, "biggest_recent_change": 0.46722857405441687},
{"total_number_of_episodes": 18211, "number_of_timesteps": 3239670, "per_episode_reward": -155.51, "episode_reward_trend_value": 0.016982303883393494, "biggest_recent_change": 0.2682265711305547},
{"total_number_of_episodes": 18221, "number_of_timesteps": 3245119, "per_episode_reward": -155.18, "episode_reward_trend_value": 0.01952819529886085, "biggest_recent_change": 0.33345886605994224},
{"total_number_of_episodes": 18231, "number_of_timesteps": 3250729, "per_episode_reward": -155.05, "episode_reward_trend_value": 0.018433804853781842, "biggest_recent_change": 0.33345886605994224},
{"total_number_of_episodes": 18241, "number_of_timesteps": 3256688, "per_episode_reward": -154.91, "episode_reward_trend_value": 0.01801005675999679, "biggest_recent_change": 0.33345886605994224},
{"total_number_of_episodes": 18252, "number_of_timesteps": 3264924, "per_episode_reward": -154.73, "episode_reward_trend_value": 0.018286777367586004, "biggest_recent_change": 0.33345886605994224},
{"total_number_of_episodes": 18262, "number_of_timesteps": 3270357, "per_episode_reward": -154.63, "episode_reward_trend_value": 0.018274433226308576, "biggest_recent_change": 0.33345886605994224},
{"total_number_of_episodes": 18272, "number_of_timesteps": 3277638, "per_episode_reward": -154.35, "episode_reward_trend_value": 0.01948660832089565, "biggest_recent_change": 0.33345886605994224},
{"total_number_of_episodes": 18282, "number_of_timesteps": 3283834, "per_episode_reward": -154.06, "episode_reward_trend_value": 0.019728350652227455, "biggest_recent_change": 0.33345886605994224},
{"total_number_of_episodes": 18292, "number_of_timesteps": 3290731, "per_episode_reward": -153.8, "episode_reward_trend_value": 0.02072294212891153, "biggest_recent_change": 0.33345886605994224},
{"total_number_of_episodes": 18302, "number_of_timesteps": 3299979, "per_episode_reward": -153.45, "episode_reward_trend_value": 0.02292450670833672, "biggest_recent_change": 0.35044721391378175},
{"total_number_of_episodes": 18312, "number_of_timesteps": 3305119, "per_episode_reward": -153.12, "episode_reward_trend_value": 0.02280256489187309, "biggest_recent_change": 0.35044721391378175},
{"total_number_of_episodes": 18322, "number_of_timesteps": 3310710, "per_episode_reward": -152.92, "episode_reward_trend_value": 0.023628574892866697, "biggest_recent_change": 0.35044721391378175},
{"total_number_of_episodes": 18333, "number_of_timesteps": 3317323, "per_episode_reward": -152.73, "episode_reward_trend_value": 0.02422025801149851, "biggest_recent_change": 0.35044721391378175},
{"total_number_of_episodes": 18343, "number_of_timesteps": 3323625, "per_episode_reward": -152.48, "episode_reward_trend_value": 0.024942026962392876, "biggest_recent_change": 0.35044721391378175},
{"total_number_of_episodes": 18353, "number_of_timesteps": 3331530, "per_episode_reward": -152.11, "episode_reward_trend_value": 0.028030231248282196, "biggest_recent_change": 0.37501345979842426},
{"total_number_of_episodes": 18363, "number_of_timesteps": 3338562, "per_episode_reward": -151.96, "episode_reward_trend_value": 0.026527804605111605, "biggest_recent_change": 0.37501345979842426},
{"total_number_of_episodes": 18373, "number_of_timesteps": 3344458, "per_episode_reward": -151.81, "episode_reward_trend_value": 0.025081374722734674, "biggest_recent_change": 0.37501345979842426},
{"total_number_of_episodes": 18383, "number_of_timesteps": 3351921, "per_episode_reward": -151.61, "episode_reward_trend_value": 0.0242835778805348, "biggest_recent_change": 0.37501345979842426},
{"total_number_of_episodes": 18393, "number_of_timesteps": 3358425, "per_episode_reward": -151.35, "episode_reward_trend_value": 0.023282323186759234, "biggest_recent_change": 0.37501345979842426},
{"total_number_of_episodes": 18403, "number_of_timesteps": 3364524, "per_episode_reward": -151.18, "episode_reward_trend_value": 0.02155140189252115, "biggest_recent_change": 0.37501345979842426},
{"total_number_of_episodes": 18413, "number_of_timesteps": 3372303, "per_episode_reward": -151.1, "episode_reward_trend_value": 0.02030096440596007, "biggest_recent_change": 0.37501345979842426},
{"total_number_of_episodes": 18424, "number_of_timesteps": 3377665, "per_episode_reward": -150.91, "episode_reward_trend_value": 0.020251983381532078, "biggest_recent_change": 0.37501345979842426},
{"total_number_of_episodes": 18434, "number_of_timesteps": 3383449, "per_episode_reward": -150.75, "episode_reward_trend_value": 0.01923789812698418, "biggest_recent_change": 0.37501345979842426},
{"total_number_of_episodes": 18444, "number_of_timesteps": 3388135, "per_episode_reward": -150.63, "episode_reward_trend_value": 0.01644002821996019, "biggest_recent_change": 0.26033429147398124},
{"total_number_of_episodes": 18454, "number_of_timesteps": 3393555, "per_episode_reward": -150.54, "episode_reward_trend_value": 0.01584795550383357, "biggest_recent_change": 0.26033429147398124},
{"total_number_of_episodes": 18464, "number_of_timesteps": 3400039, "per_episode_reward": -150.38, "episode_reward_trend_value": 0.01580641972998775, "biggest_recent_change": 0.26033429147398124},
{"total_number_of_episodes": 18474, "number_of_timesteps": 3404855, "per_episode_reward": -150.3, "episode_reward_trend_value": 0.014517059703545165, "biggest_recent_change": 0.26033429147398124},
{"total_number_of_episodes": 18484, "number_of_timesteps": 3410890, "per_episode_reward": -149.88, "episode_reward_trend_value": 0.016387587159322457, "biggest_recent_change": 0.4286817624939374},
{"total_number_of_episodes": 18494, "number_of_timesteps": 3419678, "per_episode_reward": -149.8, "episode_reward_trend_value": 0.015410706011437961, "biggest_recent_change": 0.4286817624939374},
{"total_number_of_episodes": 18504, "number_of_timesteps": 3426872, "per_episode_reward": -149.73, "episode_reward_trend_value": 0.015199358233068162, "biggest_recent_change": 0.4286817624939374},
{"total_number_of_episodes": 18514, "number_of_timesteps": 3432516, "per_episode_reward": -149.42, "episode_reward_trend_value": 0.016531134661551997, "biggest_recent_change": 0.4286817624939374},
{"total_number_of_episodes": 18524, "number_of_timesteps": 3436716, "per_episode_reward": -149.3, "episode_reward_trend_value": 0.016087407164937735, "biggest_recent_change": 0.4286817624939374},
{"total_number_of_episodes": 18534, "number_of_timesteps": 3443897, "per_episode_reward": -149.17, "episode_reward_trend_value": 0.01623588765852888, "biggest_recent_change": 0.4286817624939374},
{"total_number_of_episodes": 18544, "number_of_timesteps": 3450855, "per_episode_reward": -148.91, "episode_reward_trend_value": 0.018150682982817697, "biggest_recent_change": 0.4286817624939374},
{"total_number_of_episodes": 18555, "number_of_timesteps": 3458961, "per_episode_reward": -148.75, "episode_reward_trend_value": 0.018151505124241237, "biggest_recent_change": 0.4286817624939374},
{"total_number_of_episodes": 18565, "number_of_timesteps": 3464809, "per_episode_reward": -148.48, "episode_reward_trend_value": 0.020236794115153126, "biggest_recent_change": 0.4286817624939374},
{"total_number_of_episodes": 18575, "number_of_timesteps": 3471134, "per_episode_reward": -148.36, "episode_reward_trend_value": 0.016802101841686738, "biggest_recent_change": 0.3108920984812471},
{"total_number_of_episodes": 18585, "number_of_timesteps": 3479008, "per_episode_reward": -148.23, "episode_reward_trend_value": 0.017384264297609142, "biggest_recent_change": 0.3108920984812471},
{"total_number_of_episodes": 18595, "number_of_timesteps": 3485929, "per_episode_reward": -147.92, "episode_reward_trend_value": 0.02012175822899533, "biggest_recent_change": 0.3134224315740539},
{"total_number_of_episodes": 18605, "number_of_timesteps": 3492696, "per_episode_reward": -147.79, "episode_reward_trend_value": 0.018125367657540893, "biggest_recent_change": 0.3134224315740539},
{"total_number_of_episodes": 18615, "number_of_timesteps": 3499820, "per_episode_reward": -147.67, "episode_reward_trend_value": 0.018161289887264172, "biggest_recent_change": 0.3134224315740539},
{"total_number_of_episodes": 18625, "number_of_timesteps": 3504078, "per_episode_reward": -147.58, "episode_reward_trend_value": 0.017676200988368702, "biggest_recent_change": 0.3134224315740539},
{"total_number_of_episodes": 18635, "number_of_timesteps": 3509525, "per_episode_reward": -147.47, "episode_reward_trend_value": 0.015969941216333914, "biggest_recent_change": 0.3134224315740539},
{"total_number_of_episodes": 18645, "number_of_timesteps": 3514417, "per_episode_reward": -147.2, "episode_reward_trend_value": 0.01718298791862954, "biggest_recent_change": 0.3134224315740539},
{"total_number_of_episodes": 18655, "number_of_timesteps": 3520940, "per_episode_reward": -147.09, "episode_reward_trend_value": 0.015438459330840398, "biggest_recent_change": 0.3134224315740539},
{"total_number_of_episodes": 18665, "number_of_timesteps": 3525677, "per_episode_reward": -146.78, "episode_reward_trend_value": 0.017633783785324417, "biggest_recent_change": 0.31713865878552383},
{"total_number_of_episodes": 18675, "number_of_timesteps": 3529628, "per_episode_reward": -146.58, "episode_reward_trend_value": 0.018413612890374985, "biggest_recent_change": 0.31713865878552383},
{"total_number_of_episodes": 18685, "number_of_timesteps": 3534612, "per_episode_reward": -146.33, "episode_reward_trend_value": 0.017683838299168052, "biggest_recent_change": 0.31713865878552383},
{"total_number_of_episodes": 18695, "number_of_timesteps": 3540714, "per_episode_reward": -146.09, "episode_reward_trend_value": 0.018914851070733284, "biggest_recent_change": 0.31713865878552383},
{"total_number_of_episodes": 18705, "number_of_timesteps": 3546207, "per_episode_reward": -145.93, "episode_reward_trend_value": 0.019322522366992227, "biggest_recent_change": 0.31713865878552383},
{"total_number_of_episodes": 18715, "number_of_timesteps": 3552599, "per_episode_reward": -145.81, "episode_reward_trend_value": 0.019597717832327374, "biggest_recent_change": 0.31713865878552383},
{"total_number_of_episodes": 18725, "number_of_timesteps": 3555910, "per_episode_reward": -145.72, "episode_reward_trend_value": 0.01936748654734054, "biggest_recent_change": 0.31713865878552383},
{"total_number_of_episodes": 18735, "number_of_timesteps": 3561175, "per_episode_reward": -145.63, "episode_reward_trend_value": 0.017429237733273657, "biggest_recent_change": 0.31713865878552383},
{"total_number_of_episodes": 18745, "number_of_timesteps": 3567936, "per_episode_reward": -145.45, "episode_reward_trend_value": 0.018312869166540065, "biggest_recent_change": 0.31713865878552383},
{"total_number_of_episodes": 18755, "number_of_timesteps": 3573590, "per_episode_reward": -145.32, "episode_reward_trend_value": 0.016182575985961182, "biggest_recent_change": 0.24774271836542994},
{"total_number_of_episodes": 18765, "number_of_timesteps": 3579774, "per_episode_reward": -145.17, "episode_reward_trend_value": 0.015640249777807945, "biggest_recent_change": 0.24774271836542994},
{"total_number_of_episodes": 18775, "number_of_timesteps": 3584731, "per_episode_reward": -144.94, "episode_reward_trend_value": 0.015384509170251526, "biggest_recent_change": 0.2420080964912188},
{"total_number_of_episodes": 18786, "number_of_timesteps": 3592926, "per_episode_reward": -144.87, "episode_reward_trend_value": 0.013558635071095181, "biggest_recent_change": 0.22472606368535253},
{"total_number_of_episodes": 18796, "number_of_timesteps": 3601428, "per_episode_reward": -144.73, "episode_reward_trend_value": 0.013303787164599613, "biggest_recent_change": 0.22472606368535253},
{"total_number_of_episodes": 18806, "number_of_timesteps": 3607375, "per_episode_reward": -144.53, "episode_reward_trend_value": 0.01420986577968727, "biggest_recent_change": 0.22472606368535253},
{"total_number_of_episodes": 18816, "number_of_timesteps": 3613005, "per_episode_reward": -144.47, "episode_reward_trend_value": 0.01388960156671525, "biggest_recent_change": 0.22472606368535253},
{"total_number_of_episodes": 18826, "number_of_timesteps": 3620160, "per_episode_reward": -144.37, "episode_reward_trend_value": 0.014042245601295158, "biggest_recent_change": 0.22472606368535253},
{"total_number_of_episodes": 18836, "number_of_timesteps": 3625654, "per_episode_reward": -144.24, "episode_reward_trend_value": 0.01341933291554243, "biggest_recent_change": 0.22472606368535253},
{"total_number_of_episodes": 18846, "number_of_timesteps": 3632065, "per_episode_reward": -144.17, "episode_reward_trend_value": 0.012796292739055401, "biggest_recent_change": 0.22472606368535253},
{"total_number_of_episodes": 18856, "number_of_timesteps": 3638063, "per_episode_reward": -143.66, "episode_reward_trend_value": 0.01678059603806522, "biggest_recent_change": 0.5111390614518427},
{"total_number_of_episodes": 18866, "number_of_timesteps": 3644506, "per_episode_reward": -143.41, "episode_reward_trend_value": 0.017008897565082746, "biggest_recent_change": 0.5111390614518427},
{"total_number_of_episodes": 18876, "number_of_timesteps": 3649514, "per_episode_reward": -143.22, "episode_reward_trend_value": 0.018314048669947486, "biggest_recent_change": 0.5111390614518427},
{"total_number_of_episodes": 18887, "number_of_timesteps": 3654559, "per_episode_reward": -143.0, "episode_reward_trend_value": 0.019218305917927912, "biggest_recent_change": 0.5111390614518427},
{"total_number_of_episodes": 18897, "number_of_timesteps": 3659480, "per_episode_reward": -142.89, "episode_reward_trend_value": 0.01822145057541636, "biggest_recent_change": 0.5111390614518427},
{"total_number_of_episodes": 18907, "number_of_timesteps": 3665638, "per_episode_reward": -142.78, "episode_reward_trend_value": 0.018807975138985474, "biggest_recent_change": 0.5111390614518427},
{"total_number_of_episodes": 18917, "number_of_timesteps": 3672409, "per_episode_reward": -142.69, "episode_reward_trend_value": 0.018716715383219038, "biggest_recent_change": 0.5111390614518427},
{"total_number_of_episodes": 18927, "number_of_timesteps": 3677212, "per_episode_reward": -142.39, "episode_reward_trend_value": 0.020584676905219604, "biggest_recent_change": 0.5111390614518427},
{"total_number_of_episodes": 18937, "number_of_timesteps": 3681045, "per_episode_reward": -142.15, "episode_reward_trend_value": 0.022449572903440185, "biggest_recent_change": 0.5111390614518427},
{"total_number_of_episodes": 18947, "number_of_timesteps": 3687914, "per_episode_reward": -141.97, "episode_reward_trend_value": 0.018732195624785834, "biggest_recent_change": 0.3003592195266549},
{"total_number_of_episodes": 18957, "number_of_timesteps": 3695322, "per_episode_reward": -141.74, "episode_reward_trend_value": 0.01854928675485894, "biggest_recent_change": 0.3003592195266549},
{"total_number_of_episodes": 18967, "number_of_timesteps": 3699636, "per_episode_reward": -141.51, "episode_reward_trend_value": 0.018912777094144278, "biggest_recent_change": 0.3003592195266549},
{"total_number_of_episodes": 18977, "number_of_timesteps": 3707343, "per_episode_reward": -141.33, "episode_reward_trend_value": 0.018567733320491518, "biggest_recent_change": 0.3003592195266549},
{"total_number_of_episodes": 18987, "number_of_timesteps": 3712477, "per_episode_reward": -141.27, "episode_reward_trend_value": 0.01801545265318446, "biggest_recent_change": 0.3003592195266549},
{"total_number_of_episodes": 18997, "number_of_timesteps": 3719055, "per_episode_reward": -140.82, "episode_reward_trend_value": 0.021745863984341123, "biggest_recent_change": 0.4475494758200682},
{"total_number_of_episodes": 19007, "number_of_timesteps": 3723229, "per_episode_reward": -140.72, "episode_reward_trend_value": 0.02182718757452228, "biggest_recent_change": 0.4475494758200682},
{"total_number_of_episodes": 19017, "number_of_timesteps": 3729963, "per_episode_reward": -140.5, "episode_reward_trend_value": 0.020977696013744662, "biggest_recent_change": 0.4475494758200682},
{"total_number_of_episodes": 19027, "number_of_timesteps": 3736814, "per_episode_reward": -140.32, "episode_reward_trend_value": 0.02031956251781158, "biggest_recent_change": 0.4475494758200682},
{"total_number_of_episodes": 19037, "number_of_timesteps": 3745237, "per_episode_reward": -139.98, "episode_reward_trend_value": 0.022145643083554965, "biggest_recent_change": 0.4475494758200682},
{"total_number_of_episodes": 19047, "number_of_timesteps": 3753775, "per_episode_reward": -139.89, "episode_reward_trend_value": 0.020565442160621693, "biggest_recent_change": 0.4475494758200682},
{"total_number_of_episodes": 19057, "number_of_timesteps": 3758177, "per_episode_reward": -139.58, "episode_reward_trend_value": 0.021452835519426117, "biggest_recent_change": 0.4475494758200682},
{"total_number_of_episodes": 19067, "number_of_timesteps": 3762548, "per_episode_reward": -139.56, "episode_reward_trend_value": 0.019732570281660047, "biggest_recent_change": 0.4475494758200682},
{"total_number_of_episodes": 19077, "number_of_timesteps": 3768562, "per_episode_reward": -139.13, "episode_reward_trend_value": 0.023799391735883864, "biggest_recent_change": 0.4475494758200682},
{"total_number_of_episodes": 19087, "number_of_timesteps": 3772990, "per_episode_reward": -138.78, "episode_reward_trend_value": 0.02268317153603555, "biggest_recent_change": 0.42581676892339715},
{"total_number_of_episodes": 19097, "number_of_timesteps": 3777300, "per_episode_reward": -138.65, "episode_reward_trend_value": 0.022997066485450864, "biggest_recent_change": 0.42581676892339715},
{"total_number_of_episodes": 19107, "number_of_timesteps": 3781835, "per_episode_reward": -138.53, "episode_reward_trend_value": 0.021860292083562806, "biggest_recent_change": 0.42581676892339715},
{"total_number_of_episodes": 19117, "number_of_timesteps": 3789139, "per_episode_reward": -138.23, "episode_reward_trend_value": 0.02321485472702641, "biggest_recent_change": 0.42581676892339715},
{"total_number_of_episodes": 19127, "number_of_timesteps": 3795382, "per_episode_reward": -137.94, "episode_reward_trend_value": 0.02266350293036194, "biggest_recent_change": 0.42581676892339715},
{"total_number_of_episodes": 19137, "number_of_timesteps": 3802282, "per_episode_reward": -137.75, "episode_reward_trend_value": 0.02384698210809846, "biggest_recent_change": 0.42581676892339715},
{"total_number_of_episodes": 19147, "number_of_timesteps": 3808269, "per_episode_reward": -137.6, "episode_reward_trend_value": 0.022042607258023216, "biggest_recent_change": 0.42581676892339715},
{"total_number_of_episodes": 19157, "number_of_timesteps": 3813622, "per_episode_reward": -137.48, "episode_reward_trend_value": 0.02310181593049726, "biggest_recent_change": 0.42581676892339715},
{"total_number_of_episodes": 19167, "number_of_timesteps": 3820470, "per_episode_reward": -137.34, "episode_reward_trend_value": 0.019927930520302718, "biggest_recent_change": 0.34708965783372037},
{"total_number_of_episodes": 19177, "number_of_timesteps": 3828263, "per_episode_reward": -137.09, "episode_reward_trend_value": 0.018845079980518323, "biggest_recent_change": 0.29985791976719156},
{"total_number_of_episodes": 19187, "number_of_timesteps": 3834642, "per_episode_reward": -136.81, "episode_reward_trend_value": 0.020479851847060596, "biggest_recent_change": 0.29985791976719156},
{"total_number_of_episodes": 19197, "number_of_timesteps": 3841089, "per_episode_reward": -136.73, "episode_reward_trend_value": 0.019982878694300942, "biggest_recent_change": 0.29985791976719156},
{"total_number_of_episodes": 19207, "number_of_timesteps": 3846753, "per_episode_reward": -136.54, "episode_reward_trend_value": 0.0187563339641555, "biggest_recent_change": 0.2913006955900528},
{"total_number_of_episodes": 19217, "number_of_timesteps": 3854599, "per_episode_reward": -136.25, "episode_reward_trend_value": 0.01871817119543285, "biggest_recent_change": 0.28786604640501423},
{"total_number_of_episodes": 19227, "number_of_timesteps": 3861436, "per_episode_reward": -136.15, "episode_reward_trend_value": 0.017697987310211577, "biggest_recent_change": 0.28786604640501423},
{"total_number_of_episodes": 19237, "number_of_timesteps": 3865936, "per_episode_reward": -135.99, "episode_reward_trend_value": 0.017932377874808163, "biggest_recent_change": 0.28786604640501423},
{"total_number_of_episodes": 19248, "number_of_timesteps": 3872200, "per_episode_reward": -135.6, "episode_reward_trend_value": 0.020824102778888055, "biggest_recent_change": 0.3833565528127849},
{"total_number_of_episodes": 19258, "number_of_timesteps": 3876014, "per_episode_reward": -135.5, "episode_reward_trend_value": 0.020460935019938613, "biggest_recent_change": 0.3833565528127849},
{"total_number_of_episodes": 19268, "number_of_timesteps": 3880237, "per_episode_reward": -135.29, "episode_reward_trend_value": 0.019991692490459123, "biggest_recent_change": 0.3833565528127849},
{"total_number_of_episodes": 19278, "number_of_timesteps": 3885810, "per_episode_reward": -135.2, "episode_reward_trend_value": 0.01791691192435236, "biggest_recent_change": 0.3833565528127849},
{"total_number_of_episodes": 19288, "number_of_timesteps": 3891910, "per_episode_reward": -134.98, "episode_reward_trend_value": 0.019437537301473323, "biggest_recent_change": 0.3833565528127849},
{"total_number_of_episodes": 19298, "number_of_timesteps": 3895795, "per_episode_reward": -134.67, "episode_reward_trend_value": 0.020787894231857094, "biggest_recent_change": 0.3833565528127849},
{"total_number_of_episodes": 19308, "number_of_timesteps": 3902072, "per_episode_reward": -134.55, "episode_reward_trend_value": 0.018891404351456094, "biggest_recent_change": 0.3833565528127849},
{"total_number_of_episodes": 19318, "number_of_timesteps": 3909284, "per_episode_reward": -134.38, "episode_reward_trend_value": 0.019645418819996825, "biggest_recent_change": 0.3833565528127849},
{"total_number_of_episodes": 19328, "number_of_timesteps": 3914913, "per_episode_reward": -134.18, "episode_reward_trend_value": 0.02004650033999806, "biggest_recent_change": 0.3833565528127849},
{"total_number_of_episodes": 19338, "number_of_timesteps": 3919692, "per_episode_reward": -134.1, "episode_reward_trend_value": 0.016690865599802703, "biggest_recent_change": 0.31100101778864087},
{"total_number_of_episodes": 19348, "number_of_timesteps": 3925347, "per_episode_reward": -133.88, "episode_reward_trend_value": 0.017971133009451832, "biggest_recent_change": 0.31100101778864087},
{"total_number_of_episodes": 19358, "number_of_timesteps": 3932253, "per_episode_reward": -133.74, "episode_reward_trend_value": 0.017207282659452657, "biggest_recent_change": 0.31100101778864087},
{"total_number_of_episodes": 19368, "number_of_timesteps": 3938714, "per_episode_reward": -133.68, "episode_reward_trend_value": 0.016801656483251135, "biggest_recent_change": 0.31100101778864087},
{"total_number_of_episodes": 19378, "number_of_timesteps": 3945239, "per_episode_reward": -133.5, "episode_reward_trend_value": 0.016482720263552943, "biggest_recent_change": 0.31100101778864087},
{"total_number_of_episodes": 19388, "number_of_timesteps": 3951945, "per_episode_reward": -133.01, "episode_reward_trend_value": 0.01848739081775332, "biggest_recent_change": 0.49142136766667477},
{"total_number_of_episodes": 19398, "number_of_timesteps": 3957117, "per_episode_reward": -132.97, "episode_reward_trend_value": 0.017590851098838005, "biggest_recent_change": 0.49142136766667477},
{"total_number_of_episodes": 19408, "number_of_timesteps": 3964342, "per_episode_reward": -132.8, "episode_reward_trend_value": 0.017597641107795426, "biggest_recent_change": 0.49142136766667477},
{"total_number_of_episodes": 19420, "number_of_timesteps": 3974075, "per_episode_reward": -132.52, "episode_reward_trend_value": 0.018510729384808793, "biggest_recent_change": 0.49142136766667477},
{"total_number_of_episodes": 19431, "number_of_timesteps": 3981258, "per_episode_reward": -132.38, "episode_reward_trend_value": 0.019172301234821828, "biggest_recent_change": 0.49142136766667477},
{"total_number_of_episodes": 19441, "number_of_timesteps": 3986479, "per_episode_reward": -132.18, "episode_reward_trend_value": 0.018867684277722042, "biggest_recent_change": 0.49142136766667477},
{"total_number_of_episodes": 19451, "number_of_timesteps": 3994232, "per_episode_reward": -132.11, "episode_reward_trend_value": 0.018111629111207762, "biggest_recent_change": 0.49142136766667477},
{"total_number_of_episodes": 19461, "number_of_timesteps": 4001360, "per_episode_reward": -131.99, "episode_reward_trend_value": 0.0188559041976649, "biggest_recent_change": 0.49142136766667477},
{"total_number_of_episodes": 19471, "number_of_timesteps": 4006518, "per_episode_reward": -131.86, "episode_reward_trend_value": 0.0182370815738769, "biggest_recent_change": 0.49142136766667477},
{"total_number_of_episodes": 19481, "number_of_timesteps": 4012135, "per_episode_reward": -131.62, "episode_reward_trend_value": 0.015368537361167809, "biggest_recent_change": 0.2846992558712884},
{"total_number_of_episodes": 19491, "number_of_timesteps": 4016751, "per_episode_reward": -131.45, "episode_reward_trend_value": 0.016861358858680356, "biggest_recent_change": 0.2846992558712884},
{"total_number_of_episodes": 19501, "number_of_timesteps": 4022606, "per_episode_reward": -131.21, "episode_reward_trend_value": 0.017643574200969347, "biggest_recent_change": 0.2846992558712884},
{"total_number_of_episodes": 19511, "number_of_timesteps": 4029908, "per_episode_reward": -131.06, "episode_reward_trend_value": 0.01623018696809753, "biggest_recent_change": 0.24016167986673054},
{"total_number_of_episodes": 19521, "number_of_timesteps": 4036098, "per_episode_reward": -130.88, "episode_reward_trend_value": 0.016612470217049553, "biggest_recent_change": 0.24016167986673054},
{"total_number_of_episodes": 19531, "number_of_timesteps": 4043041, "per_episode_reward": -130.75, "episode_reward_trend_value": 0.015877144033817736, "biggest_recent_change": 0.24016167986673054},
{"total_number_of_episodes": 19541, "number_of_timesteps": 4049298, "per_episode_reward": -130.63, "episode_reward_trend_value": 0.01640779144696738, "biggest_recent_change": 0.24016167986673054},
{"total_number_of_episodes": 19551, "number_of_timesteps": 4055992, "per_episode_reward": -130.44, "episode_reward_trend_value": 0.017161648952625164, "biggest_recent_change": 0.24016167986673054},
{"total_number_of_episodes": 19561, "number_of_timesteps": 4060621, "per_episode_reward": -130.35, "episode_reward_trend_value": 0.01678794662446579, "biggest_recent_change": 0.24016167986673054},
{"total_number_of_episodes": 19571, "number_of_timesteps": 4065383, "per_episode_reward": -130.25, "episode_reward_trend_value": 0.015249869180635122, "biggest_recent_change": 0.24016167986673054},
{"total_number_of_episodes": 19581, "number_of_timesteps": 4070093, "per_episode_reward": -129.82, "episode_reward_trend_value": 0.018099531030894886, "biggest_recent_change": 0.4273168837660535},
{"total_number_of_episodes": 19591, "number_of_timesteps": 4075427, "per_episode_reward": -129.65, "episode_reward_trend_value": 0.017326351610555298, "biggest_recent_change": 0.4273168837660535},
{"total_number_of_episodes": 19601, "number_of_timesteps": 4081102, "per_episode_reward": -129.25, "episode_reward_trend_value": 0.020027692651168157, "biggest_recent_change": 0.4273168837660535},
{"total_number_of_episodes": 19611, "number_of_timesteps": 4087957, "per_episode_reward": -129.18, "episode_reward_trend_value": 0.018862822678979305, "biggest_recent_change": 0.4273168837660535},
{"total_number_of_episodes": 19621, "number_of_timesteps": 4093063, "per_episode_reward": -129.09, "episode_reward_trend_value": 0.018429598856441014, "biggest_recent_change": 0.4273168837660535},
{"total_number_of_episodes": 19631, "number_of_timesteps": 4099256, "per_episode_reward": -128.94, "episode_reward_trend_value": 0.01879505683693752, "biggest_recent_change": 0.4273168837660535},
{"total_number_of_episodes": 19641, "number_of_timesteps": 4104350, "per_episode_reward": -128.8, "episode_reward_trend_value": 0.018258179555626773, "biggest_recent_change": 0.4273168837660535},
{"total_number_of_episodes": 19651, "number_of_timesteps": 4110591, "per_episode_reward": -128.59, "episode_reward_trend_value": 0.019494169347610876, "biggest_recent_change": 0.4273168837660535},
{"total_number_of_episodes": 19661, "number_of_timesteps": 4120591, "per_episode_reward": -128.51, "episode_reward_trend_value": 0.019387818263916123, "biggest_recent_change": 0.4273168837660535},
{"total_number_of_episodes": 19671, "number_of_timesteps": 4128330, "per_episode_reward": -128.39, "episode_reward_trend_value": 0.015879505629973145, "biggest_recent_change": 0.4006150985679824},
{"total_number_of_episodes": 19681, "number_of_timesteps": 4135233, "per_episode_reward": -128.3, "episode_reward_trend_value": 0.015024777782193471, "biggest_recent_change": 0.4006150985679824},
{"total_number_of_episodes": 19691, "number_of_timesteps": 4140020, "per_episode_reward": -128.07, "episode_reward_trend_value": 0.013167523123442493, "biggest_recent_change": 0.23346217928039437},
{"total_number_of_episodes": 19701, "number_of_timesteps": 4146223, "per_episode_reward": -127.9, "episode_reward_trend_value": 0.014303068759073292, "biggest_recent_change": 0.23346217928039437},
{"total_number_of_episodes": 19711, "number_of_timesteps": 4150666, "per_episode_reward": -127.78, "episode_reward_trend_value": 0.014555842980466435, "biggest_recent_change": 0.23346217928039437},
{"total_number_of_episodes": 19721, "number_of_timesteps": 4157773, "per_episode_reward": -127.63, "episode_reward_trend_value": 0.01457576035599999, "biggest_recent_change": 0.23346217928039437},
{"total_number_of_episodes": 19732, "number_of_timesteps": 4164235, "per_episode_reward": -127.41, "episode_reward_trend_value": 0.015453574570257127, "biggest_recent_change": 0.23346217928039437},
{"total_number_of_episodes": 19742, "number_of_timesteps": 4172196, "per_episode_reward": -127.2, "episode_reward_trend_value": 0.015486568092256903, "biggest_recent_change": 0.23346217928039437},
{"total_number_of_episodes": 19752, "number_of_timesteps": 4178643, "per_episode_reward": -127.03, "episode_reward_trend_value": 0.016408870332069923, "biggest_recent_change": 0.23346217928039437},

{"total_number_of_episodes": 19763, "number_of_timesteps": 4185119, "per_episode_reward": -126.89, "episode_reward_trend_value": 0.01677212087129097, "biggest_recent_change": 0.23346217928039437},
{"total_number_of_episodes": 19773, "number_of_timesteps": 4191772, "per_episode_reward": -126.83, "episode_reward_trend_value": 0.016369372564102806, "biggest_recent_change": 0.23346217928039437},
{"total_number_of_episodes": 19783, "number_of_timesteps": 4198368, "per_episode_reward": -126.71, "episode_reward_trend_value": 0.015057725306178011, "biggest_recent_change": 0.22137564665254672},
{"total_number_of_episodes": 19793, "number_of_timesteps": 4206807, "per_episode_reward": -126.66, "episode_reward_trend_value": 0.013746361736654616, "biggest_recent_change": 0.22137564665254672},
{"total_number_of_episodes": 19804, "number_of_timesteps": 4213828, "per_episode_reward": -126.58, "episode_reward_trend_value": 0.013331858327606166, "biggest_recent_change": 0.22137564665254672},
{"total_number_of_episodes": 19814, "number_of_timesteps": 4219360, "per_episode_reward": -126.37, "episode_reward_trend_value": 0.013974822652058095, "biggest_recent_change": 0.22137564665254672},
{"total_number_of_episodes": 19824, "number_of_timesteps": 4223680, "per_episode_reward": -126.24, "episode_reward_trend_value": 0.012950944544131144, "biggest_recent_change": 0.2109186235406071},
{"total_number_of_episodes": 19834, "number_of_timesteps": 4227318, "per_episode_reward": -126.09, "episode_reward_trend_value": 0.01229099322922909, "biggest_recent_change": 0.2109186235406071},
{"total_number_of_episodes": 19844, "number_of_timesteps": 4232868, "per_episode_reward": -125.9, "episode_reward_trend_value": 0.01252246279446483, "biggest_recent_change": 0.2109186235406071},
{"total_number_of_episodes": 19854, "number_of_timesteps": 4236446, "per_episode_reward": -125.69, "episode_reward_trend_value": 0.013268784600712832, "biggest_recent_change": 0.21143025780339997},
{"total_number_of_episodes": 19864, "number_of_timesteps": 4243370, "per_episode_reward": -125.51, "episode_reward_trend_value": 0.014595157244854797, "biggest_recent_change": 0.21143025780339997},
{"total_number_of_episodes": 19874, "number_of_timesteps": 4249204, "per_episode_reward": -125.31, "episode_reward_trend_value": 0.015598860428066056, "biggest_recent_change": 0.21143025780339997},
{"total_number_of_episodes": 19884, "number_of_timesteps": 4256042, "per_episode_reward": -125.12, "episode_reward_trend_value": 0.01705682670488263, "biggest_recent_change": 0.21143025780339997},
{"total_number_of_episodes": 19896, "number_of_timesteps": 4264059, "per_episode_reward": -124.88, "episode_reward_trend_value": 0.018933895443192718, "biggest_recent_change": 0.2445015834694999},
{"total_number_of_episodes": 19906, "number_of_timesteps": 4269650, "per_episode_reward": -124.38, "episode_reward_trend_value": 0.02211258040998653, "biggest_recent_change": 0.49700027055205},
{"total_number_of_episodes": 19917, "number_of_timesteps": 4275832, "per_episode_reward": -124.15, "episode_reward_trend_value": 0.023217134137676648, "biggest_recent_change": 0.49700027055205},
{"total_number_of_episodes": 19927, "number_of_timesteps": 4279366, "per_episode_reward": -124.05, "episode_reward_trend_value": 0.022712613291479833, "biggest_recent_change": 0.49700027055205},
{"total_number_of_episodes": 19937, "number_of_timesteps": 4284812, "per_episode_reward": -123.99, "episode_reward_trend_value": 0.021241725127267193, "biggest_recent_change": 0.49700027055205},
{"total_number_of_episodes": 19947, "number_of_timesteps": 4289971, "per_episode_reward": -123.89, "episode_reward_trend_value": 0.01996999061958541, "biggest_recent_change": 0.49700027055205},
{"total_number_of_episodes": 19957, "number_of_timesteps": 4295206, "per_episode_reward": -123.73, "episode_reward_trend_value": 0.019794628029828232, "biggest_recent_change": 0.49700027055205},
{"total_number_of_episodes": 19967, "number_of_timesteps": 4300980, "per_episode_reward": -123.55, "episode_reward_trend_value": 0.0195799675904796, "biggest_recent_change": 0.49700027055205},
{"total_number_of_episodes": 19977, "number_of_timesteps": 4305957, "per_episode_reward": -123.4, "episode_reward_trend_value": 0.01917095525484456, "biggest_recent_change": 0.49700027055205},
{"total_number_of_episodes": 19988, "number_of_timesteps": 4312238, "per_episode_reward": -123.22, "episode_reward_trend_value": 0.018428884117087957, "biggest_recent_change": 0.49700027055205},
{"total_number_of_episodes": 19998, "number_of_timesteps": 4315508, "per_episode_reward": -123.12, "episode_reward_trend_value": 0.014043138965737334, "biggest_recent_change": 0.22863645243123187},
{"total_number_of_episodes": 20008, "number_of_timesteps": 4321609, "per_episode_reward": -122.94, "episode_reward_trend_value": 0.013438571755393505, "biggest_recent_change": 0.18642777301479896},
{"total_number_of_episodes": 20018, "number_of_timesteps": 4328067, "per_episode_reward": -122.85, "episode_reward_trend_value": 0.013281612016196853, "biggest_recent_change": 0.18642777301479896},
{"total_number_of_episodes": 20028, "number_of_timesteps": 4334583, "per_episode_reward": -122.64, "episode_reward_trend_value": 0.015035334274297282, "biggest_recent_change": 0.21454835194985833},
{"total_number_of_episodes": 20038, "number_of_timesteps": 4342417, "per_episode_reward": -122.6, "episode_reward_trend_value": 0.0143569377197745, "biggest_recent_change": 0.21454835194985833},
{"total_number_of_episodes": 20048, "number_of_timesteps": 4350134, "per_episode_reward": -122.49, "episode_reward_trend_value": 0.013801518104269583, "biggest_recent_change": 0.21454835194985833},
{"total_number_of_episodes": 20058, "number_of_timesteps": 4356247, "per_episode_reward": -122.38, "episode_reward_trend_value": 0.013006992974408308, "biggest_recent_change": 0.21454835194985833},
{"total_number_of_episodes": 20068, "number_of_timesteps": 4362236, "per_episode_reward": -122.22, "episode_reward_trend_value": 0.013050128117587986, "biggest_recent_change": 0.21454835194985833},
{"total_number_of_episodes": 20078, "number_of_timesteps": 4366577, "per_episode_reward": -122.01, "episode_reward_trend_value": 0.013483095177506736, "biggest_recent_change": 0.21668221646409336},
{"total_number_of_episodes": 20088, "number_of_timesteps": 4372018, "per_episode_reward": -121.94, "episode_reward_trend_value": 0.013099063778960997, "biggest_recent_change": 0.21668221646409336},
{"total_number_of_episodes": 20098, "number_of_timesteps": 4376894, "per_episode_reward": -121.83, "episode_reward_trend_value": 0.012392384836208869, "biggest_recent_change": 0.21668221646409336},
{"total_number_of_episodes": 20108, "number_of_timesteps": 4382810, "per_episode_reward": -121.73, "episode_reward_trend_value": 0.012494202933632754, "biggest_recent_change": 0.21668221646409336},
{"total_number_of_episodes": 20118, "number_of_timesteps": 4388785, "per_episode_reward": -121.66, "episode_reward_trend_value": 0.0108808322840711, "biggest_recent_change": 0.21668221646409336},
{"total_number_of_episodes": 20128, "number_of_timesteps": 4393788, "per_episode_reward": -121.57, "episode_reward_trend_value": 0.011470029035827957, "biggest_recent_change": 0.21668221646409336},
{"total_number_of_episodes": 20138, "number_of_timesteps": 4397363, "per_episode_reward": -121.31, "episode_reward_trend_value": 0.013159120081044287, "biggest_recent_change": 0.2630240116577198},
{"total_number_of_episodes": 20148, "number_of_timesteps": 4400610, "per_episode_reward": -121.13, "episode_reward_trend_value": 0.01384475310142316, "biggest_recent_change": 0.2630240116577198},
{"total_number_of_episodes": 20158, "number_of_timesteps": 4407299, "per_episode_reward": -120.84, "episode_reward_trend_value": 0.015365847501953864, "biggest_recent_change": 0.28982098719500016},
{"total_number_of_episodes": 20168, "number_of_timesteps": 4412373, "per_episode_reward": -120.72, "episode_reward_trend_value": 0.014285634934431357, "biggest_recent_change": 0.28982098719500016},
{"total_number_of_episodes": 20178, "number_of_timesteps": 4419919, "per_episode_reward": -120.27, "episode_reward_trend_value": 0.018584092602769747, "biggest_recent_change": 0.4545815712118326},
{"total_number_of_episodes": 20188, "number_of_timesteps": 4425109, "per_episode_reward": -120.08, "episode_reward_trend_value": 0.019475427493639723, "biggest_recent_change": 0.4545815712118326},
{"total_number_of_episodes": 20199, "number_of_timesteps": 4429086, "per_episode_reward": -119.86, "episode_reward_trend_value": 0.020775439106369552, "biggest_recent_change": 0.4545815712118326},
{"total_number_of_episodes": 20209, "number_of_timesteps": 4433986, "per_episode_reward": -119.76, "episode_reward_trend_value": 0.021125273325148283, "biggest_recent_change": 0.4545815712118326},
{"total_number_of_episodes": 20219, "number_of_timesteps": 4439956, "per_episode_reward": -119.65, "episode_reward_trend_value": 0.02127268133780515, "biggest_recent_change": 0.4545815712118326},
{"total_number_of_episodes": 20229, "number_of_timesteps": 4446486, "per_episode_reward": -119.55, "episode_reward_trend_value": 0.01953607690281921, "biggest_recent_change": 0.4545815712118326},
{"total_number_of_episodes": 20239, "number_of_timesteps": 4452419, "per_episode_reward": -119.29, "episode_reward_trend_value": 0.020389039459628576, "biggest_recent_change": 0.4545815712118326},
{"total_number_of_episodes": 20249, "number_of_timesteps": 4457207, "per_episode_reward": -119.23, "episode_reward_trend_value": 0.017879230419238785, "biggest_recent_change": 0.4545815712118326},
{"total_number_of_episodes": 20259, "number_of_timesteps": 4461862, "per_episode_reward": -119.06, "episode_reward_trend_value": 0.018456649239572995, "biggest_recent_change": 0.4545815712118326},
{"total_number_of_episodes": 20269, "number_of_timesteps": 4467305, "per_episode_reward": -118.89, "episode_reward_trend_value": 0.015276668882369884, "biggest_recent_change": 0.2533941132742257},
{"total_number_of_episodes": 20279, "number_of_timesteps": 4470067, "per_episode_reward": -118.67, "episode_reward_trend_value": 0.015587774428832153, "biggest_recent_change": 0.2533941132742257},
{"total_number_of_episodes": 20289, "number_of_timesteps": 4477438, "per_episode_reward": -118.51, "episode_reward_trend_value": 0.01493893961624069, "biggest_recent_change": 0.2533941132742257},
{"total_number_of_episodes": 20299, "number_of_timesteps": 4482449, "per_episode_reward": -118.31, "episode_reward_trend_value": 0.01604982915690619, "biggest_recent_change": 0.2533941132742257},
{"total_number_of_episodes": 20309, "number_of_timesteps": 4486441, "per_episode_reward": -118.11, "episode_reward_trend_value": 0.01720872690138072, "biggest_recent_change": 0.2533941132742257},
{"total_number_of_episodes": 20319, "number_of_timesteps": 4491469, "per_episode_reward": -117.81, "episode_reward_trend_value": 0.019276091700453593, "biggest_recent_change": 0.29279244442554386},
{"total_number_of_episodes": 20329, "number_of_timesteps": 4494575, "per_episode_reward": -117.69, "episode_reward_trend_value": 0.01788432910895984, "biggest_recent_change": 0.29279244442554386},
{"total_number_of_episodes": 20339, "number_of_timesteps": 4497302, "per_episode_reward": -117.43, "episode_reward_trend_value": 0.020051381527930325, "biggest_recent_change": 0.29279244442554386},
{"total_number_of_episodes": 20350, "number_of_timesteps": 4500804, "per_episode_reward": -117.24, "episode_reward_trend_value": 0.020227768983529397, "biggest_recent_change": 0.29279244442554386},
{"total_number_of_episodes": 20360, "number_of_timesteps": 4504330, "per_episode_reward": -117.18, "episode_reward_trend_value": 0.019050848857383094, "biggest_recent_change": 0.29279244442554386},
{"total_number_of_episodes": 20370, "number_of_timesteps": 4509583, "per_episode_reward": -117.01, "episode_reward_trend_value": 0.018414981635046797, "biggest_recent_change": 0.29279244442554386},
{"total_number_of_episodes": 20380, "number_of_timesteps": 4513653, "per_episode_reward": -116.79, "episode_reward_trend_value": 0.019123689283049965, "biggest_recent_change": 0.29279244442554386},
{"total_number_of_episodes": 20390, "number_of_timesteps": 4519522, "per_episode_reward": -116.64, "episode_reward_trend_value": 0.018552418253076373, "biggest_recent_change": 0.29279244442554386},
{"total_number_of_episodes": 20400, "number_of_timesteps": 4526322, "per_episode_reward": -116.54, "episode_reward_trend_value": 0.017381097561780086, "biggest_recent_change": 0.29279244442554386},
{"total_number_of_episodes": 20410, "number_of_timesteps": 4532162, "per_episode_reward": -116.32, "episode_reward_trend_value": 0.01654592209676464, "biggest_recent_change": 0.25897289126726264},
{"total_number_of_episodes": 20420, "number_of_timesteps": 4537609, "per_episode_reward": -116.24, "episode_reward_trend_value": 0.01600262778624805, "biggest_recent_change": 0.25897289126726264},
{"total_number_of_episodes": 20430, "number_of_timesteps": 4542838, "per_episode_reward": -116.1, "episode_reward_trend_value": 0.014769433211188242, "biggest_recent_change": 0.22252533396400054},
{"total_number_of_episodes": 20441, "number_of_timesteps": 4546684, "per_episode_reward": -115.96, "episode_reward_trend_value": 0.014188909705552375, "biggest_recent_change": 0.22252533396400054},
{"total_number_of_episodes": 20451, "number_of_timesteps": 4549755, "per_episode_reward": -115.83, "episode_reward_trend_value": 0.014993047678534151, "biggest_recent_change": 0.22252533396400054},
{"total_number_of_episodes": 20461, "number_of_timesteps": 4552421, "per_episode_reward": -115.79, "episode_reward_trend_value": 0.013661928248507454, "biggest_recent_change": 0.22252533396400054},
{"total_number_of_episodes": 20471, "number_of_timesteps": 4555573, "per_episode_reward": -115.59, "episode_reward_trend_value": 0.013413309745256818, "biggest_recent_change": 0.21762665257415392},
{"total_number_of_episodes": 20481, "number_of_timesteps": 4558386, "per_episode_reward": -115.33, "episode_reward_trend_value": 0.014602291817474602, "biggest_recent_change": 0.2564041256412679},
{"total_number_of_episodes": 20491, "number_of_timesteps": 4563453, "per_episode_reward": -115.21, "episode_reward_trend_value": 0.014824248299910104, "biggest_recent_change": 0.2564041256412679},
{"total_number_of_episodes": 20501, "number_of_timesteps": 4567603, "per_episode_reward": -114.89, "episode_reward_trend_value": 0.015900105342905924, "biggest_recent_change": 0.31445378644377797},
{"total_number_of_episodes": 20511, "number_of_timesteps": 4572248, "per_episode_reward": -114.75, "episode_reward_trend_value": 0.016599370143310446, "biggest_recent_change": 0.31445378644377797},
{"total_number_of_episodes": 20521, "number_of_timesteps": 4578368, "per_episode_reward": -114.62, "episode_reward_trend_value": 0.016458010693686416, "biggest_recent_change": 0.31445378644377797},
{"total_number_of_episodes": 20531, "number_of_timesteps": 4581894, "per_episode_reward": -114.41, "episode_reward_trend_value": 0.017248600969967574, "biggest_recent_change": 0.31445378644377797},
{"total_number_of_episodes": 20541, "number_of_timesteps": 4586113, "per_episode_reward": -114.26, "episode_reward_trend_value": 0.017415736144494078, "biggest_recent_change": 0.31445378644377797},
{"total_number_of_episodes": 20551, "number_of_timesteps": 4589525, "per_episode_reward": -113.89, "episode_reward_trend_value": 0.02102356210461917, "biggest_recent_change": 0.3665194757110868},
{"total_number_of_episodes": 20561, "number_of_timesteps": 4593706, "per_episode_reward": -113.79, "episode_reward_trend_value": 0.019992018370447007, "biggest_recent_change": 0.3665194757110868},
{"total_number_of_episodes": 20571, "number_of_timesteps": 4597859, "per_episode_reward": -113.64, "episode_reward_trend_value": 0.01879143268153582, "biggest_recent_change": 0.3665194757110868},
{"total_number_of_episodes": 20581, "number_of_timesteps": 4601354, "per_episode_reward": -113.5, "episode_reward_trend_value": 0.018932585394417365, "biggest_recent_change": 0.3665194757110868},
{"total_number_of_episodes": 20591, "number_of_timesteps": 4604737, "per_episode_reward": -113.4, "episode_reward_trend_value": 0.016538693475354034, "biggest_recent_change": 0.3665194757110868},
{"total_number_of_episodes": 20601, "number_of_timesteps": 4611290, "per_episode_reward": -113.23, "episode_reward_trend_value": 0.016928170570619412, "biggest_recent_change": 0.3665194757110868},
{"total_number_of_episodes": 20611, "number_of_timesteps": 4616561, "per_episode_reward": -113.04, "episode_reward_trend_value": 0.01754649597971694, "biggest_recent_change": 0.3665194757110868},
{"total_number_of_episodes": 20621, "number_of_timesteps": 4618534, "per_episode_reward": -112.77, "episode_reward_trend_value": 0.018185429351598892, "biggest_recent_change": 0.3665194757110868},
{"total_number_of_episodes": 20631, "number_of_timesteps": 4621866, "per_episode_reward": -112.67, "episode_reward_trend_value": 0.01762715475524127, "biggest_recent_change": 0.3665194757110868},
{"total_number_of_episodes": 20641, "number_of_timesteps": 4628991, "per_episode_reward": -112.61, "episode_reward_trend_value": 0.014245599387159618, "biggest_recent_change": 0.2637156630485151},
{"total_number_of_episodes": 20651, "number_of_timesteps": 4634032, "per_episode_reward": -112.49, "episode_reward_trend_value": 0.014359342614896933, "biggest_recent_change": 0.2637156630485151},
{"total_number_of_episodes": 20661, "number_of_timesteps": 4636407, "per_episode_reward": -112.39, "episode_reward_trend_value": 0.01386146494981754, "biggest_recent_change": 0.2637156630485151},
{"total_number_of_episodes": 20671, "number_of_timesteps": 4639931, "per_episode_reward": -112.14, "episode_reward_trend_value": 0.015120841859705714, "biggest_recent_change": 0.2637156630485151},
{"total_number_of_episodes": 20681, "number_of_timesteps": 4645000, "per_episode_reward": -111.68, "episode_reward_trend_value": 0.01916265900681427, "biggest_recent_change": 0.4627670569678486},
{"total_number_of_episodes": 20691, "number_of_timesteps": 4648257, "per_episode_reward": -111.43, "episode_reward_trend_value": 0.01998224979707809, "biggest_recent_change": 0.4627670569678486},
{"total_number_of_episodes": 20701, "number_of_timesteps": 4652200, "per_episode_reward": -111.31, "episode_reward_trend_value": 0.019230235523011015, "biggest_recent_change": 0.4627670569678486},
{"total_number_of_episodes": 20711, "number_of_timesteps": 4658737, "per_episode_reward": -111.1, "episode_reward_trend_value": 0.018575802731599034, "biggest_recent_change": 0.4627670569678486},
{"total_number_of_episodes": 20721, "number_of_timesteps": 4663677, "per_episode_reward": -110.95, "episode_reward_trend_value": 0.019173459805590515, "biggest_recent_change": 0.4627670569678486},
{"total_number_of_episodes": 20731, "number_of_timesteps": 4668530, "per_episode_reward": -110.65, "episode_reward_trend_value": 0.021844484305458108, "biggest_recent_change": 0.4627670569678486},
{"total_number_of_episodes": 20741, "number_of_timesteps": 4673402, "per_episode_reward": -110.53, "episode_reward_trend_value": 0.02183483137936911, "biggest_recent_change": 0.4627670569678486},
{"total_number_of_episodes": 20752, "number_of_timesteps": 4678045, "per_episode_reward": -110.27, "episode_reward_trend_value": 0.0236063584615034, "biggest_recent_change": 0.4627670569678486},
{"total_number_of_episodes": 20762, "number_of_timesteps": 4682924, "per_episode_reward": -110.08, "episode_reward_trend_value": 0.022919873491513146, "biggest_recent_change": 0.4627670569678486},
{"total_number_of_episodes": 20772, "number_of_timesteps": 4686945, "per_episode_reward": -110.02, "episode_reward_trend_value": 0.01847004150978917, "biggest_recent_change": 0.3025716975718211},
{"total_number_of_episodes": 20782, "number_of_timesteps": 4692888, "per_episode_reward": -109.9, "episode_reward_trend_value": 0.01696594430540854, "biggest_recent_change": 0.3025716975718211},
{"total_number_of_episodes": 20792, "number_of_timesteps": 4698610, "per_episode_reward": -109.8, "episode_reward_trend_value": 0.016758043545477285, "biggest_recent_change": 0.3025716975718211},
{"total_number_of_episodes": 20802, "number_of_timesteps": 4704448, "per_episode_reward": -109.7, "episode_reward_trend_value": 0.015559804739594401, "biggest_recent_change": 0.3025716975718211},
{"total_number_of_episodes": 20812, "number_of_timesteps": 4707640, "per_episode_reward": -109.52, "episode_reward_trend_value": 0.015843941132960046, "biggest_recent_change": 0.3025716975718211},
{"total_number_of_episodes": 20822, "number_of_timesteps": 4710802, "per_episode_reward": -109.45, "episode_reward_trend_value": 0.013315210053414083, "biggest_recent_change": 0.2629798611742018},
{"total_number_of_episodes": 20833, "number_of_timesteps": 4716079, "per_episode_reward": -109.33, "episode_reward_trend_value": 0.01336499394878356, "biggest_recent_change": 0.2629798611742018},
{"total_number_of_episodes": 20843, "number_of_timesteps": 4721026, "per_episode_reward": -109.19, "episode_reward_trend_value": 0.011943964827419506, "biggest_recent_change": 0.1853349279576122},
{"total_number_of_episodes": 20853, "number_of_timesteps": 4724771, "per_episode_reward": -109.09, "episode_reward_trend_value": 0.01102644433399986, "biggest_recent_change": 0.17899180937608605},
{"total_number_of_episodes": 20863, "number_of_timesteps": 4726522, "per_episode_reward": -108.95, "episode_reward_trend_value": 0.011827832240060194, "biggest_recent_change": 0.17899180937608605},
{"total_number_of_episodes": 20873, "number_of_timesteps": 4729902, "per_episode_reward": -108.73, "episode_reward_trend_value": 0.013013556793771386, "biggest_recent_change": 0.22233539526708057},
{"total_number_of_episodes": 20883, "number_of_timesteps": 4732206, "per_episode_reward": -108.57, "episode_reward_trend_value": 0.013668436425675484, "biggest_recent_change": 0.22233539526708057},
{"total_number_of_episodes": 20893, "number_of_timesteps": 4734834, "per_episode_reward": -108.44, "episode_reward_trend_value": 0.014057886119351003, "biggest_recent_change": 0.22233539526708057},
{"total_number_of_episodes": 20903, "number_of_timesteps": 4737117, "per_episode_reward": -108.29, "episode_reward_trend_value": 0.01367530797430542, "biggest_recent_change": 0.22233539526708057},
{"total_number_of_episodes": 20913, "number_of_timesteps": 4741198, "per_episode_reward": -108.24, "episode_reward_trend_value": 0.013427898320759527, "biggest_recent_change": 0.22233539526708057},
{"total_number_of_episodes": 20923, "number_of_timesteps": 4747620, "per_episode_reward": -108.14, "episode_reward_trend_value": 0.013192963213528388, "biggest_recent_change": 0.22233539526708057},
{"total_number_of_episodes": 20933, "number_of_timesteps": 4753296, "per_episode_reward": -108.03, "episode_reward_trend_value": 0.012946955966236986, "biggest_recent_change": 0.22233539526708057},
{"total_number_of_episodes": 20943, "number_of_timesteps": 4757288, "per_episode_reward": -107.66, "episode_reward_trend_value": 0.015858153993291702, "biggest_recent_change": 0.3647659059847683},
{"total_number_of_episodes": 20953, "number_of_timesteps": 4759705, "per_episode_reward": -107.64, "episode_reward_trend_value": 0.014597917798752904, "biggest_recent_change": 0.3647659059847683},
{"total_number_of_episodes": 20965, "number_of_timesteps": 4762372, "per_episode_reward": -107.57, "episode_reward_trend_value": 0.012925969103864076, "biggest_recent_change": 0.3647659059847683},
{"total_number_of_episodes": 20975, "number_of_timesteps": 4765673, "per_episode_reward": -107.48, "episode_reward_trend_value": 0.012042159207529816, "biggest_recent_change": 0.3647659059847683},
{"total_number_of_episodes": 20985, "number_of_timesteps": 4770476, "per_episode_reward": -107.38, "episode_reward_trend_value": 0.011757150848545608, "biggest_recent_change": 0.3647659059847683},
{"total_number_of_episodes": 20995, "number_of_timesteps": 4775550, "per_episode_reward": -107.22, "episode_reward_trend_value": 0.011844946185759871, "biggest_recent_change": 0.3647659059847683},
{"total_number_of_episodes": 21005, "number_of_timesteps": 4777922, "per_episode_reward": -107.1, "episode_reward_trend_value": 0.01261583186646852, "biggest_recent_change": 0.3647659059847683},
{"total_number_of_episodes": 21015, "number_of_timesteps": 4780189, "per_episode_reward": -107.02, "episode_reward_trend_value": 0.012463136463939862, "biggest_recent_change": 0.3647659059847683},
{"total_number_of_episodes": 21025, "number_of_timesteps": 4782689, "per_episode_reward": -106.81, "episode_reward_trend_value": 0.013491911199940254, "biggest_recent_change": 0.3647659059847683},
{"total_number_of_episodes": 21035, "number_of_timesteps": 4785335, "per_episode_reward": -106.61, "episode_reward_trend_value": 0.011642263700392322, "biggest_recent_change": 0.2055363142352462},
{"total_number_of_episodes": 21045, "number_of_timesteps": 4788694, "per_episode_reward": -106.49, "episode_reward_trend_value": 0.012759130120187163, "biggest_recent_change": 0.2055363142352462},
{"total_number_of_episodes": 21055, "number_of_timesteps": 4793699, "per_episode_reward": -106.4, "episode_reward_trend_value": 0.013011477295928683, "biggest_recent_change": 0.2055363142352462},
{"total_number_of_episodes": 21065, "number_of_timesteps": 4799590, "per_episode_reward": -106.21, "episode_reward_trend_value": 0.014127987143597111, "biggest_recent_change": 0.2055363142352462},
{"total_number_of_episodes": 21075, "number_of_timesteps": 4803790, "per_episode_reward": -106.11, "episode_reward_trend_value": 0.014090126801170933, "biggest_recent_change": 0.2055363142352462},
{"total_number_of_episodes": 21085, "number_of_timesteps": 4810667, "per_episode_reward": -105.85, "episode_reward_trend_value": 0.015248996323819439, "biggest_recent_change": 0.25675961370963307},
{"total_number_of_episodes": 21095, "number_of_timesteps": 4815200, "per_episode_reward": -105.78, "episode_reward_trend_value": 0.014664618741433818, "biggest_recent_change": 0.25675961370963307},
{"total_number_of_episodes": 21106, "number_of_timesteps": 4821218, "per_episode_reward": -105.7, "episode_reward_trend_value": 0.014617647182132664, "biggest_recent_change": 0.25675961370963307},
{"total_number_of_episodes": 21116, "number_of_timesteps": 4825490, "per_episode_reward": -105.51, "episode_reward_trend_value": 0.014480808191080996, "biggest_recent_change": 0.25675961370963307},
{"total_number_of_episodes": 21126, "number_of_timesteps": 4829897, "per_episode_reward": -105.4, "episode_reward_trend_value": 0.013450418382303691, "biggest_recent_change": 0.25675961370963307},
{"total_number_of_episodes": 21136, "number_of_timesteps": 4832383, "per_episode_reward": -105.29, "episode_reward_trend_value": 0.013365420033929987, "biggest_recent_change": 0.25675961370963307},
{"total_number_of_episodes": 21146, "number_of_timesteps": 4835695, "per_episode_reward": -105.2, "episode_reward_trend_value": 0.013343488983468571, "biggest_recent_change": 0.25675961370963307},
{"total_number_of_episodes": 21156, "number_of_timesteps": 4842209, "per_episode_reward": -105.1, "episode_reward_trend_value": 0.012324884702680252, "biggest_recent_change": 0.25675961370963307},
{"total_number_of_episodes": 21166, "number_of_timesteps": 4848249, "per_episode_reward": -105.05, "episode_reward_trend_value": 0.011789464006543288, "biggest_recent_change": 0.25675961370963307},
{"total_number_of_episodes": 21176, "number_of_timesteps": 4854899, "per_episode_reward": -104.95, "episode_reward_trend_value": 0.00999651011805835, "biggest_recent_change": 0.19322080504059613},
{"total_number_of_episodes": 21186, "number_of_timesteps": 4857855, "per_episode_reward": -104.86, "episode_reward_trend_value": 0.010199390222992596, "biggest_recent_change": 0.19322080504059613},
{"total_number_of_episodes": 21196, "number_of_timesteps": 4862422, "per_episode_reward": -104.72, "episode_reward_trend_value": 0.010946041495069714, "biggest_recent_change": 0.19322080504059613},
{"total_number_of_episodes": 21206, "number_of_timesteps": 4869622, "per_episode_reward": -104.69, "episode_reward_trend_value": 0.009058118792746466, "biggest_recent_change": 0.14924383859900558},
{"total_number_of_episodes": 21216, "number_of_timesteps": 4873012, "per_episode_reward": -104.63, "episode_reward_trend_value": 0.008523952701874766, "biggest_recent_change": 0.14924383859900558},
{"total_number_of_episodes": 21226, "number_of_timesteps": 4877453, "per_episode_reward": -104.57, "episode_reward_trend_value": 0.007928910392518812, "biggest_recent_change": 0.14924383859900558},
{"total_number_of_episodes": 21236, "number_of_timesteps": 4883221, "per_episode_reward": -104.53, "episode_reward_trend_value": 0.0074282291455547685, "biggest_recent_change": 0.14924383859900558},
{"total_number_of_episodes": 21246, "number_of_timesteps": 4888332, "per_episode_reward": -104.4, "episode_reward_trend_value": 0.007828082610021487, "biggest_recent_change": 0.14924383859900558},
{"total_number_of_episodes": 21256, "number_of_timesteps": 4894084, "per_episode_reward": -104.34, "episode_reward_trend_value": 0.007908389269569226, "biggest_recent_change": 0.14924383859900558},
{"total_number_of_episodes": 21266, "number_of_timesteps": 4900316, "per_episode_reward": -104.23, "episode_reward_trend_value": 0.008052731964219441, "biggest_recent_change": 0.14924383859900558},
{"total_number_of_episodes": 21276, "number_of_timesteps": 4905184, "per_episode_reward": -104.12, "episode_reward_trend_value": 0.008284288024940798, "biggest_recent_change": 0.14924383859900558},
{"total_number_of_episodes": 21286, "number_of_timesteps": 4911066, "per_episode_reward": -104.01, "episode_reward_trend_value": 0.007882404511459936, "biggest_recent_change": 0.12871455182714442},
{"total_number_of_episodes": 21297, "number_of_timesteps": 4917490, "per_episode_reward": -103.96, "episode_reward_trend_value": 0.008101583110180855, "biggest_recent_change": 0.12871455182714442},
{"total_number_of_episodes": 21308, "number_of_timesteps": 4922029, "per_episode_reward": -103.8, "episode_reward_trend_value": 0.00927140341443362, "biggest_recent_change": 0.16277142743979311},
{"total_number_of_episodes": 21318, "number_of_timesteps": 4925666, "per_episode_reward": -103.63, "episode_reward_trend_value": 0.01052560924291094, "biggest_recent_change": 0.1731786757984537},
{"total_number_of_episodes": 21328, "number_of_timesteps": 4929315, "per_episode_reward": -103.23, "episode_reward_trend_value": 0.01436713061096842, "biggest_recent_change": 0.39327307490070496},
{"total_number_of_episodes": 21338, "number_of_timesteps": 4933327, "per_episode_reward": -103.13, "episode_reward_trend_value": 0.014128670542555552, "biggest_recent_change": 0.39327307490070496},
{"total_number_of_episodes": 21348, "number_of_timesteps": 4937770, "per_episode_reward": -102.97, "episode_reward_trend_value": 0.015206082617834068, "biggest_recent_change": 0.39327307490070496},
{"total_number_of_episodes": 21358, "number_of_timesteps": 4943854, "per_episode_reward": -102.86, "episode_reward_trend_value": 0.015168197340499668, "biggest_recent_change": 0.39327307490070496},
{"total_number_of_episodes": 21368, "number_of_timesteps": 4949216, "per_episode_reward": -102.76, "episode_reward_trend_value": 0.015152219046773358, "biggest_recent_change": 0.39327307490070496},
{"total_number_of_episodes": 21378, "number_of_timesteps": 4953319, "per_episode_reward": -102.65, "episode_reward_trend_value": 0.015122752453639204, "biggest_recent_change": 0.39327307490070496},
{"total_number_of_episodes": 21388, "number_of_timesteps": 4959562, "per_episode_reward": -102.58, "episode_reward_trend_value": 0.015424249267301742, "biggest_recent_change": 0.39327307490070496},
{"total_number_of_episodes": 21398, "number_of_timesteps": 4964063, "per_episode_reward": -102.51, "episode_reward_trend_value": 0.014337179293577012, "biggest_recent_change": 0.39327307490070496},
{"total_number_of_episodes": 21408, "number_of_timesteps": 4971508, "per_episode_reward": -102.4, "episode_reward_trend_value": 0.013634399594051494, "biggest_recent_change": 0.39327307490070496},
{"total_number_of_episodes": 21418, "number_of_timesteps": 4975666, "per_episode_reward": -102.36, "episode_reward_trend_value": 0.009747685111133502, "biggest_recent_change": 0.15897433207787515},
{"total_number_of_episodes": 21429, "number_of_timesteps": 4980063, "per_episode_reward": -102.18, "episode_reward_trend_value": 0.010481918780013979, "biggest_recent_change": 0.17333417586922906},

{"total_number_of_episodes": 21439, "number_of_timesteps": 4984916, "per_episode_reward": -101.79, "episode_reward_trend_value": 0.013054266006895748, "biggest_recent_change": 0.3904855824972344},
{"total_number_of_episodes": 21449, "number_of_timesteps": 4993442, "per_episode_reward": -101.58, "episode_reward_trend_value": 0.014207108849735858, "biggest_recent_change": 0.3904855824972344},
{"total_number_of_episodes": 21459, "number_of_timesteps": 4999278, "per_episode_reward": -101.21, "episode_reward_trend_value": 0.017192502957168974, "biggest_recent_change": 0.3904855824972344},
{"total_number_of_episodes": 21469, "number_of_timesteps": 5005442, "per_episode_reward": -101.11, "episode_reward_trend_value": 0.017059145378119606, "biggest_recent_change": 0.3904855824972344},
{"total_number_of_episodes": 21479, "number_of_timesteps": 5011566, "per_episode_reward": -100.91, "episode_reward_trend_value": 0.01854345284250406, "biggest_recent_change": 0.3904855824972344},
{"total_number_of_episodes": 21489, "number_of_timesteps": 5015730, "per_episode_reward": -100.81, "episode_reward_trend_value": 0.01884579744343379, "biggest_recent_change": 0.3904855824972344},
{"total_number_of_episodes": 21499, "number_of_timesteps": 5018053, "per_episode_reward": -100.67, "episode_reward_trend_value": 0.019252513137898893, "biggest_recent_change": 0.3904855824972344},
{"total_number_of_episodes": 21509, "number_of_timesteps": 5025539, "per_episode_reward": -100.58, "episode_reward_trend_value": 0.01972914661244813, "biggest_recent_change": 0.3904855824972344},
{"total_number_of_episodes": 21519, "number_of_timesteps": 5030726, "per_episode_reward": -100.47, "episode_reward_trend_value": 0.019019109451663022, "biggest_recent_change": 0.3904855824972344},
{"total_number_of_episodes": 21529, "number_of_timesteps": 5035311, "per_episode_reward": -100.17, "episode_reward_trend_value": 0.018073575683930677, "biggest_recent_change": 0.3758514385852436},
{"total_number_of_episodes": 21539, "number_of_timesteps": 5042357, "per_episode_reward": -100.07, "episode_reward_trend_value": 0.016845279134190604, "biggest_recent_change": 0.3758514385852436},
{"total_number_of_episodes": 21549, "number_of_timesteps": 5047791, "per_episode_reward": -99.9, "episode_reward_trend_value": 0.014590225894218, "biggest_recent_change": 0.30538754340132357},
{"total_number_of_episodes": 21559, "number_of_timesteps": 5053826, "per_episode_reward": -99.85, "episode_reward_trend_value": 0.014049425009029903, "biggest_recent_change": 0.30538754340132357},
{"total_number_of_episodes": 21569, "number_of_timesteps": 5059364, "per_episode_reward": -99.63, "episode_reward_trend_value": 0.0141571261592871, "biggest_recent_change": 0.30538754340132357},
{"total_number_of_episodes": 21579, "number_of_timesteps": 5064391, "per_episode_reward": -99.59, "episode_reward_trend_value": 0.013623611377154057, "biggest_recent_change": 0.30538754340132357},
{"total_number_of_episodes": 21589, "number_of_timesteps": 5070199, "per_episode_reward": -99.38, "episode_reward_trend_value": 0.014287756492642245, "biggest_recent_change": 0.30538754340132357},
{"total_number_of_episodes": 21599, "number_of_timesteps": 5076522, "per_episode_reward": -99.25, "episode_reward_trend_value": 0.014777571919533727, "biggest_recent_change": 0.30538754340132357},
{"total_number_of_episodes": 21609, "number_of_timesteps": 5081116, "per_episode_reward": -99.11, "episode_reward_trend_value": 0.015105077457371075, "biggest_recent_change": 0.30538754340132357},
{"total_number_of_episodes": 21619, "number_of_timesteps": 5085035, "per_episode_reward": -99.0, "episode_reward_trend_value": 0.012955978673464586, "biggest_recent_change": 0.21344932426376317},
{"total_number_of_episodes": 21629, "number_of_timesteps": 5091136, "per_episode_reward": -98.87, "episode_reward_trend_value": 0.01327616871273768, "biggest_recent_change": 0.21344932426376317},
{"total_number_of_episodes": 21639, "number_of_timesteps": 5093255, "per_episode_reward": -98.65, "episode_reward_trend_value": 0.013841845643840302, "biggest_recent_change": 0.22380757078694558},
{"total_number_of_episodes": 21649, "number_of_timesteps": 5096575, "per_episode_reward": -98.58, "episode_reward_trend_value": 0.014062958912387399, "biggest_recent_change": 0.22380757078694558},
{"total_number_of_episodes": 21659, "number_of_timesteps": 5100691, "per_episode_reward": -98.44, "episode_reward_trend_value": 0.013208811851696112, "biggest_recent_change": 0.22380757078694558},
{"total_number_of_episodes": 21669, "number_of_timesteps": 5103246, "per_episode_reward": -98.13, "episode_reward_trend_value": 0.016148025428289574, "biggest_recent_change": 0.308659035389681},
{"total_number_of_episodes": 21680, "number_of_timesteps": 5105870, "per_episode_reward": -97.98, "episode_reward_trend_value": 0.015605341568492134, "biggest_recent_change": 0.308659035389681},
{"total_number_of_episodes": 21690, "number_of_timesteps": 5109523, "per_episode_reward": -97.89, "episode_reward_trend_value": 0.015141219788755697, "biggest_recent_change": 0.308659035389681},
{"total_number_of_episodes": 21700, "number_of_timesteps": 5113075, "per_episode_reward": -97.84, "episode_reward_trend_value": 0.01412993950648895, "biggest_recent_change": 0.308659035389681},
{"total_number_of_episodes": 21710, "number_of_timesteps": 5117173, "per_episode_reward": -97.7, "episode_reward_trend_value": 0.014394273479322806, "biggest_recent_change": 0.308659035389681},
{"total_number_of_episodes": 21721, "number_of_timesteps": 5118748, "per_episode_reward": -97.43, "episode_reward_trend_value": 0.015985246658908638, "biggest_recent_change": 0.308659035389681},
{"total_number_of_episodes": 21731, "number_of_timesteps": 5121968, "per_episode_reward": -97.38, "episode_reward_trend_value": 0.014067765545635463, "biggest_recent_change": 0.308659035389681},
{"total_number_of_episodes": 21741, "number_of_timesteps": 5124399, "per_episode_reward": -97.2, "episode_reward_trend_value": 0.01532371020785806, "biggest_recent_change": 0.308659035389681},
{"total_number_of_episodes": 21751, "number_of_timesteps": 5126194, "per_episode_reward": -97.09, "episode_reward_trend_value": 0.015053644546898365, "biggest_recent_change": 0.308659035389681},
{"total_number_of_episodes": 21761, "number_of_timesteps": 5129587, "per_episode_reward": -97.01, "episode_reward_trend_value": 0.012524758590373608, "biggest_recent_change": 0.27018878738071805},
{"total_number_of_episodes": 21771, "number_of_timesteps": 5135544, "per_episode_reward": -96.76, "episode_reward_trend_value": 0.01351454751884328, "biggest_recent_change": 0.27018878738071805},
{"total_number_of_episodes": 21781, "number_of_timesteps": 5139864, "per_episode_reward": -96.6, "episode_reward_trend_value": 0.014325378635882024, "biggest_recent_change": 0.27018878738071805},
{"total_number_of_episodes": 21791, "number_of_timesteps": 5144044, "per_episode_reward": -96.5, "episode_reward_trend_value": 0.014946518949304752, "biggest_recent_change": 0.27018878738071805},
{"total_number_of_episodes": 21801, "number_of_timesteps": 5147210, "per_episode_reward": -96.36, "episode_reward_trend_value": 0.014914393966356621, "biggest_recent_change": 0.27018878738071805},
{"total_number_of_episodes": 21811, "number_of_timesteps": 5151391, "per_episode_reward": -96.25, "episode_reward_trend_value": 0.01318632572342627, "biggest_recent_change": 0.24654543191745404},
{"total_number_of_episodes": 21821, "number_of_timesteps": 5153877, "per_episode_reward": -96.18, "episode_reward_trend_value": 0.013417393533995575, "biggest_recent_change": 0.24654543191745404},
{"total_number_of_episodes": 21832, "number_of_timesteps": 5157448, "per_episode_reward": -96.1, "episode_reward_trend_value": 0.012280999233590408, "biggest_recent_change": 0.24654543191745404},
{"total_number_of_episodes": 21842, "number_of_timesteps": 5162344, "per_episode_reward": -96.03, "episode_reward_trend_value": 0.011804472788278354, "biggest_recent_change": 0.24654543191745404},
{"total_number_of_episodes": 21852, "number_of_timesteps": 5167253, "per_episode_reward": -95.66, "episode_reward_trend_value": 0.01499530643280467, "biggest_recent_change": 0.3682343273098212},
{"total_number_of_episodes": 21862, "number_of_timesteps": 5170988, "per_episode_reward": -95.6, "episode_reward_trend_value": 0.01289682803216989, "biggest_recent_change": 0.3682343273098212},
{"total_number_of_episodes": 21872, "number_of_timesteps": 5175145, "per_episode_reward": -95.49, "episode_reward_trend_value": 0.012292012104880238, "biggest_recent_change": 0.3682343273098212},
{"total_number_of_episodes": 21883, "number_of_timesteps": 5178450, "per_episode_reward": -95.38, "episode_reward_trend_value": 0.012372236569952122, "biggest_recent_change": 0.3682343273098212},
{"total_number_of_episodes": 21894, "number_of_timesteps": 5180119, "per_episode_reward": -95.28, "episode_reward_trend_value": 0.011995056738022767, "biggest_recent_change": 0.3682343273098212},
{"total_number_of_episodes": 21904, "number_of_timesteps": 5183366, "per_episode_reward": -95.2, "episode_reward_trend_value": 0.011663027585540123, "biggest_recent_change": 0.3682343273098212},
{"total_number_of_episodes": 21914, "number_of_timesteps": 5184839, "per_episode_reward": -95.15, "episode_reward_trend_value": 0.011438366090985773, "biggest_recent_change": 0.3682343273098212},
{"total_number_of_episodes": 21924, "number_of_timesteps": 5186093, "per_episode_reward": -95.06, "episode_reward_trend_value": 0.011516069868737589, "biggest_recent_change": 0.3682343273098212},
{"total_number_of_episodes": 21935, "number_of_timesteps": 5187591, "per_episode_reward": -94.93, "episode_reward_trend_value": 0.012183924578948317, "biggest_recent_change": 0.3682343273098212},

{"total_number_of_episodes": 21945, "number_of_timesteps": 5189435, "per_episode_reward": -94.79, "episode_reward_trend_value": 0.009652087293581088, "biggest_recent_change": 0.14036897162677064},
{"total_number_of_episodes": 21956, "number_of_timesteps": 5191052, "per_episode_reward": -94.64, "episode_reward_trend_value": 0.010648571133742261, "biggest_recent_change": 0.14736592147482952},
{"total_number_of_episodes": 21966, "number_of_timesteps": 5193363, "per_episode_reward": -94.58, "episode_reward_trend_value": 0.010117576611974578, "biggest_recent_change": 0.14736592147482952},
{"total_number_of_episodes": 21976, "number_of_timesteps": 5195034, "per_episode_reward": -94.49, "episode_reward_trend_value": 0.00991262206128438, "biggest_recent_change": 0.14736592147482952},
{"total_number_of_episodes": 21986, "number_of_timesteps": 5197437, "per_episode_reward": -94.4, "episode_reward_trend_value": 0.009863186605469487, "biggest_recent_change": 0.14736592147482952},
{"total_number_of_episodes": 21997, "number_of_timesteps": 5201049, "per_episode_reward": -94.38, "episode_reward_trend_value": 0.00911256343498334, "biggest_recent_change": 0.14736592147482952},
{"total_number_of_episodes": 22007, "number_of_timesteps": 5203309, "per_episode_reward": -94.32, "episode_reward_trend_value": 0.009216647237414577, "biggest_recent_change": 0.14736592147482952},
{"total_number_of_episodes": 22017, "number_of_timesteps": 5207436, "per_episode_reward": -94.22, "episode_reward_trend_value": 0.009292451308588707, "biggest_recent_change": 0.14736592147482952},
{"total_number_of_episodes": 22027, "number_of_timesteps": 5209643, "per_episode_reward": -94.13, "episode_reward_trend_value": 0.008914269464528956, "biggest_recent_change": 0.14736592147482952},
{"total_number_of_episodes": 22037, "number_of_timesteps": 5210935, "per_episode_reward": -94.07, "episode_reward_trend_value": 0.008020867830448392, "biggest_recent_change": 0.14736592147482952},
{"total_number_of_episodes": 22048, "number_of_timesteps": 5212394, "per_episode_reward": -93.97, "episode_reward_trend_value": 0.007439030931039131, "biggest_recent_change": 0.09545335719067793},
{"total_number_of_episodes": 22058, "number_of_timesteps": 5213869, "per_episode_reward": -93.83, "episode_reward_trend_value": 0.008396438052043702, "biggest_recent_change": 0.1455967134002094},
{"total_number_of_episodes": 22068, "number_of_timesteps": 5216212, "per_episode_reward": -93.73, "episode_reward_trend_value": 0.00845179017679069, "biggest_recent_change": 0.1455967134002094},
{"total_number_of_episodes": 22079, "number_of_timesteps": 5219216, "per_episode_reward": -93.53, "episode_reward_trend_value": 0.009633813657861385, "biggest_recent_change": 0.20085419933883486},
{"total_number_of_episodes": 22089, "number_of_timesteps": 5220941, "per_episode_reward": -93.48, "episode_reward_trend_value": 0.009953729196433869, "biggest_recent_change": 0.20085419933883486},
{"total_number_of_episodes": 22099, "number_of_timesteps": 5226760, "per_episode_reward": -93.44, "episode_reward_trend_value": 0.009723792889013162, "biggest_recent_change": 0.20085419933883486},
{"total_number_of_episodes": 22109, "number_of_timesteps": 5229419, "per_episode_reward": -93.37, "episode_reward_trend_value": 0.009420251971414946, "biggest_recent_change": 0.20085419933883486},
{"total_number_of_episodes": 22119, "number_of_timesteps": 5235225, "per_episode_reward": -93.29, "episode_reward_trend_value": 0.009343691620685806, "biggest_recent_change": 0.20085419933883486},
{"total_number_of_episodes": 22131, "number_of_timesteps": 5240174, "per_episode_reward": -93.12, "episode_reward_trend_value": 0.010521766102258488, "biggest_recent_change": 0.20085419933883486},
{"total_number_of_episodes": 22141, "number_of_timesteps": 5242361, "per_episode_reward": -93.1, "episode_reward_trend_value": 0.00967187709194756, "biggest_recent_change": 0.20085419933883486},
{"total_number_of_episodes": 22152, "number_of_timesteps": 5247651, "per_episode_reward": -93.09, "episode_reward_trend_value": 0.008211708881532805, "biggest_recent_change": 0.20085419933883486},
{"total_number_of_episodes": 22162, "number_of_timesteps": 5250440, "per_episode_reward": -93.01, "episode_reward_trend_value": 0.007978042536780253, "biggest_recent_change": 0.20085419933883486},
{"total_number_of_episodes": 22172, "number_of_timesteps": 5253191, "per_episode_reward": -92.99, "episode_reward_trend_value": 0.006025969112906813, "biggest_recent_change": 0.16598952790106125},
{"total_number_of_episodes": 22182, "number_of_timesteps": 5257088, "per_episode_reward": -92.88, "episode_reward_trend_value": 0.006727047626903332, "biggest_recent_change": 0.16598952790106125},
{"total_number_of_episodes": 22192, "number_of_timesteps": 5260619, "per_episode_reward": -92.77, "episode_reward_trend_value": 0.007464394371218772, "biggest_recent_change": 0.16598952790106125},
{"total_number_of_episodes": 22202, "number_of_timesteps": 5263762, "per_episode_reward": -92.71, "episode_reward_trend_value": 0.007372310845287997, "biggest_recent_change": 0.16598952790106125},
{"total_number_of_episodes": 22213, "number_of_timesteps": 5267024, "per_episode_reward": -92.66, "episode_reward_trend_value": 0.006984322523784353, "biggest_recent_change": 0.16598952790106125},
{"total_number_of_episodes": 22223, "number_of_timesteps": 5270472, "per_episode_reward": -92.56, "episode_reward_trend_value": 0.006249910864051836, "biggest_recent_change": 0.10911340118100554},
{"total_number_of_episodes": 22233, "number_of_timesteps": 5272550, "per_episode_reward": -92.4, "episode_reward_trend_value": 0.007795269280337101, "biggest_recent_change": 0.15759284706568621},
{"total_number_of_episodes": 22244, "number_of_timesteps": 5277239, "per_episode_reward": -92.3, "episode_reward_trend_value": 0.008733901700786204, "biggest_recent_change": 0.15759284706568621},
{"total_number_of_episodes": 22254, "number_of_timesteps": 5281919, "per_episode_reward": -92.24, "episode_reward_trend_value": 0.008541371787681998, "biggest_recent_change": 0.15759284706568621},
{"total_number_of_episodes": 22264, "number_of_timesteps": 5288539, "per_episode_reward": -92.1, "episode_reward_trend_value": 0.009874426421644638, "biggest_recent_change": 0.15759284706568621},
{"total_number_of_episodes": 22274, "number_of_timesteps": 5290658, "per_episode_reward": -92.02, "episode_reward_trend_value": 0.009571687180910891, "biggest_recent_change": 0.15759284706568621},
{"total_number_of_episodes": 22284, "number_of_timesteps": 5294147, "per_episode_reward": -91.98, "episode_reward_trend_value": 0.008804499489432753, "biggest_recent_change": 0.15759284706568621},
{"total_number_of_episodes": 22294, "number_of_timesteps": 5297356, "per_episode_reward": -91.82, "episode_reward_trend_value": 0.009919239085244492, "biggest_recent_change": 0.15894386406387184},
{"total_number_of_episodes": 22304, "number_of_timesteps": 5303133, "per_episode_reward": -91.68, "episode_reward_trend_value": 0.010858140708397458, "biggest_recent_change": 0.15894386406387184},
{"total_number_of_episodes": 22314, "number_of_timesteps": 5307287, "per_episode_reward": -91.63, "episode_reward_trend_value": 0.010356976914218307, "biggest_recent_change": 0.15894386406387184},
{"total_number_of_episodes": 22324, "number_of_timesteps": 5310513, "per_episode_reward": -91.58, "episode_reward_trend_value": 0.009167215496276684, "biggest_recent_change": 0.15894386406387184},
{"total_number_of_episodes": 22334, "number_of_timesteps": 5315162, "per_episode_reward": -91.52, "episode_reward_trend_value": 0.00871392112545553, "biggest_recent_change": 0.15894386406387184},
{"total_number_of_episodes": 22344, "number_of_timesteps": 5318451, "per_episode_reward": -91.42, "episode_reward_trend_value": 0.00910908889613877, "biggest_recent_change": 0.15894386406387184},
{"total_number_of_episodes": 22354, "number_of_timesteps": 5321919, "per_episode_reward": -91.35, "episode_reward_trend_value": 0.008280191843994405, "biggest_recent_change": 0.15894386406387184},
{"total_number_of_episodes": 22365, "number_of_timesteps": 5326446, "per_episode_reward": -91.16, "episode_reward_trend_value": 0.009464841342738516, "biggest_recent_change": 0.18848532440193821},
{"total_number_of_episodes": 22375, "number_of_timesteps": 5329963, "per_episode_reward": -91.1, "episode_reward_trend_value": 0.009767438424344573, "biggest_recent_change": 0.18848532440193821},
{"total_number_of_episodes": 22385, "number_of_timesteps": 5333969, "per_episode_reward": -91.07, "episode_reward_trend_value": 0.008361971765426466, "biggest_recent_change": 0.18848532440193821},
{"total_number_of_episodes": 22395, "number_of_timesteps": 5337021, "per_episode_reward": -91.0, "episode_reward_trend_value": 0.007564325406304325, "biggest_recent_change": 0.18848532440193821},
{"total_number_of_episodes": 22405, "number_of_timesteps": 5341822, "per_episode_reward": -90.85, "episode_reward_trend_value": 0.008563471783477735, "biggest_recent_change": 0.18848532440193821},
{"total_number_of_episodes": 22415, "number_of_timesteps": 5346678, "per_episode_reward": -90.82, "episode_reward_trend_value": 0.008373237427911483, "biggest_recent_change": 0.18848532440193821},
{"total_number_of_episodes": 22425, "number_of_timesteps": 5350652, "per_episode_reward": -90.7, "episode_reward_trend_value": 0.009042490323032521, "biggest_recent_change": 0.18848532440193821},
{"total_number_of_episodes": 22435, "number_of_timesteps": 5355693, "per_episode_reward": -90.62, "episode_reward_trend_value": 0.008879492374025392, "biggest_recent_change": 0.18848532440193821},
{"total_number_of_episodes": 22445, "number_of_timesteps": 5358675, "per_episode_reward": -90.59, "episode_reward_trend_value": 0.008445229211101296, "biggest_recent_change": 0.18848532440193821},
{"total_number_of_episodes": 22455, "number_of_timesteps": 5363549, "per_episode_reward": -90.54, "episode_reward_trend_value": 0.0069159560454502235, "biggest_recent_change": 0.1447109109946183},
{"total_number_of_episodes": 22465, "number_of_timesteps": 5367920, "per_episode_reward": -90.42, "episode_reward_trend_value": 0.007593946016232975, "biggest_recent_change": 0.1447109109946183},
{"total_number_of_episodes": 22475, "number_of_timesteps": 5373617, "per_episode_reward": -90.27, "episode_reward_trend_value": 0.008806612308119573, "biggest_recent_change": 0.1447109109946183},
{"total_number_of_episodes": 22485, "number_of_timesteps": 5376135, "per_episode_reward": -90.15, "episode_reward_trend_value": 0.009463191969234213, "biggest_recent_change": 0.1447109109946183},
{"total_number_of_episodes": 22495, "number_of_timesteps": 5379280, "per_episode_reward": -90.07, "episode_reward_trend_value": 0.00867027713503982, "biggest_recent_change": 0.141591831031036},
{"total_number_of_episodes": 22505, "number_of_timesteps": 5383776, "per_episode_reward": -90.04, "episode_reward_trend_value": 0.008688230903038946, "biggest_recent_change": 0.141591831031036},
{"total_number_of_episodes": 22515, "number_of_timesteps": 5387525, "per_episode_reward": -89.93, "episode_reward_trend_value": 0.008571327553113406, "biggest_recent_change": 0.141591831031036},
{"total_number_of_episodes": 22525, "number_of_timesteps": 5391826, "per_episode_reward": -89.86, "episode_reward_trend_value": 0.00850292501839552, "biggest_recent_change": 0.141591831031036},
{"total_number_of_episodes": 22535, "number_of_timesteps": 5397245, "per_episode_reward": -89.82, "episode_reward_trend_value": 0.008612279434697081, "biggest_recent_change": 0.141591831031036},
{"total_number_of_episodes": 22545, "number_of_timesteps": 5402236, "per_episode_reward": -89.78, "episode_reward_trend_value": 0.008445472518426318, "biggest_recent_change": 0.141591831031036},
{"total_number_of_episodes": 22556, "number_of_timesteps": 5410163, "per_episode_reward": -89.69, "episode_reward_trend_value": 0.008010435738293766, "biggest_recent_change": 0.141591831031036},
{"total_number_of_episodes": 22566, "number_of_timesteps": 5416283, "per_episode_reward": -89.64, "episode_reward_trend_value": 0.007073967470021437, "biggest_recent_change": 0.12544911995281893},
{"total_number_of_episodes": 22577, "number_of_timesteps": 5421920, "per_episode_reward": -89.55, "episode_reward_trend_value": 0.006592997490612934, "biggest_recent_change": 0.1075734579969918},
{"total_number_of_episodes": 22587, "number_of_timesteps": 5426078, "per_episode_reward": -89.5, "episode_reward_trend_value": 0.006367405086572672, "biggest_recent_change": 0.1075734579969918},
{"total_number_of_episodes": 22597, "number_of_timesteps": 5431951, "per_episode_reward": -89.43, "episode_reward_trend_value": 0.00679086497978558, "biggest_recent_change": 0.1075734579969918},
{"total_number_of_episodes": 22607, "number_of_timesteps": 5437111, "per_episode_reward": -89.38, "episode_reward_trend_value": 0.006162746837013818, "biggest_recent_change": 0.08689795284307422},
{"total_number_of_episodes": 22617, "number_of_timesteps": 5443091, "per_episode_reward": -89.32, "episode_reward_trend_value": 0.005943123324472784, "biggest_recent_change": 0.08689795284307422},
{"total_number_of_episodes": 22627, "number_of_timesteps": 5447711, "per_episode_reward": -89.06, "episode_reward_trend_value": 0.008398098721892842, "biggest_recent_change": 0.2622477721256473},
{"total_number_of_episodes": 22637, "number_of_timesteps": 5454042, "per_episode_reward": -88.97, "episode_reward_trend_value": 0.00902320662290587, "biggest_recent_change": 0.2622477721256473},
{"total_number_of_episodes": 22647, "number_of_timesteps": 5459103, "per_episode_reward": -88.8, "episode_reward_trend_value": 0.009878698848671912, "biggest_recent_change": 0.2622477721256473},
{"total_number_of_episodes": 22658, "number_of_timesteps": 5466107, "per_episode_reward": -88.73, "episode_reward_trend_value": 0.010094456238070709, "biggest_recent_change": 0.2622477721256473},
{"total_number_of_episodes": 22668, "number_of_timesteps": 5470498, "per_episode_reward": -88.69, "episode_reward_trend_value": 0.009642074982418414, "biggest_recent_change": 0.2622477721256473},
{"total_number_of_episodes": 22678, "number_of_timesteps": 5475906, "per_episode_reward": -88.57, "episode_reward_trend_value": 0.010320036000639733, "biggest_recent_change": 0.2622477721256473},
{"total_number_of_episodes": 22688, "number_of_timesteps": 5481870, "per_episode_reward": -88.5, "episode_reward_trend_value": 0.010322090176785695, "biggest_recent_change": 0.2622477721256473},
{"total_number_of_episodes": 22698, "number_of_timesteps": 5485078, "per_episode_reward": -88.42, "episode_reward_trend_value": 0.010637836330382792, "biggest_recent_change": 0.2622477721256473},

{"total_number_of_episodes": 22708, "number_of_timesteps": 5487792, "per_episode_reward": -88.31, "episode_reward_trend_value": 0.01123465888222073, "biggest_recent_change": 0.2622477721256473},
{"total_number_of_episodes": 22719, "number_of_timesteps": 5491301, "per_episode_reward": -88.18, "episode_reward_trend_value": 0.009795574591964219, "biggest_recent_change": 0.16389225316201816},
{"total_number_of_episodes": 22729, "number_of_timesteps": 5493042, "per_episode_reward": -88.14, "episode_reward_trend_value": 0.009247057874273896, "biggest_recent_change": 0.16389225316201816},
{"total_number_of_episodes": 22739, "number_of_timesteps": 5496801, "per_episode_reward": -88.1, "episode_reward_trend_value": 0.007815480528077184, "biggest_recent_change": 0.13273018600256137},
{"total_number_of_episodes": 22749, "number_of_timesteps": 5500859, "per_episode_reward": -87.99, "episode_reward_trend_value": 0.00816889689609389, "biggest_recent_change": 0.13273018600256137},
{"total_number_of_episodes": 22759, "number_of_timesteps": 5504861, "per_episode_reward": -87.84, "episode_reward_trend_value": 0.009406741485027067, "biggest_recent_change": 0.15285352180133316},
{"total_number_of_episodes": 22769, "number_of_timesteps": 5507987, "per_episode_reward": -87.75, "episode_reward_trend_value": 0.009170495241643392, "biggest_recent_change": 0.15285352180133316},
{"total_number_of_episodes": 22779, "number_of_timesteps": 5513045, "per_episode_reward": -87.7, "episode_reward_trend_value": 0.00885110563593609, "biggest_recent_change": 0.15285352180133316},
{"total_number_of_episodes": 22790, "number_of_timesteps": 5517637, "per_episode_reward": -87.63, "episode_reward_trend_value": 0.008786596803216501, "biggest_recent_change": 0.15285352180133316},
{"total_number_of_episodes": 22801, "number_of_timesteps": 5523098, "per_episode_reward": -87.52, "episode_reward_trend_value": 0.008748831670553476, "biggest_recent_change": 0.15285352180133316},
{"total_number_of_episodes": 22811, "number_of_timesteps": 5527824, "per_episode_reward": -87.43, "episode_reward_trend_value": 0.008307446728887807, "biggest_recent_change": 0.15285352180133316},
{"total_number_of_episodes": 22821, "number_of_timesteps": 5530887, "per_episode_reward": -87.36, "episode_reward_trend_value": 0.008606039738783346, "biggest_recent_change": 0.15285352180133316},
{"total_number_of_episodes": 22831, "number_of_timesteps": 5533058, "per_episode_reward": -87.31, "episode_reward_trend_value": 0.008793308588273242, "biggest_recent_change": 0.15285352180133316},
{"total_number_of_episodes": 22841, "number_of_timesteps": 5537571, "per_episode_reward": -87.21, "episode_reward_trend_value": 0.008749927012592688, "biggest_recent_change": 0.15285352180133316},
{"total_number_of_episodes": 22851, "number_of_timesteps": 5541155, "per_episode_reward": -87.05, "episode_reward_trend_value": 0.00872785747291213, "biggest_recent_change": 0.15086726323008293},
{"total_number_of_episodes": 22862, "number_of_timesteps": 5544995, "per_episode_reward": -86.95, "episode_reward_trend_value": 0.008849281836557548, "biggest_recent_change": 0.15086726323008293},
{"total_number_of_episodes": 22873, "number_of_timesteps": 5549312, "per_episode_reward": -86.86, "episode_reward_trend_value": 0.009357309013926358, "biggest_recent_change": 0.15086726323008293},
{"total_number_of_episodes": 22883, "number_of_timesteps": 5552054, "per_episode_reward": -86.69, "episode_reward_trend_value": 0.010450318408434276, "biggest_recent_change": 0.17202502953222165},
{"total_number_of_episodes": 22893, "number_of_timesteps": 5555509, "per_episode_reward": -86.61, "episode_reward_trend_value": 0.010146357089330297, "biggest_recent_change": 0.17202502953222165},
{"total_number_of_episodes": 22903, "number_of_timesteps": 5558497, "per_episode_reward": -86.52, "episode_reward_trend_value": 0.010106822936845896, "biggest_recent_change": 0.17202502953222165},
{"total_number_of_episodes": 22913, "number_of_timesteps": 5561773, "per_episode_reward": -86.4, "episode_reward_trend_value": 0.010742769745925942, "biggest_recent_change": 0.17202502953222165},
{"total_number_of_episodes": 22923, "number_of_timesteps": 5564647, "per_episode_reward": -86.3, "episode_reward_trend_value": 0.011262249481686443, "biggest_recent_change": 0.17202502953222165},
{"total_number_of_episodes": 22933, "number_of_timesteps": 5567096, "per_episode_reward": -86.21, "episode_reward_trend_value": 0.011082853008316029, "biggest_recent_change": 0.17202502953222165},
{"total_number_of_episodes": 22943, "number_of_timesteps": 5571250, "per_episode_reward": -86.12, "episode_reward_trend_value": 0.010367568807078936, "biggest_recent_change": 0.17202502953222165},
{"total_number_of_episodes": 22953, "number_of_timesteps": 5575578, "per_episode_reward": -86.1, "episode_reward_trend_value": 0.009459546870937963, "biggest_recent_change": 0.17202502953222165},
{"total_number_of_episodes": 22963, "number_of_timesteps": 5579970, "per_episode_reward": -86.04, "episode_reward_trend_value": 0.009063790419231232, "biggest_recent_change": 0.17202502953222165},
{"total_number_of_episodes": 22973, "number_of_timesteps": 5583293, "per_episode_reward": -85.98, "episode_reward_trend_value": 0.007881434116093544, "biggest_recent_change": 0.12683990723581928},
{"total_number_of_episodes": 22984, "number_of_timesteps": 5587570, "per_episode_reward": -85.85, "episode_reward_trend_value": 0.00851249143003214, "biggest_recent_change": 0.13391879988084554},
{"total_number_of_episodes": 22994, "number_of_timesteps": 5590406, "per_episode_reward": -85.76, "episode_reward_trend_value": 0.008522896953666741, "biggest_recent_change": 0.13391879988084554},
{"total_number_of_episodes": 23004, "number_of_timesteps": 5593812, "per_episode_reward": -85.72, "episode_reward_trend_value": 0.007556914092222182, "biggest_recent_change": 0.13391879988084554},
{"total_number_of_episodes": 23014, "number_of_timesteps": 5597441, "per_episode_reward": -85.69, "episode_reward_trend_value": 0.006769631810019423, "biggest_recent_change": 0.13391879988084554},
{"total_number_of_episodes": 23024, "number_of_timesteps": 5599729, "per_episode_reward": -85.42, "episode_reward_trend_value": 0.008763020164318094, "biggest_recent_change": 0.26789025252621457},
{"total_number_of_episodes": 23035, "number_of_timesteps": 5601406, "per_episode_reward": -85.39, "episode_reward_trend_value": 0.008161797933252047, "biggest_recent_change": 0.26789025252621457},
{"total_number_of_episodes": 23045, "number_of_timesteps": 5603627, "per_episode_reward": -85.34, "episode_reward_trend_value": 0.008457270965973545, "biggest_recent_change": 0.26789025252621457},
{"total_number_of_episodes": 23055, "number_of_timesteps": 5605905, "per_episode_reward": -85.19, "episode_reward_trend_value": 0.009527925493980485, "biggest_recent_change": 0.26789025252621457},
{"total_number_of_episodes": 23066, "number_of_timesteps": 5610111, "per_episode_reward": -85.12, "episode_reward_trend_value": 0.009562564208389784, "biggest_recent_change": 0.26789025252621457},
{"total_number_of_episodes": 23076, "number_of_timesteps": 5613690, "per_episode_reward": -85.04, "episode_reward_trend_value": 0.009002809375731304, "biggest_recent_change": 0.26789025252621457},
{"total_number_of_episodes": 23086, "number_of_timesteps": 5615900, "per_episode_reward": -84.95, "episode_reward_trend_value": 0.0089264457682854, "biggest_recent_change": 0.26789025252621457},
{"total_number_of_episodes": 23096, "number_of_timesteps": 5617996, "per_episode_reward": -84.88, "episode_reward_trend_value": 0.009292620804788971, "biggest_recent_change": 0.26789025252621457},
{"total_number_of_episodes": 23106, "number_of_timesteps": 5622335, "per_episode_reward": -84.77, "episode_reward_trend_value": 0.010179446395422707, "biggest_recent_change": 0.26789025252621457},
{"total_number_of_episodes": 23116, "number_of_timesteps": 5625596, "per_episode_reward": -84.66, "episode_reward_trend_value": 0.008435221472068438, "biggest_recent_change": 0.15102354112875105},
{"total_number_of_episodes": 23126, "number_of_timesteps": 5629246, "per_episode_reward": -84.6, "episode_reward_trend_value": 0.008740593424524611, "biggest_recent_change": 0.15102354112875105},
{"total_number_of_episodes": 23136, "number_of_timesteps": 5631704, "per_episode_reward": -84.53, "episode_reward_trend_value": 0.009028733074530414, "biggest_recent_change": 0.15102354112875105},
{"total_number_of_episodes": 23146, "number_of_timesteps": 5635812, "per_episode_reward": -84.42, "episode_reward_trend_value": 0.008476535643928034, "biggest_recent_change": 0.11091000942433027},
{"total_number_of_episodes": 23156, "number_of_timesteps": 5639083, "per_episode_reward": -84.37, "episode_reward_trend_value": 0.008298003679335548, "biggest_recent_change": 0.11091000942433027},
{"total_number_of_episodes": 23166, "number_of_timesteps": 5643181, "per_episode_reward": -84.29, "episode_reward_trend_value": 0.008226596267267735, "biggest_recent_change": 0.11091000942433027},
{"total_number_of_episodes": 23176, "number_of_timesteps": 5645838, "per_episode_reward": -84.24, "episode_reward_trend_value": 0.007903751466202083, "biggest_recent_change": 0.11091000942433027},
{"total_number_of_episodes": 23186, "number_of_timesteps": 5650905, "per_episode_reward": -84.19, "episode_reward_trend_value": 0.007665328024147773, "biggest_recent_change": 0.11091000942433027},
{"total_number_of_episodes": 23196, "number_of_timesteps": 5653696, "per_episode_reward": -84.08, "episode_reward_trend_value": 0.007713022643359579, "biggest_recent_change": 0.1119090781647003},
{"total_number_of_episodes": 23206, "number_of_timesteps": 5659514, "per_episode_reward": -83.98, "episode_reward_trend_value": 0.007530433199713906, "biggest_recent_change": 0.1119090781647003},
{"total_number_of_episodes": 23216, "number_of_timesteps": 5662142, "per_episode_reward": -83.81, "episode_reward_trend_value": 0.0087356016107942, "biggest_recent_change": 0.16833031704108237},
{"total_number_of_episodes": 23226, "number_of_timesteps": 5668799, "per_episode_reward": -83.73, "episode_reward_trend_value": 0.008810747143317916, "biggest_recent_change": 0.16833031704108237},
{"total_number_of_episodes": 23237, "number_of_timesteps": 5673575, "per_episode_reward": -83.63, "episode_reward_trend_value": 0.008838006075196523, "biggest_recent_change": 0.16833031704108237},
{"total_number_of_episodes": 23247, "number_of_timesteps": 5676707, "per_episode_reward": -83.49, "episode_reward_trend_value": 0.009790617658855024, "biggest_recent_change": 0.16833031704108237},
{"total_number_of_episodes": 23257, "number_of_timesteps": 5680136, "per_episode_reward": -83.4, "episode_reward_trend_value": 0.009983070530065499, "biggest_recent_change": 0.16833031704108237},
{"total_number_of_episodes": 23267, "number_of_timesteps": 5685415, "per_episode_reward": -83.33, "episode_reward_trend_value": 0.01012893508968852, "biggest_recent_change": 0.16833031704108237},
{"total_number_of_episodes": 23277, "number_of_timesteps": 5688769, "per_episode_reward": -83.07, "episode_reward_trend_value": 0.012381759771722834, "biggest_recent_change": 0.2541533145893311},
{"total_number_of_episodes": 23287, "number_of_timesteps": 5693146, "per_episode_reward": -83.01, "episode_reward_trend_value": 0.011840194826507241, "biggest_recent_change": 0.2541533145893311},
{"total_number_of_episodes": 23297, "number_of_timesteps": 5698945, "per_episode_reward": -82.95, "episode_reward_trend_value": 0.011518432076202918, "biggest_recent_change": 0.2541533145893311},
{"total_number_of_episodes": 23307, "number_of_timesteps": 5705547, "per_episode_reward": -82.84, "episode_reward_trend_value": 0.010878831764928047, "biggest_recent_change": 0.2541533145893311},
{"total_number_of_episodes": 23317, "number_of_timesteps": 5711942, "per_episode_reward": -82.75, "episode_reward_trend_value": 0.010920861704158034, "biggest_recent_change": 0.2541533145893311},
{"total_number_of_episodes": 23327, "number_of_timesteps": 5717492, "per_episode_reward": -82.64, "episode_reward_trend_value": 0.010973996197268025, "biggest_recent_change": 0.2541533145893311},
{"total_number_of_episodes": 23339, "number_of_timesteps": 5721605, "per_episode_reward": -82.6, "episode_reward_trend_value": 0.0098482433147478, "biggest_recent_change": 0.2541533145893311},
{"total_number_of_episodes": 23349, "number_of_timesteps": 5726062, "per_episode_reward": -82.46, "episode_reward_trend_value": 0.010414524560370352, "biggest_recent_change": 0.2541533145893311},
{"total_number_of_episodes": 23359, "number_of_timesteps": 5728374, "per_episode_reward": -82.33, "episode_reward_trend_value": 0.011085484831424235, "biggest_recent_change": 0.2541533145893311},
{"total_number_of_episodes": 23369, "number_of_timesteps": 5734434, "per_episode_reward": -82.3, "episode_reward_trend_value": 0.008625451785726233, "biggest_recent_change": 0.1454002683704516},
{"total_number_of_episodes": 23379, "number_of_timesteps": 5736873, "per_episode_reward": -82.19, "episode_reward_trend_value": 0.009177005927373865, "biggest_recent_change": 0.1454002683704516},
{"total_number_of_episodes": 23390, "number_of_timesteps": 5739664, "per_episode_reward": -82.07, "episode_reward_trend_value": 0.00972246722924284, "biggest_recent_change": 0.1454002683704516},
{"total_number_of_episodes": 23400, "number_of_timesteps": 5742747, "per_episode_reward": -81.96, "episode_reward_trend_value": 0.009695885445821438, "biggest_recent_change": 0.1454002683704516},
{"total_number_of_episodes": 23410, "number_of_timesteps": 5745852, "per_episode_reward": -81.62, "episode_reward_trend_value": 0.012568241281116364, "biggest_recent_change": 0.3435887668441211},
{"total_number_of_episodes": 23420, "number_of_timesteps": 5749204, "per_episode_reward": -81.54, "episode_reward_trend_value": 0.012280182140143519, "biggest_recent_change": 0.3435887668441211},
{"total_number_of_episodes": 23430, "number_of_timesteps": 5751205, "per_episode_reward": -81.51, "episode_reward_trend_value": 0.012145671236102374, "biggest_recent_change": 0.3435887668441211},
{"total_number_of_episodes": 23441, "number_of_timesteps": 5754783, "per_episode_reward": -81.43, "episode_reward_trend_value": 0.011458862496871171, "biggest_recent_change": 0.3435887668441211},
{"total_number_of_episodes": 23451, "number_of_timesteps": 5760504, "per_episode_reward": -81.38, "episode_reward_trend_value": 0.010532307751075444, "biggest_recent_change": 0.3435887668441211},
{"total_number_of_episodes": 23461, "number_of_timesteps": 5762970, "per_episode_reward": -81.22, "episode_reward_trend_value": 0.011966535387548067, "biggest_recent_change": 0.3435887668441211},
{"total_number_of_episodes": 23471, "number_of_timesteps": 5765750, "per_episode_reward": -81.14, "episode_reward_trend_value": 0.011610138827515944, "biggest_recent_change": 0.3435887668441211},
{"total_number_of_episodes": 23481, "number_of_timesteps": 5769913, "per_episode_reward": -81.09, "episode_reward_trend_value": 0.01091619281924273, "biggest_recent_change": 0.3435887668441211},
{"total_number_of_episodes": 23492, "number_of_timesteps": 5773193, "per_episode_reward": -81.05, "episode_reward_trend_value": 0.01017964872241303, "biggest_recent_change": 0.3435887668441211},
{"total_number_of_episodes": 23502, "number_of_timesteps": 5777334, "per_episode_reward": -80.95, "episode_reward_trend_value": 0.0074476988809492025, "biggest_recent_change": 0.16183082775904722},
{"total_number_of_episodes": 23512, "number_of_timesteps": 5780544, "per_episode_reward": -80.87, "episode_reward_trend_value": 0.007426335553888129, "biggest_recent_change": 0.16183082775904722},
{"total_number_of_episodes": 23523, "number_of_timesteps": 5784613, "per_episode_reward": -80.76, "episode_reward_trend_value": 0.008358989209845428, "biggest_recent_change": 0.16183082775904722},
{"total_number_of_episodes": 23534, "number_of_timesteps": 5787030, "per_episode_reward": -80.61, "episode_reward_trend_value": 0.009101520854554856, "biggest_recent_change": 0.16183082775904722},
{"total_number_of_episodes": 23544, "number_of_timesteps": 5789147, "per_episode_reward": -80.51, "episode_reward_trend_value": 0.00968393876745684, "biggest_recent_change": 0.16183082775904722},
{"total_number_of_episodes": 23554, "number_of_timesteps": 5792370, "per_episode_reward": -80.41, "episode_reward_trend_value": 0.00898201760281236, "biggest_recent_change": 0.15041532986349182},
{"total_number_of_episodes": 23564, "number_of_timesteps": 5794556, "per_episode_reward": -80.34, "episode_reward_trend_value": 0.008892885214766801, "biggest_recent_change": 0.15041532986349182},
{"total_number_of_episodes": 23574, "number_of_timesteps": 5796774, "per_episode_reward": -80.23, "episode_reward_trend_value": 0.009588326533155112, "biggest_recent_change": 0.15041532986349182},
{"total_number_of_episodes": 23584, "number_of_timesteps": 5798244, "per_episode_reward": -80.12, "episode_reward_trend_value": 0.010340370977567027, "biggest_recent_change": 0.15041532986349182},
{"total_number_of_episodes": 23594, "number_of_timesteps": 5799628, "per_episode_reward": -80.06, "episode_reward_trend_value": 0.009905234958346101, "biggest_recent_change": 0.15041532986349182},
{"total_number_of_episodes": 23604, "number_of_timesteps": 5802017, "per_episode_reward": -79.97, "episode_reward_trend_value": 0.009982098302387499, "biggest_recent_change": 0.15041532986349182},
{"total_number_of_episodes": 23615, "number_of_timesteps": 5803763, "per_episode_reward": -79.91, "episode_reward_trend_value": 0.009487923303446482, "biggest_recent_change": 0.15041532986349182},
{"total_number_of_episodes": 23625, "number_of_timesteps": 5805140, "per_episode_reward": -79.85, "episode_reward_trend_value": 0.00846799906878996, "biggest_recent_change": 0.11474440704739663},
{"total_number_of_episodes": 23635, "number_of_timesteps": 5808128, "per_episode_reward": -79.76, "episode_reward_trend_value": 0.008350987178017515, "biggest_recent_change": 0.11474440704739663},
{"total_number_of_episodes": 23645, "number_of_timesteps": 5809513, "per_episode_reward": -79.68, "episode_reward_trend_value": 0.008102682467730283, "biggest_recent_change": 0.11474440704739663},
{"total_number_of_episodes": 23655, "number_of_timesteps": 5811035, "per_episode_reward": -79.64, "episode_reward_trend_value": 0.007753032972301179, "biggest_recent_change": 0.11474440704739663},
{"total_number_of_episodes": 23665, "number_of_timesteps": 5812568, "per_episode_reward": -79.61, "episode_reward_trend_value": 0.006852281526886214, "biggest_recent_change": 0.10976895980081736},
{"total_number_of_episodes": 23675, "number_of_timesteps": 5815092, "per_episode_reward": -79.54, "episode_reward_trend_value": 0.006429526923589416, "biggest_recent_change": 0.08763085946418414},
{"total_number_of_episodes": 23685, "number_of_timesteps": 5817483, "per_episode_reward": -79.47, "episode_reward_trend_value": 0.006562044375678038, "biggest_recent_change": 0.08763085946418414},
{"total_number_of_episodes": 23695, "number_of_timesteps": 5820791, "per_episode_reward": -79.28, "episode_reward_trend_value": 0.007672448872398421, "biggest_recent_change": 0.1875672641690187},
{"total_number_of_episodes": 23705, "number_of_timesteps": 5823990, "per_episode_reward": -79.05, "episode_reward_trend_value": 0.009499675624324924, "biggest_recent_change": 0.22888735827693552},
{"total_number_of_episodes": 23716, "number_of_timesteps": 5827633, "per_episode_reward": -78.83, "episode_reward_trend_value": 0.011319913722761674, "biggest_recent_change": 0.22888735827693552},
{"total_number_of_episodes": 23726, "number_of_timesteps": 5829032, "per_episode_reward": -78.75, "episode_reward_trend_value": 0.011183146580662159, "biggest_recent_change": 0.22888735827693552},
{"total_number_of_episodes": 23736, "number_of_timesteps": 5830387, "per_episode_reward": -78.7, "episode_reward_trend_value": 0.010900304084501045, "biggest_recent_change": 0.22888735827693552},
{"total_number_of_episodes": 23746, "number_of_timesteps": 5832023, "per_episode_reward": -78.63, "episode_reward_trend_value": 0.011292175785218381, "biggest_recent_change": 0.22888735827693552},

{"total_number_of_episodes": 23756, "number_of_timesteps": 5833440, "per_episode_reward": -78.58, "episode_reward_trend_value": 0.011397337711597306, "biggest_recent_change": 0.22888735827693552},
{"total_number_of_episodes": 23766, "number_of_timesteps": 5835763, "per_episode_reward": -78.53, "episode_reward_trend_value": 0.011225495459167848, "biggest_recent_change": 0.22888735827693552},
{"total_number_of_episodes": 23776, "number_of_timesteps": 5838315, "per_episode_reward": -78.45, "episode_reward_trend_value": 0.01127810344578519, "biggest_recent_change": 0.22888735827693552},
{"total_number_of_episodes": 23786, "number_of_timesteps": 5844244, "per_episode_reward": -78.43, "episode_reward_trend_value": 0.009402136359152439, "biggest_recent_change": 0.22888735827693552},
{"total_number_of_episodes": 23796, "number_of_timesteps": 5847418, "per_episode_reward": -78.34, "episode_reward_trend_value": 0.007925083565244665, "biggest_recent_change": 0.22244357760371258},
{"total_number_of_episodes": 23806, "number_of_timesteps": 5850106, "per_episode_reward": -78.06, "episode_reward_trend_value": 0.008531827288460015, "biggest_recent_change": 0.2770505126930942},
{"total_number_of_episodes": 23816, "number_of_timesteps": 5852809, "per_episode_reward": -78.0, "episode_reward_trend_value": 0.008366542804901024, "biggest_recent_change": 0.2770505126930942},
{"total_number_of_episodes": 23826, "number_of_timesteps": 5857743, "per_episode_reward": -77.86, "episode_reward_trend_value": 0.009310418829403172, "biggest_recent_change": 0.2770505126930942},
{"total_number_of_episodes": 23836, "number_of_timesteps": 5862517, "per_episode_reward": -77.73, "episode_reward_trend_value": 0.009981458179841713, "biggest_recent_change": 0.2770505126930942},
{"total_number_of_episodes": 23847, "number_of_timesteps": 5868658, "per_episode_reward": -77.58, "episode_reward_trend_value": 0.011167594295512135, "biggest_recent_change": 0.2770505126930942},
{"total_number_of_episodes": 23857, "number_of_timesteps": 5874379, "per_episode_reward": -77.51, "episode_reward_trend_value": 0.011289854585069748, "biggest_recent_change": 0.2770505126930942},
{"total_number_of_episodes": 23867, "number_of_timesteps": 5879296, "per_episode_reward": -77.42, "episode_reward_trend_value": 0.011485799247320471, "biggest_recent_change": 0.2770505126930942},
{"total_number_of_episodes": 23877, "number_of_timesteps": 5884774, "per_episode_reward": -77.37, "episode_reward_trend_value": 0.011857855349426277, "biggest_recent_change": 0.2770505126930942},
{"total_number_of_episodes": 23888, "number_of_timesteps": 5889450, "per_episode_reward": -77.3, "episode_reward_trend_value": 0.011558926281343595, "biggest_recent_change": 0.2770505126930942},
{"total_number_of_episodes": 23898, "number_of_timesteps": 5895818, "per_episode_reward": -77.22, "episode_reward_trend_value": 0.009332146146786614, "biggest_recent_change": 0.1498936007444911},
{"total_number_of_episodes": 23908, "number_of_timesteps": 5901252, "per_episode_reward": -77.11, "episode_reward_trend_value": 0.009894188614336486, "biggest_recent_change": 0.1498936007444911},
{"total_number_of_episodes": 23918, "number_of_timesteps": 5907755, "per_episode_reward": -77.02, "episode_reward_trend_value": 0.009421600447767749, "biggest_recent_change": 0.1498936007444911},
{"total_number_of_episodes": 23928, "number_of_timesteps": 5913103, "per_episode_reward": -76.91, "episode_reward_trend_value": 0.009059890146017342, "biggest_recent_change": 0.1498936007444911},
{"total_number_of_episodes": 23938, "number_of_timesteps": 5917469, "per_episode_reward": -76.85, "episode_reward_trend_value": 0.008051870290327025, "biggest_recent_change": 0.10986523329131614},
{"total_number_of_episodes": 23949, "number_of_timesteps": 5923042, "per_episode_reward": -76.78, "episode_reward_trend_value": 0.008146765781255914, "biggest_recent_change": 0.10986523329131614},
{"total_number_of_episodes": 23959, "number_of_timesteps": 5928928, "per_episode_reward": -76.74, "episode_reward_trend_value": 0.007522613175910761, "biggest_recent_change": 0.10986523329131614},
{"total_number_of_episodes": 23969, "number_of_timesteps": 5932832, "per_episode_reward": -76.7, "episode_reward_trend_value": 0.007404690441798006, "biggest_recent_change": 0.10986523329131614},
{"total_number_of_episodes": 23979, "number_of_timesteps": 5938332, "per_episode_reward": -76.67, "episode_reward_trend_value": 0.006986564566330679, "biggest_recent_change": 0.10986523329131614},
{"total_number_of_episodes": 23989, "number_of_timesteps": 5943052, "per_episode_reward": -76.58, "episode_reward_trend_value": 0.00714110389042525, "biggest_recent_change": 0.10986523329131614},
{"total_number_of_episodes": 23999, "number_of_timesteps": 5948880, "per_episode_reward": -76.52, "episode_reward_trend_value": 0.006565649687798075, "biggest_recent_change": 0.10435011337446554},
{"total_number_of_episodes": 24009, "number_of_timesteps": 5953088, "per_episode_reward": -76.41, "episode_reward_trend_value": 0.006786347444639457, "biggest_recent_change": 0.11313337969042436},
{"total_number_of_episodes": 24019, "number_of_timesteps": 5958069, "per_episode_reward": -76.4, "episode_reward_trend_value": 0.005732194690861706, "biggest_recent_change": 0.11313337969042436},
{"total_number_of_episodes": 24029, "number_of_timesteps": 5963535, "per_episode_reward": -76.27, "episode_reward_trend_value": 0.0064744089460412445, "biggest_recent_change": 0.12597109669852102},
{"total_number_of_episodes": 24039, "number_of_timesteps": 5967186, "per_episode_reward": -76.13, "episode_reward_trend_value": 0.007175301611593928, "biggest_recent_change": 0.13887960292898072},
{"total_number_of_episodes": 24049, "number_of_timesteps": 5970657, "per_episode_reward": -76.03, "episode_reward_trend_value": 0.007923194676672235, "biggest_recent_change": 0.13887960292898072},
{"total_number_of_episodes": 24059, "number_of_timesteps": 5972984, "per_episode_reward": -75.91, "episode_reward_trend_value": 0.00875032594430915, "biggest_recent_change": 0.13887960292898072},
{"total_number_of_episodes": 24069, "number_of_timesteps": 5975312, "per_episode_reward": -75.84, "episode_reward_trend_value": 0.009190518778058593, "biggest_recent_change": 0.13887960292898072},
{"total_number_of_episodes": 24080, "number_of_timesteps": 5977661, "per_episode_reward": -75.8, "episode_reward_trend_value": 0.008668619144609124, "biggest_recent_change": 0.13887960292898072},
{"total_number_of_episodes": 24090, "number_of_timesteps": 5980845, "per_episode_reward": -75.73, "episode_reward_trend_value": 0.008823233795287422, "biggest_recent_change": 0.13887960292898072},
{"total_number_of_episodes": 24100, "number_of_timesteps": 5982307, "per_episode_reward": -75.58, "episode_reward_trend_value": 0.009160726063223813, "biggest_recent_change": 0.14350768380469958},
{"total_number_of_episodes": 24110, "number_of_timesteps": 5984758, "per_episode_reward": -75.46, "episode_reward_trend_value": 0.010394194995434545, "biggest_recent_change": 0.14350768380469958},
{"total_number_of_episodes": 24120, "number_of_timesteps": 5987779, "per_episode_reward": -75.39, "episode_reward_trend_value": 0.00979711343524359, "biggest_recent_change": 0.14350768380469958},
{"total_number_of_episodes": 24130, "number_of_timesteps": 5990344, "per_episode_reward": -75.33, "episode_reward_trend_value": 0.008902117413403549, "biggest_recent_change": 0.14350768380469958},
{"total_number_of_episodes": 24140, "number_of_timesteps": 5995079, "per_episode_reward": -75.25, "episode_reward_trend_value": 0.008676922482306459, "biggest_recent_change": 0.14350768380469958},
{"total_number_of_episodes": 24150, "number_of_timesteps": 6000086, "per_episode_reward": -75.22, "episode_reward_trend_value": 0.007714789190454969, "biggest_recent_change": 0.14350768380469958},
{"total_number_of_episodes": 24160, "number_of_timesteps": 6003967, "per_episode_reward": -75.11, "episode_reward_trend_value": 0.008083983945532383, "biggest_recent_change": 0.14350768380469958},
{"total_number_of_episodes": 24170, "number_of_timesteps": 6008732, "per_episode_reward": -75.02, "episode_reward_trend_value": 0.008621521949809125, "biggest_recent_change": 0.14350768380469958},
{"total_number_of_episodes": 24180, "number_of_timesteps": 6012112, "per_episode_reward": -74.89, "episode_reward_trend_value": 0.009257853599972382, "biggest_recent_change": 0.14350768380469958},
{"total_number_of_episodes": 24190, "number_of_timesteps": 6017323, "per_episode_reward": -74.85, "episode_reward_trend_value": 0.008160437862578047, "biggest_recent_change": 0.1292595221306101},
{"total_number_of_episodes": 24200, "number_of_timesteps": 6021651, "per_episode_reward": -74.8, "episode_reward_trend_value": 0.007311089060737667, "biggest_recent_change": 0.1292595221306101},
{"total_number_of_episodes": 24210, "number_of_timesteps": 6025968, "per_episode_reward": -74.73, "episode_reward_trend_value": 0.007274751944171637, "biggest_recent_change": 0.1292595221306101},
{"total_number_of_episodes": 24220, "number_of_timesteps": 6032145, "per_episode_reward": -74.69, "episode_reward_trend_value": 0.007151567778721023, "biggest_recent_change": 0.1292595221306101},
{"total_number_of_episodes": 24230, "number_of_timesteps": 6037422, "per_episode_reward": -74.52, "episode_reward_trend_value": 0.00811322270975173, "biggest_recent_change": 0.17026538983860462},
{"total_number_of_episodes": 24240, "number_of_timesteps": 6044471, "per_episode_reward": -74.44, "episode_reward_trend_value": 0.008646665406212468, "biggest_recent_change": 0.17026538983860462},
{"total_number_of_episodes": 24250, "number_of_timesteps": 6053756, "per_episode_reward": -74.36, "episode_reward_trend_value": 0.0083202909251753, "biggest_recent_change": 0.17026538983860462},
{"total_number_of_episodes": 24260, "number_of_timesteps": 6061120, "per_episode_reward": -74.3, "episode_reward_trend_value": 0.00796130379728134, "biggest_recent_change": 0.17026538983860462},
{"total_number_of_episodes": 24270, "number_of_timesteps": 6068144, "per_episode_reward": -74.22, "episode_reward_trend_value": 0.0074967517767011785, "biggest_recent_change": 0.17026538983860462},
{"total_number_of_episodes": 24280, "number_of_timesteps": 6075517, "per_episode_reward": -74.17, "episode_reward_trend_value": 0.00752218234594153, "biggest_recent_change": 0.17026538983860462},
{"total_number_of_episodes": 24290, "number_of_timesteps": 6083448, "per_episode_reward": -74.09, "episode_reward_trend_value": 0.007883523135634125, "biggest_recent_change": 0.17026538983860462},
{"total_number_of_episodes": 24300, "number_of_timesteps": 6090269, "per_episode_reward": -74.05, "episode_reward_trend_value": 0.007592256201858068, "biggest_recent_change": 0.17026538983860462},
{"total_number_of_episodes": 24310, "number_of_timesteps": 6099692, "per_episode_reward": -73.98, "episode_reward_trend_value": 0.007891646467496906, "biggest_recent_change": 0.17026538983860462},
{"total_number_of_episodes": 24320, "number_of_timesteps": 6103667, "per_episode_reward": -73.78, "episode_reward_trend_value": 0.008231754297646098, "biggest_recent_change": 0.2008750945520319},
{"total_number_of_episodes": 24330, "number_of_timesteps": 6107971, "per_episode_reward": -73.73, "episode_reward_trend_value": 0.00786319688616383, "biggest_recent_change": 0.2008750945520319},
{"total_number_of_episodes": 24340, "number_of_timesteps": 6112596, "per_episode_reward": -73.63, "episode_reward_trend_value": 0.008122030076661384, "biggest_recent_change": 0.2008750945520319},
{"total_number_of_episodes": 24350, "number_of_timesteps": 6118042, "per_episode_reward": -73.47, "episode_reward_trend_value": 0.009323502308918326, "biggest_recent_change": 0.2008750945520319},
{"total_number_of_episodes": 24360, "number_of_timesteps": 6123276, "per_episode_reward": -73.34, "episode_reward_trend_value": 0.00971013025315257, "biggest_recent_change": 0.2008750945520319},
{"total_number_of_episodes": 24370, "number_of_timesteps": 6129535, "per_episode_reward": -73.23, "episode_reward_trend_value": 0.010476326617824345, "biggest_recent_change": 0.2008750945520319},
{"total_number_of_episodes": 24380, "number_of_timesteps": 6135104, "per_episode_reward": -73.13, "episode_reward_trend_value": 0.010696475758465517, "biggest_recent_change": 0.2008750945520319},
{"total_number_of_episodes": 24390, "number_of_timesteps": 6140364, "per_episode_reward": -73.04, "episode_reward_trend_value": 0.011229927982417742, "biggest_recent_change": 0.2008750945520319},
{"total_number_of_episodes": 24400, "number_of_timesteps": 6145867, "per_episode_reward": -72.98, "episode_reward_trend_value": 0.011097183653764692, "biggest_recent_change": 0.2008750945520319},
{"total_number_of_episodes": 24410, "number_of_timesteps": 6152186, "per_episode_reward": -72.96, "episode_reward_trend_value": 0.009090453748496291, "biggest_recent_change": 0.16777995251860034},
{"total_number_of_episodes": 24420, "number_of_timesteps": 6156560, "per_episode_reward": -72.86, "episode_reward_trend_value": 0.009724101489128934, "biggest_recent_change": 0.16777995251860034},
{"total_number_of_episodes": 24430, "number_of_timesteps": 6160247, "per_episode_reward": -72.74, "episode_reward_trend_value": 0.009882899759295564, "biggest_recent_change": 0.16777995251860034},
{"total_number_of_episodes": 24440, "number_of_timesteps": 6163742, "per_episode_reward": -72.69, "episode_reward_trend_value": 0.008637292026972115, "biggest_recent_change": 0.12224635525947747},
{"total_number_of_episodes": 24451, "number_of_timesteps": 6169993, "per_episode_reward": -72.56, "episode_reward_trend_value": 0.008738960112451366, "biggest_recent_change": 0.13139648295260997},
{"total_number_of_episodes": 24461, "number_of_timesteps": 6175584, "per_episode_reward": -72.34, "episode_reward_trend_value": 0.009875431033364477, "biggest_recent_change": 0.21826907437348098},
{"total_number_of_episodes": 24471, "number_of_timesteps": 6183712, "per_episode_reward": -72.27, "episode_reward_trend_value": 0.009563698334453205, "biggest_recent_change": 0.21826907437348098},
{"total_number_of_episodes": 24481, "number_of_timesteps": 6191708, "per_episode_reward": -72.16, "episode_reward_trend_value": 0.009770983947584, "biggest_recent_change": 0.21826907437348098},
{"total_number_of_episodes": 24491, "number_of_timesteps": 6198300, "per_episode_reward": -72.04, "episode_reward_trend_value": 0.010370151349497626, "biggest_recent_change": 0.21826907437348098},
{"total_number_of_episodes": 24501, "number_of_timesteps": 6205135, "per_episode_reward": -72.0, "episode_reward_trend_value": 0.010636727660702484, "biggest_recent_change": 0.21826907437348098},
{"total_number_of_episodes": 24511, "number_of_timesteps": 6214032, "per_episode_reward": -71.9, "episode_reward_trend_value": 0.010594637554971264, "biggest_recent_change": 0.21826907437348098},
{"total_number_of_episodes": 24521, "number_of_timesteps": 6220549, "per_episode_reward": -71.75, "episode_reward_trend_value": 0.011020002738606632, "biggest_recent_change": 0.21826907437348098},
{"total_number_of_episodes": 24531, "number_of_timesteps": 6224872, "per_episode_reward": -71.7, "episode_reward_trend_value": 0.010955639111273917, "biggest_recent_change": 0.21826907437348098},
{"total_number_of_episodes": 24541, "number_of_timesteps": 6231799, "per_episode_reward": -71.61, "episode_reward_trend_value": 0.010518076929764359, "biggest_recent_change": 0.21826907437348098},
{"total_number_of_episodes": 24551, "number_of_timesteps": 6237609, "per_episode_reward": -71.58, "episode_reward_trend_value": 0.00842167750180162, "biggest_recent_change": 0.15075853959376673},

{"total_number_of_episodes": 24561, "number_of_timesteps": 6243650, "per_episode_reward": -71.51, "episode_reward_trend_value": 0.008453585627586177, "biggest_recent_change": 0.15075853959376673},
{"total_number_of_episodes": 24571, "number_of_timesteps": 6248534, "per_episode_reward": -71.45, "episode_reward_trend_value": 0.007948175842994312, "biggest_recent_change": 0.15075853959376673},
{"total_number_of_episodes": 24581, "number_of_timesteps": 6254440, "per_episode_reward": -71.34, "episode_reward_trend_value": 0.007813421995562288, "biggest_recent_change": 0.15075853959376673},
{"total_number_of_episodes": 24591, "number_of_timesteps": 6259873, "per_episode_reward": -71.07, "episode_reward_trend_value": 0.010386392358639461, "biggest_recent_change": 0.2758286037632587},
{"total_number_of_episodes": 24601, "number_of_timesteps": 6265094, "per_episode_reward": -71.0, "episode_reward_trend_value": 0.010050767255136053, "biggest_recent_change": 0.2758286037632587},
{"total_number_of_episodes": 24611, "number_of_timesteps": 6270005, "per_episode_reward": -70.95, "episode_reward_trend_value": 0.008909794084408892, "biggest_recent_change": 0.2758286037632587},
{"total_number_of_episodes": 24621, "number_of_timesteps": 6278017, "per_episode_reward": -70.9, "episode_reward_trend_value": 0.008958985932262761, "biggest_recent_change": 0.2758286037632587},
{"total_number_of_episodes": 24631, "number_of_timesteps": 6283572, "per_episode_reward": -70.81, "episode_reward_trend_value": 0.008940877376546376, "biggest_recent_change": 0.2758286037632587},
{"total_number_of_episodes": 24641, "number_of_timesteps": 6290855, "per_episode_reward": -70.74, "episode_reward_trend_value": 0.009299244824147006, "biggest_recent_change": 0.2758286037632587},
{"total_number_of_episodes": 24651, "number_of_timesteps": 6296746, "per_episode_reward": -70.66, "episode_reward_trend_value": 0.009397249196495731, "biggest_recent_change": 0.2758286037632587},
{"total_number_of_episodes": 24662, "number_of_timesteps": 6304070, "per_episode_reward": -70.54, "episode_reward_trend_value": 0.010062992559326113, "biggest_recent_change": 0.2758286037632587},
{"total_number_of_episodes": 24672, "number_of_timesteps": 6307374, "per_episode_reward": -70.44, "episode_reward_trend_value": 0.010022051986112975, "biggest_recent_change": 0.2758286037632587},
{"total_number_of_episodes": 24682, "number_of_timesteps": 6310597, "per_episode_reward": -70.37, "episode_reward_trend_value": 0.007733682559428542, "biggest_recent_change": 0.12384581912948533},
{"total_number_of_episodes": 24692, "number_of_timesteps": 6316258, "per_episode_reward": -70.26, "episode_reward_trend_value": 0.008205979111225285, "biggest_recent_change": 0.12384581912948533},
{"total_number_of_episodes": 24702, "number_of_timesteps": 6319761, "per_episode_reward": -70.24, "episode_reward_trend_value": 0.007892043967247592, "biggest_recent_change": 0.12384581912948533},
{"total_number_of_episodes": 24712, "number_of_timesteps": 6324840, "per_episode_reward": -70.18, "episode_reward_trend_value": 0.007957561358338378, "biggest_recent_change": 0.12384581912948533},
{"total_number_of_episodes": 24722, "number_of_timesteps": 6328322, "per_episode_reward": -70.04, "episode_reward_trend_value": 0.00854177265152095, "biggest_recent_change": 0.1429651329887065},
{"total_number_of_episodes": 24733, "number_of_timesteps": 6335006, "per_episode_reward": -69.93, "episode_reward_trend_value": 0.009025817395315824, "biggest_recent_change": 0.1429651329887065},
{"total_number_of_episodes": 24743, "number_of_timesteps": 6338313, "per_episode_reward": -69.89, "episode_reward_trend_value": 0.008630306875212391, "biggest_recent_change": 0.1429651329887065},
{"total_number_of_episodes": 24753, "number_of_timesteps": 6341582, "per_episode_reward": -69.8, "episode_reward_trend_value": 0.008229605087922682, "biggest_recent_change": 0.1429651329887065},
{"total_number_of_episodes": 24763, "number_of_timesteps": 6345186, "per_episode_reward": -69.71, "episode_reward_trend_value": 0.008105600084395172, "biggest_recent_change": 0.1429651329887065},
{"total_number_of_episodes": 24774, "number_of_timesteps": 6350171, "per_episode_reward": -69.65, "episode_reward_trend_value": 0.008022836674360354, "biggest_recent_change": 0.1429651329887065},
{"total_number_of_episodes": 24784, "number_of_timesteps": 6354209, "per_episode_reward": -69.53, "episode_reward_trend_value": 0.008126214955971515, "biggest_recent_change": 0.1429651329887065},
{"total_number_of_episodes": 24794, "number_of_timesteps": 6357504, "per_episode_reward": -69.49, "episode_reward_trend_value": 0.008364203925862373, "biggest_recent_change": 0.1429651329887065},
{"total_number_of_episodes": 24804, "number_of_timesteps": 6361232, "per_episode_reward": -69.41, "episode_reward_trend_value": 0.008520363138963363, "biggest_recent_change": 0.1429651329887065},
{"total_number_of_episodes": 24814, "number_of_timesteps": 6368265, "per_episode_reward": -69.33, "episode_reward_trend_value": 0.007815621237471582, "biggest_recent_change": 0.11913638579272856},
{"total_number_of_episodes": 24824, "number_of_timesteps": 6372464, "per_episode_reward": -69.26, "episode_reward_trend_value": 0.00746415158319375, "biggest_recent_change": 0.11913638579272856},
{"total_number_of_episodes": 24834, "number_of_timesteps": 6376584, "per_episode_reward": -69.19, "episode_reward_trend_value": 0.007687438061487563, "biggest_recent_change": 0.11913638579272856},
{"total_number_of_episodes": 24844, "number_of_timesteps": 6379954, "per_episode_reward": -69.03, "episode_reward_trend_value": 0.008516072432608091, "biggest_recent_change": 0.1623597516742592},
{"total_number_of_episodes": 24854, "number_of_timesteps": 6382367, "per_episode_reward": -68.99, "episode_reward_trend_value": 0.008001554966626164, "biggest_recent_change": 0.1623597516742592},
{"total_number_of_episodes": 24864, "number_of_timesteps": 6385499, "per_episode_reward": -68.9, "episode_reward_trend_value": 0.008336857380632839, "biggest_recent_change": 0.1623597516742592},
{"total_number_of_episodes": 24874, "number_of_timesteps": 6388932, "per_episode_reward": -68.82, "episode_reward_trend_value": 0.007813900745981072, "biggest_recent_change": 0.1623597516742592},
{"total_number_of_episodes": 24884, "number_of_timesteps": 6391316, "per_episode_reward": -68.75, "episode_reward_trend_value": 0.00818546912599187, "biggest_recent_change": 0.1623597516742592},
{"total_number_of_episodes": 24894, "number_of_timesteps": 6392618, "per_episode_reward": -68.63, "episode_reward_trend_value": 0.008679883258114767, "biggest_recent_change": 0.1623597516742592},
{"total_number_of_episodes": 24905, "number_of_timesteps": 6395903, "per_episode_reward": -68.55, "episode_reward_trend_value": 0.00875725016901217, "biggest_recent_change": 0.1623597516742592},
{"total_number_of_episodes": 24915, "number_of_timesteps": 6399576, "per_episode_reward": -68.47, "episode_reward_trend_value": 0.00875827209137504, "biggest_recent_change": 0.1623597516742592},
{"total_number_of_episodes": 24925, "number_of_timesteps": 6402519, "per_episode_reward": -68.37, "episode_reward_trend_value": 0.009128129111276608, "biggest_recent_change": 0.1623597516742592},
{"total_number_of_episodes": 24936, "number_of_timesteps": 6408104, "per_episode_reward": -68.33, "episode_reward_trend_value": 0.007798028788867997, "biggest_recent_change": 0.11875796272471462},
{"total_number_of_episodes": 24946, "number_of_timesteps": 6410244, "per_episode_reward": -68.24, "episode_reward_trend_value": 0.008294651538846804, "biggest_recent_change": 0.11875796272471462},
{"total_number_of_episodes": 24956, "number_of_timesteps": 6413390, "per_episode_reward": -68.12, "episode_reward_trend_value": 0.008630478663725051, "biggest_recent_change": 0.12282830695816926},
{"total_number_of_episodes": 24966, "number_of_timesteps": 6416956, "per_episode_reward": -68.07, "episode_reward_trend_value": 0.00833469855542685, "biggest_recent_change": 0.12282830695816926},
{"total_number_of_episodes": 24976, "number_of_timesteps": 6421973, "per_episode_reward": -68.06, "episode_reward_trend_value": 0.007619766761023862, "biggest_recent_change": 0.12282830695816926},
{"total_number_of_episodes": 24986, "number_of_timesteps": 6427001, "per_episode_reward": -67.86, "episode_reward_trend_value": 0.008543777807572737, "biggest_recent_change": 0.20191895691411332},
{"total_number_of_episodes": 24996, "number_of_timesteps": 6431239, "per_episode_reward": -67.82, "episode_reward_trend_value": 0.008054713780430866, "biggest_recent_change": 0.20191895691411332},
{"total_number_of_episodes": 25006, "number_of_timesteps": 6436098, "per_episode_reward": -67.76, "episode_reward_trend_value": 0.007944855860077855, "biggest_recent_change": 0.20191895691411332},
{"total_number_of_episodes": 25016, "number_of_timesteps": 6440412, "per_episode_reward": -67.66, "episode_reward_trend_value": 0.007970384338273896, "biggest_recent_change": 0.20191895691411332},
{"total_number_of_episodes": 25026, "number_of_timesteps": 6447020, "per_episode_reward": -67.53, "episode_reward_trend_value": 0.008925877100191017, "biggest_recent_change": 0.20191895691411332},
{"total_number_of_episodes": 25036, "number_of_timesteps": 6453957, "per_episode_reward": -67.44, "episode_reward_trend_value": 0.008941607988704765, "biggest_recent_change": 0.20191895691411332},
{"total_number_of_episodes": 25046, "number_of_timesteps": 6459149, "per_episode_reward": -67.41, "episode_reward_trend_value": 0.007918533390463108, "biggest_recent_change": 0.20191895691411332},
{"total_number_of_episodes": 25056, "number_of_timesteps": 6464116, "per_episode_reward": -67.4, "episode_reward_trend_value": 0.0075426117901413485, "biggest_recent_change": 0.20191895691411332},
{"total_number_of_episodes": 25066, "number_of_timesteps": 6466114, "per_episode_reward": -67.38, "episode_reward_trend_value": 0.007650011604900126, "biggest_recent_change": 0.20191895691411332},
{"total_number_of_episodes": 25076, "number_of_timesteps": 6469621, "per_episode_reward": -67.33, "episode_reward_trend_value": 0.005908973602492848, "biggest_recent_change": 0.1286450712300251},
{"total_number_of_episodes": 25086, "number_of_timesteps": 6473669, "per_episode_reward": -67.24, "episode_reward_trend_value": 0.006434768844910207, "biggest_recent_change": 0.1286450712300251},
{"total_number_of_episodes": 25096, "number_of_timesteps": 6477943, "per_episode_reward": -66.97, "episode_reward_trend_value": 0.008738070780894386, "biggest_recent_change": 0.27127988861688834},
{"total_number_of_episodes": 25106, "number_of_timesteps": 6483602, "per_episode_reward": -66.87, "episode_reward_trend_value": 0.00872003370893787, "biggest_recent_change": 0.27127988861688834},
{"total_number_of_episodes": 25116, "number_of_timesteps": 6488126, "per_episode_reward": -66.76, "episode_reward_trend_value": 0.008481821881711465, "biggest_recent_change": 0.27127988861688834},
{"total_number_of_episodes": 25126, "number_of_timesteps": 6493321, "per_episode_reward": -66.66, "episode_reward_trend_value": 0.00859941122465276, "biggest_recent_change": 0.27127988861688834},
{"total_number_of_episodes": 25136, "number_of_timesteps": 6499862, "per_episode_reward": -66.6, "episode_reward_trend_value": 0.009023179630229725, "biggest_recent_change": 0.27127988861688834},
{"total_number_of_episodes": 25146, "number_of_timesteps": 6504800, "per_episode_reward": -66.54, "episode_reward_trend_value": 0.00947132774879833, "biggest_recent_change": 0.27127988861688834},
{"total_number_of_episodes": 25157, "number_of_timesteps": 6510209, "per_episode_reward": -66.5, "episode_reward_trend_value": 0.009710954783771954, "biggest_recent_change": 0.27127988861688834},
{"total_number_of_episodes": 25167, "number_of_timesteps": 6514901, "per_episode_reward": -66.47, "episode_reward_trend_value": 0.009564221222069274, "biggest_recent_change": 0.27127988861688834},
{"total_number_of_episodes": 25177, "number_of_timesteps": 6518281, "per_episode_reward": -66.41, "episode_reward_trend_value": 0.009257086016932686, "biggest_recent_change": 0.27127988861688834},
{"total_number_of_episodes": 25187, "number_of_timesteps": 6521709, "per_episode_reward": -66.35, "episode_reward_trend_value": 0.0068455439325126755, "biggest_recent_change": 0.10720600677964853},
{"total_number_of_episodes": 25198, "number_of_timesteps": 6523265, "per_episode_reward": -66.27, "episode_reward_trend_value": 0.006729017199873353, "biggest_recent_change": 0.10720600677964853},
{"total_number_of_episodes": 25208, "number_of_timesteps": 6527355, "per_episode_reward": -66.23, "episode_reward_trend_value": 0.005972657842664356, "biggest_recent_change": 0.0995819347889011},
{"total_number_of_episodes": 25218, "number_of_timesteps": 6530463, "per_episode_reward": -66.17, "episode_reward_trend_value": 0.005485792121325675, "biggest_recent_change": 0.08799124158011296},
{"total_number_of_episodes": 25228, "number_of_timesteps": 6532663, "per_episode_reward": -65.97, "episode_reward_trend_value": 0.006928509712961134, "biggest_recent_change": 0.1987353328655388},
{"total_number_of_episodes": 25238, "number_of_timesteps": 6535028, "per_episode_reward": -65.8, "episode_reward_trend_value": 0.008251516512511613, "biggest_recent_change": 0.1987353328655388},
{"total_number_of_episodes": 25248, "number_of_timesteps": 6537186, "per_episode_reward": -65.67, "episode_reward_trend_value": 0.009285629919854916, "biggest_recent_change": 0.1987353328655388},
{"total_number_of_episodes": 25258, "number_of_timesteps": 6540015, "per_episode_reward": -65.52, "episode_reward_trend_value": 0.01054451148822532, "biggest_recent_change": 0.1987353328655388},
{"total_number_of_episodes": 25268, "number_of_timesteps": 6543215, "per_episode_reward": -65.44, "episode_reward_trend_value": 0.010713016620833255, "biggest_recent_change": 0.1987353328655388},
{"total_number_of_episodes": 25278, "number_of_timesteps": 6546811, "per_episode_reward": -65.32, "episode_reward_trend_value": 0.011509024734393513, "biggest_recent_change": 0.1987353328655388},
{"total_number_of_episodes": 25288, "number_of_timesteps": 6551457, "per_episode_reward": -65.16, "episode_reward_trend_value": 0.012252701282282726, "biggest_recent_change": 0.1987353328655388},
{"total_number_of_episodes": 25298, "number_of_timesteps": 6559101, "per_episode_reward": -65.13, "episode_reward_trend_value": 0.012168935598822215, "biggest_recent_change": 0.1987353328655388},
{"total_number_of_episodes": 25309, "number_of_timesteps": 6565399, "per_episode_reward": -65.02, "episode_reward_trend_value": 0.012838803544937763, "biggest_recent_change": 0.1987353328655388},
{"total_number_of_episodes": 25319, "number_of_timesteps": 6572879, "per_episode_reward": -64.96, "episode_reward_trend_value": 0.01121388220276837, "biggest_recent_change": 0.17102107752899087},
{"total_number_of_episodes": 25329, "number_of_timesteps": 6580964, "per_episode_reward": -64.89, "episode_reward_trend_value": 0.010074013744302274, "biggest_recent_change": 0.15492213089014228},
{"total_number_of_episodes": 25340, "number_of_timesteps": 6588634, "per_episode_reward": -64.79, "episode_reward_trend_value": 0.00970380952769653, "biggest_recent_change": 0.15492213089014228},
{"total_number_of_episodes": 25350, "number_of_timesteps": 6593557, "per_episode_reward": -64.72, "episode_reward_trend_value": 0.008930492028519805, "biggest_recent_change": 0.15492213089014228},
{"total_number_of_episodes": 25360, "number_of_timesteps": 6598581, "per_episode_reward": -64.66, "episode_reward_trend_value": 0.008694482175679575, "biggest_recent_change": 0.15492213089014228},
{"total_number_of_episodes": 25370, "number_of_timesteps": 6607768, "per_episode_reward": -64.48, "episode_reward_trend_value": 0.009284497007569491, "biggest_recent_change": 0.17898316610960308},
{"total_number_of_episodes": 25380, "number_of_timesteps": 6613317, "per_episode_reward": -64.43, "episode_reward_trend_value": 0.008125326649313378, "biggest_recent_change": 0.17898316610960308},
{"total_number_of_episodes": 25390, "number_of_timesteps": 6617738, "per_episode_reward": -64.35, "episode_reward_trend_value": 0.008635994892973998, "biggest_recent_change": 0.17898316610960308},
{"total_number_of_episodes": 25400, "number_of_timesteps": 6623724, "per_episode_reward": -64.21, "episode_reward_trend_value": 0.008999204598507997, "biggest_recent_change": 0.17898316610960308},
{"total_number_of_episodes": 25410, "number_of_timesteps": 6630850, "per_episode_reward": -64.03, "episode_reward_trend_value": 0.01037563769460503, "biggest_recent_change": 0.17898316610960308},
{"total_number_of_episodes": 25420, "number_of_timesteps": 6635765, "per_episode_reward": -63.95, "episode_reward_trend_value": 0.01047183123896534, "biggest_recent_change": 0.17898316610960308},
{"total_number_of_episodes": 25430, "number_of_timesteps": 6640973, "per_episode_reward": -63.81, "episode_reward_trend_value": 0.010911621304173025, "biggest_recent_change": 0.17898316610960308},
{"total_number_of_episodes": 25441, "number_of_timesteps": 6647001, "per_episode_reward": -63.7, "episode_reward_trend_value": 0.011302619642944637, "biggest_recent_change": 0.17898316610960308},
{"total_number_of_episodes": 25451, "number_of_timesteps": 6653008, "per_episode_reward": -63.61, "episode_reward_trend_value": 0.011687008951067194, "biggest_recent_change": 0.17898316610960308},
{"total_number_of_episodes": 25461, "number_of_timesteps": 6659795, "per_episode_reward": -63.57, "episode_reward_trend_value": 0.010080235368022746, "biggest_recent_change": 0.17637139071902652},
{"total_number_of_episodes": 25471, "number_of_timesteps": 6662315, "per_episode_reward": -63.48, "episode_reward_trend_value": 0.010568098495114243, "biggest_recent_change": 0.17637139071902652},
{"total_number_of_episodes": 25482, "number_of_timesteps": 6668493, "per_episode_reward": -63.36, "episode_reward_trend_value": 0.01102809513531658, "biggest_recent_change": 0.17637139071902652},
{"total_number_of_episodes": 25492, "number_of_timesteps": 6670727, "per_episode_reward": -63.19, "episode_reward_trend_value": 0.011265503803264052, "biggest_recent_change": 0.17637139071902652},
{"total_number_of_episodes": 25502, "number_of_timesteps": 6674119, "per_episode_reward": -63.06, "episode_reward_trend_value": 0.010724978317661598, "biggest_recent_change": 0.17010778863215137},
{"total_number_of_episodes": 25512, "number_of_timesteps": 6678215, "per_episode_reward": -62.96, "episode_reward_trend_value": 0.011069864330103565, "biggest_recent_change": 0.17010778863215137},
{"total_number_of_episodes": 25522, "number_of_timesteps": 6683400, "per_episode_reward": -62.9, "episode_reward_trend_value": 0.010165922695931645, "biggest_recent_change": 0.17010778863215137},
{"total_number_of_episodes": 25532, "number_of_timesteps": 6690032, "per_episode_reward": -62.79, "episode_reward_trend_value": 0.01008965350171983, "biggest_recent_change": 0.17010778863215137},
{"total_number_of_episodes": 25542, "number_of_timesteps": 6694142, "per_episode_reward": -62.72, "episode_reward_trend_value": 0.009853176895331156, "biggest_recent_change": 0.17010778863215137},
{"total_number_of_episodes": 25552, "number_of_timesteps": 6698884, "per_episode_reward": -62.65, "episode_reward_trend_value": 0.010263179980807991, "biggest_recent_change": 0.17010778863215137},
{"total_number_of_episodes": 25562, "number_of_timesteps": 6702945, "per_episode_reward": -62.58, "episode_reward_trend_value": 0.009971184974642947, "biggest_recent_change": 0.17010778863215137},
{"total_number_of_episodes": 25572, "number_of_timesteps": 6705137, "per_episode_reward": -62.52, "episode_reward_trend_value": 0.009371941421228849, "biggest_recent_change": 0.17010778863215137},
{"total_number_of_episodes": 25582, "number_of_timesteps": 6707198, "per_episode_reward": -62.44, "episode_reward_trend_value": 0.008308965730558605, "biggest_recent_change": 0.1277240970148057},
{"total_number_of_episodes": 25592, "number_of_timesteps": 6708501, "per_episode_reward": -62.39, "episode_reward_trend_value": 0.007484313846859753, "biggest_recent_change": 0.10813007637924699},
{"total_number_of_episodes": 25602, "number_of_timesteps": 6712548, "per_episode_reward": -62.29, "episode_reward_trend_value": 0.00738498986425537, "biggest_recent_change": 0.10404590538202996},
{"total_number_of_episodes": 25612, "number_of_timesteps": 6714298, "per_episode_reward": -62.18, "episode_reward_trend_value": 0.00798586170013367, "biggest_recent_change": 0.1136221589297719},
{"total_number_of_episodes": 25622, "number_of_timesteps": 6717529, "per_episode_reward": -62.07, "episode_reward_trend_value": 0.008047061136322024, "biggest_recent_change": 0.1136221589297719},
{"total_number_of_episodes": 25632, "number_of_timesteps": 6720619, "per_episode_reward": -62.01, "episode_reward_trend_value": 0.007878452882279893, "biggest_recent_change": 0.1136221589297719},
{"total_number_of_episodes": 25642, "number_of_timesteps": 6726588, "per_episode_reward": -61.86, "episode_reward_trend_value": 0.008799560515556396, "biggest_recent_change": 0.15417350832340304},
{"total_number_of_episodes": 25653, "number_of_timesteps": 6728040, "per_episode_reward": -61.8, "episode_reward_trend_value": 0.008726859070364332, "biggest_recent_change": 0.15417350832340304},
{"total_number_of_episodes": 25663, "number_of_timesteps": 6732478, "per_episode_reward": -61.7, "episode_reward_trend_value": 0.009077414336974322, "biggest_recent_change": 0.15417350832340304},
{"total_number_of_episodes": 25673, "number_of_timesteps": 6739203, "per_episode_reward": -61.61, "episode_reward_trend_value": 0.009213665004175987, "biggest_recent_change": 0.15417350832340304},
{"total_number_of_episodes": 25683, "number_of_timesteps": 6743216, "per_episode_reward": -61.44, "episode_reward_trend_value": 0.01057828794836458, "biggest_recent_change": 0.1763214924588823},
{"total_number_of_episodes": 25693, "number_of_timesteps": 6747571, "per_episode_reward": -61.3, "episode_reward_trend_value": 0.010972463531989341, "biggest_recent_change": 0.1763214924588823},
{"total_number_of_episodes": 25703, "number_of_timesteps": 6754935, "per_episode_reward": -61.19, "episode_reward_trend_value": 0.010982679552355832, "biggest_recent_change": 0.1763214924588823},
{"total_number_of_episodes": 25713, "number_of_timesteps": 6759545, "per_episode_reward": -61.16, "episode_reward_trend_value": 0.010117245069029617, "biggest_recent_change": 0.1763214924588823},
{"total_number_of_episodes": 25724, "number_of_timesteps": 6763464, "per_episode_reward": -61.11, "episode_reward_trend_value": 0.01003856176840385, "biggest_recent_change": 0.1763214924588823},
{"total_number_of_episodes": 25734, "number_of_timesteps": 6768340, "per_episode_reward": -61.03, "episode_reward_trend_value": 0.009203157499588678, "biggest_recent_change": 0.1763214924588823},
{"total_number_of_episodes": 25745, "number_of_timesteps": 6773104, "per_episode_reward": -60.94, "episode_reward_trend_value": 0.009527012624839178, "biggest_recent_change": 0.1763214924588823},
{"total_number_of_episodes": 25755, "number_of_timesteps": 6776633, "per_episode_reward": -60.78, "episode_reward_trend_value": 0.010251419843031722, "biggest_recent_change": 0.1763214924588823},
{"total_number_of_episodes": 25767, "number_of_timesteps": 6781346, "per_episode_reward": -60.7, "episode_reward_trend_value": 0.010139645704518013, "biggest_recent_change": 0.1763214924588823},
{"total_number_of_episodes": 25778, "number_of_timesteps": 6784076, "per_episode_reward": -60.6, "episode_reward_trend_value": 0.00932242483385887, "biggest_recent_change": 0.1617692964920181},
{"total_number_of_episodes": 25788, "number_of_timesteps": 6789344, "per_episode_reward": -60.54, "episode_reward_trend_value": 0.00852949128760743, "biggest_recent_change": 0.1617692964920181},
{"total_number_of_episodes": 25798, "number_of_timesteps": 6796948, "per_episode_reward": -60.49, "episode_reward_trend_value": 0.007808786258578079, "biggest_recent_change": 0.1617692964920181},
{"total_number_of_episodes": 25808, "number_of_timesteps": 6803839, "per_episode_reward": -60.42, "episode_reward_trend_value": 0.008232296168698541, "biggest_recent_change": 0.1617692964920181},
{"total_number_of_episodes": 25818, "number_of_timesteps": 6810627, "per_episode_reward": -60.32, "episode_reward_trend_value": 0.008817352897199902, "biggest_recent_change": 0.1617692964920181},
{"total_number_of_episodes": 25828, "number_of_timesteps": 6816135, "per_episode_reward": -60.15, "episode_reward_trend_value": 0.009790166727192053, "biggest_recent_change": 0.166540368829331},
{"total_number_of_episodes": 25838, "number_of_timesteps": 6823132, "per_episode_reward": -60.09, "episode_reward_trend_value": 0.009405084334941687, "biggest_recent_change": 0.166540368829331},
{"total_number_of_episodes": 25848, "number_of_timesteps": 6829149, "per_episode_reward": -60.05, "episode_reward_trend_value": 0.008070981198990444, "biggest_recent_change": 0.166540368829331},
{"total_number_of_episodes": 25858, "number_of_timesteps": 6835103, "per_episode_reward": -59.99, "episode_reward_trend_value": 0.007953936630794326, "biggest_recent_change": 0.166540368829331},
{"total_number_of_episodes": 25869, "number_of_timesteps": 6839441, "per_episode_reward": -59.95, "episode_reward_trend_value": 0.007182463939083306, "biggest_recent_change": 0.166540368829331},
{"total_number_of_episodes": 25879, "number_of_timesteps": 6844437, "per_episode_reward": -59.77, "episode_reward_trend_value": 0.008521896058840638, "biggest_recent_change": 0.1838515920866115},
{"total_number_of_episodes": 25890, "number_of_timesteps": 6851353, "per_episode_reward": -59.7, "episode_reward_trend_value": 0.008785942517170436, "biggest_recent_change": 0.1838515920866115},
{"total_number_of_episodes": 25900, "number_of_timesteps": 6855446, "per_episode_reward": -59.63, "episode_reward_trend_value": 0.008773095563301641, "biggest_recent_change": 0.1838515920866115},
{"total_number_of_episodes": 25910, "number_of_timesteps": 6859390, "per_episode_reward": -59.51, "episode_reward_trend_value": 0.008999589760635177, "biggest_recent_change": 0.1838515920866115},
{"total_number_of_episodes": 25920, "number_of_timesteps": 6864349, "per_episode_reward": -59.47, "episode_reward_trend_value": 0.0076053392765768665, "biggest_recent_change": 0.1838515920866115},
{"total_number_of_episodes": 25931, "number_of_timesteps": 6868607, "per_episode_reward": -59.41, "episode_reward_trend_value": 0.007612391780549406, "biggest_recent_change": 0.1838515920866115},
{"total_number_of_episodes": 25942, "number_of_timesteps": 6872842, "per_episode_reward": -59.19, "episode_reward_trend_value": 0.009570143669663543, "biggest_recent_change": 0.21789768427667866},
{"total_number_of_episodes": 25952, "number_of_timesteps": 6876026, "per_episode_reward": -59.02, "episode_reward_trend_value": 0.010681511909491724, "biggest_recent_change": 0.21789768427667866},
{"total_number_of_episodes": 25963, "number_of_timesteps": 6880963, "per_episode_reward": -58.97, "episode_reward_trend_value": 0.01093021392027001, "biggest_recent_change": 0.21789768427667866},
{"total_number_of_episodes": 25973, "number_of_timesteps": 6883163, "per_episode_reward": -58.95, "episode_reward_trend_value": 0.009084725565083256, "biggest_recent_change": 0.21789768427667866},
{"total_number_of_episodes": 25983, "number_of_timesteps": 6887279, "per_episode_reward": -58.81, "episode_reward_trend_value": 0.009816373627875347, "biggest_recent_change": 0.21789768427667866},
{"total_number_of_episodes": 25993, "number_of_timesteps": 6889716, "per_episode_reward": -58.73, "episode_reward_trend_value": 0.010000997278250167, "biggest_recent_change": 0.21789768427667866},
{"total_number_of_episodes": 26004, "number_of_timesteps": 6893075, "per_episode_reward": -58.51, "episode_reward_trend_value": 0.011121731704342528, "biggest_recent_change": 0.2210511848361989},
{"total_number_of_episodes": 26014, "number_of_timesteps": 6897139, "per_episode_reward": -58.46, "episode_reward_trend_value": 0.01122728554938143, "biggest_recent_change": 0.2210511848361989},
{"total_number_of_episodes": 26024, "number_of_timesteps": 6899896, "per_episode_reward": -58.37, "episode_reward_trend_value": 0.011583982231800544, "biggest_recent_change": 0.2210511848361989},
{"total_number_of_episodes": 26034, "number_of_timesteps": 6903206, "per_episode_reward": -58.3, "episode_reward_trend_value": 0.009883672748462243, "biggest_recent_change": 0.2210511848361989},
{"total_number_of_episodes": 26044, "number_of_timesteps": 6904856, "per_episode_reward": -58.22, "episode_reward_trend_value": 0.008930486067336416, "biggest_recent_change": 0.2210511848361989},
{"total_number_of_episodes": 26054, "number_of_timesteps": 6906594, "per_episode_reward": -58.18, "episode_reward_trend_value": 0.008711838405083307, "biggest_recent_change": 0.2210511848361989},
{"total_number_of_episodes": 26064, "number_of_timesteps": 6909017, "per_episode_reward": -58.05, "episode_reward_trend_value": 0.010054351584907945, "biggest_recent_change": 0.2210511848361989},
{"total_number_of_episodes": 26075, "number_of_timesteps": 6913316, "per_episode_reward": -57.89, "episode_reward_trend_value": 0.010249503572212465, "biggest_recent_change": 0.2210511848361989},
{"total_number_of_episodes": 26085, "number_of_timesteps": 6917431, "per_episode_reward": -57.82, "episode_reward_trend_value": 0.010067854024631926, "biggest_recent_change": 0.2210511848361989},
{"total_number_of_episodes": 26095, "number_of_timesteps": 6919969, "per_episode_reward": -57.75, "episode_reward_trend_value": 0.008342350949065273, "biggest_recent_change": 0.15685433390849113},
{"total_number_of_episodes": 26105, "number_of_timesteps": 6924935, "per_episode_reward": -57.68, "episode_reward_trend_value": 0.008634305684712176, "biggest_recent_change": 0.15685433390849113},
{"total_number_of_episodes": 26115, "number_of_timesteps": 6929823, "per_episode_reward": -57.5, "episode_reward_trend_value": 0.009597620078905954, "biggest_recent_change": 0.1756070676858883},

{"total_number_of_episodes": 26125, "number_of_timesteps": 6937276, "per_episode_reward": -57.42, "episode_reward_trend_value": 0.009831542257829302, "biggest_recent_change": 0.1756070676858883},
{"total_number_of_episodes": 26135, "number_of_timesteps": 6942302, "per_episode_reward": -57.36, "episode_reward_trend_value": 0.009577928780252638, "biggest_recent_change": 0.1756070676858883},
{"total_number_of_episodes": 26145, "number_of_timesteps": 6947936, "per_episode_reward": -57.18, "episode_reward_trend_value": 0.011153938902825348, "biggest_recent_change": 0.17788487424437704},
{"total_number_of_episodes": 26155, "number_of_timesteps": 6953835, "per_episode_reward": -57.1, "episode_reward_trend_value": 0.010515371392710273, "biggest_recent_change": 0.17788487424437704},
{"total_number_of_episodes": 26165, "number_of_timesteps": 6957622, "per_episode_reward": -57.05, "episode_reward_trend_value": 0.00928856853502214, "biggest_recent_change": 0.17788487424437704},
{"total_number_of_episodes": 26175, "number_of_timesteps": 6963008, "per_episode_reward": -56.97, "episode_reward_trend_value": 0.00948694043564918, "biggest_recent_change": 0.17788487424437704},
{"total_number_of_episodes": 26186, "number_of_timesteps": 6969667, "per_episode_reward": -56.91, "episode_reward_trend_value": 0.009368056541695246, "biggest_recent_change": 0.17788487424437704},
{"total_number_of_episodes": 26196, "number_of_timesteps": 6976524, "per_episode_reward": -56.83, "episode_reward_trend_value": 0.009459565295103308, "biggest_recent_change": 0.17788487424437704},
{"total_number_of_episodes": 26206, "number_of_timesteps": 6982280, "per_episode_reward": -56.78, "episode_reward_trend_value": 0.00806209401006836, "biggest_recent_change": 0.17788487424437704},
{"total_number_of_episodes": 26216, "number_of_timesteps": 6988190, "per_episode_reward": -56.72, "episode_reward_trend_value": 0.007700274924861361, "biggest_recent_change": 0.17788487424437704},
{"total_number_of_episodes": 26226, "number_of_timesteps": 6992507, "per_episode_reward": -56.64, "episode_reward_trend_value": 0.00800086966989121, "biggest_recent_change": 0.17788487424437704},
{"total_number_of_episodes": 26236, "number_of_timesteps": 6996609, "per_episode_reward": -56.57, "episode_reward_trend_value": 0.00683276682243093, "biggest_recent_change": 0.08674555751019142},
{"total_number_of_episodes": 26246, "number_of_timesteps": 7002501, "per_episode_reward": -56.55, "episode_reward_trend_value": 0.006067193471153192, "biggest_recent_change": 0.08674555751019142},
{"total_number_of_episodes": 26256, "number_of_timesteps": 7008407, "per_episode_reward": -56.48, "episode_reward_trend_value": 0.006368456793879397, "biggest_recent_change": 0.08674555751019142},
{"total_number_of_episodes": 26266, "number_of_timesteps": 7013570, "per_episode_reward": -56.26, "episode_reward_trend_value": 0.00790745930561406, "biggest_recent_change": 0.22525578356631115},
{"total_number_of_episodes": 26276, "number_of_timesteps": 7017145, "per_episode_reward": -56.21, "episode_reward_trend_value": 0.007844298242054432, "biggest_recent_change": 0.22525578356631115},
{"total_number_of_episodes": 26286, "number_of_timesteps": 7021475, "per_episode_reward": -56.08, "episode_reward_trend_value": 0.008271840769242703, "biggest_recent_change": 0.22525578356631115},
{"total_number_of_episodes": 26296, "number_of_timesteps": 7024378, "per_episode_reward": -55.99, "episode_reward_trend_value": 0.00876713140568452, "biggest_recent_change": 0.22525578356631115},
{"total_number_of_episodes": 26306, "number_of_timesteps": 7027894, "per_episode_reward": -55.93, "episode_reward_trend_value": 0.008841539584893907, "biggest_recent_change": 0.22525578356631115},
{"total_number_of_episodes": 26316, "number_of_timesteps": 7030428, "per_episode_reward": -55.89, "episode_reward_trend_value": 0.008353013968611201, "biggest_recent_change": 0.22525578356631115},
{"total_number_of_episodes": 26327, "number_of_timesteps": 7034083, "per_episode_reward": -55.8, "episode_reward_trend_value": 0.00846984220612978, "biggest_recent_change": 0.22525578356631115},
{"total_number_of_episodes": 26337, "number_of_timesteps": 7037088, "per_episode_reward": -55.7, "episode_reward_trend_value": 0.009501415378300099, "biggest_recent_change": 0.22525578356631115},

{"total_number_of_episodes": 26347, "number_of_timesteps": 7040467, "per_episode_reward": -55.58, "episode_reward_trend_value": 0.010058192342262847, "biggest_recent_change": 0.22525578356631115},
{"total_number_of_episodes": 26357, "number_of_timesteps": 7044766, "per_episode_reward": -55.41, "episode_reward_trend_value": 0.00938068177307664, "biggest_recent_change": 0.16427983233955246},
{"total_number_of_episodes": 26367, "number_of_timesteps": 7050314, "per_episode_reward": -55.33, "episode_reward_trend_value": 0.009781421988941948, "biggest_recent_change": 0.16427983233955246},
{"total_number_of_episodes": 26377, "number_of_timesteps": 7057725, "per_episode_reward": -55.22, "episode_reward_trend_value": 0.00956008402187207, "biggest_recent_change": 0.16427983233955246},
{"total_number_of_episodes": 26387, "number_of_timesteps": 7063889, "per_episode_reward": -55.12, "episode_reward_trend_value": 0.009661202136274482, "biggest_recent_change": 0.16427983233955246},
{"total_number_of_episodes": 26397, "number_of_timesteps": 7069889, "per_episode_reward": -55.06, "episode_reward_trend_value": 0.009633593016620996, "biggest_recent_change": 0.16427983233955246},
{"total_number_of_episodes": 26407, "number_of_timesteps": 7075605, "per_episode_reward": -55.0, "episode_reward_trend_value": 0.009908003629053358, "biggest_recent_change": 0.16427983233955246},
{"total_number_of_episodes": 26417, "number_of_timesteps": 7084117, "per_episode_reward": -54.96, "episode_reward_trend_value": 0.009330171086299622, "biggest_recent_change": 0.16427983233955246},
{"total_number_of_episodes": 26427, "number_of_timesteps": 7090705, "per_episode_reward": -54.93, "episode_reward_trend_value": 0.008576161518362824, "biggest_recent_change": 0.16427983233955246},
{"total_number_of_episodes": 26437, "number_of_timesteps": 7098424, "per_episode_reward": -54.83, "episode_reward_trend_value": 0.008222831818199931, "biggest_recent_change": 0.16427983233955246},
{"total_number_of_episodes": 26448, "number_of_timesteps": 7100757, "per_episode_reward": -54.68, "episode_reward_trend_value": 0.008124958806667514, "biggest_recent_change": 0.1554712613016349},
{"total_number_of_episodes": 26458, "number_of_timesteps": 7107519, "per_episode_reward": -54.64, "episode_reward_trend_value": 0.0075863463824844424, "biggest_recent_change": 0.1554712613016349},
{"total_number_of_episodes": 26468, "number_of_timesteps": 7113374, "per_episode_reward": -54.53, "episode_reward_trend_value": 0.00768013498975364, "biggest_recent_change": 0.1554712613016349},
{"total_number_of_episodes": 26478, "number_of_timesteps": 7118029, "per_episode_reward": -54.48, "episode_reward_trend_value": 0.007098234384635698, "biggest_recent_change": 0.1554712613016349},
{"total_number_of_episodes": 26488, "number_of_timesteps": 7124332, "per_episode_reward": -54.42, "episode_reward_trend_value": 0.007170121739574774, "biggest_recent_change": 0.1554712613016349},
{"total_number_of_episodes": 26498, "number_of_timesteps": 7131292, "per_episode_reward": -54.36, "episode_reward_trend_value": 0.00707806475045116, "biggest_recent_change": 0.1554712613016349},
{"total_number_of_episodes": 26508, "number_of_timesteps": 7137017, "per_episode_reward": -54.32, "episode_reward_trend_value": 0.0071901565530884184, "biggest_recent_change": 0.1554712613016349},
{"total_number_of_episodes": 26518, "number_of_timesteps": 7142364, "per_episode_reward": -54.23, "episode_reward_trend_value": 0.007707307631745329, "biggest_recent_change": 0.1554712613016349},
{"total_number_of_episodes": 26528, "number_of_timesteps": 7148306, "per_episode_reward": -54.11, "episode_reward_trend_value": 0.008091147501551255, "biggest_recent_change": 0.1554712613016349},
{"total_number_of_episodes": 26538, "number_of_timesteps": 7155289, "per_episode_reward": -54.05, "episode_reward_trend_value": 0.006967506163414327, "biggest_recent_change": 0.12641161778643806},
{"total_number_of_episodes": 26548, "number_of_timesteps": 7164440, "per_episode_reward": -53.98, "episode_reward_trend_value": 0.007360615792053614, "biggest_recent_change": 0.12641161778643806},
{"total_number_of_episodes": 26558, "number_of_timesteps": 7169804, "per_episode_reward": -53.94, "episode_reward_trend_value": 0.006525663841265189, "biggest_recent_change": 0.12641161778643806},
{"total_number_of_episodes": 26568, "number_of_timesteps": 7174088, "per_episode_reward": -53.82, "episode_reward_trend_value": 0.0073556270015766746, "biggest_recent_change": 0.12641161778643806},
{"total_number_of_episodes": 26578, "number_of_timesteps": 7178082, "per_episode_reward": -53.75, "episode_reward_trend_value": 0.007358963019891638, "biggest_recent_change": 0.12641161778643806},
{"total_number_of_episodes": 26588, "number_of_timesteps": 7184069, "per_episode_reward": -53.69, "episode_reward_trend_value": 0.007414845960233724, "biggest_recent_change": 0.12641161778643806},
{"total_number_of_episodes": 26598, "number_of_timesteps": 7190303, "per_episode_reward": -53.66, "episode_reward_trend_value": 0.007339637683627921, "biggest_recent_change": 0.12641161778643806},
{"total_number_of_episodes": 26608, "number_of_timesteps": 7196594, "per_episode_reward": -53.55, "episode_reward_trend_value": 0.007630085355475479, "biggest_recent_change": 0.12641161778643806},
{"total_number_of_episodes": 26618, "number_of_timesteps": 7199857, "per_episode_reward": -53.47, "episode_reward_trend_value": 0.007105777914819494, "biggest_recent_change": 0.12583706957614282},
{"total_number_of_episodes": 26628, "number_of_timesteps": 7205673, "per_episode_reward": -53.37, "episode_reward_trend_value": 0.007601800060034631, "biggest_recent_change": 0.12583706957614282},
{"total_number_of_episodes": 26638, "number_of_timesteps": 7210113, "per_episode_reward": -53.38, "episode_reward_trend_value": 0.0066876213629086575, "biggest_recent_change": 0.12583706957614282},
{"total_number_of_episodes": 26648, "number_of_timesteps": 7214363, "per_episode_reward": -53.25, "episode_reward_trend_value": 0.007714292351865895, "biggest_recent_change": 0.12932348383260717},
{"total_number_of_episodes": 26658, "number_of_timesteps": 7221294, "per_episode_reward": -53.11, "episode_reward_trend_value": 0.007854194989265848, "biggest_recent_change": 0.1384283069421386},
{"total_number_of_episodes": 26669, "number_of_timesteps": 7226292, "per_episode_reward": -52.98, "episode_reward_trend_value": 0.008533232132046464, "biggest_recent_change": 0.1384283069421386},
{"total_number_of_episodes": 26679, "number_of_timesteps": 7230432, "per_episode_reward": -52.94, "episode_reward_trend_value": 0.008307267159889796, "biggest_recent_change": 0.1384283069421386},
{"total_number_of_episodes": 26689, "number_of_timesteps": 7235241, "per_episode_reward": -52.86, "episode_reward_trend_value": 0.008798227474252388, "biggest_recent_change": 0.1384283069421386},
{"total_number_of_episodes": 26699, "number_of_timesteps": 7239567, "per_episode_reward": -52.83, "episode_reward_trend_value": 0.007999442647725235, "biggest_recent_change": 0.1384283069421386},
{"total_number_of_episodes": 26710, "number_of_timesteps": 7245849, "per_episode_reward": -52.72, "episode_reward_trend_value": 0.008301586032706452, "biggest_recent_change": 0.1384283069421386},
{"total_number_of_episodes": 26720, "number_of_timesteps": 7249058, "per_episode_reward": -52.64, "episode_reward_trend_value": 0.008110159590096009, "biggest_recent_change": 0.1384283069421386},
{"total_number_of_episodes": 26730, "number_of_timesteps": 7255759, "per_episode_reward": -52.47, "episode_reward_trend_value": 0.010038394076358988, "biggest_recent_change": 0.1636082507102472},
{"total_number_of_episodes": 26740, "number_of_timesteps": 7259762, "per_episode_reward": -52.31, "episode_reward_trend_value": 0.010445674245830044, "biggest_recent_change": 0.1659786990850023},
{"total_number_of_episodes": 26750, "number_of_timesteps": 7264624, "per_episode_reward": -52.28, "episode_reward_trend_value": 0.009172151895347725, "biggest_recent_change": 0.1659786990850023},
{"total_number_of_episodes": 26761, "number_of_timesteps": 7269612, "per_episode_reward": -52.27, "episode_reward_trend_value": 0.007998829888749349, "biggest_recent_change": 0.1659786990850023},
{"total_number_of_episodes": 26771, "number_of_timesteps": 7271904, "per_episode_reward": -52.2, "episode_reward_trend_value": 0.008244893691361692, "biggest_recent_change": 0.1659786990850023},
{"total_number_of_episodes": 26782, "number_of_timesteps": 7274541, "per_episode_reward": -52.16, "episode_reward_trend_value": 0.007875150174461491, "biggest_recent_change": 0.1659786990850023},
{"total_number_of_episodes": 26792, "number_of_timesteps": 7279075, "per_episode_reward": -52.09, "episode_reward_trend_value": 0.008155499433258879, "biggest_recent_change": 0.1659786990850023},
{"total_number_of_episodes": 26802, "number_of_timesteps": 7285688, "per_episode_reward": -52.04, "episode_reward_trend_value": 0.007585981734478981, "biggest_recent_change": 0.1659786990850023},
{"total_number_of_episodes": 26812, "number_of_timesteps": 7288236, "per_episode_reward": -51.94, "episode_reward_trend_value": 0.007806723418316214, "biggest_recent_change": 0.1659786990850023},
{"total_number_of_episodes": 26823, "number_of_timesteps": 7295011, "per_episode_reward": -51.86, "episode_reward_trend_value": 0.0068230212574405865, "biggest_recent_change": 0.1659786990850023},
{"total_number_of_episodes": 26833, "number_of_timesteps": 7299534, "per_episode_reward": -51.81, "episode_reward_trend_value": 0.005493192076607616, "biggest_recent_change": 0.10162390564908463},
{"total_number_of_episodes": 26843, "number_of_timesteps": 7301924, "per_episode_reward": -51.69, "episode_reward_trend_value": 0.006600102471206999, "biggest_recent_change": 0.12343323091267422},
{"total_number_of_episodes": 26853, "number_of_timesteps": 7303640, "per_episode_reward": -51.62, "episode_reward_trend_value": 0.007222726019406957, "biggest_recent_change": 0.12343323091267422},
{"total_number_of_episodes": 26863, "number_of_timesteps": 7310960, "per_episode_reward": -51.51, "episode_reward_trend_value": 0.007704771397729439, "biggest_recent_change": 0.12343323091267422},
{"total_number_of_episodes": 26873, "number_of_timesteps": 7317452, "per_episode_reward": -51.44, "episode_reward_trend_value": 0.008006442900019313, "biggest_recent_change": 0.12343323091267422},
{"total_number_of_episodes": 26883, "number_of_timesteps": 7321778, "per_episode_reward": -51.34, "episode_reward_trend_value": 0.008335209535626751, "biggest_recent_change": 0.12343323091267422},
{"total_number_of_episodes": 26893, "number_of_timesteps": 7327652, "per_episode_reward": -51.32, "episode_reward_trend_value": 0.007999661052296384, "biggest_recent_change": 0.12343323091267422},
{"total_number_of_episodes": 26903, "number_of_timesteps": 7333655, "per_episode_reward": -51.24, "episode_reward_trend_value": 0.00776862468766808, "biggest_recent_change": 0.12343323091267422},
{"total_number_of_episodes": 26913, "number_of_timesteps": 7339170, "per_episode_reward": -51.21, "episode_reward_trend_value": 0.007186904642433628, "biggest_recent_change": 0.12343323091267422},
{"total_number_of_episodes": 26923, "number_of_timesteps": 7345323, "per_episode_reward": -51.16, "episode_reward_trend_value": 0.007298691491993895, "biggest_recent_change": 0.12343323091267422},
{"total_number_of_episodes": 26933, "number_of_timesteps": 7349777, "per_episode_reward": -50.94, "episode_reward_trend_value": 0.008305357825066612, "biggest_recent_change": 0.21403320088921873},
{"total_number_of_episodes": 26943, "number_of_timesteps": 7355326, "per_episode_reward": -50.9, "episode_reward_trend_value": 0.00797490823379808, "biggest_recent_change": 0.21403320088921873},
{"total_number_of_episodes": 26953, "number_of_timesteps": 7360975, "per_episode_reward": -50.83, "episode_reward_trend_value": 0.007572788676867187, "biggest_recent_change": 0.21403320088921873},
{"total_number_of_episodes": 26963, "number_of_timesteps": 7366083, "per_episode_reward": -50.76, "episode_reward_trend_value": 0.007455272170640054, "biggest_recent_change": 0.21403320088921873},
{"total_number_of_episodes": 26973, "number_of_timesteps": 7371901, "per_episode_reward": -50.7, "episode_reward_trend_value": 0.007138835017232105, "biggest_recent_change": 0.21403320088921873},
{"total_number_of_episodes": 26983, "number_of_timesteps": 7374150, "per_episode_reward": -50.64, "episode_reward_trend_value": 0.007504396387446377, "biggest_recent_change": 0.21403320088921873},
{"total_number_of_episodes": 26993, "number_of_timesteps": 7376764, "per_episode_reward": -50.62, "episode_reward_trend_value": 0.0067975562508302625, "biggest_recent_change": 0.21403320088921873},
{"total_number_of_episodes": 27003, "number_of_timesteps": 7381867, "per_episode_reward": -50.57, "episode_reward_trend_value": 0.007170805799941683, "biggest_recent_change": 0.21403320088921873},
{"total_number_of_episodes": 27013, "number_of_timesteps": 7385752, "per_episode_reward": -50.47, "episode_reward_trend_value": 0.007627309185677689, "biggest_recent_change": 0.21403320088921873},
{"total_number_of_episodes": 27023, "number_of_timesteps": 7392625, "per_episode_reward": -50.39, "episode_reward_trend_value": 0.006100165471796654, "biggest_recent_change": 0.09744019398669934},
{"total_number_of_episodes": 27033, "number_of_timesteps": 7396924, "per_episode_reward": -50.35, "episode_reward_trend_value": 0.006080293077868741, "biggest_recent_change": 0.09744019398669934},
{"total_number_of_episodes": 27043, "number_of_timesteps": 7401803, "per_episode_reward": -50.26, "episode_reward_trend_value": 0.006237563775095446, "biggest_recent_change": 0.09744019398669934},
{"total_number_of_episodes": 27053, "number_of_timesteps": 7409293, "per_episode_reward": -50.22, "episode_reward_trend_value": 0.00602284786419934, "biggest_recent_change": 0.09744019398669934},
{"total_number_of_episodes": 27063, "number_of_timesteps": 7415413, "per_episode_reward": -50.16, "episode_reward_trend_value": 0.0059670472801889845, "biggest_recent_change": 0.09744019398669934},
{"total_number_of_episodes": 27073, "number_of_timesteps": 7419606, "per_episode_reward": -50.12, "episode_reward_trend_value": 0.0058050530697710675, "biggest_recent_change": 0.09744019398669934},
{"total_number_of_episodes": 27083, "number_of_timesteps": 7424299, "per_episode_reward": -50.09, "episode_reward_trend_value": 0.00591342567372932, "biggest_recent_change": 0.09744019398669934},
{"total_number_of_episodes": 27093, "number_of_timesteps": 7429529, "per_episode_reward": -50.04, "episode_reward_trend_value": 0.005874976376135916, "biggest_recent_change": 0.09744019398669934},
{"total_number_of_episodes": 27103, "number_of_timesteps": 7436657, "per_episode_reward": -49.97, "episode_reward_trend_value": 0.0055395821640352155, "biggest_recent_change": 0.08520407394988183},
{"total_number_of_episodes": 27113, "number_of_timesteps": 7444983, "per_episode_reward": -49.94, "episode_reward_trend_value": 0.005032223205001114, "biggest_recent_change": 0.08520407394988183},
{"total_number_of_episodes": 27123, "number_of_timesteps": 7451640, "per_episode_reward": -49.83, "episode_reward_trend_value": 0.005744370238824024, "biggest_recent_change": 0.10845586413437758},
{"total_number_of_episodes": 27133, "number_of_timesteps": 7458444, "per_episode_reward": -49.76, "episode_reward_trend_value": 0.005577384122461224, "biggest_recent_change": 0.10845586413437758},
{"total_number_of_episodes": 27143, "number_of_timesteps": 7464452, "per_episode_reward": -49.69, "episode_reward_trend_value": 0.0059483694448181105, "biggest_recent_change": 0.10845586413437758},
{"total_number_of_episodes": 27153, "number_of_timesteps": 7468791, "per_episode_reward": -49.63, "episode_reward_trend_value": 0.005945012042420058, "biggest_recent_change": 0.10845586413437758},
{"total_number_of_episodes": 27163, "number_of_timesteps": 7474264, "per_episode_reward": -49.53, "episode_reward_trend_value": 0.00652085744672222, "biggest_recent_change": 0.10845586413437758},
{"total_number_of_episodes": 27173, "number_of_timesteps": 7478689, "per_episode_reward": -49.43, "episode_reward_trend_value": 0.007340839369469639, "biggest_recent_change": 0.10845586413437758},
{"total_number_of_episodes": 27183, "number_of_timesteps": 7484436, "per_episode_reward": -49.32, "episode_reward_trend_value": 0.008047314122242868, "biggest_recent_change": 0.11643500254655237},
{"total_number_of_episodes": 27193, "number_of_timesteps": 7490653, "per_episode_reward": -49.12, "episode_reward_trend_value": 0.009491274462420308, "biggest_recent_change": 0.19721114551360586},
{"total_number_of_episodes": 27204, "number_of_timesteps": 7496304, "per_episode_reward": -49.03, "episode_reward_trend_value": 0.010103748310784904, "biggest_recent_change": 0.19721114551360586},
{"total_number_of_episodes": 27215, "number_of_timesteps": 7505825, "per_episode_reward": -48.97, "episode_reward_trend_value": 0.009578247851941451, "biggest_recent_change": 0.19721114551360586},
{"total_number_of_episodes": 27225, "number_of_timesteps": 7513507, "per_episode_reward": -48.93, "episode_reward_trend_value": 0.009206101199638855, "biggest_recent_change": 0.19721114551360586},
{"total_number_of_episodes": 27235, "number_of_timesteps": 7519816, "per_episode_reward": -48.89, "episode_reward_trend_value": 0.008826088763471221, "biggest_recent_change": 0.19721114551360586},
{"total_number_of_episodes": 27245, "number_of_timesteps": 7526190, "per_episode_reward": -48.84, "episode_reward_trend_value": 0.008747320402021882, "biggest_recent_change": 0.19721114551360586},
{"total_number_of_episodes": 27255, "number_of_timesteps": 7532056, "per_episode_reward": -48.77, "episode_reward_trend_value": 0.008430511672678085, "biggest_recent_change": 0.19721114551360586},
{"total_number_of_episodes": 27265, "number_of_timesteps": 7538821, "per_episode_reward": -48.7, "episode_reward_trend_value": 0.008086054969520499, "biggest_recent_change": 0.19721114551360586},
{"total_number_of_episodes": 27275, "number_of_timesteps": 7544885, "per_episode_reward": -48.65, "episode_reward_trend_value": 0.007421915372845295, "biggest_recent_change": 0.19721114551360586},
{"total_number_of_episodes": 27285, "number_of_timesteps": 7552532, "per_episode_reward": -48.58, "episode_reward_trend_value": 0.006035024004488873, "biggest_recent_change": 0.08605060667967024},
{"total_number_of_episodes": 27295, "number_of_timesteps": 7557854, "per_episode_reward": -48.47, "episode_reward_trend_value": 0.006254660483078804, "biggest_recent_change": 0.10581788975276396},
{"total_number_of_episodes": 27306, "number_of_timesteps": 7566459, "per_episode_reward": -48.41, "episode_reward_trend_value": 0.006281349848865306, "biggest_recent_change": 0.10581788975276396},

{"total_number_of_episodes": 27316, "number_of_timesteps": 7570924, "per_episode_reward": -48.09, "episode_reward_trend_value": 0.009412371882279618, "biggest_recent_change": 0.31847410777728413},
{"total_number_of_episodes": 27326, "number_of_timesteps": 7577825, "per_episode_reward": -48.0, "episode_reward_trend_value": 0.00988353367646116, "biggest_recent_change": 0.31847410777728413},
{"total_number_of_episodes": 27336, "number_of_timesteps": 7584521, "per_episode_reward": -47.91, "episode_reward_trend_value": 0.010318749546751447, "biggest_recent_change": 0.31847410777728413},
{"total_number_of_episodes": 27346, "number_of_timesteps": 7589723, "per_episode_reward": -47.89, "episode_reward_trend_value": 0.009812351543671365, "biggest_recent_change": 0.31847410777728413},
{"total_number_of_episodes": 27356, "number_of_timesteps": 7595314, "per_episode_reward": -47.84, "episode_reward_trend_value": 0.009655090709196656, "biggest_recent_change": 0.31847410777728413},
{"total_number_of_episodes": 27366, "number_of_timesteps": 7603050, "per_episode_reward": -47.75, "episode_reward_trend_value": 0.009929278254537384, "biggest_recent_change": 0.31847410777728413},
{"total_number_of_episodes": 27376, "number_of_timesteps": 7610638, "per_episode_reward": -47.73, "episode_reward_trend_value": 0.009417538412839516, "biggest_recent_change": 0.31847410777728413},
{"total_number_of_episodes": 27386, "number_of_timesteps": 7617086, "per_episode_reward": -47.64, "episode_reward_trend_value": 0.009192689649568011, "biggest_recent_change": 0.31847410777728413},
{"total_number_of_episodes": 27396, "number_of_timesteps": 7623116, "per_episode_reward": -47.6, "episode_reward_trend_value": 0.008911595972144602, "biggest_recent_change": 0.31847410777728413},
{"total_number_of_episodes": 27406, "number_of_timesteps": 7629164, "per_episode_reward": -47.57, "episode_reward_trend_value": 0.005800151845786259, "biggest_recent_change": 0.09108227002629121},
{"total_number_of_episodes": 27416, "number_of_timesteps": 7636683, "per_episode_reward": -47.5, "episode_reward_trend_value": 0.005556332919771182, "biggest_recent_change": 0.09108227002629121},
{"total_number_of_episodes": 27426, "number_of_timesteps": 7643794, "per_episode_reward": -47.44, "episode_reward_trend_value": 0.005193622953210782, "biggest_recent_change": 0.08558150105832851},
{"total_number_of_episodes": 27436, "number_of_timesteps": 7651516, "per_episode_reward": -47.36, "episode_reward_trend_value": 0.005947309121865866, "biggest_recent_change": 0.08885117641546003},
{"total_number_of_episodes": 27446, "number_of_timesteps": 7657834, "per_episode_reward": -47.22, "episode_reward_trend_value": 0.006802398521770827, "biggest_recent_change": 0.1325703955451374},
{"total_number_of_episodes": 27456, "number_of_timesteps": 7664098, "per_episode_reward": -47.14, "episode_reward_trend_value": 0.0068471499864284305, "biggest_recent_change": 0.1325703955451374},
{"total_number_of_episodes": 27466, "number_of_timesteps": 7673159, "per_episode_reward": -47.09, "episode_reward_trend_value": 0.007096174388407188, "biggest_recent_change": 0.1325703955451374},
{"total_number_of_episodes": 27476, "number_of_timesteps": 7681422, "per_episode_reward": -47.03, "episode_reward_trend_value": 0.00683474086351331, "biggest_recent_change": 0.1325703955451374},
{"total_number_of_episodes": 27487, "number_of_timesteps": 7691114, "per_episode_reward": -46.95, "episode_reward_trend_value": 0.007233319320176355, "biggest_recent_change": 0.1325703955451374},
{"total_number_of_episodes": 27497, "number_of_timesteps": 7695572, "per_episode_reward": -46.91, "episode_reward_trend_value": 0.007253815272387954, "biggest_recent_change": 0.1325703955451374},
{"total_number_of_episodes": 27507, "number_of_timesteps": 7700594, "per_episode_reward": -46.86, "episode_reward_trend_value": 0.0070991309839680775, "biggest_recent_change": 0.1325703955451374},
{"total_number_of_episodes": 27517, "number_of_timesteps": 7705957, "per_episode_reward": -46.8, "episode_reward_trend_value": 0.007175547488129218, "biggest_recent_change": 0.1325703955451374},
{"total_number_of_episodes": 27527, "number_of_timesteps": 7711755, "per_episode_reward": -46.74, "episode_reward_trend_value": 0.0068151735436772914, "biggest_recent_change": 0.1325703955451374},
{"total_number_of_episodes": 27537, "number_of_timesteps": 7718088, "per_episode_reward": -46.71, "episode_reward_trend_value": 0.005733226690369659, "biggest_recent_change": 0.08536694974563375},
{"total_number_of_episodes": 27547, "number_of_timesteps": 7723403, "per_episode_reward": -46.66, "episode_reward_trend_value": 0.005326667238447413, "biggest_recent_change": 0.07413649589081928},

{"total_number_of_episodes": 27557, "number_of_timesteps": 7730279, "per_episode_reward": -46.57, "episode_reward_trend_value": 0.005745026056952204, "biggest_recent_change": 0.08639882645223906},
{"total_number_of_episodes": 27567, "number_of_timesteps": 7733543, "per_episode_reward": -46.39, "episode_reward_trend_value": 0.0071201954982193965, "biggest_recent_change": 0.18581773353192688},
{"total_number_of_episodes": 27577, "number_of_timesteps": 7737870, "per_episode_reward": -46.35, "episode_reward_trend_value": 0.00670716326576834, "biggest_recent_change": 0.18581773353192688},
{"total_number_of_episodes": 27587, "number_of_timesteps": 7745361, "per_episode_reward": -46.25, "episode_reward_trend_value": 0.007358994789575411, "biggest_recent_change": 0.18581773353192688},
{"total_number_of_episodes": 27597, "number_of_timesteps": 7751432, "per_episode_reward": -46.21, "episode_reward_trend_value": 0.007224704190783547, "biggest_recent_change": 0.18581773353192688},
{"total_number_of_episodes": 27607, "number_of_timesteps": 7760784, "per_episode_reward": -46.15, "episode_reward_trend_value": 0.007166651247433246, "biggest_recent_change": 0.18581773353192688},
{"total_number_of_episodes": 27617, "number_of_timesteps": 7768428, "per_episode_reward": -46.08, "episode_reward_trend_value": 0.007347566538803897, "biggest_recent_change": 0.18581773353192688},
{"total_number_of_episodes": 27627, "number_of_timesteps": 7776011, "per_episode_reward": -46.01, "episode_reward_trend_value": 0.007733521230419803, "biggest_recent_change": 0.18581773353192688},
{"total_number_of_episodes": 27637, "number_of_timesteps": 7785161, "per_episode_reward": -45.99, "episode_reward_trend_value": 0.007377204112298823, "biggest_recent_change": 0.18581773353192688},
{"total_number_of_episodes": 27647, "number_of_timesteps": 7790668, "per_episode_reward": -45.87, "episode_reward_trend_value": 0.007851858787456775, "biggest_recent_change": 0.18581773353192688},
{"total_number_of_episodes": 27657, "number_of_timesteps": 7793709, "per_episode_reward": -45.8, "episode_reward_trend_value": 0.006522793350843553, "biggest_recent_change": 0.12911774721645486},
{"total_number_of_episodes": 27667, "number_of_timesteps": 7800180, "per_episode_reward": -45.74, "episode_reward_trend_value": 0.006778145209971914, "biggest_recent_change": 0.12911774721645486},
{"total_number_of_episodes": 27677, "number_of_timesteps": 7804608, "per_episode_reward": -45.72, "episode_reward_trend_value": 0.005920745777466941, "biggest_recent_change": 0.12911774721645486},
{"total_number_of_episodes": 27687, "number_of_timesteps": 7809473, "per_episode_reward": -45.63, "episode_reward_trend_value": 0.006517678162608338, "biggest_recent_change": 0.12911774721645486},
{"total_number_of_episodes": 27697, "number_of_timesteps": 7812397, "per_episode_reward": -45.58, "episode_reward_trend_value": 0.006355662213667459, "biggest_recent_change": 0.12911774721645486},
{"total_number_of_episodes": 27707, "number_of_timesteps": 7816231, "per_episode_reward": -45.49, "episode_reward_trend_value": 0.006537076767510858, "biggest_recent_change": 0.12911774721645486},
{"total_number_of_episodes": 27717, "number_of_timesteps": 7821307, "per_episode_reward": -45.36, "episode_reward_trend_value": 0.007194880853720538, "biggest_recent_change": 0.12913346875175336},
{"total_number_of_episodes": 27727, "number_of_timesteps": 7823484, "per_episode_reward": -45.3, "episode_reward_trend_value": 0.007687300580938939, "biggest_recent_change": 0.12913346875175336},
{"total_number_of_episodes": 27737, "number_of_timesteps": 7825572, "per_episode_reward": -45.21, "episode_reward_trend_value": 0.007279964490758869, "biggest_recent_change": 0.12913346875175336},
{"total_number_of_episodes": 27747, "number_of_timesteps": 7828215, "per_episode_reward": -45.13, "episode_reward_trend_value": 0.00747988210615789, "biggest_recent_change": 0.12913346875175336},
{"total_number_of_episodes": 27757, "number_of_timesteps": 7831528, "per_episode_reward": -45.01, "episode_reward_trend_value": 0.008064503039789155, "biggest_recent_change": 0.12913346875175336},
{"total_number_of_episodes": 27767, "number_of_timesteps": 7835477, "per_episode_reward": -44.9, "episode_reward_trend_value": 0.009107373703805639, "biggest_recent_change": 0.12913346875175336},
{"total_number_of_episodes": 27777, "number_of_timesteps": 7842243, "per_episode_reward": -44.81, "episode_reward_trend_value": 0.009028144425525398, "biggest_recent_change": 0.12913346875175336},
{"total_number_of_episodes": 27787, "number_of_timesteps": 7847744, "per_episode_reward": -44.76, "episode_reward_trend_value": 0.009171027456164577, "biggest_recent_change": 0.12913346875175336},
{"total_number_of_episodes": 27797, "number_of_timesteps": 7854384, "per_episode_reward": -44.72, "episode_reward_trend_value": 0.00861416442825692, "biggest_recent_change": 0.12913346875175336},
{"total_number_of_episodes": 27807, "number_of_timesteps": 7859151, "per_episode_reward": -44.66, "episode_reward_trend_value": 0.007798479737448123, "biggest_recent_change": 0.1156460200827496},
{"total_number_of_episodes": 27817, "number_of_timesteps": 7862936, "per_episode_reward": -44.65, "episode_reward_trend_value": 0.0072555724634800825, "biggest_recent_change": 0.1156460200827496},
{"total_number_of_episodes": 27827, "number_of_timesteps": 7867930, "per_episode_reward": -44.5, "episode_reward_trend_value": 0.007878594680411844, "biggest_recent_change": 0.14852949862410725},
{"total_number_of_episodes": 27837, "number_of_timesteps": 7871367, "per_episode_reward": -44.44, "episode_reward_trend_value": 0.0075974282182733706, "biggest_recent_change": 0.14852949862410725},
{"total_number_of_episodes": 27848, "number_of_timesteps": 7874286, "per_episode_reward": -44.37, "episode_reward_trend_value": 0.007171069337406995, "biggest_recent_change": 0.14852949862410725},
{"total_number_of_episodes": 27858, "number_of_timesteps": 7876743, "per_episode_reward": -44.28, "episode_reward_trend_value": 0.006820502905605331, "biggest_recent_change": 0.14852949862410725},
{"total_number_of_episodes": 27868, "number_of_timesteps": 7882485, "per_episode_reward": -44.17, "episode_reward_trend_value": 0.007162930562055278, "biggest_recent_change": 0.14852949862410725},
{"total_number_of_episodes": 27878, "number_of_timesteps": 7888458, "per_episode_reward": -44.08, "episode_reward_trend_value": 0.007495169791150463, "biggest_recent_change": 0.14852949862410725},
{"total_number_of_episodes": 27888, "number_of_timesteps": 7892458, "per_episode_reward": -44.0, "episode_reward_trend_value": 0.0079210090178537, "biggest_recent_change": 0.14852949862410725},
{"total_number_of_episodes": 27898, "number_of_timesteps": 7897788, "per_episode_reward": -43.94, "episode_reward_trend_value": 0.007966259432189322, "biggest_recent_change": 0.14852949862410725},
{"total_number_of_episodes": 27908, "number_of_timesteps": 7902711, "per_episode_reward": -43.93, "episode_reward_trend_value": 0.008009696632030956, "biggest_recent_change": 0.14852949862410725},
{"total_number_of_episodes": 27918, "number_of_timesteps": 7905421, "per_episode_reward": -43.88, "episode_reward_trend_value": 0.006915081652359352, "biggest_recent_change": 0.11379622402218814},
{"total_number_of_episodes": 27928, "number_of_timesteps": 7909982, "per_episode_reward": -43.83, "episode_reward_trend_value": 0.006799474395380559, "biggest_recent_change": 0.11379622402218814},
{"total_number_of_episodes": 27938, "number_of_timesteps": 7914559, "per_episode_reward": -43.73, "episode_reward_trend_value": 0.0071064296115478, "biggest_recent_change": 0.11379622402218814},
{"total_number_of_episodes": 27948, "number_of_timesteps": 7920963, "per_episode_reward": -43.66, "episode_reward_trend_value": 0.006957518421986464, "biggest_recent_change": 0.11379622402218814},
{"total_number_of_episodes": 27958, "number_of_timesteps": 7924859, "per_episode_reward": -43.6, "episode_reward_trend_value": 0.0063847143807159055, "biggest_recent_change": 0.10181481649566848},
{"total_number_of_episodes": 27969, "number_of_timesteps": 7929684, "per_episode_reward": -43.45, "episode_reward_trend_value": 0.00700010051489528, "biggest_recent_change": 0.1436554135563881},
{"total_number_of_episodes": 27979, "number_of_timesteps": 7934402, "per_episode_reward": -43.33, "episode_reward_trend_value": 0.007473100866336797, "biggest_recent_change": 0.1436554135563881},
{"total_number_of_episodes": 27989, "number_of_timesteps": 7937114, "per_episode_reward": -43.22, "episode_reward_trend_value": 0.00809569208401481, "biggest_recent_change": 0.1436554135563881},
{"total_number_of_episodes": 27999, "number_of_timesteps": 7942894, "per_episode_reward": -43.16, "episode_reward_trend_value": 0.008563990442655644, "biggest_recent_change": 0.1436554135563881},
{"total_number_of_episodes": 28009, "number_of_timesteps": 7948725, "per_episode_reward": -43.08, "episode_reward_trend_value": 0.008870580262633293, "biggest_recent_change": 0.1436554135563881},
{"total_number_of_episodes": 28019, "number_of_timesteps": 7952305, "per_episode_reward": -43.0, "episode_reward_trend_value": 0.009201215685941833, "biggest_recent_change": 0.1436554135563881},
{"total_number_of_episodes": 28029, "number_of_timesteps": 7958017, "per_episode_reward": -42.98, "episode_reward_trend_value": 0.008261822742599475, "biggest_recent_change": 0.1436554135563881},
{"total_number_of_episodes": 28039, "number_of_timesteps": 7962229, "per_episode_reward": -42.91, "episode_reward_trend_value": 0.008306540271828785, "biggest_recent_change": 0.1436554135563881},
{"total_number_of_episodes": 28049, "number_of_timesteps": 7963948, "per_episode_reward": -42.86, "episode_reward_trend_value": 0.008155681325667213, "biggest_recent_change": 0.1436554135563881},
{"total_number_of_episodes": 28059, "number_of_timesteps": 7967069, "per_episode_reward": -42.73, "episode_reward_trend_value": 0.007962728226658555, "biggest_recent_change": 0.12628963464560883},
{"total_number_of_episodes": 28069, "number_of_timesteps": 7971170, "per_episode_reward": -42.68, "episode_reward_trend_value": 0.007261188511259557, "biggest_recent_change": 0.12628963464560883},
{"total_number_of_episodes": 28079, "number_of_timesteps": 7973708, "per_episode_reward": -42.57, "episode_reward_trend_value": 0.007194443588880972, "biggest_recent_change": 0.12628963464560883},
{"total_number_of_episodes": 28089, "number_of_timesteps": 7978633, "per_episode_reward": -42.42, "episode_reward_trend_value": 0.008209168694716436, "biggest_recent_change": 0.14954563902288953},
{"total_number_of_episodes": 28099, "number_of_timesteps": 7980904, "per_episode_reward": -42.37, "episode_reward_trend_value": 0.007901700638733031, "biggest_recent_change": 0.14954563902288953},
{"total_number_of_episodes": 28109, "number_of_timesteps": 7983960, "per_episode_reward": -42.3, "episode_reward_trend_value": 0.00779779230307977, "biggest_recent_change": 0.14954563902288953},
{"total_number_of_episodes": 28119, "number_of_timesteps": 7986172, "per_episode_reward": -42.27, "episode_reward_trend_value": 0.00793888732722997, "biggest_recent_change": 0.14954563902288953},
{"total_number_of_episodes": 28129, "number_of_timesteps": 7992909, "per_episode_reward": -42.21, "episode_reward_trend_value": 0.007809526977070805, "biggest_recent_change": 0.14954563902288953},
{"total_number_of_episodes": 28139, "number_of_timesteps": 7997436, "per_episode_reward": -42.15, "episode_reward_trend_value": 0.007882681721697872, "biggest_recent_change": 0.14954563902288953},
{"total_number_of_episodes": 28149, "number_of_timesteps": 8004283, "per_episode_reward": -42.07, "episode_reward_trend_value": 0.00734813263992559, "biggest_recent_change": 0.14954563902288953},
{"total_number_of_episodes": 28159, "number_of_timesteps": 8009561, "per_episode_reward": -42.05, "episode_reward_trend_value": 0.0069767093366185085, "biggest_recent_change": 0.14954563902288953},
{"total_number_of_episodes": 28169, "number_of_timesteps": 8015934, "per_episode_reward": -41.93, "episode_reward_trend_value": 0.0071086926075816835, "biggest_recent_change": 0.14954563902288953},
{"total_number_of_episodes": 28179, "number_of_timesteps": 8022223, "per_episode_reward": -41.82, "episode_reward_trend_value": 0.0066117575071438575, "biggest_recent_change": 0.12169904483280192},
{"total_number_of_episodes": 28189, "number_of_timesteps": 8028466, "per_episode_reward": -41.69, "episode_reward_trend_value": 0.0075176098702357304, "biggest_recent_change": 0.13146182189141342},
{"total_number_of_episodes": 28199, "number_of_timesteps": 8034655, "per_episode_reward": -41.63, "episode_reward_trend_value": 0.007429783067977683, "biggest_recent_change": 0.13146182189141342},
{"total_number_of_episodes": 28209, "number_of_timesteps": 8039636, "per_episode_reward": -41.55, "episode_reward_trend_value": 0.008015423940035207, "biggest_recent_change": 0.13146182189141342},
{"total_number_of_episodes": 28219, "number_of_timesteps": 8045955, "per_episode_reward": -41.31, "episode_reward_trend_value": 0.009976157009148699, "biggest_recent_change": 0.2395411564966068},
{"total_number_of_episodes": 28230, "number_of_timesteps": 8050331, "per_episode_reward": -41.21, "episode_reward_trend_value": 0.010456771701589516, "biggest_recent_change": 0.2395411564966068},
{"total_number_of_episodes": 28240, "number_of_timesteps": 8055785, "per_episode_reward": -41.18, "episode_reward_trend_value": 0.009960109294432978, "biggest_recent_change": 0.2395411564966068},
{"total_number_of_episodes": 28250, "number_of_timesteps": 8060017, "per_episode_reward": -41.09, "episode_reward_trend_value": 0.010668382868760378, "biggest_recent_change": 0.2395411564966068},
{"total_number_of_episodes": 28260, "number_of_timesteps": 8067138, "per_episode_reward": -41.04, "episode_reward_trend_value": 0.009821849107162784, "biggest_recent_change": 0.2395411564966068},
{"total_number_of_episodes": 28270, "number_of_timesteps": 8073462, "per_episode_reward": -41.01, "episode_reward_trend_value": 0.009031811454471812, "biggest_recent_change": 0.2395411564966068},
{"total_number_of_episodes": 28280, "number_of_timesteps": 8079559, "per_episode_reward": -40.99, "episode_reward_trend_value": 0.007806169983808944, "biggest_recent_change": 0.2395411564966068},
{"total_number_of_episodes": 28290, "number_of_timesteps": 8084190, "per_episode_reward": -40.97, "episode_reward_trend_value": 0.007312641621275794, "biggest_recent_change": 0.2395411564966068},
{"total_number_of_episodes": 28300, "number_of_timesteps": 8092143, "per_episode_reward": -40.93, "episode_reward_trend_value": 0.006867952806625904, "biggest_recent_change": 0.2395411564966068},
{"total_number_of_episodes": 28310, "number_of_timesteps": 8096922, "per_episode_reward": -40.88, "episode_reward_trend_value": 0.004765719449882589, "biggest_recent_change": 0.09850580448940605},
{"total_number_of_episodes": 28320, "number_of_timesteps": 8105541, "per_episode_reward": -40.83, "episode_reward_trend_value": 0.004240391794030135, "biggest_recent_change": 0.08698304701130866},
{"total_number_of_episodes": 28330, "number_of_timesteps": 8111557, "per_episode_reward": -40.8, "episode_reward_trend_value": 0.004212148530508605, "biggest_recent_change": 0.08698304701130866},
{"total_number_of_episodes": 28340, "number_of_timesteps": 8117188, "per_episode_reward": -40.71, "episode_reward_trend_value": 0.0042376422305416385, "biggest_recent_change": 0.08927748001428171},
{"total_number_of_episodes": 28350, "number_of_timesteps": 8124534, "per_episode_reward": -40.56, "episode_reward_trend_value": 0.0053584065886196994, "biggest_recent_change": 0.146379798516044},
{"total_number_of_episodes": 28360, "number_of_timesteps": 8132960, "per_episode_reward": -40.49, "episode_reward_trend_value": 0.0058226370265431, "biggest_recent_change": 0.146379798516044},
{"total_number_of_episodes": 28370, "number_of_timesteps": 8140543, "per_episode_reward": -40.4, "episode_reward_trend_value": 0.006530266875348742, "biggest_recent_change": 0.146379798516044},
{"total_number_of_episodes": 28381, "number_of_timesteps": 8147875, "per_episode_reward": -40.32, "episode_reward_trend_value": 0.007231808743309011, "biggest_recent_change": 0.146379798516044},
{"total_number_of_episodes": 28391, "number_of_timesteps": 8154540, "per_episode_reward": -40.26, "episode_reward_trend_value": 0.007475499940726138, "biggest_recent_change": 0.146379798516044},
{"total_number_of_episodes": 28401, "number_of_timesteps": 8161972, "per_episode_reward": -40.17, "episode_reward_trend_value": 0.00786288483621694, "biggest_recent_change": 0.146379798516044},
{"total_number_of_episodes": 28411, "number_of_timesteps": 8168146, "per_episode_reward": -40.13, "episode_reward_trend_value": 0.007763886487355462, "biggest_recent_change": 0.146379798516044},
{"total_number_of_episodes": 28421, "number_of_timesteps": 8172149, "per_episode_reward": -40.02, "episode_reward_trend_value": 0.008621585054806423, "biggest_recent_change": 0.146379798516044},
{"total_number_of_episodes": 28431, "number_of_timesteps": 8176399, "per_episode_reward": -39.94, "episode_reward_trend_value": 0.008540670787694576, "biggest_recent_change": 0.146379798516044},
{"total_number_of_episodes": 28442, "number_of_timesteps": 8184035, "per_episode_reward": -39.9, "episode_reward_trend_value": 0.007414577734605625, "biggest_recent_change": 0.10813157799566397},
{"total_number_of_episodes": 28452, "number_of_timesteps": 8188902, "per_episode_reward": -39.83, "episode_reward_trend_value": 0.007330816790196258, "biggest_recent_change": 0.10813157799566397},
{"total_number_of_episodes": 28462, "number_of_timesteps": 8194384, "per_episode_reward": -39.75, "episode_reward_trend_value": 0.007262888032015821, "biggest_recent_change": 0.10813157799566397},
{"total_number_of_episodes": 28472, "number_of_timesteps": 8199771, "per_episode_reward": -39.69, "episode_reward_trend_value": 0.007037842263136677, "biggest_recent_change": 0.10813157799566397},
{"total_number_of_episodes": 28482, "number_of_timesteps": 8206766, "per_episode_reward": -39.64, "episode_reward_trend_value": 0.006843395604289289, "biggest_recent_change": 0.10813157799566397},
{"total_number_of_episodes": 28492, "number_of_timesteps": 8215969, "per_episode_reward": -39.56, "episode_reward_trend_value": 0.006781738668304153, "biggest_recent_change": 0.10813157799566397},
{"total_number_of_episodes": 28503, "number_of_timesteps": 8223702, "per_episode_reward": -39.42, "episode_reward_trend_value": 0.007837531265934356, "biggest_recent_change": 0.1373377978518704},
{"total_number_of_episodes": 28513, "number_of_timesteps": 8231012, "per_episode_reward": -39.35, "episode_reward_trend_value": 0.007509085432368718, "biggest_recent_change": 0.1373377978518704},
{"total_number_of_episodes": 28523, "number_of_timesteps": 8237042, "per_episode_reward": -39.22, "episode_reward_trend_value": 0.00799691958102105, "biggest_recent_change": 0.1373377978518704},
{"total_number_of_episodes": 28533, "number_of_timesteps": 8241863, "per_episode_reward": -39.15, "episode_reward_trend_value": 0.008275170322338472, "biggest_recent_change": 0.1373377978518704},
{"total_number_of_episodes": 28543, "number_of_timesteps": 8247453, "per_episode_reward": -39.05, "episode_reward_trend_value": 0.00861448189692982, "biggest_recent_change": 0.1373377978518704},
{"total_number_of_episodes": 28553, "number_of_timesteps": 8253364, "per_episode_reward": -38.99, "episode_reward_trend_value": 0.008456829266406235, "biggest_recent_change": 0.1373377978518704},
{"total_number_of_episodes": 28563, "number_of_timesteps": 8258383, "per_episode_reward": -38.93, "episode_reward_trend_value": 0.00838022015807943, "biggest_recent_change": 0.1373377978518704},
{"total_number_of_episodes": 28573, "number_of_timesteps": 8264983, "per_episode_reward": -38.89, "episode_reward_trend_value": 0.008386854184542061, "biggest_recent_change": 0.1373377978518704},
{"total_number_of_episodes": 28583, "number_of_timesteps": 8269517, "per_episode_reward": -38.75, "episode_reward_trend_value": 0.009076690237061848, "biggest_recent_change": 0.14174091547199907},
{"total_number_of_episodes": 28593, "number_of_timesteps": 8274752, "per_episode_reward": -38.66, "episode_reward_trend_value": 0.008503007588683194, "biggest_recent_change": 0.14174091547199907},
{"total_number_of_episodes": 28604, "number_of_timesteps": 8281082, "per_episode_reward": -38.53, "episode_reward_trend_value": 0.00904261639085754, "biggest_recent_change": 0.14174091547199907},
{"total_number_of_episodes": 28614, "number_of_timesteps": 8287761, "per_episode_reward": -38.48, "episode_reward_trend_value": 0.008272279356833995, "biggest_recent_change": 0.14174091547199907},
{"total_number_of_episodes": 28625, "number_of_timesteps": 8293555, "per_episode_reward": -38.42, "episode_reward_trend_value": 0.008138438708720091, "biggest_recent_change": 0.14174091547199907},
{"total_number_of_episodes": 28635, "number_of_timesteps": 8296361, "per_episode_reward": -38.35, "episode_reward_trend_value": 0.00777052204119823, "biggest_recent_change": 0.14174091547199907},
{"total_number_of_episodes": 28645, "number_of_timesteps": 8299616, "per_episode_reward": -38.3, "episode_reward_trend_value": 0.007689537704919916, "biggest_recent_change": 0.14174091547199907},
{"total_number_of_episodes": 28655, "number_of_timesteps": 8302979, "per_episode_reward": -38.2, "episode_reward_trend_value": 0.008210203086849156, "biggest_recent_change": 0.14174091547199907},
{"total_number_of_episodes": 28665, "number_of_timesteps": 8307847, "per_episode_reward": -38.16, "episode_reward_trend_value": 0.00802749348345652, "biggest_recent_change": 0.14174091547199907},
{"total_number_of_episodes": 28675, "number_of_timesteps": 8312743, "per_episode_reward": -38.1, "episode_reward_trend_value": 0.0071711506901084, "biggest_recent_change": 0.12713624517044764},
{"total_number_of_episodes": 28685, "number_of_timesteps": 8314969, "per_episode_reward": -38.07, "episode_reward_trend_value": 0.006560074385567639, "biggest_recent_change": 0.12713624517044764},
{"total_number_of_episodes": 28696, "number_of_timesteps": 8319318, "per_episode_reward": -38.02, "episode_reward_trend_value": 0.005659843807415793, "biggest_recent_change": 0.09941798150138226},
{"total_number_of_episodes": 28706, "number_of_timesteps": 8325155, "per_episode_reward": -37.93, "episode_reward_trend_value": 0.006012724028509729, "biggest_recent_change": 0.09941798150138226},
{"total_number_of_episodes": 28716, "number_of_timesteps": 8331110, "per_episode_reward": -37.86, "episode_reward_trend_value": 0.006223264339204664, "biggest_recent_change": 0.09941798150138226},
{"total_number_of_episodes": 28726, "number_of_timesteps": 8336847, "per_episode_reward": -37.79, "episode_reward_trend_value": 0.006306025816626398, "biggest_recent_change": 0.09941798150138226},
{"total_number_of_episodes": 28736, "number_of_timesteps": 8342978, "per_episode_reward": -37.7, "episode_reward_trend_value": 0.006579559554638968, "biggest_recent_change": 0.09941798150138226},
{"total_number_of_episodes": 28746, "number_of_timesteps": 8347048, "per_episode_reward": -37.64, "episode_reward_trend_value": 0.006217086600946055, "biggest_recent_change": 0.08832915618926052},
{"total_number_of_episodes": 28756, "number_of_timesteps": 8355308, "per_episode_reward": -37.43, "episode_reward_trend_value": 0.008146931610853711, "biggest_recent_change": 0.20492494637432657},
{"total_number_of_episodes": 28766, "number_of_timesteps": 8363753, "per_episode_reward": -37.37, "episode_reward_trend_value": 0.008058818405802033, "biggest_recent_change": 0.20492494637432657},
{"total_number_of_episodes": 28776, "number_of_timesteps": 8369155, "per_episode_reward": -37.32, "episode_reward_trend_value": 0.00828774469795535, "biggest_recent_change": 0.20492494637432657},
{"total_number_of_episodes": 28786, "number_of_timesteps": 8371801, "per_episode_reward": -37.29, "episode_reward_trend_value": 0.008198592896313528, "biggest_recent_change": 0.20492494637432657},
{"total_number_of_episodes": 28796, "number_of_timesteps": 8378564, "per_episode_reward": -37.25, "episode_reward_trend_value": 0.0076261743719568485, "biggest_recent_change": 0.20492494637432657},
{"total_number_of_episodes": 28806, "number_of_timesteps": 8383891, "per_episode_reward": -37.21, "episode_reward_trend_value": 0.007179351734050085, "biggest_recent_change": 0.20492494637432657},
{"total_number_of_episodes": 28816, "number_of_timesteps": 8392061, "per_episode_reward": -37.13, "episode_reward_trend_value": 0.0072711547429429564, "biggest_recent_change": 0.20492494637432657},
{"total_number_of_episodes": 28826, "number_of_timesteps": 8399917, "per_episode_reward": -37.07, "episode_reward_trend_value": 0.0069900222027187275, "biggest_recent_change": 0.20492494637432657},
{"total_number_of_episodes": 28836, "number_of_timesteps": 8406374, "per_episode_reward": -37.01, "episode_reward_trend_value": 0.0069913727619434, "biggest_recent_change": 0.20492494637432657},
{"total_number_of_episodes": 28846, "number_of_timesteps": 8413306, "per_episode_reward": -36.92, "episode_reward_trend_value": 0.005672552819170246, "biggest_recent_change": 0.0862311515247427},
{"total_number_of_episodes": 28856, "number_of_timesteps": 8420500, "per_episode_reward": -36.81, "episode_reward_trend_value": 0.006286005180146266, "biggest_recent_change": 0.11195058810385916},
{"total_number_of_episodes": 28867, "number_of_timesteps": 8429530, "per_episode_reward": -36.74, "episode_reward_trend_value": 0.00643365200814464, "biggest_recent_change": 0.11195058810385916},
{"total_number_of_episodes": 28877, "number_of_timesteps": 8434931, "per_episode_reward": -36.63, "episode_reward_trend_value": 0.0072376150902757775, "biggest_recent_change": 0.11195058810385916},
{"total_number_of_episodes": 28887, "number_of_timesteps": 8437832, "per_episode_reward": -36.61, "episode_reward_trend_value": 0.0070786397146279335, "biggest_recent_change": 0.11195058810385916},
{"total_number_of_episodes": 28897, "number_of_timesteps": 8441027, "per_episode_reward": -36.51, "episode_reward_trend_value": 0.007742867384451163, "biggest_recent_change": 0.11195058810385916},
{"total_number_of_episodes": 28907, "number_of_timesteps": 8443836, "per_episode_reward": -36.47, "episode_reward_trend_value": 0.007341686932587759, "biggest_recent_change": 0.11195058810385916},
{"total_number_of_episodes": 28917, "number_of_timesteps": 8445788, "per_episode_reward": -36.4, "episode_reward_trend_value": 0.0075342194284296225, "biggest_recent_change": 0.11195058810385916},
{"total_number_of_episodes": 28927, "number_of_timesteps": 8449050, "per_episode_reward": -36.3, "episode_reward_trend_value": 0.007804482990578758, "biggest_recent_change": 0.11195058810385916},
{"total_number_of_episodes": 28937, "number_of_timesteps": 8451751, "per_episode_reward": -36.26, "episode_reward_trend_value": 0.007337208129839626, "biggest_recent_change": 0.11195058810385916},
{"total_number_of_episodes": 28947, "number_of_timesteps": 8455497, "per_episode_reward": -36.24, "episode_reward_trend_value": 0.006340212333072831, "biggest_recent_change": 0.11044850838081999},
{"total_number_of_episodes": 28957, "number_of_timesteps": 8458371, "per_episode_reward": -36.22, "episode_reward_trend_value": 0.00578338377029305, "biggest_recent_change": 0.11044850838081999},
{"total_number_of_episodes": 28967, "number_of_timesteps": 8464791, "per_episode_reward": -36.15, "episode_reward_trend_value": 0.005325944356499374, "biggest_recent_change": 0.09654341296138114},
{"total_number_of_episodes": 28977, "number_of_timesteps": 8471362, "per_episode_reward": -36.09, "episode_reward_trend_value": 0.005785746147233084, "biggest_recent_change": 0.09654341296138114},
{"total_number_of_episodes": 28987, "number_of_timesteps": 8476116, "per_episode_reward": -36.07, "episode_reward_trend_value": 0.004926631450412186, "biggest_recent_change": 0.09124068659266271},
{"total_number_of_episodes": 28997, "number_of_timesteps": 8484527, "per_episode_reward": -36.0, "episode_reward_trend_value": 0.00519720630422245, "biggest_recent_change": 0.09124068659266271},
{"total_number_of_episodes": 29007, "number_of_timesteps": 8488759, "per_episode_reward": -35.94, "episode_reward_trend_value": 0.005065353650257423, "biggest_recent_change": 0.09124068659266271},
{"total_number_of_episodes": 29017, "number_of_timesteps": 8496891, "per_episode_reward": -35.89, "episode_reward_trend_value": 0.004629166073234122, "biggest_recent_change": 0.06934218723734631},
{"total_number_of_episodes": 29027, "number_of_timesteps": 8502982, "per_episode_reward": -35.77, "episode_reward_trend_value": 0.00543002446654902, "biggest_recent_change": 0.11625366945656168},
{"total_number_of_episodes": 29037, "number_of_timesteps": 8508460, "per_episode_reward": -35.74, "episode_reward_trend_value": 0.005504661785834723, "biggest_recent_change": 0.11625366945656168},
{"total_number_of_episodes": 29047, "number_of_timesteps": 8514341, "per_episode_reward": -35.69, "episode_reward_trend_value": 0.005891313375606602, "biggest_recent_change": 0.11625366945656168},
{"total_number_of_episodes": 29059, "number_of_timesteps": 8519477, "per_episode_reward": -35.66, "episode_reward_trend_value": 0.00547570395833811, "biggest_recent_change": 0.11625366945656168},
{"total_number_of_episodes": 29069, "number_of_timesteps": 8525474, "per_episode_reward": -35.64, "episode_reward_trend_value": 0.005005357207628455, "biggest_recent_change": 0.11625366945656168},
{"total_number_of_episodes": 29079, "number_of_timesteps": 8530801, "per_episode_reward": -35.58, "episode_reward_trend_value": 0.005405621708348068, "biggest_recent_change": 0.11625366945656168},
{"total_number_of_episodes": 29089, "number_of_timesteps": 8535092, "per_episode_reward": -35.56, "episode_reward_trend_value": 0.0048696923859616, "biggest_recent_change": 0.11625366945656168},
{"total_number_of_episodes": 29099, "number_of_timesteps": 8540150, "per_episode_reward": -35.5, "episode_reward_trend_value": 0.004840467341125216, "biggest_recent_change": 0.11625366945656168},
{"total_number_of_episodes": 29110, "number_of_timesteps": 8546644, "per_episode_reward": -35.48, "episode_reward_trend_value": 0.004482754436617142, "biggest_recent_change": 0.11625366945656168},
{"total_number_of_episodes": 29120, "number_of_timesteps": 8552936, "per_episode_reward": -35.45, "episode_reward_trend_value": 0.003564601746733271, "biggest_recent_change": 0.059396900210444414},
{"total_number_of_episodes": 29130, "number_of_timesteps": 8560519, "per_episode_reward": -35.4, "episode_reward_trend_value": 0.003820750177721442, "biggest_recent_change": 0.059396900210444414},
{"total_number_of_episodes": 29140, "number_of_timesteps": 8566571, "per_episode_reward": -35.39, "episode_reward_trend_value": 0.0034066044983679456, "biggest_recent_change": 0.059396900210444414},
{"total_number_of_episodes": 29150, "number_of_timesteps": 8572490, "per_episode_reward": -35.33, "episode_reward_trend_value": 0.003664771938027971, "biggest_recent_change": 0.059396900210444414},
{"total_number_of_episodes": 29160, "number_of_timesteps": 8579330, "per_episode_reward": -35.29, "episode_reward_trend_value": 0.0038396425597989198, "biggest_recent_change": 0.059396900210444414},
{"total_number_of_episodes": 29170, "number_of_timesteps": 8584053, "per_episode_reward": -35.27, "episode_reward_trend_value": 0.003532527806729746, "biggest_recent_change": 0.059396900210444414},
{"total_number_of_episodes": 29180, "number_of_timesteps": 8589236, "per_episode_reward": -35.22, "episode_reward_trend_value": 0.003774312339955404, "biggest_recent_change": 0.059396900210444414},
{"total_number_of_episodes": 29190, "number_of_timesteps": 8594543, "per_episode_reward": -35.18, "episode_reward_trend_value": 0.003643495019802382, "biggest_recent_change": 0.05510918315462732},
{"total_number_of_episodes": 29200, "number_of_timesteps": 8597757, "per_episode_reward": -35.1, "episode_reward_trend_value": 0.004308671332430613, "biggest_recent_change": 0.07965551139137972},
{"total_number_of_episodes": 29210, "number_of_timesteps": 8605604, "per_episode_reward": -34.99, "episode_reward_trend_value": 0.005084700617561092, "biggest_recent_change": 0.10346256302875645},
{"total_number_of_episodes": 29220, "number_of_timesteps": 8614323, "per_episode_reward": -34.92, "episode_reward_trend_value": 0.005307423323302788, "biggest_recent_change": 0.10346256302875645},
{"total_number_of_episodes": 29230, "number_of_timesteps": 8619175, "per_episode_reward": -34.86, "episode_reward_trend_value": 0.005849821322057381, "biggest_recent_change": 0.10346256302875645},
{"total_number_of_episodes": 29240, "number_of_timesteps": 8626447, "per_episode_reward": -34.83, "episode_reward_trend_value": 0.005621092695481325, "biggest_recent_change": 0.10346256302875645},
{"total_number_of_episodes": 29250, "number_of_timesteps": 8632339, "per_episode_reward": -34.73, "episode_reward_trend_value": 0.006235341289761544, "biggest_recent_change": 0.10346256302875645},
{"total_number_of_episodes": 29260, "number_of_timesteps": 8640622, "per_episode_reward": -34.53, "episode_reward_trend_value": 0.00813504601008914, "biggest_recent_change": 0.1985799923655236},
{"total_number_of_episodes": 29270, "number_of_timesteps": 8647372, "per_episode_reward": -34.49, "episode_reward_trend_value": 0.0081895655364262, "biggest_recent_change": 0.1985799923655236},
{"total_number_of_episodes": 29280, "number_of_timesteps": 8654056, "per_episode_reward": -34.45, "episode_reward_trend_value": 0.008042179181834858, "biggest_recent_change": 0.1985799923655236},

{"total_number_of_episodes": 29290, "number_of_timesteps": 8657386, "per_episode_reward": -34.42, "episode_reward_trend_value": 0.007499508450786942, "biggest_recent_change": 0.1985799923655236},
{"total_number_of_episodes": 29300, "number_of_timesteps": 8664522, "per_episode_reward": -34.39, "episode_reward_trend_value": 0.006718427659451326, "biggest_recent_change": 0.1985799923655236},
{"total_number_of_episodes": 29310, "number_of_timesteps": 8671275, "per_episode_reward": -34.31, "episode_reward_trend_value": 0.006740560063008161, "biggest_recent_change": 0.1985799923655236},
{"total_number_of_episodes": 29320, "number_of_timesteps": 8675486, "per_episode_reward": -34.29, "episode_reward_trend_value": 0.006359043502727641, "biggest_recent_change": 0.1985799923655236},
{"total_number_of_episodes": 29330, "number_of_timesteps": 8681633, "per_episode_reward": -34.26, "episode_reward_trend_value": 0.006289655602950006, "biggest_recent_change": 0.1985799923655236},
{"total_number_of_episodes": 29340, "number_of_timesteps": 8687652, "per_episode_reward": -34.23, "episode_reward_trend_value": 0.0056010209551999425, "biggest_recent_change": 0.1985799923655236},
{"total_number_of_episodes": 29350, "number_of_timesteps": 8693575, "per_episode_reward": -34.19, "episode_reward_trend_value": 0.003875922510793749, "biggest_recent_change": 0.07402864375636398},
{"total_number_of_episodes": 29360, "number_of_timesteps": 8699023, "per_episode_reward": -34.18, "episode_reward_trend_value": 0.003409333109192008, "biggest_recent_change": 0.07402864375636398},
{"total_number_of_episodes": 29370, "number_of_timesteps": 8705974, "per_episode_reward": -34.13, "episode_reward_trend_value": 0.0035407492158186296, "biggest_recent_change": 0.07402864375636398},
{"total_number_of_episodes": 29380, "number_of_timesteps": 8713869, "per_episode_reward": -34.09, "episode_reward_trend_value": 0.0036913626570537874, "biggest_recent_change": 0.07402864375636398},
{"total_number_of_episodes": 29390, "number_of_timesteps": 8717650, "per_episode_reward": -34.06, "episode_reward_trend_value": 0.0036588373640692373, "biggest_recent_change": 0.07402864375636398},
{"total_number_of_episodes": 29400, "number_of_timesteps": 8722814, "per_episode_reward": -33.98, "episode_reward_trend_value": 0.0036690622845137163, "biggest_recent_change": 0.074948886596367},
{"total_number_of_episodes": 29410, "number_of_timesteps": 8728175, "per_episode_reward": -33.79, "episode_reward_trend_value": 0.0054877100293051085, "biggest_recent_change": 0.1901696606841412},
{"total_number_of_episodes": 29420, "number_of_timesteps": 8733066, "per_episode_reward": -33.75, "episode_reward_trend_value": 0.005717657647865574, "biggest_recent_change": 0.1901696606841412},
{"total_number_of_episodes": 29430, "number_of_timesteps": 8740597, "per_episode_reward": -33.69, "episode_reward_trend_value": 0.005950687427348575, "biggest_recent_change": 0.1901696606841412},

{"total_number_of_episodes": 29440, "number_of_timesteps": 8747896, "per_episode_reward": -33.61, "episode_reward_trend_value": 0.006397776049665065, "biggest_recent_change": 0.1901696606841412},
{"total_number_of_episodes": 29450, "number_of_timesteps": 8750930, "per_episode_reward": -33.52, "episode_reward_trend_value": 0.007317525238067191, "biggest_recent_change": 0.1901696606841412},
{"total_number_of_episodes": 29460, "number_of_timesteps": 8755761, "per_episode_reward": -33.47, "episode_reward_trend_value": 0.007376779393164018, "biggest_recent_change": 0.1901696606841412},
{"total_number_of_episodes": 29470, "number_of_timesteps": 8758956, "per_episode_reward": -33.41, "episode_reward_trend_value": 0.0075672510997839655, "biggest_recent_change": 0.1901696606841412},
{"total_number_of_episodes": 29480, "number_of_timesteps": 8763084, "per_episode_reward": -33.38, "episode_reward_trend_value": 0.007517681967806391, "biggest_recent_change": 0.1901696606841412},
{"total_number_of_episodes": 29490, "number_of_timesteps": 8767223, "per_episode_reward": -33.34, "episode_reward_trend_value": 0.007152079498794312, "biggest_recent_change": 0.1901696606841412},
{"total_number_of_episodes": 29500, "number_of_timesteps": 8768758, "per_episode_reward": -33.28, "episode_reward_trend_value": 0.005683114064837014, "biggest_recent_change": 0.08856029439524349},
{"total_number_of_episodes": 29511, "number_of_timesteps": 8773156, "per_episode_reward": -33.16, "episode_reward_trend_value": 0.0064840013534808675, "biggest_recent_change": 0.12105383743118381},
{"total_number_of_episodes": 29521, "number_of_timesteps": 8775712, "per_episode_reward": -33.04, "episode_reward_trend_value": 0.007306404923502975, "biggest_recent_change": 0.12558727139357728},
{"total_number_of_episodes": 29531, "number_of_timesteps": 8779569, "per_episode_reward": -32.97, "episode_reward_trend_value": 0.0070870999493532205, "biggest_recent_change": 0.12558727139357728},
{"total_number_of_episodes": 29541, "number_of_timesteps": 8784236, "per_episode_reward": -32.94, "episode_reward_trend_value": 0.006424003600066739, "biggest_recent_change": 0.12558727139357728},
{"total_number_of_episodes": 29551, "number_of_timesteps": 8786913, "per_episode_reward": -32.91, "episode_reward_trend_value": 0.006247049983684071, "biggest_recent_change": 0.12558727139357728},
{"total_number_of_episodes": 29561, "number_of_timesteps": 8790266, "per_episode_reward": -32.87, "episode_reward_trend_value": 0.006009322000683031, "biggest_recent_change": 0.12558727139357728},
{"total_number_of_episodes": 29571, "number_of_timesteps": 8793811, "per_episode_reward": -32.8, "episode_reward_trend_value": 0.006444809581228286, "biggest_recent_change": 0.12558727139357728},
{"total_number_of_episodes": 29581, "number_of_timesteps": 8797244, "per_episode_reward": -32.71, "episode_reward_trend_value": 0.006991015524085498, "biggest_recent_change": 0.12558727139357728},
{"total_number_of_episodes": 29591, "number_of_timesteps": 8800663, "per_episode_reward": -32.66, "episode_reward_trend_value": 0.006957444190433727, "biggest_recent_change": 0.12558727139357728},
{"total_number_of_episodes": 29601, "number_of_timesteps": 8806500, "per_episode_reward": -32.64, "episode_reward_trend_value": 0.005778915533178816, "biggest_recent_change": 0.12558727139357728},
{"total_number_of_episodes": 29611, "number_of_timesteps": 8810749, "per_episode_reward": -32.53, "episode_reward_trend_value": 0.005584050964277449, "biggest_recent_change": 0.1080494601924542},
{"total_number_of_episodes": 29621, "number_of_timesteps": 8813320, "per_episode_reward": -32.45, "episode_reward_trend_value": 0.0058597841118979, "biggest_recent_change": 0.1080494601924542},
{"total_number_of_episodes": 29631, "number_of_timesteps": 8817222, "per_episode_reward": -32.4, "episode_reward_trend_value": 0.005987669289349719, "biggest_recent_change": 0.1080494601924542},
{"total_number_of_episodes": 29641, "number_of_timesteps": 8820189, "per_episode_reward": -32.36, "episode_reward_trend_value": 0.006101033618118695, "biggest_recent_change": 0.1080494601924542},
{"total_number_of_episodes": 29651, "number_of_timesteps": 8827682, "per_episode_reward": -32.19, "episode_reward_trend_value": 0.007555154413349247, "biggest_recent_change": 0.17098816200468292},
{"total_number_of_episodes": 29661, "number_of_timesteps": 8832497, "per_episode_reward": -32.14, "episode_reward_trend_value": 0.0073823278005948605, "biggest_recent_change": 0.17098816200468292},
{"total_number_of_episodes": 29671, "number_of_timesteps": 8837727, "per_episode_reward": -32.08, "episode_reward_trend_value": 0.007062967488235472, "biggest_recent_change": 0.17098816200468292},
{"total_number_of_episodes": 29681, "number_of_timesteps": 8845229, "per_episode_reward": -32.03, "episode_reward_trend_value": 0.006911469918929845, "biggest_recent_change": 0.17098816200468292},
{"total_number_of_episodes": 29691, "number_of_timesteps": 8850535, "per_episode_reward": -32.0, "episode_reward_trend_value": 0.007079176160583639, "biggest_recent_change": 0.17098816200468292},
{"total_number_of_episodes": 29701, "number_of_timesteps": 8855247, "per_episode_reward": -31.93, "episode_reward_trend_value": 0.006670865638081442, "biggest_recent_change": 0.17098816200468292},
{"total_number_of_episodes": 29711, "number_of_timesteps": 8860881, "per_episode_reward": -31.88, "episode_reward_trend_value": 0.006280133928084711, "biggest_recent_change": 0.17098816200468292},
{"total_number_of_episodes": 29721, "number_of_timesteps": 8866604, "per_episode_reward": -31.76, "episode_reward_trend_value": 0.0071218310824038315, "biggest_recent_change": 0.17098816200468292},
{"total_number_of_episodes": 29731, "number_of_timesteps": 8873775, "per_episode_reward": -31.72, "episode_reward_trend_value": 0.0070624900524519614, "biggest_recent_change": 0.17098816200468292},

{"total_number_of_episodes": 29742, "number_of_timesteps": 8880718, "per_episode_reward": -31.67, "episode_reward_trend_value": 0.005766132508099039, "biggest_recent_change": 0.11614403281884478},
{"total_number_of_episodes": 29752, "number_of_timesteps": 8886304, "per_episode_reward": -31.61, "episode_reward_trend_value": 0.0058984232412593466, "biggest_recent_change": 0.11614403281884478},
{"total_number_of_episodes": 29762, "number_of_timesteps": 8891939, "per_episode_reward": -31.55, "episode_reward_trend_value": 0.005818322183665793, "biggest_recent_change": 0.11614403281884478},
{"total_number_of_episodes": 29772, "number_of_timesteps": 8898519, "per_episode_reward": -31.45, "episode_reward_trend_value": 0.006465200556956122, "biggest_recent_change": 0.11614403281884478},
{"total_number_of_episodes": 29782, "number_of_timesteps": 8907064, "per_episode_reward": -31.31, "episode_reward_trend_value": 0.007670810269253418, "biggest_recent_change": 0.13858469413384},
{"total_number_of_episodes": 29792, "number_of_timesteps": 8913212, "per_episode_reward": -31.27, "episode_reward_trend_value": 0.007319785231829535, "biggest_recent_change": 0.13858469413384},
{"total_number_of_episodes": 29802, "number_of_timesteps": 8919022, "per_episode_reward": -31.22, "episode_reward_trend_value": 0.007298000387487412, "biggest_recent_change": 0.13858469413384},
{"total_number_of_episodes": 29812, "number_of_timesteps": 8925996, "per_episode_reward": -31.19, "episode_reward_trend_value": 0.006405355067074778, "biggest_recent_change": 0.13858469413384},
{"total_number_of_episodes": 29822, "number_of_timesteps": 8935094, "per_episode_reward": -31.14, "episode_reward_trend_value": 0.006457278785205941, "biggest_recent_change": 0.13858469413384},
{"total_number_of_episodes": 29832, "number_of_timesteps": 8940485, "per_episode_reward": -31.05, "episode_reward_trend_value": 0.0068945551947915285, "biggest_recent_change": 0.13858469413384},
{"total_number_of_episodes": 29842, "number_of_timesteps": 8949629, "per_episode_reward": -31.01, "episode_reward_trend_value": 0.006626041202368861, "biggest_recent_change": 0.13858469413384},
{"total_number_of_episodes": 29852, "number_of_timesteps": 8956077, "per_episode_reward": -30.93, "episode_reward_trend_value": 0.00688581985271281, "biggest_recent_change": 0.13858469413384},
{"total_number_of_episodes": 29862, "number_of_timesteps": 8962635, "per_episode_reward": -30.88, "episode_reward_trend_value": 0.006391048713629388, "biggest_recent_change": 0.13858469413384},
{"total_number_of_episodes": 29872, "number_of_timesteps": 8970789, "per_episode_reward": -30.83, "episode_reward_trend_value": 0.005363022106014231, "biggest_recent_change": 0.09367085987562263},
{"total_number_of_episodes": 29882, "number_of_timesteps": 8978377, "per_episode_reward": -30.76, "episode_reward_trend_value": 0.0057276943315909615, "biggest_recent_change": 0.09367085987562263},
{"total_number_of_episodes": 29892, "number_of_timesteps": 8986865, "per_episode_reward": -30.68, "episode_reward_trend_value": 0.0060595318224153675, "biggest_recent_change": 0.09367085987562263},
{"total_number_of_episodes": 29902, "number_of_timesteps": 8995276, "per_episode_reward": -30.65, "episode_reward_trend_value": 0.005966714590472103, "biggest_recent_change": 0.09367085987562263},
{"total_number_of_episodes": 29912, "number_of_timesteps": 9003344, "per_episode_reward": -30.58, "episode_reward_trend_value": 0.006292941075977351, "biggest_recent_change": 0.09367085987562263},
{"total_number_of_episodes": 29922, "number_of_timesteps": 9010224, "per_episode_reward": -30.54, "episode_reward_trend_value": 0.005605997040396223, "biggest_recent_change": 0.0813765282735126},
{"total_number_of_episodes": 29932, "number_of_timesteps": 9018062, "per_episode_reward": -30.45, "episode_reward_trend_value": 0.006233828290903295, "biggest_recent_change": 0.09366099987516208},
{"total_number_of_episodes": 29942, "number_of_timesteps": 9025751, "per_episode_reward": -30.38, "episode_reward_trend_value": 0.006136551920572626, "biggest_recent_change": 0.09366099987516208},
{"total_number_of_episodes": 29952, "number_of_timesteps": 9031901, "per_episode_reward": -30.34, "episode_reward_trend_value": 0.00597197040244204, "biggest_recent_change": 0.09366099987516208},
{"total_number_of_episodes": 29962, "number_of_timesteps": 9037874, "per_episode_reward": -30.26, "episode_reward_trend_value": 0.00634794048326077, "biggest_recent_change": 0.09366099987516208},
{"total_number_of_episodes": 29972, "number_of_timesteps": 9043930, "per_episode_reward": -30.24, "episode_reward_trend_value": 0.0057557974127542075, "biggest_recent_change": 0.09366099987516208},
{"total_number_of_episodes": 29982, "number_of_timesteps": 9053081, "per_episode_reward": -30.13, "episode_reward_trend_value": 0.006036489221771922, "biggest_recent_change": 0.10663879108510699},
{"total_number_of_episodes": 29992, "number_of_timesteps": 9061224, "per_episode_reward": -30.04, "episode_reward_trend_value": 0.006812500285775671, "biggest_recent_change": 0.10663879108510699},
{"total_number_of_episodes": 30002, "number_of_timesteps": 9068283, "per_episode_reward": -29.99, "episode_reward_trend_value": 0.006484185030802081, "biggest_recent_change": 0.10663879108510699},
{"total_number_of_episodes": 30012, "number_of_timesteps": 9076673, "per_episode_reward": -29.97, "episode_reward_trend_value": 0.006352468643639142, "biggest_recent_change": 0.10663879108510699},
{"total_number_of_episodes": 30022, "number_of_timesteps": 9081273, "per_episode_reward": -29.87, "episode_reward_trend_value": 0.006433744014976936, "biggest_recent_change": 0.10663879108510699},
{"total_number_of_episodes": 30032, "number_of_timesteps": 9088089, "per_episode_reward": -29.84, "episode_reward_trend_value": 0.005956115080574165, "biggest_recent_change": 0.10663879108510699},
{"total_number_of_episodes": 30042, "number_of_timesteps": 9092084, "per_episode_reward": -29.84, "episode_reward_trend_value": 0.005580979696659503, "biggest_recent_change": 0.10663879108510699},
{"total_number_of_episodes": 30052, "number_of_timesteps": 9098156, "per_episode_reward": -29.78, "episode_reward_trend_value": 0.0053392720828402355, "biggest_recent_change": 0.10663879108510699},
{"total_number_of_episodes": 30062, "number_of_timesteps": 9104988, "per_episode_reward": -29.75, "episode_reward_trend_value": 0.005457115475906428, "biggest_recent_change": 0.10663879108510699},
{"total_number_of_episodes": 30072, "number_of_timesteps": 9108736, "per_episode_reward": -29.7, "episode_reward_trend_value": 0.004814969194877289, "biggest_recent_change": 0.10097578329556356},
{"total_number_of_episodes": 30082, "number_of_timesteps": 9114238, "per_episode_reward": -29.65, "episode_reward_trend_value": 0.004249653580136186, "biggest_recent_change": 0.10097578329556356},
{"total_number_of_episodes": 30092, "number_of_timesteps": 9119420, "per_episode_reward": -29.6, "episode_reward_trend_value": 0.004410275787025202, "biggest_recent_change": 0.10097578329556356},
{"total_number_of_episodes": 30102, "number_of_timesteps": 9124389, "per_episode_reward": -29.55, "episode_reward_trend_value": 0.004665699015325665, "biggest_recent_change": 0.10097578329556356},
{"total_number_of_episodes": 30112, "number_of_timesteps": 9130178, "per_episode_reward": -29.48, "episode_reward_trend_value": 0.004334816323615263, "biggest_recent_change": 0.07119634104162742},
{"total_number_of_episodes": 30123, "number_of_timesteps": 9137746, "per_episode_reward": -29.43, "episode_reward_trend_value": 0.004612355866561104, "biggest_recent_change": 0.07119634104162742},
{"total_number_of_episodes": 30133, "number_of_timesteps": 9143939, "per_episode_reward": -29.4, "episode_reward_trend_value": 0.004834562145715616, "biggest_recent_change": 0.07119634104162742},
{"total_number_of_episodes": 30143, "number_of_timesteps": 9151693, "per_episode_reward": -29.36, "episode_reward_trend_value": 0.0046335876034810045, "biggest_recent_change": 0.07119634104162742},
{"total_number_of_episodes": 30153, "number_of_timesteps": 9157508, "per_episode_reward": -29.34, "episode_reward_trend_value": 0.004607108948277469, "biggest_recent_change": 0.07119634104162742},
{"total_number_of_episodes": 30163, "number_of_timesteps": 9165097, "per_episode_reward": -29.31, "episode_reward_trend_value": 0.004308413379994115, "biggest_recent_change": 0.07119634104162742},
{"total_number_of_episodes": 30173, "number_of_timesteps": 9169442, "per_episode_reward": -29.11, "episode_reward_trend_value": 0.006009354594687958, "biggest_recent_change": 0.19949970286289798},
{"total_number_of_episodes": 30183, "number_of_timesteps": 9172045, "per_episode_reward": -29.04, "episode_reward_trend_value": 0.0061959581443504965, "biggest_recent_change": 0.19949970286289798},
{"total_number_of_episodes": 30193, "number_of_timesteps": 9178558, "per_episode_reward": -28.99, "episode_reward_trend_value": 0.006202676129643495, "biggest_recent_change": 0.19949970286289798},
{"total_number_of_episodes": 30203, "number_of_timesteps": 9181676, "per_episode_reward": -28.95, "episode_reward_trend_value": 0.005937317878311335, "biggest_recent_change": 0.19949970286289798},
{"total_number_of_episodes": 30214, "number_of_timesteps": 9184618, "per_episode_reward": -28.94, "episode_reward_trend_value": 0.0054674105565716506, "biggest_recent_change": 0.19949970286289798},
{"total_number_of_episodes": 30224, "number_of_timesteps": 9187936, "per_episode_reward": -28.9, "episode_reward_trend_value": 0.005610071244269972, "biggest_recent_change": 0.19949970286289798},
{"total_number_of_episodes": 30234, "number_of_timesteps": 9193822, "per_episode_reward": -28.86, "episode_reward_trend_value": 0.005595512610971317, "biggest_recent_change": 0.19949970286289798},
{"total_number_of_episodes": 30244, "number_of_timesteps": 9196984, "per_episode_reward": -28.81, "episode_reward_trend_value": 0.005882327843190775, "biggest_recent_change": 0.19949970286289798},
{"total_number_of_episodes": 30254, "number_of_timesteps": 9201754, "per_episode_reward": -28.77, "episode_reward_trend_value": 0.006013493754031174, "biggest_recent_change": 0.19949970286289798},
{"total_number_of_episodes": 30264, "number_of_timesteps": 9205252, "per_episode_reward": -28.74, "episode_reward_trend_value": 0.00416564867444554, "biggest_recent_change": 0.0761906279269553},
{"total_number_of_episodes": 30274, "number_of_timesteps": 9212615, "per_episode_reward": -28.68, "episode_reward_trend_value": 0.003924242525786031, "biggest_recent_change": 0.054464074547599495},
{"total_number_of_episodes": 30284, "number_of_timesteps": 9217178, "per_episode_reward": -28.67, "episode_reward_trend_value": 0.0036426406509735424, "biggest_recent_change": 0.054464074547599495},
{"total_number_of_episodes": 30294, "number_of_timesteps": 9220735, "per_episode_reward": -28.63, "episode_reward_trend_value": 0.003560437055337889, "biggest_recent_change": 0.054464074547599495},
{"total_number_of_episodes": 30304, "number_of_timesteps": 9226467, "per_episode_reward": -28.47, "episode_reward_trend_value": 0.005149864583550665, "biggest_recent_change": 0.15262565449931387},
{"total_number_of_episodes": 30315, "number_of_timesteps": 9232072, "per_episode_reward": -28.38, "episode_reward_trend_value": 0.005757295793075043, "biggest_recent_change": 0.15262565449931387},
{"total_number_of_episodes": 30325, "number_of_timesteps": 9238590, "per_episode_reward": -28.33, "episode_reward_trend_value": 0.005871134436546891, "biggest_recent_change": 0.15262565449931387},
{"total_number_of_episodes": 30335, "number_of_timesteps": 9245218, "per_episode_reward": -28.27, "episode_reward_trend_value": 0.005927082800280282, "biggest_recent_change": 0.15262565449931387},
{"total_number_of_episodes": 30345, "number_of_timesteps": 9248494, "per_episode_reward": -28.25, "episode_reward_trend_value": 0.0058180800590296, "biggest_recent_change": 0.15262565449931387},
{"total_number_of_episodes": 30355, "number_of_timesteps": 9254195, "per_episode_reward": -28.19, "episode_reward_trend_value": 0.00614165102239094, "biggest_recent_change": 0.15262565449931387},
{"total_number_of_episodes": 30365, "number_of_timesteps": 9258541, "per_episode_reward": -28.15, "episode_reward_trend_value": 0.005977274113526458, "biggest_recent_change": 0.15262565449931387},
{"total_number_of_episodes": 30375, "number_of_timesteps": 9263454, "per_episode_reward": -28.1, "episode_reward_trend_value": 0.00632492539286531, "biggest_recent_change": 0.15262565449931387},
{"total_number_of_episodes": 30385, "number_of_timesteps": 9268620, "per_episode_reward": -28.07, "episode_reward_trend_value": 0.00615736427652058, "biggest_recent_change": 0.15262565449931387},
{"total_number_of_episodes": 30395, "number_of_timesteps": 9275957, "per_episode_reward": -28.05, "episode_reward_trend_value": 0.0047056330906547735, "biggest_recent_change": 0.09392853613031704},
{"total_number_of_episodes": 30405, "number_of_timesteps": 9281340, "per_episode_reward": -28.01, "episode_reward_trend_value": 0.004100346391961393, "biggest_recent_change": 0.06231503240271152},
{"total_number_of_episodes": 30415, "number_of_timesteps": 9288334, "per_episode_reward": -27.96, "episode_reward_trend_value": 0.004082152036821856, "biggest_recent_change": 0.06231503240271152},
{"total_number_of_episodes": 30425, "number_of_timesteps": 9295282, "per_episode_reward": -27.87, "episode_reward_trend_value": 0.004460566726192718, "biggest_recent_change": 0.09236575584219509},
{"total_number_of_episodes": 30435, "number_of_timesteps": 9302697, "per_episode_reward": -27.84, "episode_reward_trend_value": 0.004575065651923735, "biggest_recent_change": 0.09236575584219509},
{"total_number_of_episodes": 30445, "number_of_timesteps": 9310124, "per_episode_reward": -27.81, "episode_reward_trend_value": 0.004232011458983425, "biggest_recent_change": 0.09236575584219509},
{"total_number_of_episodes": 30455, "number_of_timesteps": 9318882, "per_episode_reward": -27.78, "episode_reward_trend_value": 0.004079172727553152, "biggest_recent_change": 0.09236575584219509},
{"total_number_of_episodes": 30465, "number_of_timesteps": 9324777, "per_episode_reward": -27.74, "episode_reward_trend_value": 0.003994921147589597, "biggest_recent_change": 0.09236575584219509},
{"total_number_of_episodes": 30475, "number_of_timesteps": 9332549, "per_episode_reward": -27.71, "episode_reward_trend_value": 0.003996394047477815, "biggest_recent_change": 0.09236575584219509},
{"total_number_of_episodes": 30485, "number_of_timesteps": 9339282, "per_episode_reward": -27.66, "episode_reward_trend_value": 0.004343271057262478, "biggest_recent_change": 0.09236575584219509},
{"total_number_of_episodes": 30495, "number_of_timesteps": 9345520, "per_episode_reward": -27.65, "episode_reward_trend_value": 0.004022286361974952, "biggest_recent_change": 0.09236575584219509},
{"total_number_of_episodes": 30506, "number_of_timesteps": 9352512, "per_episode_reward": -27.63, "episode_reward_trend_value": 0.0037282700220412184, "biggest_recent_change": 0.09236575584219509},
{"total_number_of_episodes": 30516, "number_of_timesteps": 9358168, "per_episode_reward": -27.57, "episode_reward_trend_value": 0.003289019066454833, "biggest_recent_change": 0.05318877865201088},
{"total_number_of_episodes": 30526, "number_of_timesteps": 9363775, "per_episode_reward": -27.53, "episode_reward_trend_value": 0.0034471569607865383, "biggest_recent_change": 0.05318877865201088},
{"total_number_of_episodes": 30536, "number_of_timesteps": 9368561, "per_episode_reward": -27.45, "episode_reward_trend_value": 0.003911116693737979, "biggest_recent_change": 0.07319653100371326},
{"total_number_of_episodes": 30546, "number_of_timesteps": 9377687, "per_episode_reward": -27.38, "episode_reward_trend_value": 0.004463573658731413, "biggest_recent_change": 0.07563579377048057},
{"total_number_of_episodes": 30556, "number_of_timesteps": 9384559, "per_episode_reward": -27.36, "episode_reward_trend_value": 0.004143452923219431, "biggest_recent_change": 0.07563579377048057},
{"total_number_of_episodes": 30566, "number_of_timesteps": 9390492, "per_episode_reward": -27.17, "episode_reward_trend_value": 0.005998857553608122, "biggest_recent_change": 0.19195425206842032},
{"total_number_of_episodes": 30576, "number_of_timesteps": 9395117, "per_episode_reward": -27.12, "episode_reward_trend_value": 0.005962986132973016, "biggest_recent_change": 0.19195425206842032},
{"total_number_of_episodes": 30586, "number_of_timesteps": 9401654, "per_episode_reward": -27.03, "episode_reward_trend_value": 0.006905512638131483, "biggest_recent_change": 0.19195425206842032},
{"total_number_of_episodes": 30596, "number_of_timesteps": 9408557, "per_episode_reward": -26.99, "episode_reward_trend_value": 0.007072866509779946, "biggest_recent_change": 0.19195425206842032},
{"total_number_of_episodes": 30606, "number_of_timesteps": 9413941, "per_episode_reward": -26.95, "episode_reward_trend_value": 0.006996770910385584, "biggest_recent_change": 0.19195425206842032},
{"total_number_of_episodes": 30616, "number_of_timesteps": 9419496, "per_episode_reward": -26.87, "episode_reward_trend_value": 0.007311680095594121, "biggest_recent_change": 0.19195425206842032},
{"total_number_of_episodes": 30626, "number_of_timesteps": 9425533, "per_episode_reward": -26.72, "episode_reward_trend_value": 0.008177310827047497, "biggest_recent_change": 0.19195425206842032},
{"total_number_of_episodes": 30636, "number_of_timesteps": 9430331, "per_episode_reward": -26.64, "episode_reward_trend_value": 0.008230538217024257, "biggest_recent_change": 0.19195425206842032},
{"total_number_of_episodes": 30646, "number_of_timesteps": 9433657, "per_episode_reward": -26.55, "episode_reward_trend_value": 0.009052815789464536, "biggest_recent_change": 0.19195425206842032},
{"total_number_of_episodes": 30656, "number_of_timesteps": 9439758, "per_episode_reward": -26.49, "episode_reward_trend_value": 0.007584550573006707, "biggest_recent_change": 0.15110329683451695},
{"total_number_of_episodes": 30666, "number_of_timesteps": 9444019, "per_episode_reward": -26.43, "episode_reward_trend_value": 0.007673878421451856, "biggest_recent_change": 0.15110329683451695},
{"total_number_of_episodes": 30676, "number_of_timesteps": 9448312, "per_episode_reward": -26.38, "episode_reward_trend_value": 0.00724223350425568, "biggest_recent_change": 0.15110329683451695},
{"total_number_of_episodes": 30686, "number_of_timesteps": 9451471, "per_episode_reward": -26.3, "episode_reward_trend_value": 0.007716558979342381, "biggest_recent_change": 0.15110329683451695},
{"total_number_of_episodes": 30696, "number_of_timesteps": 9456151, "per_episode_reward": -26.27, "episode_reward_trend_value": 0.007509008011070545, "biggest_recent_change": 0.15110329683451695},
{"total_number_of_episodes": 30706, "number_of_timesteps": 9461960, "per_episode_reward": -26.26, "episode_reward_trend_value": 0.006772419829284122, "biggest_recent_change": 0.15110329683451695},
{"total_number_of_episodes": 30716, "number_of_timesteps": 9465630, "per_episode_reward": -26.21, "episode_reward_trend_value": 0.005629039268304147, "biggest_recent_change": 0.08714005058626739},
{"total_number_of_episodes": 30726, "number_of_timesteps": 9470541, "per_episode_reward": -26.09, "episode_reward_trend_value": 0.00604294887866372, "biggest_recent_change": 0.11767812380075071},
{"total_number_of_episodes": 30736, "number_of_timesteps": 9476171, "per_episode_reward": -26.04, "episode_reward_trend_value": 0.005671896926407566, "biggest_recent_change": 0.11767812380075071},
{"total_number_of_episodes": 30746, "number_of_timesteps": 9482067, "per_episode_reward": -26.0, "episode_reward_trend_value": 0.005468240579990969, "biggest_recent_change": 0.11767812380075071},
{"total_number_of_episodes": 30756, "number_of_timesteps": 9488026, "per_episode_reward": -25.94, "episode_reward_trend_value": 0.00550571970699107, "biggest_recent_change": 0.11767812380075071},
{"total_number_of_episodes": 30767, "number_of_timesteps": 9494865, "per_episode_reward": -25.89, "episode_reward_trend_value": 0.005419167834194423, "biggest_recent_change": 0.11767812380075071},
{"total_number_of_episodes": 30777, "number_of_timesteps": 9499766, "per_episode_reward": -25.84, "episode_reward_trend_value": 0.005090248040142677, "biggest_recent_change": 0.11767812380075071},
{"total_number_of_episodes": 30787, "number_of_timesteps": 9504719, "per_episode_reward": -25.77, "episode_reward_trend_value": 0.00550807075346174, "biggest_recent_change": 0.11767812380075071},
{"total_number_of_episodes": 30797, "number_of_timesteps": 9509614, "per_episode_reward": -25.69, "episode_reward_trend_value": 0.006286353378729912, "biggest_recent_change": 0.11767812380075071},
{"total_number_of_episodes": 30807, "number_of_timesteps": 9513196, "per_episode_reward": -25.66, "episode_reward_trend_value": 0.006133264282844506, "biggest_recent_change": 0.11767812380075071},
{"total_number_of_episodes": 30817, "number_of_timesteps": 9520791, "per_episode_reward": -25.57, "episode_reward_trend_value": 0.005839043700822681, "biggest_recent_change": 0.09119827141878645},
{"total_number_of_episodes": 30827, "number_of_timesteps": 9528621, "per_episode_reward": -25.45, "episode_reward_trend_value": 0.0065349273872933045, "biggest_recent_change": 0.11637490666556971},
{"total_number_of_episodes": 30837, "number_of_timesteps": 9534645, "per_episode_reward": -25.41, "episode_reward_trend_value": 0.0065588151391175135, "biggest_recent_change": 0.11637490666556971},
{"total_number_of_episodes": 30847, "number_of_timesteps": 9542098, "per_episode_reward": -25.33, "episode_reward_trend_value": 0.0067273946424015445, "biggest_recent_change": 0.11637490666556971},
{"total_number_of_episodes": 30857, "number_of_timesteps": 9547161, "per_episode_reward": -25.24, "episode_reward_trend_value": 0.0071467650487047115, "biggest_recent_change": 0.11637490666556971},
{"total_number_of_episodes": 30867, "number_of_timesteps": 9556133, "per_episode_reward": -25.18, "episode_reward_trend_value": 0.007271290169266385, "biggest_recent_change": 0.11637490666556971},
{"total_number_of_episodes": 30877, "number_of_timesteps": 9564835, "per_episode_reward": -25.16, "episode_reward_trend_value": 0.00686394834706875, "biggest_recent_change": 0.11637490666556971},
{"total_number_of_episodes": 30887, "number_of_timesteps": 9570993, "per_episode_reward": -25.12, "episode_reward_trend_value": 0.00631557114770796, "biggest_recent_change": 0.11637490666556971},
{"total_number_of_episodes": 30897, "number_of_timesteps": 9577412, "per_episode_reward": -25.1, "episode_reward_trend_value": 0.006245941772173088, "biggest_recent_change": 0.11637490666556971},
{"total_number_of_episodes": 30907, "number_of_timesteps": 9582915, "per_episode_reward": -25.07, "episode_reward_trend_value": 0.005491450481259442, "biggest_recent_change": 0.11637490666556971},
{"total_number_of_episodes": 30917, "number_of_timesteps": 9589448, "per_episode_reward": -25.03, "episode_reward_trend_value": 0.004707591792532323, "biggest_recent_change": 0.08649712160422851},
{"total_number_of_episodes": 30927, "number_of_timesteps": 9596666, "per_episode_reward": -24.97, "episode_reward_trend_value": 0.004850197302487618, "biggest_recent_change": 0.08649712160422851},
{"total_number_of_episodes": 30938, "number_of_timesteps": 9604554, "per_episode_reward": -24.9, "episode_reward_trend_value": 0.00474557794414048, "biggest_recent_change": 0.08649712160422851},
{"total_number_of_episodes": 30948, "number_of_timesteps": 9609734, "per_episode_reward": -24.81, "episode_reward_trend_value": 0.004801477896238597, "biggest_recent_change": 0.0915281172930591},
{"total_number_of_episodes": 30958, "number_of_timesteps": 9615059, "per_episode_reward": -24.75, "episode_reward_trend_value": 0.004803971975075783, "biggest_recent_change": 0.0915281172930591},
{"total_number_of_episodes": 30968, "number_of_timesteps": 9621742, "per_episode_reward": -24.71, "episode_reward_trend_value": 0.004988171813711636, "biggest_recent_change": 0.0915281172930591},
{"total_number_of_episodes": 30978, "number_of_timesteps": 9628520, "per_episode_reward": -24.69, "episode_reward_trend_value": 0.004863334928200855, "biggest_recent_change": 0.0915281172930591},
{"total_number_of_episodes": 30988, "number_of_timesteps": 9633162, "per_episode_reward": -24.6, "episode_reward_trend_value": 0.005539040988994238, "biggest_recent_change": 0.0915281172930591},
{"total_number_of_episodes": 30998, "number_of_timesteps": 9639554, "per_episode_reward": -24.58, "episode_reward_trend_value": 0.005518061216685963, "biggest_recent_change": 0.0915281172930591},
{"total_number_of_episodes": 31008, "number_of_timesteps": 9648000, "per_episode_reward": -24.53, "episode_reward_trend_value": 0.005536441638282123, "biggest_recent_change": 0.0915281172930591},
{"total_number_of_episodes": 31018, "number_of_timesteps": 9652860, "per_episode_reward": -24.51, "episode_reward_trend_value": 0.0051064506340937205, "biggest_recent_change": 0.0915281172930591},
{"total_number_of_episodes": 31028, "number_of_timesteps": 9659227, "per_episode_reward": -24.47, "episode_reward_trend_value": 0.004843854948790178, "biggest_recent_change": 0.0915281172930591},
{"total_number_of_episodes": 31038, "number_of_timesteps": 9665316, "per_episode_reward": -24.37, "episode_reward_trend_value": 0.004877155567919544, "biggest_recent_change": 0.09452517301470209},
{"total_number_of_episodes": 31048, "number_of_timesteps": 9669979, "per_episode_reward": -24.34, "episode_reward_trend_value": 0.0045934484657952305, "biggest_recent_change": 0.09452517301470209},
{"total_number_of_episodes": 31058, "number_of_timesteps": 9675839, "per_episode_reward": -24.29, "episode_reward_trend_value": 0.00466984015839071, "biggest_recent_change": 0.09452517301470209},
{"total_number_of_episodes": 31068, "number_of_timesteps": 9682584, "per_episode_reward": -24.21, "episode_reward_trend_value": 0.005337987664105152, "biggest_recent_change": 0.09452517301470209},
{"total_number_of_episodes": 31078, "number_of_timesteps": 9688274, "per_episode_reward": -24.09, "episode_reward_trend_value": 0.00559256918241648, "biggest_recent_change": 0.11188026603791812},
{"total_number_of_episodes": 31088, "number_of_timesteps": 9693022, "per_episode_reward": -24.07, "episode_reward_trend_value": 0.005671017576077809, "biggest_recent_change": 0.11188026603791812},
{"total_number_of_episodes": 31098, "number_of_timesteps": 9697632, "per_episode_reward": -24.05, "episode_reward_trend_value": 0.005350986091019018, "biggest_recent_change": 0.11188026603791812},
{"total_number_of_episodes": 31108, "number_of_timesteps": 9703616, "per_episode_reward": -24.02, "episode_reward_trend_value": 0.005439985286138496, "biggest_recent_change": 0.11188026603791812},
{"total_number_of_episodes": 31118, "number_of_timesteps": 9708561, "per_episode_reward": -24.01, "episode_reward_trend_value": 0.005048000262504439, "biggest_recent_change": 0.11188026603791812},
{"total_number_of_episodes": 31128, "number_of_timesteps": 9713194, "per_episode_reward": -24.01, "episode_reward_trend_value": 0.004091971371847376, "biggest_recent_change": 0.11188026603791812},
{"total_number_of_episodes": 31138, "number_of_timesteps": 9718075, "per_episode_reward": -24.0, "episode_reward_trend_value": 0.003806231746822419, "biggest_recent_change": 0.11188026603791812},
{"total_number_of_episodes": 31148, "number_of_timesteps": 9724241, "per_episode_reward": -23.98, "episode_reward_trend_value": 0.0034513853726036896, "biggest_recent_change": 0.11188026603791812},
{"total_number_of_episodes": 31158, "number_of_timesteps": 9730362, "per_episode_reward": -23.94, "episode_reward_trend_value": 0.003011831850598767, "biggest_recent_change": 0.11188026603791812},
{"total_number_of_episodes": 31168, "number_of_timesteps": 9736712, "per_episode_reward": -23.88, "episode_reward_trend_value": 0.0024334826800391737, "biggest_recent_change": 0.059828840687554674},
{"total_number_of_episodes": 31178, "number_of_timesteps": 9742073, "per_episode_reward": -23.84, "episode_reward_trend_value": 0.0025251291124559335, "biggest_recent_change": 0.059828840687554674},
{"total_number_of_episodes": 31188, "number_of_timesteps": 9749572, "per_episode_reward": -23.72, "episode_reward_trend_value": 0.00363357196132957, "biggest_recent_change": 0.11843888536711944},
{"total_number_of_episodes": 31198, "number_of_timesteps": 9754343, "per_episode_reward": -23.64, "episode_reward_trend_value": 0.004194900627408495, "biggest_recent_change": 0.11843888536711944},
{"total_number_of_episodes": 31208, "number_of_timesteps": 9760131, "per_episode_reward": -23.44, "episode_reward_trend_value": 0.006355640230837839, "biggest_recent_change": 0.20268369213350113},
{"total_number_of_episodes": 31218, "number_of_timesteps": 9765095, "per_episode_reward": -23.43, "episode_reward_trend_value": 0.006437515976420174, "biggest_recent_change": 0.20268369213350113},
{"total_number_of_episodes": 31228, "number_of_timesteps": 9768480, "per_episode_reward": -23.39, "episode_reward_trend_value": 0.0066853370629327375, "biggest_recent_change": 0.20268369213350113},
{"total_number_of_episodes": 31238, "number_of_timesteps": 9772324, "per_episode_reward": -23.36, "episode_reward_trend_value": 0.0068743687670491955, "biggest_recent_change": 0.20268369213350113},
{"total_number_of_episodes": 31248, "number_of_timesteps": 9778698, "per_episode_reward": -23.34, "episode_reward_trend_value": 0.006636820149661401, "biggest_recent_change": 0.20268369213350113},
{"total_number_of_episodes": 31258, "number_of_timesteps": 9788286, "per_episode_reward": -23.32, "episode_reward_trend_value": 0.006225881762993642, "biggest_recent_change": 0.20268369213350113},
{"total_number_of_episodes": 31268, "number_of_timesteps": 9793532, "per_episode_reward": -23.23, "episode_reward_trend_value": 0.006714649043035534, "biggest_recent_change": 0.20268369213350113},
{"total_number_of_episodes": 31278, "number_of_timesteps": 9798012, "per_episode_reward": -23.21, "episode_reward_trend_value": 0.0056715141051034285, "biggest_recent_change": 0.20268369213350113},
{"total_number_of_episodes": 31289, "number_of_timesteps": 9804186, "per_episode_reward": -23.2, "episode_reward_trend_value": 0.004980659502459477, "biggest_recent_change": 0.20268369213350113},
{"total_number_of_episodes": 31299, "number_of_timesteps": 9808799, "per_episode_reward": -23.08, "episode_reward_trend_value": 0.004052702178061512, "biggest_recent_change": 0.11916753293768423},
{"total_number_of_episodes": 31309, "number_of_timesteps": 9814021, "per_episode_reward": -23.04, "episode_reward_trend_value": 0.00428015234377273, "biggest_recent_change": 0.11916753293768423},
{"total_number_of_episodes": 31320, "number_of_timesteps": 9819431, "per_episode_reward": -22.99, "episode_reward_trend_value": 0.004459127780533163, "biggest_recent_change": 0.11916753293768423},
{"total_number_of_episodes": 31331, "number_of_timesteps": 9824850, "per_episode_reward": -22.96, "episode_reward_trend_value": 0.004456745429050812, "biggest_recent_change": 0.11916753293768423},
{"total_number_of_episodes": 31341, "number_of_timesteps": 9831429, "per_episode_reward": -22.78, "episode_reward_trend_value": 0.006155279533412678, "biggest_recent_change": 0.17206223502090978},
{"total_number_of_episodes": 31351, "number_of_timesteps": 9837029, "per_episode_reward": -22.74, "episode_reward_trend_value": 0.006357874642398976, "biggest_recent_change": 0.17206223502090978},
{"total_number_of_episodes": 31361, "number_of_timesteps": 9844218, "per_episode_reward": -22.71, "episode_reward_trend_value": 0.005773649626853819, "biggest_recent_change": 0.17206223502090978},
{"total_number_of_episodes": 31371, "number_of_timesteps": 9850752, "per_episode_reward": -22.69, "episode_reward_trend_value": 0.0057332087229624625, "biggest_recent_change": 0.17206223502090978},
{"total_number_of_episodes": 31381, "number_of_timesteps": 9857556, "per_episode_reward": -22.67, "episode_reward_trend_value": 0.005885536679713768, "biggest_recent_change": 0.17206223502090978},
{"total_number_of_episodes": 31391, "number_of_timesteps": 9863877, "per_episode_reward": -22.64, "episode_reward_trend_value": 0.004843036645144849, "biggest_recent_change": 0.17206223502090978},
{"total_number_of_episodes": 31401, "number_of_timesteps": 9870754, "per_episode_reward": -22.61, "episode_reward_trend_value": 0.0047932769135964216, "biggest_recent_change": 0.17206223502090978},
{"total_number_of_episodes": 31412, "number_of_timesteps": 9876369, "per_episode_reward": -22.58, "episode_reward_trend_value": 0.004600249888572745, "biggest_recent_change": 0.17206223502090978},
{"total_number_of_episodes": 31422, "number_of_timesteps": 9882014, "per_episode_reward": -22.54, "episode_reward_trend_value": 0.004665101256396219, "biggest_recent_change": 0.17206223502090978},
{"total_number_of_episodes": 31432, "number_of_timesteps": 9889429, "per_episode_reward": -22.5, "episode_reward_trend_value": 0.003119955085215567, "biggest_recent_change": 0.04240038792270795},
{"total_number_of_episodes": 31442, "number_of_timesteps": 9894902, "per_episode_reward": -22.43, "episode_reward_trend_value": 0.003430074369324229, "biggest_recent_change": 0.06898868126600277},
{"total_number_of_episodes": 31452, "number_of_timesteps": 9900479, "per_episode_reward": -22.4, "episode_reward_trend_value": 0.0034459378852206317, "biggest_recent_change": 0.06898868126600277},
{"total_number_of_episodes": 31462, "number_of_timesteps": 9904258, "per_episode_reward": -22.38, "episode_reward_trend_value": 0.003516723232316189, "biggest_recent_change": 0.06898868126600277},
{"total_number_of_episodes": 31472, "number_of_timesteps": 9908167, "per_episode_reward": -22.22, "episode_reward_trend_value": 0.0049376232064162195, "biggest_recent_change": 0.15570962163944202},

{"total_number_of_episodes": 31482, "number_of_timesteps": 9911416, "per_episode_reward": -22.15, "episode_reward_trend_value": 0.00541135544985699, "biggest_recent_change": 0.15570962163944202},
{"total_number_of_episodes": 31492, "number_of_timesteps": 9916801, "per_episode_reward": -22.14, "episode_reward_trend_value": 0.005204069437089605, "biggest_recent_change": 0.15570962163944202},
{"total_number_of_episodes": 31502, "number_of_timesteps": 9924435, "per_episode_reward": -22.1, "episode_reward_trend_value": 0.005270557561864011, "biggest_recent_change": 0.15570962163944202},
{"total_number_of_episodes": 31512, "number_of_timesteps": 9932831, "per_episode_reward": -22.07, "episode_reward_trend_value": 0.005232503217070633, "biggest_recent_change": 0.15570962163944202},
{"total_number_of_episodes": 31522, "number_of_timesteps": 9940270, "per_episode_reward": -22.02, "episode_reward_trend_value": 0.005375121064413019, "biggest_recent_change": 0.15570962163944202},
{"total_number_of_episodes": 31532, "number_of_timesteps": 9947811, "per_episode_reward": -21.98, "episode_reward_trend_value": 0.005091167825592535, "biggest_recent_change": 0.15570962163944202},
{"total_number_of_episodes": 31542, "number_of_timesteps": 9953859, "per_episode_reward": -21.96, "episode_reward_trend_value": 0.004968693602098047, "biggest_recent_change": 0.15570962163944202},
{"total_number_of_episodes": 31552, "number_of_timesteps": 9961705, "per_episode_reward": -21.9, "episode_reward_trend_value": 0.005295080032941494, "biggest_recent_change": 0.15570962163944202},
{"total_number_of_episodes": 31562, "number_of_timesteps": 9966297, "per_episode_reward": -21.87, "episode_reward_trend_value": 0.003918467159449079, "biggest_recent_change": 0.06797843173615092},
{"total_number_of_episodes": 31572, "number_of_timesteps": 9974328, "per_episode_reward": -21.82, "episode_reward_trend_value": 0.003743539439212403, "biggest_recent_change": 0.056662519617518115},

{"total_number_of_episodes": 31582, "number_of_timesteps": 9979618, "per_episode_reward": -21.78, "episode_reward_trend_value": 0.0040143749771773055, "biggest_recent_change": 0.056662519617518115},
{"total_number_of_episodes": 31592, "number_of_timesteps": 9983107, "per_episode_reward": -21.69, "episode_reward_trend_value": 0.00459957372584125, "biggest_recent_change": 0.08891540673216625},
{"total_number_of_episodes": 31602, "number_of_timesteps": 9987227, "per_episode_reward": -21.59, "episode_reward_trend_value": 0.005337378686983227, "biggest_recent_change": 0.1053779433940818},
{"total_number_of_episodes": 31612, "number_of_timesteps": 9990748, "per_episode_reward": -21.53, "episode_reward_trend_value": 0.005419982300614971, "biggest_recent_change": 0.1053779433940818},
{"total_number_of_episodes": 31623, "number_of_timesteps": 9994752, "per_episode_reward": -21.49, "episode_reward_trend_value": 0.005388733625572012, "biggest_recent_change": 0.1053779433940818},
{"total_number_of_episodes": 31633, "number_of_timesteps": 9997117, "per_episode_reward": -21.47, "episode_reward_trend_value": 0.005390248955612581, "biggest_recent_change": 0.1053779433940818},
{"total_number_of_episodes": 31643, "number_of_timesteps": 10002123, "per_episode_reward": -21.45, "episode_reward_trend_value": 0.005029590752441453, "biggest_recent_change": 0.1053779433940818},
{"total_number_of_episodes": 31653, "number_of_timesteps": 10005419, "per_episode_reward": -21.37, "episode_reward_trend_value": 0.005512710693879047, "biggest_recent_change": 0.1053779433940818},
{"total_number_of_episodes": 31663, "number_of_timesteps": 10010081, "per_episode_reward": -21.27, "episode_reward_trend_value": 0.006075758016203873, "biggest_recent_change": 0.1053779433940818},
{"total_number_of_episodes": 31673, "number_of_timesteps": 10012853, "per_episode_reward": -21.19, "episode_reward_trend_value": 0.0065617292687793986, "biggest_recent_change": 0.1053779433940818},
{"total_number_of_episodes": 31683, "number_of_timesteps": 10015936, "per_episode_reward": -21.12, "episode_reward_trend_value": 0.006353241181459286, "biggest_recent_change": 0.1053779433940818},
{"total_number_of_episodes": 31693, "number_of_timesteps": 10022405, "per_episode_reward": -21.04, "episode_reward_trend_value": 0.006100515528796693, "biggest_recent_change": 0.10290919592408443},
{"total_number_of_episodes": 31703, "number_of_timesteps": 10026474, "per_episode_reward": -20.99, "episode_reward_trend_value": 0.005991046297253138, "biggest_recent_change": 0.10290919592408443},
{"total_number_of_episodes": 31713, "number_of_timesteps": 10029086, "per_episode_reward": -20.91, "episode_reward_trend_value": 0.006416418132266817, "biggest_recent_change": 0.10290919592408443},
{"total_number_of_episodes": 31723, "number_of_timesteps": 10033130, "per_episode_reward": -20.85, "episode_reward_trend_value": 0.006879157279646916, "biggest_recent_change": 0.10290919592408443},
{"total_number_of_episodes": 31733, "number_of_timesteps": 10035689, "per_episode_reward": -20.82, "episode_reward_trend_value": 0.006951281217127558, "biggest_recent_change": 0.10290919592408443},
{"total_number_of_episodes": 31743, "number_of_timesteps": 10040002, "per_episode_reward": -20.78, "episode_reward_trend_value": 0.006546607014415428, "biggest_recent_change": 0.10290919592408443},
{"total_number_of_episodes": 31753, "number_of_timesteps": 10044457, "per_episode_reward": -20.76, "episode_reward_trend_value": 0.005647999199226206, "biggest_recent_change": 0.08263263465444837},
{"total_number_of_episodes": 31763, "number_of_timesteps": 10051107, "per_episode_reward": -20.71, "episode_reward_trend_value": 0.005325234070345727, "biggest_recent_change": 0.08263263465444837},
{"total_number_of_episodes": 31773, "number_of_timesteps": 10057510, "per_episode_reward": -20.68, "episode_reward_trend_value": 0.004835485395460795, "biggest_recent_change": 0.08263263465444837},
{"total_number_of_episodes": 31783, "number_of_timesteps": 10063478, "per_episode_reward": -20.64, "episode_reward_trend_value": 0.004346792659541876, "biggest_recent_change": 0.0789039741695241},
{"total_number_of_episodes": 31793, "number_of_timesteps": 10067631, "per_episode_reward": -20.63, "episode_reward_trend_value": 0.00401343795055098, "biggest_recent_change": 0.0789039741695241},
{"total_number_of_episodes": 31803, "number_of_timesteps": 10070750, "per_episode_reward": -20.58, "episode_reward_trend_value": 0.0037117457713515185, "biggest_recent_change": 0.060311153164580134},
{"total_number_of_episodes": 31813, "number_of_timesteps": 10076144, "per_episode_reward": -20.55, "episode_reward_trend_value": 0.0033786560433918334, "biggest_recent_change": 0.05225153743295863},
{"total_number_of_episodes": 31824, "number_of_timesteps": 10082228, "per_episode_reward": -20.5, "episode_reward_trend_value": 0.0035523799295681217, "biggest_recent_change": 0.05225153743295863},
{"total_number_of_episodes": 31835, "number_of_timesteps": 10086357, "per_episode_reward": -20.48, "episode_reward_trend_value": 0.0033693287618343087, "biggest_recent_change": 0.05225153743295863},
{"total_number_of_episodes": 31845, "number_of_timesteps": 10091179, "per_episode_reward": -20.42, "episode_reward_trend_value": 0.0037883196414783293, "biggest_recent_change": 0.059743671725016156},
{"total_number_of_episodes": 31855, "number_of_timesteps": 10098352, "per_episode_reward": -20.4, "episode_reward_trend_value": 0.0034456148947111923, "biggest_recent_change": 0.059743671725016156},
{"total_number_of_episodes": 31865, "number_of_timesteps": 10104313, "per_episode_reward": -20.38, "episode_reward_trend_value": 0.0034047979410212056, "biggest_recent_change": 0.059743671725016156},
{"total_number_of_episodes": 31875, "number_of_timesteps": 10111144, "per_episode_reward": -20.29, "episode_reward_trend_value": 0.003946435224663524, "biggest_recent_change": 0.0873976439495543},
{"total_number_of_episodes": 31885, "number_of_timesteps": 10116024, "per_episode_reward": -20.24, "episode_reward_trend_value": 0.004332932925857196, "biggest_recent_change": 0.0873976439495543},
{"total_number_of_episodes": 31895, "number_of_timesteps": 10122089, "per_episode_reward": -20.21, "episode_reward_trend_value": 0.004134651044004695, "biggest_recent_change": 0.0873976439495543},
{"total_number_of_episodes": 31905, "number_of_timesteps": 10128091, "per_episode_reward": -20.16, "episode_reward_trend_value": 0.004272925503916466, "biggest_recent_change": 0.0873976439495543},
{"total_number_of_episodes": 31915, "number_of_timesteps": 10135742, "per_episode_reward": -20.11, "episode_reward_trend_value": 0.004398046595260751, "biggest_recent_change": 0.0873976439495543},
{"total_number_of_episodes": 31925, "number_of_timesteps": 10140697, "per_episode_reward": -20.06, "episode_reward_trend_value": 0.004727254487217536, "biggest_recent_change": 0.0873976439495543},
{"total_number_of_episodes": 31935, "number_of_timesteps": 10147332, "per_episode_reward": -19.99, "episode_reward_trend_value": 0.004834980653047596, "biggest_recent_change": 0.0873976439495543},
{"total_number_of_episodes": 31945, "number_of_timesteps": 10154293, "per_episode_reward": -19.91, "episode_reward_trend_value": 0.005458571399625356, "biggest_recent_change": 0.0873976439495543},
{"total_number_of_episodes": 31955, "number_of_timesteps": 10160765, "per_episode_reward": -19.87, "episode_reward_trend_value": 0.005624441212599271, "biggest_recent_change": 0.0873976439495543},
{"total_number_of_episodes": 31965, "number_of_timesteps": 10164544, "per_episode_reward": -19.83, "episode_reward_trend_value": 0.0050654243541386115, "biggest_recent_change": 0.0775312774159147},
{"total_number_of_episodes": 31975, "number_of_timesteps": 10168836, "per_episode_reward": -19.79, "episode_reward_trend_value": 0.005060707716985233, "biggest_recent_change": 0.0775312774159147},
{"total_number_of_episodes": 31985, "number_of_timesteps": 10175968, "per_episode_reward": -19.74, "episode_reward_trend_value": 0.0051532826674037975, "biggest_recent_change": 0.0775312774159147},

{"total_number_of_episodes": 31995, "number_of_timesteps": 10178867, "per_episode_reward": -19.72, "episode_reward_trend_value": 0.004944415971926672, "biggest_recent_change": 0.0775312774159147},
{"total_number_of_episodes": 32005, "number_of_timesteps": 10185035, "per_episode_reward": -19.67, "episode_reward_trend_value": 0.0048523816018686714, "biggest_recent_change": 0.0775312774159147},
{"total_number_of_episodes": 32015, "number_of_timesteps": 10188924, "per_episode_reward": -19.63, "episode_reward_trend_value": 0.0047119116602459595, "biggest_recent_change": 0.0775312774159147},
{"total_number_of_episodes": 32026, "number_of_timesteps": 10197506, "per_episode_reward": -19.57, "episode_reward_trend_value": 0.004597491444040989, "biggest_recent_change": 0.0775312774159147},
{"total_number_of_episodes": 32036, "number_of_timesteps": 10201684, "per_episode_reward": -19.52, "episode_reward_trend_value": 0.00425953445261512, "biggest_recent_change": 0.05914120719127425},
{"total_number_of_episodes": 32046, "number_of_timesteps": 10205320, "per_episode_reward": -19.48, "episode_reward_trend_value": 0.004364448326876532, "biggest_recent_change": 0.05914120719127425},
{"total_number_of_episodes": 32056, "number_of_timesteps": 10211222, "per_episode_reward": -19.44, "episode_reward_trend_value": 0.004396241032326742, "biggest_recent_change": 0.05914120719127425},
{"total_number_of_episodes": 32066, "number_of_timesteps": 10217680, "per_episode_reward": -19.41, "episode_reward_trend_value": 0.004127647435858369, "biggest_recent_change": 0.05914120719127425},
{"total_number_of_episodes": 32076, "number_of_timesteps": 10222706, "per_episode_reward": -19.38, "episode_reward_trend_value": 0.004031662993048476, "biggest_recent_change": 0.05914120719127425},
{"total_number_of_episodes": 32086, "number_of_timesteps": 10228778, "per_episode_reward": -19.33, "episode_reward_trend_value": 0.004371670469182555, "biggest_recent_change": 0.05914120719127425},
{"total_number_of_episodes": 32096, "number_of_timesteps": 10235724, "per_episode_reward": -19.31, "episode_reward_trend_value": 0.003961392143589669, "biggest_recent_change": 0.05914120719127425},
{"total_number_of_episodes": 32106, "number_of_timesteps": 10240202, "per_episode_reward": -19.26, "episode_reward_trend_value": 0.004088211804997539, "biggest_recent_change": 0.05914120719127425},
{"total_number_of_episodes": 32116, "number_of_timesteps": 10246085, "per_episode_reward": -19.22, "episode_reward_trend_value": 0.0038764970310363684, "biggest_recent_change": 0.05458044929939376},
{"total_number_of_episodes": 32126, "number_of_timesteps": 10253742, "per_episode_reward": -19.16, "episode_reward_trend_value": 0.004090797245478386, "biggest_recent_change": 0.06640216748736805},
{"total_number_of_episodes": 32137, "number_of_timesteps": 10260697, "per_episode_reward": -19.12, "episode_reward_trend_value": 0.003948691253808, "biggest_recent_change": 0.06640216748736805},
{"total_number_of_episodes": 32147, "number_of_timesteps": 10265595, "per_episode_reward": -19.07, "episode_reward_trend_value": 0.004036388070282489, "biggest_recent_change": 0.06640216748736805},
{"total_number_of_episodes": 32157, "number_of_timesteps": 10271271, "per_episode_reward": -19.02, "episode_reward_trend_value": 0.004405713111635931, "biggest_recent_change": 0.06640216748736805},
{"total_number_of_episodes": 32167, "number_of_timesteps": 10278082, "per_episode_reward": -19.0, "episode_reward_trend_value": 0.004213214185819444, "biggest_recent_change": 0.06640216748736805},
{"total_number_of_episodes": 32177, "number_of_timesteps": 10285321, "per_episode_reward": -18.97, "episode_reward_trend_value": 0.003964227345379001, "biggest_recent_change": 0.06640216748736805},
{"total_number_of_episodes": 32187, "number_of_timesteps": 10288842, "per_episode_reward": -18.92, "episode_reward_trend_value": 0.004353639396715023, "biggest_recent_change": 0.06640216748736805},
{"total_number_of_episodes": 32197, "number_of_timesteps": 10292321, "per_episode_reward": -18.88, "episode_reward_trend_value": 0.004202680588430654, "biggest_recent_change": 0.06640216748736805},
{"total_number_of_episodes": 32207, "number_of_timesteps": 10299009, "per_episode_reward": -18.82, "episode_reward_trend_value": 0.0044422322204392605, "biggest_recent_change": 0.06640216748736805},
{"total_number_of_episodes": 32218, "number_of_timesteps": 10303644, "per_episode_reward": -18.77, "episode_reward_trend_value": 0.00430539487387299, "biggest_recent_change": 0.061646524415543524},
{"total_number_of_episodes": 32228, "number_of_timesteps": 10309318, "per_episode_reward": -18.71, "episode_reward_trend_value": 0.004624296218962145, "biggest_recent_change": 0.06268268596048188},
{"total_number_of_episodes": 32238, "number_of_timesteps": 10314653, "per_episode_reward": -18.66, "episode_reward_trend_value": 0.004617775065681763, "biggest_recent_change": 0.06268268596048188},
{"total_number_of_episodes": 32248, "number_of_timesteps": 10320577, "per_episode_reward": -18.61, "episode_reward_trend_value": 0.004531648810922681, "biggest_recent_change": 0.06268268596048188},
{"total_number_of_episodes": 32258, "number_of_timesteps": 10324432, "per_episode_reward": -18.56, "episode_reward_trend_value": 0.004924115161354297, "biggest_recent_change": 0.06268268596048188},
{"total_number_of_episodes": 32268, "number_of_timesteps": 10327401, "per_episode_reward": -18.51, "episode_reward_trend_value": 0.0051018078916750574, "biggest_recent_change": 0.06268268596048188},
{"total_number_of_episodes": 32278, "number_of_timesteps": 10330946, "per_episode_reward": -18.47, "episode_reward_trend_value": 0.005003005055727686, "biggest_recent_change": 0.06268268596048188},
{"total_number_of_episodes": 32288, "number_of_timesteps": 10334657, "per_episode_reward": -18.43, "episode_reward_trend_value": 0.005058990237801689, "biggest_recent_change": 0.06268268596048188},
{"total_number_of_episodes": 32298, "number_of_timesteps": 10337663, "per_episode_reward": -18.4, "episode_reward_trend_value": 0.004712024969782686, "biggest_recent_change": 0.06268268596048188},
{"total_number_of_episodes": 32308, "number_of_timesteps": 10338839, "per_episode_reward": -18.37, "episode_reward_trend_value": 0.004431019407764344, "biggest_recent_change": 0.06268268596048188},
{"total_number_of_episodes": 32318, "number_of_timesteps": 10341935, "per_episode_reward": -18.33, "episode_reward_trend_value": 0.004206218331620764, "biggest_recent_change": 0.05159652257498948},
{"total_number_of_episodes": 32328, "number_of_timesteps": 10347778, "per_episode_reward": -18.27, "episode_reward_trend_value": 0.004364334799893123, "biggest_recent_change": 0.06148376201059591},
{"total_number_of_episodes": 32338, "number_of_timesteps": 10354200, "per_episode_reward": -18.24, "episode_reward_trend_value": 0.004077457501688878, "biggest_recent_change": 0.06148376201059591},
{"total_number_of_episodes": 32348, "number_of_timesteps": 10359194, "per_episode_reward": -18.15, "episode_reward_trend_value": 0.004496196956383772, "biggest_recent_change": 0.08928307349752984},
{"total_number_of_episodes": 32359, "number_of_timesteps": 10364229, "per_episode_reward": -18.13, "episode_reward_trend_value": 0.004215500806782341, "biggest_recent_change": 0.08928307349752984},
{"total_number_of_episodes": 32369, "number_of_timesteps": 10368372, "per_episode_reward": -18.11, "episode_reward_trend_value": 0.004071302566135415, "biggest_recent_change": 0.08928307349752984},
{"total_number_of_episodes": 32379, "number_of_timesteps": 10371326, "per_episode_reward": -18.02, "episode_reward_trend_value": 0.0045225417258795714, "biggest_recent_change": 0.08928307349752984},
{"total_number_of_episodes": 32389, "number_of_timesteps": 10376853, "per_episode_reward": -18.0, "episode_reward_trend_value": 0.004459870870211131, "biggest_recent_change": 0.08928307349752984},
{"total_number_of_episodes": 32399, "number_of_timesteps": 10382139, "per_episode_reward": -17.94, "episode_reward_trend_value": 0.004776575104282009, "biggest_recent_change": 0.08928307349752984},
{"total_number_of_episodes": 32409, "number_of_timesteps": 10388403, "per_episode_reward": -17.9, "episode_reward_trend_value": 0.0047638749727872045, "biggest_recent_change": 0.08928307349752984},
{"total_number_of_episodes": 32419, "number_of_timesteps": 10392717, "per_episode_reward": -17.83, "episode_reward_trend_value": 0.004887626351350605, "biggest_recent_change": 0.08928307349752984},
{"total_number_of_episodes": 32429, "number_of_timesteps": 10398492, "per_episode_reward": -17.79, "episode_reward_trend_value": 0.005086176367737849, "biggest_recent_change": 0.08928307349752984},
{"total_number_of_episodes": 32439, "number_of_timesteps": 10405458, "per_episode_reward": -17.75, "episode_reward_trend_value": 0.004478406602294763, "biggest_recent_change": 0.08286405748918924},
{"total_number_of_episodes": 32449, "number_of_timesteps": 10411179, "per_episode_reward": -17.71, "episode_reward_trend_value": 0.004677760342138468, "biggest_recent_change": 0.08286405748918924},
{"total_number_of_episodes": 32459, "number_of_timesteps": 10416918, "per_episode_reward": -17.67, "episode_reward_trend_value": 0.00478666596623047, "biggest_recent_change": 0.08286405748918924},
{"total_number_of_episodes": 32469, "number_of_timesteps": 10420844, "per_episode_reward": -17.66, "episode_reward_trend_value": 0.004064611330346995, "biggest_recent_change": 0.07262138608130186},
{"total_number_of_episodes": 32480, "number_of_timesteps": 10425230, "per_episode_reward": -17.63, "episode_reward_trend_value": 0.004109501443642768, "biggest_recent_change": 0.07262138608130186},
{"total_number_of_episodes": 32490, "number_of_timesteps": 10428374, "per_episode_reward": -17.61, "episode_reward_trend_value": 0.003639651861742937, "biggest_recent_change": 0.07262138608130186},
{"total_number_of_episodes": 32500, "number_of_timesteps": 10432651, "per_episode_reward": -17.59, "episode_reward_trend_value": 0.0034869326566749634, "biggest_recent_change": 0.07262138608130186},
{"total_number_of_episodes": 32510, "number_of_timesteps": 10437863, "per_episode_reward": -17.49, "episode_reward_trend_value": 0.0037592105728968365, "biggest_recent_change": 0.09712639854127048},
{"total_number_of_episodes": 32520, "number_of_timesteps": 10440969, "per_episode_reward": -17.47, "episode_reward_trend_value": 0.0034904645261163757, "biggest_recent_change": 0.09712639854127048},
{"total_number_of_episodes": 32530, "number_of_timesteps": 10445067, "per_episode_reward": -17.46, "episode_reward_trend_value": 0.0032682980507272837, "biggest_recent_change": 0.09712639854127048},
{"total_number_of_episodes": 32540, "number_of_timesteps": 10447691, "per_episode_reward": -17.45, "episode_reward_trend_value": 0.002851719947128828, "biggest_recent_change": 0.09712639854127048},
{"total_number_of_episodes": 32550, "number_of_timesteps": 10450289, "per_episode_reward": -17.37, "episode_reward_trend_value": 0.0033966438294198847, "biggest_recent_change": 0.09712639854127048},
{"total_number_of_episodes": 32560, "number_of_timesteps": 10455881, "per_episode_reward": -17.34, "episode_reward_trend_value": 0.0034879045500608814, "biggest_recent_change": 0.09712639854127048},
{"total_number_of_episodes": 32570, "number_of_timesteps": 10462533, "per_episode_reward": -17.28, "episode_reward_trend_value": 0.003917273543621076, "biggest_recent_change": 0.09712639854127048},
{"total_number_of_episodes": 32580, "number_of_timesteps": 10469453, "per_episode_reward": -17.25, "episode_reward_trend_value": 0.004057675711872517, "biggest_recent_change": 0.09712639854127048},
{"total_number_of_episodes": 32590, "number_of_timesteps": 10476125, "per_episode_reward": -17.21, "episode_reward_trend_value": 0.00414963455278882, "biggest_recent_change": 0.09712639854127048},
{"total_number_of_episodes": 32600, "number_of_timesteps": 10481913, "per_episode_reward": -17.2, "episode_reward_trend_value": 0.0032548155065257275, "biggest_recent_change": 0.08440398437487673},
{"total_number_of_episodes": 32610, "number_of_timesteps": 10486828, "per_episode_reward": -17.17, "episode_reward_trend_value": 0.003323938909253678, "biggest_recent_change": 0.08440398437487673},
{"total_number_of_episodes": 32620, "number_of_timesteps": 10492654, "per_episode_reward": -17.1, "episode_reward_trend_value": 0.004004083597658336, "biggest_recent_change": 0.08440398437487673},
{"total_number_of_episodes": 32630, "number_of_timesteps": 10498011, "per_episode_reward": -17.02, "episode_reward_trend_value": 0.00477494189651557, "biggest_recent_change": 0.08440398437487673},
{"total_number_of_episodes": 32640, "number_of_timesteps": 10504504, "per_episode_reward": -16.97, "episode_reward_trend_value": 0.004466250856643583, "biggest_recent_change": 0.07580183377905314},
{"total_number_of_episodes": 32650, "number_of_timesteps": 10509887, "per_episode_reward": -16.84, "episode_reward_trend_value": 0.005614784799891047, "biggest_recent_change": 0.12946066000963796},
{"total_number_of_episodes": 32660, "number_of_timesteps": 10514165, "per_episode_reward": -16.76, "episode_reward_trend_value": 0.0057605214160641, "biggest_recent_change": 0.12946066000963796},
{"total_number_of_episodes": 32671, "number_of_timesteps": 10520043, "per_episode_reward": -16.7, "episode_reward_trend_value": 0.006063318535636439, "biggest_recent_change": 0.12946066000963796},
{"total_number_of_episodes": 32681, "number_of_timesteps": 10523655, "per_episode_reward": -16.62, "episode_reward_trend_value": 0.006528491821863251, "biggest_recent_change": 0.12946066000963796},
{"total_number_of_episodes": 32691, "number_of_timesteps": 10528096, "per_episode_reward": -16.56, "episode_reward_trend_value": 0.007039513618181638, "biggest_recent_change": 0.12946066000963796},
{"total_number_of_episodes": 32701, "number_of_timesteps": 10533919, "per_episode_reward": -16.54, "episode_reward_trend_value": 0.006988154507887935, "biggest_recent_change": 0.12946066000963796},
{"total_number_of_episodes": 32711, "number_of_timesteps": 10541548, "per_episode_reward": -16.49, "episode_reward_trend_value": 0.006709272389352074, "biggest_recent_change": 0.12946066000963796},
{"total_number_of_episodes": 32721, "number_of_timesteps": 10544390, "per_episode_reward": -16.46, "episode_reward_trend_value": 0.006211645053887654, "biggest_recent_change": 0.12946066000963796},
{"total_number_of_episodes": 32731, "number_of_timesteps": 10550267, "per_episode_reward": -16.38, "episode_reward_trend_value": 0.006568720605278561, "biggest_recent_change": 0.12946066000963796},
{"total_number_of_episodes": 32741, "number_of_timesteps": 10555733, "per_episode_reward": -16.36, "episode_reward_trend_value": 0.005291259200237045, "biggest_recent_change": 0.08875859041157952},
{"total_number_of_episodes": 32751, "number_of_timesteps": 10559963, "per_episode_reward": -16.31, "episode_reward_trend_value": 0.004931408274094275, "biggest_recent_change": 0.08875859041157952},
{"total_number_of_episodes": 32761, "number_of_timesteps": 10566617, "per_episode_reward": -16.3, "episode_reward_trend_value": 0.004487260217336894, "biggest_recent_change": 0.08875859041157952},
{"total_number_of_episodes": 32771, "number_of_timesteps": 10572550, "per_episode_reward": -16.23, "episode_reward_trend_value": 0.004425920780786541, "biggest_recent_change": 0.08875859041157952},

{"total_number_of_episodes": 32781, "number_of_timesteps": 10576364, "per_episode_reward": -16.2, "episode_reward_trend_value": 0.004023551926577796, "biggest_recent_change": 0.08875859041157952},
{"total_number_of_episodes": 32791, "number_of_timesteps": 10581284, "per_episode_reward": -16.17, "episode_reward_trend_value": 0.004141995916488778, "biggest_recent_change": 0.08875859041157952},
{"total_number_of_episodes": 32801, "number_of_timesteps": 10585013, "per_episode_reward": -16.14, "episode_reward_trend_value": 0.003863674173134236, "biggest_recent_change": 0.08875859041157952},
{"total_number_of_episodes": 32812, "number_of_timesteps": 10590105, "per_episode_reward": -16.12, "episode_reward_trend_value": 0.003824806642518455, "biggest_recent_change": 0.08875859041157952},
{"total_number_of_episodes": 32822, "number_of_timesteps": 10592428, "per_episode_reward": -16.09, "episode_reward_trend_value": 0.003211282147728964, "biggest_recent_change": 0.0721841909702583},
{"total_number_of_episodes": 32832, "number_of_timesteps": 10599175, "per_episode_reward": -16.06, "episode_reward_trend_value": 0.0033716919813722747, "biggest_recent_change": 0.0721841909702583},
{"total_number_of_episodes": 32842, "number_of_timesteps": 10604721, "per_episode_reward": -16.03, "episode_reward_trend_value": 0.0031300850169118793, "biggest_recent_change": 0.0721841909702583},
{"total_number_of_episodes": 32852, "number_of_timesteps": 10610706, "per_episode_reward": -16.0, "episode_reward_trend_value": 0.003299512044599398, "biggest_recent_change": 0.0721841909702583},
{"total_number_of_episodes": 32862, "number_of_timesteps": 10614649, "per_episode_reward": -15.97, "episode_reward_trend_value": 0.0028621708550556828, "biggest_recent_change": 0.033541385880525354},
{"total_number_of_episodes": 32872, "number_of_timesteps": 10620451, "per_episode_reward": -15.94, "episode_reward_trend_value": 0.0029187708012950882, "biggest_recent_change": 0.033541385880525354},
{"total_number_of_episodes": 32883, "number_of_timesteps": 10624267, "per_episode_reward": -15.87, "episode_reward_trend_value": 0.0033305661743548223, "biggest_recent_change": 0.06627334874186275},
{"total_number_of_episodes": 32893, "number_of_timesteps": 10630624, "per_episode_reward": -15.85, "episode_reward_trend_value": 0.003276904855063714, "biggest_recent_change": 0.06627334874186275},
{"total_number_of_episodes": 32903, "number_of_timesteps": 10638027, "per_episode_reward": -15.74, "episode_reward_trend_value": 0.004255787795035123, "biggest_recent_change": 0.11254330673392587},
{"total_number_of_episodes": 32913, "number_of_timesteps": 10643984, "per_episode_reward": -15.7, "episode_reward_trend_value": 0.004346577197833687, "biggest_recent_change": 0.11254330673392587},
{"total_number_of_episodes": 32923, "number_of_timesteps": 10649379, "per_episode_reward": -15.66, "episode_reward_trend_value": 0.004392240165165538, "biggest_recent_change": 0.11254330673392587},
{"total_number_of_episodes": 32933, "number_of_timesteps": 10656109, "per_episode_reward": -15.64, "episode_reward_trend_value": 0.004304047278137801, "biggest_recent_change": 0.11254330673392587},
{"total_number_of_episodes": 32943, "number_of_timesteps": 10661014, "per_episode_reward": -15.6, "episode_reward_trend_value": 0.004444029354833784, "biggest_recent_change": 0.11254330673392587},
{"total_number_of_episodes": 32953, "number_of_timesteps": 10666109, "per_episode_reward": -15.57, "episode_reward_trend_value": 0.004408758624612277, "biggest_recent_change": 0.11254330673392587},
{"total_number_of_episodes": 32963, "number_of_timesteps": 10669690, "per_episode_reward": -15.54, "episode_reward_trend_value": 0.004444329107166961, "biggest_recent_change": 0.11254330673392587},
{"total_number_of_episodes": 32973, "number_of_timesteps": 10673566, "per_episode_reward": -15.47, "episode_reward_trend_value": 0.004452425334814691, "biggest_recent_change": 0.11254330673392587},

{"total_number_of_episodes": 32984, "number_of_timesteps": 10680320, "per_episode_reward": -15.45, "episode_reward_trend_value": 0.004443761575305514, "biggest_recent_change": 0.11254330673392587},
{"total_number_of_episodes": 32994, "number_of_timesteps": 10683480, "per_episode_reward": -15.38, "episode_reward_trend_value": 0.004017753635040656, "biggest_recent_change": 0.07420259211008862},
{"total_number_of_episodes": 33004, "number_of_timesteps": 10687592, "per_episode_reward": -15.36, "episode_reward_trend_value": 0.0037418618290277275, "biggest_recent_change": 0.07420259211008862},
{"total_number_of_episodes": 33014, "number_of_timesteps": 10690555, "per_episode_reward": -15.33, "episode_reward_trend_value": 0.0037151400476994486, "biggest_recent_change": 0.07420259211008862},
{"total_number_of_episodes": 33024, "number_of_timesteps": 10696002, "per_episode_reward": -15.28, "episode_reward_trend_value": 0.004037395383570461, "biggest_recent_change": 0.07420259211008862},
{"total_number_of_episodes": 33034, "number_of_timesteps": 10701873, "per_episode_reward": -15.24, "episode_reward_trend_value": 0.004017602847478684, "biggest_recent_change": 0.07420259211008862},
{"total_number_of_episodes": 33044, "number_of_timesteps": 10704022, "per_episode_reward": -15.21, "episode_reward_trend_value": 0.004038573550916623, "biggest_recent_change": 0.07420259211008862},
{"total_number_of_episodes": 33054, "number_of_timesteps": 10709684, "per_episode_reward": -15.17, "episode_reward_trend_value": 0.004047200134792028, "biggest_recent_change": 0.07420259211008862},
{"total_number_of_episodes": 33064, "number_of_timesteps": 10713753, "per_episode_reward": -15.13, "episode_reward_trend_value": 0.003779146319236995, "biggest_recent_change": 0.07420259211008862},
{"total_number_of_episodes": 33074, "number_of_timesteps": 10717643, "per_episode_reward": -15.12, "episode_reward_trend_value": 0.0036434037003835705, "biggest_recent_change": 0.07420259211008862},
{"total_number_of_episodes": 33084, "number_of_timesteps": 10720760, "per_episode_reward": -15.11, "episode_reward_trend_value": 0.0029466466536709037, "biggest_recent_change": 0.047513298597895215},
{"total_number_of_episodes": 33094, "number_of_timesteps": 10725455, "per_episode_reward": -15.1, "episode_reward_trend_value": 0.002848243030908924, "biggest_recent_change": 0.047513298597895215},
{"total_number_of_episodes": 33104, "number_of_timesteps": 10730465, "per_episode_reward": -15.09, "episode_reward_trend_value": 0.002649418913867072, "biggest_recent_change": 0.047513298597895215},
{"total_number_of_episodes": 33114, "number_of_timesteps": 10734141, "per_episode_reward": -15.05, "episode_reward_trend_value": 0.0025198716609349248, "biggest_recent_change": 0.0428771658302054},
{"total_number_of_episodes": 33124, "number_of_timesteps": 10735591, "per_episode_reward": -15.02, "episode_reward_trend_value": 0.0024569793600206996, "biggest_recent_change": 0.0428771658302054},
{"total_number_of_episodes": 33134, "number_of_timesteps": 10738323, "per_episode_reward": -15.0, "episode_reward_trend_value": 0.0022897041101284147, "biggest_recent_change": 0.0428771658302054},
{"total_number_of_episodes": 33145, "number_of_timesteps": 10744185, "per_episode_reward": -14.96, "episode_reward_trend_value": 0.0023398869437570484, "biggest_recent_change": 0.0428771658302054},
{"total_number_of_episodes": 33155, "number_of_timesteps": 10747559, "per_episode_reward": -14.94, "episode_reward_trend_value": 0.0021073852792762083, "biggest_recent_change": 0.03995963533429148},
{"total_number_of_episodes": 33165, "number_of_timesteps": 10754069, "per_episode_reward": -14.88, "episode_reward_trend_value": 0.0027061707985606316, "biggest_recent_change": 0.06171809015568108},
{"total_number_of_episodes": 33175, "number_of_timesteps": 10760310, "per_episode_reward": -14.81, "episode_reward_trend_value": 0.0033634164144672636, "biggest_recent_change": 0.07064656333754549},
{"total_number_of_episodes": 33186, "number_of_timesteps": 10764563, "per_episode_reward": -14.76, "episode_reward_trend_value": 0.0038434678573699677, "biggest_recent_change": 0.07064656333754549},
{"total_number_of_episodes": 33196, "number_of_timesteps": 10767922, "per_episode_reward": -14.69, "episode_reward_trend_value": 0.0044109115244184, "biggest_recent_change": 0.07064656333754549},
{"total_number_of_episodes": 33206, "number_of_timesteps": 10774549, "per_episode_reward": -14.65, "episode_reward_trend_value": 0.0045294755674354275, "biggest_recent_change": 0.07064656333754549},
{"total_number_of_episodes": 33216, "number_of_timesteps": 10780281, "per_episode_reward": -14.61, "episode_reward_trend_value": 0.0045565318711198325, "biggest_recent_change": 0.07064656333754549},
{"total_number_of_episodes": 33226, "number_of_timesteps": 10784556, "per_episode_reward": -14.59, "episode_reward_trend_value": 0.004591560138908473, "biggest_recent_change": 0.07064656333754549},
{"total_number_of_episodes": 33236, "number_of_timesteps": 10789665, "per_episode_reward": -14.57, "episode_reward_trend_value": 0.004365850118515091, "biggest_recent_change": 0.07064656333754549},
{"total_number_of_episodes": 33246, "number_of_timesteps": 10797232, "per_episode_reward": -14.55, "episode_reward_trend_value": 0.004354662477870244, "biggest_recent_change": 0.07064656333754549},
{"total_number_of_episodes": 33256, "number_of_timesteps": 10802925, "per_episode_reward": -14.54, "episode_reward_trend_value": 0.003815891682426889, "biggest_recent_change": 0.07064656333754549},
{"total_number_of_episodes": 33266, "number_of_timesteps": 10806640, "per_episode_reward": -14.47, "episode_reward_trend_value": 0.003733429620567582, "biggest_recent_change": 0.0638064848247133},
{"total_number_of_episodes": 33276, "number_of_timesteps": 10811407, "per_episode_reward": -14.43, "episode_reward_trend_value": 0.003611847712965835, "biggest_recent_change": 0.0638064848247133},
{"total_number_of_episodes": 33286, "number_of_timesteps": 10815281, "per_episode_reward": -14.35, "episode_reward_trend_value": 0.0038041905962693475, "biggest_recent_change": 0.08111734432202944},
{"total_number_of_episodes": 33296, "number_of_timesteps": 10819376, "per_episode_reward": -14.31, "episode_reward_trend_value": 0.003722489345445249, "biggest_recent_change": 0.08111734432202944},
{"total_number_of_episodes": 33306, "number_of_timesteps": 10823983, "per_episode_reward": -14.27, "episode_reward_trend_value": 0.003792183849240338, "biggest_recent_change": 0.08111734432202944},
{"total_number_of_episodes": 33316, "number_of_timesteps": 10828111, "per_episode_reward": -14.24, "episode_reward_trend_value": 0.003930462930848715, "biggest_recent_change": 0.08111734432202944},
{"total_number_of_episodes": 33326, "number_of_timesteps": 10830707, "per_episode_reward": -14.22, "episode_reward_trend_value": 0.003828416835362683, "biggest_recent_change": 0.08111734432202944},
{"total_number_of_episodes": 33336, "number_of_timesteps": 10833243, "per_episode_reward": -14.2, "episode_reward_trend_value": 0.003825595989859249, "biggest_recent_change": 0.08111734432202944},
{"total_number_of_episodes": 33346, "number_of_timesteps": 10838123, "per_episode_reward": -14.14, "episode_reward_trend_value": 0.004407417853882478, "biggest_recent_change": 0.08111734432202944},
{"total_number_of_episodes": 33357, "number_of_timesteps": 10843986, "per_episode_reward": -14.1, "episode_reward_trend_value": 0.004082740212101576, "biggest_recent_change": 0.08111734432202944},
{"total_number_of_episodes": 33367, "number_of_timesteps": 10846801, "per_episode_reward": -14.09, "episode_reward_trend_value": 0.0038082661966510126, "biggest_recent_change": 0.08111734432202944},
{"total_number_of_episodes": 33377, "number_of_timesteps": 10849974, "per_episode_reward": -14.03, "episode_reward_trend_value": 0.0035141857807247864, "biggest_recent_change": 0.06559268632786974},
{"total_number_of_episodes": 33387, "number_of_timesteps": 10854947, "per_episode_reward": -14.02, "episode_reward_trend_value": 0.003206800646689266, "biggest_recent_change": 0.06559268632786974},
{"total_number_of_episodes": 33397, "number_of_timesteps": 10859363, "per_episode_reward": -13.95, "episode_reward_trend_value": 0.00357094842967446, "biggest_recent_change": 0.07681389241191994},
{"total_number_of_episodes": 33407, "number_of_timesteps": 10864312, "per_episode_reward": -13.94, "episode_reward_trend_value": 0.003326042490577367, "biggest_recent_change": 0.07681389241191994},
{"total_number_of_episodes": 33417, "number_of_timesteps": 10868346, "per_episode_reward": -13.89, "episode_reward_trend_value": 0.0036944610108534054, "biggest_recent_change": 0.07681389241191994},
{"total_number_of_episodes": 33427, "number_of_timesteps": 10872781, "per_episode_reward": -13.86, "episode_reward_trend_value": 0.003795889762115756, "biggest_recent_change": 0.07681389241191994},
{"total_number_of_episodes": 33437, "number_of_timesteps": 10878274, "per_episode_reward": -13.84, "episode_reward_trend_value": 0.0033208459948481997, "biggest_recent_change": 0.07681389241191994},
{"total_number_of_episodes": 33447, "number_of_timesteps": 10882666, "per_episode_reward": -13.79, "episode_reward_trend_value": 0.003516188312248146, "biggest_recent_change": 0.07681389241191994},
{"total_number_of_episodes": 33457, "number_of_timesteps": 10887527, "per_episode_reward": -13.76, "episode_reward_trend_value": 0.0037054062003565808, "biggest_recent_change": 0.07681389241191994},
{"total_number_of_episodes": 33467, "number_of_timesteps": 10891817, "per_episode_reward": -13.75, "episode_reward_trend_value": 0.003180038866221402, "biggest_recent_change": 0.07681389241191994},
{"total_number_of_episodes": 33477, "number_of_timesteps": 10899260, "per_episode_reward": -13.73, "episode_reward_trend_value": 0.0032159506551539727, "biggest_recent_change": 0.07681389241191994},
{"total_number_of_episodes": 33487, "number_of_timesteps": 10906022, "per_episode_reward": -13.7, "episode_reward_trend_value": 0.0027061375305227073, "biggest_recent_change": 0.05158479857592191},
{"total_number_of_episodes": 33497, "number_of_timesteps": 10913311, "per_episode_reward": -13.68, "episode_reward_trend_value": 0.0028116465783028645, "biggest_recent_change": 0.05158479857592191},
{"total_number_of_episodes": 33507, "number_of_timesteps": 10918452, "per_episode_reward": -13.65, "episode_reward_trend_value": 0.0027258932155961287, "biggest_recent_change": 0.05158479857592191},
{"total_number_of_episodes": 33517, "number_of_timesteps": 10923530, "per_episode_reward": -13.62, "episode_reward_trend_value": 0.0027158164329360206, "biggest_recent_change": 0.05158479857592191},
{"total_number_of_episodes": 33527, "number_of_timesteps": 10931836, "per_episode_reward": -13.61, "episode_reward_trend_value": 0.002599146617970464, "biggest_recent_change": 0.05158479857592191},
{"total_number_of_episodes": 33537, "number_of_timesteps": 10937824, "per_episode_reward": -13.58, "episode_reward_trend_value": 0.002337354119697525, "biggest_recent_change": 0.035901449086381376},
{"total_number_of_episodes": 33548, "number_of_timesteps": 10942726, "per_episode_reward": -13.54, "episode_reward_trend_value": 0.002359666640844675, "biggest_recent_change": 0.035901449086381376},
{"total_number_of_episodes": 33558, "number_of_timesteps": 10947032, "per_episode_reward": -13.52, "episode_reward_trend_value": 0.0025704297769897897, "biggest_recent_change": 0.035901449086381376},
{"total_number_of_episodes": 33568, "number_of_timesteps": 10951366, "per_episode_reward": -13.48, "episode_reward_trend_value": 0.0028091919036985244, "biggest_recent_change": 0.03622768747588623},
{"total_number_of_episodes": 33578, "number_of_timesteps": 10957058, "per_episode_reward": -13.43, "episode_reward_trend_value": 0.0029847283811979724, "biggest_recent_change": 0.04672899417005638},
{"total_number_of_episodes": 33588, "number_of_timesteps": 10963957, "per_episode_reward": -13.38, "episode_reward_trend_value": 0.003332825403110462, "biggest_recent_change": 0.05086238220982864},
{"total_number_of_episodes": 33598, "number_of_timesteps": 10970843, "per_episode_reward": -13.35, "episode_reward_trend_value": 0.003275250034395564, "biggest_recent_change": 0.05086238220982864},
{"total_number_of_episodes": 33608, "number_of_timesteps": 10973266, "per_episode_reward": -13.31, "episode_reward_trend_value": 0.0034124146421886437, "biggest_recent_change": 0.05086238220982864},
{"total_number_of_episodes": 33618, "number_of_timesteps": 10977241, "per_episode_reward": -13.27, "episode_reward_trend_value": 0.0036955796921861782, "biggest_recent_change": 0.05086238220982864},
{"total_number_of_episodes": 33628, "number_of_timesteps": 10982357, "per_episode_reward": -13.23, "episode_reward_trend_value": 0.003866737349273228, "biggest_recent_change": 0.05086238220982864},
{"total_number_of_episodes": 33639, "number_of_timesteps": 10989901, "per_episode_reward": -13.19, "episode_reward_trend_value": 0.0038786674906174192, "biggest_recent_change": 0.05086238220982864},
{"total_number_of_episodes": 33649, "number_of_timesteps": 10995235, "per_episode_reward": -13.16, "episode_reward_trend_value": 0.003964870326840043, "biggest_recent_change": 0.05086238220982864},
{"total_number_of_episodes": 33659, "number_of_timesteps": 11001338, "per_episode_reward": -13.12, "episode_reward_trend_value": 0.003955462991918384, "biggest_recent_change": 0.05086238220982864},
{"total_number_of_episodes": 33669, "number_of_timesteps": 11008893, "per_episode_reward": -13.11, "episode_reward_trend_value": 0.0035908587813169553, "biggest_recent_change": 0.05086238220982864},
{"total_number_of_episodes": 33679, "number_of_timesteps": 11015895, "per_episode_reward": -13.08, "episode_reward_trend_value": 0.0033767526550858226, "biggest_recent_change": 0.04342766286919186},
{"total_number_of_episodes": 33689, "number_of_timesteps": 11020842, "per_episode_reward": -12.99, "episode_reward_trend_value": 0.003996894488223764, "biggest_recent_change": 0.08653243088445528},
{"total_number_of_episodes": 33699, "number_of_timesteps": 11026678, "per_episode_reward": -12.95, "episode_reward_trend_value": 0.004016050536340762, "biggest_recent_change": 0.08653243088445528},
{"total_number_of_episodes": 33709, "number_of_timesteps": 11033236, "per_episode_reward": -12.92, "episode_reward_trend_value": 0.003919432803916697, "biggest_recent_change": 0.08653243088445528},
{"total_number_of_episodes": 33719, "number_of_timesteps": 11036573, "per_episode_reward": -12.9, "episode_reward_trend_value": 0.00371473608799096, "biggest_recent_change": 0.08653243088445528},
{"total_number_of_episodes": 33729, "number_of_timesteps": 11042345, "per_episode_reward": -12.85, "episode_reward_trend_value": 0.0038702450590647947, "biggest_recent_change": 0.08653243088445528},
{"total_number_of_episodes": 33739, "number_of_timesteps": 11047144, "per_episode_reward": -12.79, "episode_reward_trend_value": 0.00409280549462125, "biggest_recent_change": 0.08653243088445528},
{"total_number_of_episodes": 33749, "number_of_timesteps": 11053445, "per_episode_reward": -12.77, "episode_reward_trend_value": 0.003987629789824057, "biggest_recent_change": 0.08653243088445528},
{"total_number_of_episodes": 33759, "number_of_timesteps": 11056044, "per_episode_reward": -12.74, "episode_reward_trend_value": 0.004070117743388795, "biggest_recent_change": 0.08653243088445528},
{"total_number_of_episodes": 33769, "number_of_timesteps": 11061032, "per_episode_reward": -12.69, "episode_reward_trend_value": 0.004299371197169775, "biggest_recent_change": 0.08653243088445528},
{"total_number_of_episodes": 33779, "number_of_timesteps": 11066139, "per_episode_reward": -12.66, "episode_reward_trend_value": 0.0037206636189947733, "biggest_recent_change": 0.0541244235296805},
{"total_number_of_episodes": 33790, "number_of_timesteps": 11071174, "per_episode_reward": -12.63, "episode_reward_trend_value": 0.003536338106403372, "biggest_recent_change": 0.0541244235296805},
{"total_number_of_episodes": 33800, "number_of_timesteps": 11074396, "per_episode_reward": -12.6, "episode_reward_trend_value": 0.0035681350944525097, "biggest_recent_change": 0.0541244235296805},
{"total_number_of_episodes": 33810, "number_of_timesteps": 11076934, "per_episode_reward": -12.51, "episode_reward_trend_value": 0.004254430499856138, "biggest_recent_change": 0.08677154492220218},
{"total_number_of_episodes": 33820, "number_of_timesteps": 11080777, "per_episode_reward": -12.5, "episode_reward_trend_value": 0.0038534479609169657, "biggest_recent_change": 0.08677154492220218},
{"total_number_of_episodes": 33830, "number_of_timesteps": 11087718, "per_episode_reward": -12.47, "episode_reward_trend_value": 0.003577086853477477, "biggest_recent_change": 0.08677154492220218},
{"total_number_of_episodes": 33840, "number_of_timesteps": 11092876, "per_episode_reward": -12.43, "episode_reward_trend_value": 0.003745762851815984, "biggest_recent_change": 0.08677154492220218},
{"total_number_of_episodes": 33850, "number_of_timesteps": 11097280, "per_episode_reward": -12.37, "episode_reward_trend_value": 0.004185188135356495, "biggest_recent_change": 0.08677154492220218},
{"total_number_of_episodes": 33860, "number_of_timesteps": 11103353, "per_episode_reward": -12.31, "episode_reward_trend_value": 0.004218566014805663, "biggest_recent_change": 0.08677154492220218},
{"total_number_of_episodes": 33870, "number_of_timesteps": 11109411, "per_episode_reward": -12.27, "episode_reward_trend_value": 0.004309551103635378, "biggest_recent_change": 0.08677154492220218},
{"total_number_of_episodes": 33880, "number_of_timesteps": 11115371, "per_episode_reward": -12.22, "episode_reward_trend_value": 0.004563811493721598, "biggest_recent_change": 0.08677154492220218},
{"total_number_of_episodes": 33890, "number_of_timesteps": 11123232, "per_episode_reward": -12.2, "episode_reward_trend_value": 0.004472233761088873, "biggest_recent_change": 0.08677154492220218},
{"total_number_of_episodes": 33900, "number_of_timesteps": 11128495, "per_episode_reward": -12.17, "episode_reward_trend_value": 0.0037861644904601693, "biggest_recent_change": 0.06088680655540024},
{"total_number_of_episodes": 33910, "number_of_timesteps": 11133363, "per_episode_reward": -12.12, "episode_reward_trend_value": 0.004201086159190995, "biggest_recent_change": 0.06088680655540024},
{"total_number_of_episodes": 33920, "number_of_timesteps": 11139322, "per_episode_reward": -12.07, "episode_reward_trend_value": 0.004404823515158579, "biggest_recent_change": 0.06088680655540024},
{"total_number_of_episodes": 33930, "number_of_timesteps": 11143423, "per_episode_reward": -12.06, "episode_reward_trend_value": 0.004129287334384379, "biggest_recent_change": 0.06088680655540024},
{"total_number_of_episodes": 33940, "number_of_timesteps": 11146912, "per_episode_reward": -12.01, "episode_reward_trend_value": 0.003947314470586388, "biggest_recent_change": 0.055229650839740074},
{"total_number_of_episodes": 33950, "number_of_timesteps": 11152426, "per_episode_reward": -11.95, "episode_reward_trend_value": 0.003974228965303439, "biggest_recent_change": 0.0576519553642747},
{"total_number_of_episodes": 33960, "number_of_timesteps": 11155719, "per_episode_reward": -11.92, "episode_reward_trend_value": 0.0038570838035998116, "biggest_recent_change": 0.0576519553642747},
{"total_number_of_episodes": 33970, "number_of_timesteps": 11161412, "per_episode_reward": -11.87, "episode_reward_trend_value": 0.003858071549384176, "biggest_recent_change": 0.0576519553642747},
{"total_number_of_episodes": 33980, "number_of_timesteps": 11164400, "per_episode_reward": -11.83, "episode_reward_trend_value": 0.004051670188970075, "biggest_recent_change": 0.0576519553642747},
{"total_number_of_episodes": 33990, "number_of_timesteps": 11168954, "per_episode_reward": -11.78, "episode_reward_trend_value": 0.004310239918087275, "biggest_recent_change": 0.0576519553642747},
{"total_number_of_episodes": 34000, "number_of_timesteps": 11175160, "per_episode_reward": -11.67, "episode_reward_trend_value": 0.005053050969498211, "biggest_recent_change": 0.1178002135880476},
{"total_number_of_episodes": 34011, "number_of_timesteps": 11181077, "per_episode_reward": -11.62, "episode_reward_trend_value": 0.005060503733340245, "biggest_recent_change": 0.1178002135880476},
{"total_number_of_episodes": 34021, "number_of_timesteps": 11184066, "per_episode_reward": -11.59, "episode_reward_trend_value": 0.005203424451454038, "biggest_recent_change": 0.1178002135880476},
{"total_number_of_episodes": 34031, "number_of_timesteps": 11188663, "per_episode_reward": -11.54, "episode_reward_trend_value": 0.00526773912032973, "biggest_recent_change": 0.1178002135880476},
{"total_number_of_episodes": 34041, "number_of_timesteps": 11193675, "per_episode_reward": -11.51, "episode_reward_trend_value": 0.00497932933721561, "biggest_recent_change": 0.1178002135880476},
{"total_number_of_episodes": 34051, "number_of_timesteps": 11200579, "per_episode_reward": -11.45, "episode_reward_trend_value": 0.005276753133572261, "biggest_recent_change": 0.1178002135880476},
{"total_number_of_episodes": 34061, "number_of_timesteps": 11206478, "per_episode_reward": -11.42, "episode_reward_trend_value": 0.005079241041473459, "biggest_recent_change": 0.1178002135880476},
{"total_number_of_episodes": 34071, "number_of_timesteps": 11209549, "per_episode_reward": -11.32, "episode_reward_trend_value": 0.005700370646804447, "biggest_recent_change": 0.1178002135880476},
{"total_number_of_episodes": 34081, "number_of_timesteps": 11213562, "per_episode_reward": -11.27, "episode_reward_trend_value": 0.00575590122695867, "biggest_recent_change": 0.1178002135880476},

{"total_number_of_episodes": 34091, "number_of_timesteps": 11218593, "per_episode_reward": -11.24, "episode_reward_trend_value": 0.0047544672435438345, "biggest_recent_change": 0.09707299753849874},
{"total_number_of_episodes": 34101, "number_of_timesteps": 11222626, "per_episode_reward": -11.23, "episode_reward_trend_value": 0.004282106226038114, "biggest_recent_change": 0.09707299753849874},
{"total_number_of_episodes": 34111, "number_of_timesteps": 11226951, "per_episode_reward": -11.15, "episode_reward_trend_value": 0.004926034960597154, "biggest_recent_change": 0.09707299753849874},
{"total_number_of_episodes": 34121, "number_of_timesteps": 11230210, "per_episode_reward": -11.1, "episode_reward_trend_value": 0.0048956306470649205, "biggest_recent_change": 0.09707299753849874},
{"total_number_of_episodes": 34131, "number_of_timesteps": 11233229, "per_episode_reward": -11.0, "episode_reward_trend_value": 0.005610925416369699, "biggest_recent_change": 0.09707299753849874},
{"total_number_of_episodes": 34141, "number_of_timesteps": 11239620, "per_episode_reward": -10.9, "episode_reward_trend_value": 0.006120608340435613, "biggest_recent_change": 0.10473394712808393},
{"total_number_of_episodes": 34151, "number_of_timesteps": 11242118, "per_episode_reward": -10.79, "episode_reward_trend_value": 0.00696763606527821, "biggest_recent_change": 0.10782123152176126},
{"total_number_of_episodes": 34161, "number_of_timesteps": 11245752, "per_episode_reward": -10.78, "episode_reward_trend_value": 0.006006547464111596, "biggest_recent_change": 0.10782123152176126},
{"total_number_of_episodes": 34171, "number_of_timesteps": 11250594, "per_episode_reward": -10.71, "episode_reward_trend_value": 0.006164458068798635, "biggest_recent_change": 0.10782123152176126},

{"total_number_of_episodes": 34182, "number_of_timesteps": 11253035, "per_episode_reward": -10.67, "episode_reward_trend_value": 0.006337240928086037, "biggest_recent_change": 0.10782123152176126},
{"total_number_of_episodes": 34192, "number_of_timesteps": 11255991, "per_episode_reward": -10.71, "episode_reward_trend_value": 0.005771935566694629, "biggest_recent_change": 0.10782123152176126},
{"total_number_of_episodes": 34202, "number_of_timesteps": 11258441, "per_episode_reward": -10.69, "episode_reward_trend_value": 0.00504922928817252, "biggest_recent_change": 0.10782123152176126},
{"total_number_of_episodes": 34212, "number_of_timesteps": 11261446, "per_episode_reward": -10.68, "episode_reward_trend_value": 0.004670802331480514, "biggest_recent_change": 0.10782123152176126},
{"total_number_of_episodes": 34223, "number_of_timesteps": 11265614, "per_episode_reward": -10.63, "episode_reward_trend_value": 0.00415209174969537, "biggest_recent_change": 0.10782123152176126},
{"total_number_of_episodes": 34233, "number_of_timesteps": 11267453, "per_episode_reward": -10.56, "episode_reward_trend_value": 0.003772407054140478, "biggest_recent_change": 0.10782123152176126},
{"total_number_of_episodes": 34244, "number_of_timesteps": 11270070, "per_episode_reward": -10.51, "episode_reward_trend_value": 0.0031046808190018124, "biggest_recent_change": 0.0705623245281437},
{"total_number_of_episodes": 34254, "number_of_timesteps": 11275205, "per_episode_reward": -10.5, "episode_reward_trend_value": 0.0030720355875593222, "biggest_recent_change": 0.0705623245281437},
{"total_number_of_episodes": 34264, "number_of_timesteps": 11279982, "per_episode_reward": -10.48, "episode_reward_trend_value": 0.002557691467363416, "biggest_recent_change": 0.0705623245281437},
{"total_number_of_episodes": 34274, "number_of_timesteps": 11283677, "per_episode_reward": -10.43, "episode_reward_trend_value": 0.002609563069634291, "biggest_recent_change": 0.0705623245281437},
{"total_number_of_episodes": 34284, "number_of_timesteps": 11287163, "per_episode_reward": -10.38, "episode_reward_trend_value": 0.003725965640351841, "biggest_recent_change": 0.0705623245281437},
{"total_number_of_episodes": 34294, "number_of_timesteps": 11292960, "per_episode_reward": -10.35, "episode_reward_trend_value": 0.0037419779155148367, "biggest_recent_change": 0.0705623245281437},
{"total_number_of_episodes": 34304, "number_of_timesteps": 11298942, "per_episode_reward": -10.31, "episode_reward_trend_value": 0.004059873155691306, "biggest_recent_change": 0.0705623245281437},
{"total_number_of_episodes": 34314, "number_of_timesteps": 11304157, "per_episode_reward": -10.28, "episode_reward_trend_value": 0.003892885723701846, "biggest_recent_change": 0.0705623245281437},
{"total_number_of_episodes": 34324, "number_of_timesteps": 11308412, "per_episode_reward": -10.25, "episode_reward_trend_value": 0.00340356385431103, "biggest_recent_change": 0.05534529190683024},
{"total_number_of_episodes": 34334, "number_of_timesteps": 11314048, "per_episode_reward": -10.23, "episode_reward_trend_value": 0.0031474363969829803, "biggest_recent_change": 0.05534529190683024},
{"total_number_of_episodes": 34344, "number_of_timesteps": 11320834, "per_episode_reward": -10.16, "episode_reward_trend_value": 0.0038085051760993116, "biggest_recent_change": 0.06713314272414905},
{"total_number_of_episodes": 34354, "number_of_timesteps": 11327569, "per_episode_reward": -10.14, "episode_reward_trend_value": 0.003824262872853584, "biggest_recent_change": 0.06713314272414905},
{"total_number_of_episodes": 34364, "number_of_timesteps": 11333476, "per_episode_reward": -10.1, "episode_reward_trend_value": 0.003724844886247977, "biggest_recent_change": 0.06713314272414905},
{"total_number_of_episodes": 34374, "number_of_timesteps": 11335749, "per_episode_reward": -10.07, "episode_reward_trend_value": 0.0034418930121560528, "biggest_recent_change": 0.06713314272414905},
{"total_number_of_episodes": 34384, "number_of_timesteps": 11338728, "per_episode_reward": -10.04, "episode_reward_trend_value": 0.003466853092196488, "biggest_recent_change": 0.06713314272414905},
{"total_number_of_episodes": 34394, "number_of_timesteps": 11342343, "per_episode_reward": -10.03, "episode_reward_trend_value": 0.003113328187660712, "biggest_recent_change": 0.06713314272414905},
{"total_number_of_episodes": 34404, "number_of_timesteps": 11348297, "per_episode_reward": -10.02, "episode_reward_trend_value": 0.0028646127368941246, "biggest_recent_change": 0.06713314272414905},
{"total_number_of_episodes": 34414, "number_of_timesteps": 11354965, "per_episode_reward": -9.99, "episode_reward_trend_value": 0.0028659191174021715, "biggest_recent_change": 0.06713314272414905},
{"total_number_of_episodes": 34424, "number_of_timesteps": 11359273, "per_episode_reward": -9.98, "episode_reward_trend_value": 0.0026977041268410004, "biggest_recent_change": 0.06713314272414905},
{"total_number_of_episodes": 34435, "number_of_timesteps": 11364859, "per_episode_reward": -9.91, "episode_reward_trend_value": 0.002738476715741653, "biggest_recent_change": 0.07080267572520782},
{"total_number_of_episodes": 34445, "number_of_timesteps": 11371835, "per_episode_reward": -9.87, "episode_reward_trend_value": 0.0029260711415707323, "biggest_recent_change": 0.07080267572520782},
{"total_number_of_episodes": 34455, "number_of_timesteps": 11376770, "per_episode_reward": -9.8, "episode_reward_trend_value": 0.0032737993560268248, "biggest_recent_change": 0.07080267572520782},
{"total_number_of_episodes": 34465, "number_of_timesteps": 11379067, "per_episode_reward": -9.76, "episode_reward_trend_value": 0.0034166864538925207, "biggest_recent_change": 0.07080267572520782},
{"total_number_of_episodes": 34475, "number_of_timesteps": 11382162, "per_episode_reward": -9.73, "episode_reward_trend_value": 0.003432063482305203, "biggest_recent_change": 0.07080267572520782},
{"total_number_of_episodes": 34485, "number_of_timesteps": 11386702, "per_episode_reward": -9.69, "episode_reward_trend_value": 0.0037804623197640747, "biggest_recent_change": 0.07080267572520782},
{"total_number_of_episodes": 34495, "number_of_timesteps": 11390559, "per_episode_reward": -9.63, "episode_reward_trend_value": 0.004310560102767565, "biggest_recent_change": 0.07080267572520782},
{"total_number_of_episodes": 34505, "number_of_timesteps": 11393902, "per_episode_reward": -9.59, "episode_reward_trend_value": 0.004421896733922459, "biggest_recent_change": 0.07080267572520782},
{"total_number_of_episodes": 34515, "number_of_timesteps": 11399207, "per_episode_reward": -9.54, "episode_reward_trend_value": 0.004916648149954522, "biggest_recent_change": 0.07080267572520782},
{"total_number_of_episodes": 34525, "number_of_timesteps": 11404895, "per_episode_reward": -9.52, "episode_reward_trend_value": 0.004407445953310586, "biggest_recent_change": 0.07023797712750124},
{"total_number_of_episodes": 34535, "number_of_timesteps": 11410852, "per_episode_reward": -9.46, "episode_reward_trend_value": 0.004577781696680263, "biggest_recent_change": 0.07023797712750124},
{"total_number_of_episodes": 34545, "number_of_timesteps": 11415925, "per_episode_reward": -9.44, "episode_reward_trend_value": 0.004060030411721113, "biggest_recent_change": 0.059683192783040795},
{"total_number_of_episodes": 34555, "number_of_timesteps": 11421472, "per_episode_reward": -9.41, "episode_reward_trend_value": 0.0038845096089642956, "biggest_recent_change": 0.059683192783040795},
{"total_number_of_episodes": 34565, "number_of_timesteps": 11427257, "per_episode_reward": -9.38, "episode_reward_trend_value": 0.00391500623515003, "biggest_recent_change": 0.059683192783040795},
{"total_number_of_episodes": 34576, "number_of_timesteps": 11435458, "per_episode_reward": -9.35, "episode_reward_trend_value": 0.003818485859042416, "biggest_recent_change": 0.059683192783040795},
{"total_number_of_episodes": 34586, "number_of_timesteps": 11441625, "per_episode_reward": -9.33, "episode_reward_trend_value": 0.003364610318367925, "biggest_recent_change": 0.054847229940021336},
{"total_number_of_episodes": 34596, "number_of_timesteps": 11447500, "per_episode_reward": -9.3, "episode_reward_trend_value": 0.003314161865643466, "biggest_recent_change": 0.054847229940021336},
{"total_number_of_episodes": 34606, "number_of_timesteps": 11450945, "per_episode_reward": -9.24, "episode_reward_trend_value": 0.0033136366160520106, "biggest_recent_change": 0.054847229940021336},
{"total_number_of_episodes": 34616, "number_of_timesteps": 11455674, "per_episode_reward": -9.21, "episode_reward_trend_value": 0.00343650468306783, "biggest_recent_change": 0.054847229940021336},
{"total_number_of_episodes": 34626, "number_of_timesteps": 11458924, "per_episode_reward": -9.18, "episode_reward_trend_value": 0.0031638421921113906, "biggest_recent_change": 0.054015405028906116},
{"total_number_of_episodes": 34636, "number_of_timesteps": 11465902, "per_episode_reward": -9.14, "episode_reward_trend_value": 0.0033028935070704953, "biggest_recent_change": 0.054015405028906116},
{"total_number_of_episodes": 34646, "number_of_timesteps": 11470659, "per_episode_reward": -9.08, "episode_reward_trend_value": 0.003637675462986856, "biggest_recent_change": 0.05707296583082844},
{"total_number_of_episodes": 34656, "number_of_timesteps": 11477538, "per_episode_reward": -9.04, "episode_reward_trend_value": 0.0037812242290250512, "biggest_recent_change": 0.05707296583082844},
{"total_number_of_episodes": 34666, "number_of_timesteps": 11481066, "per_episode_reward": -9.02, "episode_reward_trend_value": 0.0036198755367844943, "biggest_recent_change": 0.05707296583082844},
{"total_number_of_episodes": 34676, "number_of_timesteps": 11485064, "per_episode_reward": -8.99, "episode_reward_trend_value": 0.003718068744063095, "biggest_recent_change": 0.05707296583082844},
{"total_number_of_episodes": 34686, "number_of_timesteps": 11487885, "per_episode_reward": -8.99, "episode_reward_trend_value": 0.003419726524414103, "biggest_recent_change": 0.05707296583082844},

{"total_number_of_episodes": 34696, "number_of_timesteps": 11489556, "per_episode_reward": -8.98, "episode_reward_trend_value": 0.0029550994715529513, "biggest_recent_change": 0.05707296583082844},
{"total_number_of_episodes": 34706, "number_of_timesteps": 11496705, "per_episode_reward": -8.92, "episode_reward_trend_value": 0.0031450613793598003, "biggest_recent_change": 0.05707296583082844},
{"total_number_of_episodes": 34716, "number_of_timesteps": 11502516, "per_episode_reward": -8.91, "episode_reward_trend_value": 0.003008806766465059, "biggest_recent_change": 0.05707296583082844},
{"total_number_of_episodes": 34726, "number_of_timesteps": 11507624, "per_episode_reward": -8.89, "episode_reward_trend_value": 0.002786725156511673, "biggest_recent_change": 0.05707296583082844},
{"total_number_of_episodes": 34736, "number_of_timesteps": 11513882, "per_episode_reward": -8.83, "episode_reward_trend_value": 0.0028416987241758366, "biggest_recent_change": 0.06202058692060319},
{"total_number_of_episodes": 34746, "number_of_timesteps": 11521528, "per_episode_reward": -8.79, "episode_reward_trend_value": 0.0027839556917773497, "biggest_recent_change": 0.06202058692060319},
{"total_number_of_episodes": 34756, "number_of_timesteps": 11526458, "per_episode_reward": -8.76, "episode_reward_trend_value": 0.002883608961945959, "biggest_recent_change": 0.06202058692060319},
{"total_number_of_episodes": 34766, "number_of_timesteps": 11530613, "per_episode_reward": -8.73, "episode_reward_trend_value": 0.0028832775078973566, "biggest_recent_change": 0.06202058692060319},
{"total_number_of_episodes": 34776, "number_of_timesteps": 11534861, "per_episode_reward": -8.72, "episode_reward_trend_value": 0.002960533020922165, "biggest_recent_change": 0.06202058692060319},
{"total_number_of_episodes": 34787, "number_of_timesteps": 11540416, "per_episode_reward": -8.7, "episode_reward_trend_value": 0.003023669915956775, "biggest_recent_change": 0.06202058692060319},
{"total_number_of_episodes": 34797, "number_of_timesteps": 11543622, "per_episode_reward": -8.68, "episode_reward_trend_value": 0.002730882258704624, "biggest_recent_change": 0.06202058692060319},
{"total_number_of_episodes": 34808, "number_of_timesteps": 11547317, "per_episode_reward": -8.63, "episode_reward_trend_value": 0.003045815799827365, "biggest_recent_change": 0.06202058692060319},
{"total_number_of_episodes": 34819, "number_of_timesteps": 11552050, "per_episode_reward": -8.59, "episode_reward_trend_value": 0.00334388189297646, "biggest_recent_change": 0.06202058692060319},
{"total_number_of_episodes": 34829, "number_of_timesteps": 11556686, "per_episode_reward": -8.57, "episode_reward_trend_value": 0.0028266626829044524, "biggest_recent_change": 0.046388709294461705},
{"total_number_of_episodes": 34839, "number_of_timesteps": 11561795, "per_episode_reward": -8.52, "episode_reward_trend_value": 0.003017954032131224, "biggest_recent_change": 0.054825561495691844},
{"total_number_of_episodes": 34849, "number_of_timesteps": 11565687, "per_episode_reward": -8.46, "episode_reward_trend_value": 0.0033485888168285445, "biggest_recent_change": 0.05716968905777087},
{"total_number_of_episodes": 34859, "number_of_timesteps": 11571709, "per_episode_reward": -8.42, "episode_reward_trend_value": 0.0034734064182022134, "biggest_recent_change": 0.05716968905777087},
{"total_number_of_episodes": 34869, "number_of_timesteps": 11578621, "per_episode_reward": -8.4, "episode_reward_trend_value": 0.0035478506884880586, "biggest_recent_change": 0.05716968905777087},
{"total_number_of_episodes": 34879, "number_of_timesteps": 11586365, "per_episode_reward": -8.39, "episode_reward_trend_value": 0.0034973449074090918, "biggest_recent_change": 0.05716968905777087},
{"total_number_of_episodes": 34889, "number_of_timesteps": 11591994, "per_episode_reward": -8.36, "episode_reward_trend_value": 0.00352270229743969, "biggest_recent_change": 0.05716968905777087},
{"total_number_of_episodes": 34899, "number_of_timesteps": 11595939, "per_episode_reward": -8.33, "episode_reward_trend_value": 0.003311146879573338, "biggest_recent_change": 0.05716968905777087},
{"total_number_of_episodes": 34909, "number_of_timesteps": 11601122, "per_episode_reward": -8.32, "episode_reward_trend_value": 0.0029639766071875287, "biggest_recent_change": 0.05716968905777087},
{"total_number_of_episodes": 34919, "number_of_timesteps": 11609571, "per_episode_reward": -8.29, "episode_reward_trend_value": 0.0030987159314788374, "biggest_recent_change": 0.05716968905777087},
{"total_number_of_episodes": 34929, "number_of_timesteps": 11616218, "per_episode_reward": -8.27, "episode_reward_trend_value": 0.0027330432864871037, "biggest_recent_change": 0.05716968905777087},
{"total_number_of_episodes": 34939, "number_of_timesteps": 11622827, "per_episode_reward": -8.24, "episode_reward_trend_value": 0.0024301620249981997, "biggest_recent_change": 0.0388755360366666},
{"total_number_of_episodes": 34949, "number_of_timesteps": 11626880, "per_episode_reward": -8.22, "episode_reward_trend_value": 0.002284344610101839, "biggest_recent_change": 0.029910375523769517},
{"total_number_of_episodes": 34959, "number_of_timesteps": 11632683, "per_episode_reward": -8.19, "episode_reward_trend_value": 0.0024149504386057983, "biggest_recent_change": 0.03067757188233955},
{"total_number_of_episodes": 34969, "number_of_timesteps": 11640595, "per_episode_reward": -8.14, "episode_reward_trend_value": 0.002813543305793055, "biggest_recent_change": 0.049209128574263516},
{"total_number_of_episodes": 34979, "number_of_timesteps": 11645664, "per_episode_reward": -8.11, "episode_reward_trend_value": 0.002731540631228096, "biggest_recent_change": 0.049209128574263516},
{"total_number_of_episodes": 34990, "number_of_timesteps": 11654610, "per_episode_reward": -8.06, "episode_reward_trend_value": 0.0029960058643176326, "biggest_recent_change": 0.051150592664548356},
{"total_number_of_episodes": 35000, "number_of_timesteps": 11659448, "per_episode_reward": -8.04, "episode_reward_trend_value": 0.0031251589840558458, "biggest_recent_change": 0.051150592664548356},
{"total_number_of_episodes": 35010, "number_of_timesteps": 11665781, "per_episode_reward": -8.02, "episode_reward_trend_value": 0.003070736798317597, "biggest_recent_change": 0.051150592664548356},
{"total_number_of_episodes": 35020, "number_of_timesteps": 11672638, "per_episode_reward": -8.0, "episode_reward_trend_value": 0.00304072994581074, "biggest_recent_change": 0.051150592664548356},
{"total_number_of_episodes": 35030, "number_of_timesteps": 11679017, "per_episode_reward": -7.96, "episode_reward_trend_value": 0.0030964408104000958, "biggest_recent_change": 0.051150592664548356},
{"total_number_of_episodes": 35040, "number_of_timesteps": 11684373, "per_episode_reward": -7.91, "episode_reward_trend_value": 0.0033520678641759992, "biggest_recent_change": 0.051150592664548356},
{"total_number_of_episodes": 35050, "number_of_timesteps": 11690460, "per_episode_reward": -7.9, "episode_reward_trend_value": 0.0031450516160175662, "biggest_recent_change": 0.051150592664548356},
{"total_number_of_episodes": 35060, "number_of_timesteps": 11697455, "per_episode_reward": -7.88, "episode_reward_trend_value": 0.002799829624783692, "biggest_recent_change": 0.051150592664548356},
{"total_number_of_episodes": 35070, "number_of_timesteps": 11704975, "per_episode_reward": -7.85, "episode_reward_trend_value": 0.00296567189243127, "biggest_recent_change": 0.051150592664548356},
{"total_number_of_episodes": 35080, "number_of_timesteps": 11710360, "per_episode_reward": -7.81, "episode_reward_trend_value": 0.0027785482334684018, "biggest_recent_change": 0.0487584035358255},
{"total_number_of_episodes": 35090, "number_of_timesteps": 11714912, "per_episode_reward": -7.79, "episode_reward_trend_value": 0.0028099630631098745, "biggest_recent_change": 0.0487584035358255},
{"total_number_of_episodes": 35100, "number_of_timesteps": 11719386, "per_episode_reward": -7.76, "episode_reward_trend_value": 0.002874056355211696, "biggest_recent_change": 0.0487584035358255},
{"total_number_of_episodes": 35110, "number_of_timesteps": 11726011, "per_episode_reward": -7.73, "episode_reward_trend_value": 0.002955024145198188, "biggest_recent_change": 0.0487584035358255},
{"total_number_of_episodes": 35120, "number_of_timesteps": 11730728, "per_episode_reward": -7.67, "episode_reward_trend_value": 0.003316123365467089, "biggest_recent_change": 0.06742328316101265},
{"total_number_of_episodes": 35130, "number_of_timesteps": 11735391, "per_episode_reward": -7.65, "episode_reward_trend_value": 0.0029345688243074064, "biggest_recent_change": 0.06742328316101265},
{"total_number_of_episodes": 35140, "number_of_timesteps": 11741058, "per_episode_reward": -7.61, "episode_reward_trend_value": 0.0032059131172014073, "biggest_recent_change": 0.06742328316101265},

{"total_number_of_episodes": 35150, "number_of_timesteps": 11746085, "per_episode_reward": -7.6, "episode_reward_trend_value": 0.003161027957927617, "biggest_recent_change": 0.06742328316101265},
{"total_number_of_episodes": 35160, "number_of_timesteps": 11750414, "per_episode_reward": -7.58, "episode_reward_trend_value": 0.002949813368456618, "biggest_recent_change": 0.06742328316101265},
{"total_number_of_episodes": 35170, "number_of_timesteps": 11755205, "per_episode_reward": -7.56, "episode_reward_trend_value": 0.0028507461156724546, "biggest_recent_change": 0.06742328316101265},
{"total_number_of_episodes": 35181, "number_of_timesteps": 11763196, "per_episode_reward": -7.5, "episode_reward_trend_value": 0.0031682775183250215, "biggest_recent_change": 0.06742328316101265},
{"total_number_of_episodes": 35191, "number_of_timesteps": 11766695, "per_episode_reward": -7.47, "episode_reward_trend_value": 0.003174005510116413, "biggest_recent_change": 0.06742328316101265},
{"total_number_of_episodes": 35201, "number_of_timesteps": 11772538, "per_episode_reward": -7.43, "episode_reward_trend_value": 0.0034049442292998318, "biggest_recent_change": 0.06742328316101265},
{"total_number_of_episodes": 35211, "number_of_timesteps": 11777124, "per_episode_reward": -7.4, "episode_reward_trend_value": 0.0029467543365402507, "biggest_recent_change": 0.05477720048329093},
{"total_number_of_episodes": 35221, "number_of_timesteps": 11781985, "per_episode_reward": -7.35, "episode_reward_trend_value": 0.00333508278909656, "biggest_recent_change": 0.05477720048329093},
{"total_number_of_episodes": 35231, "number_of_timesteps": 11788601, "per_episode_reward": -7.3, "episode_reward_trend_value": 0.0034677591422614283, "biggest_recent_change": 0.05477720048329093},
{"total_number_of_episodes": 35241, "number_of_timesteps": 11796325, "per_episode_reward": -7.19, "episode_reward_trend_value": 0.00458803897008819, "biggest_recent_change": 0.1149246695329822},

{"total_number_of_episodes": 35251, "number_of_timesteps": 11801613, "per_episode_reward": -7.14, "episode_reward_trend_value": 0.004904426409614911, "biggest_recent_change": 0.1149246695329822},
{"total_number_of_episodes": 35261, "number_of_timesteps": 11808526, "per_episode_reward": -7.12, "episode_reward_trend_value": 0.004821113155505754, "biggest_recent_change": 0.1149246695329822},
{"total_number_of_episodes": 35271, "number_of_timesteps": 11814073, "per_episode_reward": -7.11, "episode_reward_trend_value": 0.004403011937303613, "biggest_recent_change": 0.1149246695329822},
{"total_number_of_episodes": 35281, "number_of_timesteps": 11818420, "per_episode_reward": -7.09, "episode_reward_trend_value": 0.004275604324681916, "biggest_recent_change": 0.1149246695329822},
{"total_number_of_episodes": 35291, "number_of_timesteps": 11822680, "per_episode_reward": -7.04, "episode_reward_trend_value": 0.00428367046420059, "biggest_recent_change": 0.1149246695329822},
{"total_number_of_episodes": 35301, "number_of_timesteps": 11829862, "per_episode_reward": -7.0, "episode_reward_trend_value": 0.004479670366334106, "biggest_recent_change": 0.1149246695329822},
{"total_number_of_episodes": 35311, "number_of_timesteps": 11835918, "per_episode_reward": -6.96, "episode_reward_trend_value": 0.004335364631560938, "biggest_recent_change": 0.1149246695329822},
{"total_number_of_episodes": 35321, "number_of_timesteps": 11842780, "per_episode_reward": -6.93, "episode_reward_trend_value": 0.00408429889274089, "biggest_recent_change": 0.1149246695329822},
{"total_number_of_episodes": 35331, "number_of_timesteps": 11847460, "per_episode_reward": -6.88, "episode_reward_trend_value": 0.0034300485794861225, "biggest_recent_change": 0.05604214134005314},
{"total_number_of_episodes": 35341, "number_of_timesteps": 11852705, "per_episode_reward": -6.86, "episode_reward_trend_value": 0.0031044298000401363, "biggest_recent_change": 0.05604214134005314},
{"total_number_of_episodes": 35351, "number_of_timesteps": 11859020, "per_episode_reward": -6.83, "episode_reward_trend_value": 0.0032503979796890113, "biggest_recent_change": 0.05604214134005314},
{"total_number_of_episodes": 35361, "number_of_timesteps": 11864001, "per_episode_reward": -6.82, "episode_reward_trend_value": 0.0032171380558685355, "biggest_recent_change": 0.05604214134005314},
{"total_number_of_episodes": 35371, "number_of_timesteps": 11870085, "per_episode_reward": -6.8, "episode_reward_trend_value": 0.0032052461441032937, "biggest_recent_change": 0.05604214134005314},
{"total_number_of_episodes": 35382, "number_of_timesteps": 11877807, "per_episode_reward": -6.73, "episode_reward_trend_value": 0.0035032378999717813, "biggest_recent_change": 0.07483120313095526},

{"total_number_of_episodes": 35392, "number_of_timesteps": 11885465, "per_episode_reward": -6.68, "episode_reward_trend_value": 0.0034846325032043385, "biggest_recent_change": 0.07483120313095526},
{"total_number_of_episodes": 35402, "number_of_timesteps": 11890071, "per_episode_reward": -6.66, "episode_reward_trend_value": 0.0033762847338767743, "biggest_recent_change": 0.07483120313095526},
{"total_number_of_episodes": 35412, "number_of_timesteps": 11895906, "per_episode_reward": -6.62, "episode_reward_trend_value": 0.0035340357950198473, "biggest_recent_change": 0.07483120313095526},
{"total_number_of_episodes": 35422, "number_of_timesteps": 11901653, "per_episode_reward": -6.56, "episode_reward_trend_value": 0.003567990444304018, "biggest_recent_change": 0.07483120313095526},
{"total_number_of_episodes": 35432, "number_of_timesteps": 11906798, "per_episode_reward": -6.51, "episode_reward_trend_value": 0.0039347694874631856, "biggest_recent_change": 0.07483120313095526},
{"total_number_of_episodes": 35442, "number_of_timesteps": 11912584, "per_episode_reward": -6.46, "episode_reward_trend_value": 0.004167597254931435, "biggest_recent_change": 0.07483120313095526},
{"total_number_of_episodes": 35452, "number_of_timesteps": 11918179, "per_episode_reward": -6.4, "episode_reward_trend_value": 0.004581824063589204, "biggest_recent_change": 0.07483120313095526},
{"total_number_of_episodes": 35462, "number_of_timesteps": 11923758, "per_episode_reward": -6.39, "episode_reward_trend_value": 0.0045738855564451935, "biggest_recent_change": 0.07483120313095526},
{"total_number_of_episodes": 35472, "number_of_timesteps": 11928972, "per_episode_reward": -6.34, "episode_reward_trend_value": 0.004231372126121781, "biggest_recent_change": 0.05909805977562854},
{"total_number_of_episodes": 35482, "number_of_timesteps": 11935267, "per_episode_reward": -6.32, "episode_reward_trend_value": 0.004016190556520548, "biggest_recent_change": 0.05909805977562854},
{"total_number_of_episodes": 35492, "number_of_timesteps": 11942061, "per_episode_reward": -6.27, "episode_reward_trend_value": 0.004321338361048808, "biggest_recent_change": 0.05909805977562854},
{"total_number_of_episodes": 35502, "number_of_timesteps": 11948208, "per_episode_reward": -6.22, "episode_reward_trend_value": 0.004376871989449733, "biggest_recent_change": 0.05909805977562854},
{"total_number_of_episodes": 35512, "number_of_timesteps": 11954106, "per_episode_reward": -6.17, "episode_reward_trend_value": 0.004340721648143356, "biggest_recent_change": 0.055844529058054704},
{"total_number_of_episodes": 35522, "number_of_timesteps": 11960022, "per_episode_reward": -6.14, "episode_reward_trend_value": 0.004049886752001896, "biggest_recent_change": 0.055844529058054704},
{"total_number_of_episodes": 35532, "number_of_timesteps": 11964251, "per_episode_reward": -6.11, "episode_reward_trend_value": 0.003871302995854483, "biggest_recent_change": 0.055844529058054704},
{"total_number_of_episodes": 35542, "number_of_timesteps": 11968374, "per_episode_reward": -6.08, "episode_reward_trend_value": 0.0036158451062519247, "biggest_recent_change": 0.055844529058054704},
{"total_number_of_episodes": 35552, "number_of_timesteps": 11972702, "per_episode_reward": -6.07, "episode_reward_trend_value": 0.0035927841831139853, "biggest_recent_change": 0.055844529058054704},
{"total_number_of_episodes": 35562, "number_of_timesteps": 11977693, "per_episode_reward": -6.04, "episode_reward_trend_value": 0.0033750606716850978, "biggest_recent_change": 0.055844529058054704},
{"total_number_of_episodes": 35572, "number_of_timesteps": 11980194, "per_episode_reward": -5.99, "episode_reward_trend_value": 0.0037155006164237094, "biggest_recent_change": 0.055844529058054704},
{"total_number_of_episodes": 35582, "number_of_timesteps": 11985236, "per_episode_reward": -5.93, "episode_reward_trend_value": 0.003730980575757689, "biggest_recent_change": 0.055844529058054704},
{"total_number_of_episodes": 35592, "number_of_timesteps": 11988243, "per_episode_reward": -5.9, "episode_reward_trend_value": 0.0035711704188646997, "biggest_recent_change": 0.055844529058054704},
{"total_number_of_episodes": 35602, "number_of_timesteps": 11992327, "per_episode_reward": -5.88, "episode_reward_trend_value": 0.0032205281005400445, "biggest_recent_change": 0.055485738940057594},
{"total_number_of_episodes": 35612, "number_of_timesteps": 11995486, "per_episode_reward": -5.85, "episode_reward_trend_value": 0.0032776028742668036, "biggest_recent_change": 0.055485738940057594},
{"total_number_of_episodes": 35623, "number_of_timesteps": 12000945, "per_episode_reward": -5.81, "episode_reward_trend_value": 0.0032950940265198134, "biggest_recent_change": 0.055485738940057594},
{"total_number_of_episodes": 35633, "number_of_timesteps": 12004522, "per_episode_reward": -5.75, "episode_reward_trend_value": 0.0036928075438277573, "biggest_recent_change": 0.06423811697393944},
{"total_number_of_episodes": 35643, "number_of_timesteps": 12007483, "per_episode_reward": -5.72, "episode_reward_trend_value": 0.003809609560608814, "biggest_recent_change": 0.06423811697393944},
{"total_number_of_episodes": 35653, "number_of_timesteps": 12013497, "per_episode_reward": -5.69, "episode_reward_trend_value": 0.003946750051931483, "biggest_recent_change": 0.06423811697393944},
{"total_number_of_episodes": 35663, "number_of_timesteps": 12016649, "per_episode_reward": -5.68, "episode_reward_trend_value": 0.003460166791632761, "biggest_recent_change": 0.06423811697393944},
{"total_number_of_episodes": 35673, "number_of_timesteps": 12019740, "per_episode_reward": -5.66, "episode_reward_trend_value": 0.0030145781532703434, "biggest_recent_change": 0.06423811697393944},
{"total_number_of_episodes": 35683, "number_of_timesteps": 12024768, "per_episode_reward": -5.65, "episode_reward_trend_value": 0.0027992394251525887, "biggest_recent_change": 0.06423811697393944},
{"total_number_of_episodes": 35694, "number_of_timesteps": 12030472, "per_episode_reward": -5.62, "episode_reward_trend_value": 0.0028486498612906234, "biggest_recent_change": 0.06423811697393944},
{"total_number_of_episodes": 35704, "number_of_timesteps": 12033543, "per_episode_reward": -5.58, "episode_reward_trend_value": 0.002981525785059347, "biggest_recent_change": 0.06423811697393944},
{"total_number_of_episodes": 35714, "number_of_timesteps": 12038359, "per_episode_reward": -5.55, "episode_reward_trend_value": 0.0029428888766167166, "biggest_recent_change": 0.06423811697393944},
{"total_number_of_episodes": 35724, "number_of_timesteps": 12042585, "per_episode_reward": -5.52, "episode_reward_trend_value": 0.0024846576668238344, "biggest_recent_change": 0.04069641744985297},
{"total_number_of_episodes": 35734, "number_of_timesteps": 12046574, "per_episode_reward": -5.51, "episode_reward_trend_value": 0.0023566368751300358, "biggest_recent_change": 0.04069641744985297},
{"total_number_of_episodes": 35744, "number_of_timesteps": 12049240, "per_episode_reward": -5.48, "episode_reward_trend_value": 0.0022473173793549272, "biggest_recent_change": 0.04069641744985297},
{"total_number_of_episodes": 35754, "number_of_timesteps": 12053532, "per_episode_reward": -5.45, "episode_reward_trend_value": 0.0025486850707916653, "biggest_recent_change": 0.04069641744985297},
{"total_number_of_episodes": 35765, "number_of_timesteps": 12058641, "per_episode_reward": -5.39, "episode_reward_trend_value": 0.00305125810638983, "biggest_recent_change": 0.06061433469127486},
{"total_number_of_episodes": 35775, "number_of_timesteps": 12061324, "per_episode_reward": -5.38, "episode_reward_trend_value": 0.002983865475405888, "biggest_recent_change": 0.06061433469127486},

{"total_number_of_episodes": 35785, "number_of_timesteps": 12067147, "per_episode_reward": -5.36, "episode_reward_trend_value": 0.0028750334353905356, "biggest_recent_change": 0.06061433469127486},
{"total_number_of_episodes": 35795, "number_of_timesteps": 12071332, "per_episode_reward": -5.35, "episode_reward_trend_value": 0.002574477268801465, "biggest_recent_change": 0.06061433469127486},
{"total_number_of_episodes": 35805, "number_of_timesteps": 12078339, "per_episode_reward": -5.32, "episode_reward_trend_value": 0.0024891232445988106, "biggest_recent_change": 0.06061433469127486},
{"total_number_of_episodes": 35815, "number_of_timesteps": 12082982, "per_episode_reward": -5.3, "episode_reward_trend_value": 0.0024340526686622193, "biggest_recent_change": 0.06061433469127486},
{"total_number_of_episodes": 35825, "number_of_timesteps": 12088895, "per_episode_reward": -5.28, "episode_reward_trend_value": 0.0025451299964844507, "biggest_recent_change": 0.06061433469127486},
{"total_number_of_episodes": 35835, "number_of_timesteps": 12095949, "per_episode_reward": -5.26, "episode_reward_trend_value": 0.0024745382963206274, "biggest_recent_change": 0.06061433469127486},

{"total_number_of_episodes": 35845, "number_of_timesteps": 12101751, "per_episode_reward": -5.2, "episode_reward_trend_value": 0.0027157799656214207, "biggest_recent_change": 0.06061433469127486},
{"total_number_of_episodes": 35855, "number_of_timesteps": 12108211, "per_episode_reward": -5.19, "episode_reward_trend_value": 0.002230342452974041, "biggest_recent_change": 0.058467301097453905},
{"total_number_of_episodes": 35865, "number_of_timesteps": 12115450, "per_episode_reward": -5.14, "episode_reward_trend_value": 0.0026958643726149216, "biggest_recent_change": 0.058467301097453905},
{"total_number_of_episodes": 35875, "number_of_timesteps": 12121397, "per_episode_reward": -5.12, "episode_reward_trend_value": 0.00270668933211106, "biggest_recent_change": 0.058467301097453905},
{"total_number_of_episodes": 35885, "number_of_timesteps": 12128316, "per_episode_reward": -4.99, "episode_reward_trend_value": 0.003926475616252429, "biggest_recent_change": 0.1234271280295598},
{"total_number_of_episodes": 35895, "number_of_timesteps": 12134391, "per_episode_reward": -4.97, "episode_reward_trend_value": 0.00391429194320959, "biggest_recent_change": 0.1234271280295598},
{"total_number_of_episodes": 35905, "number_of_timesteps": 12140029, "per_episode_reward": -4.92, "episode_reward_trend_value": 0.004267247577659924, "biggest_recent_change": 0.1234271280295598},
{"total_number_of_episodes": 35915, "number_of_timesteps": 12145018, "per_episode_reward": -4.88, "episode_reward_trend_value": 0.004421795356642298, "biggest_recent_change": 0.1234271280295598},
{"total_number_of_episodes": 35925, "number_of_timesteps": 12149384, "per_episode_reward": -4.86, "episode_reward_trend_value": 0.004463816984267361, "biggest_recent_change": 0.1234271280295598},
{"total_number_of_episodes": 35935, "number_of_timesteps": 12154098, "per_episode_reward": -4.85, "episode_reward_trend_value": 0.0038867521139386517, "biggest_recent_change": 0.1234271280295598},
{"total_number_of_episodes": 35945, "number_of_timesteps": 12159973, "per_episode_reward": -4.84, "episode_reward_trend_value": 0.0038805250362855663, "biggest_recent_change": 0.1234271280295598},
{"total_number_of_episodes": 35955, "number_of_timesteps": 12165009, "per_episode_reward": -4.81, "episode_reward_trend_value": 0.0035933915439182625, "biggest_recent_change": 0.1234271280295598},

{"total_number_of_episodes": 35965, "number_of_timesteps": 12172524, "per_episode_reward": -4.8, "episode_reward_trend_value": 0.003543334984969467, "biggest_recent_change": 0.1234271280295598},
{"total_number_of_episodes": 35975, "number_of_timesteps": 12178160, "per_episode_reward": -4.77, "episode_reward_trend_value": 0.00249531516471765, "biggest_recent_change": 0.04980696335881696},
{"total_number_of_episodes": 35985, "number_of_timesteps": 12184875, "per_episode_reward": -4.75, "episode_reward_trend_value": 0.0024229940902839647, "biggest_recent_change": 0.04980696335881696},
{"total_number_of_episodes": 35996, "number_of_timesteps": 12193713, "per_episode_reward": -4.73, "episode_reward_trend_value": 0.002156411666592955, "biggest_recent_change": 0.03655297998435447},
{"total_number_of_episodes": 36006, "number_of_timesteps": 12200295, "per_episode_reward": -4.7, "episode_reward_trend_value": 0.002048478620926354, "biggest_recent_change": 0.029105344206896255},
{"total_number_of_episodes": 36016, "number_of_timesteps": 12207055, "per_episode_reward": -4.63, "episode_reward_trend_value": 0.002587689440224563, "biggest_recent_change": 0.07287143518087902},
{"total_number_of_episodes": 36026, "number_of_timesteps": 12213815, "per_episode_reward": -4.61, "episode_reward_trend_value": 0.0026428352712371426, "biggest_recent_change": 0.07287143518087902},
{"total_number_of_episodes": 36036, "number_of_timesteps": 12220306, "per_episode_reward": -4.59, "episode_reward_trend_value": 0.002690478514390963, "biggest_recent_change": 0.07287143518087902},
{"total_number_of_episodes": 36046, "number_of_timesteps": 12225211, "per_episode_reward": -4.57, "episode_reward_trend_value": 0.0027013593467416523, "biggest_recent_change": 0.07287143518087902},
{"total_number_of_episodes": 36056, "number_of_timesteps": 12230249, "per_episode_reward": -4.53, "episode_reward_trend_value": 0.002969540470157157, "biggest_recent_change": 0.07287143518087902},
{"total_number_of_episodes": 36066, "number_of_timesteps": 12235233, "per_episode_reward": -4.52, "episode_reward_trend_value": 0.0027503765367882732, "biggest_recent_change": 0.07287143518087902},
{"total_number_of_episodes": 36076, "number_of_timesteps": 12242781, "per_episode_reward": -4.5, "episode_reward_trend_value": 0.0027972768168288294, "biggest_recent_change": 0.07287143518087902},
{"total_number_of_episodes": 36087, "number_of_timesteps": 12250723, "per_episode_reward": -4.47, "episode_reward_trend_value": 0.0028675942283157064, "biggest_recent_change": 0.07287143518087902},
{"total_number_of_episodes": 36097, "number_of_timesteps": 12255183, "per_episode_reward": -4.46, "episode_reward_trend_value": 0.0026229699107451075, "biggest_recent_change": 0.07287143518087902},
{"total_number_of_episodes": 36107, "number_of_timesteps": 12259838, "per_episode_reward": -4.42, "episode_reward_trend_value": 0.002329626711054436, "biggest_recent_change": 0.04647054720871857},
{"total_number_of_episodes": 36117, "number_of_timesteps": 12264561, "per_episode_reward": -4.38, "episode_reward_trend_value": 0.0026528931570409045, "biggest_recent_change": 0.04647054720871857},
{"total_number_of_episodes": 36127, "number_of_timesteps": 12269837, "per_episode_reward": -4.32, "episode_reward_trend_value": 0.003021480644033265, "biggest_recent_change": 0.05382528727738922},
{"total_number_of_episodes": 36137, "number_of_timesteps": 12274470, "per_episode_reward": -4.25, "episode_reward_trend_value": 0.003617923302967934, "biggest_recent_change": 0.07589300948931665},
{"total_number_of_episodes": 36147, "number_of_timesteps": 12279608, "per_episode_reward": -4.22, "episode_reward_trend_value": 0.003418343171748707, "biggest_recent_change": 0.07589300948931665},
{"total_number_of_episodes": 36157, "number_of_timesteps": 12286844, "per_episode_reward": -4.19, "episode_reward_trend_value": 0.003720274416531755, "biggest_recent_change": 0.07589300948931665},
{"total_number_of_episodes": 36168, "number_of_timesteps": 12292923, "per_episode_reward": -4.16, "episode_reward_trend_value": 0.003746888555224251, "biggest_recent_change": 0.07589300948931665},
{"total_number_of_episodes": 36178, "number_of_timesteps": 12295428, "per_episode_reward": -4.16, "episode_reward_trend_value": 0.003382753623407759, "biggest_recent_change": 0.07589300948931665},
{"total_number_of_episodes": 36188, "number_of_timesteps": 12303444, "per_episode_reward": -4.12, "episode_reward_trend_value": 0.0037723243224513842, "biggest_recent_change": 0.07589300948931665},
{"total_number_of_episodes": 36198, "number_of_timesteps": 12306984, "per_episode_reward": -4.11, "episode_reward_trend_value": 0.003425007601575006, "biggest_recent_change": 0.07589300948931665},
{"total_number_of_episodes": 36209, "number_of_timesteps": 12309944, "per_episode_reward": -4.07, "episode_reward_trend_value": 0.0033424509514898837, "biggest_recent_change": 0.07589300948931665},
{"total_number_of_episodes": 36219, "number_of_timesteps": 12313994, "per_episode_reward": -4.06, "episode_reward_trend_value": 0.0029412823422984877, "biggest_recent_change": 0.07589300948931665},
{"total_number_of_episodes": 36229, "number_of_timesteps": 12317415, "per_episode_reward": -4.05, "episode_reward_trend_value": 0.0022243183916931426, "biggest_recent_change": 0.03988418020693274},
{"total_number_of_episodes": 36239, "number_of_timesteps": 12323960, "per_episode_reward": -4.02, "episode_reward_trend_value": 0.002246885160002549, "biggest_recent_change": 0.03988418020693274},
{"total_number_of_episodes": 36249, "number_of_timesteps": 12328818, "per_episode_reward": -4.0, "episode_reward_trend_value": 0.0020668968394422214, "biggest_recent_change": 0.03988418020693274},
{"total_number_of_episodes": 36259, "number_of_timesteps": 12331251, "per_episode_reward": -3.96, "episode_reward_trend_value": 0.002242378958430412, "biggest_recent_change": 0.041133595811485346},
{"total_number_of_episodes": 36269, "number_of_timesteps": 12332631, "per_episode_reward": -3.95, "episode_reward_trend_value": 0.0023957153079880705, "biggest_recent_change": 0.041133595811485346},

{"total_number_of_episodes": 36280, "number_of_timesteps": 12335982, "per_episode_reward": -3.93, "episode_reward_trend_value": 0.002115614876138504, "biggest_recent_change": 0.041133595811485346},
{"total_number_of_episodes": 36291, "number_of_timesteps": 12338394, "per_episode_reward": -3.93, "episode_reward_trend_value": 0.0019818068501607387, "biggest_recent_change": 0.041133595811485346},
{"total_number_of_episodes": 36301, "number_of_timesteps": 12341301, "per_episode_reward": -3.91, "episode_reward_trend_value": 0.0018057212663354597, "biggest_recent_change": 0.041133595811485346},
{"total_number_of_episodes": 36311, "number_of_timesteps": 12342357, "per_episode_reward": -3.91, "episode_reward_trend_value": 0.0016318359331766222, "biggest_recent_change": 0.041133595811485346},
{"total_number_of_episodes": 36321, "number_of_timesteps": 12344952, "per_episode_reward": -3.89, "episode_reward_trend_value": 0.0017201743794507587, "biggest_recent_change": 0.041133595811485346},
{"total_number_of_episodes": 36332, "number_of_timesteps": 12347727, "per_episode_reward": -3.85, "episode_reward_trend_value": 0.0018616628585930509, "biggest_recent_change": 0.041133595811485346},
{"total_number_of_episodes": 36342, "number_of_timesteps": 12350354, "per_episode_reward": -3.82, "episode_reward_trend_value": 0.002044346671266764, "biggest_recent_change": 0.041133595811485346},
{"total_number_of_episodes": 36352, "number_of_timesteps": 12353418, "per_episode_reward": -3.8, "episode_reward_trend_value": 0.0018278648168824408, "biggest_recent_change": 0.036796996524375736},
{"total_number_of_episodes": 36362, "number_of_timesteps": 12355805, "per_episode_reward": -3.78, "episode_reward_trend_value": 0.0018909868216425017, "biggest_recent_change": 0.036796996524375736},
{"total_number_of_episodes": 36372, "number_of_timesteps": 12359428, "per_episode_reward": -3.75, "episode_reward_trend_value": 0.0020778803354970557, "biggest_recent_change": 0.036796996524375736},
{"total_number_of_episodes": 36382, "number_of_timesteps": 12362442, "per_episode_reward": -3.73, "episode_reward_trend_value": 0.0022112991958656014, "biggest_recent_change": 0.036796996524375736},
{"total_number_of_episodes": 36393, "number_of_timesteps": 12365542, "per_episode_reward": -3.71, "episode_reward_trend_value": 0.0022650718269525893, "biggest_recent_change": 0.036796996524375736},
{"total_number_of_episodes": 36403, "number_of_timesteps": 12367543, "per_episode_reward": -3.67, "episode_reward_trend_value": 0.0026565224489811753, "biggest_recent_change": 0.037300988448440986},
{"total_number_of_episodes": 36413, "number_of_timesteps": 12368761, "per_episode_reward": -3.66, "episode_reward_trend_value": 0.0026076640892617855, "biggest_recent_change": 0.037300988448440986},
{"total_number_of_episodes": 36423, "number_of_timesteps": 12370818, "per_episode_reward": -3.64, "episode_reward_trend_value": 0.002412283866176414, "biggest_recent_change": 0.037300988448440986},
{"total_number_of_episodes": 36433, "number_of_timesteps": 12373209, "per_episode_reward": -3.59, "episode_reward_trend_value": 0.002581127452729288, "biggest_recent_change": 0.05199291931413441},
{"total_number_of_episodes": 36443, "number_of_timesteps": 12378006, "per_episode_reward": -3.58, "episode_reward_trend_value": 0.0024352344972523514, "biggest_recent_change": 0.05199291931413441},
{"total_number_of_episodes": 36453, "number_of_timesteps": 12380418, "per_episode_reward": -3.54, "episode_reward_trend_value": 0.0026404469633473956, "biggest_recent_change": 0.05199291931413441},
{"total_number_of_episodes": 36463, "number_of_timesteps": 12384325, "per_episode_reward": -3.51, "episode_reward_trend_value": 0.0026525009661378224, "biggest_recent_change": 0.05199291931413441},
{"total_number_of_episodes": 36473, "number_of_timesteps": 12389225, "per_episode_reward": -3.49, "episode_reward_trend_value": 0.0026687005878429995, "biggest_recent_change": 0.05199291931413441},
{"total_number_of_episodes": 36484, "number_of_timesteps": 12392571, "per_episode_reward": -3.46, "episode_reward_trend_value": 0.0027268616193272797, "biggest_recent_change": 0.05199291931413441},
{"total_number_of_episodes": 36494, "number_of_timesteps": 12398070, "per_episode_reward": -3.44, "episode_reward_trend_value": 0.0025455147838704542, "biggest_recent_change": 0.05199291931413441},
{"total_number_of_episodes": 36504, "number_of_timesteps": 12400069, "per_episode_reward": -3.42, "episode_reward_trend_value": 0.0026030998977995485, "biggest_recent_change": 0.05199291931413441},
{"total_number_of_episodes": 36514, "number_of_timesteps": 12403281, "per_episode_reward": -3.41, "episode_reward_trend_value": 0.002532649586971135, "biggest_recent_change": 0.05199291931413441},
{"total_number_of_episodes": 36524, "number_of_timesteps": 12407069, "per_episode_reward": -3.37, "episode_reward_trend_value": 0.002373326530505566, "biggest_recent_change": 0.03765384423223317},
{"total_number_of_episodes": 36534, "number_of_timesteps": 12409883, "per_episode_reward": -3.32, "episode_reward_trend_value": 0.002871722560045884, "biggest_recent_change": 0.053375505582600624},
{"total_number_of_episodes": 36544, "number_of_timesteps": 12415641, "per_episode_reward": -3.28, "episode_reward_trend_value": 0.0029141781610510817, "biggest_recent_change": 0.053375505582600624},
{"total_number_of_episodes": 36554, "number_of_timesteps": 12420526, "per_episode_reward": -3.2, "episode_reward_trend_value": 0.0034363375676026405, "biggest_recent_change": 0.07957476442816036},
{"total_number_of_episodes": 36564, "number_of_timesteps": 12422009, "per_episode_reward": -3.18, "episode_reward_trend_value": 0.0034901359537459777, "biggest_recent_change": 0.07957476442816036},
{"total_number_of_episodes": 36574, "number_of_timesteps": 12426695, "per_episode_reward": -3.15, "episode_reward_trend_value": 0.0034566224829951863, "biggest_recent_change": 0.07957476442816036},

{"total_number_of_episodes": 36594, "number_of_timesteps": 12436602, "per_episode_reward": -3.13, "episode_reward_trend_value": 0.003217244874574342, "biggest_recent_change": 0.07957476442816036},
{"total_number_of_episodes": 36604, "number_of_timesteps": 12439389, "per_episode_reward": -3.1, "episode_reward_trend_value": 0.0034583082708049473, "biggest_recent_change": 0.07957476442816036},
{"total_number_of_episodes": 36614, "number_of_timesteps": 12443456, "per_episode_reward": -3.09, "episode_reward_trend_value": 0.0031780359079388366, "biggest_recent_change": 0.07957476442816036},
{"total_number_of_episodes": 36624, "number_of_timesteps": 12446781, "per_episode_reward": -3.08, "episode_reward_trend_value": 0.002620492038824058, "biggest_recent_change": 0.07957476442816036},
{"total_number_of_episodes": 36635, "number_of_timesteps": 12450915, "per_episode_reward": -3.06, "episode_reward_trend_value": 0.002402046602721672, "biggest_recent_change": 0.07957476442816036},
{"total_number_of_episodes": 36645, "number_of_timesteps": 12455744, "per_episode_reward": -3.04, "episode_reward_trend_value": 0.0017570765627581073, "biggest_recent_change": 0.03411795128596973},
{"total_number_of_episodes": 36655, "number_of_timesteps": 12457967, "per_episode_reward": -2.98, "episode_reward_trend_value": 0.0021968062474603182, "biggest_recent_change": 0.06105250975457999},
{"total_number_of_episodes": 36665, "number_of_timesteps": 12460936, "per_episode_reward": -2.96, "episode_reward_trend_value": 0.0021085802998904455, "biggest_recent_change": 0.06105250975457999},
{"total_number_of_episodes": 36675, "number_of_timesteps": 12463870, "per_episode_reward": -2.93, "episode_reward_trend_value": 0.0024323083348351403, "biggest_recent_change": 0.06105250975457999},
{"total_number_of_episodes": 36685, "number_of_timesteps": 12467416, "per_episode_reward": -2.89, "episode_reward_trend_value": 0.00272080208991284, "biggest_recent_change": 0.06105250975457999},
{"total_number_of_episodes": 36695, "number_of_timesteps": 12471660, "per_episode_reward": -2.87, "episode_reward_trend_value": 0.002567679727834138, "biggest_recent_change": 0.06105250975457999},
{"total_number_of_episodes": 36705, "number_of_timesteps": 12474806, "per_episode_reward": -2.85, "episode_reward_trend_value": 0.0026354911066453182, "biggest_recent_change": 0.06105250975457999},
{"total_number_of_episodes": 36715, "number_of_timesteps": 12479992, "per_episode_reward": -2.85, "episode_reward_trend_value": 0.002634695945053167, "biggest_recent_change": 0.06105250975457999},
{"total_number_of_episodes": 36725, "number_of_timesteps": 12484067, "per_episode_reward": -2.8, "episode_reward_trend_value": 0.002861240959488049, "biggest_recent_change": 0.06105250975457999},
{"total_number_of_episodes": 36735, "number_of_timesteps": 12489002, "per_episode_reward": -2.79, "episode_reward_trend_value": 0.002789872173135234, "biggest_recent_change": 0.06105250975457999},
{"total_number_of_episodes": 36745, "number_of_timesteps": 12492133, "per_episode_reward": -2.77, "episode_reward_trend_value": 0.002312806976387622, "biggest_recent_change": 0.041871308374501925},
{"total_number_of_episodes": 36755, "number_of_timesteps": 12498337, "per_episode_reward": -2.74, "episode_reward_trend_value": 0.0024470956613248706, "biggest_recent_change": 0.041871308374501925},
{"total_number_of_episodes": 36765, "number_of_timesteps": 12503442, "per_episode_reward": -2.75, "episode_reward_trend_value": 0.002039092514992502, "biggest_recent_change": 0.041871308374501925},
{"total_number_of_episodes": 36775, "number_of_timesteps": 12509203, "per_episode_reward": -2.72, "episode_reward_trend_value": 0.0018472728099806616, "biggest_recent_change": 0.041871308374501925},
{"total_number_of_episodes": 36785, "number_of_timesteps": 12514180, "per_episode_reward": -2.7, "episode_reward_trend_value": 0.0018501021792399, "biggest_recent_change": 0.041871308374501925},
{"total_number_of_episodes": 36795, "number_of_timesteps": 12518537, "per_episode_reward": -2.69, "episode_reward_trend_value": 0.0017626551320794911, "biggest_recent_change": 0.041871308374501925},
{"total_number_of_episodes": 36805, "number_of_timesteps": 12522786, "per_episode_reward": -2.66, "episode_reward_trend_value": 0.002005576461035119, "biggest_recent_change": 0.041871308374501925},
{"total_number_of_episodes": 36815, "number_of_timesteps": 12526715, "per_episode_reward": -2.65, "episode_reward_trend_value": 0.0017479569513058932, "biggest_recent_change": 0.028514230272755015},
{"total_number_of_episodes": 36825, "number_of_timesteps": 12529912, "per_episode_reward": -2.64, "episode_reward_trend_value": 0.0017021519700294529, "biggest_recent_change": 0.028514230272755015},
{"total_number_of_episodes": 36835, "number_of_timesteps": 12531980, "per_episode_reward": -2.62, "episode_reward_trend_value": 0.0016868485173782686, "biggest_recent_change": 0.028514230272755015},
{"total_number_of_episodes": 36845, "number_of_timesteps": 12535342, "per_episode_reward": -2.6, "episode_reward_trend_value": 0.001620527833542562, "biggest_recent_change": 0.02498791242498344},
{"total_number_of_episodes": 36855, "number_of_timesteps": 12540458, "per_episode_reward": -2.57, "episode_reward_trend_value": 0.001979586473150594, "biggest_recent_change": 0.0285055748170171},
{"total_number_of_episodes": 36865, "number_of_timesteps": 12546317, "per_episode_reward": -2.56, "episode_reward_trend_value": 0.0018132865030849655, "biggest_recent_change": 0.0285055748170171},
{"total_number_of_episodes": 36875, "number_of_timesteps": 12550266, "per_episode_reward": -2.53, "episode_reward_trend_value": 0.0019427469729667024, "biggest_recent_change": 0.03224302422157432},
{"total_number_of_episodes": 36885, "number_of_timesteps": 12555848, "per_episode_reward": -2.49, "episode_reward_trend_value": 0.0022255867577968885, "biggest_recent_change": 0.03611770205756937},
{"total_number_of_episodes": 36895, "number_of_timesteps": 12560943, "per_episode_reward": -2.44, "episode_reward_trend_value": 0.0024481127308976793, "biggest_recent_change": 0.0450152500040546},
{"total_number_of_episodes": 36905, "number_of_timesteps": 12564597, "per_episode_reward": -2.42, "episode_reward_trend_value": 0.0025294165039422326, "biggest_recent_change": 0.0450152500040546},
{"total_number_of_episodes": 36915, "number_of_timesteps": 12569355, "per_episode_reward": -2.41, "episode_reward_trend_value": 0.002555734904759764, "biggest_recent_change": 0.0450152500040546},
{"total_number_of_episodes": 36925, "number_of_timesteps": 12574875, "per_episode_reward": -2.36, "episode_reward_trend_value": 0.00286593229361111, "biggest_recent_change": 0.0450152500040546},
{"total_number_of_episodes": 36935, "number_of_timesteps": 12579691, "per_episode_reward": -2.33, "episode_reward_trend_value": 0.002928756105886896, "biggest_recent_change": 0.0450152500040546},
{"total_number_of_episodes": 36945, "number_of_timesteps": 12585430, "per_episode_reward": -2.3, "episode_reward_trend_value": 0.0029499488852562025, "biggest_recent_change": 0.0450152500040546},
{"total_number_of_episodes": 36956, "number_of_timesteps": 12593015, "per_episode_reward": -2.27, "episode_reward_trend_value": 0.0031830491609100148, "biggest_recent_change": 0.0450152500040546},
{"total_number_of_episodes": 36966, "number_of_timesteps": 12599726, "per_episode_reward": -2.24, "episode_reward_trend_value": 0.0031291433900057716, "biggest_recent_change": 0.0450152500040546},
{"total_number_of_episodes": 36977, "number_of_timesteps": 12605390, "per_episode_reward": -2.22, "episode_reward_trend_value": 0.003049602263050962, "biggest_recent_change": 0.0450152500040546},
{"total_number_of_episodes": 36987, "number_of_timesteps": 12610285, "per_episode_reward": -2.21, "episode_reward_trend_value": 0.0026567025980220797, "biggest_recent_change": 0.04465709630530945},
{"total_number_of_episodes": 36997, "number_of_timesteps": 12616562, "per_episode_reward": -2.17, "episode_reward_trend_value": 0.0028117927081227536, "biggest_recent_change": 0.04465709630530945},
{"total_number_of_episodes": 37007, "number_of_timesteps": 12622621, "per_episode_reward": -2.13, "episode_reward_trend_value": 0.003085429578600893, "biggest_recent_change": 0.04465709630530945},
{"total_number_of_episodes": 37017, "number_of_timesteps": 12628442, "per_episode_reward": -2.11, "episode_reward_trend_value": 0.0027919698029220254, "biggest_recent_change": 0.03996100198194208},
{"total_number_of_episodes": 37027, "number_of_timesteps": 12632772, "per_episode_reward": -2.09, "episode_reward_trend_value": 0.0026895007403416956, "biggest_recent_change": 0.03996100198194208},
{"total_number_of_episodes": 37037, "number_of_timesteps": 12638584, "per_episode_reward": -2.09, "episode_reward_trend_value": 0.0024099761203177127, "biggest_recent_change": 0.03996100198194208},
{"total_number_of_episodes": 37047, "number_of_timesteps": 12642390, "per_episode_reward": -2.06, "episode_reward_trend_value": 0.0023634022465089917, "biggest_recent_change": 0.03996100198194208},
{"total_number_of_episodes": 37057, "number_of_timesteps": 12650204, "per_episode_reward": -2.04, "episode_reward_trend_value": 0.002309094985173379, "biggest_recent_change": 0.03996100198194208},
{"total_number_of_episodes": 37067, "number_of_timesteps": 12659027, "per_episode_reward": -1.94, "episode_reward_trend_value": 0.0030836045324069547, "biggest_recent_change": 0.09866485988265827},
{"total_number_of_episodes": 37077, "number_of_timesteps": 12661981, "per_episode_reward": -1.93, "episode_reward_trend_value": 0.003064700802235638, "biggest_recent_change": 0.09866485988265827},
{"total_number_of_episodes": 37087, "number_of_timesteps": 12667208, "per_episode_reward": -1.89, "episode_reward_trend_value": 0.0030720051445353985, "biggest_recent_change": 0.09866485988265827},

{"total_number_of_episodes": 37097, "number_of_timesteps": 12674246, "per_episode_reward": -1.86, "episode_reward_trend_value": 0.0029568800041571155, "biggest_recent_change": 0.09866485988265827},
{"total_number_of_episodes": 37107, "number_of_timesteps": 12679567, "per_episode_reward": -1.85, "episode_reward_trend_value": 0.002880062063209237, "biggest_recent_change": 0.09866485988265827},
{"total_number_of_episodes": 37117, "number_of_timesteps": 12683976, "per_episode_reward": -1.83, "episode_reward_trend_value": 0.002891691579909171, "biggest_recent_change": 0.09866485988265827},
{"total_number_of_episodes": 37127, "number_of_timesteps": 12690188, "per_episode_reward": -1.8, "episode_reward_trend_value": 0.003215594264612741, "biggest_recent_change": 0.09866485988265827},
{"total_number_of_episodes": 37137, "number_of_timesteps": 12695315, "per_episode_reward": -1.79, "episode_reward_trend_value": 0.0029965992678436582, "biggest_recent_change": 0.09866485988265827},
{"total_number_of_episodes": 37147, "number_of_timesteps": 12701035, "per_episode_reward": -1.75, "episode_reward_trend_value": 0.0031316095647394965, "biggest_recent_change": 0.09866485988265827},
{"total_number_of_episodes": 37157, "number_of_timesteps": 12707293, "per_episode_reward": -1.72, "episode_reward_trend_value": 0.0023739626092712566, "biggest_recent_change": 0.04061839278892054},
{"total_number_of_episodes": 37167, "number_of_timesteps": 12714799, "per_episode_reward": -1.7, "episode_reward_trend_value": 0.0025903828345536393, "biggest_recent_change": 0.04061839278892054},
{"total_number_of_episodes": 37178, "number_of_timesteps": 12722064, "per_episode_reward": -1.67, "episode_reward_trend_value": 0.002387237989349088, "biggest_recent_change": 0.03465477804061279},
{"total_number_of_episodes": 37188, "number_of_timesteps": 12729755, "per_episode_reward": -1.65, "episode_reward_trend_value": 0.00240113729809245, "biggest_recent_change": 0.03465477804061279},
{"total_number_of_episodes": 37198, "number_of_timesteps": 12737627, "per_episode_reward": -1.62, "episode_reward_trend_value": 0.00260923346710565, "biggest_recent_change": 0.03465477804061279},
{"total_number_of_episodes": 37208, "number_of_timesteps": 12744849, "per_episode_reward": -1.58, "episode_reward_trend_value": 0.0027485308589527816, "biggest_recent_change": 0.03465477804061279},
{"total_number_of_episodes": 37218, "number_of_timesteps": 12749781, "per_episode_reward": -1.57, "episode_reward_trend_value": 0.002513784227987532, "biggest_recent_change": 0.03465477804061279},
{"total_number_of_episodes": 37228, "number_of_timesteps": 12756098, "per_episode_reward": -1.55, "episode_reward_trend_value": 0.0026357119003926036, "biggest_recent_change": 0.03465477804061279},

{"total_number_of_episodes": 37239, "number_of_timesteps": 12764182, "per_episode_reward": -1.52, "episode_reward_trend_value": 0.00256372783950021, "biggest_recent_change": 0.032560717969368325},
{"total_number_of_episodes": 37249, "number_of_timesteps": 12770853, "per_episode_reward": -1.48, "episode_reward_trend_value": 0.0027114670078944017, "biggest_recent_change": 0.04377315904599399},
{"total_number_of_episodes": 37259, "number_of_timesteps": 12777676, "per_episode_reward": -1.43, "episode_reward_trend_value": 0.002947264762437639, "biggest_recent_change": 0.048652562620342454},
{"total_number_of_episodes": 37269, "number_of_timesteps": 12785313, "per_episode_reward": -1.41, "episode_reward_trend_value": 0.0029803006738684944, "biggest_recent_change": 0.048652562620342454},
{"total_number_of_episodes": 37279, "number_of_timesteps": 12791254, "per_episode_reward": -1.37, "episode_reward_trend_value": 0.0030304333250528344, "biggest_recent_change": 0.048652562620342454},
{"total_number_of_episodes": 37289, "number_of_timesteps": 12798585, "per_episode_reward": -1.32, "episode_reward_trend_value": 0.0033064477252848683, "biggest_recent_change": 0.0549020530409734},
{"total_number_of_episodes": 37300, "number_of_timesteps": 12806716, "per_episode_reward": -1.32, "episode_reward_trend_value": 0.002960953987697586, "biggest_recent_change": 0.0549020530409734},
{"total_number_of_episodes": 37310, "number_of_timesteps": 12813726, "per_episode_reward": -1.28, "episode_reward_trend_value": 0.0031793027863996153, "biggest_recent_change": 0.0549020530409734},
{"total_number_of_episodes": 37320, "number_of_timesteps": 12816942, "per_episode_reward": -1.26, "episode_reward_trend_value": 0.003277044972016653, "biggest_recent_change": 0.0549020530409734},
{"total_number_of_episodes": 37330, "number_of_timesteps": 12823856, "per_episode_reward": -1.19, "episode_reward_trend_value": 0.003668021931255226, "biggest_recent_change": 0.06336413889176895},
{"total_number_of_episodes": 37340, "number_of_timesteps": 12828963, "per_episode_reward": -1.17, "episode_reward_trend_value": 0.003462752219721472, "biggest_recent_change": 0.06336413889176895},
{"total_number_of_episodes": 37350, "number_of_timesteps": 12835867, "per_episode_reward": -1.15, "episode_reward_trend_value": 0.003081703438441346, "biggest_recent_change": 0.06336413889176895},
{"total_number_of_episodes": 37360, "number_of_timesteps": 12841913, "per_episode_reward": -1.14, "episode_reward_trend_value": 0.00298291222060446, "biggest_recent_change": 0.06336413889176895},
{"total_number_of_episodes": 37370, "number_of_timesteps": 12848699, "per_episode_reward": -1.12, "episode_reward_trend_value": 0.002764795137799932, "biggest_recent_change": 0.06336413889176895},
{"total_number_of_episodes": 37380, "number_of_timesteps": 12855418, "per_episode_reward": -1.1, "episode_reward_trend_value": 0.0024108892050475825, "biggest_recent_change": 0.06336413889176895},
{"total_number_of_episodes": 37390, "number_of_timesteps": 12861838, "per_episode_reward": -1.09, "episode_reward_trend_value": 0.0024905835369155235, "biggest_recent_change": 0.06336413889176895},
{"total_number_of_episodes": 37400, "number_of_timesteps": 12866201, "per_episode_reward": -1.08, "episode_reward_trend_value": 0.002255987130554655, "biggest_recent_change": 0.06336413889176895},
{"total_number_of_episodes": 37410, "number_of_timesteps": 12872855, "per_episode_reward": -1.06, "episode_reward_trend_value": 0.0022432938047583667, "biggest_recent_change": 0.06336413889176895},
{"total_number_of_episodes": 37420, "number_of_timesteps": 12878917, "per_episode_reward": -1.02, "episode_reward_trend_value": 0.001930423628713392, "biggest_recent_change": 0.03520582304772124},
{"total_number_of_episodes": 37430, "number_of_timesteps": 12885112, "per_episode_reward": -0.99, "episode_reward_trend_value": 0.0019321266019618748, "biggest_recent_change": 0.03520582304772124},
{"total_number_of_episodes": 37440, "number_of_timesteps": 12892417, "per_episode_reward": -0.98, "episode_reward_trend_value": 0.0019669377202483447, "biggest_recent_change": 0.03520582304772124},
{"total_number_of_episodes": 37451, "number_of_timesteps": 12899650, "per_episode_reward": -0.93, "episode_reward_trend_value": 0.002312590442058619, "biggest_recent_change": 0.04752612410689283},
{"total_number_of_episodes": 37461, "number_of_timesteps": 12905278, "per_episode_reward": -0.89, "episode_reward_trend_value": 0.0026043457287322986, "biggest_recent_change": 0.04752612410689283},
{"total_number_of_episodes": 37471, "number_of_timesteps": 12912771, "per_episode_reward": -0.85, "episode_reward_trend_value": 0.0027821039913447656, "biggest_recent_change": 0.04752612410689283},
{"total_number_of_episodes": 37481, "number_of_timesteps": 12920156, "per_episode_reward": -0.83, "episode_reward_trend_value": 0.0028885089142474214, "biggest_recent_change": 0.04752612410689283},
{"total_number_of_episodes": 37491, "number_of_timesteps": 12926969, "per_episode_reward": -0.79, "episode_reward_trend_value": 0.003237894687579504, "biggest_recent_change": 0.04752612410689283},

{"total_number_of_episodes": 37501, "number_of_timesteps": 12933987, "per_episode_reward": -0.75, "episode_reward_trend_value": 0.003373667635359065, "biggest_recent_change": 0.04752612410689283},
{"total_number_of_episodes": 37511, "number_of_timesteps": 12941663, "per_episode_reward": -0.72, "episode_reward_trend_value": 0.0033094976252916316, "biggest_recent_change": 0.04752612410689283},
{"total_number_of_episodes": 37521, "number_of_timesteps": 12946621, "per_episode_reward": -0.67, "episode_reward_trend_value": 0.003604856184026243, "biggest_recent_change": 0.05203442288643456},
{"total_number_of_episodes": 37531, "number_of_timesteps": 12954284, "per_episode_reward": -0.65, "episode_reward_trend_value": 0.003611956782153314, "biggest_recent_change": 0.05203442288643456},
{"total_number_of_episodes": 37541, "number_of_timesteps": 12957869, "per_episode_reward": -0.61, "episode_reward_trend_value": 0.0035641984595989598, "biggest_recent_change": 0.05203442288643456},
{"total_number_of_episodes": 37551, "number_of_timesteps": 12961944, "per_episode_reward": -0.6, "episode_reward_trend_value": 0.0032670196356017326, "biggest_recent_change": 0.05203442288643456},
{"total_number_of_episodes": 37561, "number_of_timesteps": 12968096, "per_episode_reward": -0.58, "episode_reward_trend_value": 0.002993565077216513, "biggest_recent_change": 0.05203442288643456},
{"total_number_of_episodes": 37571, "number_of_timesteps": 12975238, "per_episode_reward": -0.57, "episode_reward_trend_value": 0.0029240418059175892, "biggest_recent_change": 0.05203442288643456},
{"total_number_of_episodes": 37581, "number_of_timesteps": 12981836, "per_episode_reward": -0.56, "episode_reward_trend_value": 0.0025001212125199076, "biggest_recent_change": 0.05203442288643456},
{"total_number_of_episodes": 37591, "number_of_timesteps": 12988426, "per_episode_reward": -0.48, "episode_reward_trend_value": 0.003053620561021799, "biggest_recent_change": 0.08723674142316323},
{"total_number_of_episodes": 37601, "number_of_timesteps": 12997501, "per_episode_reward": -0.42, "episode_reward_trend_value": 0.003304944563132426, "biggest_recent_change": 0.08723674142316323},
{"total_number_of_episodes": 37611, "number_of_timesteps": 13002466, "per_episode_reward": -0.43, "episode_reward_trend_value": 0.0026818319474115762, "biggest_recent_change": 0.08723674142316323},
{"total_number_of_episodes": 37621, "number_of_timesteps": 13010382, "per_episode_reward": -0.41, "episode_reward_trend_value": 0.0027116191250769676, "biggest_recent_change": 0.08723674142316323},
{"total_number_of_episodes": 37631, "number_of_timesteps": 13016107, "per_episode_reward": -0.37, "episode_reward_trend_value": 0.0026027738980502904, "biggest_recent_change": 0.08723674142316323},
{"total_number_of_episodes": 37641, "number_of_timesteps": 13021099, "per_episode_reward": -0.36, "episode_reward_trend_value": 0.002645883217402651, "biggest_recent_change": 0.08723674142316323},
{"total_number_of_episodes": 37651, "number_of_timesteps": 13025897, "per_episode_reward": -0.32, "episode_reward_trend_value": 0.0028639485445425333, "biggest_recent_change": 0.08723674142316323},
{"total_number_of_episodes": 37661, "number_of_timesteps": 13028688, "per_episode_reward": -0.3, "episode_reward_trend_value": 0.003038375781762521, "biggest_recent_change": 0.08723674142316323},
{"total_number_of_episodes": 37671, "number_of_timesteps": 13034239, "per_episode_reward": -0.28, "episode_reward_trend_value": 0.003169582090724942, "biggest_recent_change": 0.08723674142316323},
{"total_number_of_episodes": 37681, "number_of_timesteps": 13039728, "per_episode_reward": -0.26, "episode_reward_trend_value": 0.0024108139214239007, "biggest_recent_change": 0.05204968233160867},
{"total_number_of_episodes": 37692, "number_of_timesteps": 13046497, "per_episode_reward": -0.22, "episode_reward_trend_value": 0.0022670777172757936, "biggest_recent_change": 0.03911342395827902},
{"total_number_of_episodes": 37702, "number_of_timesteps": 13051602, "per_episode_reward": -0.2, "episode_reward_trend_value": 0.0025698883280237403, "biggest_recent_change": 0.03911342395827902},
{"total_number_of_episodes": 37712, "number_of_timesteps": 13057680, "per_episode_reward": -0.16, "episode_reward_trend_value": 0.002788395763175507, "biggest_recent_change": 0.04047674193589401},
{"total_number_of_episodes": 37722, "number_of_timesteps": 13061946, "per_episode_reward": -0.15, "episode_reward_trend_value": 0.002466578468456259, "biggest_recent_change": 0.04047674193589401},
{"total_number_of_episodes": 37732, "number_of_timesteps": 13066444, "per_episode_reward": -0.11, "episode_reward_trend_value": 0.0027327504981880047, "biggest_recent_change": 0.04109607552690733},
{"total_number_of_episodes": 37742, "number_of_timesteps": 13071550, "per_episode_reward": -0.07, "episode_reward_trend_value": 0.0027710906955830854, "biggest_recent_change": 0.04109607552690733},
{"total_number_of_episodes": 37752, "number_of_timesteps": 13074992, "per_episode_reward": -0.06, "episode_reward_trend_value": 0.002607524919999662, "biggest_recent_change": 0.04109607552690733},
{"total_number_of_episodes": 37762, "number_of_timesteps": 13080477, "per_episode_reward": -0.02, "episode_reward_trend_value": 0.0028875457326529544, "biggest_recent_change": 0.042119776444759796},
{"total_number_of_episodes": 37772, "number_of_timesteps": 13083963, "per_episode_reward": -0.02, "episode_reward_trend_value": 0.002713706944276295, "biggest_recent_change": 0.042119776444759796},
{"total_number_of_episodes": 37782, "number_of_timesteps": 13088453, "per_episode_reward": -0.0, "episode_reward_trend_value": 0.002428215430520572, "biggest_recent_change": 0.042119776444759796},
{"total_number_of_episodes": 37792, "number_of_timesteps": 13093203, "per_episode_reward": 0.01, "episode_reward_trend_value": 0.0022800148729611737, "biggest_recent_change": 0.042119776444759796},
{"total_number_of_episodes": 37802, "number_of_timesteps": 13100574, "per_episode_reward": 0.04, "episode_reward_trend_value": 0.0022396144912171607, "biggest_recent_change": 0.042119776444759796},
{"total_number_of_episodes": 37812, "number_of_timesteps": 13109719, "per_episode_reward": 0.08, "episode_reward_trend_value": 0.002597190121533678, "biggest_recent_change": 0.042119776444759796},
{"total_number_of_episodes": 37822, "number_of_timesteps": 13114566, "per_episode_reward": 0.1, "episode_reward_trend_value": 0.002303537614204766, "biggest_recent_change": 0.042119776444759796},
{"total_number_of_episodes": 37832, "number_of_timesteps": 13119291, "per_episode_reward": 0.13, "episode_reward_trend_value": 0.0022613051903810797, "biggest_recent_change": 0.042119776444759796},
{"total_number_of_episodes": 37842, "number_of_timesteps": 13124593, "per_episode_reward": 0.15, "episode_reward_trend_value": 0.0023363948574122635, "biggest_recent_change": 0.042119776444759796},
{"total_number_of_episodes": 37852, "number_of_timesteps": 13127552, "per_episode_reward": 0.16, "episode_reward_trend_value": 0.0020246144477865614, "biggest_recent_change": 0.036840707578932805},
{"total_number_of_episodes": 37862, "number_of_timesteps": 13132312, "per_episode_reward": 0.18, "episode_reward_trend_value": 0.002152572219262841, "biggest_recent_change": 0.036840707578932805},
{"total_number_of_episodes": 37872, "number_of_timesteps": 13137350, "per_episode_reward": 0.21, "episode_reward_trend_value": 0.00240831937947079, "biggest_recent_change": 0.036840707578932805},
{"total_number_of_episodes": 37883, "number_of_timesteps": 13141635, "per_episode_reward": 0.21, "episode_reward_trend_value": 0.0023001708307463136, "biggest_recent_change": 0.036840707578932805},
{"total_number_of_episodes": 37893, "number_of_timesteps": 13145706, "per_episode_reward": 0.26, "episode_reward_trend_value": 0.0023638903119535272, "biggest_recent_change": 0.04257546088758207},
{"total_number_of_episodes": 37903, "number_of_timesteps": 13148708, "per_episode_reward": 0.3, "episode_reward_trend_value": 0.0024845036449330058, "biggest_recent_change": 0.04750525481650736},
{"total_number_of_episodes": 37913, "number_of_timesteps": 13150910, "per_episode_reward": 0.32, "episode_reward_trend_value": 0.0024688186058831403, "biggest_recent_change": 0.04750525481650736},
{"total_number_of_episodes": 37923, "number_of_timesteps": 13154834, "per_episode_reward": 0.35, "episode_reward_trend_value": 0.0024403000096038913, "biggest_recent_change": 0.04750525481650736},
{"total_number_of_episodes": 37933, "number_of_timesteps": 13157433, "per_episode_reward": 0.37, "episode_reward_trend_value": 0.002487223916707022, "biggest_recent_change": 0.04750525481650736},
{"total_number_of_episodes": 37943, "number_of_timesteps": 13159501, "per_episode_reward": 0.39, "episode_reward_trend_value": 0.0025130842491108826, "biggest_recent_change": 0.04750525481650736},
{"total_number_of_episodes": 37953, "number_of_timesteps": 13160857, "per_episode_reward": 0.41, "episode_reward_trend_value": 0.0025661350564248884, "biggest_recent_change": 0.04750525481650736},
{"total_number_of_episodes": 37963, "number_of_timesteps": 13163768, "per_episode_reward": 0.41, "episode_reward_trend_value": 0.002199455092516713, "biggest_recent_change": 0.04750525481650736},
{"total_number_of_episodes": 37973, "number_of_timesteps": 13167384, "per_episode_reward": 0.45, "episode_reward_trend_value": 0.0026229787350088123, "biggest_recent_change": 0.04750525481650736},
{"total_number_of_episodes": 37983, "number_of_timesteps": 13171667, "per_episode_reward": 0.49, "episode_reward_trend_value": 0.0025729155511241848, "biggest_recent_change": 0.04750525481650736},
{"total_number_of_episodes": 37993, "number_of_timesteps": 13176010, "per_episode_reward": 0.52, "episode_reward_trend_value": 0.0023661969758693143, "biggest_recent_change": 0.038252950697613475},
{"total_number_of_episodes": 38003, "number_of_timesteps": 13180557, "per_episode_reward": 0.54, "episode_reward_trend_value": 0.0024667076661392586, "biggest_recent_change": 0.038252950697613475},
{"total_number_of_episodes": 38013, "number_of_timesteps": 13184944, "per_episode_reward": 0.59, "episode_reward_trend_value": 0.0026190317188818724, "biggest_recent_change": 0.04485592261943194},
{"total_number_of_episodes": 38023, "number_of_timesteps": 13187995, "per_episode_reward": 0.6, "episode_reward_trend_value": 0.002545246570602215, "biggest_recent_change": 0.04485592261943194},
{"total_number_of_episodes": 38033, "number_of_timesteps": 13192878, "per_episode_reward": 0.64, "episode_reward_trend_value": 0.002786161425031814, "biggest_recent_change": 0.04485592261943194},
{"total_number_of_episodes": 38043, "number_of_timesteps": 13196629, "per_episode_reward": 0.67, "episode_reward_trend_value": 0.00289697364267532, "biggest_recent_change": 0.04485592261943194},
{"total_number_of_episodes": 38053, "number_of_timesteps": 13200543, "per_episode_reward": 0.68, "episode_reward_trend_value": 0.0029550389316832103, "biggest_recent_change": 0.04485592261943194},

{"total_number_of_episodes": 38063, "number_of_timesteps": 13206191, "per_episode_reward": 0.72, "episode_reward_trend_value": 0.0029438169491449477, "biggest_recent_change": 0.04485592261943194},
{"total_number_of_episodes": 38073, "number_of_timesteps": 13209929, "per_episode_reward": 0.75, "episode_reward_trend_value": 0.0028623148003546336, "biggest_recent_change": 0.04485592261943194},
{"total_number_of_episodes": 38083, "number_of_timesteps": 13215875, "per_episode_reward": 0.76, "episode_reward_trend_value": 0.002661096739007497, "biggest_recent_change": 0.04485592261943194},
{"total_number_of_episodes": 38093, "number_of_timesteps": 13218721, "per_episode_reward": 0.77, "episode_reward_trend_value": 0.002595147305443066, "biggest_recent_change": 0.04485592261943194},
{"total_number_of_episodes": 38103, "number_of_timesteps": 13221988, "per_episode_reward": 0.83, "episode_reward_trend_value": 0.002740996844918876, "biggest_recent_change": 0.05798238117225485},
{"total_number_of_episodes": 38113, "number_of_timesteps": 13225253, "per_episode_reward": 0.84, "episode_reward_trend_value": 0.0026013371722003907, "biggest_recent_change": 0.05798238117225485},
{"total_number_of_episodes": 38123, "number_of_timesteps": 13229448, "per_episode_reward": 0.85, "episode_reward_trend_value": 0.002350906687132565, "biggest_recent_change": 0.05798238117225485},
{"total_number_of_episodes": 38134, "number_of_timesteps": 13236202, "per_episode_reward": 0.88, "episode_reward_trend_value": 0.0023164412500578397, "biggest_recent_change": 0.05798238117225485},
{"total_number_of_episodes": 38145, "number_of_timesteps": 13239610, "per_episode_reward": 0.91, "episode_reward_trend_value": 0.002538809952542627, "biggest_recent_change": 0.05798238117225485},
{"total_number_of_episodes": 38156, "number_of_timesteps": 13244741, "per_episode_reward": 0.93, "episode_reward_trend_value": 0.0024089222569428715, "biggest_recent_change": 0.05798238117225485},
{"total_number_of_episodes": 38166, "number_of_timesteps": 13248728, "per_episode_reward": 0.96, "episode_reward_trend_value": 0.002391380706059978, "biggest_recent_change": 0.05798238117225485},
{"total_number_of_episodes": 38176, "number_of_timesteps": 13254000, "per_episode_reward": 0.98, "episode_reward_trend_value": 0.002483097168702268, "biggest_recent_change": 0.05798238117225485},
{"total_number_of_episodes": 38186, "number_of_timesteps": 13258968, "per_episode_reward": 1.0, "episode_reward_trend_value": 0.0024635059281050403, "biggest_recent_change": 0.05798238117225485},
{"total_number_of_episodes": 38196, "number_of_timesteps": 13261916, "per_episode_reward": 1.01, "episode_reward_trend_value": 0.001971600782080106, "biggest_recent_change": 0.029155841367376922},
{"total_number_of_episodes": 38206, "number_of_timesteps": 13265665, "per_episode_reward": 1.03, "episode_reward_trend_value": 0.0021469560932333718, "biggest_recent_change": 0.029155841367376922},
{"total_number_of_episodes": 38217, "number_of_timesteps": 13269610, "per_episode_reward": 1.05, "episode_reward_trend_value": 0.002173124158181202, "biggest_recent_change": 0.029155841367376922},
{"total_number_of_episodes": 38227, "number_of_timesteps": 13271063, "per_episode_reward": 1.1, "episode_reward_trend_value": 0.002466745008139004, "biggest_recent_change": 0.052889974070688295},
{"total_number_of_episodes": 38237, "number_of_timesteps": 13274245, "per_episode_reward": 1.13, "episode_reward_trend_value": 0.002459544419077062, "biggest_recent_change": 0.052889974070688295},
{"total_number_of_episodes": 38247, "number_of_timesteps": 13275529, "per_episode_reward": 1.15, "episode_reward_trend_value": 0.0023990397581974236, "biggest_recent_change": 0.052889974070688295},
{"total_number_of_episodes": 38257, "number_of_timesteps": 13278363, "per_episode_reward": 1.16, "episode_reward_trend_value": 0.002243304708736682, "biggest_recent_change": 0.052889974070688295},
{"total_number_of_episodes": 38267, "number_of_timesteps": 13280863, "per_episode_reward": 1.2, "episode_reward_trend_value": 0.002486545068171316, "biggest_recent_change": 0.052889974070688295},
{"total_number_of_episodes": 38277, "number_of_timesteps": 13282791, "per_episode_reward": 1.22, "episode_reward_trend_value": 0.002493689879097332, "biggest_recent_change": 0.052889974070688295},

{"total_number_of_episodes": 38287, "number_of_timesteps": 13286700, "per_episode_reward": 1.24, "episode_reward_trend_value": 0.002517854529308086, "biggest_recent_change": 0.052889974070688295},
{"total_number_of_episodes": 38297, "number_of_timesteps": 13291726, "per_episode_reward": 1.25, "episode_reward_trend_value": 0.0024875965396790514, "biggest_recent_change": 0.052889974070688295},
{"total_number_of_episodes": 38307, "number_of_timesteps": 13295708, "per_episode_reward": 1.28, "episode_reward_trend_value": 0.0025651907946655133, "biggest_recent_change": 0.052889974070688295},
{"total_number_of_episodes": 38317, "number_of_timesteps": 13300985, "per_episode_reward": 1.31, "episode_reward_trend_value": 0.0023450123043464942, "biggest_recent_change": 0.040937071509249856},
{"total_number_of_episodes": 38327, "number_of_timesteps": 13304541, "per_episode_reward": 1.33, "episode_reward_trend_value": 0.0022654195453944313, "biggest_recent_change": 0.040937071509249856},
{"total_number_of_episodes": 38337, "number_of_timesteps": 13307101, "per_episode_reward": 1.34, "episode_reward_trend_value": 0.002138278188232026, "biggest_recent_change": 0.040937071509249856},
{"total_number_of_episodes": 38347, "number_of_timesteps": 13310214, "per_episode_reward": 1.38, "episode_reward_trend_value": 0.0024019682779844133, "biggest_recent_change": 0.040937071509249856},
{"total_number_of_episodes": 38357, "number_of_timesteps": 13312725, "per_episode_reward": 1.44, "episode_reward_trend_value": 0.0025867341824374075, "biggest_recent_change": 0.05756600291001934},
{"total_number_of_episodes": 38367, "number_of_timesteps": 13313892, "per_episode_reward": 1.46, "episode_reward_trend_value": 0.0026635191434495505, "biggest_recent_change": 0.05756600291001934},
{"total_number_of_episodes": 38379, "number_of_timesteps": 13317802, "per_episode_reward": 1.49, "episode_reward_trend_value": 0.00281810490749473, "biggest_recent_change": 0.05756600291001934},
{"total_number_of_episodes": 38389, "number_of_timesteps": 13320296, "per_episode_reward": 1.54, "episode_reward_trend_value": 0.003138803366670108, "biggest_recent_change": 0.05756600291001934},
{"total_number_of_episodes": 38399, "number_of_timesteps": 13322149, "per_episode_reward": 1.56, "episode_reward_trend_value": 0.0030853836892391776, "biggest_recent_change": 0.05756600291001934},
{"total_number_of_episodes": 38409, "number_of_timesteps": 13324775, "per_episode_reward": 1.58, "episode_reward_trend_value": 0.0029489349454618575, "biggest_recent_change": 0.05756600291001934},
{"total_number_of_episodes": 38419, "number_of_timesteps": 13327660, "per_episode_reward": 1.59, "episode_reward_trend_value": 0.0028796299788525605, "biggest_recent_change": 0.05756600291001934},
{"total_number_of_episodes": 38429, "number_of_timesteps": 13329678, "per_episode_reward": 1.61, "episode_reward_trend_value": 0.0030381014254304665, "biggest_recent_change": 0.05756600291001934},
{"total_number_of_episodes": 38439, "number_of_timesteps": 13330916, "per_episode_reward": 1.64, "episode_reward_trend_value": 0.0028920362909973193, "biggest_recent_change": 0.05756600291001934},
{"total_number_of_episodes": 38449, "number_of_timesteps": 13333906, "per_episode_reward": 1.67, "episode_reward_trend_value": 0.002558130286745894, "biggest_recent_change": 0.046628459691474555},
{"total_number_of_episodes": 38461, "number_of_timesteps": 13335714, "per_episode_reward": 1.71, "episode_reward_trend_value": 0.00276242854606707, "biggest_recent_change": 0.046628459691474555},
{"total_number_of_episodes": 38471, "number_of_timesteps": 13336958, "per_episode_reward": 1.74, "episode_reward_trend_value": 0.002782154083563336, "biggest_recent_change": 0.046628459691474555},
{"total_number_of_episodes": 38481, "number_of_timesteps": 13340083, "per_episode_reward": 1.77, "episode_reward_trend_value": 0.0025916448148848624, "biggest_recent_change": 0.04054352061590327},
{"total_number_of_episodes": 38492, "number_of_timesteps": 13342732, "per_episode_reward": 1.81, "episode_reward_trend_value": 0.0028064960873410484, "biggest_recent_change": 0.04054352061590327},
{"total_number_of_episodes": 38502, "number_of_timesteps": 13344749, "per_episode_reward": 1.83, "episode_reward_trend_value": 0.002851387644673194, "biggest_recent_change": 0.04054352061590327},
{"total_number_of_episodes": 38512, "number_of_timesteps": 13346183, "per_episode_reward": 1.87, "episode_reward_trend_value": 0.0030630219218146706, "biggest_recent_change": 0.04054352061590327},
{"total_number_of_episodes": 38522, "number_of_timesteps": 13349476, "per_episode_reward": 1.88, "episode_reward_trend_value": 0.0029373887401263083, "biggest_recent_change": 0.04054352061590327},
{"total_number_of_episodes": 38532, "number_of_timesteps": 13354831, "per_episode_reward": 1.95, "episode_reward_trend_value": 0.003390813203430137, "biggest_recent_change": 0.06653413459198632},
{"total_number_of_episodes": 38542, "number_of_timesteps": 13358108, "per_episode_reward": 1.97, "episode_reward_trend_value": 0.003351867127199691, "biggest_recent_change": 0.06653413459198632},
{"total_number_of_episodes": 38552, "number_of_timesteps": 13360522, "per_episode_reward": 1.97, "episode_reward_trend_value": 0.002891306428095218, "biggest_recent_change": 0.06653413459198632},
{"total_number_of_episodes": 38562, "number_of_timesteps": 13363179, "per_episode_reward": 1.98, "episode_reward_trend_value": 0.0026167873564625576, "biggest_recent_change": 0.06653413459198632},
{"total_number_of_episodes": 38572, "number_of_timesteps": 13367011, "per_episode_reward": 2.02, "episode_reward_trend_value": 0.002741779742419386, "biggest_recent_change": 0.06653413459198632},
{"total_number_of_episodes": 38582, "number_of_timesteps": 13368391, "per_episode_reward": 2.02, "episode_reward_trend_value": 0.0023964786485090165, "biggest_recent_change": 0.06653413459198632},
{"total_number_of_episodes": 38592, "number_of_timesteps": 13371798, "per_episode_reward": 2.07, "episode_reward_trend_value": 0.0026325067088810066, "biggest_recent_change": 0.06653413459198632},
{"total_number_of_episodes": 38602, "number_of_timesteps": 13374194, "per_episode_reward": 2.09, "episode_reward_trend_value": 0.002442699530899333, "biggest_recent_change": 0.06653413459198632},
{"total_number_of_episodes": 38612, "number_of_timesteps": 13376322, "per_episode_reward": 2.11, "episode_reward_trend_value": 0.0025149605316813627, "biggest_recent_change": 0.06653413459198632},
{"total_number_of_episodes": 38622, "number_of_timesteps": 13378205, "per_episode_reward": 2.14, "episode_reward_trend_value": 0.00213714462501892, "biggest_recent_change": 0.046076288595390036},
{"total_number_of_episodes": 38633, "number_of_timesteps": 13381255, "per_episode_reward": 2.15, "episode_reward_trend_value": 0.002023518610662532, "biggest_recent_change": 0.046076288595390036},
{"total_number_of_episodes": 38644, "number_of_timesteps": 13382768, "per_episode_reward": 2.18, "episode_reward_trend_value": 0.0023223007513482694, "biggest_recent_change": 0.046076288595390036},
{"total_number_of_episodes": 38654, "number_of_timesteps": 13385325, "per_episode_reward": 2.19, "episode_reward_trend_value": 0.0023769800822680716, "biggest_recent_change": 0.046076288595390036},
{"total_number_of_episodes": 38664, "number_of_timesteps": 13388685, "per_episode_reward": 2.21, "episode_reward_trend_value": 0.0022089894308603567, "biggest_recent_change": 0.046076288595390036},
{"total_number_of_episodes": 38674, "number_of_timesteps": 13389986, "per_episode_reward": 2.23, "episode_reward_trend_value": 0.002270471199914967, "biggest_recent_change": 0.046076288595390036},
{"total_number_of_episodes": 38684, "number_of_timesteps": 13392069, "per_episode_reward": 2.29, "episode_reward_trend_value": 0.0024184710619659447, "biggest_recent_change": 0.059396276179978},
{"total_number_of_episodes": 38694, "number_of_timesteps": 13394357, "per_episode_reward": 2.31, "episode_reward_trend_value": 0.002448984678578212, "biggest_recent_change": 0.059396276179978},
{"total_number_of_episodes": 38705, "number_of_timesteps": 13397415, "per_episode_reward": 2.37, "episode_reward_trend_value": 0.0028930717527573505, "biggest_recent_change": 0.059396276179978},
{"total_number_of_episodes": 38715, "number_of_timesteps": 13401495, "per_episode_reward": 2.38, "episode_reward_trend_value": 0.002710125466720075, "biggest_recent_change": 0.059396276179978},
{"total_number_of_episodes": 38725, "number_of_timesteps": 13402598, "per_episode_reward": 2.4, "episode_reward_trend_value": 0.0027787305620120724, "biggest_recent_change": 0.059396276179978},
{"total_number_of_episodes": 38735, "number_of_timesteps": 13404095, "per_episode_reward": 2.44, "episode_reward_trend_value": 0.002909095722656854, "biggest_recent_change": 0.059396276179978},
{"total_number_of_episodes": 38745, "number_of_timesteps": 13406712, "per_episode_reward": 2.49, "episode_reward_trend_value": 0.0033086480178317105, "biggest_recent_change": 0.059396276179978},
{"total_number_of_episodes": 38755, "number_of_timesteps": 13407984, "per_episode_reward": 2.49, "episode_reward_trend_value": 0.0030551635471711, "biggest_recent_change": 0.059396276179978},
{"total_number_of_episodes": 38766, "number_of_timesteps": 13411153, "per_episode_reward": 2.51, "episode_reward_trend_value": 0.0031222559349476106, "biggest_recent_change": 0.059396276179978},
{"total_number_of_episodes": 38776, "number_of_timesteps": 13413001, "per_episode_reward": 2.52, "episode_reward_trend_value": 0.002620277708826703, "biggest_recent_change": 0.05809170862797197},
{"total_number_of_episodes": 38786, "number_of_timesteps": 13417286, "per_episode_reward": 2.57, "episode_reward_trend_value": 0.002942604190805051, "biggest_recent_change": 0.05809170862797197},
{"total_number_of_episodes": 38796, "number_of_timesteps": 13419485, "per_episode_reward": 2.6, "episode_reward_trend_value": 0.002612456191603761, "biggest_recent_change": 0.04834549410302502},
{"total_number_of_episodes": 38806, "number_of_timesteps": 13420857, "per_episode_reward": 2.64, "episode_reward_trend_value": 0.002832918385915094, "biggest_recent_change": 0.04834549410302502},
{"total_number_of_episodes": 38817, "number_of_timesteps": 13424566, "per_episode_reward": 2.66, "episode_reward_trend_value": 0.0028855784966500026, "biggest_recent_change": 0.04834549410302502},
{"total_number_of_episodes": 38827, "number_of_timesteps": 13427175, "per_episode_reward": 2.69, "episode_reward_trend_value": 0.0028061339998430262, "biggest_recent_change": 0.04834549410302502},
{"total_number_of_episodes": 38837, "number_of_timesteps": 13429286, "per_episode_reward": 2.72, "episode_reward_trend_value": 0.0025697585297687533, "biggest_recent_change": 0.04834549410302502},
{"total_number_of_episodes": 38847, "number_of_timesteps": 13431857, "per_episode_reward": 2.71, "episode_reward_trend_value": 0.0024710918890003034, "biggest_recent_change": 0.04834549410302502},
{"total_number_of_episodes": 38857, "number_of_timesteps": 13433514, "per_episode_reward": 2.72, "episode_reward_trend_value": 0.0023288982650177203, "biggest_recent_change": 0.04834549410302502},
{"total_number_of_episodes": 38867, "number_of_timesteps": 13436195, "per_episode_reward": 2.73, "episode_reward_trend_value": 0.0022485947818519708, "biggest_recent_change": 0.04834549410302502},
{"total_number_of_episodes": 38877, "number_of_timesteps": 13440999, "per_episode_reward": 2.76, "episode_reward_trend_value": 0.002035321841653628, "biggest_recent_change": 0.035907134737031665},
{"total_number_of_episodes": 38887, "number_of_timesteps": 13444048, "per_episode_reward": 2.79, "episode_reward_trend_value": 0.0020852736902526496, "biggest_recent_change": 0.035907134737031665},
{"total_number_of_episodes": 38897, "number_of_timesteps": 13448520, "per_episode_reward": 2.79, "episode_reward_trend_value": 0.0017460765355356233, "biggest_recent_change": 0.03287405507376784},
{"total_number_of_episodes": 38907, "number_of_timesteps": 13455069, "per_episode_reward": 2.81, "episode_reward_trend_value": 0.0016269768452752062, "biggest_recent_change": 0.03287405507376784},
{"total_number_of_episodes": 38917, "number_of_timesteps": 13458133, "per_episode_reward": 2.84, "episode_reward_trend_value": 0.0016122942765885995, "biggest_recent_change": 0.03287405507376784},
{"total_number_of_episodes": 38927, "number_of_timesteps": 13463213, "per_episode_reward": 2.87, "episode_reward_trend_value": 0.0016475683263581509, "biggest_recent_change": 0.03287405507376784},
{"total_number_of_episodes": 38937, "number_of_timesteps": 13468224, "per_episode_reward": 2.88, "episode_reward_trend_value": 0.0019151149939263244, "biggest_recent_change": 0.03287405507376784},
{"total_number_of_episodes": 38947, "number_of_timesteps": 13473964, "per_episode_reward": 2.91, "episode_reward_trend_value": 0.0021394453976466554, "biggest_recent_change": 0.03287405507376784},
{"total_number_of_episodes": 38957, "number_of_timesteps": 13480226, "per_episode_reward": 2.98, "episode_reward_trend_value": 0.002849851930971554, "biggest_recent_change": 0.07092751034341971},
{"total_number_of_episodes": 38967, "number_of_timesteps": 13483439, "per_episode_reward": 3.0, "episode_reward_trend_value": 0.0027155791623977325, "biggest_recent_change": 0.07092751034341971},
{"total_number_of_episodes": 38977, "number_of_timesteps": 13487650, "per_episode_reward": 3.01, "episode_reward_trend_value": 0.0024502426280302984, "biggest_recent_change": 0.07092751034341971},
{"total_number_of_episodes": 38987, "number_of_timesteps": 13492866, "per_episode_reward": 3.04, "episode_reward_trend_value": 0.002692304641228678, "biggest_recent_change": 0.07092751034341971},
{"total_number_of_episodes": 38997, "number_of_timesteps": 13495887, "per_episode_reward": 3.05, "episode_reward_trend_value": 0.0026421296953833204, "biggest_recent_change": 0.07092751034341971},
{"total_number_of_episodes": 39007, "number_of_timesteps": 13499257, "per_episode_reward": 3.06, "episode_reward_trend_value": 0.002488299965626734, "biggest_recent_change": 0.07092751034341971},
{"total_number_of_episodes": 39017, "number_of_timesteps": 13505679, "per_episode_reward": 3.1, "episode_reward_trend_value": 0.0025994973402479558, "biggest_recent_change": 0.07092751034341971},
{"total_number_of_episodes": 39027, "number_of_timesteps": 13510017, "per_episode_reward": 3.12, "episode_reward_trend_value": 0.0026387177705998075, "biggest_recent_change": 0.07092751034341971},
{"total_number_of_episodes": 39037, "number_of_timesteps": 13512048, "per_episode_reward": 3.14, "episode_reward_trend_value": 0.002482999174586029, "biggest_recent_change": 0.07092751034341971},
{"total_number_of_episodes": 39047, "number_of_timesteps": 13515153, "per_episode_reward": 3.13, "episode_reward_trend_value": 0.0016456408088593093, "biggest_recent_change": 0.0396565194777736},
{"total_number_of_episodes": 39057, "number_of_timesteps": 13519649, "per_episode_reward": 3.15, "episode_reward_trend_value": 0.0016613943450458784, "biggest_recent_change": 0.0396565194777736},
{"total_number_of_episodes": 39067, "number_of_timesteps": 13525462, "per_episode_reward": 3.17, "episode_reward_trend_value": 0.001826375733204793, "biggest_recent_change": 0.0396565194777736},
{"total_number_of_episodes": 39077, "number_of_timesteps": 13529803, "per_episode_reward": 3.18, "episode_reward_trend_value": 0.0016333257142598849, "biggest_recent_change": 0.0396565194777736},
{"total_number_of_episodes": 39087, "number_of_timesteps": 13533958, "per_episode_reward": 3.2, "episode_reward_trend_value": 0.001697447174165687, "biggest_recent_change": 0.0396565194777736},
{"total_number_of_episodes": 39097, "number_of_timesteps": 13537097, "per_episode_reward": 3.21, "episode_reward_trend_value": 0.0016299897870102678, "biggest_recent_change": 0.0396565194777736},
{"total_number_of_episodes": 39109, "number_of_timesteps": 13541541, "per_episode_reward": 3.23, "episode_reward_trend_value": 0.001399582756639164, "biggest_recent_change": 0.023842091915001085},
{"total_number_of_episodes": 39119, "number_of_timesteps": 13544803, "per_episode_reward": 3.25, "episode_reward_trend_value": 0.0014604942172703743, "biggest_recent_change": 0.02701025186082795},
{"total_number_of_episodes": 39129, "number_of_timesteps": 13547588, "per_episode_reward": 3.26, "episode_reward_trend_value": 0.0013776720847720784, "biggest_recent_change": 0.02701025186082795},
{"total_number_of_episodes": 39139, "number_of_timesteps": 13550126, "per_episode_reward": 3.31, "episode_reward_trend_value": 0.0019915712938357514, "biggest_recent_change": 0.05081618624374551},
{"total_number_of_episodes": 39149, "number_of_timesteps": 13556179, "per_episode_reward": 3.33, "episode_reward_trend_value": 0.001973931115086626, "biggest_recent_change": 0.05081618624374551},
{"total_number_of_episodes": 39159, "number_of_timesteps": 13558617, "per_episode_reward": 3.33, "episode_reward_trend_value": 0.0017390712052541266, "biggest_recent_change": 0.05081618624374551},
{"total_number_of_episodes": 39169, "number_of_timesteps": 13564218, "per_episode_reward": 3.35, "episode_reward_trend_value": 0.0018847609252154857, "biggest_recent_change": 0.05081618624374551},
{"total_number_of_episodes": 39179, "number_of_timesteps": 13567316, "per_episode_reward": 3.37, "episode_reward_trend_value": 0.0018638275677684145, "biggest_recent_change": 0.05081618624374551},
{"total_number_of_episodes": 39189, "number_of_timesteps": 13571070, "per_episode_reward": 3.38, "episode_reward_trend_value": 0.001865783753054156, "biggest_recent_change": 0.05081618624374551},
{"total_number_of_episodes": 39199, "number_of_timesteps": 13573476, "per_episode_reward": 3.38, "episode_reward_trend_value": 0.0016505023828255558, "biggest_recent_change": 0.05081618624374551},
{"total_number_of_episodes": 39209, "number_of_timesteps": 13580479, "per_episode_reward": 3.41, "episode_reward_trend_value": 0.001711135832054901, "biggest_recent_change": 0.05081618624374551},
{"total_number_of_episodes": 39219, "number_of_timesteps": 13586024, "per_episode_reward": 3.42, "episode_reward_trend_value": 0.001804056262792085, "biggest_recent_change": 0.05081618624374551},
{"total_number_of_episodes": 39229, "number_of_timesteps": 13588362, "per_episode_reward": 3.44, "episode_reward_trend_value": 0.0014075235316155558, "biggest_recent_change": 0.03246726229146901},
{"total_number_of_episodes": 39239, "number_of_timesteps": 13592397, "per_episode_reward": 3.47, "episode_reward_trend_value": 0.0016025007392709608, "biggest_recent_change": 0.034444531171886617},
{"total_number_of_episodes": 39249, "number_of_timesteps": 13594505, "per_episode_reward": 3.5, "episode_reward_trend_value": 0.001935938985902139, "biggest_recent_change": 0.034444531171886617},
{"total_number_of_episodes": 39259, "number_of_timesteps": 13596001, "per_episode_reward": 3.54, "episode_reward_trend_value": 0.002101863857027893, "biggest_recent_change": 0.037835783493151975},
{"total_number_of_episodes": 39270, "number_of_timesteps": 13598401, "per_episode_reward": 3.55, "episode_reward_trend_value": 0.002094362348041044, "biggest_recent_change": 0.037835783493151975},
{"total_number_of_episodes": 39280, "number_of_timesteps": 13602456, "per_episode_reward": 3.6, "episode_reward_trend_value": 0.0024597266220156913, "biggest_recent_change": 0.04238787973317937},
{"total_number_of_episodes": 39290, "number_of_timesteps": 13608364, "per_episode_reward": 3.62, "episode_reward_trend_value": 0.0027265954469175174, "biggest_recent_change": 0.04238787973317937},
{"total_number_of_episodes": 39300, "number_of_timesteps": 13610917, "per_episode_reward": 3.65, "episode_reward_trend_value": 0.0027037076061884866, "biggest_recent_change": 0.04238787973317937},
{"total_number_of_episodes": 39311, "number_of_timesteps": 13613709, "per_episode_reward": 3.69, "episode_reward_trend_value": 0.0030244474187833405, "biggest_recent_change": 0.04304565725677456},
{"total_number_of_episodes": 39321, "number_of_timesteps": 13616059, "per_episode_reward": 3.72, "episode_reward_trend_value": 0.0031770902999460142, "biggest_recent_change": 0.04304565725677456},
{"total_number_of_episodes": 39331, "number_of_timesteps": 13620096, "per_episode_reward": 3.74, "episode_reward_trend_value": 0.003036911665019732, "biggest_recent_change": 0.04304565725677456},
{"total_number_of_episodes": 39341, "number_of_timesteps": 13623727, "per_episode_reward": 3.77, "episode_reward_trend_value": 0.0029211002518951612, "biggest_recent_change": 0.04304565725677456},
{"total_number_of_episodes": 39352, "number_of_timesteps": 13627506, "per_episode_reward": 3.78, "episode_reward_trend_value": 0.0026256114258091092, "biggest_recent_change": 0.04304565725677456},
{"total_number_of_episodes": 39363, "number_of_timesteps": 13630618, "per_episode_reward": 3.81, "episode_reward_trend_value": 0.0028274244493269613, "biggest_recent_change": 0.04304565725677456},
{"total_number_of_episodes": 39374, "number_of_timesteps": 13634454, "per_episode_reward": 3.85, "episode_reward_trend_value": 0.0027984573056992383, "biggest_recent_change": 0.04304565725677456},
{"total_number_of_episodes": 39384, "number_of_timesteps": 13636725, "per_episode_reward": 3.87, "episode_reward_trend_value": 0.0027408449034285187, "biggest_recent_change": 0.04304565725677456},
{"total_number_of_episodes": 39394, "number_of_timesteps": 13638034, "per_episode_reward": 3.88, "episode_reward_trend_value": 0.0025955139846457896, "biggest_recent_change": 0.04304565725677456},
{"total_number_of_episodes": 39404, "number_of_timesteps": 13640374, "per_episode_reward": 3.97, "episode_reward_trend_value": 0.0030625058126560727, "biggest_recent_change": 0.08507492177770004},
{"total_number_of_episodes": 39414, "number_of_timesteps": 13644566, "per_episode_reward": 3.99, "episode_reward_trend_value": 0.0029592100655955584, "biggest_recent_change": 0.08507492177770004},
{"total_number_of_episodes": 39424, "number_of_timesteps": 13651515, "per_episode_reward": 4.05, "episode_reward_trend_value": 0.0033612780109388445, "biggest_recent_change": 0.08507492177770004},
{"total_number_of_episodes": 39434, "number_of_timesteps": 13655478, "per_episode_reward": 4.06, "episode_reward_trend_value": 0.0033013342400643004, "biggest_recent_change": 0.08507492177770004},
{"total_number_of_episodes": 39445, "number_of_timesteps": 13662885, "per_episode_reward": 4.09, "episode_reward_trend_value": 0.003519142400184223, "biggest_recent_change": 0.08507492177770004},
{"total_number_of_episodes": 39455, "number_of_timesteps": 13667009, "per_episode_reward": 4.12, "episode_reward_trend_value": 0.0034513801294584383, "biggest_recent_change": 0.08507492177770004},
{"total_number_of_episodes": 39465, "number_of_timesteps": 13671307, "per_episode_reward": 4.15, "episode_reward_trend_value": 0.0033484017462203164, "biggest_recent_change": 0.08507492177770004},
{"total_number_of_episodes": 39475, "number_of_timesteps": 13674769, "per_episode_reward": 4.17, "episode_reward_trend_value": 0.003389909156573983, "biggest_recent_change": 0.08507492177770004},
{"total_number_of_episodes": 39485, "number_of_timesteps": 13676906, "per_episode_reward": 4.18, "episode_reward_trend_value": 0.0032591257962914177, "biggest_recent_change": 0.08507492177770004},
{"total_number_of_episodes": 39495, "number_of_timesteps": 13680568, "per_episode_reward": 4.21, "episode_reward_trend_value": 0.0026836226239214237, "biggest_recent_change": 0.058014569109416936},
{"total_number_of_episodes": 39505, "number_of_timesteps": 13683556, "per_episode_reward": 4.21, "episode_reward_trend_value": 0.0024780618079169917, "biggest_recent_change": 0.058014569109416936},
{"total_number_of_episodes": 39515, "number_of_timesteps": 13687698, "per_episode_reward": 4.23, "episode_reward_trend_value": 0.0019898862401034555, "biggest_recent_change": 0.03327963626440056},
{"total_number_of_episodes": 39525, "number_of_timesteps": 13690847, "per_episode_reward": 4.24, "episode_reward_trend_value": 0.001948659465529455, "biggest_recent_change": 0.03327963626440056},
{"total_number_of_episodes": 39535, "number_of_timesteps": 13693651, "per_episode_reward": 4.25, "episode_reward_trend_value": 0.0017090580190826938, "biggest_recent_change": 0.03327963626440056},
{"total_number_of_episodes": 39545, "number_of_timesteps": 13699956, "per_episode_reward": 4.3, "episode_reward_trend_value": 0.00200768498885717, "biggest_recent_change": 0.051614914110936105},
{"total_number_of_episodes": 39555, "number_of_timesteps": 13701229, "per_episode_reward": 4.33, "episode_reward_trend_value": 0.0019498435055242958, "biggest_recent_change": 0.051614914110936105},
{"total_number_of_episodes": 39565, "number_of_timesteps": 13704979, "per_episode_reward": 4.35, "episode_reward_trend_value": 0.0019974322482851567, "biggest_recent_change": 0.051614914110936105},
{"total_number_of_episodes": 39576, "number_of_timesteps": 13708532, "per_episode_reward": 4.37, "episode_reward_trend_value": 0.002153923763087216, "biggest_recent_change": 0.051614914110936105},
{"total_number_of_episodes": 39586, "number_of_timesteps": 13711151, "per_episode_reward": 4.39, "episode_reward_trend_value": 0.0019706447103693056, "biggest_recent_change": 0.051614914110936105},
{"total_number_of_episodes": 39596, "number_of_timesteps": 13713475, "per_episode_reward": 4.43, "episode_reward_trend_value": 0.0024145863437038074, "biggest_recent_change": 0.051614914110936105},
{"total_number_of_episodes": 39606, "number_of_timesteps": 13717645, "per_episode_reward": 4.45, "episode_reward_trend_value": 0.0024622263048637016, "biggest_recent_change": 0.051614914110936105},
{"total_number_of_episodes": 39616, "number_of_timesteps": 13719220, "per_episode_reward": 4.46, "episode_reward_trend_value": 0.0024197391859780005, "biggest_recent_change": 0.051614914110936105},
{"total_number_of_episodes": 39627, "number_of_timesteps": 13722770, "per_episode_reward": 4.5, "episode_reward_trend_value": 0.002807648034527875, "biggest_recent_change": 0.051614914110936105},
{"total_number_of_episodes": 39637, "number_of_timesteps": 13725814, "per_episode_reward": 4.51, "episode_reward_trend_value": 0.0023628115758568, "biggest_recent_change": 0.04419218974548045},
{"total_number_of_episodes": 39647, "number_of_timesteps": 13727483, "per_episode_reward": 4.54, "episode_reward_trend_value": 0.0023757235314611357, "biggest_recent_change": 0.04419218974548045},
{"total_number_of_episodes": 39657, "number_of_timesteps": 13730915, "per_episode_reward": 4.58, "episode_reward_trend_value": 0.0025690262090762813, "biggest_recent_change": 0.04419218974548045},
{"total_number_of_episodes": 39667, "number_of_timesteps": 13732506, "per_episode_reward": 4.65, "episode_reward_trend_value": 0.003082372585440534, "biggest_recent_change": 0.06584248171494789},
{"total_number_of_episodes": 39677, "number_of_timesteps": 13733903, "per_episode_reward": 4.68, "episode_reward_trend_value": 0.003256170233568935, "biggest_recent_change": 0.06584248171494789},
{"total_number_of_episodes": 39687, "number_of_timesteps": 13736142, "per_episode_reward": 4.71, "episode_reward_trend_value": 0.003064030795529613, "biggest_recent_change": 0.06584248171494789},
{"total_number_of_episodes": 39697, "number_of_timesteps": 13738894, "per_episode_reward": 4.72, "episode_reward_trend_value": 0.0029898130395047753, "biggest_recent_change": 0.06584248171494789},
{"total_number_of_episodes": 39708, "number_of_timesteps": 13740970, "per_episode_reward": 4.73, "episode_reward_trend_value": 0.0030079514800060696, "biggest_recent_change": 0.06584248171494789},
{"total_number_of_episodes": 39718, "number_of_timesteps": 13742647, "per_episode_reward": 4.73, "episode_reward_trend_value": 0.0025757450407283993, "biggest_recent_change": 0.06584248171494789},
{"total_number_of_episodes": 39728, "number_of_timesteps": 13744204, "per_episode_reward": 4.76, "episode_reward_trend_value": 0.002759151641810773, "biggest_recent_change": 0.06584248171494789},
{"total_number_of_episodes": 39738, "number_of_timesteps": 13746255, "per_episode_reward": 4.79, "episode_reward_trend_value": 0.0028192120053063168, "biggest_recent_change": 0.06584248171494789},
{"total_number_of_episodes": 39749, "number_of_timesteps": 13749024, "per_episode_reward": 4.79, "episode_reward_trend_value": 0.002328620674143147, "biggest_recent_change": 0.06584248171494789},
{"total_number_of_episodes": 39760, "number_of_timesteps": 13750426, "per_episode_reward": 4.79, "episode_reward_trend_value": 0.0015434481231571774, "biggest_recent_change": 0.03242630985134465},
{"total_number_of_episodes": 39771, "number_of_timesteps": 13752866, "per_episode_reward": 4.82, "episode_reward_trend_value": 0.0015234391886577035, "biggest_recent_change": 0.03187455753428381},
{"total_number_of_episodes": 39781, "number_of_timesteps": 13756637, "per_episode_reward": 4.86, "episode_reward_trend_value": 0.0017300291544693717, "biggest_recent_change": 0.042324303566269705},
{"total_number_of_episodes": 39791, "number_of_timesteps": 13760034, "per_episode_reward": 4.91, "episode_reward_trend_value": 0.002173453333231892, "biggest_recent_change": 0.051594942556980605},
{"total_number_of_episodes": 39801, "number_of_timesteps": 13763034, "per_episode_reward": 4.94, "episode_reward_trend_value": 0.0023171444269300167, "biggest_recent_change": 0.051594942556980605},
{"total_number_of_episodes": 39812, "number_of_timesteps": 13766560, "per_episode_reward": 4.96, "episode_reward_trend_value": 0.0024996418716494067, "biggest_recent_change": 0.051594942556980605},
{"total_number_of_episodes": 39823, "number_of_timesteps": 13769431, "per_episode_reward": 4.99, "episode_reward_trend_value": 0.002547290904595832, "biggest_recent_change": 0.051594942556980605},
{"total_number_of_episodes": 39833, "number_of_timesteps": 13774004, "per_episode_reward": 5.0, "episode_reward_trend_value": 0.002350972529345441, "biggest_recent_change": 0.051594942556980605},
{"total_number_of_episodes": 39843, "number_of_timesteps": 13777132, "per_episode_reward": 5.02, "episode_reward_trend_value": 0.0024923960393622756, "biggest_recent_change": 0.051594942556980605},
{"total_number_of_episodes": 39853, "number_of_timesteps": 13778434, "per_episode_reward": 5.02, "episode_reward_trend_value": 0.0026212745325551326, "biggest_recent_change": 0.051594942556980605},
{"total_number_of_episodes": 39863, "number_of_timesteps": 13780363, "per_episode_reward": 5.04, "episode_reward_trend_value": 0.0024850738328994894, "biggest_recent_change": 0.051594942556980605},
{"total_number_of_episodes": 39873, "number_of_timesteps": 13782125, "per_episode_reward": 5.05, "episode_reward_trend_value": 0.002112440752007701, "biggest_recent_change": 0.051594942556980605},
{"total_number_of_episodes": 39883, "number_of_timesteps": 13784271, "per_episode_reward": 5.07, "episode_reward_trend_value": 0.0016955556663608127, "biggest_recent_change": 0.032374639893131274},
{"total_number_of_episodes": 39894, "number_of_timesteps": 13786071, "per_episode_reward": 5.08, "episode_reward_trend_value": 0.001625299479243046, "biggest_recent_change": 0.032374639893131274},
{"total_number_of_episodes": 39904, "number_of_timesteps": 13787220, "per_episode_reward": 5.08, "episode_reward_trend_value": 0.001367988460131237, "biggest_recent_change": 0.032374639893131274},
{"total_number_of_episodes": 39914, "number_of_timesteps": 13788719, "per_episode_reward": 5.1, "episode_reward_trend_value": 0.001191468383410014, "biggest_recent_change": 0.018367442777384113},
{"total_number_of_episodes": 39924, "number_of_timesteps": 13790478, "per_episode_reward": 5.12, "episode_reward_trend_value": 0.0012455459805408666, "biggest_recent_change": 0.019072887503525315},
{"total_number_of_episodes": 39934, "number_of_timesteps": 13792048, "per_episode_reward": 5.14, "episode_reward_trend_value": 0.0013924232438110313, "biggest_recent_change": 0.02558738601741517},
{"total_number_of_episodes": 39944, "number_of_timesteps": 13793713, "per_episode_reward": 5.15, "episode_reward_trend_value": 0.0014539257028199297, "biggest_recent_change": 0.02558738601741517},
{"total_number_of_episodes": 39954, "number_of_timesteps": 13795275, "per_episode_reward": 5.16, "episode_reward_trend_value": 0.001316393589034437, "biggest_recent_change": 0.02558738601741517},
{"total_number_of_episodes": 39964, "number_of_timesteps": 13798239, "per_episode_reward": 5.17, "episode_reward_trend_value": 0.0013598944007475744, "biggest_recent_change": 0.02558738601741517},
{"total_number_of_episodes": 39974, "number_of_timesteps": 13802436, "per_episode_reward": 5.2, "episode_reward_trend_value": 0.0015536109747301217, "biggest_recent_change": 0.03150977650718989},
{"total_number_of_episodes": 39984, "number_of_timesteps": 13805982, "per_episode_reward": 5.21, "episode_reward_trend_value": 0.0014528945162134556, "biggest_recent_change": 0.03150977650718989},
{"total_number_of_episodes": 39994, "number_of_timesteps": 13808667, "per_episode_reward": 5.26, "episode_reward_trend_value": 0.0019386881872739971, "biggest_recent_change": 0.042281818910621105},
exited at all_updated_barrier.wait(): 4, error = 
None
exited at all_updated_barrier.wait(): 0, error = 
None
exited at all_updated_barrier.wait(): 2, error = 
None
exited at all_updated_barrier.wait(): 3, error = 
None
exited at all_updated_barrier.wait(): 1, error = 
None
exited at all_updated_barrier.wait(): 6, error = 
None
exited at all_updated_barrier.wait(): 5, error = 
None
exited at all_updated_barrier.wait(): 7, error = 
None
exited at all_updated_barrier.wait(): 8, error = 
None
[done calling async_.run_async()]
{"number_of_steps": 125000, "number_of_episodes": null, "mean": 127.23698221297303, "median": 109.8548204060121, "stdev": 110.18068076609015, "final_eval": true}
{"fitness":"11.66448560920076","env":"lunar_lander","attack":"sign","defense":"ucb"}
