config = {
    "evaluation": {
        "enabled": True, 
        "number_of_episodes_before_eval": 130, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": 125000, 
            "number_of_episodes": None, 
        }, 
    }, 
    "verbose": True, 
    "number_of_processes": 7, 
    "number_of_malicious_processes": 0, 
    "expected_number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": {
        0: 0.1, 
        1: 0.08, 
        2: 0.063, 
        3: 0.05, 
        4: 0.04, 
        5: 0.032, 
        6: 0.025, 
        7: 0.02, 
        8: 0.016, 
        9: 0.012, 
        10: 0.01, 
        11: 0.008, 
        12: 0.0063, 
        13: 0.005, 
        14: 0.004, 
        15: 0.0032, 
        16: 0.0025, 
        17: 0.002, 
        18: 0.0016, 
        19: 0.0012, 
        20: 0.001, 
        21: 0.0008, 
        22: 0.00063, 
        23: 0.0005, 
        24: 0.0004, 
        25: 0.00032, 
        26: 0.00025, 
        27: 0.0002, 
        28: 0.00016, 
        29: 0.00012, 
        30: 1e-05, 
        31: 8e-06, 
        32: 6.3e-06, 
        33: 5e-06, 
        34: 4e-06, 
        35: 3.2e-06, 
        36: 2.5e-06, 
        37: 2e-06, 
        38: 1.6e-06, 
        39: 1.2e-06, 
    }, 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": {0: 0, }, 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0, 
        "min_number_of_episodes": 30, 
        "thresholds": {}, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": {0: 0, 1: 1, 2: 2, }, }, 
            "sequential_options": {
                "t_max": {0: 3, 1: 5, 2: 10, 3: 20, 4: 30, 5: 50, }, 
                "hidden_size": {0: 16, 1: 32, 2: 64, 3: 128, }, 
                "learning_rate": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
                "beta": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
                "beta": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 40000, }, 
    "env_config": {
        "env_name": "LunarLander-v2", 
        "learning_rate": 0.0009, 
        "beta": 2e-05, 
        "t_max": 10, 
        "activation": 1, 
        "hidden_size": 128, 
        "permaban_threshold": 1000, 
        "variance_scaling_factor": 1, 
    }, 
}
args = {
    "processes": 7, 
    "env": "LunarLander-v2", 
    "seed": 3854073986, 
    "outdir": "results", 
    "t_max": 10, 
    "beta": 2e-05, 
    "profile": False, 
    "steps": 40000, 
    "max_frames": (108000, ), 
    "lr": 0.0009, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 1000, 
    "malicious": 0, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 128, 
    "activation": 1, 
}
[starting train_a3c()]
[starting train_agent_async()]
[about to call async_.run_async()]
[starting run_func()]
[starting train_loop()]
Step 0 0 visits [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1 0 visits [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-4.978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2 1 visits [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-4.978, -11.111, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 3 2 visits [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-4.978, -11.111, -11.111, 0.0, 0.0, 0.0, 0.0]
Step 4 3 visits [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-4.978, -11.111, -11.111, -11.111, 0.0, 0.0, 0.0]
Step 5 4 visits [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 0 q_vals: [-4.978, -11.111, -11.111, -11.111, 0.0, 0.0, 0.0]
Step 6 5 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 0 q_vals: [-4.978, -11.111, -11.111, -11.111, 0.0, -11.111, 0.0]
Step 7 6 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 3 q_vals: [-4.978, -11.111, -11.111, -11.111, 0.0, -11.111, 0.0]
Step 8 4 visits [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0]  episode_count: 5 q_vals: [-4.978, -11.111, -11.111, -11.111, -2.69, -11.111, 0.0]
Step 9 6 visits [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0]  episode_count: 6 q_vals: [-4.978, -11.111, -11.111, -11.111, -2.69, -11.111, -5.556]
Step 10 4 visits [1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0]  episode_count: 6 q_vals: [-4.978, -11.111, -11.111, -11.111, -5.497, -11.111, -5.556]
Step 11 0 visits [2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0]  episode_count: 7 q_vals: [-8.045, -11.111, -11.111, -11.111, -5.497, -11.111, -5.556]
Step 12 6 visits [2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0]  episode_count: 7 q_vals: [-8.045, -11.111, -11.111, -11.111, -5.497, -11.111, -5.24]
Step 13 6 visits [2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4.0]  episode_count: 7 q_vals: [-8.045, -11.111, -11.111, -11.111, -5.497, -11.111, -6.708]
Step 14 4 visits [2.0, 1.0, 1.0, 1.0, 4.0, 1.0, 4.0]  episode_count: 7 q_vals: [-8.045, -11.111, -11.111, -11.111, -6.901, -11.111, -6.708]
Step 15 6 visits [2.0, 1.0, 1.0, 1.0, 4.0, 1.0, 5.0]  episode_count: 7 q_vals: [-8.045, -11.111, -11.111, -11.111, -6.901, -11.111, -7.588]
Step 16 4 visits [2.0, 1.0, 1.0, 1.0, 5.0, 1.0, 5.0]  episode_count: 7 q_vals: [-8.045, -11.111, -11.111, -11.111, -7.743, -11.111, -7.588]
Step 17 6 visits [2.0, 1.0, 1.0, 1.0, 5.0, 1.0, 6.0]  episode_count: 7 q_vals: [-8.045, -11.111, -11.111, -11.111, -7.743, -11.111, -8.175]
Step 18 0 visits [3.0, 1.0, 1.0, 1.0, 5.0, 1.0, 6.0]  episode_count: 8 q_vals: [-9.067, -11.111, -11.111, -11.111, -7.743, -11.111, -8.175]
Step 19 4 visits [3.0, 1.0, 1.0, 1.0, 6.0, 1.0, 6.0]  episode_count: 10 q_vals: [-9.067, -11.111, -11.111, -11.111, -8.304, -11.111, -8.175]
Step 20 6 visits [3.0, 1.0, 1.0, 1.0, 6.0, 1.0, 7.0]  episode_count: 11 q_vals: [-9.067, -11.111, -11.111, -11.111, -8.304, -11.111, -8.595]
Step 21 4 visits [3.0, 1.0, 1.0, 1.0, 7.0, 1.0, 7.0]  episode_count: 13 q_vals: [-9.067, -11.111, -11.111, -11.111, -8.705, -11.111, -8.595]
Step 22 6 visits [3.0, 1.0, 1.0, 1.0, 7.0, 1.0, 8.0]  episode_count: 14 q_vals: [-9.067, -11.111, -11.111, -11.111, -8.705, -11.111, -8.089]
Step 23 6 visits [3.0, 1.0, 1.0, 1.0, 7.0, 1.0, 9.0]  episode_count: 14 q_vals: [-9.067, -11.111, -11.111, -11.111, -8.705, -11.111, -8.425]
Step 24 6 visits [3.0, 1.0, 1.0, 1.0, 7.0, 1.0, 10.0]  episode_count: 14 q_vals: [-9.067, -11.111, -11.111, -11.111, -8.705, -11.111, -8.693]
Step 25 4 visits [3.0, 1.0, 1.0, 1.0, 8.0, 1.0, 10.0]  episode_count: 14 q_vals: [-9.067, -11.111, -11.111, -11.111, -9.006, -11.111, -8.693]
Step 26 0 visits [4.0, 1.0, 1.0, 1.0, 8.0, 1.0, 10.0]  episode_count: 14 q_vals: [-9.578, -11.111, -11.111, -11.111, -9.006, -11.111, -8.693]
Step 27 6 visits [4.0, 1.0, 1.0, 1.0, 8.0, 1.0, 11.0]  episode_count: 15 q_vals: [-9.578, -11.111, -11.111, -11.111, -9.006, -11.111, -8.913]
Step 28 4 visits [4.0, 1.0, 1.0, 1.0, 9.0, 1.0, 11.0]  episode_count: 17 q_vals: [-9.578, -11.111, -11.111, -11.111, -9.24, -11.111, -8.913]
Step 29 6 visits [4.0, 1.0, 1.0, 1.0, 9.0, 1.0, 12.0]  episode_count: 18 q_vals: [-9.578, -11.111, -11.111, -11.111, -9.24, -11.111, -9.096]
Step 30 6 visits [4.0, 1.0, 1.0, 1.0, 9.0, 1.0, 13.0]  episode_count: 18 q_vals: [-9.578, -11.111, -11.111, -11.111, -9.24, -11.111, -9.251]
Step 31 4 visits [4.0, 1.0, 1.0, 1.0, 10.0, 1.0, 13.0]  episode_count: 19 q_vals: [-9.578, -11.111, -11.111, -11.111, -9.427, -11.111, -9.251]
Step 32 0 visits [5.0, 1.0, 1.0, 1.0, 10.0, 1.0, 13.0]  episode_count: 19 q_vals: [-9.885, -11.111, -11.111, -11.111, -9.427, -11.111, -9.251]
Step 33 6 visits [5.0, 1.0, 1.0, 1.0, 10.0, 1.0, 14.0]  episode_count: 20 q_vals: [-9.885, -11.111, -11.111, -11.111, -9.427, -11.111, -9.384]
Step 34 4 visits [5.0, 1.0, 1.0, 1.0, 11.0, 1.0, 14.0]  episode_count: 20 q_vals: [-9.885, -11.111, -11.111, -11.111, -9.58, -11.111, -9.384]
Step 35 6 visits [5.0, 1.0, 1.0, 1.0, 11.0, 1.0, 15.0]  episode_count: 21 q_vals: [-9.885, -11.111, -11.111, -11.111, -9.58, -11.111, -9.499]
Step 36 4 visits [5.0, 1.0, 1.0, 1.0, 12.0, 1.0, 15.0]  episode_count: 21 q_vals: [-9.885, -11.111, -11.111, -11.111, -9.708, -11.111, -9.499]
Step 37 6 visits [5.0, 1.0, 1.0, 1.0, 12.0, 1.0, 16.0]  episode_count: 22 q_vals: [-9.885, -11.111, -11.111, -11.111, -9.708, -11.111, -9.6]
Step 38 0 visits [6.0, 1.0, 1.0, 1.0, 12.0, 1.0, 16.0]  episode_count: 25 q_vals: [-10.089, -11.111, -11.111, -11.111, -9.708, -11.111, -9.6]
Step 39 6 visits [6.0, 1.0, 1.0, 1.0, 12.0, 1.0, 17.0]  episode_count: 25 q_vals: [-10.089, -11.111, -11.111, -11.111, -9.708, -11.111, -9.689]
Step 40 4 visits [6.0, 1.0, 1.0, 1.0, 13.0, 1.0, 17.0]  episode_count: 25 q_vals: [-10.089, -11.111, -11.111, -11.111, -8.961, -11.111, -9.689]
Step 41 4 visits [6.0, 1.0, 1.0, 1.0, 14.0, 1.0, 17.0]  episode_count: 26 q_vals: [-10.089, -11.111, -11.111, -11.111, -9.114, -11.111, -9.689]
Step 42 4 visits [6.0, 1.0, 1.0, 1.0, 15.0, 1.0, 17.0]  episode_count: 26 q_vals: [-10.089, -11.111, -11.111, -11.111, -9.248, -11.111, -9.689]
Step 43 4 visits [6.0, 1.0, 1.0, 1.0, 16.0, 1.0, 17.0]  episode_count: 27 q_vals: [-10.089, -11.111, -11.111, -11.111, -9.364, -11.111, -9.689]
Step 44 4 visits [6.0, 1.0, 1.0, 1.0, 17.0, 1.0, 17.0]  episode_count: 27 q_vals: [-10.089, -11.111, -11.111, -11.111, -9.467, -11.111, -9.689]
Step 45 4 visits [6.0, 1.0, 1.0, 1.0, 18.0, 1.0, 17.0]  episode_count: 28 q_vals: [-10.089, -11.111, -11.111, -11.111, -8.941, -11.111, -9.689]
Step 46 4 visits [6.0, 1.0, 1.0, 1.0, 19.0, 1.0, 17.0]  episode_count: 29 q_vals: [-10.089, -11.111, -11.111, -11.111, -9.055, -11.111, -9.689]
{"total_number_of_episodes": 32, "number_of_timesteps": 3012, "per_episode_reward": -215.88, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Step 47 4 visits [6.0, 1.0, 1.0, 1.0, 20.0, 1.0, 17.0]  episode_count: 32 q_vals: [-10.089, -11.111, -11.111, -11.111, -9.158, -11.111, -9.689]
Step 48 4 visits [6.0, 1.0, 1.0, 1.0, 21.0, 1.0, 17.0]  episode_count: 32 q_vals: [-10.089, -11.111, -11.111, -11.111, -9.251, -11.111, -9.689]
Step 49 4 visits [6.0, 1.0, 1.0, 1.0, 22.0, 1.0, 17.0]  episode_count: 33 q_vals: [-10.089, -11.111, -11.111, -11.111, -9.335, -11.111, -9.689]
Step 50 4 visits [6.0, 1.0, 1.0, 1.0, 23.0, 1.0, 17.0]  episode_count: 33 q_vals: [-10.089, -11.111, -11.111, -11.111, -9.413, -11.111, -9.689]
Step 51 4 visits [6.0, 1.0, 1.0, 1.0, 24.0, 1.0, 17.0]  episode_count: 33 q_vals: [-10.089, -11.111, -11.111, -11.111, -9.483, -11.111, -9.689]
Step 52 4 visits [6.0, 1.0, 1.0, 1.0, 25.0, 1.0, 17.0]  episode_count: 33 q_vals: [-10.089, -11.111, -11.111, -11.111, -9.549, -11.111, -9.689]
Step 53 1 visits [6.0, 2.0, 1.0, 1.0, 25.0, 1.0, 17.0]  episode_count: 34 q_vals: [-10.089, -5.556, -11.111, -11.111, -9.549, -11.111, -9.689]
Step 54 1 visits [6.0, 3.0, 1.0, 1.0, 25.0, 1.0, 17.0]  episode_count: 35 q_vals: [-10.089, -7.407, -11.111, -11.111, -9.549, -11.111, -9.689]
Step 55 1 visits [6.0, 4.0, 1.0, 1.0, 25.0, 1.0, 17.0]  episode_count: 35 q_vals: [-10.089, -8.333, -11.111, -11.111, -9.549, -11.111, -9.689]
Step 56 1 visits [6.0, 5.0, 1.0, 1.0, 25.0, 1.0, 17.0]  episode_count: 36 q_vals: [-10.089, -8.889, -11.111, -11.111, -9.549, -11.111, -9.689]
Step 57 1 visits [6.0, 6.0, 1.0, 1.0, 25.0, 1.0, 17.0]  episode_count: 39 q_vals: [-10.089, -9.259, -11.111, -11.111, -9.549, -11.111, -9.689]
Step 58 1 visits [6.0, 7.0, 1.0, 1.0, 25.0, 1.0, 17.0]  episode_count: 40 q_vals: [-10.089, -9.524, -11.111, -11.111, -9.549, -11.111, -9.689]
Step 59 1 visits [6.0, 8.0, 1.0, 1.0, 25.0, 1.0, 17.0]  episode_count: 40 q_vals: [-10.089, -9.722, -11.111, -11.111, -9.549, -11.111, -9.689]
Step 60 1 visits [6.0, 9.0, 1.0, 1.0, 25.0, 1.0, 17.0]  episode_count: 40 q_vals: [-10.089, -9.877, -11.111, -11.111, -9.549, -11.111, -9.689]
Step 61 3 visits [6.0, 9.0, 1.0, 2.0, 25.0, 1.0, 17.0]  episode_count: 40 q_vals: [-10.089, -9.877, -11.111, -11.111, -9.549, -11.111, -9.689]
Step 62 2 visits [6.0, 9.0, 2.0, 2.0, 25.0, 1.0, 17.0]  episode_count: 40 q_vals: [-10.089, -9.877, -11.111, -11.111, -9.549, -11.111, -9.689]
Step 63 5 visits [6.0, 9.0, 2.0, 2.0, 25.0, 2.0, 17.0]  episode_count: 41 q_vals: [-10.089, -9.877, -11.111, -11.111, -9.549, -11.111, -9.689]
{"total_number_of_episodes": 42, "number_of_timesteps": 3900, "per_episode_reward": -242.19, "episode_reward_trend_value": -2.6311605121276047, "biggest_recent_change": NaN},
Step 64 4 visits [6.0, 9.0, 2.0, 2.0, 26.0, 2.0, 17.0]  episode_count: 42 q_vals: [-10.089, -9.877, -11.111, -11.111, -9.609, -11.111, -9.689]
Step 65 6 visits [6.0, 9.0, 2.0, 2.0, 26.0, 2.0, 18.0]  episode_count: 44 q_vals: [-10.089, -9.877, -11.111, -11.111, -9.609, -11.111, -9.768]
Step 66 1 visits [6.0, 10.0, 2.0, 2.0, 26.0, 2.0, 18.0]  episode_count: 45 q_vals: [-10.089, -8.889, -11.111, -11.111, -9.609, -11.111, -9.768]
Step 67 1 visits [6.0, 11.0, 2.0, 2.0, 26.0, 2.0, 18.0]  episode_count: 46 q_vals: [-10.089, -9.091, -11.111, -11.111, -9.609, -11.111, -9.768]
Step 68 1 visits [6.0, 12.0, 2.0, 2.0, 26.0, 2.0, 18.0]  episode_count: 47 q_vals: [-10.089, -9.259, -11.111, -11.111, -9.609, -11.111, -9.768]
Step 69 1 visits [6.0, 13.0, 2.0, 2.0, 26.0, 2.0, 18.0]  episode_count: 47 q_vals: [-10.089, -9.402, -11.111, -11.111, -9.609, -11.111, -9.768]
Step 70 1 visits [6.0, 14.0, 2.0, 2.0, 26.0, 2.0, 18.0]  episode_count: 47 q_vals: [-10.089, -9.524, -11.111, -11.111, -9.609, -11.111, -9.768]
Step 71 1 visits [6.0, 15.0, 2.0, 2.0, 26.0, 2.0, 18.0]  episode_count: 47 q_vals: [-10.089, -9.63, -11.111, -11.111, -9.609, -11.111, -9.768]
Step 72 1 visits [6.0, 16.0, 2.0, 2.0, 26.0, 2.0, 18.0]  episode_count: 48 q_vals: [-10.089, -9.722, -11.111, -11.111, -9.609, -11.111, -9.768]
Step 73 4 visits [6.0, 16.0, 2.0, 2.0, 27.0, 2.0, 18.0]  episode_count: 48 q_vals: [-10.089, -9.722, -11.111, -11.111, -9.664, -11.111, -9.768]
Step 74 1 visits [6.0, 17.0, 2.0, 2.0, 27.0, 2.0, 18.0]  episode_count: 49 q_vals: [-10.089, -9.804, -11.111, -11.111, -9.664, -11.111, -9.768]
Step 75 0 visits [7.0, 17.0, 2.0, 2.0, 27.0, 2.0, 18.0]  episode_count: 50 q_vals: [-10.235, -9.804, -11.111, -11.111, -9.664, -11.111, -9.768]
Step 76 4 visits [7.0, 17.0, 2.0, 2.0, 28.0, 2.0, 18.0]  episode_count: 50 q_vals: [-10.235, -9.804, -11.111, -11.111, -9.716, -11.111, -9.768]
Step 77 6 visits [7.0, 17.0, 2.0, 2.0, 28.0, 2.0, 19.0]  episode_count: 51 q_vals: [-10.235, -9.804, -11.111, -11.111, -9.716, -11.111, -9.839]
Step 78 1 visits [7.0, 18.0, 2.0, 2.0, 28.0, 2.0, 19.0]  episode_count: 51 q_vals: [-10.235, -9.877, -11.111, -11.111, -9.716, -11.111, -9.839]
{"total_number_of_episodes": 52, "number_of_timesteps": 4890, "per_episode_reward": -262.76, "episode_reward_trend_value": -2.344023634430691, "biggest_recent_change": NaN},
Step 79 4 visits [7.0, 18.0, 2.0, 2.0, 29.0, 2.0, 19.0]  episode_count: 52 q_vals: [-10.235, -9.877, -11.111, -11.111, -9.764, -11.111, -9.839]
Step 80 6 visits [7.0, 18.0, 2.0, 2.0, 29.0, 2.0, 20.0]  episode_count: 52 q_vals: [-10.235, -9.877, -11.111, -11.111, -9.764, -11.111, -9.902]
Step 81 4 visits [7.0, 18.0, 2.0, 2.0, 30.0, 2.0, 20.0]  episode_count: 52 q_vals: [-10.235, -9.877, -11.111, -11.111, -9.809, -11.111, -9.902]
Step 82 1 visits [7.0, 19.0, 2.0, 2.0, 30.0, 2.0, 20.0]  episode_count: 53 q_vals: [-10.235, -9.942, -11.111, -11.111, -9.809, -11.111, -9.902]
Step 83 4 visits [7.0, 19.0, 2.0, 2.0, 31.0, 2.0, 20.0]  episode_count: 55 q_vals: [-10.235, -9.942, -11.111, -11.111, -9.851, -11.111, -9.902]
Step 84 6 visits [7.0, 19.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 55 q_vals: [-10.235, -9.942, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 85 0 visits [8.0, 19.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 55 q_vals: [-10.345, -9.942, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 86 1 visits [8.0, 20.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 55 q_vals: [-10.345, -9.444, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 87 1 visits [8.0, 21.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 55 q_vals: [-10.345, -9.524, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 88 1 visits [8.0, 22.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 56 q_vals: [-10.345, -9.091, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 89 1 visits [8.0, 23.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 57 q_vals: [-10.345, -9.179, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 90 1 visits [8.0, 24.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 57 q_vals: [-10.345, -9.259, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 91 1 visits [8.0, 25.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 57 q_vals: [-10.345, -9.333, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 92 1 visits [8.0, 26.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 58 q_vals: [-10.345, -9.402, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 93 1 visits [8.0, 27.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 59 q_vals: [-10.345, -9.465, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 94 1 visits [8.0, 28.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 59 q_vals: [-10.345, -9.524, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 95 1 visits [8.0, 29.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 59 q_vals: [-10.345, -9.579, -11.111, -11.111, -9.851, -11.111, -9.96]
{"total_number_of_episodes": 62, "number_of_timesteps": 6219, "per_episode_reward": -315.34, "episode_reward_trend_value": -3.315539480980769, "biggest_recent_change": NaN},
Step 96 1 visits [8.0, 30.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 62 q_vals: [-10.345, -9.63, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 97 1 visits [8.0, 31.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 62 q_vals: [-10.345, -9.677, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 98 1 visits [8.0, 32.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 63 q_vals: [-10.345, -9.722, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 99 1 visits [8.0, 33.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 63 q_vals: [-10.345, -9.764, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 100 1 visits [8.0, 34.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 63 q_vals: [-10.345, -9.804, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 101 1 visits [8.0, 35.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 65 q_vals: [-10.345, -9.524, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 102 1 visits [8.0, 36.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 66 q_vals: [-10.345, -9.568, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 103 1 visits [8.0, 37.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 66 q_vals: [-10.345, -9.61, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 104 1 visits [8.0, 38.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 66 q_vals: [-10.345, -9.649, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 105 1 visits [8.0, 39.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 67 q_vals: [-10.345, -9.402, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 106 1 visits [8.0, 40.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 69 q_vals: [-10.345, -9.444, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 107 1 visits [8.0, 41.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 69 q_vals: [-10.345, -9.485, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 108 1 visits [8.0, 42.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 70 q_vals: [-10.345, -9.524, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 109 1 visits [8.0, 43.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 71 q_vals: [-10.345, -9.561, -11.111, -11.111, -9.851, -11.111, -9.96]
{"total_number_of_episodes": 72, "number_of_timesteps": 7130, "per_episode_reward": -336.08, "episode_reward_trend_value": -3.0049512241373044, "biggest_recent_change": NaN},
Step 110 1 visits [8.0, 44.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 72 q_vals: [-10.345, -9.343, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 111 1 visits [8.0, 45.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 74 q_vals: [-10.345, -9.383, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 112 1 visits [8.0, 46.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 75 q_vals: [-10.345, -9.42, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 113 1 visits [8.0, 47.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 75 q_vals: [-10.345, -9.456, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 114 1 visits [8.0, 48.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 75 q_vals: [-10.345, -9.491, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 115 1 visits [8.0, 49.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 75 q_vals: [-10.345, -9.297, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 116 1 visits [8.0, 50.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 76 q_vals: [-10.345, -9.333, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 117 1 visits [8.0, 51.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 78 q_vals: [-10.345, -9.368, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 118 1 visits [8.0, 52.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 78 q_vals: [-10.345, -9.402, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 119 1 visits [8.0, 53.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 79 q_vals: [-10.345, -9.434, -11.111, -11.111, -9.851, -11.111, -9.96]
{"total_number_of_episodes": 82, "number_of_timesteps": 7916, "per_episode_reward": -349.96, "episode_reward_trend_value": -2.681591793273496, "biggest_recent_change": NaN},
Step 120 1 visits [8.0, 54.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 82 q_vals: [-10.345, -9.465, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 121 1 visits [8.0, 55.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 82 q_vals: [-10.345, -9.495, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 122 1 visits [8.0, 56.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 82 q_vals: [-10.345, -9.524, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 123 1 visits [8.0, 57.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 82 q_vals: [-10.345, -9.357, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 124 1 visits [8.0, 58.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 83 q_vals: [-10.345, -9.195, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 125 1 visits [8.0, 59.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 85 q_vals: [-10.345, -9.228, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 126 1 visits [8.0, 60.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 85 q_vals: [-10.345, -9.259, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 127 1 visits [8.0, 61.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 85 q_vals: [-10.345, -9.29, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 128 1 visits [8.0, 62.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 85 q_vals: [-10.345, -9.319, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 129 1 visits [8.0, 63.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 87 q_vals: [-10.345, -9.347, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 130 1 visits [8.0, 64.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 87 q_vals: [-10.345, -9.375, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 131 1 visits [8.0, 65.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 88 q_vals: [-10.345, -9.402, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 132 1 visits [8.0, 66.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 88 q_vals: [-10.345, -9.428, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 133 1 visits [8.0, 67.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 90 q_vals: [-10.345, -9.453, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 134 1 visits [8.0, 68.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 90 q_vals: [-10.345, -9.477, -11.111, -11.111, -9.851, -11.111, -9.96]
{"total_number_of_episodes": 92, "number_of_timesteps": 8845, "per_episode_reward": -386.91, "episode_reward_trend_value": -2.8505663790676015, "biggest_recent_change": NaN},
Step 135 1 visits [8.0, 69.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 92 q_vals: [-10.345, -9.501, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 136 1 visits [8.0, 70.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 92 q_vals: [-10.345, -9.524, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 137 1 visits [8.0, 71.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 93 q_vals: [-10.345, -9.546, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 138 1 visits [8.0, 72.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 93 q_vals: [-10.345, -9.568, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 139 1 visits [8.0, 73.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 94 q_vals: [-10.345, -9.589, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 140 1 visits [8.0, 74.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 94 q_vals: [-10.345, -9.61, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 141 1 visits [8.0, 75.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 95 q_vals: [-10.345, -9.63, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 142 1 visits [8.0, 76.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 97 q_vals: [-10.345, -9.649, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 143 1 visits [8.0, 77.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 98 q_vals: [-10.345, -9.668, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 144 1 visits [8.0, 78.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 100 q_vals: [-10.345, -9.687, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 145 1 visits [8.0, 79.0, 2.0, 2.0, 31.0, 2.0, 21.0]  episode_count: 100 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.851, -11.111, -9.96]
Step 146 4 visits [8.0, 79.0, 2.0, 2.0, 32.0, 2.0, 21.0]  episode_count: 101 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.543, -11.111, -9.96]
Step 147 4 visits [8.0, 79.0, 2.0, 2.0, 33.0, 2.0, 21.0]  episode_count: 101 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.591, -11.111, -9.96]
Step 148 4 visits [8.0, 79.0, 2.0, 2.0, 34.0, 2.0, 21.0]  episode_count: 101 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.635, -11.111, -9.96]
{"total_number_of_episodes": 102, "number_of_timesteps": 9669, "per_episode_reward": -396.63, "episode_reward_trend_value": -2.5821320914505086, "biggest_recent_change": NaN},
Step 149 4 visits [8.0, 79.0, 2.0, 2.0, 35.0, 2.0, 21.0]  episode_count: 102 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.678, -11.111, -9.96]
Step 150 4 visits [8.0, 79.0, 2.0, 2.0, 36.0, 2.0, 21.0]  episode_count: 103 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.409, -11.111, -9.96]
Step 151 4 visits [8.0, 79.0, 2.0, 2.0, 37.0, 2.0, 21.0]  episode_count: 103 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.455, -11.111, -9.96]
Step 152 4 visits [8.0, 79.0, 2.0, 2.0, 38.0, 2.0, 21.0]  episode_count: 104 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.498, -11.111, -9.96]
Step 153 4 visits [8.0, 79.0, 2.0, 2.0, 39.0, 2.0, 21.0]  episode_count: 105 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.255, -11.111, -9.96]
Step 154 4 visits [8.0, 79.0, 2.0, 2.0, 40.0, 2.0, 21.0]  episode_count: 107 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.301, -11.111, -9.96]
Step 155 4 visits [8.0, 79.0, 2.0, 2.0, 41.0, 2.0, 21.0]  episode_count: 109 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.345, -11.111, -9.96]
Step 156 4 visits [8.0, 79.0, 2.0, 2.0, 42.0, 2.0, 21.0]  episode_count: 110 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.387, -11.111, -9.96]
Step 157 4 visits [8.0, 79.0, 2.0, 2.0, 43.0, 2.0, 21.0]  episode_count: 110 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.427, -11.111, -9.96]
Step 158 4 visits [8.0, 79.0, 2.0, 2.0, 44.0, 2.0, 21.0]  episode_count: 110 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.466, -11.111, -9.96]
Step 159 4 visits [8.0, 79.0, 2.0, 2.0, 45.0, 2.0, 21.0]  episode_count: 111 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.502, -11.111, -9.96]
{"total_number_of_episodes": 112, "number_of_timesteps": 10456, "per_episode_reward": -408.36, "episode_reward_trend_value": -2.4060134511295916, "biggest_recent_change": NaN},
Step 160 4 visits [8.0, 79.0, 2.0, 2.0, 46.0, 2.0, 21.0]  episode_count: 112 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.537, -11.111, -9.96]
Step 161 4 visits [8.0, 79.0, 2.0, 2.0, 47.0, 2.0, 21.0]  episode_count: 113 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.571, -11.111, -9.96]
Step 162 4 visits [8.0, 79.0, 2.0, 2.0, 48.0, 2.0, 21.0]  episode_count: 113 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.603, -11.111, -9.96]
Step 163 4 visits [8.0, 79.0, 2.0, 2.0, 49.0, 2.0, 21.0]  episode_count: 115 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.634, -11.111, -9.96]
Step 164 4 visits [8.0, 79.0, 2.0, 2.0, 50.0, 2.0, 21.0]  episode_count: 116 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.663, -11.111, -9.96]
Step 165 4 visits [8.0, 79.0, 2.0, 2.0, 51.0, 2.0, 21.0]  episode_count: 117 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.692, -11.111, -9.96]
Step 166 4 visits [8.0, 79.0, 2.0, 2.0, 52.0, 2.0, 21.0]  episode_count: 118 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.719, -11.111, -9.96]
Step 167 4 visits [8.0, 79.0, 2.0, 2.0, 53.0, 2.0, 21.0]  episode_count: 118 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.745, -11.111, -9.96]
Step 168 4 visits [8.0, 79.0, 2.0, 2.0, 54.0, 2.0, 21.0]  episode_count: 118 q_vals: [-10.345, -9.705, -11.111, -11.111, -9.77, -11.111, -9.96]
Step 169 1 visits [8.0, 80.0, 2.0, 2.0, 54.0, 2.0, 21.0]  episode_count: 118 q_vals: [-10.345, -9.722, -11.111, -11.111, -9.77, -11.111, -9.96]
Step 170 4 visits [8.0, 80.0, 2.0, 2.0, 55.0, 2.0, 21.0]  episode_count: 120 q_vals: [-10.345, -9.722, -11.111, -11.111, -9.795, -11.111, -9.96]
Step 171 6 visits [8.0, 80.0, 2.0, 2.0, 55.0, 2.0, 22.0]  episode_count: 120 q_vals: [-10.345, -9.722, -11.111, -11.111, -9.795, -11.111, -10.012]
{"total_number_of_episodes": 124, "number_of_timesteps": 11426, "per_episode_reward": -434.16, "episode_reward_trend_value": -2.4253821152987003, "biggest_recent_change": 52.585711740809245},
Step 172 1 visits [8.0, 81.0, 2.0, 2.0, 55.0, 2.0, 22.0]  episode_count: 124 q_vals: [-10.345, -9.739, -11.111, -11.111, -9.795, -11.111, -10.012]
Step 173 1 visits [8.0, 82.0, 2.0, 2.0, 55.0, 2.0, 22.0]  episode_count: 124 q_vals: [-10.345, -9.756, -11.111, -11.111, -9.795, -11.111, -10.012]
Step 174 4 visits [8.0, 82.0, 2.0, 2.0, 56.0, 2.0, 22.0]  episode_count: 125 q_vals: [-10.345, -9.756, -11.111, -11.111, -9.818, -11.111, -10.012]
Step 175 3 visits [8.0, 82.0, 2.0, 3.0, 56.0, 2.0, 22.0]  episode_count: 125 q_vals: [-10.345, -9.756, -11.111, -11.111, -9.818, -11.111, -10.012]
Step 176 5 visits [8.0, 82.0, 2.0, 3.0, 56.0, 3.0, 22.0]  episode_count: 125 q_vals: [-10.345, -9.756, -11.111, -11.111, -9.818, -11.111, -10.012]
Step 177 2 visits [8.0, 82.0, 3.0, 3.0, 56.0, 3.0, 22.0]  episode_count: 126 q_vals: [-10.345, -9.756, -11.111, -11.111, -9.818, -11.111, -10.012]
Step 178 1 visits [8.0, 83.0, 3.0, 3.0, 56.0, 3.0, 22.0]  episode_count: 127 q_vals: [-10.345, -9.772, -11.111, -11.111, -9.818, -11.111, -10.012]
Step 179 4 visits [8.0, 83.0, 3.0, 3.0, 57.0, 3.0, 22.0]  episode_count: 129 q_vals: [-10.345, -9.772, -11.111, -11.111, -9.841, -11.111, -10.012]
Step 180 1 visits [8.0, 84.0, 3.0, 3.0, 57.0, 3.0, 22.0]  episode_count: 131 q_vals: [-10.345, -9.788, -11.111, -11.111, -9.841, -11.111, -10.012]
Step 181 6 visits [8.0, 84.0, 3.0, 3.0, 57.0, 3.0, 23.0]  episode_count: 131 q_vals: [-10.345, -9.788, -11.111, -11.111, -9.841, -11.111, -10.06]
Step 182 0 visits [9.0, 84.0, 3.0, 3.0, 57.0, 3.0, 23.0]  episode_count: 132 q_vals: [-10.43, -9.788, -11.111, -11.111, -9.841, -11.111, -10.06]
Step 183 4 visits [9.0, 84.0, 3.0, 3.0, 58.0, 3.0, 23.0]  episode_count: 132 q_vals: [-10.43, -9.788, -11.111, -11.111, -9.863, -11.111, -10.06]
Step 184 1 visits [9.0, 85.0, 3.0, 3.0, 58.0, 3.0, 23.0]  episode_count: 132 q_vals: [-10.43, -9.804, -11.111, -11.111, -9.863, -11.111, -10.06]
Step 185 1 visits [9.0, 86.0, 3.0, 3.0, 58.0, 3.0, 23.0]  episode_count: 132 q_vals: [-10.43, -9.819, -11.111, -11.111, -9.863, -11.111, -10.06]
{"total_number_of_episodes": 134, "number_of_timesteps": 12165, "per_episode_reward": -436.28, "episode_reward_trend_value": -2.1565368485852354, "biggest_recent_change": 52.585711740809245},
Step 186 4 visits [9.0, 86.0, 3.0, 3.0, 59.0, 3.0, 23.0]  episode_count: 134 q_vals: [-10.43, -9.819, -11.111, -11.111, -9.884, -11.111, -10.06]
Step 187 1 visits [9.0, 87.0, 3.0, 3.0, 59.0, 3.0, 23.0]  episode_count: 135 q_vals: [-10.43, -9.834, -11.111, -11.111, -9.884, -11.111, -10.06]
Step 188 6 visits [9.0, 87.0, 3.0, 3.0, 59.0, 3.0, 24.0]  episode_count: 138 q_vals: [-10.43, -9.834, -11.111, -11.111, -9.884, -11.111, -10.104]
Step 189 4 visits [9.0, 87.0, 3.0, 3.0, 60.0, 3.0, 24.0]  episode_count: 138 q_vals: [-10.43, -9.834, -11.111, -11.111, -9.904, -11.111, -10.104]
Step 190 1 visits [9.0, 88.0, 3.0, 3.0, 60.0, 3.0, 24.0]  episode_count: 139 q_vals: [-10.43, -9.848, -11.111, -11.111, -9.904, -11.111, -10.104]
Step 191 1 visits [9.0, 89.0, 3.0, 3.0, 60.0, 3.0, 24.0]  episode_count: 139 q_vals: [-10.43, -9.863, -11.111, -11.111, -9.904, -11.111, -10.104]
Step 192 4 visits [9.0, 89.0, 3.0, 3.0, 61.0, 3.0, 24.0]  episode_count: 140 q_vals: [-10.43, -9.863, -11.111, -11.111, -9.924, -11.111, -10.104]
Step 193 1 visits [9.0, 90.0, 3.0, 3.0, 61.0, 3.0, 24.0]  episode_count: 140 q_vals: [-10.43, -9.877, -11.111, -11.111, -9.924, -11.111, -10.104]
Step 194 4 visits [9.0, 90.0, 3.0, 3.0, 62.0, 3.0, 24.0]  episode_count: 142 q_vals: [-10.43, -9.877, -11.111, -11.111, -9.943, -11.111, -10.104]
Step 195 1 visits [9.0, 91.0, 3.0, 3.0, 62.0, 3.0, 24.0]  episode_count: 143 q_vals: [-10.43, -9.89, -11.111, -11.111, -9.943, -11.111, -10.104]
{"total_number_of_episodes": 146, "number_of_timesteps": 13047, "per_episode_reward": -438.87, "episode_reward_trend_value": -1.9568335282119602, "biggest_recent_change": 52.585711740809245},
Step 196 6 visits [9.0, 91.0, 3.0, 3.0, 62.0, 3.0, 25.0]  episode_count: 146 q_vals: [-10.43, -9.89, -11.111, -11.111, -9.943, -11.111, -10.144]
Step 197 1 visits [9.0, 92.0, 3.0, 3.0, 62.0, 3.0, 25.0]  episode_count: 146 q_vals: [-10.43, -9.903, -11.111, -11.111, -9.943, -11.111, -10.144]
Step 198 4 visits [9.0, 92.0, 3.0, 3.0, 63.0, 3.0, 25.0]  episode_count: 146 q_vals: [-10.43, -9.903, -11.111, -11.111, -9.786, -11.111, -10.144]
Step 199 4 visits [9.0, 92.0, 3.0, 3.0, 64.0, 3.0, 25.0]  episode_count: 146 q_vals: [-10.43, -9.903, -11.111, -11.111, -9.806, -11.111, -10.144]
Step 200 4 visits [9.0, 92.0, 3.0, 3.0, 65.0, 3.0, 25.0]  episode_count: 147 q_vals: [-10.43, -9.903, -11.111, -11.111, -9.826, -11.111, -10.144]
Step 201 4 visits [9.0, 92.0, 3.0, 3.0, 66.0, 3.0, 25.0]  episode_count: 148 q_vals: [-10.43, -9.903, -11.111, -11.111, -9.846, -11.111, -10.144]
Step 202 4 visits [9.0, 92.0, 3.0, 3.0, 67.0, 3.0, 25.0]  episode_count: 148 q_vals: [-10.43, -9.903, -11.111, -11.111, -9.865, -11.111, -10.144]
Step 203 4 visits [9.0, 92.0, 3.0, 3.0, 68.0, 3.0, 25.0]  episode_count: 149 q_vals: [-10.43, -9.903, -11.111, -11.111, -9.883, -11.111, -10.144]
Step 204 4 visits [9.0, 92.0, 3.0, 3.0, 69.0, 3.0, 25.0]  episode_count: 150 q_vals: [-10.43, -9.903, -11.111, -11.111, -9.901, -11.111, -10.144]
Step 205 4 visits [9.0, 92.0, 3.0, 3.0, 70.0, 3.0, 25.0]  episode_count: 153 q_vals: [-10.43, -9.903, -11.111, -11.111, -9.918, -11.111, -10.144]
Step 206 4 visits [9.0, 92.0, 3.0, 3.0, 71.0, 3.0, 25.0]  episode_count: 153 q_vals: [-10.43, -9.903, -11.111, -11.111, -9.935, -11.111, -10.144]
Step 207 0 visits [10.0, 92.0, 3.0, 3.0, 71.0, 3.0, 25.0]  episode_count: 153 q_vals: [-10.498, -9.903, -11.111, -11.111, -9.935, -11.111, -10.144]
Step 208 4 visits [10.0, 92.0, 3.0, 3.0, 72.0, 3.0, 25.0]  episode_count: 153 q_vals: [-10.498, -9.903, -11.111, -11.111, -9.951, -11.111, -10.144]
Step 209 1 visits [10.0, 93.0, 3.0, 3.0, 72.0, 3.0, 25.0]  episode_count: 153 q_vals: [-10.498, -9.916, -11.111, -11.111, -9.951, -11.111, -10.144]
Step 210 1 visits [10.0, 94.0, 3.0, 3.0, 72.0, 3.0, 25.0]  episode_count: 155 q_vals: [-10.498, -9.929, -11.111, -11.111, -9.951, -11.111, -10.144]
Step 211 4 visits [10.0, 94.0, 3.0, 3.0, 73.0, 3.0, 25.0]  episode_count: 155 q_vals: [-10.498, -9.929, -11.111, -11.111, -9.967, -11.111, -10.144]
Step 212 6 visits [10.0, 94.0, 3.0, 3.0, 73.0, 3.0, 26.0]  episode_count: 155 q_vals: [-10.498, -9.929, -11.111, -11.111, -9.967, -11.111, -10.181]
{"total_number_of_episodes": 156, "number_of_timesteps": 13850, "per_episode_reward": -438.54, "episode_reward_trend_value": -1.3688375083192827, "biggest_recent_change": 36.954393080381294},
Step 213 1 visits [10.0, 95.0, 3.0, 3.0, 73.0, 3.0, 26.0]  episode_count: 156 q_vals: [-10.498, -9.942, -11.111, -11.111, -9.967, -11.111, -10.181]
Step 214 4 visits [10.0, 95.0, 3.0, 3.0, 74.0, 3.0, 26.0]  episode_count: 157 q_vals: [-10.498, -9.942, -11.111, -11.111, -9.983, -11.111, -10.181]
Step 215 1 visits [10.0, 96.0, 3.0, 3.0, 74.0, 3.0, 26.0]  episode_count: 158 q_vals: [-10.498, -9.954, -11.111, -11.111, -9.983, -11.111, -10.181]
Step 216 4 visits [10.0, 96.0, 3.0, 3.0, 75.0, 3.0, 26.0]  episode_count: 159 q_vals: [-10.498, -9.954, -11.111, -11.111, -9.998, -11.111, -10.181]
Step 217 1 visits [10.0, 97.0, 3.0, 3.0, 75.0, 3.0, 26.0]  episode_count: 159 q_vals: [-10.498, -9.966, -11.111, -11.111, -9.998, -11.111, -10.181]
Step 218 6 visits [10.0, 97.0, 3.0, 3.0, 75.0, 3.0, 27.0]  episode_count: 159 q_vals: [-10.498, -9.966, -11.111, -11.111, -9.998, -11.111, -10.216]
Step 219 4 visits [10.0, 97.0, 3.0, 3.0, 76.0, 3.0, 27.0]  episode_count: 159 q_vals: [-10.498, -9.966, -11.111, -11.111, -10.012, -11.111, -10.216]
Step 220 1 visits [10.0, 98.0, 3.0, 3.0, 76.0, 3.0, 27.0]  episode_count: 160 q_vals: [-10.498, -9.977, -11.111, -11.111, -10.012, -11.111, -10.216]
Step 221 1 visits [10.0, 99.0, 3.0, 3.0, 76.0, 3.0, 27.0]  episode_count: 162 q_vals: [-10.498, -9.989, -11.111, -11.111, -10.012, -11.111, -10.216]
Step 222 4 visits [10.0, 99.0, 3.0, 3.0, 77.0, 3.0, 27.0]  episode_count: 162 q_vals: [-10.498, -9.989, -11.111, -11.111, -10.027, -11.111, -10.216]
Step 223 1 visits [10.0, 100.0, 3.0, 3.0, 77.0, 3.0, 27.0]  episode_count: 163 q_vals: [-10.498, -10.0, -11.111, -11.111, -10.027, -11.111, -10.216]
Step 224 4 visits [10.0, 100.0, 3.0, 3.0, 78.0, 3.0, 27.0]  episode_count: 163 q_vals: [-10.498, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
Step 225 0 visits [11.0, 100.0, 3.0, 3.0, 78.0, 3.0, 27.0]  episode_count: 163 q_vals: [-9.543, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
Step 226 0 visits [12.0, 100.0, 3.0, 3.0, 78.0, 3.0, 27.0]  episode_count: 163 q_vals: [-9.674, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
Step 227 0 visits [13.0, 100.0, 3.0, 3.0, 78.0, 3.0, 27.0]  episode_count: 163 q_vals: [-9.785, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
Step 228 0 visits [14.0, 100.0, 3.0, 3.0, 78.0, 3.0, 27.0]  episode_count: 165 q_vals: [-9.879, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
{"total_number_of_episodes": 166, "number_of_timesteps": 14957, "per_episode_reward": -433.71, "episode_reward_trend_value": -1.0848532609392318, "biggest_recent_change": 36.954393080381294},
Step 229 0 visits [15.0, 100.0, 3.0, 3.0, 78.0, 3.0, 27.0]  episode_count: 166 q_vals: [-9.962, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
Step 230 0 visits [16.0, 100.0, 3.0, 3.0, 78.0, 3.0, 27.0]  episode_count: 168 q_vals: [-10.033, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
Step 231 0 visits [17.0, 100.0, 3.0, 3.0, 78.0, 3.0, 27.0]  episode_count: 168 q_vals: [-10.097, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
Step 232 0 visits [18.0, 100.0, 3.0, 3.0, 78.0, 3.0, 27.0]  episode_count: 169 q_vals: [-10.153, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
Step 233 0 visits [19.0, 100.0, 3.0, 3.0, 78.0, 3.0, 27.0]  episode_count: 169 q_vals: [-10.204, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
Step 234 0 visits [20.0, 100.0, 3.0, 3.0, 78.0, 3.0, 27.0]  episode_count: 169 q_vals: [-10.249, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
Step 235 0 visits [21.0, 100.0, 3.0, 3.0, 78.0, 3.0, 27.0]  episode_count: 169 q_vals: [-10.29, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
Step 236 3 visits [21.0, 100.0, 3.0, 4.0, 78.0, 3.0, 27.0]  episode_count: 169 q_vals: [-10.29, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
Step 237 2 visits [21.0, 100.0, 4.0, 4.0, 78.0, 3.0, 27.0]  episode_count: 169 q_vals: [-10.29, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
Step 238 5 visits [21.0, 100.0, 4.0, 4.0, 78.0, 4.0, 27.0]  episode_count: 171 q_vals: [-10.29, -10.0, -11.111, -11.111, -10.04, -11.111, -10.216]
Step 239 6 visits [21.0, 100.0, 4.0, 4.0, 78.0, 4.0, 28.0]  episode_count: 171 q_vals: [-10.29, -10.0, -11.111, -11.111, -10.04, -11.111, -10.248]
Step 240 1 visits [21.0, 101.0, 4.0, 4.0, 78.0, 4.0, 28.0]  episode_count: 173 q_vals: [-10.29, -9.901, -11.111, -11.111, -10.04, -11.111, -10.248]
Step 241 1 visits [21.0, 102.0, 4.0, 4.0, 78.0, 4.0, 28.0]  episode_count: 173 q_vals: [-10.29, -9.913, -11.111, -11.111, -10.04, -11.111, -10.248]
Step 242 1 visits [21.0, 103.0, 4.0, 4.0, 78.0, 4.0, 28.0]  episode_count: 175 q_vals: [-10.29, -9.924, -11.111, -11.111, -10.04, -11.111, -10.248]
{"total_number_of_episodes": 176, "number_of_timesteps": 16116, "per_episode_reward": -439.95, "episode_reward_trend_value": -0.9999353152033101, "biggest_recent_change": 36.954393080381294},
[starting run_func()]
[starting train_loop()]
Step 243 1 visits [21.0, 104.0, 4.0, 4.0, 78.0, 4.0, 28.0]  episode_count: 176 q_vals: [-10.29, -9.936, -11.111, -11.111, -10.04, -11.111, -10.248]
Step 244 1 visits [21.0, 105.0, 4.0, 4.0, 78.0, 4.0, 28.0]  episode_count: 176 q_vals: [-10.29, -9.947, -11.111, -11.111, -10.04, -11.111, -10.248]
Step 245 1 visits [21.0, 106.0, 4.0, 4.0, 78.0, 4.0, 28.0]  episode_count: 176 q_vals: [-10.29, -9.958, -11.111, -11.111, -10.04, -11.111, -10.248]
Step 246 1 visits [21.0, 107.0, 4.0, 4.0, 78.0, 4.0, 28.0]  episode_count: 176 q_vals: [-10.29, -9.969, -11.111, -11.111, -10.04, -11.111, -10.248]
Step 247 1 visits [21.0, 108.0, 4.0, 4.0, 78.0, 4.0, 28.0]  episode_count: 176 q_vals: [-10.29, -9.979, -11.111, -11.111, -10.04, -11.111, -10.248]
Step 248 1 visits [21.0, 109.0, 4.0, 4.0, 78.0, 4.0, 28.0]  episode_count: 176 q_vals: [-10.29, -9.99, -11.111, -11.111, -10.04, -11.111, -10.248]
Step 249 1 visits [21.0, 110.0, 4.0, 4.0, 78.0, 4.0, 28.0]  episode_count: 177 q_vals: [-10.29, -10.0, -11.111, -11.111, -10.04, -11.111, -10.248]
Step 250 4 visits [21.0, 110.0, 4.0, 4.0, 79.0, 4.0, 28.0]  episode_count: 178 q_vals: [-10.29, -10.0, -11.111, -11.111, -10.054, -11.111, -10.248]
Step 251 1 visits [21.0, 111.0, 4.0, 4.0, 79.0, 4.0, 28.0]  episode_count: 180 q_vals: [-10.29, -10.01, -11.111, -11.111, -10.054, -11.111, -10.248]
Step 252 0 visits [22.0, 111.0, 4.0, 4.0, 79.0, 4.0, 28.0]  episode_count: 180 q_vals: [-10.327, -10.01, -11.111, -11.111, -10.054, -11.111, -10.248]
Step 253 1 visits [22.0, 112.0, 4.0, 4.0, 79.0, 4.0, 28.0]  episode_count: 181 q_vals: [-10.327, -10.02, -11.111, -11.111, -10.054, -11.111, -10.248]
Step 254 4 visits [22.0, 112.0, 4.0, 4.0, 80.0, 4.0, 28.0]  episode_count: 181 q_vals: [-10.327, -10.02, -11.111, -11.111, -10.067, -11.111, -10.248]
Step 255 1 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 28.0]  episode_count: 181 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -10.248]
Step 256 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 29.0]  episode_count: 182 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.894]
Step 257 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 30.0]  episode_count: 182 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.935]
Step 258 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 31.0]  episode_count: 183 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.614]
Step 259 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 32.0]  episode_count: 183 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.661]
Step 260 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 33.0]  episode_count: 183 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.705]
Step 261 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 34.0]  episode_count: 183 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.746]
Step 262 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 35.0]  episode_count: 183 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.785]
Step 263 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 36.0]  episode_count: 185 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.822]
{"total_number_of_episodes": 186, "number_of_timesteps": 17251, "per_episode_reward": -446.09, "episode_reward_trend_value": -0.6575774781113757, "biggest_recent_change": 25.803314286515672},
Step 264 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 37.0]  episode_count: 186 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.857]
Step 265 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 38.0]  episode_count: 187 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.598]
Step 266 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 39.0]  episode_count: 188 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.636]
Step 267 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 40.0]  episode_count: 189 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.673]
Step 268 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 41.0]  episode_count: 190 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.437]
Step 269 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 42.0]  episode_count: 190 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.477]
Step 270 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 43.0]  episode_count: 190 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.515]
Step 271 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 44.0]  episode_count: 190 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.299]
Step 272 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 45.0]  episode_count: 191 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.339]
Step 273 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 46.0]  episode_count: 192 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.136]
Step 274 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 47.0]  episode_count: 193 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.178]
Step 275 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 48.0]  episode_count: 194 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.218]
Step 276 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 49.0]  episode_count: 195 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.03]
Step 277 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 50.0]  episode_count: 195 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.072]
{"total_number_of_episodes": 196, "number_of_timesteps": 18364, "per_episode_reward": -450.68, "episode_reward_trend_value": -0.6006374991248701, "biggest_recent_change": 25.803314286515672},
Step 278 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 51.0]  episode_count: 196 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.112]
Step 279 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 52.0]  episode_count: 196 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.15]
Step 280 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 53.0]  episode_count: 196 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.978]
Step 281 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 54.0]  episode_count: 198 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.017]
Step[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
 282 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 55.0]  episode_count: 199 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.055]
Step 283 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 56.0]  episode_count: 200 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.092]
Step 284 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 57.0]  episode_count: 201 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.127]
Step 285 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 58.0]  episode_count: 203 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.162]
Step 286 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 59.0]  episode_count: 203 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.195]
Step 287 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 60.0]  episode_count: 203 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.227]
Step 288 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 61.0]  episode_count: 203 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.258]
Step 289 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 62.0]  episode_count: 205 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.287]
Step 290 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 63.0]  episode_count: 205 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.316]
{"total_number_of_episodes": 207, "number_of_timesteps": 19288, "per_episode_reward": -451.68, "episode_reward_trend_value": -0.4813800650401851, "biggest_recent_change": 25.803314286515672},
Step 291 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 64.0]  episode_count: 207 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.344]
Step 292 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 65.0]  episode_count: 209 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.201]
Step 293 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 66.0]  episode_count: 209 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.23]
Step 294 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 67.0]  episode_count: 210 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.258]
Step 295 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 68.0]  episode_count: 212 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.285]
Step 296 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 69.0]  episode_count: 212 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.311]
Step 297 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 70.0]  episode_count: 212 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.337]
Step 298 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 71.0]  episode_count: 213 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.362]
Step 299 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 72.0]  episode_count: 215 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.232]
{"total_number_of_episodes": 217, "number_of_timesteps": 19987, "per_episode_reward": -452.28, "episode_reward_trend_value": -0.20129218777563299, "biggest_recent_change": 6.2389255819496725},
Step 300 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 73.0]  episode_count: 217 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.258]
Step 301 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 74.0]  episode_count: 217 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.133]
Step 302 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 75.0]  episode_count: 218 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.011]
Step 303 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 76.0]  episode_count: 218 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.039]
Step 304 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 77.0]  episode_count: 219 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.065]
Step 305 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 78.0]  episode_count: 221 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.092]
Step 306 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 79.0]  episode_count: 222 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.117]
Step 307 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 80.0]  episode_count: 224 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.142]
Step 308 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 81.0]  episode_count: 224 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.029]
Step 309 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 82.0]  episode_count: 224 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.055]
Step 310 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 83.0]  episode_count: 224 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.079]
Step 311 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 84.0]  episode_count: 225 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.104]
Step 312 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 85.0]  episode_count: 226 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.127]
Step 313 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 86.0]  episode_count: 226 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.15]
Step 314 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 87.0]  episode_count: 226 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.173]
{"total_number_of_episodes": 228, "number_of_timesteps": 20793, "per_episode_reward": -454.44, "episode_reward_trend_value": -0.20179985595447839, "biggest_recent_change": 6.2389255819496725},
Step 315 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 88.0]  episode_count: 228 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.195]
Step 316 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 89.0]  episode_count: 228 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.216]
Step 317 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 90.0]  episode_count: 228 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.238]
Step 318 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 91.0]  episode_count: 229 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.136]
Step 319 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 92.0]  episode_count: 229 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.157]
Step 320 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 93.0]  episode_count: 231 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.059]
Step 321 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 94.0]  episode_count: 231 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.081]
Step 322 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 95.0]  episode_count: 232 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.102]
Step 323 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 96.0]  episode_count: 232 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.123]
Step 324 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 97.0]  episode_count: 232 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.144]
Step 325 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 98.0]  episode_count: 232 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.164]
Step 326 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 99.0]  episode_count: 232 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.183]
Step 327 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 100.0]  episode_count: 232 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.203]
Step 328 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 101.0]  episode_count: 234 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.222]
Step 329 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 102.0]  episode_count: 236 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.24]
Step 330 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 103.0]  episode_count: 236 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.258]
Step 331 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 104.0]  episode_count: 236 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.276]
{"total_number_of_episodes": 238, "number_of_timesteps": 22042, "per_episode_reward": -461.25, "episode_reward_trend_value": -0.2486038184394955, "biggest_recent_change": 6.807925357394538},
Step 332 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 105.0]  episode_count: 238 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.294]
Step 333 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 106.0]  episode_count: 239 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.311]
Step 334 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 107.0]  episode_count: 239 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.328]
Step 335 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 108.0]  episode_count: 239 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.344]
Step 336 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 109.0]  episode_count: 239 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.258]
Step 337 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 110.0]  episode_count: 239 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.275]
Step 338 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 111.0]  episode_count: 239 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.292]
Step 339 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 112.0]  episode_count: 239 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.308]
Step 340 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 113.0]  episode_count: 239 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.324]
Step 341 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 114.0]  episode_count: 242 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.34]
Step 342 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 115.0]  episode_count: 243 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.258]
Step 343 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 116.0]  episode_count: 244 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.274]
Step 344 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 117.0]  episode_count: 246 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.195]
Step 345 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 118.0]  episode_count: 246 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.211]
Step 346 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 119.0]  episode_count: 246 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.227]
Step 347 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 120.0]  episode_count: 247 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.243]
{"total_number_of_episodes": 248, "number_of_timesteps": 23072, "per_episode_reward": -464.7, "episode_reward_trend_value": -0.29069275980600273, "biggest_recent_change": 6.807925357394538},
Step 348 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 121.0]  episode_count: 248 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.167]
Step 349 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 122.0]  episode_count: 248 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.183]
Step 350 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 123.0]  episode_count: 248 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.198]
Step 351 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 124.0]  episode_count: 250 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.124]
Step 352 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 125.0]  episode_count: 250 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.14]
Step 353 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 126.0]  episode_count: 250 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.156]
Step 354 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 127.0]  episode_count: 251 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.083]
Step 355 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 128.0]  episode_count: 252 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.099]
Step 356 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 129.0]  episode_count: 253 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.115]
Step 357 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 130.0]  episode_count: 254 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.13]
Step 358 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 131.0]  episode_count: 254 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.061]
Step 359 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 132.0]  episode_count: 255 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.076]
Step 360 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 133.0]  episode_count: 255 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.091]
Step 361 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 134.0]  episode_count: 255 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.106]
Step 362 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 135.0]  episode_count: 256 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.039]
Step 363 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 136.0]  episode_count: 256 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.054]
{"total_number_of_episodes": 258, "number_of_timesteps": 24132, "per_episode_reward": -463.26, "episode_reward_trend_value": -0.32833766819866433, "biggest_recent_change": 6.807925357394538},
Step 364 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 137.0]  episode_count: 258 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.069]
Step 365 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 138.0]  episode_count: 258 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.004]
Step 366 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 139.0]  episode_count: 259 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.019]
Step 367 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 140.0]  episode_count: 260 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.954]
Step 368 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 141.0]  episode_count: 261 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.97]
Step 369 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 142.0]  episode_count: 262 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.985]
Step 370 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 143.0]  episode_count: 263 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.0]
Step 371 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 144.0]  episode_count: 264 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.937]
Step 372 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 145.0]  episode_count: 265 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.952]
Step 373 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 146.0]  episode_count: 265 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.967]
Step 374 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 147.0]  episode_count: 265 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.981]
Step 375 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 148.0]  episode_count: 266 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.996]
Step 376 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 149.0]  episode_count: 267 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.01]
Step 377 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 150.0]  episode_count: 267 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.024]
Step 378 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 151.0]  episode_count: 267 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.038]
Step 379 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 152.0]  episode_count: 267 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.051]
Step 380 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 153.0]  episode_count: 267 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.065]
Step 381 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 154.0]  episode_count: 267 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.078]
{"total_number_of_episodes": 268, "number_of_timesteps": 25058, "per_episode_reward": -462.96, "episode_reward_trend_value": -0.25567000537413886, "biggest_recent_change": 6.807925357394538},
Step 382 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 155.0]  episode_count: 268 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.091]
Step 383 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 156.0]  episode_count: 268 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.104]
Step 384 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 157.0]  episode_count: 268 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.117]
Step 385 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 158.0]  episode_count: 269 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.059]
Step 386 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 159.0]  episode_count: 271 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.072]
Step 387 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 160.0]  episode_count: 271 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.016]
Step 388 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 161.0]  episode_count: 271 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.029]
Step 389 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 162.0]  episode_count: 272 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.041]
Step 390 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 163.0]  episode_count: 272 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.054]
Step 391 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 164.0]  episode_count: 273 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.067]
Step 392 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 165.0]  episode_count: 274 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.079]
Step 393 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 166.0]  episode_count: 274 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.024]
Step 394 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 167.0]  episode_count: 275 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.037]
Step 395 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 168.0]  episode_count: 276 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.983]
Step 396 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 169.0]  episode_count: 277 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.996]
Step 397 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 170.0]  episode_count: 277 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.008]
Step 398 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 171.0]  episode_count: 277 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.02]
{"total_number_of_episodes": 278, "number_of_timesteps": 26446, "per_episode_reward": -466.44, "episode_reward_trend_value": -0.22603450232601166, "biggest_recent_change": 6.807925357394538},
Step 399 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 172.0]  episode_count: 278 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.033]
Step 400 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 173.0]  episode_count: 278 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.045]
Step 401 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 174.0]  episode_count: 278 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.056]
Step 402 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 175.0]  episode_count: 279 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.068]
Step 403 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 176.0]  episode_count: 280 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.08]
Step 404 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 177.0]  episode_count: 281 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.091]
Step 405 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 178.0]  episode_count: 283 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.103]
Step 406 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 179.0]  episode_count: 284 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.114]
Step 407 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 180.0]  episode_count: 285 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.125]
Step 408 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 181.0]  episode_count: 285 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.075]
Step 409 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 182.0]  episode_count: 285 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.086]
Step 410 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 183.0]  episode_count: 285 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.097]
Step 411 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 184.0]  episode_count: 285 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.047]
Step 412 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 185.0]  episode_count: 285 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.058]
Step 413 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 186.0]  episode_count: 285 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.07]
Step 414 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 187.0]  episode_count: 285 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.08]
Step 415 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 188.0]  episode_count: 285 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.091]
Step 416 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 189.0]  episode_count: 287 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.102]
{"total_number_of_episodes": 288, "number_of_timesteps": 27523, "per_episode_reward": -463.28, "episode_reward_trend_value": -0.1399835784108499, "biggest_recent_change": 6.807925357394538},
Step 417 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 190.0]  episode_count: 288 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.113]
Step 418 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 191.0]  episode_count: 290 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.123]
Step 419 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 192.0]  episode_count: 290 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.133]
Step 420 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 193.0]  episode_count: 291 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.086]
Step 421 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 194.0]  episode_count: 291 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.096]
Step 422 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 195.0]  episode_count: 291 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.05]
Step 423 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 196.0]  episode_count: 291 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.06]
Step 424 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 197.0]  episode_count: 291 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.071]
Step 425 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 198.0]  episode_count: 292 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.025]
Step 426 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 199.0]  episode_count: 293 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.035]
Step 427 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 200.0]  episode_count: 294 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.046]
Step 428 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 201.0]  episode_count: 296 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.056]
Step 429 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 202.0]  episode_count: 296 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.066]
Step 430 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 203.0]  episode_count: 296 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.076]
Step 431 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 204.0]  episode_count: 297 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.086]
Step 432 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 205.0]  episode_count: 297 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.096]
{"total_number_of_episodes": 298, "number_of_timesteps": 28772, "per_episode_reward": -463.01, "episode_reward_trend_value": -0.12588149933139714, "biggest_recent_change": 6.807925357394538},
Step 433 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 206.0]  episode_count: 298 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.052]
Step 434 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 207.0]  episode_count: 299 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.062]
Step 435 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 208.0]  episode_count: 299 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.072]
Step 436 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 209.0]  episode_count: 300 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.028]
Step 437 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 210.0]  episode_count: 301 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.038]
Step 438 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 211.0]  episode_count: 302 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.048]
Step 439 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 212.0]  episode_count: 303 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.058]
Step 440 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 213.0]  episode_count: 304 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.067]
Step 441 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 214.0]  episode_count: 304 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.077]
Step 442 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 215.0]  episode_count: 305 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.087]
Step 443 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 216.0]  episode_count: 305 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.096]
Step 444 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 217.0]  episode_count: 307 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.105]
{"total_number_of_episodes": 309, "number_of_timesteps": 29732, "per_episode_reward": -467.3, "episode_reward_trend_value": -0.16690424600374867, "biggest_recent_change": 6.807925357394538},
Step 445 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 218.0]  episode_count: 309 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.114]
Step 446 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 219.0]  episode_count: 309 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.123]
Step 447 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 220.0]  episode_count: 310 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.133]
Step 448 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 221.0]  episode_count: 310 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.141]
Step 449 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 222.0]  episode_count: 310 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.15]
Step 450 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 223.0]  episode_count: 311 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.109]
Step 451 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 224.0]  episode_count: 311 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.069]
Step 452 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 225.0]  episode_count: 312 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.078]
Step 453 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 226.0]  episode_count: 316 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.087]
Step 454 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 227.0]  episode_count: 316 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.096]
Step 455 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 228.0]  episode_count: 317 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.104]
Step 456 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 229.0]  episode_count: 318 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.113]
Step 457 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 230.0]  episode_count: 318 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.122]
Step 458 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 231.0]  episode_count: 318 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.131]
Step 459 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 232.0]  episode_count: 318 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.139]
{"total_number_of_episodes": 319, "number_of_timesteps": 30529, "per_episode_reward": -470.81, "episode_reward_trend_value": -0.1819470399394883, "biggest_recent_change": 6.807925357394538},
Step 460 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 233.0]  episode_count: 319 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.148]
Step 461 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 234.0]  episode_count: 320 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.156]
Step 462 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 235.0]  episode_count: 322 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.164]
Step 463 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 236.0]  episode_count: 324 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.172]
Step 464 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 237.0]  episode_count: 325 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.134]
Step 465 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 238.0]  episode_count: 325 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.142]
Step 466 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 239.0]  episode_count: 325 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.15]
Step 467 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 240.0]  episode_count: 326 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.159]
Step 468 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 241.0]  episode_count: 327 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.121]
Step 469 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 242.0]  episode_count: 328 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.129]
{"total_number_of_episodes": 329, "number_of_timesteps": 31292, "per_episode_reward": -471.99, "episode_reward_trend_value": -0.1193986649158982, "biggest_recent_change": 4.287452533217618},
Step 470 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 243.0]  episode_count: 329 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.137]
Step 471 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 244.0]  episode_count: 330 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.145]
Step 472 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 245.0]  episode_count: 331 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.153]
Step 473 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 246.0]  episode_count: 332 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.161]
Step 474 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 247.0]  episode_count: 332 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.124]
Step 475 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 248.0]  episode_count: 333 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.132]
Step 476 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 249.0]  episode_count: 334 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.14]
Step 477 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 250.0]  episode_count: 334 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.148]
Step 478 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 251.0]  episode_count: 335 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.156]
Step 479 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 252.0]  episode_count: 336 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.163]
Step 480 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 253.0]  episode_count: 336 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.171]
Step 481 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 254.0]  episode_count: 337 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.179]
{"total_number_of_episodes": 340, "number_of_timesteps": 32209, "per_episode_reward": -473.19, "episode_reward_trend_value": -0.09433684572087739, "biggest_recent_change": 4.287452533217618},
Step 482 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 255.0]  episode_count: 340 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.186]
Step 483 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 256.0]  episode_count: 341 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.194]
Step 484 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 257.0]  episode_count: 341 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.201]
Step 485 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 258.0]  episode_count: 343 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.209]
Step 486 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 259.0]  episode_count: 343 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.216]
Step 487 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 260.0]  episode_count: 343 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.223]
Step 488 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 261.0]  episode_count: 343 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.23]
Step 489 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 262.0]  episode_count: 345 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.195]
Step 490 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 263.0]  episode_count: 347 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.203]
Step 491 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 264.0]  episode_count: 348 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.21]
Step 492 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 265.0]  episode_count: 348 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.175]
{"total_number_of_episodes": 350, "number_of_timesteps": 32930, "per_episode_reward": -475.67, "episode_reward_trend_value": -0.1378905306576169, "biggest_recent_change": 4.287452533217618},
Step 493 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 266.0]  episode_count: 350 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.182]
Step 494 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 267.0]  episode_count: 350 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.19]
Step 495 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 268.0]  episode_count: 350 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.197]
Step 496 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 269.0]  episode_count: 350 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.204]
Step 497 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 270.0]  episode_count: 352 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.211]
Step 498 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 271.0]  episode_count: 352 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.177]
Step 499 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 272.0]  episode_count: 353 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.184]
Step 500 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 273.0]  episode_count: 353 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.191]
Step 501 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 274.0]  episode_count: 354 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.198]
Step 502 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 275.0]  episode_count: 354 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.205]
Step 503 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 276.0]  episode_count: 355 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.212]
Step 504 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 277.0]  episode_count: 356 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.219]
Step 505 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 278.0]  episode_count: 359 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.226]
Step 506 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 279.0]  episode_count: 359 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.232]
Step 507 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 280.0]  episode_count: 359 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.199]
{"total_number_of_episodes": 361, "number_of_timesteps": 33914, "per_episode_reward": -476.01, "episode_reward_trend_value": -0.14502640315367077, "biggest_recent_change": 4.287452533217618},
Step 508 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 281.0]  episode_count: 361 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.206]
Step 509 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 282.0]  episode_count: 361 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.213]
Step 510 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 283.0]  episode_count: 361 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.22]
Step 511 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 284.0]  episode_count: 361 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.226]
Step 512 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 285.0]  episode_count: 362 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.233]
Step 513 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 286.0]  episode_count: 363 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.239]
Step 514 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 287.0]  episode_count: 365 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.246]
Step 515 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 288.0]  episode_count: 365 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.252]
Step 516 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 289.0]  episode_count: 366 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.22]
Step 517 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 290.0]  episode_count: 367 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.227]
Step 518 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 291.0]  episode_count: 368 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.233]
Step 519 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 292.0]  episode_count: 368 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.24]
Step 520 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 293.0]  episode_count: 368 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.246]
Step 521 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 294.0]  episode_count: 369 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.253]
Step 522 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 295.0]  episode_count: 369 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 523 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 296.0]  episode_count: 370 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.265]
{"total_number_of_episodes": 371, "number_of_timesteps": 34800, "per_episode_reward": -475.62, "episode_reward_trend_value": -0.10204354000424967, "biggest_recent_change": 4.287452533217618},
Step 524 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 297.0]  episode_count: 371 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.271]
Step 525 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 298.0]  episode_count: 371 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.278]
Step 526 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 299.0]  episode_count: 373 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.284]
Step 527 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 300.0]  episode_count: 374 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.253]
Step 528 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 301.0]  episode_count: 375 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 529 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 302.0]  episode_count: 376 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.228]
Step 530 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 303.0]  episode_count: 378 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.234]
Step 531 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 304.0]  episode_count: 378 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.241]
Step 532 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 305.0]  episode_count: 378 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.247]
Step 533 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 306.0]  episode_count: 379 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.217]
Step 534 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 307.0]  episode_count: 379 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.223]
{"total_number_of_episodes": 382, "number_of_timesteps": 35700, "per_episode_reward": -474.88, "episode_reward_trend_value": -0.1288839507299258, "biggest_recent_change": 4.287452533217618},
Step 535 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 308.0]  episode_count: 382 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.229]
Step 536 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 309.0]  episode_count: 382 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.235]
Step 537 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 310.0]  episode_count: 383 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.241]
Step 538 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 311.0]  episode_count: 384 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.211]
Step 539 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 312.0]  episode_count: 385 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.217]
Step 540 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 313.0]  episode_count: 385 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.188]
Step 541 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 314.0]  episode_count: 386 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.194]
Step 542 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 315.0]  episode_count: 386 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.2]
Step 543 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 316.0]  episode_count: 387 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.206]
Step 544 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 317.0]  episode_count: 388 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.212]
Step 545 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 318.0]  episode_count: 389 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.183]
Step 546 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 319.0]  episode_count: 390 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.189]
{"total_number_of_episodes": 393, "number_of_timesteps": 36566, "per_episode_reward": -475.48, "episode_reward_trend_value": -0.1385200584072082, "biggest_recent_change": 4.287452533217618},
Step 547 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 320.0]  episode_count: 393 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.195]
Step 548 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 321.0]  episode_count: 393 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.167]
Step 549 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 322.0]  episode_count: 393 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.173]
Step 550 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 323.0]  episode_count: 395 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.179]
Step 551 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 324.0]  episode_count: 395 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.185]
[-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.191]
Step 553 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 326.0]  episode_count: 397 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.162]
Step 554 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 327.0]  episode_count: 397 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.134]
Step 555 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 328.0]  episode_count: 398 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.106]
Step 556 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 329.0]  episode_count: 400 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.113]
Step 557 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 330.0]  episode_count: 401 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.119]
Step 558 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 331.0]  episode_count: 401 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.125]
Step 559 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 332.0]  episode_count: 402 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.131]
{"total_number_of_episodes": 403, "number_of_timesteps": 37299, "per_episode_reward": -480.71, "episode_reward_trend_value": -0.14900001803542234, "biggest_recent_change": 5.230648899756886},
Step 560 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 333.0]  episode_count: 403 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.137]
Step 561 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 334.0]  episode_count: 403 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.109]
Step 562 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 335.0]  episode_count: 403 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.115]
Step 563 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 336.0]  episode_count: 404 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.088]
Step 564 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 337.0]  episode_count: 407 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.094]
Step 565 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 338.0]  episode_count: 407 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.067]
Step 566 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 339.0]  episode_count: 409 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.073]
Step 567 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 340.0]  episode_count: 409 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.047]
Step 568 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 341.0]  episode_count: 409 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.053]
Step 569 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 342.0]  episode_count: 410 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.05]
Step 570 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 343.0]  episode_count: 410 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.056]
Step 571 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 344.0]  episode_count: 411 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.062]
Step 572 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 345.0]  episode_count: 412 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.068]
{"total_number_of_episodes": 413, "number_of_timesteps": 38064, "per_episode_reward": -483.96, "episode_reward_trend_value": -0.1461051511155549, "biggest_recent_change": 5.230648899756886},
Step 573 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 346.0]  episode_count: 413 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.074]
Step 574 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 347.0]  episode_count: 414 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.08]
Step 575 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 348.0]  episode_count: 414 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.086]
Step 576 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 349.0]  episode_count: 416 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.06]
Step 577 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 350.0]  episode_count: 416 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.066]
Step 578 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 351.0]  episode_count: 417 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.072]
Step 579 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 352.0]  episode_count: 417 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.077]
Step 580 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 353.0]  episode_count: 417 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.083]
Step 581 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 354.0]  episode_count: 419 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.089]
Step 582 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 355.0]  episode_count: 419 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.063]
Step 583 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 356.0]  episode_count: 420 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.069]
Step 584 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 357.0]  episode_count: 420 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.075]
Step 585 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 358.0]  episode_count: 422 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.08]
{"total_number_of_episodes": 423, "number_of_timesteps": 39017, "per_episode_reward": -485.38, "episode_reward_trend_value": -0.14873821175062732, "biggest_recent_change": 5.230648899756886},
Step 586 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 359.0]  episode_count: 423 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.086]
Step 587 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 360.0]  episode_count: 423 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.092]
Step 588 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 361.0]  episode_count: 423 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.067]
Step 589 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 362.0]  episode_count: 425 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.072]
visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 363.0]  episode_count: 425 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.078]
Step 591 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 364.0]  episode_count: 425 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.083]
Step 592 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 365.0]  episode_count: 426 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.059]
Step 593 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 366.0]  episode_count: 427 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.034]
Step 594 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 367.0]  episode_count: 427 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.039]
Step 595 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 368.0]  episode_count: 429 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.045]
Step 596 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 369.0]  episode_count: 431 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.051]
Step 597 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 370.0]  episode_count: 431 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.056]
Step 598 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 371.0]  episode_count: 432 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.062]
Step 599 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 372.0]  episode_count: 432 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.067]
Step 600 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 373.0]  episode_count: 432 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.073]
Step 601 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 374.0]  episode_count: 432 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.078]
Step 602 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 375.0]  episode_count: 432 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.084]
Step 603 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 376.0]  episode_count: 432 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.089]
Step 604 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 377.0]  episode_count: 432 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.065]
{"total_number_of_episodes": 433, "number_of_timesteps": 39958, "per_episode_reward": -482.89, "episode_reward_trend_value": -0.10775064431763011, "biggest_recent_change": 5.230648899756886},
Step 605 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 378.0]  episode_count: 433 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.041]
Step 606 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 379.0]  episode_count: 435 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.046]
Step 607 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 380.0]  episode_count: 436 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.052]
Step 608 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 381.0]  episode_count: 438 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.057]
Step 609 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 382.0]  episode_count: 438 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.063]
Step 610 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 383.0]  episode_count: 438 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.068]
Step 611 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 384.0]  episode_count: 438 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.073]
Step 612 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 385.0]  episode_count: 438 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.079]
Step 613 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 386.0]  episode_count: 439 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.084]
Step 614 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 387.0]  episode_count: 439 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.06]
Step 615 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 388.0]  episode_count: 440 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.066]
Step 616 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 389.0]  episode_count: 441 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.071]
{"total_number_of_episodes": 443, "number_of_timesteps": 41047, "per_episode_reward": -483.67, "episode_reward_trend_value": -0.08885829506107952, "biggest_recent_change": 5.230648899756886},
Step 617 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 390.0]  episode_count: 443 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.048]
Step 618 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 391.0]  episode_count: 443 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.053]
Step 619 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 392.0]  episode_count: 443 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.058]
Step 620 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 393.0]  episode_count: 444 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.063]
Step 621 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 394.0]  episode_count: 444 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.04]
Step 622 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 395.0]  episode_count: 444 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.046]
Step 623 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 396.0]  episode_count: 445 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.051]
Step 624 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 397.0]  episode_count: 445 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.056]
Step 625 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 398.0]  episode_count: 447 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.033]
Step 626 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 399.0]  episode_count: 447 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.028]
Step 627 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 400.0]  episode_count: 447 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.033]
Step 628 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 401.0]  episode_count: 447 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.011]
Step 629 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 402.0]  episode_count: 448 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.016]
Step 630 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 403.0]  episode_count: 450 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.021]
Step 631 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 404.0]  episode_count: 450 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.026]
Step 632 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 405.0]  episode_count: 452 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.031]
{"total_number_of_episodes": 453, "number_of_timesteps": 42222, "per_episode_reward": -484.06, "episode_reward_trend_value": -0.08937101516844323, "biggest_recent_change": 5.230648899756886},
Step 633 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 406.0]  episode_count: 453 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.037]
Step 634 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 407.0]  episode_count: 453 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.042]
Step 635 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 408.0]  episode_count: 453 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.047]
Step 636 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 409.0]  episode_count: 453 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.052]
Step 637 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 410.0]  episode_count: 453 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.057]
Step 638 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 411.0]  episode_count: 453 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.062]
Step 639 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 412.0]  episode_count: 454 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.067]
Step 640 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 413.0]  episode_count: 455 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.045]
Step 641 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 414.0]  episode_count: 457 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.05]
Step 642 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 415.0]  episode_count: 458 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.055]
Step 643 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 416.0]  episode_count: 459 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.06]
Step 644 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 417.0]  episode_count: 459 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.065]
Step 645 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 418.0]  episode_count: 460 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.07]
Step 646 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 419.0]  episode_count: 460 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.074]
Step 647 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 420.0]  episode_count: 460 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.053]
Step 648 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 421.0]  episode_count: 460 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.031]
{"total_number_of_episodes": 463, "number_of_timesteps": 43191, "per_episode_reward": -480.5, "episode_reward_trend_value": -0.05419599904836585, "biggest_recent_change": 5.230648899756886},
Step 649 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 422.0]  episode_count: 463 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.036]
Step 650 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 423.0]  episode_count: 463 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.041]
Step 651 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 424.0]  episode_count: 464 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.046]
Step 652 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 425.0]  episode_count: 466 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.051]
Step 653 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 426.0]  episode_count: 466 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.056]
Step 654 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 427.0]  episode_count: 466 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.061]
Step 655 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 428.0]  episode_count: 467 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.065]
Step 656 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 429.0]  episode_count: 467 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.07]
Step 657 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 430.0]  episode_count: 468 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.075]
Step 658 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 431.0]  episode_count: 468 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.08]
Step 659 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 432.0]  episode_count: 468 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.084]
Step 660 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 433.0]  episode_count: 469 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.089]
Step 661 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 434.0]  episode_count: 471 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.094]
Step 662 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 435.0]  episode_count: 472 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.073]
Step 663 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 436.0]  episode_count: 472 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.077]
Step 664 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 437.0]  episode_count: 472 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.057]
{"total_number_of_episodes": 473, "number_of_timesteps": 44228, "per_episode_reward": -480.89, "episode_reward_trend_value": -0.06674173448863661, "biggest_recent_change": 5.230648899756886},
Step 665 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 438.0]  episode_count: 473 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.061]
Step 666 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 439.0]  episode_count: 474 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.066]
Step 667 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 440.0]  episode_count: 474 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.071]
Step 668 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 441.0]  episode_count: 474 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.075]
Step 669 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 442.0]  episode_count: 474 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.08]
Step 670 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 443.0]  episode_count: 475 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.059]
Step 671 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 444.0]  episode_count: 476 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.064]
Step 672 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 445.0]  episode_count: 478 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.069]
Step 673 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 446.0]  episode_count: 478 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.048]
Step 674 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 447.0]  episode_count: 478 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.028]
Step 675 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 448.0]  episode_count: 478 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.008]
Step 676 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 449.0]  episode_count: 480 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.013]
Step 677 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 450.0]  episode_count: 480 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.993]
Step 678 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 451.0]  episode_count: 480 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.997]
Step 679 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 452.0]  episode_count: 480 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.977]
Step 680 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 453.0]  episode_count: 481 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.982]
Step 681 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 454.0]  episode_count: 481 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.962]
Step 682 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 455.0]  episode_count: 482 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.967]
Step 683 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 456.0]  episode_count: 482 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.947]
{"total_number_of_episodes": 484, "number_of_timesteps": 45300, "per_episode_reward": -480.98, "episode_reward_trend_value": -0.06115279559114824, "biggest_recent_change": 5.230648899756886},
Step 684 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 457.0]  episode_count: 484 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.952]
Step 685 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 458.0]  episode_count: 486 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.957]
Step 686 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 459.0]  episode_count: 486 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.937]
Step 687 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 460.0]  episode_count: 486 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.918]
Step 688 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 461.0]  episode_count: 486 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.923]
Step 689 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 462.0]  episode_count: 488 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.927]
Step 690 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 463.0]  episode_count: 488 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.932]
Step 691 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 464.0]  episode_count: 489 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.937]
Step 692 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 465.0]  episode_count: 489 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.941]
Step 693 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 466.0]  episode_count: 490 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.946]
Step 694 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 467.0]  episode_count: 491 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.951]
Step 695 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 468.0]  episode_count: 491 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.955]
Step 696 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 469.0]  episode_count: 492 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.96]
Step 697 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 470.0]  episode_count: 493 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.941]
{"total_number_of_episodes": 494, "number_of_timesteps": 46519, "per_episode_reward": -478.56, "episode_reward_trend_value": 0.023885639702412063, "biggest_recent_change": 3.5592166664791307},
Step 698 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 471.0]  episode_count: 494 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.945]
Step 699 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 472.0]  episode_count: 495 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.95]
Step 700 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 473.0]  episode_count: 495 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.955]
Step 701 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 474.0]  episode_count: 495 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.959]
Step 702 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 475.0]  episode_count: 497 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.94]
Step 703 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 476.0]  episode_count: 497 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.945]
Step 704 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 477.0]  episode_count: 498 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.949]
Step 705 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 478.0]  episode_count: 498 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.954]
Step 706 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 479.0]  episode_count: 499 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.935]
Step 707 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 480.0]  episode_count: 499 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.94]
Step 708 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 481.0]  episode_count: 501 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.944]
Step 709 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 482.0]  episode_count: 501 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.949]
Step 710 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 483.0]  episode_count: 502 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.953]
Step 711 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 484.0]  episode_count: 502 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.958]
Step 712 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 485.0]  episode_count: 503 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.962]
Step 713 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 486.0]  episode_count: 503 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.944]
{"total_number_of_episodes": 504, "number_of_timesteps": 47523, "per_episode_reward": -476.37, "episode_reward_trend_value": 0.08440294575468607, "biggest_recent_change": 3.5592166664791307},
Step 714 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 487.0]  episode_count: 504 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.948]
Step 715 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 488.0]  episode_count: 504 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.953]
Step 716 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 489.0]  episode_count: 506 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.957]
Step 717 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 490.0]  episode_count: 507 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.961]
Step 718 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 491.0]  episode_count: 507 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.966]
Step 719 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 492.0]  episode_count: 507 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.97]
Step 720 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 493.0]  episode_count: 508 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.974]
Step 721 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 494.0]  episode_count: 508 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.979]
Step 722 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 495.0]  episode_count: 508 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.983]
Step 723 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 496.0]  episode_count: 510 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.987]
Step 724 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 497.0]  episode_count: 511 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.992]
Step 725 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 498.0]  episode_count: 511 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.996]
Step 726 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 499.0]  episode_count: 512 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.978]
Step 727 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 500.0]  episode_count: 512 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.982]
Step 728 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 501.0]  episode_count: 513 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.986]
{"total_number_of_episodes": 514, "number_of_timesteps": 48579, "per_episode_reward": -473.96, "episode_reward_trend_value": 0.12688753147849827, "biggest_recent_change": 3.5592166664791307},
Step 729 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 502.0]  episode_count: 514 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.991]
Step 730 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 503.0]  episode_count: 514 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.995]
Step 731 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 504.0]  episode_count: 517 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.999]
Step 732 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 505.0]  episode_count: 518 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.003]
Step 733 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 506.0]  episode_count: 518 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.985]
Step 734 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 507.0]  episode_count: 519 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.99]
Step 735 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 508.0]  episode_count: 519 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.972]
Step 736 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 509.0]  episode_count: 520 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.976]
Step 737 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 510.0]  episode_count: 520 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.98]
Step 738 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 511.0]  episode_count: 521 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.985]
Step 739 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 512.0]  episode_count: 523 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.989]
{"total_number_of_episodes": 525, "number_of_timesteps": 49448, "per_episode_reward": -474.31, "episode_reward_trend_value": 0.09531728586037438, "biggest_recent_change": 3.5592166664791307},
Step 740 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 513.0]  episode_count: 525 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.993]
Step 741 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 514.0]  episode_count: 526 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.997]
Step 742 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 515.0]  episode_count: 526 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.001]
Step 743 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 516.0]  episode_count: 526 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.005]
Step 744 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 517.0]  episode_count: 526 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.009]
Step 745 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 518.0]  episode_count: 527 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.013]
Step 746 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 519.0]  episode_count: 528 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -8.996]
Step 747 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 520.0]  episode_count: 529 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.0]
Step 748 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 521.0]  episode_count: 530 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.004]
Step 749 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 522.0]  episode_count: 531 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.008]
Step 750 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 523.0]  episode_count: 531 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.012]
Step 751 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 524.0]  episode_count: 531 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.016]
Step 752 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 525.0]  episode_count: 532 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.02]
Step 753 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 526.0]  episode_count: 534 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.024]
Step 754 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 527.0]  episode_count: 534 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.028]
{"total_number_of_episodes": 535, "number_of_timesteps": 50308, "per_episode_reward": -476.92, "episode_reward_trend_value": 0.07496803557279463, "biggest_recent_change": 3.5592166664791307},
Step 755 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 528.0]  episode_count: 535 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.032]
Step 756 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 529.0]  episode_count: 535 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.036]
Step 757 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 530.0]  episode_count: 535 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.019]
Step 758 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 531.0]  episode_count: 535 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.023]
Step 759 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 532.0]  episode_count: 536 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.027]
Step 760 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 533.0]  episode_count: 537 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.031]
Step 761 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 534.0]  episode_count: 537 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.034]
Step 762 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 535.0]  episode_count: 538 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.038]
Step 763 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 536.0]  episode_count: 538 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.042]
Step 764 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 537.0]  episode_count: 539 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.025]
Step 765 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 538.0]  episode_count: 539 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.029]
Step 766 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 539.0]  episode_count: 540 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.033]
Step 767 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 540.0]  episode_count: 540 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.037]
Step 768 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 541.0]  episode_count: 540 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.02]
Step 769 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 542.0]  episode_count: 541 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.024]
Step 770 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 543.0]  episode_count: 541 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.028]
Step 771 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 544.0]  episode_count: 541 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.032]
Step 772 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 545.0]  episode_count: 543 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.036]
Step 773 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 546.0]  episode_count: 544 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.039]
{"total_number_of_episodes": 545, "number_of_timesteps": 51584, "per_episode_reward": -471.28, "episode_reward_trend_value": 0.14200050826193988, "biggest_recent_change": 5.6457132799731085},
Step 774 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 547.0]  episode_count: 545 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.023]
Step 775 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 548.0]  episode_count: 545 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.027]
Step 776 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 549.0]  episode_count: 545 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.031]
Step 777 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 550.0]  episode_count: 547 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.034]
Step 778 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 551.0]  episode_count: 548 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.038]
Step 779 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 552.0]  episode_count: 548 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.022]
Step 780 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 553.0]  episode_count: 548 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.025]
Step 781 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 554.0]  episode_count: 550 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.029]
Step 782 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 555.0]  episode_count: 551 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.033]
Step 783 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 556.0]  episode_count: 552 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.037]
Step 784 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 557.0]  episode_count: 553 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.04]
{"total_number_of_episodes": 555, "number_of_timesteps": 52485, "per_episode_reward": -469.28, "episode_reward_trend_value": 0.12466108628556058, "biggest_recent_change": 5.6457132799731085},
Step 785 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 558.0]  episode_count: 555 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.044]
Step 786 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 559.0]  episode_count: 555 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.048]
Step 787 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 560.0]  episode_count: 555 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.052]
Step 788 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 561.0]  episode_count: 555 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.055]
Step 789 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 562.0]  episode_count: 555 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.059]
Step 790 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 563.0]  episode_count: 556 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.063]
Step 791 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 564.0]  episode_count: 557 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.046]
Step 792 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 565.0]  episode_count: 557 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.05]
Step 793 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 566.0]  episode_count: 557 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.054]
Step 794 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 567.0]  episode_count: 557 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.057]
Step 795 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 568.0]  episode_count: 558 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.041]
Step 796 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 569.0]  episode_count: 559 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.045]
Step 797 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 570.0]  episode_count: 559 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.049]
Step 798 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 571.0]  episode_count: 561 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.052]
Step 799 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 572.0]  episode_count: 561 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.056]
Step 800 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 573.0]  episode_count: 562 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.059]
Step 801 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 574.0]  episode_count: 562 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.063]
Step 802 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 575.0]  episode_count: 564 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.067]
{"total_number_of_episodes": 566, "number_of_timesteps": 53686, "per_episode_reward": -466.75, "episode_reward_trend_value": 0.15706521603431914, "biggest_recent_change": 5.6457132799731085},
Step 803 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 576.0]  episode_count: 566 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.07]
Step 804 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 577.0]  episode_count: 566 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.074]
Step 805 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 578.0]  episode_count: 566 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.058]
Step 806 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 579.0]  episode_count: 566 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.062]
Step 807 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 580.0]  episode_count: 567 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.065]
Step 808 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 581.0]  episode_count: 568 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.069]
Step 809 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 582.0]  episode_count: 568 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.072]
Step 810 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 583.0]  episode_count: 571 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.076]
Step 811 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 584.0]  episode_count: 571 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.079]
Step 812 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 585.0]  episode_count: 571 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.083]
Step 813 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 586.0]  episode_count: 572 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.086]
Step 814 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 587.0]  episode_count: 572 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.089]
Step 815 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 588.0]  episode_count: 572 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.074]
Step 816 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 589.0]  episode_count: 574 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.077]
Step 817 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 590.0]  episode_count: 575 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.081]
Step 818 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 591.0]  episode_count: 575 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.084]
{"total_number_of_episodes": 577, "number_of_timesteps": 54683, "per_episode_reward": -469.52, "episode_reward_trend_value": 0.12732136517644851, "biggest_recent_change": 5.6457132799731085},
Step 819 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 592.0]  episode_count: 577 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.088]
Step 820 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 593.0]  episode_count: 578 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.091]
Step 821 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 594.0]  episode_count: 578 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.095]
q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.098]
Step 823 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 596.0]  episode_count: 578 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.101]
Step 824 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 597.0]  episode_count: 580 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.105]
Step 825 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 598.0]  episode_count: 581 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.09]
Step 826 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 599.0]  episode_count: 581 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.093]
Step 827 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 600.0]  episode_count: 582 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.096]
Step 828 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 601.0]  episode_count: 582 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.081]
Step 829 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 602.0]  episode_count: 582 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.084]
Step 830 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 603.0]  episode_count: 582 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.088]
Step 831 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 604.0]  episode_count: 582 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.091]
Step 832 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 605.0]  episode_count: 582 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.095]
Step 833 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 606.0]  episode_count: 583 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.098]
Step 834 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 607.0]  episode_count: 584 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.101]
Step 835 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 608.0]  episode_count: 586 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.104]
{"total_number_of_episodes": 587, "number_of_timesteps": 55751, "per_episode_reward": -474.32, "episode_reward_trend_value": 0.047091164362752305, "biggest_recent_change": 5.6457132799731085},
Step 836 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 609.0]  episode_count: 587 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.108]
Step 837 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 610.0]  episode_count: 588 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.111]
Step 838 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 611.0]  episode_count: 589 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.114]
Step 839 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 612.0]  episode_count: 589 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.118]
Step 840 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 613.0]  episode_count: 589 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.121]
Step 841 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 614.0]  episode_count: 591 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.124]
Step 842 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 615.0]  episode_count: 592 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.127]
Step 843 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 616.0]  episode_count: 594 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.113]
Step 844 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 617.0]  episode_count: 594 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.116]
Step 845 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 618.0]  episode_count: 595 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.119]
Step 846 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 619.0]  episode_count: 595 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.122]
Step 847 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 620.0]  episode_count: 596 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.125]
{"total_number_of_episodes": 598, "number_of_timesteps": 56644, "per_episode_reward": -470.93, "episode_reward_trend_value": 0.06046519397748903, "biggest_recent_change": 5.6457132799731085},
Step 848 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 621.0]  episode_count: 598 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.129]
Step 849 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 622.0]  episode_count: 598 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.132]
Step 850 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 623.0]  episode_count: 599 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.135]
Step 851 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 624.0]  episode_count: 600 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.138]
Step 852 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 625.0]  episode_count: 600 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.141]
Step 853 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 626.0]  episode_count: 602 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.144]
Step 854 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 627.0]  episode_count: 604 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.148]
Step 855 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 628.0]  episode_count: 604 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.133]
Step 856 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 629.0]  episode_count: 605 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.118]
Step 857 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 630.0]  episode_count: 605 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.122]
Step 858 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 631.0]  episode_count: 605 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.107]
{"total_number_of_episodes": 608, "number_of_timesteps": 57402, "per_episode_reward": -469.44, "episode_reward_trend_value": 0.05019838729454844, "biggest_recent_change": 5.6457132799731085},
Step 859 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 632.0]  episode_count: 608 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.11]
Step 860 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 633.0]  episode_count: 609 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.114]
Step 861 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 634.0]  episode_count: 609 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.117]
Step 862 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 635.0]  episode_count: 610 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.12]
Step 863 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 636.0]  episode_count: 611 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.123]
Step 864 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 637.0]  episode_count: 612 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.126]
Step 865 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 638.0]  episode_count: 612 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.129]
Step 866 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 639.0]  episode_count: 613 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.132]
Step 867 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 640.0]  episode_count: 616 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.135]
Step 868 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 641.0]  episode_count: 616 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.138]
Step 869 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 642.0]  episode_count: 617 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.142]
Step 870 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 643.0]  episode_count: 617 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.145]
{"total_number_of_episodes": 619, "number_of_timesteps": 58213, "per_episode_reward": -475.9, "episode_reward_trend_value": -0.017605258146013134, "biggest_recent_change": 6.453280072214},
Step 871 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 644.0]  episode_count: 619 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.148]
Step 872 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 645.0]  episode_count: 619 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.151]
Step 873 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 646.0]  episode_count: 620 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.137]
Step 874 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 647.0]  episode_count: 621 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.122]
Step 875 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 648.0]  episode_count: 622 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.108]
Step 876 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 649.0]  episode_count: 623 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.111]
Step 877 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 650.0]  episode_count: 624 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.114]
Step 878 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 651.0]  episode_count: 625 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.118]
Step 879 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 652.0]  episode_count: 625 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.121]
Step 880 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 653.0]  episode_count: 625 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.124]
Step 881 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 654.0]  episode_count: 625 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.127]
Step 882 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 655.0]  episode_count: 627 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.13]
Step 883 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 656.0]  episode_count: 628 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.133]
{"total_number_of_episodes": 629, "number_of_timesteps": 59001, "per_episode_reward": -476.07, "episode_reward_trend_value": 0.009475110812529566, "biggest_recent_change": 6.453280072214},
Step 884 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 657.0]  episode_count: 629 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.136]
Step 885 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 658.0]  episode_count: 630 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.139]
Step 886 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 659.0]  episode_count: 631 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.142]
Step 887 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 660.0]  episode_count: 631 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.145]
Step 888 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 661.0]  episode_count: 631 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.148]
Step 889 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 662.0]  episode_count: 632 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.151]
Step 890 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 663.0]  episode_count: 632 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.154]
Step 891 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 664.0]  episode_count: 632 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.157]
Step 892 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 665.0]  episode_count: 635 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.16]
Step 893 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 666.0]  episode_count: 636 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.162]
Step 894 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 667.0]  episode_count: 637 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.165]
Step 895 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 668.0]  episode_count: 637 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.168]
Step 896 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 669.0]  episode_count: 637 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.171]
Step 897 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 670.0]  episode_count: 637 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.174]
Step 898 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 671.0]  episode_count: 637 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.177]
Step 899 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 672.0]  episode_count: 637 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.18]
Step 900 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 673.0]  episode_count: 638 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.183]
{"total_number_of_episodes": 639, "number_of_timesteps": 59951, "per_episode_reward": -480.23, "episode_reward_trend_value": -0.0994482173750037, "biggest_recent_change": 6.453280072214},
Step 901 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 674.0]  episode_count: 639 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.169]
Step 902 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 675.0]  episode_count: 641 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.172]
Step 903 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 676.0]  episode_count: 641 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.175]
Step 904 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 677.0]  episode_count: 641 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.178]
Step 905 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 678.0]  episode_count: 642 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.181]
Step 906 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 679.0]  episode_count: 644 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.183]
Step 907 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 680.0]  episode_count: 645 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.186]
Step 908 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 681.0]  episode_count: 645 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.173]
Step 909 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 682.0]  episode_count: 646 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.176]
Step 910 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 683.0]  episode_count: 646 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.178]
Step 911 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 684.0]  episode_count: 646 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.181]
Step 912 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 685.0]  episode_count: 646 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.184]
Step 913 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 686.0]  episode_count: 647 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.187]
{"total_number_of_episodes": 649, "number_of_timesteps": 60991, "per_episode_reward": -481.98, "episode_reward_trend_value": -0.14109080753737796, "biggest_recent_change": 6.453280072214},
Step 914 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 687.0]  episode_count: 649 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.19]
Step 915 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 688.0]  episode_count: 649 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.192]
Step 916 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 689.0]  episode_count: 650 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.195]
Step 917 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 690.0]  episode_count: 650 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.198]
Step 918 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 691.0]  episode_count: 651 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.201]
Step 919 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 692.0]  episode_count: 652 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.204]
Step 920 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 693.0]  episode_count: 652 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.206]
Step 921 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 694.0]  episode_count: 653 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.209]
Step 922 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 695.0]  episode_count: 653 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.212]
Step 923 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 696.0]  episode_count: 654 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.215]
Step 924 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 697.0]  episode_count: 654 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.201]
Step 925 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 698.0]  episode_count: 654 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.188]
Step 926 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 699.0]  episode_count: 655 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.191]
Step 927 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 700.0]  episode_count: 658 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.194]
Step 928 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 701.0]  episode_count: 658 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.18]
Step 929 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 702.0]  episode_count: 658 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.183]
Step 930 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 703.0]  episode_count: 658 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.186]
Step 931 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 704.0]  episode_count: 658 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.189]
Step 932 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 705.0]  episode_count: 658 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.191]
Step 933 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 706.0]  episode_count: 658 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.178]
Step 934 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 707.0]  episode_count: 658 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.165]
{"total_number_of_episodes": 659, "number_of_timesteps": 62029, "per_episode_reward": -485.86, "episode_reward_trend_value": -0.2123327883026453, "biggest_recent_change": 6.453280072214},
Step 935 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 708.0]  episode_count: 659 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.168]
Step 936 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 709.0]  episode_count: 660 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.171]
Step 937 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 710.0]  episode_count: 661 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.174]
Step 938 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 711.0]  episode_count: 663 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.176]
Step 939 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 712.0]  episode_count: 664 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.164]
Step 940 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 713.0]  episode_count: 665 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.166]
Step 941 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 714.0]  episode_count: 665 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.169]
Step 942 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 715.0]  episode_count: 665 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.172]
Step 943 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 716.0]  episode_count: 666 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.174]
Step 944 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 717.0]  episode_count: 666 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.177]
Step 945 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 718.0]  episode_count: 667 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.18]
Step 946 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 719.0]  episode_count: 668 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.182]
{"total_number_of_episodes": 670, "number_of_timesteps": 63267, "per_episode_reward": -487.55, "episode_reward_trend_value": -0.2003119771213619, "biggest_recent_change": 6.453280072214},
Step 947 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 720.0]  episode_count: 670 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.185]
Step 948 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 721.0]  episode_count: 671 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.187]
Step 949 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 722.0]  episode_count: 672 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.174]
Step 950 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 723.0]  episode_count: 672 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.177]
Step 951 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 724.0]  episode_count: 672 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.179]
Step 952 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 725.0]  episode_count: 674 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.182]
Step 953 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 726.0]  episode_count: 674 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.185]
Step 954 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 727.0]  episode_count: 674 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.172]
Step 955 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 728.0]  episode_count: 675 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.159]
Step 956 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 729.0]  episode_count: 675 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.162]
Step 957 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 730.0]  episode_count: 676 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.165]
Step 958 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 731.0]  episode_count: 677 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.167]
Step 959 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 732.0]  episode_count: 678 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.17]
Step 960 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 733.0]  episode_count: 678 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.173]
Step 961 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 734.0]  episode_count: 678 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.175]
Step 962 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 735.0]  episode_count: 679 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.178]
Step 963 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 736.0]  episode_count: 679 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.181]
Step 964 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 737.0]  episode_count: 679 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.183]
Step 965 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 738.0]  episode_count: 679 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.186]
Step 966 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 739.0]  episode_count: 679 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.188]
{"total_number_of_episodes": 681, "number_of_timesteps": 64283, "per_episode_reward": -488.01, "episode_reward_trend_value": -0.15214422808783626, "biggest_recent_change": 6.453280072214},
Step 967 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 740.0]  episode_count: 681 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.191]
Step 968 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 741.0]  episode_count: 682 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.179]
Step 969 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 742.0]  episode_count: 683 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.166]
Step 970 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 743.0]  episode_count: 683 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.169]
Step 971 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 744.0]  episode_count: 684 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.171]
Step 972 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 745.0]  episode_count: 685 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.159]
Step 973 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 746.0]  episode_count: 685 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.162]
Step 974 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 747.0]  episode_count: 685 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.164]
Step 975 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 748.0]  episode_count: 686 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.167]
Step 976 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 749.0]  episode_count: 686 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.17]
Step 977 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 750.0]  episode_count: 687 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.172]
Step 978 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 751.0]  episode_count: 688 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.175]
Step 979 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 752.0]  episode_count: 688 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.177]
Step 980 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 753.0]  episode_count: 688 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.18]
Step 981 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 754.0]  episode_count: 689 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.182]
Step 982 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 755.0]  episode_count: 689 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.185]
{"total_number_of_episodes": 691, "number_of_timesteps": 65585, "per_episode_reward": -486.85, "episode_reward_trend_value": -0.17697954003400457, "biggest_recent_change": 6.453280072214},
Step 983 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 756.0]  episode_count: 691 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.173]
Step 984 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 757.0]  episode_count: 691 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.175]
Step 985 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 758.0]  episode_count: 691 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.178]
Step 986 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 759.0]  episode_count: 692 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.181]
Step 987 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 760.0]  episode_count: 692 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.183]
Step 988 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 761.0]  episode_count: 693 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.171]
Step 989 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 762.0]  episode_count: 693 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.159]
Step 990 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 763.0]  episode_count: 694 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.162]
Step 991 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 764.0]  episode_count: 695 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.164]
Step 992 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 765.0]  episode_count: 695 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.167]
Step 993 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 766.0]  episode_count: 696 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.169]
Step 994 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 767.0]  episode_count: 696 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.172]
Step 995 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 768.0]  episode_count: 697 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.174]
Step 996 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 769.0]  episode_count: 699 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.177]
Step 997 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 770.0]  episode_count: 699 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.179]
Step 998 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 771.0]  episode_count: 699 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.167]
Step 999 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 772.0]  episode_count: 699 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.17]
Step 1000 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 773.0]  episode_count: 699 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.172]
Step 1001 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 774.0]  episode_count: 699 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.175]
Step 1002 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 775.0]  episode_count: 699 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.177]
{"total_number_of_episodes": 701, "number_of_timesteps": 66804, "per_episode_reward": -486.16, "episode_reward_trend_value": -0.1858093206417632, "biggest_recent_change": 6.453280072214},
Step 1003 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 776.0]  episode_count: 701 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.166]
Step 1004 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 777.0]  episode_count: 703 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.168]
Step 1005 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 778.0]  episode_count: 703 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.171]
Step 1006 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 779.0]  episode_count: 704 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.173]
Step 1007 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 780.0]  episode_count: 706 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.176]
Step 1008 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 781.0]  episode_count: 706 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.178]
Step 1009 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 782.0]  episode_count: 706 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.18]
Step 1010 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 783.0]  episode_count: 706 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.183]
Step 1011 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 784.0]  episode_count: 707 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.185]
Step 1012 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 785.0]  episode_count: 708 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.188]
Step 1013 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 786.0]  episode_count: 708 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.19]
Step 1014 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 787.0]  episode_count: 709 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.193]
Step 1015 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 788.0]  episode_count: 710 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.195]
{"total_number_of_episodes": 712, "number_of_timesteps": 67925, "per_episode_reward": -483.27, "episode_reward_trend_value": -0.08189842737418884, "biggest_recent_change": 4.157386256904886},
Step 1016 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 789.0]  episode_count: 712 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.198]
Step 1017 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 790.0]  episode_count: 712 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.2]
Step 1018 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 791.0]  episode_count: 713 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.202]
Step 1019 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 792.0]  episode_count: 713 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.205]
Step 1020 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 793.0]  episode_count: 715 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.207]
Step 1021 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 794.0]  episode_count: 715 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.21]
Step 1022 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 795.0]  episode_count: 716 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.212]
Step 1023 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 796.0]  episode_count: 716 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.214]
Step 1024 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 797.0]  episode_count: 719 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.217]
Step 1025 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 798.0]  episode_count: 719 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.219]
Step 1026 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 799.0]  episode_count: 719 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.222]
Step 1027 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 800.0]  episode_count: 719 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.224]
Step 1028 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 801.0]  episode_count: 720 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.226]
{"total_number_of_episodes": 722, "number_of_timesteps": 68756, "per_episode_reward": -484.99, "episode_reward_trend_value": -0.09905658436761024, "biggest_recent_change": 4.157386256904886},
Step 1029 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 802.0]  episode_count: 722 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.229]
Step 1030 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 803.0]  episode_count: 723 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.231]
Step 1031 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 804.0]  episode_count: 724 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.233]
Step 1032 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 805.0]  episode_count: 725 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.236]
Step 1033 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 806.0]  episode_count: 726 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.238]
Step 1034 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 807.0]  episode_count: 726 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.24]
Step 1035 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 808.0]  episode_count: 726 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.243]
Step 1036 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 809.0]  episode_count: 726 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.245]
Step 1037 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 810.0]  episode_count: 726 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.247]
Step 1038 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 811.0]  episode_count: 727 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.236]
Step 1039 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 812.0]  episode_count: 729 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.238]
Step 1040 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 813.0]  episode_count: 730 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.227]
Step 1041 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 814.0]  episode_count: 731 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.229]
{"total_number_of_episodes": 733, "number_of_timesteps": 69749, "per_episode_reward": -485.3, "episode_reward_trend_value": -0.05630266091323379, "biggest_recent_change": 3.8862421427504614},
Step 1042 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 815.0]  episode_count: 733 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.231]
Step 1043 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 816.0]  episode_count: 733 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.234]
Step 1044 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 817.0]  episode_count: 733 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.236]
Step 1045 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 818.0]  episode_count: 734 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.238]
Step 1046 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 819.0]  episode_count: 734 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.227]
Step 1047 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 820.0]  episode_count: 735 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.229]
Step 1048 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 821.0]  episode_count: 737 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.232]
Step 1049 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 822.0]  episode_count: 738 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.234]
Step 1050 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 823.0]  episode_count: 738 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.23]
Step 1051 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 824.0]  episode_count: 740 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.232]
Step 1052 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 825.0]  episode_count: 740 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.234]
Step 1053 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 826.0]  episode_count: 740 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.236]
Step 1054 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 827.0]  episode_count: 742 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.239]
Step 1055 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 828.0]  episode_count: 742 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.241]
Step 1056 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 829.0]  episode_count: 742 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.243]
{"total_number_of_episodes": 743, "number_of_timesteps": 70555, "per_episode_reward": -486.3, "episode_reward_trend_value": -0.048079763151793034, "biggest_recent_change": 3.8862421427504614},
Step 1057 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 830.0]  episode_count: 743 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.245]
Step 1058 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 831.0]  episode_count: 743 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.234]
Step 1059 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 832.0]  episode_count: 746 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.237]
Step 1060 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 833.0]  episode_count: 747 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.239]
Step 1061 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 834.0]  episode_count: 747 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.241]
Step 1062 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 835.0]  episode_count: 748 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.243]
Step 1063 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 836.0]  episode_count: 748 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.246]
Step 1064 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 837.0]  episode_count: 749 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.248]
Step 1065 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 838.0]  episode_count: 749 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.25]
Step 1066 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 839.0]  episode_count: 749 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.252]
Step 1067 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 840.0]  episode_count: 749 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.254]
Step 1068 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 841.0]  episode_count: 751 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.243]
Step 1069 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 842.0]  episode_count: 752 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.246]
{"total_number_of_episodes": 753, "number_of_timesteps": 71487, "per_episode_reward": -486.79, "episode_reward_trend_value": -0.010297878435827417, "biggest_recent_change": 2.898700321867693},
Step 1070 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 843.0]  episode_count: 753 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.248]
Step 1071 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 844.0]  episode_count: 754 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.25]
Step 1072 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 845.0]  episode_count: 754 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.252]
Step 1073 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 846.0]  episode_count: 755 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.254]
Step 1074 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 847.0]  episode_count: 755 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.257]
Step 1075 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 848.0]  episode_count: 756 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.246]
Step 1076 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 849.0]  episode_count: 758 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.248]
Step 1077 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 850.0]  episode_count: 758 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.25]
Step 1078 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 851.0]  episode_count: 758 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.239]
Step 1079 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 852.0]  episode_count: 759 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.241]
Step 1080 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 853.0]  episode_count: 760 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.244]
Step 1081 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 854.0]  episode_count: 761 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.246]
Step 1082 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 855.0]  episode_count: 762 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.248]
Step 1083 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 856.0]  episode_count: 762 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.25]
{"total_number_of_episodes": 764, "number_of_timesteps": 72484, "per_episode_reward": -488.29, "episode_reward_trend_value": -0.008235159847165757, "biggest_recent_change": 2.898700321867693},
Step 1084 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 857.0]  episode_count: 764 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.252]
Step 1085 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 858.0]  episode_count: 764 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.242]
Step 1086 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 859.0]  episode_count: 765 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.244]
Step 1087 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 860.0]  episode_count: 765 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.246]
Step 1088 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 861.0]  episode_count: 766 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.248]
Step 1089 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 862.0]  episode_count: 768 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.25]
Step 1090 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 863.0]  episode_count: 768 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.252]
Step 1091 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 864.0]  episode_count: 768 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.255]
Step 1092 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 865.0]  episode_count: 768 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.244]
Step 1093 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 866.0]  episode_count: 769 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.246]
Step 1094 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 867.0]  episode_count: 771 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.248]
Step 1095 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 868.0]  episode_count: 771 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.25]
Step 1096 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 869.0]  episode_count: 772 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.252]
Step 1097 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 870.0]  episode_count: 773 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.255]
Step 1098 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 871.0]  episode_count: 773 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.257]
Step 1099 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 872.0]  episode_count: 773 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.246]
{"total_number_of_episodes": 774, "number_of_timesteps": 73405, "per_episode_reward": -490.02, "episode_reward_trend_value": -0.02230484554714154, "biggest_recent_change": 2.898700321867693},
Step 1100 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 873.0]  episode_count: 774 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.248]
Step 1101 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 874.0]  episode_count: 775 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.25]
Step 1102 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 875.0]  episode_count: 775 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.253]
Step 1103 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 876.0]  episode_count: 775 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.255]
Step 1104 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 877.0]  episode_count: 776 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.257]
Step 1105 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 878.0]  episode_count: 777 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 1106 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 879.0]  episode_count: 777 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.261]
Step 1107 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 880.0]  episode_count: 778 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.263]
Step 1108 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 881.0]  episode_count: 779 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.265]
Step 1109 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 882.0]  episode_count: 779 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.255]
Step 1110 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 883.0]  episode_count: 779 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.257]
Step 1111 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 884.0]  episode_count: 780 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 1112 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 885.0]  episode_count: 781 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.261]
Step 1113 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 886.0]  episode_count: 781 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.263]
Step 1114 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 887.0]  episode_count: 781 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.253]
Step 1115 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 888.0]  episode_count: 781 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.255]
{"total_number_of_episodes": 784, "number_of_timesteps": 74566, "per_episode_reward": -492.84, "episode_reward_trend_value": -0.06650361431185843, "biggest_recent_change": 2.898700321867693},
Step 1116 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 889.0]  episode_count: 784 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.257]
Step 1117 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 890.0]  episode_count: 785 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 1118 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 891.0]  episode_count: 786 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.261]
Step 1119 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 892.0]  episode_count: 786 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.263]
Step 1120 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 893.0]  episode_count: 788 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.265]
Step 1121 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 894.0]  episode_count: 788 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.267]
Step 1122 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 895.0]  episode_count: 788 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.269]
Step 1123 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 896.0]  episode_count: 788 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 1124 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 897.0]  episode_count: 789 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.261]
Step 1125 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 898.0]  episode_count: 789 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.263]
Step 1126 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 899.0]  episode_count: 790 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.265]
Step 1127 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 900.0]  episode_count: 791 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.267]
Step 1128 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 901.0]  episode_count: 791 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.257]
{"total_number_of_episodes": 794, "number_of_timesteps": 75501, "per_episode_reward": -493.49, "episode_reward_trend_value": -0.08136340037151892, "biggest_recent_change": 2.898700321867693},
Step 1129 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 902.0]  episode_count: 794 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 1130 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 903.0]  episode_count: 795 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.261]
Step 1131 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 904.0]  episode_count: 795 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.263]
Step 1132 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 905.0]  episode_count: 795 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.265]
[-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.267]
Step 1134 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 907.0]  episode_count: 796 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.269]
Step 1135 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 908.0]  episode_count: 797 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.271]
Step 1136 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 909.0]  episode_count: 797 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.273]
Step 1137 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 910.0]  episode_count: 800 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.275]
Step 1138 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 911.0]  episode_count: 800 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.265]
Step 1139 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 912.0]  episode_count: 800 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.267]
Step 1140 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 913.0]  episode_count: 800 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.269]
Step 1141 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 914.0]  episode_count: 801 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.271]
Step 1142 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 915.0]  episode_count: 801 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.273]
Step 1143 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 916.0]  episode_count: 802 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.275]
Step 1144 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 917.0]  episode_count: 803 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.277]
Step 1145 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 918.0]  episode_count: 803 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.279]
{"total_number_of_episodes": 804, "number_of_timesteps": 76443, "per_episode_reward": -494.68, "episode_reward_trend_value": -0.1268059749909892, "biggest_recent_change": 2.817381738537506},
Step 1146 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 919.0]  episode_count: 804 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.281]
Step 1147 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 920.0]  episode_count: 805 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.283]
Step 1148 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 921.0]  episode_count: 806 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.285]
Step 1149 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 922.0]  episode_count: 806 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.287]
Step 1150 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 923.0]  episode_count: 806 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.289]
Step 1151 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 924.0]  episode_count: 806 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.279]
Step 1152 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 925.0]  episode_count: 807 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.269]
Step 1153 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 926.0]  episode_count: 808 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.271]
Step 1154 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 927.0]  episode_count: 809 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.261]
Step 1155 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 928.0]  episode_count: 810 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.263]
Step 1156 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 929.0]  episode_count: 810 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.253]
Step 1157 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 930.0]  episode_count: 810 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.255]
Step 1158 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 931.0]  episode_count: 811 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.257]
Step 1159 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 932.0]  episode_count: 811 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 1160 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 933.0]  episode_count: 811 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.261]
Step 1161 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 934.0]  episode_count: 811 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.263]
Step 1162 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 935.0]  episode_count: 812 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.265]
{"total_number_of_episodes": 814, "number_of_timesteps": 77621, "per_episode_reward": -495.11, "episode_reward_trend_value": -0.1124635026391944, "biggest_recent_change": 2.817381738537506},
Step 1163 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 936.0]  episode_count: 814 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.267]
Step 1164 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 937.0]  episode_count: 816 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.269]
Step 1165 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 938.0]  episode_count: 816 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.271]
Step 1166 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 939.0]  episode_count: 816 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.273]
Step 1167 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 940.0]  episode_count: 817 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.275]
Step 1168 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 941.0]  episode_count: 818 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.277]
Step 1169 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 942.0]  episode_count: 818 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.279]
Step 1170 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 943.0]  episode_count: 818 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.28]
Step 1171 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 944.0]  episode_count: 818 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.282]
Step 1172 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 945.0]  episode_count: 819 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.284]
Step 1173 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 946.0]  episode_count: 819 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.275]
Step 1174 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 947.0]  episode_count: 819 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.276]
Step 1175 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 948.0]  episode_count: 819 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.278]
Step 1176 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 949.0]  episode_count: 819 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.28]
Step 1177 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 950.0]  episode_count: 823 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.271]
{"total_number_of_episodes": 824, "number_of_timesteps": 78741, "per_episode_reward": -495.93, "episode_reward_trend_value": -0.1181203959652142, "biggest_recent_change": 2.817381738537506},
Step 1178 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 951.0]  episode_count: 824 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.273]
Step 1179 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 952.0]  episode_count: 825 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.274]
Step 1180 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 953.0]  episode_count: 825 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.276]
Step 1181 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 954.0]  episode_count: 825 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.278]
Step 1182 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 955.0]  episode_count: 826 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.269]
Step 1183 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 956.0]  episode_count: 826 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 1184 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 957.0]  episode_count: 826 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.261]
Step 1185 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 958.0]  episode_count: 830 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.263]
Step 1186 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 959.0]  episode_count: 830 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.265]
Step 1187 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 960.0]  episode_count: 831 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.267]
Step 1188 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 961.0]  episode_count: 831 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.269]
Step 1189 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 962.0]  episode_count: 832 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 1190 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 963.0]  episode_count: 832 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.261]
Step 1191 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 964.0]  episode_count: 833 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.251]
{"total_number_of_episodes": 835, "number_of_timesteps": 79681, "per_episode_reward": -496.05, "episode_reward_trend_value": -0.1082478252996768, "biggest_recent_change": 2.817381738537506},
Step 1192 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 965.0]  episode_count: 835 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.253]
Step 1193 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 966.0]  episode_count: 836 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.255]
Step 1194 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 967.0]  episode_count: 836 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.257]
Step 1195 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 968.0]  episode_count: 837 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 1196 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 969.0]  episode_count: 838 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.249]
Step 1197 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 970.0]  episode_count: 838 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.251]
Step 1198 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 971.0]  episode_count: 840 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.253]
Step 1199 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 972.0]  episode_count: 841 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.255]
Step 1200 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 973.0]  episode_count: 842 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.257]
Step 1201 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 974.0]  episode_count: 843 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 1202 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 975.0]  episode_count: 843 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.261]
Step 1203 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 976.0]  episode_count: 844 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.263]
{"total_number_of_episodes": 845, "number_of_timesteps": 80447, "per_episode_reward": -497.78, "episode_reward_trend_value": -0.12214175694606096, "biggest_recent_change": 2.817381738537506},
Step 1204 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 977.0]  episode_count: 845 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.265]
Step 1205 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 978.0]  episode_count: 846 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.266]
Step 1206 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 979.0]  episode_count: 847 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.257]
Step 1207 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 980.0]  episode_count: 848 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 1208 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 981.0]  episode_count: 848 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.261]
Step 1209 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 982.0]  episode_count: 850 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.251]
Step 1210 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 983.0]  episode_count: 851 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.253]
Step 1211 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 984.0]  episode_count: 852 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.255]
Step 1212 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 985.0]  episode_count: 852 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.257]
{"total_number_of_episodes": 855, "number_of_timesteps": 81173, "per_episode_reward": -498.13, "episode_reward_trend_value": -0.10927190449131356, "biggest_recent_change": 2.817381738537506},
Step 1213 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 986.0]  episode_count: 855 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 1214 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 987.0]  episode_count: 855 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.261]
Step 1215 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 988.0]  episode_count: 856 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.263]
Step 1216 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 989.0]  episode_count: 856 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.265]
Step 1217 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 990.0]  episode_count: 858 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.255]
Step 1218 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 991.0]  episode_count: 859 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.257]
Step 1219 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 992.0]  episode_count: 859 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.259]
Step 1220 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 993.0]  episode_count: 860 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.261]
Step 1221 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 994.0]  episode_count: 862 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.263]
Step 1222 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 995.0]  episode_count: 863 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.264]
Step 1223 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 996.0]  episode_count: 864 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.266]
Step 1224 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 997.0]  episode_count: 864 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.268]
{"total_number_of_episodes": 865, "number_of_timesteps": 81861, "per_episode_reward": -497.24, "episode_reward_trend_value": -0.08023452937220554, "biggest_recent_change": 2.817381738537506},
Step 1225 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 998.0]  episode_count: 865 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.27]
Step 1226 6 visits [22.0, 113.0, 4.0, 4.0, 80.0, 4.0, 999.0]  episode_count: 866 q_vals: [-10.327, -10.029, -11.111, -11.111, -10.067, -11.111, -9.272]
Step 1227 6 visits [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1000.0]  episode_count: 866 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf]
Step 1228 0 visits [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1000.0]  episode_count: 869 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf]
Step 1229 1 visits [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1000.0]  episode_count: 869 q_vals: [0.0, -12.8, 0.0, 0.0, 0.0, 0.0, -inf]
Step 1230 2 visits [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1000.0]  episode_count: 870 q_vals: [0.0, -12.8, 0.0, 0.0, 0.0, 0.0, -inf]
Step 1231 3 visits [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1000.0]  episode_count: 870 q_vals: [0.0, -12.8, 0.0, 0.0, 0.0, 0.0, -inf]
Step 1232 4 visits [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1000.0]  episode_count: 871 q_vals: [0.0, -12.8, 0.0, 0.0, -12.8, 0.0, -inf]
Step 1233 5 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1000.0]  episode_count: 872 q_vals: [0.0, -12.8, 0.0, 0.0, -12.8, -12.8, -inf]
Step 1234 0 visits [2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1000.0]  episode_count: 873 q_vals: [0.0, -12.8, 0.0, 0.0, -12.8, -12.8, -inf]
Step 1235 2 visits [2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1000.0]  episode_count: 873 q_vals: [0.0, -12.8, -6.4, 0.0, -12.8, -12.8, -inf]
{"total_number_of_episodes": 875, "number_of_timesteps": 82609, "per_episode_reward": -426.22, "episode_reward_trend_value": 0.7402489723590742, "biggest_recent_change": 71.02613341727766},
Step 1236 3 visits [2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1000.0]  episode_count: 875 q_vals: [0.0, -12.8, -6.4, 0.0, -12.8, -12.8, -inf]
Step 1237 0 visits [3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1000.0]  episode_count: 876 q_vals: [0.0, -12.8, -6.4, 0.0, -12.8, -12.8, -inf]
Step 1238 3 visits [3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1000.0]  episode_count: 876 q_vals: [0.0, -12.8, -6.4, -4.267, -12.8, -12.8, -inf]
Step 1239 0 visits [4.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1000.0]  episode_count: 877 q_vals: [-3.2, -12.8, -6.4, -4.267, -12.8, -12.8, -inf]
Step 1240 0 visits [5.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1000.0]  episode_count: 878 q_vals: [-5.12, -12.8, -6.4, -4.267, -12.8, -12.8, -inf]
Step 1241 3 visits [5.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1000.0]  episode_count: 878 q_vals: [-5.12, -12.8, -6.4, -6.4, -12.8, -12.8, -inf]
Step 1242 0 visits [6.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1000.0]  episode_count: 879 q_vals: [-6.4, -12.8, -6.4, -6.4, -12.8, -12.8, -inf]
Step 1243 2 visits [6.0, 1.0, 3.0, 4.0, 1.0, 1.0, 1000.0]  episode_count: 879 q_vals: [-6.4, -12.8, -4.267, -6.4, -12.8, -12.8, -inf]
Step 1244 2 visits [6.0, 1.0, 4.0, 4.0, 1.0, 1.0, 1000.0]  episode_count: 880 q_vals: [-6.4, -12.8, -3.2, -6.4, -12.8, -12.8, -inf]
Step 1245 2 visits [6.0, 1.0, 5.0, 4.0, 1.0, 1.0, 1000.0]  episode_count: 883 q_vals: [-6.4, -12.8, -2.56, -6.4, -12.8, -12.8, -inf]
Step 1246 2 visits [6.0, 1.0, 6.0, 4.0, 1.0, 1.0, 1000.0]  episode_count: 883 q_vals: [-6.4, -12.8, -2.133, -6.4, -12.8, -12.8, -inf]
Step 1247 2 visits [6.0, 1.0, 7.0, 4.0, 1.0, 1.0, 1000.0]  episode_count: 884 q_vals: [-6.4, -12.8, -3.657, -6.4, -12.8, -12.8, -inf]
{"total_number_of_episodes": 885, "number_of_timesteps": 83428, "per_episode_reward": -426.9, "episode_reward_trend_value": 0.7399129148412239, "biggest_recent_change": 71.02613341727766},
Step 1248 2 visits [6.0, 1.0, 8.0, 4.0, 1.0, 1.0, 1000.0]  episode_count: 885 q_vals: [-6.4, -12.8, -4.8, -6.4, -12.8, -12.8, -inf]
Step 1249 2 visits [6.0, 1.0, 9.0, 4.0, 1.0, 1.0, 1000.0]  episode_count: 885 q_vals: [-6.4, -12.8, -4.267, -6.4, -12.8, -12.8, -inf]
Step 1250 2 visits [6.0, 1.0, 10.0, 4.0, 1.0, 1.0, 1000.0]  episode_count: 885 q_vals: [-6.4, -12.8, -5.12, -6.4, -12.8, -12.8, -inf]
Step 1251 2 visits [6.0, 1.0, 11.0, 4.0, 1.0, 1.0, 1000.0]  episode_count: 886 q_vals: [-6.4, -12.8, -5.818, -6.4, -12.8, -12.8, -inf]
Step 1252 2 visits [6.0, 1.0, 12.0, 4.0, 1.0, 1.0, 1000.0]  episode_count: 886 q_vals: [-6.4, -12.8, -6.4, -6.4, -12.8, -12.8, -inf]
Step 1253 3 visits [6.0, 1.0, 12.0, 5.0, 1.0, 1.0, 1000.0]  episode_count: 886 q_vals: [-6.4, -12.8, -6.4, -5.12, -12.8, -12.8, -inf]
Step 1254 3 visits [6.0, 1.0, 12.0, 6.0, 1.0, 1.0, 1000.0]  episode_count: 886 q_vals: [-6.4, -12.8, -6.4, -6.4, -12.8, -12.8, -inf]
Step 1255 3 visits [6.0, 1.0, 12.0, 7.0, 1.0, 1.0, 1000.0]  episode_count: 888 q_vals: [-6.4, -12.8, -6.4, -5.486, -12.8, -12.8, -inf]
Step 1256 3 visits [6.0, 1.0, 12.0, 8.0, 1.0, 1.0, 1000.0]  episode_count: 889 q_vals: [-6.4, -12.8, -6.4, -6.4, -12.8, -12.8, -inf]
Step 1257 0 visits [7.0, 1.0, 12.0, 8.0, 1.0, 1.0, 1000.0]  episode_count: 889 q_vals: [-7.314, -12.8, -6.4, -6.4, -12.8, -12.8, -inf]
Step 1258 3 visits [7.0, 1.0, 12.0, 9.0, 1.0, 1.0, 1000.0]  episode_count: 889 q_vals: [-7.314, -12.8, -6.4, -7.111, -12.8, -12.8, -inf]
Step 1259 2 visits [7.0, 1.0, 13.0, 9.0, 1.0, 1.0, 1000.0]  episode_count: 890 q_vals: [-7.314, -12.8, -6.892, -7.111, -12.8, -12.8, -inf]
Step 1260 2 visits [7.0, 1.0, 14.0, 9.0, 1.0, 1.0, 1000.0]  episode_count: 892 q_vals: [-7.314, -12.8, -7.314, -7.111, -12.8, -12.8, -inf]
Step 1261 3 visits [7.0, 1.0, 14.0, 10.0, 1.0, 1.0, 1000.0]  episode_count: 892 q_vals: [-7.314, -12.8, -7.314, -7.68, -12.8, -12.8, -inf]
Step 1262 0 visits [8.0, 1.0, 14.0, 10.0, 1.0, 1.0, 1000.0]  episode_count: 892 q_vals: [-8.0, -12.8, -7.314, -7.68, -12.8, -12.8, -inf]
Step 1263 2 visits [8.0, 1.0, 15.0, 10.0, 1.0, 1.0, 1000.0]  episode_count: 892 q_vals: [-8.0, -12.8, -7.68, -7.68, -12.8, -12.8, -inf]
Step 1264 3 visits [8.0, 1.0, 15.0, 11.0, 1.0, 1.0, 1000.0]  episode_count: 892 q_vals: [-8.0, -12.8, -7.68, -8.145, -12.8, -12.8, -inf]
Step 1265 2 visits [8.0, 1.0, 16.0, 11.0, 1.0, 1.0, 1000.0]  episode_count: 894 q_vals: [-8.0, -12.8, -7.2, -8.145, -12.8, -12.8, -inf]
{"total_number_of_episodes": 895, "number_of_timesteps": 84537, "per_episode_reward": -427.12, "episode_reward_trend_value": 0.7506834942031257, "biggest_recent_change": 71.02613341727766},
Step 1266 2 visits [8.0, 1.0, 17.0, 11.0, 1.0, 1.0, 1000.0]  episode_count: 895 q_vals: [-8.0, -12.8, -7.529, -8.145, -12.8, -12.8, -inf]
Step 1267 2 visits [8.0, 1.0, 18.0, 11.0, 1.0, 1.0, 1000.0]  episode_count: 896 q_vals: [-8.0, -12.8, -7.822, -8.145, -12.8, -12.8, -inf]
Step 1268 0 visits [9.0, 1.0, 18.0, 11.0, 1.0, 1.0, 1000.0]  episode_count: 898 q_vals: [-8.533, -12.8, -7.822, -8.145, -12.8, -12.8, -inf]
Step 1269 2 visits [9.0, 1.0, 19.0, 11.0, 1.0, 1.0, 1000.0]  episode_count: 899 q_vals: [-8.533, -12.8, -8.084, -8.145, -12.8, -12.8, -inf]
Step 1270 3 visits [9.0, 1.0, 19.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 899 q_vals: [-8.533, -12.8, -8.084, -8.533, -12.8, -12.8, -inf]
Step 1271 2 visits [9.0, 1.0, 20.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 899 q_vals: [-8.533, -12.8, -7.68, -8.533, -12.8, -12.8, -inf]
Step 1272 2 visits [9.0, 1.0, 21.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 900 q_vals: [-8.533, -12.8, -7.924, -8.533, -12.8, -12.8, -inf]
Step 1273 2 visits [9.0, 1.0, 22.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 901 q_vals: [-8.533, -12.8, -7.564, -8.533, -12.8, -12.8, -inf]
Step 1274 2 visits [9.0, 1.0, 23.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 901 q_vals: [-8.533, -12.8, -7.235, -8.533, -12.8, -12.8, -inf]
Step 1275 2 visits [9.0, 1.0, 24.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 902 q_vals: [-8.533, -12.8, -7.467, -8.533, -12.8, -12.8, -inf]
Step 1276 2 visits [9.0, 1.0, 25.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 902 q_vals: [-8.533, -12.8, -7.619, -8.533, -12.8, -12.8, -inf]
Step 1277 2 visits [9.0, 1.0, 26.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 902 q_vals: [-8.533, -12.8, -7.818, -8.533, -12.8, -12.8, -inf]
Step 1278 2 visits [9.0, 1.0, 27.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 902 q_vals: [-8.533, -12.8, -7.528, -8.533, -12.8, -12.8, -inf]
{"total_number_of_episodes": 905, "number_of_timesteps": 85414, "per_episode_reward": -425.79, "episode_reward_trend_value": 0.7702015490036445, "biggest_recent_change": 71.02613341727766},
Step 1279 2 visits [9.0, 1.0, 28.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 905 q_vals: [-8.533, -12.8, -7.717, -8.533, -12.8, -12.8, -inf]
Step 1280 2 visits [9.0, 1.0, 29.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 907 q_vals: [-8.533, -12.8, -7.892, -8.533, -12.8, -12.8, -inf]
Step 1281 2 visits [9.0, 1.0, 30.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 907 q_vals: [-8.533, -12.8, -7.629, -8.533, -12.8, -12.8, -inf]
Step 1282 2 visits [9.0, 1.0, 31.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 907 q_vals: [-8.533, -12.8, -7.383, -8.533, -12.8, -12.8, -inf]
Step 1283 2 visits [9.0, 1.0, 32.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 908 q_vals: [-8.533, -12.8, -7.552, -8.533, -12.8, -12.8, -inf]
Step 1284 2 visits [9.0, 1.0, 33.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 908 q_vals: [-8.533, -12.8, -7.323, -8.533, -12.8, -12.8, -inf]
Step 1285 2 visits [9.0, 1.0, 34.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 908 q_vals: [-8.533, -12.8, -7.108, -8.533, -12.8, -12.8, -inf]
Step 1286 2 visits [9.0, 1.0, 35.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 908 q_vals: [-8.533, -12.8, -6.905, -8.533, -12.8, -12.8, -inf]
Step 1287 2 visits [9.0, 1.0, 36.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 909 q_vals: [-8.533, -12.8, -6.713, -8.533, -12.8, -12.8, -inf]
Step 1288 2 visits [9.0, 1.0, 37.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 910 q_vals: [-8.533, -12.8, -6.877, -8.533, -12.8, -12.8, -inf]
Step 1289 2 visits [9.0, 1.0, 38.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 911 q_vals: [-8.533, -12.8, -6.696, -8.533, -12.8, -12.8, -inf]
Step 1290 2 visits [9.0, 1.0, 39.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 911 q_vals: [-8.533, -12.8, -6.525, -8.533, -12.8, -12.8, -inf]
Step 1291 2 visits [9.0, 1.0, 40.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 912 q_vals: [-8.533, -12.8, -6.682, -8.533, -12.8, -12.8, -inf]
Step 1292 2 visits [9.0, 1.0, 41.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 912 q_vals: [-8.533, -12.8, -6.831, -8.533, -12.8, -12.8, -inf]
Step 1293 2 visits [9.0, 1.0, 42.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 912 q_vals: [-8.533, -12.8, -6.668, -8.533, -12.8, -12.8, -inf]
Step 1294 2 visits [9.0, 1.0, 43.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 912 q_vals: [-8.533, -12.8, -6.811, -8.533, -12.8, -12.8, -inf]
Step 1295 2 visits [9.0, 1.0, 44.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 914 q_vals: [-8.533, -12.8, -6.947, -8.533, -12.8, -12.8, -inf]
{"total_number_of_episodes": 916, "number_of_timesteps": 86629, "per_episode_reward": -428.76, "episode_reward_trend_value": 0.7462664690744545, "biggest_recent_change": 71.02613341727766},
Step 1296 2 visits [9.0, 1.0, 45.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 916 q_vals: [-8.533, -12.8, -7.077, -8.533, -12.8, -12.8, -inf]
Step 1297 2 visits [9.0, 1.0, 46.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 916 q_vals: [-8.533, -12.8, -7.201, -8.533, -12.8, -12.8, -inf]
Step 1298 2 visits [9.0, 1.0, 47.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 916 q_vals: [-8.533, -12.8, -7.321, -8.533, -12.8, -12.8, -inf]
Step 1299 2 visits [9.0, 1.0, 48.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 916 q_vals: [-8.533, -12.8, -7.168, -8.533, -12.8, -12.8, -inf]
Step 1300 2 visits [9.0, 1.0, 49.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 916 q_vals: [-8.533, -12.8, -7.022, -8.533, -12.8, -12.8, -inf]
Step 1301 2 visits [9.0, 1.0, 50.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 916 q_vals: [-8.533, -12.8, -7.137, -8.533, -12.8, -12.8, -inf]
Step 1302 2 visits [9.0, 1.0, 51.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 916 q_vals: [-8.533, -12.8, -7.248, -8.533, -12.8, -12.8, -inf]
Step 1303 2 visits [9.0, 1.0, 52.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 918 q_vals: [-8.533, -12.8, -7.109, -8.533, -12.8, -12.8, -inf]
Step 1304 2 visits [9.0, 1.0, 53.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 919 q_vals: [-8.533, -12.8, -7.216, -8.533, -12.8, -12.8, -inf]
Step 1305 2 visits [9.0, 1.0, 54.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 920 q_vals: [-8.533, -12.8, -7.32, -8.533, -12.8, -12.8, -inf]
Step 1306 2 visits [9.0, 1.0, 55.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 921 q_vals: [-8.533, -12.8, -7.419, -8.533, -12.8, -12.8, -inf]
Step 1307 2 visits [9.0, 1.0, 56.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 921 q_vals: [-8.533, -12.8, -7.287, -8.533, -12.8, -12.8, -inf]
Step 1308 2 visits [9.0, 1.0, 57.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 922 q_vals: [-8.533, -12.8, -7.384, -8.533, -12.8, -12.8, -inf]
Step 1309 2 visits [9.0, 1.0, 58.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 923 q_vals: [-8.533, -12.8, -7.477, -8.533, -12.8, -12.8, -inf]
Step 1310 2 visits [9.0, 1.0, 59.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 923 q_vals: [-8.533, -12.8, -7.567, -8.533, -12.8, -12.8, -inf]
Step 1311 2 visits [9.0, 1.0, 60.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 925 q_vals: [-8.533, -12.8, -7.654, -8.533, -12.8, -12.8, -inf]
Step 1312 2 visits [9.0, 1.0, 61.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 925 q_vals: [-8.533, -12.8, -7.529, -8.533, -12.8, -12.8, -inf]
{"total_number_of_episodes": 926, "number_of_timesteps": 87721, "per_episode_reward": -429.0, "episode_reward_trend_value": 0.7449278066147006, "biggest_recent_change": 71.02613341727766},
Step 1313 2 visits [9.0, 1.0, 62.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 926 q_vals: [-8.533, -12.8, -7.614, -8.533, -12.8, -12.8, -inf]
Step 1314 2 visits [9.0, 1.0, 63.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 926 q_vals: [-8.533, -12.8, -7.696, -8.533, -12.8, -12.8, -inf]
Step 1315 2 visits [9.0, 1.0, 64.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 927 q_vals: [-8.533, -12.8, -7.776, -8.533, -12.8, -12.8, -inf]
Step 1316 2 visits [9.0, 1.0, 65.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 928 q_vals: [-8.533, -12.8, -7.853, -8.533, -12.8, -12.8, -inf]
Step 1317 2 visits [9.0, 1.0, 66.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 928 q_vals: [-8.533, -12.8, -7.734, -8.533, -12.8, -12.8, -inf]
Step 1318 2 visits [9.0, 1.0, 67.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 929 q_vals: [-8.533, -12.8, -7.81, -8.533, -12.8, -12.8, -inf]
Step 1319 2 visits [9.0, 1.0, 68.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 929 q_vals: [-8.533, -12.8, -7.883, -8.533, -12.8, -12.8, -inf]
Step 1320 2 visits [9.0, 1.0, 69.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 930 q_vals: [-8.533, -12.8, -7.769, -8.533, -12.8, -12.8, -inf]
Step 1321 2 visits [9.0, 1.0, 70.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 931 q_vals: [-8.533, -12.8, -7.841, -8.533, -12.8, -12.8, -inf]
Step 1322 2 visits [9.0, 1.0, 71.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 933 q_vals: [-8.533, -12.8, -7.911, -8.533, -12.8, -12.8, -inf]
Step 1323 2 visits [9.0, 1.0, 72.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 933 q_vals: [-8.533, -12.8, -7.979, -8.533, -12.8, -12.8, -inf]
Step 1324 2 visits [9.0, 1.0, 73.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 934 q_vals: [-8.533, -12.8, -7.869, -8.533, -12.8, -12.8, -inf]
Step 1325 2 visits [9.0, 1.0, 74.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 935 q_vals: [-8.533, -12.8, -7.763, -8.533, -12.8, -12.8, -inf]
Step 1326 2 visits [9.0, 1.0, 75.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 935 q_vals: [-8.533, -12.8, -7.83, -8.533, -12.8, -12.8, -inf]
Step 1327 2 visits [9.0, 1.0, 76.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 935 q_vals: [-8.533, -12.8, -7.896, -8.533, -12.8, -12.8, -inf]
{"total_number_of_episodes": 938, "number_of_timesteps": 88791, "per_episode_reward": -427.84, "episode_reward_trend_value": 0.7771786431631394, "biggest_recent_change": 71.02613341727766},
Step 1328 2 visits [9.0, 1.0, 77.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 938 q_vals: [-8.533, -12.8, -7.793, -8.533, -12.8, -12.8, -inf]
Step 1329 2 visits [9.0, 1.0, 78.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 940 q_vals: [-8.533, -12.8, -7.857, -8.533, -12.8, -12.8, -inf]
Step 1330 2 visits [9.0, 1.0, 79.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 940 q_vals: [-8.533, -12.8, -7.92, -8.533, -12.8, -12.8, -inf]
Step 1331 2 visits [9.0, 1.0, 80.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 940 q_vals: [-8.533, -12.8, -7.981, -8.533, -12.8, -12.8, -inf]
Step 1332 2 visits [9.0, 1.0, 81.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 941 q_vals: [-8.533, -12.8, -8.04, -8.533, -12.8, -12.8, -inf]
Step 1333 2 visits [9.0, 1.0, 82.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 942 q_vals: [-8.533, -12.8, -8.098, -8.533, -12.8, -12.8, -inf]
Step 1334 0 visits [10.0, 1.0, 82.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 942 q_vals: [-8.96, -12.8, -8.098, -8.533, -12.8, -12.8, -inf]
Step 1335 2 visits [10.0, 1.0, 83.0, 12.0, 1.0, 1.0, 1000.0]  episode_count: 943 q_vals: [-8.96, -12.8, -8.155, -8.533, -12.8, -12.8, -inf]
Step 1336 3 visits [10.0, 1.0, 83.0, 13.0, 1.0, 1.0, 1000.0]  episode_count: 946 q_vals: [-8.96, -12.8, -8.155, -7.877, -12.8, -12.8, -inf]
Step 1337 3 visits [10.0, 1.0, 83.0, 14.0, 1.0, 1.0, 1000.0]  episode_count: 946 q_vals: [-8.96, -12.8, -8.155, -8.229, -12.8, -12.8, -inf]
Step 1338 3 visits [10.0, 1.0, 83.0, 15.0, 1.0, 1.0, 1000.0]  episode_count: 947 q_vals: [-8.96, -12.8, -8.155, -8.533, -12.8, -12.8, -inf]
{"total_number_of_episodes": 948, "number_of_timesteps": 89541, "per_episode_reward": -424.95, "episode_reward_trend_value": 0.8131028538616996, "biggest_recent_change": 71.02613341727766},
Step 1339 2 visits [10.0, 1.0, 84.0, 15.0, 1.0, 1.0, 1000.0]  episode_count: 948 q_vals: [-8.96, -12.8, -8.21, -8.533, -12.8, -12.8, -inf]
Step 1340 3 visits [10.0, 1.0, 84.0, 16.0, 1.0, 1.0, 1000.0]  episode_count: 948 q_vals: [-8.96, -12.8, -8.21, -8.8, -12.8, -12.8, -inf]
Step 1341 2 visits [10.0, 1.0, 85.0, 16.0, 1.0, 1.0, 1000.0]  episode_count: 948 q_vals: [-8.96, -12.8, -8.264, -8.8, -12.8, -12.8, -inf]
Step 1342 2 visits [10.0, 1.0, 86.0, 16.0, 1.0, 1.0, 1000.0]  episode_count: 949 q_vals: [-8.96, -12.8, -8.317, -8.8, -12.8, -12.8, -inf]
Step 1343 2 visits [10.0, 1.0, 87.0, 16.0, 1.0, 1.0, 1000.0]  episode_count: 950 q_vals: [-8.96, -12.8, -8.369, -8.8, -12.8, -12.8, -inf]
Step 1344 2 visits [10.0, 1.0, 88.0, 16.0, 1.0, 1.0, 1000.0]  episode_count: 950 q_vals: [-8.96, -12.8, -8.419, -8.8, -12.8, -12.8, -inf]
Step 1345 2 visits [10.0, 1.0, 89.0, 16.0, 1.0, 1.0, 1000.0]  episode_count: 952 q_vals: [-8.96, -12.8, -8.468, -8.8, -12.8, -12.8, -inf]
Step 1346 2 visits [10.0, 1.0, 90.0, 16.0, 1.0, 1.0, 1000.0]  episode_count: 954 q_vals: [-8.96, -12.8, -8.516, -8.8, -12.8, -12.8, -inf]
Step 1347 3 visits [10.0, 1.0, 90.0, 17.0, 1.0, 1.0, 1000.0]  episode_count: 954 q_vals: [-8.96, -12.8, -8.516, -9.035, -12.8, -12.8, -inf]
Step 1348 0 visits [11.0, 1.0, 90.0, 17.0, 1.0, 1.0, 1000.0]  episode_count: 955 q_vals: [-9.309, -12.8, -8.516, -9.035, -12.8, -12.8, -inf]
Step 1349 2 visits [11.0, 1.0, 91.0, 17.0, 1.0, 1.0, 1000.0]  episode_count: 955 q_vals: [-9.309, -12.8, -8.563, -9.035, -12.8, -12.8, -inf]
Step 1350 2 visits [11.0, 1.0, 92.0, 17.0, 1.0, 1.0, 1000.0]  episode_count: 957 q_vals: [-9.309, -12.8, -8.609, -9.035, -12.8, -12.8, -inf]
Step 1351 2 visits [11.0, 1.0, 93.0, 17.0, 1.0, 1.0, 1000.0]  episode_count: 957 q_vals: [-9.309, -12.8, -8.654, -9.035, -12.8, -12.8, -inf]
Step 1352 2 visits [11.0, 1.0, 94.0, 17.0, 1.0, 1.0, 1000.0]  episode_count: 957 q_vals: [-9.309, -12.8, -8.699, -9.035, -12.8, -12.8, -inf]
{"total_number_of_episodes": 958, "number_of_timesteps": 90339, "per_episode_reward": -422.36, "episode_reward_trend_value": 0.8320632004237722, "biggest_recent_change": 71.02613341727766},
Step 1353 2 visits [11.0, 1.0, 95.0, 17.0, 1.0, 1.0, 1000.0]  episode_count: 958 q_vals: [-9.309, -12.8, -8.742, -9.035, -12.8, -12.8, -inf]
Step 1354 3 visits [11.0, 1.0, 95.0, 18.0, 1.0, 1.0, 1000.0]  episode_count: 959 q_vals: [-9.309, -12.8, -8.742, -8.533, -12.8, -12.8, -inf]
Step 1355 3 visits [11.0, 1.0, 95.0, 19.0, 1.0, 1.0, 1000.0]  episode_count: 960 q_vals: [-9.309, -12.8, -8.742, -8.084, -12.8, -12.8, -inf]
Step 1356 3 visits [11.0, 1.0, 95.0, 20.0, 1.0, 1.0, 1000.0]  episode_count: 961 q_vals: [-9.309, -12.8, -8.742, -8.32, -12.8, -12.8, -inf]
Step 1357 3 visits [11.0, 1.0, 95.0, 21.0, 1.0, 1.0, 1000.0]  episode_count: 961 q_vals: [-9.309, -12.8, -8.742, -8.533, -12.8, -12.8, -inf]
Step 1358 3 visits [11.0, 1.0, 95.0, 22.0, 1.0, 1.0, 1000.0]  episode_count: 961 q_vals: [-9.309, -12.8, -8.742, -8.727, -12.8, -12.8, -inf]
Step 1359 3 visits [11.0, 1.0, 95.0, 23.0, 1.0, 1.0, 1000.0]  episode_count: 962 q_vals: [-9.309, -12.8, -8.742, -8.904, -12.8, -12.8, -inf]
Step 1360 3 visits [11.0, 1.0, 95.0, 24.0, 1.0, 1.0, 1000.0]  episode_count: 962 q_vals: [-9.309, -12.8, -8.742, -9.067, -12.8, -12.8, -inf]
Step 1361 2 visits [11.0, 1.0, 96.0, 24.0, 1.0, 1.0, 1000.0]  episode_count: 963 q_vals: [-9.309, -12.8, -8.784, -9.067, -12.8, -12.8, -inf]
Step 1362 2 visits [11.0, 1.0, 97.0, 24.0, 1.0, 1.0, 1000.0]  episode_count: 965 q_vals: [-9.309, -12.8, -8.825, -9.067, -12.8, -12.8, -inf]
Step 1363 2 visits [11.0, 1.0, 98.0, 24.0, 1.0, 1.0, 1000.0]  episode_count: 965 q_vals: [-9.309, -12.8, -8.866, -9.067, -12.8, -12.8, -inf]
Step 1364 3 visits [11.0, 1.0, 98.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 967 q_vals: [-9.309, -12.8, -8.866, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 968, "number_of_timesteps": 91251, "per_episode_reward": -419.71, "episode_reward_trend_value": 0.07226056391978722, "biggest_recent_change": 2.972810738979888},
Step 1365 0 visits [12.0, 1.0, 98.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 968 q_vals: [-9.6, -12.8, -8.866, -9.216, -12.8, -12.8, -inf]
Step 1366 2 visits [12.0, 1.0, 99.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 969 q_vals: [-9.6, -12.8, -8.906, -9.216, -12.8, -12.8, -inf]
Step 1367 2 visits [12.0, 1.0, 100.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 969 q_vals: [-9.6, -12.8, -8.817, -9.216, -12.8, -12.8, -inf]
Step 1368 2 visits [12.0, 1.0, 101.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 970 q_vals: [-9.6, -12.8, -8.856, -9.216, -12.8, -12.8, -inf]
Step 1369 2 visits [12.0, 1.0, 102.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 970 q_vals: [-9.6, -12.8, -8.895, -9.216, -12.8, -12.8, -inf]
Step 1370 2 visits [12.0, 1.0, 103.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 971 q_vals: [-9.6, -12.8, -8.933, -9.216, -12.8, -12.8, -inf]
Step 1371 2 visits [12.0, 1.0, 104.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 972 q_vals: [-9.6, -12.8, -8.847, -9.216, -12.8, -12.8, -inf]
Step 1372 2 visits [12.0, 1.0, 105.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 972 q_vals: [-9.6, -12.8, -8.763, -9.216, -12.8, -12.8, -inf]
Step 1373 2 visits [12.0, 1.0, 106.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 973 q_vals: [-9.6, -12.8, -8.801, -9.216, -12.8, -12.8, -inf]
Step 1374 2 visits [12.0, 1.0, 107.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 974 q_vals: [-9.6, -12.8, -8.718, -9.216, -12.8, -12.8, -inf]
Step 1375 2 visits [12.0, 1.0, 108.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 974 q_vals: [-9.6, -12.8, -8.756, -9.216, -12.8, -12.8, -inf]
Step 1376 2 visits [12.0, 1.0, 109.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 974 q_vals: [-9.6, -12.8, -8.676, -9.216, -12.8, -12.8, -inf]
Step 1377 2 visits [12.0, 1.0, 110.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 974 q_vals: [-9.6, -12.8, -8.713, -9.216, -12.8, -12.8, -inf]
Step 1378 2 visits [12.0, 1.0, 111.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 977 q_vals: [-9.6, -12.8, -8.75, -9.216, -12.8, -12.8, -inf]
Step 1379 2 visits [12.0, 1.0, 112.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 977 q_vals: [-9.6, -12.8, -8.672, -9.216, -12.8, -12.8, -inf]
Step 1380 2 visits [12.0, 1.0, 113.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 977 q_vals: [-9.6, -12.8, -8.709, -9.216, -12.8, -12.8, -inf]
Step 1381 2 visits [12.0, 1.0, 114.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 977 q_vals: [-9.6, -12.8, -8.744, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 978, "number_of_timesteps": 92194, "per_episode_reward": -417.02, "episode_reward_trend_value": 0.10974561007753385, "biggest_recent_change": 2.972810738979888},
Step 1382 2 visits [12.0, 1.0, 115.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 978 q_vals: [-9.6, -12.8, -8.668, -9.216, -12.8, -12.8, -inf]
Step 1383 2 visits [12.0, 1.0, 116.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 979 q_vals: [-9.6, -12.8, -8.704, -9.216, -12.8, -12.8, -inf]
Step 1384 2 visits [12.0, 1.0, 117.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 979 q_vals: [-9.6, -12.8, -8.739, -9.216, -12.8, -12.8, -inf]
Step 1385 2 visits [12.0, 1.0, 118.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 979 q_vals: [-9.6, -12.8, -8.773, -9.216, -12.8, -12.8, -inf]
Step 1386 2 visits [12.0, 1.0, 119.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 979 q_vals: [-9.6, -12.8, -8.807, -9.216, -12.8, -12.8, -inf]
Step 1387 2 visits [12.0, 1.0, 120.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 980 q_vals: [-9.6, -12.8, -8.841, -9.216, -12.8, -12.8, -inf]
Step 1388 2 visits [12.0, 1.0, 121.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 982 q_vals: [-9.6, -12.8, -8.873, -9.216, -12.8, -12.8, -inf]
Step 1389 2 visits [12.0, 1.0, 122.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 982 q_vals: [-9.6, -12.8, -8.801, -9.216, -12.8, -12.8, -inf]
Step 1390 2 visits [12.0, 1.0, 123.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 982 q_vals: [-9.6, -12.8, -8.833, -9.216, -12.8, -12.8, -inf]
Step 1391 2 visits [12.0, 1.0, 124.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 982 q_vals: [-9.6, -12.8, -8.762, -9.216, -12.8, -12.8, -inf]
Step 1392 2 visits [12.0, 1.0, 125.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 983 q_vals: [-9.6, -12.8, -8.692, -9.216, -12.8, -12.8, -inf]
Step 1393 2 visits [12.0, 1.0, 126.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 983 q_vals: [-9.6, -12.8, -8.623, -9.216, -12.8, -12.8, -inf]
Step 1394 2 visits [12.0, 1.0, 127.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 983 q_vals: [-9.6, -12.8, -8.656, -9.216, -12.8, -12.8, -inf]
Step 1395 2 visits [12.0, 1.0, 128.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 983 q_vals: [-9.6, -12.8, -8.588, -9.216, -12.8, -12.8, -inf]
Step 1396 2 visits [12.0, 1.0, 129.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 984 q_vals: [-9.6, -12.8, -8.521, -9.216, -12.8, -12.8, -inf]
Step 1397 2 visits [12.0, 1.0, 130.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 985 q_vals: [-9.6, -12.8, -8.554, -9.216, -12.8, -12.8, -inf]
Step 1398 2 visits [12.0, 1.0, 131.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 985 q_vals: [-9.6, -12.8, -8.587, -9.216, -12.8, -12.8, -inf]
Step 1399 2 visits [12.0, 1.0, 132.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 985 q_vals: [-9.6, -12.8, -8.619, -9.216, -12.8, -12.8, -inf]
Step 1400 2 visits [12.0, 1.0, 133.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 985 q_vals: [-9.6, -12.8, -8.554, -9.216, -12.8, -12.8, -inf]
Step 1401 2 visits [12.0, 1.0, 134.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 985 q_vals: [-9.6, -12.8, -8.49, -9.216, -12.8, -12.8, -inf]
Step 1402 2 visits [12.0, 1.0, 135.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 985 q_vals: [-9.6, -12.8, -8.522, -9.216, -12.8, -12.8, -inf]
Step 1403 2 visits [12.0, 1.0, 136.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 985 q_vals: [-9.6, -12.8, -8.459, -9.216, -12.8, -12.8, -inf]
Step 1404 2 visits [12.0, 1.0, 137.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 986 q_vals: [-9.6, -12.8, -8.398, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 988, "number_of_timesteps": 93337, "per_episode_reward": -414.06, "episode_reward_trend_value": 0.14503141987727872, "biggest_recent_change": 2.972810738979888},
Step 1405 2 visits [12.0, 1.0, 138.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 988 q_vals: [-9.6, -12.8, -8.337, -9.216, -12.8, -12.8, -inf]
Step 1406 2 visits [12.0, 1.0, 139.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 989 q_vals: [-9.6, -12.8, -8.277, -9.216, -12.8, -12.8, -inf]
Step 1407 2 visits [12.0, 1.0, 140.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 989 q_vals: [-9.6, -12.8, -8.218, -9.216, -12.8, -12.8, -inf]
Step 1408 2 visits [12.0, 1.0, 141.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 989 q_vals: [-9.6, -12.8, -8.25, -9.216, -12.8, -12.8, -inf]
Step 1409 2 visits [12.0, 1.0, 142.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 989 q_vals: [-9.6, -12.8, -8.192, -9.216, -12.8, -12.8, -inf]
Step 1410 2 visits [12.0, 1.0, 143.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 989 q_vals: [-9.6, -12.8, -8.135, -9.216, -12.8, -12.8, -inf]
Step 1411 2 visits [12.0, 1.0, 144.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 990 q_vals: [-9.6, -12.8, -8.167, -9.216, -12.8, -12.8, -inf]
Step 1412 2 visits [12.0, 1.0, 145.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 990 q_vals: [-9.6, -12.8, -8.111, -9.216, -12.8, -12.8, -inf]
[-9.6, -12.8, -8.055, -9.216, -12.8, -12.8, -inf]
Step 1414 2 visits [12.0, 1.0, 147.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 993 q_vals: [-9.6, -12.8, -8.0, -9.216, -12.8, -12.8, -inf]
Step 1415 2 visits [12.0, 1.0, 148.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 993 q_vals: [-9.6, -12.8, -7.946, -9.216, -12.8, -12.8, -inf]
Step 1416 2 visits [12.0, 1.0, 149.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 995 q_vals: [-9.6, -12.8, -7.96, -9.216, -12.8, -12.8, -inf]
Step 1417 2 visits [12.0, 1.0, 150.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 995 q_vals: [-9.6, -12.8, -7.907, -9.216, -12.8, -12.8, -inf]
Step 1418 2 visits [12.0, 1.0, 151.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 995 q_vals: [-9.6, -12.8, -7.939, -9.216, -12.8, -12.8, -inf]
Step 1419 2 visits [12.0, 1.0, 152.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 996 q_vals: [-9.6, -12.8, -7.971, -9.216, -12.8, -12.8, -inf]
Step 1420 2 visits [12.0, 1.0, 153.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 997 q_vals: [-9.6, -12.8, -7.919, -9.216, -12.8, -12.8, -inf]
Step 1421 2 visits [12.0, 1.0, 154.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 997 q_vals: [-9.6, -12.8, -7.951, -9.216, -12.8, -12.8, -inf]
Step 1422 2 visits [12.0, 1.0, 155.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 997 q_vals: [-9.6, -12.8, -7.982, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 999, "number_of_timesteps": 95067, "per_episode_reward": -412.58, "episode_reward_trend_value": 0.14681486516518905, "biggest_recent_change": 2.972810738979888},
Step 1423 2 visits [12.0, 1.0, 156.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 999 q_vals: [-9.6, -12.8, -8.013, -9.216, -12.8, -12.8, -inf]
Step 1424 2 visits [12.0, 1.0, 157.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1000 q_vals: [-9.6, -12.8, -7.962, -9.216, -12.8, -12.8, -inf]
Step 1425 2 visits [12.0, 1.0, 158.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1001 q_vals: [-9.6, -12.8, -7.912, -9.216, -12.8, -12.8, -inf]
Step 1426 2 visits [12.0, 1.0, 159.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1002 q_vals: [-9.6, -12.8, -7.862, -9.216, -12.8, -12.8, -inf]
Step 1427 2 visits [12.0, 1.0, 160.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1003 q_vals: [-9.6, -12.8, -7.813, -9.216, -12.8, -12.8, -inf]
Step 1428 2 visits [12.0, 1.0, 161.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1003 q_vals: [-9.6, -12.8, -7.844, -9.216, -12.8, -12.8, -inf]
Step 1429 2 visits [12.0, 1.0, 162.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1003 q_vals: [-9.6, -12.8, -7.874, -9.216, -12.8, -12.8, -inf]
Step 1430 2 visits [12.0, 1.0, 163.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1003 q_vals: [-9.6, -12.8, -7.905, -9.216, -12.8, -12.8, -inf]
Step 1431 2 visits [12.0, 1.0, 164.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1004 q_vals: [-9.6, -12.8, -7.856, -9.216, -12.8, -12.8, -inf]
Step 1432 2 visits [12.0, 1.0, 165.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1004 q_vals: [-9.6, -12.8, -7.886, -9.216, -12.8, -12.8, -inf]
Step 1433 2 visits [12.0, 1.0, 166.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1005 q_vals: [-9.6, -12.8, -7.839, -9.216, -12.8, -12.8, -inf]
Step 1434 2 visits [12.0, 1.0, 167.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1006 q_vals: [-9.6, -12.8, -7.869, -9.216, -12.8, -12.8, -inf]
Step 1435 2 visits [12.0, 1.0, 168.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1006 q_vals: [-9.6, -12.8, -7.898, -9.216, -12.8, -12.8, -inf]
Step 1436 2 visits [12.0, 1.0, 169.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1006 q_vals: [-9.6, -12.8, -7.927, -9.216, -12.8, -12.8, -inf]
Step 1437 2 visits [12.0, 1.0, 170.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1007 q_vals: [-9.6, -12.8, -7.88, -9.216, -12.8, -12.8, -inf]
Step 1438 2 visits [12.0, 1.0, 171.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1007 q_vals: [-9.6, -12.8, -7.834, -9.216, -12.8, -12.8, -inf]
Step 1439 2 visits [12.0, 1.0, 172.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1007 q_vals: [-9.6, -12.8, -7.789, -9.216, -12.8, -12.8, -inf]
Step 1440 2 visits [12.0, 1.0, 173.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1008 q_vals: [-9.6, -12.8, -7.766, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1009, "number_of_timesteps": 96163, "per_episode_reward": -410.4, "episode_reward_trend_value": 0.2039871714502346, "biggest_recent_change": 2.9539436306635594},
Step 1441 2 visits [12.0, 1.0, 174.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1009 q_vals: [-9.6, -12.8, -7.795, -9.216, -12.8, -12.8, -inf]
Step 1442 2 visits [12.0, 1.0, 175.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1009 q_vals: [-9.6, -12.8, -7.824, -9.216, -12.8, -12.8, -inf]
Step 1443 2 visits [12.0, 1.0, 176.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1009 q_vals: [-9.6, -12.8, -7.779, -9.216, -12.8, -12.8, -inf]
Step 1444 2 visits [12.0, 1.0, 177.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1009 q_vals: [-9.6, -12.8, -7.735, -9.216, -12.8, -12.8, -inf]
Step 1445 2 visits [12.0, 1.0, 178.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1009 q_vals: [-9.6, -12.8, -7.692, -9.216, -12.8, -12.8, -inf]
Step 1446 2 visits [12.0, 1.0, 179.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1009 q_vals: [-9.6, -12.8, -7.721, -9.216, -12.8, -12.8, -inf]
Step 1447 2 visits [12.0, 1.0, 180.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1010 q_vals: [-9.6, -12.8, -7.705, -9.216, -12.8, -12.8, -inf]
Step 1448 2 visits [12.0, 1.0, 181.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1014 q_vals: [-9.6, -12.8, -7.662, -9.216, -12.8, -12.8, -inf]
Step 1449 2 visits [12.0, 1.0, 182.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1015 q_vals: [-9.6, -12.8, -7.69, -9.216, -12.8, -12.8, -inf]
Step 1450 2 visits [12.0, 1.0, 183.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1015 q_vals: [-9.6, -12.8, -7.648, -9.216, -12.8, -12.8, -inf]
Step 1451 2 visits [12.0, 1.0, 184.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1015 q_vals: [-9.6, -12.8, -7.607, -9.216, -12.8, -12.8, -inf]
Step 1452 2 visits [12.0, 1.0, 185.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1015 q_vals: [-9.6, -12.8, -7.635, -9.216, -12.8, -12.8, -inf]
[12.0, 1.0, 186.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1017 q_vals: [-9.6, -12.8, -7.663, -9.216, -12.8, -12.8, -inf]
Step 1454 2 visits [12.0, 1.0, 187.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1017 q_vals: [-9.6, -12.8, -7.69, -9.216, -12.8, -12.8, -inf]
Step 1455 2 visits [12.0, 1.0, 188.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1018 q_vals: [-9.6, -12.8, -7.717, -9.216, -12.8, -12.8, -inf]
Step 1456 2 visits [12.0, 1.0, 189.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1018 q_vals: [-9.6, -12.8, -7.744, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1019, "number_of_timesteps": 97323, "per_episode_reward": -408.34, "episode_reward_trend_value": 0.22956247238604988, "biggest_recent_change": 2.9539436306635594},
Step 1457 2 visits [12.0, 1.0, 190.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1019 q_vals: [-9.6, -12.8, -7.771, -9.216, -12.8, -12.8, -inf]
Step 1458 2 visits [12.0, 1.0, 191.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1019 q_vals: [-9.6, -12.8, -7.797, -9.216, -12.8, -12.8, -inf]
Step 1459 2 visits [12.0, 1.0, 192.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1019 q_vals: [-9.6, -12.8, -7.756, -9.216, -12.8, -12.8, -inf]
Step 1460 2 visits [12.0, 1.0, 193.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1020 q_vals: [-9.6, -12.8, -7.776, -9.216, -12.8, -12.8, -inf]
Step 1461 2 visits [12.0, 1.0, 194.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1021 q_vals: [-9.6, -12.8, -7.736, -9.216, -12.8, -12.8, -inf]
Step 1462 2 visits [12.0, 1.0, 195.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1021 q_vals: [-9.6, -12.8, -7.762, -9.216, -12.8, -12.8, -inf]
Step 1463 2 visits [12.0, 1.0, 196.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1021 q_vals: [-9.6, -12.8, -7.788, -9.216, -12.8, -12.8, -inf]
Step 1464 2 visits [12.0, 1.0, 197.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1021 q_vals: [-9.6, -12.8, -7.813, -9.216, -12.8, -12.8, -inf]
Step 1465 2 visits [12.0, 1.0, 198.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1021 q_vals: [-9.6, -12.8, -7.839, -9.216, -12.8, -12.8, -inf]
Step 1466 2 visits [12.0, 1.0, 199.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1022 q_vals: [-9.6, -12.8, -7.864, -9.216, -12.8, -12.8, -inf]
Step 1467 2 visits [12.0, 1.0, 200.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1022 q_vals: [-9.6, -12.8, -7.888, -9.216, -12.8, -12.8, -inf]
Step 1468 2 visits [12.0, 1.0, 201.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1023 q_vals: [-9.6, -12.8, -7.913, -9.216, -12.8, -12.8, -inf]
Step 1469 2 visits [12.0, 1.0, 202.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1023 q_vals: [-9.6, -12.8, -7.873, -9.216, -12.8, -12.8, -inf]
Step 1470 2 visits [12.0, 1.0, 203.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1026 q_vals: [-9.6, -12.8, -7.835, -9.216, -12.8, -12.8, -inf]
Step 1471 2 visits [12.0, 1.0, 204.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1026 q_vals: [-9.6, -12.8, -7.796, -9.216, -12.8, -12.8, -inf]
Step 1472 2 visits [12.0, 1.0, 205.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1026 q_vals: [-9.6, -12.8, -7.821, -9.216, -12.8, -12.8, -inf]
Step 1473 2 visits [12.0, 1.0, 206.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1026 q_vals: [-9.6, -12.8, -7.845, -9.216, -12.8, -12.8, -inf]
Step 1474 2 visits [12.0, 1.0, 207.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1026 q_vals: [-9.6, -12.8, -7.869, -9.216, -12.8, -12.8, -inf]
Step 1475 2 visits [12.0, 1.0, 208.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1026 q_vals: [-9.6, -12.8, -7.892, -9.216, -12.8, -12.8, -inf]
Step 1476 2 visits [12.0, 1.0, 209.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1027 q_vals: [-9.6, -12.8, -7.916, -9.216, -12.8, -12.8, -inf]
Step 1477 2 visits [12.0, 1.0, 210.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1027 q_vals: [-9.6, -12.8, -7.878, -9.216, -12.8, -12.8, -inf]
Step 1478 2 visits [12.0, 1.0, 211.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1027 q_vals: [-9.6, -12.8, -7.902, -9.216, -12.8, -12.8, -inf]
Step 1479 2 visits [12.0, 1.0, 212.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1028 q_vals: [-9.6, -12.8, -7.864, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1029, "number_of_timesteps": 98548, "per_episode_reward": -404.91, "episode_reward_trend_value": 0.2547284012431425, "biggest_recent_change": 3.4311825200097132},
Step 1480 2 visits [12.0, 1.0, 213.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1029 q_vals: [-9.6, -12.8, -7.888, -9.216, -12.8, -12.8, -inf]
Step 1481 2 visits [12.0, 1.0, 214.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1029 q_vals: [-9.6, -12.8, -7.91, -9.216, -12.8, -12.8, -inf]
Step 1482 2 visits [12.0, 1.0, 215.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1030 q_vals: [-9.6, -12.8, -7.874, -9.216, -12.8, -12.8, -inf]
Step 1483 2 visits [12.0, 1.0, 216.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1031 q_vals: [-9.6, -12.8, -7.896, -9.216, -12.8, -12.8, -inf]
Step 1484 2 visits [12.0, 1.0, 217.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1032 q_vals: [-9.6, -12.8, -7.86, -9.216, -12.8, -12.8, -inf]
Step 1485 2 visits [12.0, 1.0, 218.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1032 q_vals: [-9.6, -12.8, -7.883, -9.216, -12.8, -12.8, -inf]
Step 1486 2 visits [12.0, 1.0, 219.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1032 q_vals: [-9.6, -12.8, -7.905, -9.216, -12.8, -12.8, -inf]
Step 1487 2 visits [12.0, 1.0, 220.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1032 q_vals: [-9.6, -12.8, -7.927, -9.216, -12.8, -12.8, -inf]
Step 1488 2 visits [12.0, 1.0, 221.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1033 q_vals: [-9.6, -12.8, -7.949, -9.216, -12.8, -12.8, -inf]
Step 1489 2 visits [12.0, 1.0, 222.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1034 q_vals: [-9.6, -12.8, -7.914, -9.216, -12.8, -12.8, -inf]
Step 1490 2 visits [12.0, 1.0, 223.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1035 q_vals: [-9.6, -12.8, -7.936, -9.216, -12.8, -12.8, -inf]
Step 1491 2 visits [12.0, 1.0, 224.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1035 q_vals: [-9.6, -12.8, -7.957, -9.216, -12.8, -12.8, -inf]
Step 1492 2 visits [12.0, 1.0, 225.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1036 q_vals: [-9.6, -12.8, -7.979, -9.216, -12.8, -12.8, -inf]
Step 1493 2 visits [12.0, 1.0, 226.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1037 q_vals: [-9.6, -12.8, -8.0, -9.216, -12.8, -12.8, -inf]
Step 1494 2 visits [12.0, 1.0, 227.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1037 q_vals: [-9.6, -12.8, -8.021, -9.216, -12.8, -12.8, -inf]
Step 1495 2 visits [12.0, 1.0, 228.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1037 q_vals: [-9.6, -12.8, -7.986, -9.216, -12.8, -12.8, -inf]
Step 1496 2 visits [12.0, 1.0, 229.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1038 q_vals: [-9.6, -12.8, -8.007, -9.216, -12.8, -12.8, -inf]
Step 1497 2 visits [12.0, 1.0, 230.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1038 q_vals: [-9.6, -12.8, -8.028, -9.216, -12.8, -12.8, -inf]
Step 1498 2 visits [12.0, 1.0, 231.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1038 q_vals: [-9.6, -12.8, -8.049, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1040, "number_of_timesteps": 100078, "per_episode_reward": -403.48, "episode_reward_trend_value": 0.23853061030804762, "biggest_recent_change": 3.4311825200097132},
Step 1499 2 visits [12.0, 1.0, 232.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1040 q_vals: [-9.6, -12.8, -8.069, -9.216, -12.8, -12.8, -inf]
Step 1500 2 visits [12.0, 1.0, 233.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1041 q_vals: [-9.6, -12.8, -8.034, -9.216, -12.8, -12.8, -inf]
Step 1501 2 visits [12.0, 1.0, 234.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1041 q_vals: [-9.6, -12.8, -8.0, -9.216, -12.8, -12.8, -inf]
Step 1502 2 visits [12.0, 1.0, 235.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1042 q_vals: [-9.6, -12.8, -8.021, -9.216, -12.8, -12.8, -inf]
Step 1503 2 visits [12.0, 1.0, 236.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1042 q_vals: [-9.6, -12.8, -8.041, -9.216, -12.8, -12.8, -inf]
Step 1504 2 visits [12.0, 1.0, 237.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1043 q_vals: [-9.6, -12.8, -8.061, -9.216, -12.8, -12.8, -inf]
Step 1505 2 visits [12.0, 1.0, 238.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1044 q_vals: [-9.6, -12.8, -8.081, -9.216, -12.8, -12.8, -inf]
Step 1506 2 visits [12.0, 1.0, 239.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1045 q_vals: [-9.6, -12.8, -8.101, -9.216, -12.8, -12.8, -inf]
Step 1507 2 visits [12.0, 1.0, 240.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1046 q_vals: [-9.6, -12.8, -8.12, -9.216, -12.8, -12.8, -inf]
Step 1508 2 visits [12.0, 1.0, 241.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1046 q_vals: [-9.6, -12.8, -8.14, -9.216, -12.8, -12.8, -inf]
Step 1509 2 visits [12.0, 1.0, 242.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1047 q_vals: [-9.6, -12.8, -8.106, -9.216, -12.8, -12.8, -inf]
Step 1510 2 visits [12.0, 1.0, 243.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1047 q_vals: [-9.6, -12.8, -8.125, -9.216, -12.8, -12.8, -inf]
Step 1511 2 visits [12.0, 1.0, 244.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1048 q_vals: [-9.6, -12.8, -8.092, -9.216, -12.8, -12.8, -inf]
Step 1512 2 visits [12.0, 1.0, 245.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1049 q_vals: [-9.6, -12.8, -8.111, -9.216, -12.8, -12.8, -inf]
Step 1513 2 visits [12.0, 1.0, 246.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1049 q_vals: [-9.6, -12.8, -8.13, -9.216, -12.8, -12.8, -inf]
Step 1514 2 visits [12.0, 1.0, 247.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1049 q_vals: [-9.6, -12.8, -8.097, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1051, "number_of_timesteps": 101305, "per_episode_reward": -398.09, "episode_reward_trend_value": 0.2696690323176218, "biggest_recent_change": 5.393170835618321},
Step 1515 2 visits [12.0, 1.0, 248.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1051 q_vals: [-9.6, -12.8, -8.065, -9.216, -12.8, -12.8, -inf]
Step 1516 2 visits [12.0, 1.0, 249.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1051 q_vals: [-9.6, -12.8, -8.084, -9.216, -12.8, -12.8, -inf]
Step 1517 2 visits [12.0, 1.0, 250.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1052 q_vals: [-9.6, -12.8, -8.103, -9.216, -12.8, -12.8, -inf]
Step 1518 2 visits [12.0, 1.0, 251.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1054 q_vals: [-9.6, -12.8, -8.121, -9.216, -12.8, -12.8, -inf]
Step 1519 2 visits [12.0, 1.0, 252.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1054 q_vals: [-9.6, -12.8, -8.14, -9.216, -12.8, -12.8, -inf]
Step 1520 2 visits [12.0, 1.0, 253.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1054 q_vals: [-9.6, -12.8, -8.158, -9.216, -12.8, -12.8, -inf]
Step 1521 2 visits [12.0, 1.0, 254.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1054 q_vals: [-9.6, -12.8, -8.177, -9.216, -12.8, -12.8, -inf]
Step 1522 2 visits [12.0, 1.0, 255.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1054 q_vals: [-9.6, -12.8, -8.144, -9.216, -12.8, -12.8, -inf]
Step 1523 2 visits [12.0, 1.0, 256.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1056 q_vals: [-9.6, -12.8, -8.163, -9.216, -12.8, -12.8, -inf]
Step 1524 2 visits [12.0, 1.0, 257.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1056 q_vals: [-9.6, -12.8, -8.181, -9.216, -12.8, -12.8, -inf]
Step 1525 2 visits [12.0, 1.0, 258.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1057 q_vals: [-9.6, -12.8, -8.149, -9.216, -12.8, -12.8, -inf]
Step 1526 2 visits [12.0, 1.0, 259.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1057 q_vals: [-9.6, -12.8, -8.118, -9.216, -12.8, -12.8, -inf]
Step 1527 2 visits [12.0, 1.0, 260.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1058 q_vals: [-9.6, -12.8, -8.136, -9.216, -12.8, -12.8, -inf]
Step 1528 2 visits [12.0, 1.0, 261.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1060 q_vals: [-9.6, -12.8, -8.104, -9.216, -12.8, -12.8, -inf]
Step 1529 2 visits [12.0, 1.0, 262.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1060 q_vals: [-9.6, -12.8, -8.073, -9.216, -12.8, -12.8, -inf]
Step 1530 2 visits [12.0, 1.0, 263.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1060 q_vals: [-9.6, -12.8, -8.091, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1061, "number_of_timesteps": 102352, "per_episode_reward": -396.1, "episode_reward_trend_value": 0.2623873834137145, "biggest_recent_change": 5.393170835618321},
Step 1531 2 visits [12.0, 1.0, 264.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1061 q_vals: [-9.6, -12.8, -8.109, -9.216, -12.8, -12.8, -inf]
Step 1532 2 visits [12.0, 1.0, 265.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1061 q_vals: [-9.6, -12.8, -8.127, -9.216, -12.8, -12.8, -inf]
Step 1533 2 visits [12.0, 1.0, 266.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1062 q_vals: [-9.6, -12.8, -8.096, -9.216, -12.8, -12.8, -inf]
Step 1534 2 visits [12.0, 1.0, 267.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1062 q_vals: [-9.6, -12.8, -8.114, -9.216, -12.8, -12.8, -inf]
Step 1535 2 visits [12.0, 1.0, 268.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1064 q_vals: [-9.6, -12.8, -8.131, -9.216, -12.8, -12.8, -inf]
Step 1536 2 visits [12.0, 1.0, 269.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1064 q_vals: [-9.6, -12.8, -8.101, -9.216, -12.8, -12.8, -inf]
Step 1537 2 visits [12.0, 1.0, 270.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1066 q_vals: [-9.6, -12.8, -8.119, -9.216, -12.8, -12.8, -inf]
Step 1538 2 visits [12.0, 1.0, 271.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1066 q_vals: [-9.6, -12.8, -8.089, -9.216, -12.8, -12.8, -inf]
Step 1539 2 visits [12.0, 1.0, 272.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1066 q_vals: [-9.6, -12.8, -8.106, -9.216, -12.8, -12.8, -inf]
Step 1540 2 visits [12.0, 1.0, 273.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1066 q_vals: [-9.6, -12.8, -8.123, -9.216, -12.8, -12.8, -inf]
Step 1541 2 visits [12.0, 1.0, 274.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1068 q_vals: [-9.6, -12.8, -8.14, -9.216, -12.8, -12.8, -inf]
Step 1542 2 visits [12.0, 1.0, 275.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1068 q_vals: [-9.6, -12.8, -8.157, -9.216, -12.8, -12.8, -inf]
Step 1543 2 visits [12.0, 1.0, 276.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1069 q_vals: [-9.6, -12.8, -8.174, -9.216, -12.8, -12.8, -inf]
Step 1544 2 visits [12.0, 1.0, 277.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1070 q_vals: [-9.6, -12.8, -8.145, -9.216, -12.8, -12.8, -inf]
Step 1545 2 visits [12.0, 1.0, 278.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1070 q_vals: [-9.6, -12.8, -8.115, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1071, "number_of_timesteps": 103338, "per_episode_reward": -394.56, "episode_reward_trend_value": 0.24954831951280818, "biggest_recent_change": 5.393170835618321},
Step 1546 2 visits [12.0, 1.0, 279.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1071 q_vals: [-9.6, -12.8, -8.132, -9.216, -12.8, -12.8, -inf]
Step 1547 2 visits [12.0, 1.0, 280.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1073 q_vals: [-9.6, -12.8, -8.103, -9.216, -12.8, -12.8, -inf]
Step 1548 2 visits [12.0, 1.0, 281.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1074 q_vals: [-9.6, -12.8, -8.12, -9.216, -12.8, -12.8, -inf]
Step 1549 2 visits [12.0, 1.0, 282.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1074 q_vals: [-9.6, -12.8, -8.136, -9.216, -12.8, -12.8, -inf]
Step 1550 2 visits [12.0, 1.0, 283.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1075 q_vals: [-9.6, -12.8, -8.108, -9.216, -12.8, -12.8, -inf]
Step 1551 2 visits [12.0, 1.0, 284.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1075 q_vals: [-9.6, -12.8, -8.124, -9.216, -12.8, -12.8, -inf]
Step 1552 2 visits [12.0, 1.0, 285.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1076 q_vals: [-9.6, -12.8, -8.096, -9.216, -12.8, -12.8, -inf]
Step 1553 2 visits [12.0, 1.0, 286.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1076 q_vals: [-9.6, -12.8, -8.112, -9.216, -12.8, -12.8, -inf]
Step 1554 2 visits [12.0, 1.0, 287.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1077 q_vals: [-9.6, -12.8, -8.128, -9.216, -12.8, -12.8, -inf]
Step 1555 2 visits [12.0, 1.0, 288.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1078 q_vals: [-9.6, -12.8, -8.145, -9.216, -12.8, -12.8, -inf]
Step 1556 2 visits [12.0, 1.0, 289.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1079 q_vals: [-9.6, -12.8, -8.161, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1081, "number_of_timesteps": 104244, "per_episode_reward": -393.23, "episode_reward_trend_value": 0.23147765192794179, "biggest_recent_change": 5.393170835618321},
Step 1557 2 visits [12.0, 1.0, 290.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1081 q_vals: [-9.6, -12.8, -8.133, -9.216, -12.8, -12.8, -inf]
Step 1558 2 visits [12.0, 1.0, 291.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1081 q_vals: [-9.6, -12.8, -8.149, -9.216, -12.8, -12.8, -inf]
Step 1559 2 visits [12.0, 1.0, 292.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1081 q_vals: [-9.6, -12.8, -8.165, -9.216, -12.8, -12.8, -inf]
Step 1560 2 visits [12.0, 1.0, 293.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1081 q_vals: [-9.6, -12.8, -8.18, -9.216, -12.8, -12.8, -inf]
Step 1561 2 visits [12.0, 1.0, 294.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1082 q_vals: [-9.6, -12.8, -8.153, -9.216, -12.8, -12.8, -inf]
Step 1562 2 visits [12.0, 1.0, 295.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1082 q_vals: [-9.6, -12.8, -8.125, -9.216, -12.8, -12.8, -inf]
Step 1563 2 visits [12.0, 1.0, 296.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1082 q_vals: [-9.6, -12.8, -8.097, -9.216, -12.8, -12.8, -inf]
Step 1564 2 visits [12.0, 1.0, 297.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1082 q_vals: [-9.6, -12.8, -8.07, -9.216, -12.8, -12.8, -inf]
Step 1565 2 visits [12.0, 1.0, 298.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1082 q_vals: [-9.6, -12.8, -8.086, -9.216, -12.8, -12.8, -inf]
Step 1566 2 visits [12.0, 1.0, 299.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1084 q_vals: [-9.6, -12.8, -8.102, -9.216, -12.8, -12.8, -inf]
Step 1567 2 visits [12.0, 1.0, 300.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1086 q_vals: [-9.6, -12.8, -8.117, -9.216, -12.8, -12.8, -inf]
Step 1568 2 visits [12.0, 1.0, 301.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1086 q_vals: [-9.6, -12.8, -8.133, -9.216, -12.8, -12.8, -inf]
Step 1569 2 visits [12.0, 1.0, 302.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1086 q_vals: [-9.6, -12.8, -8.148, -9.216, -12.8, -12.8, -inf]
Step 1570 2 visits [12.0, 1.0, 303.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1086 q_vals: [-9.6, -12.8, -8.164, -9.216, -12.8, -12.8, -inf]
Step 1571 2 visits [12.0, 1.0, 304.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1086 q_vals: [-9.6, -12.8, -8.179, -9.216, -12.8, -12.8, -inf]
Step 1572 2 visits [12.0, 1.0, 305.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1086 q_vals: [-9.6, -12.8, -8.152, -9.216, -12.8, -12.8, -inf]
Step 1573 2 visits [12.0, 1.0, 306.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1086 q_vals: [-9.6, -12.8, -8.167, -9.216, -12.8, -12.8, -inf]
Step 1574 2 visits [12.0, 1.0, 307.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1087 q_vals: [-9.6, -12.8, -8.183, -9.216, -12.8, -12.8, -inf]
Step 1575 2 visits [12.0, 1.0, 308.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1088 q_vals: [-9.6, -12.8, -8.198, -9.216, -12.8, -12.8, -inf]
Step 1576 2 visits [12.0, 1.0, 309.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1089 q_vals: [-9.6, -12.8, -8.212, -9.216, -12.8, -12.8, -inf]
Step 1577 2 visits [12.0, 1.0, 310.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1089 q_vals: [-9.6, -12.8, -8.227, -9.216, -12.8, -12.8, -inf]
Step 1578 2 visits [12.0, 1.0, 311.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1089 q_vals: [-9.6, -12.8, -8.242, -9.216, -12.8, -12.8, -inf]
Step 1579 2 visits [12.0, 1.0, 312.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1089 q_vals: [-9.6, -12.8, -8.257, -9.216, -12.8, -12.8, -inf]
Step 1580 2 visits [12.0, 1.0, 313.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1089 q_vals: [-9.6, -12.8, -8.23, -9.216, -12.8, -12.8, -inf]
Step 1581 2 visits [12.0, 1.0, 314.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1089 q_vals: [-9.6, -12.8, -8.245, -9.216, -12.8, -12.8, -inf]
Step 1582 2 visits [12.0, 1.0, 315.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1090 q_vals: [-9.6, -12.8, -8.259, -9.216, -12.8, -12.8, -inf]
Step 1583 2 visits [12.0, 1.0, 316.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1090 q_vals: [-9.6, -12.8, -8.233, -9.216, -12.8, -12.8, -inf]
Step 1584 2 visits [12.0, 1.0, 317.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1090 q_vals: [-9.6, -12.8, -8.247, -9.216, -12.8, -12.8, -inf]
Step 1585 2 visits [12.0, 1.0, 318.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1090 q_vals: [-9.6, -12.8, -8.262, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1091, "number_of_timesteps": 105486, "per_episode_reward": -391.56, "episode_reward_trend_value": 0.23346519075679076, "biggest_recent_change": 5.393170835618321},
Step 1586 2 visits [12.0, 1.0, 319.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1091 q_vals: [-9.6, -12.8, -8.236, -9.216, -12.8, -12.8, -inf]
Step 1587 2 visits [12.0, 1.0, 320.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1093 q_vals: [-9.6, -12.8, -8.21, -9.216, -12.8, -12.8, -inf]
Step 1588 2 visits [12.0, 1.0, 321.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1093 q_vals: [-9.6, -12.8, -8.224, -9.216, -12.8, -12.8, -inf]
Step 1589 2 visits [12.0, 1.0, 322.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1093 q_vals: [-9.6, -12.8, -8.239, -9.216, -12.8, -12.8, -inf]
Step 1590 2 visits [12.0, 1.0, 323.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1094 q_vals: [-9.6, -12.8, -8.253, -9.216, -12.8, -12.8, -inf]
Step 1591 2 visits [12.0, 1.0, 324.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1095 q_vals: [-9.6, -12.8, -8.267, -9.216, -12.8, -12.8, -inf]
Step 1592 2 visits [12.0, 1.0, 325.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1095 q_vals: [-9.6, -12.8, -8.281, -9.216, -12.8, -12.8, -inf]
Step 1593 2 visits [12.0, 1.0, 326.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1095 q_vals: [-9.6, -12.8, -8.266, -9.216, -12.8, -12.8, -inf]
Step 1594 2 visits [12.0, 1.0, 327.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1095 q_vals: [-9.6, -12.8, -8.279, -9.216, -12.8, -12.8, -inf]
Step 1595 2 visits [12.0, 1.0, 328.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1096 q_vals: [-9.6, -12.8, -8.293, -9.216, -12.8, -12.8, -inf]
Step 1596 2 visits [12.0, 1.0, 329.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1098 q_vals: [-9.6, -12.8, -8.307, -9.216, -12.8, -12.8, -inf]
Step 1597 2 visits [12.0, 1.0, 330.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1098 q_vals: [-9.6, -12.8, -8.282, -9.216, -12.8, -12.8, -inf]
Step 1598 2 visits [12.0, 1.0, 331.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1099 q_vals: [-9.6, -12.8, -8.257, -9.216, -12.8, -12.8, -inf]
Step 1599 2 visits [12.0, 1.0, 332.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1100 q_vals: [-9.6, -12.8, -8.232, -9.216, -12.8, -12.8, -inf]
Step 1600 2 visits [12.0, 1.0, 333.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1100 q_vals: [-9.6, -12.8, -8.207, -9.216, -12.8, -12.8, -inf]
Step 1601 2 visits [12.0, 1.0, 334.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1100 q_vals: [-9.6, -12.8, -8.183, -9.216, -12.8, -12.8, -inf]
Step 1602 2 visits [12.0, 1.0, 335.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1100 q_vals: [-9.6, -12.8, -8.196, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1102, "number_of_timesteps": 107149, "per_episode_reward": -390.97, "episode_reward_trend_value": 0.21589739154858245, "biggest_recent_change": 5.393170835618321},
Step 1603 2 visits [12.0, 1.0, 336.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1102 q_vals: [-9.6, -12.8, -8.172, -9.216, -12.8, -12.8, -inf]
Step 1604 2 visits [12.0, 1.0, 337.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1102 q_vals: [-9.6, -12.8, -8.148, -9.216, -12.8, -12.8, -inf]
Step 1605 2 visits [12.0, 1.0, 338.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1103 q_vals: [-9.6, -12.8, -8.161, -9.216, -12.8, -12.8, -inf]
Step 1606 2 visits [12.0, 1.0, 339.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1103 q_vals: [-9.6, -12.8, -8.175, -9.216, -12.8, -12.8, -inf]
Step 1607 2 visits [12.0, 1.0, 340.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1104 q_vals: [-9.6, -12.8, -8.151, -9.216, -12.8, -12.8, -inf]
Step 1608 2 visits [12.0, 1.0, 341.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1104 q_vals: [-9.6, -12.8, -8.127, -9.216, -12.8, -12.8, -inf]
Step 1609 2 visits [12.0, 1.0, 342.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1104 q_vals: [-9.6, -12.8, -8.103, -9.216, -12.8, -12.8, -inf]
Step 1610 2 visits [12.0, 1.0, 343.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1104 q_vals: [-9.6, -12.8, -8.08, -9.216, -12.8, -12.8, -inf]
Step 1611 2 visits [12.0, 1.0, 344.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1105 q_vals: [-9.6, -12.8, -8.056, -9.216, -12.8, -12.8, -inf]
Step 1612 2 visits [12.0, 1.0, 345.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1105 q_vals: [-9.6, -12.8, -8.07, -9.216, -12.8, -12.8, -inf]
Step 1613 2 visits [12.0, 1.0, 346.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1105 q_vals: [-9.6, -12.8, -8.084, -9.216, -12.8, -12.8, -inf]
Step 1614 2 visits [12.0, 1.0, 347.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1106 q_vals: [-9.6, -12.8, -8.06, -9.216, -12.8, -12.8, -inf]
Step 1615 2 visits [12.0, 1.0, 348.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1108 q_vals: [-9.6, -12.8, -8.074, -9.216, -12.8, -12.8, -inf]
Step 1616 2 visits [12.0, 1.0, 349.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1110 q_vals: [-9.6, -12.8, -8.088, -9.216, -12.8, -12.8, -inf]
Step 1617 2 visits [12.0, 1.0, 350.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1110 q_vals: [-9.6, -12.8, -8.101, -9.216, -12.8, -12.8, -inf]
Step 1618 2 visits [12.0, 1.0, 351.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1110 q_vals: [-9.6, -12.8, -8.114, -9.216, -12.8, -12.8, -inf]
Step 1619 2 visits [12.0, 1.0, 352.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1111 q_vals: [-9.6, -12.8, -8.091, -9.216, -12.8, -12.8, -inf]
Step 1620 2 visits [12.0, 1.0, 353.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1111 q_vals: [-9.6, -12.8, -8.105, -9.216, -12.8, -12.8, -inf]
Step 1621 2 visits [12.0, 1.0, 354.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1111 q_vals: [-9.6, -12.8, -8.118, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1112, "number_of_timesteps": 108399, "per_episode_reward": -389.03, "episode_reward_trend_value": 0.2145826045552187, "biggest_recent_change": 5.393170835618321},
Step 1622 2 visits [12.0, 1.0, 355.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1112 q_vals: [-9.6, -12.8, -8.131, -9.216, -12.8, -12.8, -inf]
Step 1623 2 visits [12.0, 1.0, 356.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1113 q_vals: [-9.6, -12.8, -8.144, -9.216, -12.8, -12.8, -inf]
Step 1624 2 visits [12.0, 1.0, 357.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1115 q_vals: [-9.6, -12.8, -8.157, -9.216, -12.8, -12.8, -inf]
Step 1625 2 visits [12.0, 1.0, 358.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1115 q_vals: [-9.6, -12.8, -8.17, -9.216, -12.8, -12.8, -inf]
Step 1626 2 visits [12.0, 1.0, 359.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1115 q_vals: [-9.6, -12.8, -8.183, -9.216, -12.8, -12.8, -inf]
Step 1627 2 visits [12.0, 1.0, 360.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1115 q_vals: [-9.6, -12.8, -8.18, -9.216, -12.8, -12.8, -inf]
Step 1628 2 visits [12.0, 1.0, 361.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1117 q_vals: [-9.6, -12.8, -8.193, -9.216, -12.8, -12.8, -inf]
Step 1629 2 visits [12.0, 1.0, 362.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1117 q_vals: [-9.6, -12.8, -8.205, -9.216, -12.8, -12.8, -inf]
Step 1630 2 visits [12.0, 1.0, 363.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1117 q_vals: [-9.6, -12.8, -8.183, -9.216, -12.8, -12.8, -inf]
Step 1631 2 visits [12.0, 1.0, 364.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1118 q_vals: [-9.6, -12.8, -8.195, -9.216, -12.8, -12.8, -inf]
Step 1632 2 visits [12.0, 1.0, 365.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1119 q_vals: [-9.6, -12.8, -8.208, -9.216, -12.8, -12.8, -inf]
Step 1633 2 visits [12.0, 1.0, 366.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1120 q_vals: [-9.6, -12.8, -8.22, -9.216, -12.8, -12.8, -inf]
Step 1634 2 visits [12.0, 1.0, 367.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1121 q_vals: [-9.6, -12.8, -8.198, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1123, "number_of_timesteps": 109522, "per_episode_reward": -388.06, "episode_reward_trend_value": 0.18725740242617614, "biggest_recent_change": 5.393170835618321},
Step 1635 2 visits [12.0, 1.0, 368.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1123 q_vals: [-9.6, -12.8, -8.211, -9.216, -12.8, -12.8, -inf]
Step 1636 2 visits [12.0, 1.0, 369.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1123 q_vals: [-9.6, -12.8, -8.223, -9.216, -12.8, -12.8, -inf]
Step 1637 2 visits [12.0, 1.0, 370.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1123 q_vals: [-9.6, -12.8, -8.201, -9.216, -12.8, -12.8, -inf]
Step 1638 2 visits [12.0, 1.0, 371.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1124 q_vals: [-9.6, -12.8, -8.2, -9.216, -12.8, -12.8, -inf]
Step 1639 2 visits [12.0, 1.0, 372.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1124 q_vals: [-9.6, -12.8, -8.212, -9.216, -12.8, -12.8, -inf]
Step 1640 2 visits [12.0, 1.0, 373.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1124 q_vals: [-9.6, -12.8, -8.224, -9.216, -12.8, -12.8, -inf]
Step 1641 2 visits [12.0, 1.0, 374.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1124 q_vals: [-9.6, -12.8, -8.202, -9.216, -12.8, -12.8, -inf]
Step 1642 2 visits [12.0, 1.0, 375.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1125 q_vals: [-9.6, -12.8, -8.18, -9.216, -12.8, -12.8, -inf]
Step 1643 2 visits [12.0, 1.0, 376.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1126 q_vals: [-9.6, -12.8, -8.193, -9.216, -12.8, -12.8, -inf]
Step 1644 2 visits [12.0, 1.0, 377.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1128 q_vals: [-9.6, -12.8, -8.205, -9.216, -12.8, -12.8, -inf]
Step 1645 2 visits [12.0, 1.0, 378.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1129 q_vals: [-9.6, -12.8, -8.217, -9.216, -12.8, -12.8, -inf]
Step 1646 2 visits [12.0, 1.0, 379.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1129 q_vals: [-9.6, -12.8, -8.229, -9.216, -12.8, -12.8, -inf]
Step 1647 2 visits [12.0, 1.0, 380.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1129 q_vals: [-9.6, -12.8, -8.241, -9.216, -12.8, -12.8, -inf]
Step 1648 2 visits [12.0, 1.0, 381.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1129 q_vals: [-9.6, -12.8, -8.22, -9.216, -12.8, -12.8, -inf]
Step 1649 2 visits [12.0, 1.0, 382.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1130 q_vals: [-9.6, -12.8, -8.198, -9.216, -12.8, -12.8, -inf]
Step 1650 2 visits [12.0, 1.0, 383.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1130 q_vals: [-9.6, -12.8, -8.21, -9.216, -12.8, -12.8, -inf]
Step 1651 2 visits [12.0, 1.0, 384.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1130 q_vals: [-9.6, -12.8, -8.222, -9.216, -12.8, -12.8, -inf]
Step 1652 2 visits [12.0, 1.0, 385.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1131 q_vals: [-9.6, -12.8, -8.234, -9.216, -12.8, -12.8, -inf]
Step 1653 2 visits [12.0, 1.0, 386.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1132 q_vals: [-9.6, -12.8, -8.213, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1133, "number_of_timesteps": 110597, "per_episode_reward": -386.38, "episode_reward_trend_value": 0.1900021965291627, "biggest_recent_change": 5.393170835618321},
Step 1654 2 visits [12.0, 1.0, 387.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1133 q_vals: [-9.6, -12.8, -8.191, -9.216, -12.8, -12.8, -inf]
Step 1655 2 visits [12.0, 1.0, 388.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1133 q_vals: [-9.6, -12.8, -8.17, -9.216, -12.8, -12.8, -inf]
Step 1656 2 visits [12.0, 1.0, 389.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1133 q_vals: [-9.6, -12.8, -8.182, -9.216, -12.8, -12.8, -inf]
Step 1657 2 visits [12.0, 1.0, 390.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1133 q_vals: [-9.6, -12.8, -8.161, -9.216, -12.8, -12.8, -inf]
Step 1658 2 visits [12.0, 1.0, 391.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1133 q_vals: [-9.6, -12.8, -8.173, -9.216, -12.8, -12.8, -inf]
Step 1659 2 visits [12.0, 1.0, 392.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1135 q_vals: [-9.6, -12.8, -8.185, -9.216, -12.8, -12.8, -inf]
Step 1660 2 visits [12.0, 1.0, 393.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1135 q_vals: [-9.6, -12.8, -8.197, -9.216, -12.8, -12.8, -inf]
Step 1661 2 visits [12.0, 1.0, 394.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1136 q_vals: [-9.6, -12.8, -8.208, -9.216, -12.8, -12.8, -inf]
Step 1662 2 visits [12.0, 1.0, 395.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1138 q_vals: [-9.6, -12.8, -8.22, -9.216, -12.8, -12.8, -inf]
Step 1663 2 visits [12.0, 1.0, 396.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1139 q_vals: [-9.6, -12.8, -8.231, -9.216, -12.8, -12.8, -inf]
Step 1664 2 visits [12.0, 1.0, 397.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1139 q_vals: [-9.6, -12.8, -8.243, -9.216, -12.8, -12.8, -inf]
Step 1665 2 visits [12.0, 1.0, 398.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1139 q_vals: [-9.6, -12.8, -8.254, -9.216, -12.8, -12.8, -inf]
Step 1666 2 visits [12.0, 1.0, 399.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1139 q_vals: [-9.6, -12.8, -8.234, -9.216, -12.8, -12.8, -inf]
Step 1667 2 visits [12.0, 1.0, 400.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1139 q_vals: [-9.6, -12.8, -8.245, -9.216, -12.8, -12.8, -inf]
Step 1668 2 visits [12.0, 1.0, 401.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1139 q_vals: [-9.6, -12.8, -8.225, -9.216, -12.8, -12.8, -inf]
Step 1669 2 visits [12.0, 1.0, 402.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1140 q_vals: [-9.6, -12.8, -8.236, -9.216, -12.8, -12.8, -inf]
Step 1670 2 visits [12.0, 1.0, 403.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1141 q_vals: [-9.6, -12.8, -8.247, -9.216, -12.8, -12.8, -inf]
Step 1671 2 visits [12.0, 1.0, 404.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1141 q_vals: [-9.6, -12.8, -8.259, -9.216, -12.8, -12.8, -inf]
Step 1672 2 visits [12.0, 1.0, 405.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1142 q_vals: [-9.6, -12.8, -8.27, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1143, "number_of_timesteps": 111826, "per_episode_reward": -385.44, "episode_reward_trend_value": 0.14047768478406447, "biggest_recent_change": 1.9885477305673476},
Step 1673 2 visits [12.0, 1.0, 406.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1143 q_vals: [-9.6, -12.8, -8.281, -9.216, -12.8, -12.8, -inf]
Step 1674 2 visits [12.0, 1.0, 407.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1143 q_vals: [-9.6, -12.8, -8.261, -9.216, -12.8, -12.8, -inf]
Step 1675 2 visits [12.0, 1.0, 408.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1144 q_vals: [-9.6, -12.8, -8.272, -9.216, -12.8, -12.8, -inf]
Step 1676 2 visits [12.0, 1.0, 409.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1144 q_vals: [-9.6, -12.8, -8.283, -9.216, -12.8, -12.8, -inf]
Step 1677 2 visits [12.0, 1.0, 410.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1145 q_vals: [-9.6, -12.8, -8.294, -9.216, -12.8, -12.8, -inf]
Step 1678 2 visits [12.0, 1.0, 411.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1147 q_vals: [-9.6, -12.8, -8.305, -9.216, -12.8, -12.8, -inf]
Step 1679 2 visits [12.0, 1.0, 412.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1148 q_vals: [-9.6, -12.8, -8.316, -9.216, -12.8, -12.8, -inf]
Step 1680 2 visits [12.0, 1.0, 413.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1148 q_vals: [-9.6, -12.8, -8.326, -9.216, -12.8, -12.8, -inf]
Step 1681 2 visits [12.0, 1.0, 414.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1148 q_vals: [-9.6, -12.8, -8.337, -9.216, -12.8, -12.8, -inf]
Step 1682 2 visits [12.0, 1.0, 415.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1148 q_vals: [-9.6, -12.8, -8.348, -9.216, -12.8, -12.8, -inf]
Step 1683 2 visits [12.0, 1.0, 416.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1149 q_vals: [-9.6, -12.8, -8.358, -9.216, -12.8, -12.8, -inf]
Step 1684 2 visits [12.0, 1.0, 417.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1149 q_vals: [-9.6, -12.8, -8.369, -9.216, -12.8, -12.8, -inf]
Step 1685 2 visits [12.0, 1.0, 418.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1149 q_vals: [-9.6, -12.8, -8.379, -9.216, -12.8, -12.8, -inf]
Step 1686 2 visits [12.0, 1.0, 419.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1149 q_vals: [-9.6, -12.8, -8.39, -9.216, -12.8, -12.8, -inf]
Step 1687 2 visits [12.0, 1.0, 420.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1150 q_vals: [-9.6, -12.8, -8.4, -9.216, -12.8, -12.8, -inf]
Step 1688 2 visits [12.0, 1.0, 421.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1152 q_vals: [-9.6, -12.8, -8.411, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1153, "number_of_timesteps": 113027, "per_episode_reward": -383.74, "episode_reward_trend_value": 0.1372727042602125, "biggest_recent_change": 1.9423943658621283},
Step 1689 2 visits [12.0, 1.0, 422.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1153 q_vals: [-9.6, -12.8, -8.421, -9.216, -12.8, -12.8, -inf]
Step 1690 2 visits [12.0, 1.0, 423.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1153 q_vals: [-9.6, -12.8, -8.401, -9.216, -12.8, -12.8, -inf]
Step 1691 2 visits [12.0, 1.0, 424.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1153 q_vals: [-9.6, -12.8, -8.382, -9.216, -12.8, -12.8, -inf]
Step 1692 2 visits [12.0, 1.0, 425.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1153 q_vals: [-9.6, -12.8, -8.387, -9.216, -12.8, -12.8, -inf]
Step 1693 2 visits [12.0, 1.0, 426.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1154 q_vals: [-9.6, -12.8, -8.367, -9.216, -12.8, -12.8, -inf]
Step 1694 2 visits [12.0, 1.0, 427.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1155 q_vals: [-9.6, -12.8, -8.378, -9.216, -12.8, -12.8, -inf]
Step 1695 2 visits [12.0, 1.0, 428.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1157 q_vals: [-9.6, -12.8, -8.358, -9.216, -12.8, -12.8, -inf]
Step 1696 2 visits [12.0, 1.0, 429.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1159 q_vals: [-9.6, -12.8, -8.365, -9.216, -12.8, -12.8, -inf]
Step 1697 2 visits [12.0, 1.0, 430.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1159 q_vals: [-9.6, -12.8, -8.345, -9.216, -12.8, -12.8, -inf]
Step 1698 2 visits [12.0, 1.0, 431.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1160 q_vals: [-9.6, -12.8, -8.355, -9.216, -12.8, -12.8, -inf]
Step 1699 2 visits [12.0, 1.0, 432.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1160 q_vals: [-9.6, -12.8, -8.366, -9.216, -12.8, -12.8, -inf]
[-9.6, -12.8, -8.346, -9.216, -12.8, -12.8, -inf]
Step 1701 2 visits [12.0, 1.0, 434.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1161 q_vals: [-9.6, -12.8, -8.357, -9.216, -12.8, -12.8, -inf]
Step 1702 2 visits [12.0, 1.0, 435.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1161 q_vals: [-9.6, -12.8, -8.367, -9.216, -12.8, -12.8, -inf]
Step 1703 2 visits [12.0, 1.0, 436.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1162 q_vals: [-9.6, -12.8, -8.377, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1163, "number_of_timesteps": 113999, "per_episode_reward": -382.34, "episode_reward_trend_value": 0.13581571607549878, "biggest_recent_change": 1.9423943658621283},
Step 1704 2 visits [12.0, 1.0, 437.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1163 q_vals: [-9.6, -12.8, -8.387, -9.216, -12.8, -12.8, -inf]
Step 1705 2 visits [12.0, 1.0, 438.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1164 q_vals: [-9.6, -12.8, -8.397, -9.216, -12.8, -12.8, -inf]
Step 1706 2 visits [12.0, 1.0, 439.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1164 q_vals: [-9.6, -12.8, -8.378, -9.216, -12.8, -12.8, -inf]
Step 1707 2 visits [12.0, 1.0, 440.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1165 q_vals: [-9.6, -12.8, -8.359, -9.216, -12.8, -12.8, -inf]
Step 1708 2 visits [12.0, 1.0, 441.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1166 q_vals: [-9.6, -12.8, -8.34, -9.216, -12.8, -12.8, -inf]
Step 1709 2 visits [12.0, 1.0, 442.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1166 q_vals: [-9.6, -12.8, -8.321, -9.216, -12.8, -12.8, -inf]
Step 1710 2 visits [12.0, 1.0, 443.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1167 q_vals: [-9.6, -12.8, -8.313, -9.216, -12.8, -12.8, -inf]
Step 1711 2 visits [12.0, 1.0, 444.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1168 q_vals: [-9.6, -12.8, -8.323, -9.216, -12.8, -12.8, -inf]
Step 1712 2 visits [12.0, 1.0, 445.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1169 q_vals: [-9.6, -12.8, -8.333, -9.216, -12.8, -12.8, -inf]
Step 1713 2 visits [12.0, 1.0, 446.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1169 q_vals: [-9.6, -12.8, -8.343, -9.216, -12.8, -12.8, -inf]
Step 1714 2 visits [12.0, 1.0, 447.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1170 q_vals: [-9.6, -12.8, -8.353, -9.216, -12.8, -12.8, -inf]
Step 1715 2 visits [12.0, 1.0, 448.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1171 q_vals: [-9.6, -12.8, -8.363, -9.216, -12.8, -12.8, -inf]
Step 1716 2 visits [12.0, 1.0, 449.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1171 q_vals: [-9.6, -12.8, -8.344, -9.216, -12.8, -12.8, -inf]
Step 1717 2 visits [12.0, 1.0, 450.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1171 q_vals: [-9.6, -12.8, -8.354, -9.216, -12.8, -12.8, -inf]
Step 1718 2 visits [12.0, 1.0, 451.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1171 q_vals: [-9.6, -12.8, -8.364, -9.216, -12.8, -12.8, -inf]
Step 1719 2 visits [12.0, 1.0, 452.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1171 q_vals: [-9.6, -12.8, -8.345, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1173, "number_of_timesteps": 115039, "per_episode_reward": -379.16, "episode_reward_trend_value": 0.15635407169547005, "biggest_recent_change": 3.1760355538229987},
Step 1720 2 visits [12.0, 1.0, 453.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1173 q_vals: [-9.6, -12.8, -8.327, -9.216, -12.8, -12.8, -inf]
Step 1721 2 visits [12.0, 1.0, 454.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1173 q_vals: [-9.6, -12.8, -8.337, -9.216, -12.8, -12.8, -inf]
Step 1722 2 visits [12.0, 1.0, 455.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1174 q_vals: [-9.6, -12.8, -8.346, -9.216, -12.8, -12.8, -inf]
Step 1723 2 visits [12.0, 1.0, 456.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1174 q_vals: [-9.6, -12.8, -8.356, -9.216, -12.8, -12.8, -inf]
Step 1724 2 visits [12.0, 1.0, 457.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1176 q_vals: [-9.6, -12.8, -8.366, -9.216, -12.8, -12.8, -inf]
Step 1725 2 visits [12.0, 1.0, 458.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1176 q_vals: [-9.6, -12.8, -8.348, -9.216, -12.8, -12.8, -inf]
Step 1726 2 visits [12.0, 1.0, 459.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1176 q_vals: [-9.6, -12.8, -8.357, -9.216, -12.8, -12.8, -inf]
Step 1727 2 visits [12.0, 1.0, 460.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1176 q_vals: [-9.6, -12.8, -8.367, -9.216, -12.8, -12.8, -inf]
Step 1728 2 visits [12.0, 1.0, 461.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1176 q_vals: [-9.6, -12.8, -8.377, -9.216, -12.8, -12.8, -inf]
Step 1729 2 visits [12.0, 1.0, 462.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1176 q_vals: [-9.6, -12.8, -8.386, -9.216, -12.8, -12.8, -inf]
Step 1730 2 visits [12.0, 1.0, 463.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1177 q_vals: [-9.6, -12.8, -8.396, -9.216, -12.8, -12.8, -inf]
Step 1731 2 visits [12.0, 1.0, 464.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1178 q_vals: [-9.6, -12.8, -8.378, -9.216, -12.8, -12.8, -inf]
Step 1732 2 visits [12.0, 1.0, 465.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1179 q_vals: [-9.6, -12.8, -8.387, -9.216, -12.8, -12.8, -inf]
Step 1733 2 visits [12.0, 1.0, 466.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1180 q_vals: [-9.6, -12.8, -8.369, -9.216, -12.8, -12.8, -inf]
Step 1734 2 visits [12.0, 1.0, 467.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1182 q_vals: [-9.6, -12.8, -8.357, -9.216, -12.8, -12.8, -inf]
Step 1735 2 visits [12.0, 1.0, 468.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1182 q_vals: [-9.6, -12.8, -8.339, -9.216, -12.8, -12.8, -inf]
Step 1736 2 visits [12.0, 1.0, 469.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1182 q_vals: [-9.6, -12.8, -8.348, -9.216, -12.8, -12.8, -inf]
Step 1737 2 visits [12.0, 1.0, 470.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1182 q_vals: [-9.6, -12.8, -8.358, -9.216, -12.8, -12.8, -inf]
Step 1738 2 visits [12.0, 1.0, 471.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1182 q_vals: [-9.6, -12.8, -8.367, -9.216, -12.8, -12.8, -inf]
Step 1739 2 visits [12.0, 1.0, 472.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1182 q_vals: [-9.6, -12.8, -8.377, -9.216, -12.8, -12.8, -inf]
Step 1740 2 visits [12.0, 1.0, 473.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1182 q_vals: [-9.6, -12.8, -8.386, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1183, "number_of_timesteps": 116270, "per_episode_reward": -376.52, "episode_reward_trend_value": 0.16711680247953115, "biggest_recent_change": 3.1760355538229987},
Step 1741 2 visits [12.0, 1.0, 474.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1183 q_vals: [-9.6, -12.8, -8.395, -9.216, -12.8, -12.8, -inf]
Step 1742 2 visits [12.0, 1.0, 475.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1183 q_vals: [-9.6, -12.8, -8.378, -9.216, -12.8, -12.8, -inf]
Step 1743 2 visits [12.0, 1.0, 476.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1183 q_vals: [-9.6, -12.8, -8.387, -9.216, -12.8, -12.8, -inf]
Step 1744 2 visits [12.0, 1.0, 477.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1184 q_vals: [-9.6, -12.8, -8.396, -9.216, -12.8, -12.8, -inf]
Step 1745 2 visits [12.0, 1.0, 478.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1185 q_vals: [-9.6, -12.8, -8.378, -9.216, -12.8, -12.8, -inf]
Step 1746 2 visits [12.0, 1.0, 479.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1188 q_vals: [-9.6, -12.8, -8.388, -9.216, -12.8, -12.8, -inf]
Step 1747 2 visits [12.0, 1.0, 480.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1188 q_vals: [-9.6, -12.8, -8.397, -9.216, -12.8, -12.8, -inf]
Step 1748 2 visits [12.0, 1.0, 481.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1188 q_vals: [-9.6, -12.8, -8.398, -9.216, -12.8, -12.8, -inf]
Step 1749 2 visits [12.0, 1.0, 482.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1188 q_vals: [-9.6, -12.8, -8.407, -9.216, -12.8, -12.8, -inf]
Step 1750 2 visits [12.0, 1.0, 483.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1188 q_vals: [-9.6, -12.8, -8.416, -9.216, -12.8, -12.8, -inf]
Step 1751 2 visits [12.0, 1.0, 484.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1188 q_vals: [-9.6, -12.8, -8.425, -9.216, -12.8, -12.8, -inf]
Step 1752 2 visits [12.0, 1.0, 485.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1188 q_vals: [-9.6, -12.8, -8.434, -9.216, -12.8, -12.8, -inf]
Step 1753 2 visits [12.0, 1.0, 486.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1189 q_vals: [-9.6, -12.8, -8.443, -9.216, -12.8, -12.8, -inf]
Step 1754 2 visits [12.0, 1.0, 487.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1191 q_vals: [-9.6, -12.8, -8.452, -9.216, -12.8, -12.8, -inf]
Step 1755 2 visits [12.0, 1.0, 488.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1192 q_vals: [-9.6, -12.8, -8.461, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1195, "number_of_timesteps": 117780, "per_episode_reward": -372.64, "episode_reward_trend_value": 0.2037129545468998, "biggest_recent_change": 3.8852485839986457},
Step 1756 2 visits [12.0, 1.0, 489.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1195 q_vals: [-9.6, -12.8, -8.47, -9.216, -12.8, -12.8, -inf]
Step 1757 2 visits [12.0, 1.0, 490.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1195 q_vals: [-9.6, -12.8, -8.452, -9.216, -12.8, -12.8, -inf]
Step 1758 2 visits [12.0, 1.0, 491.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1195 q_vals: [-9.6, -12.8, -8.461, -9.216, -12.8, -12.8, -inf]
Step 1759 2 visits [12.0, 1.0, 492.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1195 q_vals: [-9.6, -12.8, -8.444, -9.216, -12.8, -12.8, -inf]
Step 1760 2 visits [12.0, 1.0, 493.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1195 q_vals: [-9.6, -12.8, -8.427, -9.216, -12.8, -12.8, -inf]
Step 1761 2 visits [12.0, 1.0, 494.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1195 q_vals: [-9.6, -12.8, -8.434, -9.216, -12.8, -12.8, -inf]
Step 1762 2 visits [12.0, 1.0, 495.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1195 q_vals: [-9.6, -12.8, -8.443, -9.216, -12.8, -12.8, -inf]
Step 1763 2 visits [12.0, 1.0, 496.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1195 q_vals: [-9.6, -12.8, -8.451, -9.216, -12.8, -12.8, -inf]
Step 1764 2 visits [12.0, 1.0, 497.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1195 q_vals: [-9.6, -12.8, -8.46, -9.216, -12.8, -12.8, -inf]
Step 1765 2 visits [12.0, 1.0, 498.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1195 q_vals: [-9.6, -12.8, -8.469, -9.216, -12.8, -12.8, -inf]
Step 1766 2 visits [12.0, 1.0, 499.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1197 q_vals: [-9.6, -12.8, -8.477, -9.216, -12.8, -12.8, -inf]
Step 1767 2 visits [12.0, 1.0, 500.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1198 q_vals: [-9.6, -12.8, -8.461, -9.216, -12.8, -12.8, -inf]
Step 1768 2 visits [12.0, 1.0, 501.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1200 q_vals: [-9.6, -12.8, -8.444, -9.216, -12.8, -12.8, -inf]
Step 1769 2 visits [12.0, 1.0, 502.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1201 q_vals: [-9.6, -12.8, -8.452, -9.216, -12.8, -12.8, -inf]
Step 1770 2 visits [12.0, 1.0, 503.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1201 q_vals: [-9.6, -12.8, -8.461, -9.216, -12.8, -12.8, -inf]
Step 1771 2 visits [12.0, 1.0, 504.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1202 q_vals: [-9.6, -12.8, -8.47, -9.216, -12.8, -12.8, -inf]
Step 1772 2 visits [12.0, 1.0, 505.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1202 q_vals: [-9.6, -12.8, -8.478, -9.216, -12.8, -12.8, -inf]
Step 1773 2 visits [12.0, 1.0, 506.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1202 q_vals: [-9.6, -12.8, -8.487, -9.216, -12.8, -12.8, -inf]
Step 1774 2 visits [12.0, 1.0, 507.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1202 q_vals: [-9.6, -12.8, -8.477, -9.216, -12.8, -12.8, -inf]
Step 1775 2 visits [12.0, 1.0, 508.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1202 q_vals: [-9.6, -12.8, -8.461, -9.216, -12.8, -12.8, -inf]
Step 1776 2 visits [12.0, 1.0, 509.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1203 q_vals: [-9.6, -12.8, -8.469, -9.216, -12.8, -12.8, -inf]
Step 1777 2 visits [12.0, 1.0, 510.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1204 q_vals: [-9.6, -12.8, -8.478, -9.216, -12.8, -12.8, -inf]
Step 1778 2 visits [12.0, 1.0, 511.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1204 q_vals: [-9.6, -12.8, -8.486, -9.216, -12.8, -12.8, -inf]
Step 1779 2 visits [12.0, 1.0, 512.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1204 q_vals: [-9.6, -12.8, -8.47, -9.216, -12.8, -12.8, -inf]
Step 1780 2 visits [12.0, 1.0, 513.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1204 q_vals: [-9.6, -12.8, -8.478, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1205, "number_of_timesteps": 118976, "per_episode_reward": -371.08, "episode_reward_trend_value": 0.1993968302240085, "biggest_recent_change": 3.8852485839986457},
Step 1781 2 visits [12.0, 1.0, 514.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1205 q_vals: [-9.6, -12.8, -8.461, -9.216, -12.8, -12.8, -inf]
Step 1782 2 visits [12.0, 1.0, 515.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1206 q_vals: [-9.6, -12.8, -8.445, -9.216, -12.8, -12.8, -inf]
Step 1783 2 visits [12.0, 1.0, 516.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1207 q_vals: [-9.6, -12.8, -8.452, -9.216, -12.8, -12.8, -inf]
Step 1784 2 visits [12.0, 1.0, 517.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1208 q_vals: [-9.6, -12.8, -8.436, -9.216, -12.8, -12.8, -inf]
Step 1785 2 visits [12.0, 1.0, 518.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1208 q_vals: [-9.6, -12.8, -8.42, -9.216, -12.8, -12.8, -inf]
Step 1786 2 visits [12.0, 1.0, 519.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1208 q_vals: [-9.6, -12.8, -8.428, -9.216, -12.8, -12.8, -inf]
Step 1787 2 visits [12.0, 1.0, 520.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1210 q_vals: [-9.6, -12.8, -8.412, -9.216, -12.8, -12.8, -inf]
Step 1788 2 visits [12.0, 1.0, 521.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1210 q_vals: [-9.6, -12.8, -8.42, -9.216, -12.8, -12.8, -inf]
Step 1789 2 visits [12.0, 1.0, 522.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1210 q_vals: [-9.6, -12.8, -8.429, -9.216, -12.8, -12.8, -inf]
Step 1790 2 visits [12.0, 1.0, 523.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1210 q_vals: [-9.6, -12.8, -8.437, -9.216, -12.8, -12.8, -inf]
Step 1791 2 visits [12.0, 1.0, 524.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1210 q_vals: [-9.6, -12.8, -8.446, -9.216, -12.8, -12.8, -inf]
Step 1792 2 visits [12.0, 1.0, 525.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1211 q_vals: [-9.6, -12.8, -8.454, -9.216, -12.8, -12.8, -inf]
Step 1793 2 visits [12.0, 1.0, 526.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1212 q_vals: [-9.6, -12.8, -8.462, -9.216, -12.8, -12.8, -inf]
Step 1794 2 visits [12.0, 1.0, 527.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1213 q_vals: [-9.6, -12.8, -8.47, -9.216, -12.8, -12.8, -inf]
Step 1795 2 visits [12.0, 1.0, 528.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1214 q_vals: [-9.6, -12.8, -8.479, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1216, "number_of_timesteps": 120360, "per_episode_reward": -369.08, "episode_reward_trend_value": 0.21082056026627233, "biggest_recent_change": 3.8852485839986457},
Step 1796 2 visits [12.0, 1.0, 529.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1216 q_vals: [-9.6, -12.8, -8.487, -9.216, -12.8, -12.8, -inf]
Step 1797 2 visits [12.0, 1.0, 530.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1217 q_vals: [-9.6, -12.8, -8.495, -9.216, -12.8, -12.8, -inf]
Step 1798 2 visits [12.0, 1.0, 531.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1218 q_vals: [-9.6, -12.8, -8.503, -9.216, -12.8, -12.8, -inf]
Step 1799 2 visits [12.0, 1.0, 532.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1218 q_vals: [-9.6, -12.8, -8.487, -9.216, -12.8, -12.8, -inf]
Step 1800 2 visits [12.0, 1.0, 533.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1218 q_vals: [-9.6, -12.8, -8.471, -9.216, -12.8, -12.8, -inf]
Step 1801 2 visits [12.0, 1.0, 534.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1218 q_vals: [-9.6, -12.8, -8.479, -9.216, -12.8, -12.8, -inf]
Step 1802 2 visits [12.0, 1.0, 535.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1219 q_vals: [-9.6, -12.8, -8.463, -9.216, -12.8, -12.8, -inf]
Step 1803 2 visits [12.0, 1.0, 536.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1222 q_vals: [-9.6, -12.8, -8.471, -9.216, -12.8, -12.8, -inf]
Step 1804 2 visits [12.0, 1.0, 537.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1223 q_vals: [-9.6, -12.8, -8.456, -9.216, -12.8, -12.8, -inf]
Step 1805 2 visits [12.0, 1.0, 538.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1223 q_vals: [-9.6, -12.8, -8.464, -9.216, -12.8, -12.8, -inf]
Step 1806 2 visits [12.0, 1.0, 539.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1223 q_vals: [-9.6, -12.8, -8.472, -9.216, -12.8, -12.8, -inf]
Step 1807 2 visits [12.0, 1.0, 540.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1224 q_vals: [-9.6, -12.8, -8.48, -9.216, -12.8, -12.8, -inf]
Step 1808 2 visits [12.0, 1.0, 541.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1224 q_vals: [-9.6, -12.8, -8.464, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1226, "number_of_timesteps": 121171, "per_episode_reward": -367.62, "episode_reward_trend_value": 0.2084990968093779, "biggest_recent_change": 3.8852485839986457},
Step 1809 2 visits [12.0, 1.0, 542.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1226 q_vals: [-9.6, -12.8, -8.472, -9.216, -12.8, -12.8, -inf]
Step 1810 2 visits [12.0, 1.0, 543.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1226 q_vals: [-9.6, -12.8, -8.48, -9.216, -12.8, -12.8, -inf]
Step 1811 2 visits [12.0, 1.0, 544.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1227 q_vals: [-9.6, -12.8, -8.488, -9.216, -12.8, -12.8, -inf]
Step 1812 2 visits [12.0, 1.0, 545.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1227 q_vals: [-9.6, -12.8, -8.496, -9.216, -12.8, -12.8, -inf]
Step 1813 2 visits [12.0, 1.0, 546.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1229 q_vals: [-9.6, -12.8, -8.504, -9.216, -12.8, -12.8, -inf]
Step 1814 2 visits [12.0, 1.0, 547.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1229 q_vals: [-9.6, -12.8, -8.512, -9.216, -12.8, -12.8, -inf]
Step 1815 2 visits [12.0, 1.0, 548.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1229 q_vals: [-9.6, -12.8, -8.519, -9.216, -12.8, -12.8, -inf]
Step 1816 2 visits [12.0, 1.0, 549.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1230 q_vals: [-9.6, -12.8, -8.527, -9.216, -12.8, -12.8, -inf]
Step 1817 2 visits [12.0, 1.0, 550.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1231 q_vals: [-9.6, -12.8, -8.535, -9.216, -12.8, -12.8, -inf]
Step 1818 2 visits [12.0, 1.0, 551.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1231 q_vals: [-9.6, -12.8, -8.52, -9.216, -12.8, -12.8, -inf]
Step 1819 2 visits [12.0, 1.0, 552.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1233 q_vals: [-9.6, -12.8, -8.504, -9.216, -12.8, -12.8, -inf]
Step 1820 2 visits [12.0, 1.0, 553.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1233 q_vals: [-9.6, -12.8, -8.489, -9.216, -12.8, -12.8, -inf]
Step 1821 2 visits [12.0, 1.0, 554.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1233 q_vals: [-9.6, -12.8, -8.497, -9.216, -12.8, -12.8, -inf]
Step 1822 2 visits [12.0, 1.0, 555.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1233 q_vals: [-9.6, -12.8, -8.481, -9.216, -12.8, -12.8, -inf]
Step 1823 2 visits [12.0, 1.0, 556.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1234 q_vals: [-9.6, -12.8, -8.489, -9.216, -12.8, -12.8, -inf]
Step 1824 2 visits [12.0, 1.0, 557.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1235 q_vals: [-9.6, -12.8, -8.497, -9.216, -12.8, -12.8, -inf]
Step 1825 2 visits [12.0, 1.0, 558.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1235 q_vals: [-9.6, -12.8, -8.504, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1237, "number_of_timesteps": 122240, "per_episode_reward": -365.39, "episode_reward_trend_value": 0.22278038238275397, "biggest_recent_change": 3.8852485839986457},
Step 1826 2 visits [12.0, 1.0, 559.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1237 q_vals: [-9.6, -12.8, -8.489, -9.216, -12.8, -12.8, -inf]
Step 1827 2 visits [12.0, 1.0, 560.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1237 q_vals: [-9.6, -12.8, -8.497, -9.216, -12.8, -12.8, -inf]
Step 1828 2 visits [12.0, 1.0, 561.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1237 q_vals: [-9.6, -12.8, -8.505, -9.216, -12.8, -12.8, -inf]
Step 1829 2 visits [12.0, 1.0, 562.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1237 q_vals: [-9.6, -12.8, -8.512, -9.216, -12.8, -12.8, -inf]
Step 1830 2 visits [12.0, 1.0, 563.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1237 q_vals: [-9.6, -12.8, -8.52, -9.216, -12.8, -12.8, -inf]
Step 1831 2 visits [12.0, 1.0, 564.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1237 q_vals: [-9.6, -12.8, -8.527, -9.216, -12.8, -12.8, -inf]
Step 1832 2 visits [12.0, 1.0, 565.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1237 q_vals: [-9.6, -12.8, -8.512, -9.216, -12.8, -12.8, -inf]
Step 1833 2 visits [12.0, 1.0, 566.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1239 q_vals: [-9.6, -12.8, -8.52, -9.216, -12.8, -12.8, -inf]
Step 1834 2 visits [12.0, 1.0, 567.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1240 q_vals: [-9.6, -12.8, -8.527, -9.216, -12.8, -12.8, -inf]
Step 1835 2 visits [12.0, 1.0, 568.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1240 q_vals: [-9.6, -12.8, -8.535, -9.216, -12.8, -12.8, -inf]
Step 1836 2 visits [12.0, 1.0, 569.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1240 q_vals: [-9.6, -12.8, -8.542, -9.216, -12.8, -12.8, -inf]
Step 1837 2 visits [12.0, 1.0, 570.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1243 q_vals: [-9.6, -12.8, -8.55, -9.216, -12.8, -12.8, -inf]
Step 1838 2 visits [12.0, 1.0, 571.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1243 q_vals: [-9.6, -12.8, -8.535, -9.216, -12.8, -12.8, -inf]
Step 1839 2 visits [12.0, 1.0, 572.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1243 q_vals: [-9.6, -12.8, -8.542, -9.216, -12.8, -12.8, -inf]
Step 1840 2 visits [12.0, 1.0, 573.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1244 q_vals: [-9.6, -12.8, -8.55, -9.216, -12.8, -12.8, -inf]
Step 1841 2 visits [12.0, 1.0, 574.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1245 q_vals: [-9.6, -12.8, -8.557, -9.216, -12.8, -12.8, -inf]
Step 1842 2 visits [12.0, 1.0, 575.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1245 q_vals: [-9.6, -12.8, -8.542, -9.216, -12.8, -12.8, -inf]
Step 1843 2 visits [12.0, 1.0, 576.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1245 q_vals: [-9.6, -12.8, -8.55, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1247, "number_of_timesteps": 123399, "per_episode_reward": -364.36, "episode_reward_trend_value": 0.2153585288617017, "biggest_recent_change": 3.8852485839986457},
Step 1844 2 visits [12.0, 1.0, 577.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1247 q_vals: [-9.6, -12.8, -8.535, -9.216, -12.8, -12.8, -inf]
Step 1845 2 visits [12.0, 1.0, 578.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1249 q_vals: [-9.6, -12.8, -8.542, -9.216, -12.8, -12.8, -inf]
Step 1846 2 visits [12.0, 1.0, 579.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1250 q_vals: [-9.6, -12.8, -8.535, -9.216, -12.8, -12.8, -inf]
Step 1847 2 visits [12.0, 1.0, 580.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1250 q_vals: [-9.6, -12.8, -8.543, -9.216, -12.8, -12.8, -inf]
Step 1848 2 visits [12.0, 1.0, 581.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1250 q_vals: [-9.6, -12.8, -8.528, -9.216, -12.8, -12.8, -inf]
Step 1849 2 visits [12.0, 1.0, 582.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1251 q_vals: [-9.6, -12.8, -8.522, -9.216, -12.8, -12.8, -inf]
Step 1850 2 visits [12.0, 1.0, 583.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1251 q_vals: [-9.6, -12.8, -8.53, -9.216, -12.8, -12.8, -inf]
Step 1851 2 visits [12.0, 1.0, 584.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1251 q_vals: [-9.6, -12.8, -8.537, -9.216, -12.8, -12.8, -inf]
Step 1852 2 visits [12.0, 1.0, 585.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1252 q_vals: [-9.6, -12.8, -8.539, -9.216, -12.8, -12.8, -inf]
Step 1853 2 visits [12.0, 1.0, 586.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1252 q_vals: [-9.6, -12.8, -8.524, -9.216, -12.8, -12.8, -inf]
Step 1854 2 visits [12.0, 1.0, 587.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1254 q_vals: [-9.6, -12.8, -8.531, -9.216, -12.8, -12.8, -inf]
Step 1855 2 visits [12.0, 1.0, 588.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1255 q_vals: [-9.6, -12.8, -8.539, -9.216, -12.8, -12.8, -inf]
Step 1856 2 visits [12.0, 1.0, 589.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1255 q_vals: [-9.6, -12.8, -8.546, -9.216, -12.8, -12.8, -inf]
Step 1857 2 visits [12.0, 1.0, 590.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1255 q_vals: [-9.6, -12.8, -8.553, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1257, "number_of_timesteps": 124414, "per_episode_reward": -362.68, "episode_reward_trend_value": 0.2183884451090206, "biggest_recent_change": 3.8852485839986457},
Step 1858 2 visits [12.0, 1.0, 591.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1257 q_vals: [-9.6, -12.8, -8.56, -9.216, -12.8, -12.8, -inf]
Step 1859 2 visits [12.0, 1.0, 592.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1258 q_vals: [-9.6, -12.8, -8.546, -9.216, -12.8, -12.8, -inf]
Step 1860 2 visits [12.0, 1.0, 593.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1258 q_vals: [-9.6, -12.8, -8.531, -9.216, -12.8, -12.8, -inf]
Step 1861 2 visits [12.0, 1.0, 594.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1258 q_vals: [-9.6, -12.8, -8.539, -9.216, -12.8, -12.8, -inf]
Step 1862 2 visits [12.0, 1.0, 595.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1259 q_vals: [-9.6, -12.8, -8.546, -9.216, -12.8, -12.8, -inf]
Step 1863 2 visits [12.0, 1.0, 596.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1259 q_vals: [-9.6, -12.8, -8.531, -9.216, -12.8, -12.8, -inf]
Step 1864 2 visits [12.0, 1.0, 597.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1259 q_vals: [-9.6, -12.8, -8.539, -9.216, -12.8, -12.8, -inf]
Step 1865 2 visits [12.0, 1.0, 598.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1260 q_vals: [-9.6, -12.8, -8.546, -9.216, -12.8, -12.8, -inf]
Step 1866 2 visits [12.0, 1.0, 599.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1260 q_vals: [-9.6, -12.8, -8.553, -9.216, -12.8, -12.8, -inf]
Step 1867 2 visits [12.0, 1.0, 600.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1261 q_vals: [-9.6, -12.8, -8.56, -9.216, -12.8, -12.8, -inf]
Step 1868 2 visits [12.0, 1.0, 601.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1262 q_vals: [-9.6, -12.8, -8.567, -9.216, -12.8, -12.8, -inf]
Step 1869 2 visits [12.0, 1.0, 602.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1262 q_vals: [-9.6, -12.8, -8.574, -9.216, -12.8, -12.8, -inf]
Step 1870 2 visits [12.0, 1.0, 603.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1263 q_vals: [-9.6, -12.8, -8.56, -9.216, -12.8, -12.8, -inf]
Step 1871 2 visits [12.0, 1.0, 604.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1263 q_vals: [-9.6, -12.8, -8.567, -9.216, -12.8, -12.8, -inf]
Step 1872 2 visits [12.0, 1.0, 605.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1266 q_vals: [-9.6, -12.8, -8.553, -9.216, -12.8, -12.8, -inf]
Step 1873 2 visits [12.0, 1.0, 606.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1266 q_vals: [-9.6, -12.8, -8.56, -9.216, -12.8, -12.8, -inf]
Step 1874 2 visits [12.0, 1.0, 607.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1266 q_vals: [-9.6, -12.8, -8.567, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1267, "number_of_timesteps": 125566, "per_episode_reward": -361.24, "episode_reward_trend_value": 0.19911556189519564, "biggest_recent_change": 3.8852485839986457},
Step 1875 2 visits [12.0, 1.0, 608.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1267 q_vals: [-9.6, -12.8, -8.574, -9.216, -12.8, -12.8, -inf]
Step 1876 2 visits [12.0, 1.0, 609.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1267 q_vals: [-9.6, -12.8, -8.581, -9.216, -12.8, -12.8, -inf]
Step 1877 2 visits [12.0, 1.0, 610.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1267 q_vals: [-9.6, -12.8, -8.566, -9.216, -12.8, -12.8, -inf]
Step 1878 2 visits [12.0, 1.0, 611.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1268 q_vals: [-9.6, -12.8, -8.573, -9.216, -12.8, -12.8, -inf]
Step 1879 2 visits [12.0, 1.0, 612.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1268 q_vals: [-9.6, -12.8, -8.58, -9.216, -12.8, -12.8, -inf]
Step 1880 2 visits [12.0, 1.0, 613.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1268 q_vals: [-9.6, -12.8, -8.587, -9.216, -12.8, -12.8, -inf]
Step 1881 2 visits [12.0, 1.0, 614.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1270 q_vals: [-9.6, -12.8, -8.594, -9.216, -12.8, -12.8, -inf]
Step 1882 2 visits [12.0, 1.0, 615.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1271 q_vals: [-9.6, -12.8, -8.58, -9.216, -12.8, -12.8, -inf]
Step 1883 2 visits [12.0, 1.0, 616.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1272 q_vals: [-9.6, -12.8, -8.566, -9.216, -12.8, -12.8, -inf]
Step 1884 2 visits [12.0, 1.0, 617.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1272 q_vals: [-9.6, -12.8, -8.563, -9.216, -12.8, -12.8, -inf]
Step 1885 2 visits [12.0, 1.0, 618.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1273 q_vals: [-9.6, -12.8, -8.57, -9.216, -12.8, -12.8, -inf]
Step 1886 2 visits [12.0, 1.0, 619.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1273 q_vals: [-9.6, -12.8, -8.577, -9.216, -12.8, -12.8, -inf]
Step 1887 2 visits [12.0, 1.0, 620.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1274 q_vals: [-9.6, -12.8, -8.584, -9.216, -12.8, -12.8, -inf]
Step 1888 2 visits [12.0, 1.0, 621.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1274 q_vals: [-9.6, -12.8, -8.591, -9.216, -12.8, -12.8, -inf]
Step 1889 2 visits [12.0, 1.0, 622.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1275 q_vals: [-9.6, -12.8, -8.597, -9.216, -12.8, -12.8, -inf]
Step 1890 2 visits [12.0, 1.0, 623.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1275 q_vals: [-9.6, -12.8, -8.584, -9.216, -12.8, -12.8, -inf]
Step 1891 2 visits [12.0, 1.0, 624.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1276 q_vals: [-9.6, -12.8, -8.59, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1278, "number_of_timesteps": 126708, "per_episode_reward": -359.6, "episode_reward_trend_value": 0.18802181947264987, "biggest_recent_change": 3.8852485839986457},
Step 1892 2 visits [12.0, 1.0, 625.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1278 q_vals: [-9.6, -12.8, -8.597, -9.216, -12.8, -12.8, -inf]
Step 1893 2 visits [12.0, 1.0, 626.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1280 q_vals: [-9.6, -12.8, -8.583, -9.216, -12.8, -12.8, -inf]
Step 1894 2 visits [12.0, 1.0, 627.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1281 q_vals: [-9.6, -12.8, -8.59, -9.216, -12.8, -12.8, -inf]
Step 1895 2 visits [12.0, 1.0, 628.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1281 q_vals: [-9.6, -12.8, -8.597, -9.216, -12.8, -12.8, -inf]
Step 1896 2 visits [12.0, 1.0, 629.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1281 q_vals: [-9.6, -12.8, -8.583, -9.216, -12.8, -12.8, -inf]
Step 1897 2 visits [12.0, 1.0, 630.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1282 q_vals: [-9.6, -12.8, -8.59, -9.216, -12.8, -12.8, -inf]
Step 1898 2 visits [12.0, 1.0, 631.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1282 q_vals: [-9.6, -12.8, -8.597, -9.216, -12.8, -12.8, -inf]
Step 1899 2 visits [12.0, 1.0, 632.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1283 q_vals: [-9.6, -12.8, -8.583, -9.216, -12.8, -12.8, -inf]
Step 1900 2 visits [12.0, 1.0, 633.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1284 q_vals: [-9.6, -12.8, -8.59, -9.216, -12.8, -12.8, -inf]
Step 1901 2 visits [12.0, 1.0, 634.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1284 q_vals: [-9.6, -12.8, -8.596, -9.216, -12.8, -12.8, -inf]
Step 1902 2 visits [12.0, 1.0, 635.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1286 q_vals: [-9.6, -12.8, -8.603, -9.216, -12.8, -12.8, -inf]
Step 1903 2 visits [12.0, 1.0, 636.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1286 q_vals: [-9.6, -12.8, -8.609, -9.216, -12.8, -12.8, -inf]
Step 1904 2 visits [12.0, 1.0, 637.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1286 q_vals: [-9.6, -12.8, -8.616, -9.216, -12.8, -12.8, -inf]
Step 1905 2 visits [12.0, 1.0, 638.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1286 q_vals: [-9.6, -12.8, -8.603, -9.216, -12.8, -12.8, -inf]
Step 1906 2 visits [12.0, 1.0, 639.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1286 q_vals: [-9.6, -12.8, -8.589, -9.216, -12.8, -12.8, -inf]
Step 1907 2 visits [12.0, 1.0, 640.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1287 q_vals: [-9.6, -12.8, -8.596, -9.216, -12.8, -12.8, -inf]
Step 1908 2 visits [12.0, 1.0, 641.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1287 q_vals: [-9.6, -12.8, -8.602, -9.216, -12.8, -12.8, -inf]
Step 1909 2 visits [12.0, 1.0, 642.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1287 q_vals: [-9.6, -12.8, -8.589, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1289, "number_of_timesteps": 127715, "per_episode_reward": -358.58, "episode_reward_trend_value": 0.15624177169494954, "biggest_recent_change": 2.2212804801633297},
Step 1910 2 visits [12.0, 1.0, 643.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1289 q_vals: [-9.6, -12.8, -8.595, -9.216, -12.8, -12.8, -inf]
Step 1911 2 visits [12.0, 1.0, 644.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1290 q_vals: [-9.6, -12.8, -8.602, -9.216, -12.8, -12.8, -inf]
Step 1912 2 visits [12.0, 1.0, 645.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1290 q_vals: [-9.6, -12.8, -8.608, -9.216, -12.8, -12.8, -inf]
Step 1913 2 visits [12.0, 1.0, 646.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1290 q_vals: [-9.6, -12.8, -8.615, -9.216, -12.8, -12.8, -inf]
Step 1914 2 visits [12.0, 1.0, 647.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1290 q_vals: [-9.6, -12.8, -8.621, -9.216, -12.8, -12.8, -inf]
Step 1915 2 visits [12.0, 1.0, 648.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1292 q_vals: [-9.6, -12.8, -8.608, -9.216, -12.8, -12.8, -inf]
Step 1916 2 visits [12.0, 1.0, 649.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1293 q_vals: [-9.6, -12.8, -8.615, -9.216, -12.8, -12.8, -inf]
Step 1917 2 visits [12.0, 1.0, 650.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1294 q_vals: [-9.6, -12.8, -8.601, -9.216, -12.8, -12.8, -inf]
Step 1918 2 visits [12.0, 1.0, 651.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1294 q_vals: [-9.6, -12.8, -8.608, -9.216, -12.8, -12.8, -inf]
Step 1919 2 visits [12.0, 1.0, 652.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1294 q_vals: [-9.6, -12.8, -8.614, -9.216, -12.8, -12.8, -inf]
Step 1920 2 visits [12.0, 1.0, 653.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1294 q_vals: [-9.6, -12.8, -8.621, -9.216, -12.8, -12.8, -inf]
Step 1921 2 visits [12.0, 1.0, 654.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1295 q_vals: [-9.6, -12.8, -8.627, -9.216, -12.8, -12.8, -inf]
Step 1922 2 visits [12.0, 1.0, 655.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1295 q_vals: [-9.6, -12.8, -8.633, -9.216, -12.8, -12.8, -inf]
Step 1923 2 visits [12.0, 1.0, 656.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1295 q_vals: [-9.6, -12.8, -8.64, -9.216, -12.8, -12.8, -inf]
Step 1924 2 visits [12.0, 1.0, 657.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1296 q_vals: [-9.6, -12.8, -8.627, -9.216, -12.8, -12.8, -inf]
Step 1925 2 visits [12.0, 1.0, 658.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1297 q_vals: [-9.6, -12.8, -8.633, -9.216, -12.8, -12.8, -inf]
Step 1926 2 visits [12.0, 1.0, 659.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1298 q_vals: [-9.6, -12.8, -8.637, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1299, "number_of_timesteps": 128901, "per_episode_reward": -357.04, "episode_reward_trend_value": 0.15608651649751612, "biggest_recent_change": 2.2212804801633297},
Step 1927 2 visits [12.0, 1.0, 660.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1299 q_vals: [-9.6, -12.8, -8.643, -9.216, -12.8, -12.8, -inf]
Step 1928 2 visits [12.0, 1.0, 661.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1299 q_vals: [-9.6, -12.8, -8.65, -9.216, -12.8, -12.8, -inf]
Step 1929 2 visits [12.0, 1.0, 662.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1300 q_vals: [-9.6, -12.8, -8.656, -9.216, -12.8, -12.8, -inf]
Step 1930 2 visits [12.0, 1.0, 663.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1300 q_vals: [-9.6, -12.8, -8.643, -9.216, -12.8, -12.8, -inf]
Step 1931 2 visits [12.0, 1.0, 664.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1301 q_vals: [-9.6, -12.8, -8.649, -9.216, -12.8, -12.8, -inf]
Step 1932 2 visits [12.0, 1.0, 665.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1302 q_vals: [-9.6, -12.8, -8.655, -9.216, -12.8, -12.8, -inf]
Step 1933 2 visits [12.0, 1.0, 666.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1302 q_vals: [-9.6, -12.8, -8.661, -9.216, -12.8, -12.8, -inf]
Step 1934 2 visits [12.0, 1.0, 667.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1302 q_vals: [-9.6, -12.8, -8.648, -9.216, -12.8, -12.8, -inf]
Step 1935 2 visits [12.0, 1.0, 668.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1303 q_vals: [-9.6, -12.8, -8.655, -9.216, -12.8, -12.8, -inf]
Step 1936 2 visits [12.0, 1.0, 669.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1304 q_vals: [-9.6, -12.8, -8.642, -9.216, -12.8, -12.8, -inf]
Step 1937 2 visits [12.0, 1.0, 670.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1305 q_vals: [-9.6, -12.8, -8.648, -9.216, -12.8, -12.8, -inf]
Step 1938 2 visits [12.0, 1.0, 671.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1305 q_vals: [-9.6, -12.8, -8.654, -9.216, -12.8, -12.8, -inf]
Step 1939 2 visits [12.0, 1.0, 672.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1308 q_vals: [-9.6, -12.8, -8.66, -9.216, -12.8, -12.8, -inf]
Step 1940 2 visits [12.0, 1.0, 673.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1308 q_vals: [-9.6, -12.8, -8.666, -9.216, -12.8, -12.8, -inf]
Step 1941 2 visits [12.0, 1.0, 674.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1308 q_vals: [-9.6, -12.8, -8.673, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1309, "number_of_timesteps": 130092, "per_episode_reward": -354.43, "episode_reward_trend_value": 0.16284679472928537, "biggest_recent_change": 2.6084750730588553},
Step 1942 2 visits [12.0, 1.0, 675.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1309 q_vals: [-9.6, -12.8, -8.679, -9.216, -12.8, -12.8, -inf]
Step 1943 2 visits [12.0, 1.0, 676.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1309 q_vals: [-9.6, -12.8, -8.685, -9.216, -12.8, -12.8, -inf]
Step 1944 2 visits [12.0, 1.0, 677.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1310 q_vals: [-9.6, -12.8, -8.691, -9.216, -12.8, -12.8, -inf]
Step 1945 2 visits [12.0, 1.0, 678.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1310 q_vals: [-9.6, -12.8, -8.678, -9.216, -12.8, -12.8, -inf]
Step 1946 2 visits [12.0, 1.0, 679.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1313 q_vals: [-9.6, -12.8, -8.684, -9.216, -12.8, -12.8, -inf]
Step 1947 2 visits [12.0, 1.0, 680.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1314 q_vals: [-9.6, -12.8, -8.671, -9.216, -12.8, -12.8, -inf]
Step 1948 2 visits [12.0, 1.0, 681.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1314 q_vals: [-9.6, -12.8, -8.677, -9.216, -12.8, -12.8, -inf]
Step 1949 2 visits [12.0, 1.0, 682.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1314 q_vals: [-9.6, -12.8, -8.683, -9.216, -12.8, -12.8, -inf]
Step 1950 2 visits [12.0, 1.0, 683.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1315 q_vals: [-9.6, -12.8, -8.671, -9.216, -12.8, -12.8, -inf]
Step 1951 2 visits [12.0, 1.0, 684.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1315 q_vals: [-9.6, -12.8, -8.677, -9.216, -12.8, -12.8, -inf]
Step 1952 2 visits [12.0, 1.0, 685.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1315 q_vals: [-9.6, -12.8, -8.664, -9.216, -12.8, -12.8, -inf]
Step 1953 2 visits [12.0, 1.0, 686.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1316 q_vals: [-9.6, -12.8, -8.67, -9.216, -12.8, -12.8, -inf]
Step 1954 2 visits [12.0, 1.0, 687.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1316 q_vals: [-9.6, -12.8, -8.676, -9.216, -12.8, -12.8, -inf]
Step 1955 2 visits [12.0, 1.0, 688.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1316 q_vals: [-9.6, -12.8, -8.682, -9.216, -12.8, -12.8, -inf]
Step 1956 2 visits [12.0, 1.0, 689.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1317 q_vals: [-9.6, -12.8, -8.67, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1319, "number_of_timesteps": 130999, "per_episode_reward": -352.07, "episode_reward_trend_value": 0.17275567218333537, "biggest_recent_change": 2.6084750730588553},
Step 1957 2 visits [12.0, 1.0, 690.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1319 q_vals: [-9.6, -12.8, -8.676, -9.216, -12.8, -12.8, -inf]
Step 1958 2 visits [12.0, 1.0, 691.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1321 q_vals: [-9.6, -12.8, -8.682, -9.216, -12.8, -12.8, -inf]
Step 1959 2 visits [12.0, 1.0, 692.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1321 q_vals: [-9.6, -12.8, -8.687, -9.216, -12.8, -12.8, -inf]
Step 1960 2 visits [12.0, 1.0, 693.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1321 q_vals: [-9.6, -12.8, -8.693, -9.216, -12.8, -12.8, -inf]
Step 1961 2 visits [12.0, 1.0, 694.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1321 q_vals: [-9.6, -12.8, -8.699, -9.216, -12.8, -12.8, -inf]
Step 1962 2 visits [12.0, 1.0, 695.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1321 q_vals: [-9.6, -12.8, -8.705, -9.216, -12.8, -12.8, -inf]
Step 1963 2 visits [12.0, 1.0, 696.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1322 q_vals: [-9.6, -12.8, -8.711, -9.216, -12.8, -12.8, -inf]
Step 1964 2 visits [12.0, 1.0, 697.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1322 q_vals: [-9.6, -12.8, -8.699, -9.216, -12.8, -12.8, -inf]
Step 1965 2 visits [12.0, 1.0, 698.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1323 q_vals: [-9.6, -12.8, -8.704, -9.216, -12.8, -12.8, -inf]
Step 1966 2 visits [12.0, 1.0, 699.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1323 q_vals: [-9.6, -12.8, -8.692, -9.216, -12.8, -12.8, -inf]
Step 1967 2 visits [12.0, 1.0, 700.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1323 q_vals: [-9.6, -12.8, -8.698, -9.216, -12.8, -12.8, -inf]
Step 1968 2 visits [12.0, 1.0, 701.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1324 q_vals: [-9.6, -12.8, -8.704, -9.216, -12.8, -12.8, -inf]
Step 1969 2 visits [12.0, 1.0, 702.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1324 q_vals: [-9.6, -12.8, -8.691, -9.216, -12.8, -12.8, -inf]
Step 1970 2 visits [12.0, 1.0, 703.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1324 q_vals: [-9.6, -12.8, -8.679, -9.216, -12.8, -12.8, -inf]
Step 1971 2 visits [12.0, 1.0, 704.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1324 q_vals: [-9.6, -12.8, -8.667, -9.216, -12.8, -12.8, -inf]
Step 1972 2 visits [12.0, 1.0, 705.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1325 q_vals: [-9.6, -12.8, -8.654, -9.216, -12.8, -12.8, -inf]
Step 1973 2 visits [12.0, 1.0, 706.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1326 q_vals: [-9.6, -12.8, -8.66, -9.216, -12.8, -12.8, -inf]
Step 1974 2 visits [12.0, 1.0, 707.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1327 q_vals: [-9.6, -12.8, -8.648, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1329, "number_of_timesteps": 132292, "per_episode_reward": -350.32, "episode_reward_trend_value": 0.16750119798024724, "biggest_recent_change": 2.6084750730588553},
Step 1975 2 visits [12.0, 1.0, 708.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1329 q_vals: [-9.6, -12.8, -8.636, -9.216, -12.8, -12.8, -inf]
Step 1976 2 visits [12.0, 1.0, 709.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1329 q_vals: [-9.6, -12.8, -8.624, -9.216, -12.8, -12.8, -inf]
Step 1977 2 visits [12.0, 1.0, 710.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1329 q_vals: [-9.6, -12.8, -8.629, -9.216, -12.8, -12.8, -inf]
Step 1978 2 visits [12.0, 1.0, 711.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1330 q_vals: [-9.6, -12.8, -8.635, -9.216, -12.8, -12.8, -inf]
Step 1979 2 visits [12.0, 1.0, 712.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1330 q_vals: [-9.6, -12.8, -8.641, -9.216, -12.8, -12.8, -inf]
Step 1980 2 visits [12.0, 1.0, 713.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1330 q_vals: [-9.6, -12.8, -8.647, -9.216, -12.8, -12.8, -inf]
Step 1981 2 visits [12.0, 1.0, 714.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1331 q_vals: [-9.6, -12.8, -8.635, -9.216, -12.8, -12.8, -inf]
Step 1982 2 visits [12.0, 1.0, 715.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1331 q_vals: [-9.6, -12.8, -8.641, -9.216, -12.8, -12.8, -inf]
Step 1983 2 visits [12.0, 1.0, 716.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1331 q_vals: [-9.6, -12.8, -8.647, -9.216, -12.8, -12.8, -inf]
Step 1984 2 visits [12.0, 1.0, 717.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1331 q_vals: [-9.6, -12.8, -8.652, -9.216, -12.8, -12.8, -inf]
Step 1985 2 visits [12.0, 1.0, 718.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1334 q_vals: [-9.6, -12.8, -8.658, -9.216, -12.8, -12.8, -inf]
Step 1986 2 visits [12.0, 1.0, 719.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1334 q_vals: [-9.6, -12.8, -8.664, -9.216, -12.8, -12.8, -inf]
Step 1987 2 visits [12.0, 1.0, 720.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1334 q_vals: [-9.6, -12.8, -8.652, -9.216, -12.8, -12.8, -inf]
Step 1988 2 visits [12.0, 1.0, 721.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1335 q_vals: [-9.6, -12.8, -8.658, -9.216, -12.8, -12.8, -inf]
Step 1989 2 visits [12.0, 1.0, 722.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1335 q_vals: [-9.6, -12.8, -8.663, -9.216, -12.8, -12.8, -inf]
visits [12.0, 1.0, 723.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1336 q_vals: [-9.6, -12.8, -8.669, -9.216, -12.8, -12.8, -inf]
Step 1991 2 visits [12.0, 1.0, 724.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1337 q_vals: [-9.6, -12.8, -8.675, -9.216, -12.8, -12.8, -inf]
Step 1992 2 visits [12.0, 1.0, 725.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1337 q_vals: [-9.6, -12.8, -8.68, -9.216, -12.8, -12.8, -inf]
Step 1993 2 visits [12.0, 1.0, 726.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1338 q_vals: [-9.6, -12.8, -8.686, -9.216, -12.8, -12.8, -inf]
Step 1994 2 visits [12.0, 1.0, 727.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1338 q_vals: [-9.6, -12.8, -8.692, -9.216, -12.8, -12.8, -inf]
Step 1995 2 visits [12.0, 1.0, 728.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1338 q_vals: [-9.6, -12.8, -8.697, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1340, "number_of_timesteps": 133678, "per_episode_reward": -350.1, "episode_reward_trend_value": 0.15844545313050906, "biggest_recent_change": 2.6084750730588553},
Step 1996 2 visits [12.0, 1.0, 729.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1340 q_vals: [-9.6, -12.8, -8.703, -9.216, -12.8, -12.8, -inf]
Step 1997 2 visits [12.0, 1.0, 730.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1340 q_vals: [-9.6, -12.8, -8.691, -9.216, -12.8, -12.8, -inf]
Step 1998 2 visits [12.0, 1.0, 731.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1340 q_vals: [-9.6, -12.8, -8.697, -9.216, -12.8, -12.8, -inf]
Step 1999 2 visits [12.0, 1.0, 732.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1340 q_vals: [-9.6, -12.8, -8.702, -9.216, -12.8, -12.8, -inf]
Step 2000 2 visits [12.0, 1.0, 733.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1340 q_vals: [-9.6, -12.8, -8.69, -9.216, -12.8, -12.8, -inf]
Step 2001 2 visits [12.0, 1.0, 734.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1340 q_vals: [-9.6, -12.8, -8.679, -9.216, -12.8, -12.8, -inf]
Step 2002 2 visits [12.0, 1.0, 735.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1340 q_vals: [-9.6, -12.8, -8.667, -9.216, -12.8, -12.8, -inf]
Step 2003 2 visits [12.0, 1.0, 736.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1342 q_vals: [-9.6, -12.8, -8.655, -9.216, -12.8, -12.8, -inf]
Step 2004 2 visits [12.0, 1.0, 737.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1344 q_vals: [-9.6, -12.8, -8.661, -9.216, -12.8, -12.8, -inf]
Step 2005 2 visits [12.0, 1.0, 738.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1344 q_vals: [-9.6, -12.8, -8.666, -9.216, -12.8, -12.8, -inf]
Step 2006 2 visits [12.0, 1.0, 739.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1344 q_vals: [-9.6, -12.8, -8.672, -9.216, -12.8, -12.8, -inf]
Step 2007 2 visits [12.0, 1.0, 740.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1345 q_vals: [-9.6, -12.8, -8.66, -9.216, -12.8, -12.8, -inf]
Step 2008 2 visits [12.0, 1.0, 741.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1346 q_vals: [-9.6, -12.8, -8.666, -9.216, -12.8, -12.8, -inf]
Step 2009 2 visits [12.0, 1.0, 742.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1346 q_vals: [-9.6, -12.8, -8.671, -9.216, -12.8, -12.8, -inf]
Step 2010 2 visits [12.0, 1.0, 743.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1346 q_vals: [-9.6, -12.8, -8.677, -9.216, -12.8, -12.8, -inf]
Step 2011 2 visits [12.0, 1.0, 744.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1347 q_vals: [-9.6, -12.8, -8.682, -9.216, -12.8, -12.8, -inf]
Step 2012 2 visits [12.0, 1.0, 745.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1348 q_vals: [-9.6, -12.8, -8.688, -9.216, -12.8, -12.8, -inf]
Step 2013 2 visits [12.0, 1.0, 746.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1349 q_vals: [-9.6, -12.8, -8.688, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1350, "number_of_timesteps": 134731, "per_episode_reward": -348.89, "episode_reward_trend_value": 0.1532802674973305, "biggest_recent_change": 2.6084750730588553},
Step 2014 2 visits [12.0, 1.0, 747.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1350 q_vals: [-9.6, -12.8, -8.693, -9.216, -12.8, -12.8, -inf]
Step 2015 2 visits [12.0, 1.0, 748.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1351 q_vals: [-9.6, -12.8, -8.699, -9.216, -12.8, -12.8, -inf]
Step 2016 2 visits [12.0, 1.0, 749.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1351 q_vals: [-9.6, -12.8, -8.687, -9.216, -12.8, -12.8, -inf]
Step 2017 2 visits [12.0, 1.0, 750.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1352 q_vals: [-9.6, -12.8, -8.676, -9.216, -12.8, -12.8, -inf]
Step 2018 2 visits [12.0, 1.0, 751.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1352 q_vals: [-9.6, -12.8, -8.681, -9.216, -12.8, -12.8, -inf]
Step 2019 2 visits [12.0, 1.0, 752.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1353 q_vals: [-9.6, -12.8, -8.686, -9.216, -12.8, -12.8, -inf]
Step 2020 2 visits [12.0, 1.0, 753.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1353 q_vals: [-9.6, -12.8, -8.692, -9.216, -12.8, -12.8, -inf]
Step 2021 2 visits [12.0, 1.0, 754.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1354 q_vals: [-9.6, -12.8, -8.68, -9.216, -12.8, -12.8, -inf]
Step 2022 2 visits [12.0, 1.0, 755.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1355 q_vals: [-9.6, -12.8, -8.686, -9.216, -12.8, -12.8, -inf]
Step 2023 2 visits [12.0, 1.0, 756.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1355 q_vals: [-9.6, -12.8, -8.691, -9.216, -12.8, -12.8, -inf]
Step 2024 2 visits [12.0, 1.0, 757.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1355 q_vals: [-9.6, -12.8, -8.697, -9.216, -12.8, -12.8, -inf]
Step 2025 2 visits [12.0, 1.0, 758.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1356 q_vals: [-9.6, -12.8, -8.702, -9.216, -12.8, -12.8, -inf]
Step 2026 2 visits [12.0, 1.0, 759.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1357 q_vals: [-9.6, -12.8, -8.708, -9.216, -12.8, -12.8, -inf]
Step 2027 2 visits [12.0, 1.0, 760.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1357 q_vals: [-9.6, -12.8, -8.696, -9.216, -12.8, -12.8, -inf]
Step 2028 2 visits [12.0, 1.0, 761.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1358 q_vals: [-9.6, -12.8, -8.701, -9.216, -12.8, -12.8, -inf]
Step 2029 2 visits [12.0, 1.0, 762.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1358 q_vals: [-9.6, -12.8, -8.707, -9.216, -12.8, -12.8, -inf]
Step 2030 2 visits [12.0, 1.0, 763.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1358 q_vals: [-9.6, -12.8, -8.695, -9.216, -12.8, -12.8, -inf]
Step 2031 2 visits [12.0, 1.0, 764.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1359 q_vals: [-9.6, -12.8, -8.701, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1360, "number_of_timesteps": 136011, "per_episode_reward": -347.24, "episode_reward_trend_value": 0.15556148554102517, "biggest_recent_change": 2.6084750730588553},
Step 2032 2 visits [12.0, 1.0, 765.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1360 q_vals: [-9.6, -12.8, -8.706, -9.216, -12.8, -12.8, -inf]
Step 2033 2 visits [12.0, 1.0, 766.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1360 q_vals: [-9.6, -12.8, -8.712, -9.216, -12.8, -12.8, -inf]
Step 2034 2 visits [12.0, 1.0, 767.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1361 q_vals: [-9.6, -12.8, -8.717, -9.216, -12.8, -12.8, -inf]
Step 2035 2 visits [12.0, 1.0, 768.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1362 q_vals: [-9.6, -12.8, -8.722, -9.216, -12.8, -12.8, -inf]
Step 2036 2 visits [12.0, 1.0, 769.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1363 q_vals: [-9.6, -12.8, -8.727, -9.216, -12.8, -12.8, -inf]
Step 2037 2 visits [12.0, 1.0, 770.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1363 q_vals: [-9.6, -12.8, -8.733, -9.216, -12.8, -12.8, -inf]
Step 2038 2 visits [12.0, 1.0, 771.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1364 q_vals: [-9.6, -12.8, -8.738, -9.216, -12.8, -12.8, -inf]
Step 2039 2 visits [12.0, 1.0, 772.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1364 q_vals: [-9.6, -12.8, -8.743, -9.216, -12.8, -12.8, -inf]
Step 2040 2 visits [12.0, 1.0, 773.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1364 q_vals: [-9.6, -12.8, -8.732, -9.216, -12.8, -12.8, -inf]
Step 2041 2 visits [12.0, 1.0, 774.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1364 q_vals: [-9.6, -12.8, -8.737, -9.216, -12.8, -12.8, -inf]
Step 2042 2 visits [12.0, 1.0, 775.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1366 q_vals: [-9.6, -12.8, -8.726, -9.216, -12.8, -12.8, -inf]
Step 2043 2 visits [12.0, 1.0, 776.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1367 q_vals: [-9.6, -12.8, -8.731, -9.216, -12.8, -12.8, -inf]
Step 2044 2 visits [12.0, 1.0, 777.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1368 q_vals: [-9.6, -12.8, -8.736, -9.216, -12.8, -12.8, -inf]
Step 2045 2 visits [12.0, 1.0, 778.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1368 q_vals: [-9.6, -12.8, -8.742, -9.216, -12.8, -12.8, -inf]
Step 2046 2 visits [12.0, 1.0, 779.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1369 q_vals: [-9.6, -12.8, -8.747, -9.216, -12.8, -12.8, -inf]
Step 2047 2 visits [12.0, 1.0, 780.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1369 q_vals: [-9.6, -12.8, -8.745, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1371, "number_of_timesteps": 137288, "per_episode_reward": -346.13, "episode_reward_trend_value": 0.14972513547275967, "biggest_recent_change": 2.6084750730588553},
Step 2048 2 visits [12.0, 1.0, 781.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1371 q_vals: [-9.6, -12.8, -8.75, -9.216, -12.8, -12.8, -inf]
Step 2049 2 visits [12.0, 1.0, 782.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1371 q_vals: [-9.6, -12.8, -8.739, -9.216, -12.8, -12.8, -inf]
Step 2050 2 visits [12.0, 1.0, 783.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1373 q_vals: [-9.6, -12.8, -8.744, -9.216, -12.8, -12.8, -inf]
Step 2051 2 visits [12.0, 1.0, 784.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1374 q_vals: [-9.6, -12.8, -8.749, -9.216, -12.8, -12.8, -inf]
Step 2052 2 visits [12.0, 1.0, 785.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1374 q_vals: [-9.6, -12.8, -8.754, -9.216, -12.8, -12.8, -inf]
Step 2053 2 visits [12.0, 1.0, 786.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1374 q_vals: [-9.6, -12.8, -8.759, -9.216, -12.8, -12.8, -inf]
Step 2054 2 visits [12.0, 1.0, 787.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1375 q_vals: [-9.6, -12.8, -8.765, -9.216, -12.8, -12.8, -inf]
Step 2055 2 visits [12.0, 1.0, 788.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1375 q_vals: [-9.6, -12.8, -8.753, -9.216, -12.8, -12.8, -inf]
Step 2056 2 visits [12.0, 1.0, 789.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1376 q_vals: [-9.6, -12.8, -8.759, -9.216, -12.8, -12.8, -inf]
Step 2057 2 visits [12.0, 1.0, 790.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1376 q_vals: [-9.6, -12.8, -8.764, -9.216, -12.8, -12.8, -inf]
Step 2058 2 visits [12.0, 1.0, 791.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1377 q_vals: [-9.6, -12.8, -8.769, -9.216, -12.8, -12.8, -inf]
Step 2059 2 visits [12.0, 1.0, 792.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1377 q_vals: [-9.6, -12.8, -8.774, -9.216, -12.8, -12.8, -inf]
Step 2060 2 visits [12.0, 1.0, 793.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1379 q_vals: [-9.6, -12.8, -8.779, -9.216, -12.8, -12.8, -inf]
Step 2061 2 visits [12.0, 1.0, 794.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1379 q_vals: [-9.6, -12.8, -8.784, -9.216, -12.8, -12.8, -inf]
Step 2062 2 visits [12.0, 1.0, 795.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1379 q_vals: [-9.6, -12.8, -8.789, -9.216, -12.8, -12.8, -inf]
Step 2063 2 visits [12.0, 1.0, 796.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1379 q_vals: [-9.6, -12.8, -8.778, -9.216, -12.8, -12.8, -inf]
Step 2064 2 visits [12.0, 1.0, 797.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1379 q_vals: [-9.6, -12.8, -8.783, -9.216, -12.8, -12.8, -inf]
Step 2065 2 visits [12.0, 1.0, 798.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1379 q_vals: [-9.6, -12.8, -8.772, -9.216, -12.8, -12.8, -inf]
Step 2066 2 visits [12.0, 1.0, 799.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1380 q_vals: [-9.6, -12.8, -8.761, -9.216, -12.8, -12.8, -inf]
Step 2067 2 visits [12.0, 1.0, 800.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1380 q_vals: [-9.6, -12.8, -8.75, -9.216, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1381, "number_of_timesteps": 138183, "per_episode_reward": -342.84, "episode_reward_trend_value": 0.1748804849285837, "biggest_recent_change": 3.2890257350297816},
Step 2068 2 visits [12.0, 1.0, 801.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1381 q_vals: [-9.6, -12.8, -8.755, -9.216, -12.8, -12.8, -inf]
Step 2069 2 visits [12.0, 1.0, 802.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1382 q_vals: [-9.6, -12.8, -8.76, -9.216, -12.8, -12.8, -inf]
Step 2070 2 visits [12.0, 1.0, 803.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1382 q_vals: [-9.6, -12.8, -8.765, -9.216, -12.8, -12.8, -inf]
Step 2071 2 visits [12.0, 1.0, 804.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1383 q_vals: [-9.6, -12.8, -8.77, -9.216, -12.8, -12.8, -inf]
Step 2072 2 visits [12.0, 1.0, 805.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1383 q_vals: [-9.6, -12.8, -8.775, -9.216, -12.8, -12.8, -inf]
Step 2073 2 visits [12.0, 1.0, 806.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1383 q_vals: [-9.6, -12.8, -8.78, -9.216, -12.8, -12.8, -inf]
Step 2074 2 visits [12.0, 1.0, 807.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1383 q_vals: [-9.6, -12.8, -8.785, -9.216, -12.8, -12.8, -inf]
Step 2075 2 visits [12.0, 1.0, 808.0, 25.0, 1.0, 1.0, 1000.0]  episode_count: 1384 q_vals: [-9.6, -12.8, -8.79, -9.216, -12.8, -12.8, -inf]
Step 2076 3 visits [12.0, 1.0, 808.0, 26.0, 1.0, 1.0, 1000.0]  episode_count: 1385 q_vals: [-9.6, -12.8, -8.79, -8.862, -12.8, -12.8, -inf]
Step 2077 3 visits [12.0, 1.0, 808.0, 27.0, 1.0, 1.0, 1000.0]  episode_count: 1385 q_vals: [-9.6, -12.8, -8.79, -9.007, -12.8, -12.8, -inf]
Step 2078 3 visits [12.0, 1.0, 808.0, 28.0, 1.0, 1.0, 1000.0]  episode_count: 1385 q_vals: [-9.6, -12.8, -8.79, -9.143, -12.8, -12.8, -inf]
Step 2079 3 visits [12.0, 1.0, 808.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1386 q_vals: [-9.6, -12.8, -8.79, -9.269, -12.8, -12.8, -inf]
Step 2080 2 visits [12.0, 1.0, 809.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1387 q_vals: [-9.6, -12.8, -8.779, -9.269, -12.8, -12.8, -inf]
Step 2081 2 visits [12.0, 1.0, 810.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1387 q_vals: [-9.6, -12.8, -8.784, -9.269, -12.8, -12.8, -inf]
Step 2082 2 visits [12.0, 1.0, 811.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1388 q_vals: [-9.6, -12.8, -8.789, -9.269, -12.8, -12.8, -inf]
Step 2083 2 visits [12.0, 1.0, 812.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1388 q_vals: [-9.6, -12.8, -8.794, -9.269, -12.8, -12.8, -inf]
Step 2084 2 visits [12.0, 1.0, 813.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1388 q_vals: [-9.6, -12.8, -8.799, -9.269, -12.8, -12.8, -inf]
Step 2085 2 visits [12.0, 1.0, 814.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1388 q_vals: [-9.6, -12.8, -8.804, -9.269, -12.8, -12.8, -inf]
Step 2086 2 visits [12.0, 1.0, 815.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1388 q_vals: [-9.6, -12.8, -8.809, -9.269, -12.8, -12.8, -inf]
Step 2087 2 visits [12.0, 1.0, 816.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1388 q_vals: [-9.6, -12.8, -8.814, -9.269, -12.8, -12.8, -inf]
Step 2088 2 visits [12.0, 1.0, 817.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1388 q_vals: [-9.6, -12.8, -8.819, -9.269, -12.8, -12.8, -inf]
Step 2089 2 visits [12.0, 1.0, 818.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1388 q_vals: [-9.6, -12.8, -8.824, -9.269, -12.8, -12.8, -inf]
Step 2090 2 visits [12.0, 1.0, 819.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1389 q_vals: [-9.6, -12.8, -8.828, -9.269, -12.8, -12.8, -inf]
Step 2091 2 visits [12.0, 1.0, 820.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1390 q_vals: [-9.6, -12.8, -8.833, -9.269, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1392, "number_of_timesteps": 140005, "per_episode_reward": -342.95, "episode_reward_trend_value": 0.15648777845316317, "biggest_recent_change": 3.2890257350297816},
Step 2092 2 visits [12.0, 1.0, 821.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1392 q_vals: [-9.6, -12.8, -8.838, -9.269, -12.8, -12.8, -inf]
Step 2093 2 visits [12.0, 1.0, 822.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1393 q_vals: [-9.6, -12.8, -8.827, -9.269, -12.8, -12.8, -inf]
Step 2094 2 visits [12.0, 1.0, 823.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1394 q_vals: [-9.6, -12.8, -8.832, -9.269, -12.8, -12.8, -inf]
Step 2095 2 visits [12.0, 1.0, 824.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1394 q_vals: [-9.6, -12.8, -8.837, -9.269, -12.8, -12.8, -inf]
Step 2096 2 visits [12.0, 1.0, 825.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1394 q_vals: [-9.6, -12.8, -8.826, -9.269, -12.8, -12.8, -inf]
Step 2097 2 visits [12.0, 1.0, 826.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1395 q_vals: [-9.6, -12.8, -8.831, -9.269, -12.8, -12.8, -inf]
Step 2098 2 visits [12.0, 1.0, 827.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1395 q_vals: [-9.6, -12.8, -8.836, -9.269, -12.8, -12.8, -inf]
Step 2099 2 visits [12.0, 1.0, 828.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1395 q_vals: [-9.6, -12.8, -8.841, -9.269, -12.8, -12.8, -inf]
Step 2100 2 visits [12.0, 1.0, 829.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1395 q_vals: [-9.6, -12.8, -8.83, -9.269, -12.8, -12.8, -inf]
Step 2101 2 visits [12.0, 1.0, 830.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1395 q_vals: [-9.6, -12.8, -8.835, -9.269, -12.8, -12.8, -inf]
Step 2102 2 visits [12.0, 1.0, 831.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1396 q_vals: [-9.6, -12.8, -8.84, -9.269, -12.8, -12.8, -inf]
Step 2103 2 visits [12.0, 1.0, 832.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1398 q_vals: [-9.6, -12.8, -8.844, -9.269, -12.8, -12.8, -inf]
Step 2104 2 visits [12.0, 1.0, 833.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1398 q_vals: [-9.6, -12.8, -8.849, -9.269, -12.8, -12.8, -inf]
Step 2105 2 visits [12.0, 1.0, 834.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1401 q_vals: [-9.6, -12.8, -8.839, -9.269, -12.8, -12.8, -inf]
Step 2106 2 visits [12.0, 1.0, 835.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1401 q_vals: [-9.6, -12.8, -8.828, -9.269, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1402, "number_of_timesteps": 141263, "per_episode_reward": -340.79, "episode_reward_trend_value": 0.1514927022951636, "biggest_recent_change": 3.2890257350297816},
Step 2107 2 visits [12.0, 1.0, 836.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1402 q_vals: [-9.6, -12.8, -8.817, -9.269, -12.8, -12.8, -inf]
Step 2108 2 visits [12.0, 1.0, 837.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1402 q_vals: [-9.6, -12.8, -8.822, -9.269, -12.8, -12.8, -inf]
Step 2109 2 visits [12.0, 1.0, 838.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1402 q_vals: [-9.6, -12.8, -8.812, -9.269, -12.8, -12.8, -inf]
Step 2110 2 visits [12.0, 1.0, 839.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1402 q_vals: [-9.6, -12.8, -8.801, -9.269, -12.8, -12.8, -inf]
Step 2111 2 visits [12.0, 1.0, 840.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1402 q_vals: [-9.6, -12.8, -8.791, -9.269, -12.8, -12.8, -inf]
Step 2112 2 visits [12.0, 1.0, 841.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1402 q_vals: [-9.6, -12.8, -8.795, -9.269, -12.8, -12.8, -inf]
Step 2113 2 visits [12.0, 1.0, 842.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1403 q_vals: [-9.6, -12.8, -8.785, -9.269, -12.8, -12.8, -inf]
Step 2114 2 visits [12.0, 1.0, 843.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1405 q_vals: [-9.6, -12.8, -8.79, -9.269, -12.8, -12.8, -inf]
Step 2115 2 visits [12.0, 1.0, 844.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1406 q_vals: [-9.6, -12.8, -8.794, -9.269, -12.8, -12.8, -inf]
Step 2116 2 visits [12.0, 1.0, 845.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1407 q_vals: [-9.6, -12.8, -8.799, -9.269, -12.8, -12.8, -inf]
Step 2117 2 visits [12.0, 1.0, 846.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1408 q_vals: [-9.6, -12.8, -8.804, -9.269, -12.8, -12.8, -inf]
Step 2118 2 visits [12.0, 1.0, 847.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1408 q_vals: [-9.6, -12.8, -8.794, -9.269, -12.8, -12.8, -inf]
Step 2119 2 visits [12.0, 1.0, 848.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1408 q_vals: [-9.6, -12.8, -8.783, -9.269, -12.8, -12.8, -inf]
Step 2120 2 visits [12.0, 1.0, 849.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1409 q_vals: [-9.6, -12.8, -8.788, -9.269, -12.8, -12.8, -inf]
Step 2121 2 visits [12.0, 1.0, 850.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1409 q_vals: [-9.6, -12.8, -8.793, -9.269, -12.8, -12.8, -inf]
Step 2122 2 visits [12.0, 1.0, 851.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1409 q_vals: [-9.6, -12.8, -8.797, -9.269, -12.8, -12.8, -inf]
Step 2123 2 visits [12.0, 1.0, 852.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1409 q_vals: [-9.6, -12.8, -8.802, -9.269, -12.8, -12.8, -inf]
Step 2124 2 visits [12.0, 1.0, 853.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1410 q_vals: [-9.6, -12.8, -8.792, -9.269, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1413, "number_of_timesteps": 142412, "per_episode_reward": -338.81, "episode_reward_trend_value": 0.14731360340593497, "biggest_recent_change": 3.2890257350297816},
Step 2125 2 visits [12.0, 1.0, 854.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1413 q_vals: [-9.6, -12.8, -8.796, -9.269, -12.8, -12.8, -inf]
Step 2126 2 visits [12.0, 1.0, 855.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1414 q_vals: [-9.6, -12.8, -8.801, -9.269, -12.8, -12.8, -inf]
Step 2127 2 visits [12.0, 1.0, 856.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1414 q_vals: [-9.6, -12.8, -8.791, -9.269, -12.8, -12.8, -inf]
Step 2128 2 visits [12.0, 1.0, 857.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1414 q_vals: [-9.6, -12.8, -8.781, -9.269, -12.8, -12.8, -inf]
Step 2129 2 visits [12.0, 1.0, 858.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1414 q_vals: [-9.6, -12.8, -8.785, -9.269, -12.8, -12.8, -inf]
Step 2130 2 visits [12.0, 1.0, 859.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1415 q_vals: [-9.6, -12.8, -8.79, -9.269, -12.8, -12.8, -inf]
Step 2131 2 visits [12.0, 1.0, 860.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1415 q_vals: [-9.6, -12.8, -8.795, -9.269, -12.8, -12.8, -inf]
Step 2132 2 visits [12.0, 1.0, 861.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1418 q_vals: [-9.6, -12.8, -8.799, -9.269, -12.8, -12.8, -inf]
Step 2133 2 visits [12.0, 1.0, 862.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1418 q_vals: [-9.6, -12.8, -8.789, -9.269, -12.8, -12.8, -inf]
Step 2134 2 visits [12.0, 1.0, 863.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1420 q_vals: [-9.6, -12.8, -8.779, -9.269, -12.8, -12.8, -inf]
Step 2135 2 visits [12.0, 1.0, 864.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1421 q_vals: [-9.6, -12.8, -8.783, -9.269, -12.8, -12.8, -inf]
Step 2136 2 visits [12.0, 1.0, 865.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1421 q_vals: [-9.6, -12.8, -8.773, -9.269, -12.8, -12.8, -inf]
Step 2137 2 visits [12.0, 1.0, 866.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1422 q_vals: [-9.6, -12.8, -8.763, -9.269, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1423, "number_of_timesteps": 143300, "per_episode_reward": -336.52, "episode_reward_trend_value": 0.15333143005395805, "biggest_recent_change": 3.2890257350297816},
Step 2138 2 visits [12.0, 1.0, 867.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1423 q_vals: [-9.6, -12.8, -8.768, -9.269, -12.8, -12.8, -inf]
Step 2139 2 visits [12.0, 1.0, 868.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1423 q_vals: [-9.6, -12.8, -8.773, -9.269, -12.8, -12.8, -inf]
Step 2140 2 visits [12.0, 1.0, 869.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1424 q_vals: [-9.6, -12.8, -8.777, -9.269, -12.8, -12.8, -inf]
Step 2141 2 visits [12.0, 1.0, 870.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1426 q_vals: [-9.6, -12.8, -8.767, -9.269, -12.8, -12.8, -inf]
Step 2142 2 visits [12.0, 1.0, 871.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1426 q_vals: [-9.6, -12.8, -8.757, -9.269, -12.8, -12.8, -inf]
Step 2143 2 visits [12.0, 1.0, 872.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1427 q_vals: [-9.6, -12.8, -8.747, -9.269, -12.8, -12.8, -inf]
Step 2144 2 visits [12.0, 1.0, 873.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1427 q_vals: [-9.6, -12.8, -8.737, -9.269, -12.8, -12.8, -inf]
Step 2145 2 visits [12.0, 1.0, 874.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1427 q_vals: [-9.6, -12.8, -8.742, -9.269, -12.8, -12.8, -inf]
Step 2146 2 visits [12.0, 1.0, 875.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1427 q_vals: [-9.6, -12.8, -8.746, -9.269, -12.8, -12.8, -inf]
Step 2147 2 visits [12.0, 1.0, 876.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1427 q_vals: [-9.6, -12.8, -8.751, -9.269, -12.8, -12.8, -inf]
Step 2148 2 visits [12.0, 1.0, 877.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1429 q_vals: [-9.6, -12.8, -8.755, -9.269, -12.8, -12.8, -inf]
Step 2149 2 visits [12.0, 1.0, 878.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1430 q_vals: [-9.6, -12.8, -8.76, -9.269, -12.8, -12.8, -inf]
Step 2150 2 visits [12.0, 1.0, 879.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1431 q_vals: [-9.6, -12.8, -8.763, -9.269, -12.8, -12.8, -inf]
Step 2151 2 visits [12.0, 1.0, 880.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1431 q_vals: [-9.6, -12.8, -8.768, -9.269, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1433, "number_of_timesteps": 144249, "per_episode_reward": -334.02, "episode_reward_trend_value": 0.17869094983201927, "biggest_recent_change": 3.2890257350297816},
Step 2152 2 visits [12.0, 1.0, 881.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1433 q_vals: [-9.6, -12.8, -8.773, -9.269, -12.8, -12.8, -inf]
Step 2153 2 visits [12.0, 1.0, 882.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1433 q_vals: [-9.6, -12.8, -8.763, -9.269, -12.8, -12.8, -inf]
Step 2154 2 visits [12.0, 1.0, 883.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1433 q_vals: [-9.6, -12.8, -8.758, -9.269, -12.8, -12.8, -inf]
Step 2155 2 visits [12.0, 1.0, 884.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1433 q_vals: [-9.6, -12.8, -8.762, -9.269, -12.8, -12.8, -inf]
Step 2156 2 visits [12.0, 1.0, 885.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1433 q_vals: [-9.6, -12.8, -8.752, -9.269, -12.8, -12.8, -inf]
Step 2157 2 visits [12.0, 1.0, 886.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1433 q_vals: [-9.6, -12.8, -8.742, -9.269, -12.8, -12.8, -inf]
Step 2158 2 visits [12.0, 1.0, 887.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1433 q_vals: [-9.6, -12.8, -8.747, -9.269, -12.8, -12.8, -inf]
Step 2159 2 visits [12.0, 1.0, 888.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1434 q_vals: [-9.6, -12.8, -8.751, -9.269, -12.8, -12.8, -inf]
Step 2160 2 visits [12.0, 1.0, 889.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1435 q_vals: [-9.6, -12.8, -8.756, -9.269, -12.8, -12.8, -inf]
Step 2161 2 visits [12.0, 1.0, 890.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1435 q_vals: [-9.6, -12.8, -8.761, -9.269, -12.8, -12.8, -inf]
Step 2162 2 visits [12.0, 1.0, 891.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1438 q_vals: [-9.6, -12.8, -8.751, -9.269, -12.8, -12.8, -inf]
Step 2163 2 visits [12.0, 1.0, 892.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1438 q_vals: [-9.6, -12.8, -8.755, -9.269, -12.8, -12.8, -inf]
Step 2164 2 visits [12.0, 1.0, 893.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1439 q_vals: [-9.6, -12.8, -8.76, -9.269, -12.8, -12.8, -inf]
Step 2165 2 visits [12.0, 1.0, 894.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1439 q_vals: [-9.6, -12.8, -8.75, -9.269, -12.8, -12.8, -inf]
Step 2166 2 visits [12.0, 1.0, 895.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1439 q_vals: [-9.6, -12.8, -8.755, -9.269, -12.8, -12.8, -inf]
Step 2167 2 visits [12.0, 1.0, 896.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1439 q_vals: [-9.6, -12.8, -8.745, -9.269, -12.8, -12.8, -inf]
Step 2168 2 visits [12.0, 1.0, 897.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1440 q_vals: [-9.6, -12.8, -8.749, -9.269, -12.8, -12.8, -inf]
Step 2169 2 visits [12.0, 1.0, 898.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1441 q_vals: [-9.6, -12.8, -8.74, -9.269, -12.8, -12.8, -inf]
Step 2170 2 visits [12.0, 1.0, 899.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1441 q_vals: [-9.6, -12.8, -8.744, -9.269, -12.8, -12.8, -inf]
Step 2171 2 visits [12.0, 1.0, 900.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1442 q_vals: [-9.6, -12.8, -8.749, -9.269, -12.8, -12.8, -inf]
Step 2172 2 visits [12.0, 1.0, 901.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1442 q_vals: [-9.6, -12.8, -8.753, -9.269, -12.8, -12.8, -inf]
Step 2173 2 visits [12.0, 1.0, 902.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1442 q_vals: [-9.6, -12.8, -8.758, -9.269, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1443, "number_of_timesteps": 145288, "per_episode_reward": -329.19, "episode_reward_trend_value": 0.2188764336402446, "biggest_recent_change": 4.8332756390805685},
Step 2174 2 visits [12.0, 1.0, 903.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1443 q_vals: [-9.6, -12.8, -8.762, -9.269, -12.8, -12.8, -inf]
Step 2175 2 visits [12.0, 1.0, 904.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1443 q_vals: [-9.6, -12.8, -8.766, -9.269, -12.8, -12.8, -inf]
Step 2176 2 visits [12.0, 1.0, 905.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1443 q_vals: [-9.6, -12.8, -8.757, -9.269, -12.8, -12.8, -inf]
Step 2177 2 visits [12.0, 1.0, 906.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1445 q_vals: [-9.6, -12.8, -8.747, -9.269, -12.8, -12.8, -inf]
Step 2178 2 visits [12.0, 1.0, 907.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1445 q_vals: [-9.6, -12.8, -8.752, -9.269, -12.8, -12.8, -inf]
Step 2179 2 visits [12.0, 1.0, 908.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1445 q_vals: [-9.6, -12.8, -8.756, -9.269, -12.8, -12.8, -inf]
Step 2180 2 visits [12.0, 1.0, 909.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1447 q_vals: [-9.6, -12.8, -8.761, -9.269, -12.8, -12.8, -inf]
Step 2181 2 visits [12.0, 1.0, 910.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1448 q_vals: [-9.6, -12.8, -8.765, -9.269, -12.8, -12.8, -inf]
Step 2182 2 visits [12.0, 1.0, 911.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1449 q_vals: [-9.6, -12.8, -8.769, -9.269, -12.8, -12.8, -inf]
Step 2183 2 visits [12.0, 1.0, 912.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1449 q_vals: [-9.6, -12.8, -8.76, -9.269, -12.8, -12.8, -inf]
Step 2184 2 visits [12.0, 1.0, 913.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1449 q_vals: [-9.6, -12.8, -8.764, -9.269, -12.8, -12.8, -inf]
Step 2185 2 visits [12.0, 1.0, 914.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1449 q_vals: [-9.6, -12.8, -8.769, -9.269, -12.8, -12.8, -inf]
Step 2186 2 visits [12.0, 1.0, 915.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1450 q_vals: [-9.6, -12.8, -8.773, -9.269, -12.8, -12.8, -inf]
Step 2187 2 visits [12.0, 1.0, 916.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1451 q_vals: [-9.6, -12.8, -8.777, -9.269, -12.8, -12.8, -inf]
Step 2188 2 visits [12.0, 1.0, 917.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1452 q_vals: [-9.6, -12.8, -8.782, -9.269, -12.8, -12.8, -inf]
Step 2189 2 visits [12.0, 1.0, 918.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1452 q_vals: [-9.6, -12.8, -8.786, -9.269, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1453, "number_of_timesteps": 146489, "per_episode_reward": -328.28, "episode_reward_trend_value": 0.21066962401200157, "biggest_recent_change": 4.8332756390805685},
Step 2190 2 visits [12.0, 1.0, 919.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1453 q_vals: [-9.6, -12.8, -8.791, -9.269, -12.8, -12.8, -inf]
Step 2191 2 visits [12.0, 1.0, 920.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1453 q_vals: [-9.6, -12.8, -8.795, -9.269, -12.8, -12.8, -inf]
Step 2192 2 visits [12.0, 1.0, 921.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1454 q_vals: [-9.6, -12.8, -8.799, -9.269, -12.8, -12.8, -inf]
Step 2193 2 visits [12.0, 1.0, 922.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1455 q_vals: [-9.6, -12.8, -8.804, -9.269, -12.8, -12.8, -inf]
Step 2194 2 visits [12.0, 1.0, 923.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1455 q_vals: [-9.6, -12.8, -8.807, -9.269, -12.8, -12.8, -inf]
Step 2195 2 visits [12.0, 1.0, 924.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1456 q_vals: [-9.6, -12.8, -8.811, -9.269, -12.8, -12.8, -inf]
Step 2196 2 visits [12.0, 1.0, 925.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1457 q_vals: [-9.6, -12.8, -8.815, -9.269, -12.8, -12.8, -inf]
Step 2197 2 visits [12.0, 1.0, 926.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1457 q_vals: [-9.6, -12.8, -8.82, -9.269, -12.8, -12.8, -inf]
Step 2198 2 visits [12.0, 1.0, 927.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1458 q_vals: [-9.6, -12.8, -8.824, -9.269, -12.8, -12.8, -inf]
Step 2199 2 visits [12.0, 1.0, 928.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1458 q_vals: [-9.6, -12.8, -8.828, -9.269, -12.8, -12.8, -inf]
Step 2200 2 visits [12.0, 1.0, 929.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1459 q_vals: [-9.6, -12.8, -8.832, -9.269, -12.8, -12.8, -inf]
Step 2201 2 visits [12.0, 1.0, 930.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1459 q_vals: [-9.6, -12.8, -8.837, -9.269, -12.8, -12.8, -inf]
Step 2202 2 visits [12.0, 1.0, 931.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1461 q_vals: [-9.6, -12.8, -8.841, -9.269, -12.8, -12.8, -inf]
Step 2203 2 visits [12.0, 1.0, 932.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1462 q_vals: [-9.6, -12.8, -8.831, -9.269, -12.8, -12.8, -inf]
Step 2204 2 visits [12.0, 1.0, 933.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1462 q_vals: [-9.6, -12.8, -8.836, -9.269, -12.8, -12.8, -inf]
Step 2205 2 visits [12.0, 1.0, 934.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1462 q_vals: [-9.6, -12.8, -8.84, -9.269, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1463, "number_of_timesteps": 147739, "per_episode_reward": -325.96, "episode_reward_trend_value": 0.22401583244908982, "biggest_recent_change": 4.8332756390805685},
Step 2206 2 visits [12.0, 1.0, 935.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1463 q_vals: [-9.6, -12.8, -8.844, -9.269, -12.8, -12.8, -inf]
Step 2207 2 visits [12.0, 1.0, 936.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1464 q_vals: [-9.6, -12.8, -8.848, -9.269, -12.8, -12.8, -inf]
Step 2208 2 visits [12.0, 1.0, 937.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1464 q_vals: [-9.6, -12.8, -8.853, -9.269, -12.8, -12.8, -inf]
Step 2209 2 visits [12.0, 1.0, 938.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1464 q_vals: [-9.6, -12.8, -8.857, -9.269, -12.8, -12.8, -inf]
Step 2210 2 visits [12.0, 1.0, 939.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1464 q_vals: [-9.6, -12.8, -8.861, -9.269, -12.8, -12.8, -inf]
Step 2211 2 visits [12.0, 1.0, 940.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1464 q_vals: [-9.6, -12.8, -8.865, -9.269, -12.8, -12.8, -inf]
Step 2212 2 visits [12.0, 1.0, 941.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1465 q_vals: [-9.6, -12.8, -8.862, -9.269, -12.8, -12.8, -inf]
Step 2213 2 visits [12.0, 1.0, 942.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1466 q_vals: [-9.6, -12.8, -8.866, -9.269, -12.8, -12.8, -inf]
Step 2214 2 visits [12.0, 1.0, 943.0, 29.0, 1.0, 1.0, 1000.0]  episode_count: 1468 q_vals: [-9.6, -12.8, -8.87, -9.269, -12.8, -12.8, -inf]
Step 2215 3 visits [12.0, 1.0, 943.0, 30.0, 1.0, 1.0, 1000.0]  episode_count: 1468 q_vals: [-9.6, -12.8, -8.87, -8.96, -12.8, -12.8, -inf]
Step 2216 3 visits [12.0, 1.0, 943.0, 31.0, 1.0, 1.0, 1000.0]  episode_count: 1469 q_vals: [-9.6, -12.8, -8.87, -9.084, -12.8, -12.8, -inf]
Step 2217 3 visits [12.0, 1.0, 943.0, 32.0, 1.0, 1.0, 1000.0]  episode_count: 1469 q_vals: [-9.6, -12.8, -8.87, -8.8, -12.8, -12.8, -inf]
Step 2218 3 visits [12.0, 1.0, 943.0, 33.0, 1.0, 1.0, 1000.0]  episode_count: 1469 q_vals: [-9.6, -12.8, -8.87, -8.921, -12.8, -12.8, -inf]
Step 2219 3 visits [12.0, 1.0, 943.0, 34.0, 1.0, 1.0, 1000.0]  episode_count: 1470 q_vals: [-9.6, -12.8, -8.87, -9.035, -12.8, -12.8, -inf]
Step 2220 3 visits [12.0, 1.0, 943.0, 35.0, 1.0, 1.0, 1000.0]  episode_count: 1470 q_vals: [-9.6, -12.8, -8.87, -9.143, -12.8, -12.8, -inf]
Step 2221 3 visits [12.0, 1.0, 943.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1472 q_vals: [-9.6, -12.8, -8.87, -9.244, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1473, "number_of_timesteps": 148899, "per_episode_reward": -325.48, "episode_reward_trend_value": 0.19284904261061228, "biggest_recent_change": 4.8332756390805685},
Step 2222 2 visits [12.0, 1.0, 944.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1473 q_vals: [-9.6, -12.8, -8.874, -9.244, -12.8, -12.8, -inf]
Step 2223 2 visits [12.0, 1.0, 945.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1473 q_vals: [-9.6, -12.8, -8.878, -9.244, -12.8, -12.8, -inf]
Step 2224 2 visits [12.0, 1.0, 946.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1474 q_vals: [-9.6, -12.8, -8.882, -9.244, -12.8, -12.8, -inf]
Step 2225 2 visits [12.0, 1.0, 947.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1475 q_vals: [-9.6, -12.8, -8.873, -9.244, -12.8, -12.8, -inf]
Step 2226 2 visits [12.0, 1.0, 948.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1475 q_vals: [-9.6, -12.8, -8.877, -9.244, -12.8, -12.8, -inf]
Step 2227 2 visits [12.0, 1.0, 949.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1476 q_vals: [-9.6, -12.8, -8.881, -9.244, -12.8, -12.8, -inf]
Step 2228 2 visits [12.0, 1.0, 950.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1476 q_vals: [-9.6, -12.8, -8.872, -9.244, -12.8, -12.8, -inf]
Step 2229 2 visits [12.0, 1.0, 951.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1476 q_vals: [-9.6, -12.8, -8.876, -9.244, -12.8, -12.8, -inf]
Step 2230 2 visits [12.0, 1.0, 952.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1477 q_vals: [-9.6, -12.8, -8.88, -9.244, -12.8, -12.8, -inf]
Step 2231 2 visits [12.0, 1.0, 953.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1478 q_vals: [-9.6, -12.8, -8.871, -9.244, -12.8, -12.8, -inf]
Step 2232 2 visits [12.0, 1.0, 954.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1478 q_vals: [-9.6, -12.8, -8.862, -9.244, -12.8, -12.8, -inf]
Step 2233 2 visits [12.0, 1.0, 955.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1478 q_vals: [-9.6, -12.8, -8.866, -9.244, -12.8, -12.8, -inf]
Step 2234 2 visits [12.0, 1.0, 956.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1478 q_vals: [-9.6, -12.8, -8.856, -9.244, -12.8, -12.8, -inf]
Step 2235 2 visits [12.0, 1.0, 957.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1478 q_vals: [-9.6, -12.8, -8.86, -9.244, -12.8, -12.8, -inf]
Step 2236 2 visits [12.0, 1.0, 958.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1478 q_vals: [-9.6, -12.8, -8.851, -9.244, -12.8, -12.8, -inf]
Step 2237 2 visits [12.0, 1.0, 959.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1478 q_vals: [-9.6, -12.8, -8.855, -9.244, -12.8, -12.8, -inf]
[12.0, 1.0, 960.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1479 q_vals: [-9.6, -12.8, -8.846, -9.244, -12.8, -12.8, -inf]
Step 2239 2 visits [12.0, 1.0, 961.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1480 q_vals: [-9.6, -12.8, -8.837, -9.244, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1483, "number_of_timesteps": 150068, "per_episode_reward": -326.73, "episode_reward_trend_value": 0.1802653498177386, "biggest_recent_change": 4.8332756390805685},
Step 2240 2 visits [12.0, 1.0, 962.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1483 q_vals: [-9.6, -12.8, -8.828, -9.244, -12.8, -12.8, -inf]
Step 2241 2 visits [12.0, 1.0, 963.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1485 q_vals: [-9.6, -12.8, -8.832, -9.244, -12.8, -12.8, -inf]
Step 2242 2 visits [12.0, 1.0, 964.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1485 q_vals: [-9.6, -12.8, -8.836, -9.244, -12.8, -12.8, -inf]
Step 2243 2 visits [12.0, 1.0, 965.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1485 q_vals: [-9.6, -12.8, -8.84, -9.244, -12.8, -12.8, -inf]
Step 2244 2 visits [12.0, 1.0, 966.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1485 q_vals: [-9.6, -12.8, -8.844, -9.244, -12.8, -12.8, -inf]
Step 2245 2 visits [12.0, 1.0, 967.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1485 q_vals: [-9.6, -12.8, -8.848, -9.244, -12.8, -12.8, -inf]
Step 2246 2 visits [12.0, 1.0, 968.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1485 q_vals: [-9.6, -12.8, -8.839, -9.244, -12.8, -12.8, -inf]
Step 2247 2 visits [12.0, 1.0, 969.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1485 q_vals: [-9.6, -12.8, -8.843, -9.244, -12.8, -12.8, -inf]
Step 2248 2 visits [12.0, 1.0, 970.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1485 q_vals: [-9.6, -12.8, -8.847, -9.244, -12.8, -12.8, -inf]
Step 2249 2 visits [12.0, 1.0, 971.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1486 q_vals: [-9.6, -12.8, -8.851, -9.244, -12.8, -12.8, -inf]
Step 2250 2 visits [12.0, 1.0, 972.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1486 q_vals: [-9.6, -12.8, -8.855, -9.244, -12.8, -12.8, -inf]
Step 2251 2 visits [12.0, 1.0, 973.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1486 q_vals: [-9.6, -12.8, -8.857, -9.244, -12.8, -12.8, -inf]
Step 2252 2 visits [12.0, 1.0, 974.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1488 q_vals: [-9.6, -12.8, -8.861, -9.244, -12.8, -12.8, -inf]
Step 2253 2 visits [12.0, 1.0, 975.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1489 q_vals: [-9.6, -12.8, -8.865, -9.244, -12.8, -12.8, -inf]
Step 2254 2 visits [12.0, 1.0, 976.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1490 q_vals: [-9.6, -12.8, -8.869, -9.244, -12.8, -12.8, -inf]
Step 2255 2 visits [12.0, 1.0, 977.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1490 q_vals: [-9.6, -12.8, -8.873, -9.244, -12.8, -12.8, -inf]
Step 2256 2 visits [12.0, 1.0, 978.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1490 q_vals: [-9.6, -12.8, -8.864, -9.244, -12.8, -12.8, -inf]
Step 2257 2 visits [12.0, 1.0, 979.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1491 q_vals: [-9.6, -12.8, -8.868, -9.244, -12.8, -12.8, -inf]
Step 2258 2 visits [12.0, 1.0, 980.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1491 q_vals: [-9.6, -12.8, -8.864, -9.244, -12.8, -12.8, -inf]
Step 2259 2 visits [12.0, 1.0, 981.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1491 q_vals: [-9.6, -12.8, -8.868, -9.244, -12.8, -12.8, -inf]
Step 2260 2 visits [12.0, 1.0, 982.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1491 q_vals: [-9.6, -12.8, -8.859, -9.244, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1493, "number_of_timesteps": 151305, "per_episode_reward": -327.27, "episode_reward_trend_value": 0.15023990937025045, "biggest_recent_change": 4.8332756390805685},
Step 2261 2 visits [12.0, 1.0, 983.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1493 q_vals: [-9.6, -12.8, -8.863, -9.244, -12.8, -12.8, -inf]
Step 2262 2 visits [12.0, 1.0, 984.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1493 q_vals: [-9.6, -12.8, -8.867, -9.244, -12.8, -12.8, -inf]
Step 2263 2 visits [12.0, 1.0, 985.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1493 q_vals: [-9.6, -12.8, -8.869, -9.244, -12.8, -12.8, -inf]
Step 2264 2 visits [12.0, 1.0, 986.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1494 q_vals: [-9.6, -12.8, -8.873, -9.244, -12.8, -12.8, -inf]
Step 2265 2 visits [12.0, 1.0, 987.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1494 q_vals: [-9.6, -12.8, -8.877, -9.244, -12.8, -12.8, -inf]
Step 2266 2 visits [12.0, 1.0, 988.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1495 q_vals: [-9.6, -12.8, -8.87, -9.244, -12.8, -12.8, -inf]
Step 2267 2 visits [12.0, 1.0, 989.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1495 q_vals: [-9.6, -12.8, -8.874, -9.244, -12.8, -12.8, -inf]
Step 2268 2 visits [12.0, 1.0, 990.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1496 q_vals: [-9.6, -12.8, -8.878, -9.244, -12.8, -12.8, -inf]
Step 2269 2 visits [12.0, 1.0, 991.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1498 q_vals: [-9.6, -12.8, -8.882, -9.244, -12.8, -12.8, -inf]
Step 2270 2 visits [12.0, 1.0, 992.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1498 q_vals: [-9.6, -12.8, -8.873, -9.244, -12.8, -12.8, -inf]
Step 2271 2 visits [12.0, 1.0, 993.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1498 q_vals: [-9.6, -12.8, -8.864, -9.244, -12.8, -12.8, -inf]
Step 2272 2 visits [12.0, 1.0, 994.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1499 q_vals: [-9.6, -12.8, -8.863, -9.244, -12.8, -12.8, -inf]
Step 2273 2 visits [12.0, 1.0, 995.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1499 q_vals: [-9.6, -12.8, -8.854, -9.244, -12.8, -12.8, -inf]
Step 2274 2 visits [12.0, 1.0, 996.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1500 q_vals: [-9.6, -12.8, -8.858, -9.244, -12.8, -12.8, -inf]
Step 2275 2 visits [12.0, 1.0, 997.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1500 q_vals: [-9.6, -12.8, -8.862, -9.244, -12.8, -12.8, -inf]
{"total_number_of_episodes": 1503, "number_of_timesteps": 152607, "per_episode_reward": -324.93, "episode_reward_trend_value": 0.15415892052132246, "biggest_recent_change": 4.8332756390805685},
Step 2276 2 visits [12.0, 1.0, 998.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1503 q_vals: [-9.6, -12.8, -8.866, -9.244, -12.8, -12.8, -inf]
Step 2277 2 visits [12.0, 1.0, 999.0, 36.0, 1.0, 1.0, 1000.0]  episode_count: 1504 q_vals: [-9.6, -12.8, -8.857, -9.244, -12.8, -12.8, -inf]
Step 2278 2 visits [0.0, 0.0, 1000.0, 0.0, 0.0, 0.0, 1000.0]  episode_count: 1504 q_vals: [0.0, 0.0, -inf, 0.0, 0.0, 0.0, -inf]
 2279 0 visits [1.0, 0.0, 1000.0, 0.0, 0.0, 0.0, 1000.0]  episode_count: 1504 q_vals: [0.0, 0.0, -inf, 0.0, 0.0, 0.0, -inf]
Step 2280 1 visits [1.0, 1.0, 1000.0, 0.0, 0.0, 0.0, 1000.0]  episode_count: 1504 q_vals: [0.0, -15.0, -inf, 0.0, 0.0, 0.0, -inf]
Step 2281 3 visits [1.0, 1.0, 1000.0, 1.0, 0.0, 0.0, 1000.0]  episode_count: 1505 q_vals: [0.0, -15.0, -inf, -15.0, 0.0, 0.0, -inf]
Step 2282 4 visits [1.0, 1.0, 1000.0, 1.0, 1.0, 0.0, 1000.0]  episode_count: 1507 q_vals: [0.0, -15.0, -inf, -15.0, -15.0, 0.0, -inf]
Step 2283 5 visits [1.0, 1.0, 1000.0, 1.0, 1.0, 1.0, 1000.0]  episode_count: 1508 q_vals: [0.0, -15.0, -inf, -15.0, -15.0, 0.0, -inf]
Step 2284 0 visits [2.0, 1.0, 1000.0, 1.0, 1.0, 1.0, 1000.0]  episode_count: 1508 q_vals: [-7.5, -15.0, -inf, -15.0, -15.0, 0.0, -inf]
Step 2285 5 visits [2.0, 1.0, 1000.0, 1.0, 1.0, 2.0, 1000.0]  episode_count: 1509 q_vals: [-7.5, -15.0, -inf, -15.0, -15.0, -7.5, -inf]
Step 2286 0 visits [3.0, 1.0, 1000.0, 1.0, 1.0, 2.0, 1000.0]  episode_count: 1509 q_vals: [-5.0, -15.0, -inf, -15.0, -15.0, -7.5, -inf]
Step 2287 0 visits [4.0, 1.0, 1000.0, 1.0, 1.0, 2.0, 1000.0]  episode_count: 1510 q_vals: [-3.75, -15.0, -inf, -15.0, -15.0, -7.5, -inf]
Step 2288 0 visits [5.0, 1.0, 1000.0, 1.0, 1.0, 2.0, 1000.0]  episode_count: 1511 q_vals: [-6.0, -15.0, -inf, -15.0, -15.0, -7.5, -inf]
Step 2289 0 visits [6.0, 1.0, 1000.0, 1.0, 1.0, 2.0, 1000.0]  episode_count: 1511 q_vals: [-7.5, -15.0, -inf, -15.0, -15.0, -7.5, -inf]
Step 2290 5 visits [6.0, 1.0, 1000.0, 1.0, 1.0, 3.0, 1000.0]  episode_count: 1512 q_vals: [-7.5, -15.0, -inf, -15.0, -15.0, -10.0, -inf]
Step 2291 0 visits [7.0, 1.0, 1000.0, 1.0, 1.0, 3.0, 1000.0]  episode_count: 1512 q_vals: [-8.571, -15.0, -inf, -15.0, -15.0, -10.0, -inf]
Step 2292 0 visits [8.0, 1.0, 1000.0, 1.0, 1.0, 3.0, 1000.0]  episode_count: 1512 q_vals: [-9.375, -15.0, -inf, -15.0, -15.0, -10.0, -inf]
{"total_number_of_episodes": 1514, "number_of_timesteps": 153598, "per_episode_reward": -272.55, "episode_reward_trend_value": 0.7107317133168143, "biggest_recent_change": 52.38153355180174},
Step 2293 0 visits [9.0, 1.0, 1000.0, 1.0, 1.0, 3.0, 1000.0]  episode_count: 1514 q_vals: [-10.0, -15.0, -inf, -15.0, -15.0, -10.0, -inf]
Step 2294 5 visits [9.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1515 q_vals: [-10.0, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2295 0 visits [10.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1516 q_vals: [-9.0, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2296 0 visits [11.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1516 q_vals: [-9.545, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2297 0 visits [12.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1516 q_vals: [-10.0, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2298 0 visits [13.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1516 q_vals: [-10.385, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2299 0 visits [14.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1516 q_vals: [-10.714, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2300 0 visits [15.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1516 q_vals: [-10.0, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2301 0 visits [16.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1516 q_vals: [-9.375, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2302 0 visits [17.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1516 q_vals: [-9.706, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2303 0 visits [18.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1517 q_vals: [-9.167, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2304 0 visits [19.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1518 q_vals: [-8.684, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2305 0 visits [20.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1518 q_vals: [-9.0, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2306 0 visits [21.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1519 q_vals: [-9.286, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2307 0 visits [22.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1521 q_vals: [-8.864, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2308 0 visits [23.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1521 q_vals: [-8.478, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2309 0 visits [24.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1521 q_vals: [-8.125, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2310 0 visits [25.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1522 q_vals: [-7.8, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2311 0 visits [26.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1523 q_vals: [-7.5, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2312 0 visits [27.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1523 q_vals: [-7.778, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1524, "number_of_timesteps": 154967, "per_episode_reward": -272.48, "episode_reward_trend_value": 0.6837875776786082, "biggest_recent_change": 52.38153355180174},
Step 2313 0 visits [28.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1524 q_vals: [-7.5, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2314 0 visits [29.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1524 q_vals: [-7.759, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2315 0 visits [30.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1524 q_vals: [-8.0, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2316 0 visits [31.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1526 q_vals: [-8.226, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2317 0 visits [32.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1527 q_vals: [-7.969, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2318 0 visits [33.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1527 q_vals: [-7.727, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2319 0 visits [34.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1529 q_vals: [-7.5, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2320 0 visits [35.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1529 q_vals: [-7.286, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
[-7.5, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2322 0 visits [37.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1530 q_vals: [-7.297, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2323 0 visits [38.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1530 q_vals: [-7.105, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2324 0 visits [39.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1530 q_vals: [-7.308, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2325 0 visits [40.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1531 q_vals: [-7.5, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2326 0 visits [41.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1532 q_vals: [-7.317, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2327 0 visits [42.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1532 q_vals: [-7.5, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1536, "number_of_timesteps": 156190, "per_episode_reward": -271.6, "episode_reward_trend_value": 0.6398121151954734, "biggest_recent_change": 52.38153355180174},
Step 2328 0 visits [43.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1536 q_vals: [-7.674, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2329 0 visits [44.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1536 q_vals: [-7.5, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2330 0 visits [45.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1536 q_vals: [-7.667, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2331 0 visits [46.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1536 q_vals: [-7.826, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2332 0 visits [47.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1536 q_vals: [-7.66, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2333 0 visits [48.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1537 q_vals: [-7.5, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2334 0 visits [49.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1537 q_vals: [-7.653, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2335 0 visits [50.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1541 q_vals: [-7.8, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2336 0 visits [51.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1541 q_vals: [-7.941, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2337 0 visits [52.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1541 q_vals: [-8.077, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2338 0 visits [53.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1542 q_vals: [-8.208, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2339 0 visits [54.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1542 q_vals: [-8.056, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2340 0 visits [55.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1542 q_vals: [-8.182, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2341 0 visits [56.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1542 q_vals: [-8.304, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2342 0 visits [57.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1542 q_vals: [-8.158, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2343 0 visits [58.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1543 q_vals: [-8.276, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2344 0 visits [59.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1544 q_vals: [-8.136, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2345 0 visits [60.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1545 q_vals: [-8.25, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1546, "number_of_timesteps": 157162, "per_episode_reward": -271.09, "episode_reward_trend_value": 0.6354239437663953, "biggest_recent_change": 52.38153355180174},
Step 2346 0 visits [61.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1546 q_vals: [-8.361, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2347 0 visits [62.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1546 q_vals: [-8.226, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2348 0 visits [63.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1547 q_vals: [-8.333, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2349 0 visits [64.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1548 q_vals: [-8.438, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2350 0 visits [65.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1549 q_vals: [-8.308, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2351 0 visits [66.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1549 q_vals: [-8.182, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2352 0 visits [67.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1549 q_vals: [-8.06, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2353 0 visits [68.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1549 q_vals: [-8.162, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2354 0 visits [69.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1549 q_vals: [-8.043, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2355 0 visits [70.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1551 q_vals: [-7.929, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2356 0 visits [71.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1551 q_vals: [-8.028, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2357 0 visits [72.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1551 q_vals: [-8.125, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2358 0 visits [73.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1551 q_vals: [-8.014, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2359 0 visits [74.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1552 q_vals: [-8.108, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2360 0 visits [75.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1553 q_vals: [-8.2, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2361 0 visits [76.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1554 q_vals: [-8.289, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1556, "number_of_timesteps": 158380, "per_episode_reward": -270.04, "episode_reward_trend_value": 0.621437909927865, "biggest_recent_change": 52.38153355180174},
Step 2362 0 visits [77.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1556 q_vals: [-8.182, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2363 0 visits [78.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1557 q_vals: [-8.269, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2364 0 visits [79.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1557 q_vals: [-8.354, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2365 0 visits [80.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1557 q_vals: [-8.438, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2366 0 visits [81.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1557 q_vals: [-8.519, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2367 0 visits [82.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1558 q_vals: [-8.598, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2368 0 visits [83.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1559 q_vals: [-8.494, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2369 0 visits [84.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1560 q_vals: [-8.393, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2370 0 visits [85.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1561 q_vals: [-8.471, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2371 0 visits [86.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1561 q_vals: [-8.372, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2372 0 visits [87.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1562 q_vals: [-8.448, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2373 0 visits [88.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1562 q_vals: [-8.352, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2374 0 visits [89.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1563 q_vals: [-8.427, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2375 0 visits [90.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1564 q_vals: [-8.333, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2376 0 visits [91.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1564 q_vals: [-8.242, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1566, "number_of_timesteps": 159326, "per_episode_reward": -268.18, "episode_reward_trend_value": 0.6366191664027359, "biggest_recent_change": 52.38153355180174},
Step 2377 0 visits [92.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1566 q_vals: [-8.253, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2378 0 visits [93.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1567 q_vals: [-8.325, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2379 0 visits [94.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1567 q_vals: [-8.237, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2380 0 visits [95.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1568 q_vals: [-8.15, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2381 0 visits [96.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1569 q_vals: [-8.221, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2382 0 visits [97.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1569 q_vals: [-8.137, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2383 0 visits [98.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1570 q_vals: [-8.207, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2384 0 visits [99.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1572 q_vals: [-8.275, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2385 0 visits [100.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1573 q_vals: [-8.343, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2386 0 visits [101.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1574 q_vals: [-8.26, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2387 0 visits [102.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1574 q_vals: [-8.326, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2388 0 visits [103.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1575 q_vals: [-8.391, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1576, "number_of_timesteps": 160130, "per_episode_reward": -267.19, "episode_reward_trend_value": 0.6615778332909706, "biggest_recent_change": 52.38153355180174},
Step 2389 0 visits [104.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1576 q_vals: [-8.31, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2390 0 visits [105.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1576 q_vals: [-8.231, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2391 0 visits [106.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1576 q_vals: [-8.203, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2392 0 visits [107.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1578 q_vals: [-8.127, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2393 0 visits [108.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1578 q_vals: [-8.19, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2394 0 visits [109.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1580 q_vals: [-8.253, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2395 0 visits [110.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1581 q_vals: [-8.178, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2396 0 visits [111.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1581 q_vals: [-8.104, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2397 0 visits [112.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1582 q_vals: [-8.032, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2398 0 visits [113.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1582 q_vals: [-7.961, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2399 0 visits [114.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1582 q_vals: [-8.022, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2400 0 visits [115.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1583 q_vals: [-8.083, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2401 0 visits [116.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1584 q_vals: [-8.013, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2402 0 visits [117.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1585 q_vals: [-8.073, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2403 0 visits [118.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1585 q_vals: [-8.132, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2404 0 visits [119.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1585 q_vals: [-8.063, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2405 0 visits [120.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1585 q_vals: [-7.996, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1587, "number_of_timesteps": 161118, "per_episode_reward": -266.46, "episode_reward_trend_value": 0.6757047345249771, "biggest_recent_change": 52.38153355180174},
Step 2406 0 visits [121.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1587 q_vals: [-7.93, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2407 0 visits [122.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1587 q_vals: [-7.865, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2408 0 visits [123.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1588 q_vals: [-7.801, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2409 0 visits [124.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1588 q_vals: [-7.859, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2410 0 visits [125.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1588 q_vals: [-7.916, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2411 0 visits [126.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1588 q_vals: [-7.854, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2412 0 visits [127.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1589 q_vals: [-7.792, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2413 0 visits [128.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1590 q_vals: [-7.848, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2414 0 visits [129.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1591 q_vals: [-7.903, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2415 0 visits [130.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1591 q_vals: [-7.843, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2416 0 visits [131.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1593 q_vals: [-7.897, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2417 0 visits [132.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1593 q_vals: [-7.837, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2418 0 visits [133.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1594 q_vals: [-7.779, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2419 0 visits [134.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1594 q_vals: [-7.832, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2420 0 visits [135.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1594 q_vals: [-7.885, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2421 0 visits [136.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1594 q_vals: [-7.828, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2422 0 visits [137.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1595 q_vals: [-7.88, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2423 0 visits [138.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1595 q_vals: [-7.931, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2424 0 visits [139.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1595 q_vals: [-7.982, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2425 0 visits [140.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1596 q_vals: [-8.032, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2426 0 visits [141.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1596 q_vals: [-8.082, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1598, "number_of_timesteps": 162460, "per_episode_reward": -265.31, "episode_reward_trend_value": 0.662538499413628, "biggest_recent_change": 52.38153355180174},
Step 2427 0 visits [142.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1598 q_vals: [-8.131, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2428 0 visits [143.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1598 q_vals: [-8.179, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2429 0 visits [144.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1599 q_vals: [-8.122, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2430 0 visits [145.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1599 q_vals: [-8.066, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2431 0 visits [146.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1601 q_vals: [-8.011, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2432 0 visits [147.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1602 q_vals: [-7.956, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2433 0 visits [148.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1603 q_vals: [-7.902, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2434 0 visits [149.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1604 q_vals: [-7.95, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2435 0 visits [150.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1604 q_vals: [-7.997, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2436 0 visits [151.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1604 q_vals: [-7.944, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2437 0 visits [152.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1606 q_vals: [-7.892, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2438 0 visits [153.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1607 q_vals: [-7.938, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2439 0 visits [154.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1607 q_vals: [-7.887, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2440 0 visits [155.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1607 q_vals: [-7.933, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1609, "number_of_timesteps": 163544, "per_episode_reward": -263.36, "episode_reward_trend_value": 0.10209749117752835, "biggest_recent_change": 1.941842810552771},
Step 2441 0 visits [156.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1609 q_vals: [-7.978, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2442 0 visits [157.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1609 q_vals: [-7.927, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2443 0 visits [158.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1609 q_vals: [-7.972, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2444 0 visits [159.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1611 q_vals: [-8.016, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2445 0 visits [160.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1611 q_vals: [-8.06, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2446 0 visits [161.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1611 q_vals: [-8.103, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2447 0 visits [162.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1611 q_vals: [-8.053, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2448 0 visits [163.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1612 q_vals: [-8.003, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2449 0 visits [164.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1612 q_vals: [-8.046, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2450 0 visits [165.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1613 q_vals: [-8.088, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2451 0 visits [166.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1614 q_vals: [-8.13, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2452 0 visits [167.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1615 q_vals: [-8.081, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2453 0 visits [168.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1615 q_vals: [-8.122, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2454 0 visits [169.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1615 q_vals: [-8.163, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2455 0 visits [170.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1615 q_vals: [-8.115, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2456 0 visits [171.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1616 q_vals: [-8.067, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2457 0 visits [172.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1616 q_vals: [-8.021, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2458 0 visits [173.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1617 q_vals: [-7.974, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2459 0 visits [174.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1617 q_vals: [-8.015, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1619, "number_of_timesteps": 164739, "per_episode_reward": -262.7, "episode_reward_trend_value": 0.10866330648375236, "biggest_recent_change": 1.941842810552771},
Step 2460 0 visits [175.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1619 q_vals: [-8.055, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2461 0 visits [176.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1621 q_vals: [-8.009, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2462 0 visits [177.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1621 q_vals: [-7.964, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2463 0 visits [178.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1621 q_vals: [-7.919, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2464 0 visits [179.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1621 q_vals: [-7.875, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2465 0 visits [180.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1622 q_vals: [-7.831, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2466 0 visits [181.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1622 q_vals: [-7.87, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2467 0 visits [182.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1622 q_vals: [-7.91, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2468 0 visits [183.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1623 q_vals: [-7.948, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2469 0 visits [184.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1623 q_vals: [-7.987, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2470 0 visits [185.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1623 q_vals: [-8.025, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2471 0 visits [186.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1623 q_vals: [-8.062, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2472 0 visits [187.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1624 q_vals: [-8.099, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2473 0 visits [188.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1625 q_vals: [-8.136, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2474 0 visits [189.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1626 q_vals: [-8.093, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2475 0 visits [190.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1628 q_vals: [-8.05, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1629, "number_of_timesteps": 165907, "per_episode_reward": -262.48, "episode_reward_trend_value": 0.10135517862508689, "biggest_recent_change": 1.941842810552771},
Step 2476 0 visits [191.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1629 q_vals: [-8.087, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2477 0 visits [192.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1629 q_vals: [-8.044, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2478 0 visits [193.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1630 q_vals: [-8.003, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2479 0 visits [194.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1630 q_vals: [-8.039, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2480 0 visits [195.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1630 q_vals: [-8.075, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2481 0 visits [196.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1630 q_vals: [-8.033, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2482 0 visits [197.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1630 q_vals: [-7.993, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2483 0 visits [198.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1631 q_vals: [-7.952, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2484 0 visits [199.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1632 q_vals: [-7.912, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2485 0 visits [200.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1632 q_vals: [-7.873, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2486 0 visits [201.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1632 q_vals: [-7.834, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2487 0 visits [202.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1635 q_vals: [-7.869, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2488 0 visits [203.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1636 q_vals: [-7.904, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2489 0 visits [204.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1637 q_vals: [-7.865, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2490 0 visits [205.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1637 q_vals: [-7.9, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2491 0 visits [206.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1637 q_vals: [-7.862, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2492 0 visits [207.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1637 q_vals: [-7.896, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2493 0 visits [208.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1638 q_vals: [-7.858, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1639, "number_of_timesteps": 167101, "per_episode_reward": -261.87, "episode_reward_trend_value": 0.10247590468693676, "biggest_recent_change": 1.941842810552771},
Step 2494 0 visits [209.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1639 q_vals: [-7.893, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2495 0 visits [210.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1639 q_vals: [-7.926, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2496 0 visits [211.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1639 q_vals: [-7.96, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2497 0 visits [212.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1640 q_vals: [-7.993, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2498 0 visits [213.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1640 q_vals: [-7.956, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2499 0 visits [214.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1640 q_vals: [-7.989, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2500 0 visits [215.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1640 q_vals: [-7.951, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2501 0 visits [216.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1642 q_vals: [-7.984, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2502 0 visits [217.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1644 q_vals: [-8.016, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2503 0 visits [218.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1645 q_vals: [-7.98, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2504 0 visits [219.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1645 q_vals: [-7.943, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2505 0 visits [220.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1645 q_vals: [-7.907, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2506 0 visits [221.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1646 q_vals: [-7.939, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2507 0 visits [222.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1647 q_vals: [-7.971, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2508 0 visits [223.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1647 q_vals: [-8.002, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2509 0 visits [224.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1647 q_vals: [-7.967, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2510 0 visits [225.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1647 q_vals: [-7.998, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2511 0 visits [226.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1648 q_vals: [-8.029, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2512 0 visits [227.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1648 q_vals: [-8.06, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2513 0 visits [228.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1648 q_vals: [-8.024, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1650, "number_of_timesteps": 168303, "per_episode_reward": -261.12, "episode_reward_trend_value": 0.09901435595849585, "biggest_recent_change": 1.941842810552771},
Step 2514 0 visits [229.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1650 q_vals: [-7.989, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2515 0 visits [230.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1651 q_vals: [-8.02, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2516 0 visits [231.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1651 q_vals: [-8.05, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2517 0 visits [232.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1651 q_vals: [-8.015, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2518 0 visits [233.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1651 q_vals: [-8.045, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2519 0 visits [234.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1651 q_vals: [-8.011, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2520 0 visits [235.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1652 q_vals: [-7.977, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2521 0 visits [236.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1652 q_vals: [-8.007, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2522 0 visits [237.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1653 q_vals: [-7.973, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2523 0 visits [238.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1654 q_vals: [-7.939, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2524 0 visits [239.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1655 q_vals: [-7.969, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2525 0 visits [240.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1655 q_vals: [-7.936, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2526 0 visits [241.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1655 q_vals: [-7.965, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2527 0 visits [242.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1655 q_vals: [-7.932, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2528 0 visits [243.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1656 q_vals: [-7.961, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2529 0 visits [244.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1657 q_vals: [-7.928, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2530 0 visits [245.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1658 q_vals: [-7.896, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2531 0 visits [246.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1658 q_vals: [-7.864, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2532 0 visits [247.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1658 q_vals: [-7.832, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2533 0 visits [248.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1658 q_vals: [-7.801, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2534 0 visits [249.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1658 q_vals: [-7.769, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2535 0 visits [250.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1659 q_vals: [-7.738, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2536 0 visits [251.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1659 q_vals: [-7.707, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1660, "number_of_timesteps": 169593, "per_episode_reward": -259.99, "episode_reward_trend_value": 0.09105745701593264, "biggest_recent_change": 1.941842810552771},
Step 2537 0 visits [252.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1660 q_vals: [-7.677, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2538 0 visits [253.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1660 q_vals: [-7.646, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2539 0 visits [254.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1662 q_vals: [-7.675, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2540 0 visits [255.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1663 q_vals: [-7.645, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2541 0 visits [256.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1663 q_vals: [-7.674, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2542 0 visits [257.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1664 q_vals: [-7.644, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2543 0 visits [258.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1664 q_vals: [-7.615, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2544 0 visits [259.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1665 q_vals: [-7.585, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2545 0 visits [260.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1665 q_vals: [-7.614, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2546 0 visits [261.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1665 q_vals: [-7.584, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2547 0 visits [262.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1665 q_vals: [-7.556, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2548 0 visits [263.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1665 q_vals: [-7.584, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2549 0 visits [264.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1666 q_vals: [-7.612, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2550 0 visits [265.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1667 q_vals: [-7.583, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2551 0 visits [266.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1667 q_vals: [-7.611, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2552 0 visits [267.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1668 q_vals: [-7.583, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1670, "number_of_timesteps": 171043, "per_episode_reward": -259.49, "episode_reward_trend_value": 0.08546850359896072, "biggest_recent_change": 1.941842810552771},
Step 2553 0 visits [268.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1670 q_vals: [-7.61, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2554 0 visits [269.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1670 q_vals: [-7.582, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2555 0 visits [270.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1671 q_vals: [-7.554, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2556 0 visits [271.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1673 q_vals: [-7.581, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2557 0 visits [272.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1673 q_vals: [-7.609, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2558 0 visits [273.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1673 q_vals: [-7.581, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2559 0 visits [274.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1674 q_vals: [-7.553, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2560 0 visits [275.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1676 q_vals: [-7.58, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2561 0 visits [276.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1677 q_vals: [-7.607, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2562 0 visits [277.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1678 q_vals: [-7.634, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2563 0 visits [278.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1679 q_vals: [-7.66, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1680, "number_of_timesteps": 171976, "per_episode_reward": -258.02, "episode_reward_trend_value": 0.09381116936460217, "biggest_recent_change": 1.941842810552771},
Step 2564 0 visits [279.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1680 q_vals: [-7.633, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2565 0 visits [280.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1680 q_vals: [-7.659, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2566 0 visits [281.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1680 q_vals: [-7.685, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
0 visits [282.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1682 q_vals: [-7.711, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2568 0 visits [283.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1682 q_vals: [-7.684, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2569 0 visits [284.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1683 q_vals: [-7.71, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2570 0 visits [285.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1683 q_vals: [-7.735, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2571 0 visits [286.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1686 q_vals: [-7.761, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2572 0 visits [287.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1686 q_vals: [-7.786, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2573 0 visits [288.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1686 q_vals: [-7.811, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2574 0 visits [289.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1687 q_vals: [-7.784, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2575 0 visits [290.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1687 q_vals: [-7.757, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2576 0 visits [291.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1688 q_vals: [-7.73, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2577 0 visits [292.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1688 q_vals: [-7.704, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2578 0 visits [293.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1688 q_vals: [-7.729, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2579 0 visits [294.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1688 q_vals: [-7.754, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1693, "number_of_timesteps": 173129, "per_episode_reward": -255.06, "episode_reward_trend_value": 0.11387030162394751, "biggest_recent_change": 2.9573684833833624},
Step 2580 0 visits [295.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1693 q_vals: [-7.778, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2581 0 visits [296.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1693 q_vals: [-7.752, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2582 0 visits [297.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1693 q_vals: [-7.776, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2583 0 visits [298.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1693 q_vals: [-7.75, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2584 0 visits [299.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1693 q_vals: [-7.724, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2585 0 visits [300.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1693 q_vals: [-7.748, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2586 0 visits [301.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1694 q_vals: [-7.773, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2587 0 visits [302.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1694 q_vals: [-7.747, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2588 0 visits [303.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1694 q_vals: [-7.771, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2589 0 visits [304.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1694 q_vals: [-7.795, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2590 0 visits [305.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1694 q_vals: [-7.769, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2591 0 visits [306.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1694 q_vals: [-7.756, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2592 0 visits [307.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1696 q_vals: [-7.779, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2593 0 visits [308.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1697 q_vals: [-7.754, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2594 0 visits [309.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1697 q_vals: [-7.777, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2595 0 visits [310.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1699 q_vals: [-7.801, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2596 0 visits [311.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1699 q_vals: [-7.776, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2597 0 visits [312.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1699 q_vals: [-7.751, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2598 0 visits [313.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1699 q_vals: [-7.726, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2599 0 visits [314.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1699 q_vals: [-7.701, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2600 0 visits [315.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1699 q_vals: [-7.677, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2601 0 visits [316.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1700 q_vals: [-7.653, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2602 0 visits [317.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1700 q_vals: [-7.628, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2603 0 visits [318.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1701 q_vals: [-7.652, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2604 0 visits [319.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1702 q_vals: [-7.675, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1704, "number_of_timesteps": 174433, "per_episode_reward": -252.89, "episode_reward_trend_value": 0.116437046564276, "biggest_recent_change": 2.9573684833833624},
Step 2605 0 visits [320.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1704 q_vals: [-7.651, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2606 0 visits [321.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1704 q_vals: [-7.627, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2607 0 visits [322.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1705 q_vals: [-7.603, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2608 0 visits [323.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1705 q_vals: [-7.58, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
[-7.603, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2610 0 visits [325.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1705 q_vals: [-7.579, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2611 0 visits [326.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1705 q_vals: [-7.602, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2612 0 visits [327.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1706 q_vals: [-7.625, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2613 0 visits [328.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1707 q_vals: [-7.647, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2614 0 visits [329.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1707 q_vals: [-7.669, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2615 0 visits [330.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1709 q_vals: [-7.692, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2616 0 visits [331.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1709 q_vals: [-7.668, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2617 0 visits [332.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1710 q_vals: [-7.69, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2618 0 visits [333.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1712 q_vals: [-7.667, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2619 0 visits [334.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1712 q_vals: [-7.689, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2620 0 visits [335.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1712 q_vals: [-7.666, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2621 0 visits [336.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1712 q_vals: [-7.688, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2622 0 visits [337.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1713 q_vals: [-7.665, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2623 0 visits [338.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1713 q_vals: [-7.687, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1714, "number_of_timesteps": 175829, "per_episode_reward": -251.98, "episode_reward_trend_value": 0.1190836001034032, "biggest_recent_change": 2.9573684833833624},
Step 2624 0 visits [339.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1714 q_vals: [-7.709, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2625 0 visits [340.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1715 q_vals: [-7.73, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2626 0 visits [341.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1716 q_vals: [-7.707, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2627 0 visits [342.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1716 q_vals: [-7.729, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2628 0 visits [343.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1716 q_vals: [-7.75, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2629 0 visits [344.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1716 q_vals: [-7.771, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2630 0 visits [345.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1717 q_vals: [-7.748, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2631 0 visits [346.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1717 q_vals: [-7.769, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2632 0 visits [347.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1718 q_vals: [-7.79, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2633 0 visits [348.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1720 q_vals: [-7.811, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2634 0 visits [349.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1720 q_vals: [-7.789, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2635 0 visits [350.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1720 q_vals: [-7.809, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2636 0 visits [351.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1720 q_vals: [-7.83, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2637 0 visits [352.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1720 q_vals: [-7.85, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2638 0 visits [353.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1723 q_vals: [-7.87, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2639 0 visits [354.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1723 q_vals: [-7.89, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1725, "number_of_timesteps": 177042, "per_episode_reward": -251.22, "episode_reward_trend_value": 0.1251698376816765, "biggest_recent_change": 2.9573684833833624},
Step 2640 0 visits [355.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1725 q_vals: [-7.911, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2641 0 visits [356.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1725 q_vals: [-7.93, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2642 0 visits [357.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1725 q_vals: [-7.95, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2643 0 visits [358.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1727 q_vals: [-7.928, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2644 0 visits [359.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1727 q_vals: [-7.906, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2645 0 visits [360.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1727 q_vals: [-7.884, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2646 0 visits [361.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1727 q_vals: [-7.904, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2647 0 visits [362.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1727 q_vals: [-7.882, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2648 0 visits [363.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1729 q_vals: [-7.901, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2649 0 visits [364.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1729 q_vals: [-7.921, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2650 0 visits [365.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1729 q_vals: [-7.94, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2651 0 visits [366.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1729 q_vals: [-7.919, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2652 0 visits [367.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1729 q_vals: [-7.938, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2653 0 visits [368.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1729 q_vals: [-7.957, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2654 0 visits [369.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1730 q_vals: [-7.976, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2655 0 visits [370.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1731 q_vals: [-7.995, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2656 0 visits [371.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1731 q_vals: [-8.014, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2657 0 visits [372.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1734 q_vals: [-8.033, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2658 0 visits [373.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1734 q_vals: [-8.052, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2659 0 visits [374.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1734 q_vals: [-8.07, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2660 0 visits [375.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1734 q_vals: [-8.049, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1735, "number_of_timesteps": 178240, "per_episode_reward": -250.52, "episode_reward_trend_value": 0.12611455765163523, "biggest_recent_change": 2.9573684833833624},
Step 2661 0 visits [376.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1735 q_vals: [-8.027, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2662 0 visits [377.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1736 q_vals: [-8.046, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2663 0 visits [378.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1736 q_vals: [-8.064, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2664 0 visits [379.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1737 q_vals: [-8.043, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2665 0 visits [380.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1738 q_vals: [-8.061, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2666 0 visits [381.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1738 q_vals: [-8.04, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2667 0 visits [382.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1738 q_vals: [-8.058, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2668 0 visits [383.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1738 q_vals: [-8.076, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2669 0 visits [384.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1739 q_vals: [-8.094, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2670 0 visits [385.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1739 q_vals: [-8.112, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2671 0 visits [386.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1739 q_vals: [-8.13, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2672 0 visits [387.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1740 q_vals: [-8.109, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2673 0 visits [388.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1741 q_vals: [-8.088, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2674 0 visits [389.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1742 q_vals: [-8.106, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2675 0 visits [390.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1742 q_vals: [-8.085, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2676 0 visits [391.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1742 q_vals: [-8.065, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2677 0 visits [392.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1742 q_vals: [-8.082, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2678 0 visits [393.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1743 q_vals: [-8.062, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1745, "number_of_timesteps": 179596, "per_episode_reward": -250.77, "episode_reward_trend_value": 0.11506087526725979, "biggest_recent_change": 2.9573684833833624},
Step 2679 0 visits [394.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1745 q_vals: [-8.079, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2680 0 visits [395.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1746 q_vals: [-8.059, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2681 0 visits [396.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1746 q_vals: [-8.076, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2682 0 visits [397.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1747 q_vals: [-8.094, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2683 0 visits [398.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1748 q_vals: [-8.111, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2684 0 visits [399.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1749 q_vals: [-8.128, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2685 0 visits [400.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1750 q_vals: [-8.108, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2686 0 visits [401.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1751 q_vals: [-8.125, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2687 0 visits [402.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1752 q_vals: [-8.132, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2688 0 visits [403.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1753 q_vals: [-8.149, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2689 0 visits [404.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1753 q_vals: [-8.144, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2690 0 visits [405.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1754 q_vals: [-8.161, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2691 0 visits [406.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1754 q_vals: [-8.141, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1755, "number_of_timesteps": 180461, "per_episode_reward": -249.5, "episode_reward_trend_value": 0.11659020651122458, "biggest_recent_change": 2.9573684833833624},
Step 2692 0 visits [407.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1755 q_vals: [-8.138, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2693 0 visits [408.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1757 q_vals: [-8.155, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2694 0 visits [409.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1758 q_vals: [-8.171, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2695 0 visits [410.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1758 q_vals: [-8.188, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2696 0 visits [411.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1759 q_vals: [-8.168, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2697 0 visits [412.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1761 q_vals: [-8.185, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2698 0 visits [413.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1761 q_vals: [-8.201, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2699 0 visits [414.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1761 q_vals: [-8.218, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2700 0 visits [415.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1761 q_vals: [-8.234, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2701 0 visits [416.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1761 q_vals: [-8.25, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2702 0 visits [417.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1762 q_vals: [-8.231, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1765, "number_of_timesteps": 181303, "per_episode_reward": -248.23, "episode_reward_trend_value": 0.12518418677503956, "biggest_recent_change": 2.9573684833833624},
Step 2703 0 visits [418.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1765 q_vals: [-8.247, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2704 0 visits [419.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1765 q_vals: [-8.263, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2705 0 visits [420.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1766 q_vals: [-8.279, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2706 0 visits [421.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1767 q_vals: [-8.295, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2707 0 visits [422.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1767 q_vals: [-8.311, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2708 0 visits [423.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1768 q_vals: [-8.291, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2709 0 visits [424.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1768 q_vals: [-8.272, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2710 0 visits [425.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1768 q_vals: [-8.287, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2711 0 visits [426.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1768 q_vals: [-8.268, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2712 0 visits [427.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1768 q_vals: [-8.249, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2713 0 visits [428.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1768 q_vals: [-8.264, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2714 0 visits [429.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1770 q_vals: [-8.245, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2715 0 visits [430.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1771 q_vals: [-8.261, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2716 0 visits [431.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1773 q_vals: [-8.276, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2717 0 visits [432.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1773 q_vals: [-8.292, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2718 0 visits [433.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1774 q_vals: [-8.307, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1775, "number_of_timesteps": 182363, "per_episode_reward": -247.48, "episode_reward_trend_value": 0.11710556124136784, "biggest_recent_change": 2.9573684833833624},
Step 2719 0 visits [434.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1775 q_vals: [-8.288, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2720 0 visits [435.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1775 q_vals: [-8.304, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2721 0 visits [436.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1775 q_vals: [-8.285, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2722 0 visits [437.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1775 q_vals: [-8.3, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2723 0 visits [438.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1775 q_vals: [-8.315, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2724 0 visits [439.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1777 q_vals: [-8.331, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2725 0 visits [440.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1778 q_vals: [-8.312, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2726 0 visits [441.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1778 q_vals: [-8.293, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2727 0 visits [442.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1778 q_vals: [-8.274, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2728 0 visits [443.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1778 q_vals: [-8.255, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2729 0 visits [444.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1781 q_vals: [-8.271, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2730 0 visits [445.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1781 q_vals: [-8.252, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2731 0 visits [446.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1781 q_vals: [-8.267, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2732 0 visits [447.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1781 q_vals: [-8.282, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2733 0 visits [448.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1781 q_vals: [-8.297, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2734 0 visits [449.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1782 q_vals: [-8.279, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2735 0 visits [450.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1784 q_vals: [-8.26, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2736 0 visits [451.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1784 q_vals: [-8.275, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2737 0 visits [452.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1784 q_vals: [-8.29, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2738 0 visits [453.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1784 q_vals: [-8.272, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1785, "number_of_timesteps": 183455, "per_episode_reward": -246.97, "episode_reward_trend_value": 0.08989070140212303, "biggest_recent_change": 2.172849855182335},
Step 2739 0 visits [454.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1785 q_vals: [-8.287, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2740 0 visits [455.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1786 q_vals: [-8.268, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2741 0 visits [456.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1786 q_vals: [-8.283, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2742 0 visits [457.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1787 q_vals: [-8.298, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2743 0 visits [458.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1787 q_vals: [-8.28, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2744 0 visits [459.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1788 q_vals: [-8.262, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2745 0 visits [460.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1788 q_vals: [-8.244, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2746 0 visits [461.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1789 q_vals: [-8.226, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2747 0 visits [462.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1789 q_vals: [-8.241, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2748 0 visits [463.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1789 q_vals: [-8.255, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2749 0 visits [464.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1789 q_vals: [-8.27, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2750 0 visits [465.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1789 q_vals: [-8.252, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2751 0 visits [466.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1792 q_vals: [-8.234, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2752 0 visits [467.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1792 q_vals: [-8.249, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2753 0 visits [468.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1793 q_vals: [-8.231, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2754 0 visits [469.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1793 q_vals: [-8.214, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2755 0 visits [470.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1794 q_vals: [-8.228, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1795, "number_of_timesteps": 184784, "per_episode_reward": -245.68, "episode_reward_trend_value": 0.08009207918383557, "biggest_recent_change": 1.290973855536464},
Step 2756 0 visits [471.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1795 q_vals: [-8.242, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2757 0 visits [472.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1796 q_vals: [-8.257, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2758 0 visits [473.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1796 q_vals: [-8.271, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2759 0 visits [474.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1797 q_vals: [-8.285, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2760 0 visits [475.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1797 q_vals: [-8.268, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2761 0 visits [476.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1797 q_vals: [-8.25, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2762 0 visits [477.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1797 q_vals: [-8.264, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2763 0 visits [478.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1799 q_vals: [-8.247, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2764 0 visits [479.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1799 q_vals: [-8.261, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2765 0 visits [480.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1799 q_vals: [-8.275, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2766 0 visits [481.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1799 q_vals: [-8.289, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2767 0 visits [482.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1800 q_vals: [-8.303, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2768 0 visits [483.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1800 q_vals: [-8.286, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2769 0 visits [484.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1802 q_vals: [-8.3, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2770 0 visits [485.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1802 q_vals: [-8.283, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2771 0 visits [486.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1803 q_vals: [-8.266, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2772 0 visits [487.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1804 q_vals: [-8.249, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2773 0 visits [488.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1804 q_vals: [-8.232, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1805, "number_of_timesteps": 185963, "per_episode_reward": -244.51, "episode_reward_trend_value": 0.08303804215589676, "biggest_recent_change": 1.290973855536464},
Step 2774 0 visits [489.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1805 q_vals: [-8.246, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2775 0 visits [490.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1805 q_vals: [-8.259, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2776 0 visits [491.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1805 q_vals: [-8.273, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2777 0 visits [492.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1807 q_vals: [-8.287, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2778 0 visits [493.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1808 q_vals: [-8.3, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2779 0 visits [494.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1810 q_vals: [-8.284, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2780 0 visits [495.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1811 q_vals: [-8.267, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2781 0 visits [496.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1811 q_vals: [-8.281, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2782 0 visits [497.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1811 q_vals: [-8.264, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2783 0 visits [498.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1811 q_vals: [-8.247, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2784 0 visits [499.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1811 q_vals: [-8.261, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2785 0 visits [500.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1811 q_vals: [-8.244, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2786 0 visits [501.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1812 q_vals: [-8.258, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2787 0 visits [502.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1812 q_vals: [-8.241, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2788 0 visits [503.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1813 q_vals: [-8.255, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2789 0 visits [504.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1813 q_vals: [-8.238, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2790 0 visits [505.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1814 q_vals: [-8.252, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1816, "number_of_timesteps": 187096, "per_episode_reward": -244.11, "episode_reward_trend_value": 0.07900730828156384, "biggest_recent_change": 1.290973855536464},
Step 2791 0 visits [506.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1816 q_vals: [-8.265, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2792 0 visits [507.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1816 q_vals: [-8.278, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2793 0 visits [508.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1816 q_vals: [-8.262, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2794 0 visits [509.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1816 q_vals: [-8.275, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2795 0 visits [510.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1818 q_vals: [-8.289, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2796 0 visits [511.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1818 q_vals: [-8.302, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2797 0 visits [512.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1818 q_vals: [-8.315, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2798 0 visits [513.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1819 q_vals: [-8.328, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2799 0 visits [514.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1819 q_vals: [-8.341, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2800 0 visits [515.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1820 q_vals: [-8.325, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2801 0 visits [516.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1821 q_vals: [-8.337, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2802 0 visits [517.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1821 q_vals: [-8.35, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2803 0 visits [518.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1821 q_vals: [-8.363, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2804 0 visits [519.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1822 q_vals: [-8.347, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2805 0 visits [520.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1823 q_vals: [-8.36, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2806 0 visits [521.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1824 q_vals: [-8.373, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2807 0 visits [522.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1824 q_vals: [-8.385, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2808 0 visits [523.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1825 q_vals: [-8.369, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1826, "number_of_timesteps": 188336, "per_episode_reward": -244.15, "episode_reward_trend_value": 0.0707684762416597, "biggest_recent_change": 1.290973855536464},
Step 2809 0 visits [524.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1826 q_vals: [-8.382, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2810 0 visits [525.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1826 q_vals: [-8.366, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2811 0 visits [526.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1826 q_vals: [-8.379, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2812 0 visits [527.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1826 q_vals: [-8.391, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2813 0 visits [528.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1826 q_vals: [-8.404, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2814 0 visits [529.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1826 q_vals: [-8.416, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2815 0 visits [530.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1827 q_vals: [-8.429, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
[531.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1829 q_vals: [-8.44, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2817 0 visits [532.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1830 q_vals: [-8.424, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2818 0 visits [533.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1830 q_vals: [-8.409, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2819 0 visits [534.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1831 q_vals: [-8.393, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2820 0 visits [535.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1833 q_vals: [-8.405, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2821 0 visits [536.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1833 q_vals: [-8.417, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2822 0 visits [537.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1833 q_vals: [-8.402, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2823 0 visits [538.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1834 q_vals: [-8.414, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2824 0 visits [539.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1834 q_vals: [-8.426, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2825 0 visits [540.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1834 q_vals: [-8.438, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2826 0 visits [541.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1834 q_vals: [-8.423, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2827 0 visits [542.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1835 q_vals: [-8.407, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1836, "number_of_timesteps": 189488, "per_episode_reward": -242.86, "episode_reward_trend_value": 0.08786864136776684, "biggest_recent_change": 1.290973855536464},
Step 2828 0 visits [543.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1836 q_vals: [-8.419, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2829 0 visits [544.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1836 q_vals: [-8.432, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2830 0 visits [545.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1838 q_vals: [-8.416, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2831 0 visits [546.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1838 q_vals: [-8.401, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2832 0 visits [547.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1839 q_vals: [-8.413, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2833 0 visits [548.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1841 q_vals: [-8.425, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2834 0 visits [549.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1841 q_vals: [-8.437, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2835 0 visits [550.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1842 q_vals: [-8.449, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2836 0 visits [551.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1843 q_vals: [-8.461, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2837 0 visits [552.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1843 q_vals: [-8.445, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2838 0 visits [553.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1843 q_vals: [-8.457, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2839 0 visits [554.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1843 q_vals: [-8.468, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2840 0 visits [555.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1843 q_vals: [-8.48, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2841 0 visits [556.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1845 q_vals: [-8.492, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2842 0 visits [557.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1845 q_vals: [-8.503, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1846, "number_of_timesteps": 190501, "per_episode_reward": -240.57, "episode_reward_trend_value": 0.09918779155609628, "biggest_recent_change": 2.2905701563809657},
Step 2843 0 visits [558.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1846 q_vals: [-8.488, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2844 0 visits [559.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1848 q_vals: [-8.5, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2845 0 visits [560.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1848 q_vals: [-8.511, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2846 0 visits [561.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1848 q_vals: [-8.523, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2847 0 visits [562.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1850 q_vals: [-8.534, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2848 0 visits [563.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1851 q_vals: [-8.546, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2849 0 visits [564.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1852 q_vals: [-8.531, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2850 0 visits [565.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1852 q_vals: [-8.516, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2851 0 visits [566.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1853 q_vals: [-8.527, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2852 0 visits [567.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1853 q_vals: [-8.512, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2853 0 visits [568.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1853 q_vals: [-8.497, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2854 0 visits [569.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1853 q_vals: [-8.482, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2855 0 visits [570.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1854 q_vals: [-8.494, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2856 0 visits [571.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1854 q_vals: [-8.479, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2857 0 visits [572.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1854 q_vals: [-8.49, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1856, "number_of_timesteps": 191479, "per_episode_reward": -239.38, "episode_reward_trend_value": 0.0983211344008639, "biggest_recent_change": 2.2905701563809657},
Step 2858 0 visits [573.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1856 q_vals: [-8.475, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2859 0 visits [574.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1856 q_vals: [-8.461, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2860 0 visits [575.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1857 q_vals: [-8.446, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2861 0 visits [576.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1857 q_vals: [-8.431, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2862 0 visits [577.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1857 q_vals: [-8.417, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2863 0 visits [578.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1857 q_vals: [-8.428, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2864 0 visits [579.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1857 q_vals: [-8.439, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2865 0 visits [580.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1858 q_vals: [-8.425, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2866 0 visits [581.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1858 q_vals: [-8.41, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2867 0 visits [582.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1860 q_vals: [-8.422, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2868 0 visits [583.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1861 q_vals: [-8.407, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2869 0 visits [584.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1861 q_vals: [-8.393, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2870 0 visits [585.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1861 q_vals: [-8.404, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2871 0 visits [586.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1862 q_vals: [-8.39, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2872 0 visits [587.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1862 q_vals: [-8.401, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2873 0 visits [588.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1863 q_vals: [-8.412, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2874 0 visits [589.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1863 q_vals: [-8.423, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2875 0 visits [590.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1863 q_vals: [-8.434, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2876 0 visits [591.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1864 q_vals: [-8.446, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2877 0 visits [592.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1864 q_vals: [-8.457, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2878 0 visits [593.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1865 q_vals: [-8.442, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2879 0 visits [594.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1865 q_vals: [-8.428, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2880 0 visits [595.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1865 q_vals: [-8.439, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1866, "number_of_timesteps": 192924, "per_episode_reward": -239.34, "episode_reward_trend_value": 0.090397078027905, "biggest_recent_change": 2.2905701563809657},
Step 2881 0 visits [596.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1866 q_vals: [-8.45, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2882 0 visits [597.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1868 q_vals: [-8.461, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2883 0 visits [598.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1868 q_vals: [-8.447, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2884 0 visits [599.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1868 q_vals: [-8.433, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2885 0 visits [600.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1868 q_vals: [-8.419, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2886 0 visits [601.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1869 q_vals: [-8.43, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2887 0 visits [602.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1870 q_vals: [-8.441, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2888 0 visits [603.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1871 q_vals: [-8.427, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2889 0 visits [604.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1872 q_vals: [-8.438, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2890 0 visits [605.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1873 q_vals: [-8.448, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2891 0 visits [606.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1873 q_vals: [-8.453, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2892 0 visits [607.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1874 q_vals: [-8.464, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2893 0 visits [608.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1874 q_vals: [-8.45, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2894 0 visits [609.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1875 q_vals: [-8.461, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2895 0 visits [610.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1875 q_vals: [-8.447, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1876, "number_of_timesteps": 194121, "per_episode_reward": -238.76, "episode_reward_trend_value": 0.09125476310490734, "biggest_recent_change": 2.2905701563809657},
Step 2896 0 visits [611.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1876 q_vals: [-8.458, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2897 0 visits [612.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1877 q_vals: [-8.444, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2898 0 visits [613.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1878 q_vals: [-8.454, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2899 0 visits [614.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1879 q_vals: [-8.441, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2900 0 visits [615.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1880 q_vals: [-8.427, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2901 0 visits [616.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1880 q_vals: [-8.438, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2902 0 visits [617.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1880 q_vals: [-8.448, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2903 0 visits [618.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1881 q_vals: [-8.435, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2904 0 visits [619.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1882 q_vals: [-8.421, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2905 0 visits [620.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1883 q_vals: [-8.432, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2906 0 visits [621.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1883 q_vals: [-8.418, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2907 0 visits [622.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1883 q_vals: [-8.429, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2908 0 visits [623.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1884 q_vals: [-8.439, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2909 0 visits [624.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1885 q_vals: [-8.45, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2910 0 visits [625.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1885 q_vals: [-8.46, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1886, "number_of_timesteps": 195116, "per_episode_reward": -238.59, "episode_reward_trend_value": 0.07874885052343422, "biggest_recent_change": 2.2905701563809657},
Step 2911 0 visits [626.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1886 q_vals: [-8.471, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2912 0 visits [627.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1886 q_vals: [-8.481, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2913 0 visits [628.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1887 q_vals: [-8.491, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2914 0 visits [629.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1887 q_vals: [-8.478, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2915 0 visits [630.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1888 q_vals: [-8.488, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2916 0 visits [631.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1888 q_vals: [-8.499, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2917 0 visits [632.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1888 q_vals: [-8.509, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2918 0 visits [633.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1889 q_vals: [-8.495, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2919 0 visits [634.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1890 q_vals: [-8.506, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2920 0 visits [635.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1891 q_vals: [-8.492, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2921 0 visits [636.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1891 q_vals: [-8.479, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2922 0 visits [637.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1893 q_vals: [-8.466, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2923 0 visits [638.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1893 q_vals: [-8.452, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2924 0 visits [639.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1893 q_vals: [-8.439, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2925 0 visits [640.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1894 q_vals: [-8.449, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2926 0 visits [641.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1894 q_vals: [-8.46, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2927 0 visits [642.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1894 q_vals: [-8.47, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2928 0 visits [643.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1894 q_vals: [-8.48, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2929 0 visits [644.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1895 q_vals: [-8.49, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2930 0 visits [645.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1895 q_vals: [-8.5, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2931 0 visits [646.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1895 q_vals: [-8.51, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2932 0 visits [647.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1895 q_vals: [-8.52, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1897, "number_of_timesteps": 196332, "per_episode_reward": -238.53, "episode_reward_trend_value": 0.06640462043149348, "biggest_recent_change": 2.2905701563809657},
Step 2933 0 visits [648.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1897 q_vals: [-8.53, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2934 0 visits [649.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1900 q_vals: [-8.54, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2935 0 visits [650.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1900 q_vals: [-8.527, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2936 0 visits [651.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1900 q_vals: [-8.537, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2937 0 visits [652.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1900 q_vals: [-8.524, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2938 0 visits [653.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1900 q_vals: [-8.534, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2939 0 visits [654.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1900 q_vals: [-8.521, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2940 0 visits [655.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1901 q_vals: [-8.531, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2941 0 visits [656.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1902 q_vals: [-8.518, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2942 0 visits [657.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1903 q_vals: [-8.505, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2943 0 visits [658.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1903 q_vals: [-8.492, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2944 0 visits [659.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1903 q_vals: [-8.479, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2945 0 visits [660.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1905 q_vals: [-8.489, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1907, "number_of_timesteps": 197676, "per_episode_reward": -238.13, "episode_reward_trend_value": 0.06639408792160281, "biggest_recent_change": 2.2905701563809657},
Step 2946 0 visits [661.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1907 q_vals: [-8.499, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2947 0 visits [662.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1908 q_vals: [-8.495, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2948 0 visits [663.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1908 q_vals: [-8.504, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2949 0 visits [664.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1908 q_vals: [-8.492, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2950 0 visits [665.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1908 q_vals: [-8.479, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2951 0 visits [666.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1909 q_vals: [-8.466, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2952 0 visits [667.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1910 q_vals: [-8.453, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2953 0 visits [668.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1910 q_vals: [-8.441, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2954 0 visits [669.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1910 q_vals: [-8.428, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2955 0 visits [670.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1911 q_vals: [-8.416, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2956 0 visits [671.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1913 q_vals: [-8.403, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2957 0 visits [672.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1913 q_vals: [-8.391, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2958 0 visits [673.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1913 q_vals: [-8.4, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2959 0 visits [674.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1913 q_vals: [-8.41, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2960 0 visits [675.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1914 q_vals: [-8.42, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2961 0 visits [676.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1915 q_vals: [-8.43, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2962 0 visits [677.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1915 q_vals: [-8.439, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2963 0 visits [678.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1915 q_vals: [-8.449, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1917, "number_of_timesteps": 198612, "per_episode_reward": -237.78, "episode_reward_trend_value": 0.07071157604196401, "biggest_recent_change": 2.2905701563809657},
Step 2964 0 visits [679.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1917 q_vals: [-8.459, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2965 0 visits [680.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1917 q_vals: [-8.468, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2966 0 visits [681.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1918 q_vals: [-8.456, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2967 0 visits [682.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1918 q_vals: [-8.465, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2968 0 visits [683.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1918 q_vals: [-8.453, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2969 0 visits [684.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1919 q_vals: [-8.463, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2970 0 visits [685.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1919 q_vals: [-8.45, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2971 0 visits [686.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1919 q_vals: [-8.46, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2972 0 visits [687.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1920 q_vals: [-8.448, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2973 0 visits [688.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1921 q_vals: [-8.435, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2974 0 visits [689.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1921 q_vals: [-8.445, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2975 0 visits [690.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1921 q_vals: [-8.454, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2976 0 visits [691.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1922 q_vals: [-8.442, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2977 0 visits [692.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1922 q_vals: [-8.43, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2978 0 visits [693.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1923 q_vals: [-8.439, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2979 0 visits [694.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1923 q_vals: [-8.427, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2980 0 visits [695.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1924 q_vals: [-8.415, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2981 0 visits [696.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1925 q_vals: [-8.425, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2982 0 visits [697.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1925 q_vals: [-8.412, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2983 0 visits [698.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1925 q_vals: [-8.422, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2984 0 visits [699.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1925 q_vals: [-8.41, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2985 0 visits [700.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1925 q_vals: [-8.419, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2986 0 visits [701.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1926 q_vals: [-8.429, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1927, "number_of_timesteps": 199907, "per_episode_reward": -237.84, "episode_reward_trend_value": 0.05575663367084884, "biggest_recent_change": 2.2905701563809657},
Step 2987 0 visits [702.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1927 q_vals: [-8.438, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2988 0 visits [703.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1928 q_vals: [-8.426, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2989 0 visits [704.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1928 q_vals: [-8.435, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2990 0 visits [705.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1929 q_vals: [-8.423, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2991 0 visits [706.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1929 q_vals: [-8.433, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2992 0 visits [707.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1929 q_vals: [-8.424, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2993 0 visits [708.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1929 q_vals: [-8.433, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2994 0 visits [709.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1929 q_vals: [-8.421, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2995 0 visits [710.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1932 q_vals: [-8.43, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2996 0 visits [711.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1933 q_vals: [-8.439, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2997 0 visits [712.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1933 q_vals: [-8.449, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2998 0 visits [713.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1934 q_vals: [-8.437, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 2999 0 visits [714.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1934 q_vals: [-8.425, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3000 0 visits [715.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1934 q_vals: [-8.434, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3001 0 visits [716.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1936 q_vals: [-8.443, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3002 0 visits [717.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1936 q_vals: [-8.452, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1937, "number_of_timesteps": 201087, "per_episode_reward": -237.29, "episode_reward_trend_value": 0.03649241444151856, "biggest_recent_change": 1.1908275670725175},
Step 3003 0 visits [718.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1937 q_vals: [-8.462, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3004 0 visits [719.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1938 q_vals: [-8.45, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3005 0 visits [720.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1939 q_vals: [-8.459, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3006 0 visits [721.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1940 q_vals: [-8.447, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3007 0 visits [722.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1942 q_vals: [-8.435, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3008 0 visits [723.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1942 q_vals: [-8.445, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3009 0 visits [724.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1943 q_vals: [-8.433, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3010 0 visits [725.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1944 q_vals: [-8.442, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3011 0 visits [726.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1946 q_vals: [-8.451, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3012 0 visits [727.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1946 q_vals: [-8.46, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3013 0 visits [728.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1946 q_vals: [-8.448, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3014 0 visits [729.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1946 q_vals: [-8.457, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1949, "number_of_timesteps": 202336, "per_episode_reward": -236.6, "episode_reward_trend_value": 0.030904698016242883, "biggest_recent_change": 0.6879330887977062},
Step 3015 0 visits [730.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1949 q_vals: [-8.466, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3016 0 visits [731.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1951 q_vals: [-8.455, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3017 0 visits [732.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1951 q_vals: [-8.443, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3018 0 visits [733.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1951 q_vals: [-8.452, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3019 0 visits [734.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1953 q_vals: [-8.441, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3020 0 visits [735.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1953 q_vals: [-8.45, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3021 0 visits [736.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1954 q_vals: [-8.438, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3022 0 visits [737.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1956 q_vals: [-8.447, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3023 0 visits [738.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1958 q_vals: [-8.456, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3024 0 visits [739.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1958 q_vals: [-8.444, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3025 0 visits [740.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1958 q_vals: [-8.433, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1959, "number_of_timesteps": 202989, "per_episode_reward": -233.88, "episode_reward_trend_value": 0.06072155017349069, "biggest_recent_change": 2.7221649310888267},
Step 3026 0 visits [741.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1959 q_vals: [-8.437, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3027 0 visits [742.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1960 q_vals: [-8.426, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3028 0 visits [743.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1961 q_vals: [-8.415, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3029 0 visits [744.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1962 q_vals: [-8.403, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3030 0 visits [745.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1965 q_vals: [-8.392, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3031 0 visits [746.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1965 q_vals: [-8.381, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3032 0 visits [747.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1966 q_vals: [-8.37, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3033 0 visits [748.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1966 q_vals: [-8.378, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3034 0 visits [749.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1967 q_vals: [-8.367, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3035 0 visits [750.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1967 q_vals: [-8.376, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3036 0 visits [751.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1968 q_vals: [-8.385, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3037 0 visits [752.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1968 q_vals: [-8.374, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1970, "number_of_timesteps": 203771, "per_episode_reward": -232.96, "episode_reward_trend_value": 0.06438683119533897, "biggest_recent_change": 2.7221649310888267},
Step 3038 0 visits [753.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1970 q_vals: [-8.383, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3039 0 visits [754.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1971 q_vals: [-8.371, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3040 0 visits [755.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1974 q_vals: [-8.38, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3041 0 visits [756.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1974 q_vals: [-8.369, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3042 0 visits [757.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1974 q_vals: [-8.358, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3043 0 visits [758.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1975 q_vals: [-8.367, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3044 0 visits [759.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1976 q_vals: [-8.376, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3045 0 visits [760.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1976 q_vals: [-8.365, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3046 0 visits [761.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1977 q_vals: [-8.373, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3047 0 visits [762.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1979 q_vals: [-8.382, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1981, "number_of_timesteps": 204570, "per_episode_reward": -232.38, "episode_reward_trend_value": 0.0690305392073406, "biggest_recent_change": 2.7221649310888267},
Step 3048 0 visits [763.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1981 q_vals: [-8.371, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3049 0 visits [764.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1981 q_vals: [-8.38, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3050 0 visits [765.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1982 q_vals: [-8.369, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3051 0 visits [766.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1982 q_vals: [-8.358, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3052 0 visits [767.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1982 q_vals: [-8.366, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3053 0 visits [768.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1982 q_vals: [-8.375, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3054 0 visits [769.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1983 q_vals: [-8.364, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3055 0 visits [770.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1983 q_vals: [-8.373, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3056 0 visits [771.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1984 q_vals: [-8.362, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3057 0 visits [772.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1986 q_vals: [-8.351, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3058 0 visits [773.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1987 q_vals: [-8.36, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3059 0 visits [774.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1989 q_vals: [-8.366, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3060 0 visits [775.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1989 q_vals: [-8.374, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3061 0 visits [776.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1989 q_vals: [-8.383, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3062 0 visits [777.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1989 q_vals: [-8.391, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3063 0 visits [778.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1989 q_vals: [-8.4, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3064 0 visits [779.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1989 q_vals: [-8.389, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3065 0 visits [780.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1989 q_vals: [-8.397, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3066 0 visits [781.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1989 q_vals: [-8.387, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 1992, "number_of_timesteps": 205626, "per_episode_reward": -231.99, "episode_reward_trend_value": 0.07268103066231282, "biggest_recent_change": 2.7221649310888267},
Step 3067 0 visits [782.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1992 q_vals: [-8.395, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3068 0 visits [783.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1993 q_vals: [-8.384, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3069 0 visits [784.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1994 q_vals: [-8.374, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3070 0 visits [785.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1994 q_vals: [-8.382, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3071 0 visits [786.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1994 q_vals: [-8.391, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3072 0 visits [787.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1994 q_vals: [-8.38, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3073 0 visits [788.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1994 q_vals: [-8.369, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3074 0 visits [789.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1994 q_vals: [-8.378, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3075 0 visits [790.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1997 q_vals: [-8.367, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3076 0 visits [791.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1997 q_vals: [-8.375, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3077 0 visits [792.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1997 q_vals: [-8.384, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3078 0 visits [793.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1997 q_vals: [-8.392, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3079 0 visits [794.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1998 q_vals: [-8.4, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3080 0 visits [795.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1998 q_vals: [-8.39, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3081 0 visits [796.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 1999 q_vals: [-8.379, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3082 0 visits [797.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2001 q_vals: [-8.388, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3083 0 visits [798.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2001 q_vals: [-8.396, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 2002, "number_of_timesteps": 206838, "per_episode_reward": -231.73, "episode_reward_trend_value": 0.07105852826438384, "biggest_recent_change": 2.7221649310888267},
Step 3084 0 visits [799.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2002 q_vals: [-8.404, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3085 0 visits [800.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2003 q_vals: [-8.412, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3086 0 visits [801.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2004 q_vals: [-8.402, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3087 0 visits [802.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2004 q_vals: [-8.391, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3088 0 visits [803.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2004 q_vals: [-8.4, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3089 0 visits [804.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2004 q_vals: [-8.408, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3090 0 visits [805.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2004 q_vals: [-8.397, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3091 0 visits [806.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2005 q_vals: [-8.406, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3092 0 visits [807.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2006 q_vals: [-8.395, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3093 0 visits [808.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2008 q_vals: [-8.385, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3094 0 visits [809.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2009 q_vals: [-8.393, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3095 0 visits [810.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2010 q_vals: [-8.383, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3096 0 visits [811.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2011 q_vals: [-8.391, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3097 0 visits [812.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2011 q_vals: [-8.38, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3098 0 visits [813.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2011 q_vals: [-8.37, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3099 0 visits [814.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2011 q_vals: [-8.378, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 2013, "number_of_timesteps": 207921, "per_episode_reward": -230.86, "episode_reward_trend_value": 0.07692738194327894, "biggest_recent_change": 2.7221649310888267},
Step 3100 0 visits [815.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2013 q_vals: [-8.368, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3101 0 visits [816.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2014 q_vals: [-8.376, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3102 0 visits [817.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2014 q_vals: [-8.384, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3103 0 visits [818.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2014 q_vals: [-8.392, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3104 0 visits [819.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2017 q_vals: [-8.382, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3105 0 visits [820.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2017 q_vals: [-8.39, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3106 0 visits [821.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2017 q_vals: [-8.38, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3107 0 visits [822.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2017 q_vals: [-8.37, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3108 0 visits [823.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2017 q_vals: [-8.36, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3109 0 visits [824.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2017 q_vals: [-8.368, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3110 0 visits [825.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2019 q_vals: [-8.358, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3111 0 visits [826.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2019 q_vals: [-8.366, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3112 0 visits [827.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2019 q_vals: [-8.374, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3113 0 visits [828.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2020 q_vals: [-8.382, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3114 0 visits [829.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2021 q_vals: [-8.39, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3115 0 visits [830.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2021 q_vals: [-8.379, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3116 0 visits [831.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2021 q_vals: [-8.387, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 2023, "number_of_timesteps": 209027, "per_episode_reward": -230.0, "episode_reward_trend_value": 0.08717597548868178, "biggest_recent_change": 2.7221649310888267},
Step 3117 0 visits [832.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2023 q_vals: [-8.377, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3118 0 visits [833.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2023 q_vals: [-8.367, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3119 0 visits [834.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2024 q_vals: [-8.357, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3120 0 visits [835.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2024 q_vals: [-8.361, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3121 0 visits [836.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2024 q_vals: [-8.369, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3122 0 visits [837.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2024 q_vals: [-8.359, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3123 0 visits [838.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2025 q_vals: [-8.349, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3124 0 visits [839.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2025 q_vals: [-8.357, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3125 0 visits [840.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2025 q_vals: [-8.365, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3126 0 visits [841.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2025 q_vals: [-8.355, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3127 0 visits [842.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2026 q_vals: [-8.362, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3128 0 visits [843.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2026 q_vals: [-8.37, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3129 0 visits [844.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2029 q_vals: [-8.36, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3130 0 visits [845.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2029 q_vals: [-8.351, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3131 0 visits [846.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2029 q_vals: [-8.341, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3132 0 visits [847.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2029 q_vals: [-8.349, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3133 0 visits [848.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2029 q_vals: [-8.339, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3134 0 visits [849.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2029 q_vals: [-8.347, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3135 0 visits [850.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2029 q_vals: [-8.337, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3136 0 visits [851.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2029 q_vals: [-8.345, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3137 0 visits [852.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2029 q_vals: [-8.352, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3138 0 visits [853.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2031 q_vals: [-8.343, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3139 0 visits [854.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2032 q_vals: [-8.333, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3140 0 visits [855.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2032 q_vals: [-8.323, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 2033, "number_of_timesteps": 210414, "per_episode_reward": -229.57, "episode_reward_trend_value": 0.0857356511765709, "biggest_recent_change": 2.7221649310888267},
Step 3141 0 visits [856.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2033 q_vals: [-8.313, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3142 0 visits [857.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2033 q_vals: [-8.304, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3143 0 visits [858.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2033 q_vals: [-8.294, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3144 0 visits [859.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2033 q_vals: [-8.302, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
[-8.292, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3146 0 visits [861.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2034 q_vals: [-8.3, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3147 0 visits [862.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2034 q_vals: [-8.29, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3148 0 visits [863.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2035 q_vals: [-8.298, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3149 0 visits [864.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2037 q_vals: [-8.306, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3150 0 visits [865.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2038 q_vals: [-8.296, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3151 0 visits [866.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2038 q_vals: [-8.287, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3152 0 visits [867.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2039 q_vals: [-8.277, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3153 0 visits [868.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2039 q_vals: [-8.268, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3154 0 visits [869.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2039 q_vals: [-8.275, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3155 0 visits [870.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2039 q_vals: [-8.283, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3156 0 visits [871.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2039 q_vals: [-8.291, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3157 0 visits [872.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2039 q_vals: [-8.298, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3158 0 visits [873.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2039 q_vals: [-8.289, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3159 0 visits [874.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2040 q_vals: [-8.297, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3160 0 visits [875.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2041 q_vals: [-8.304, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3161 0 visits [876.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2042 q_vals: [-8.312, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 2043, "number_of_timesteps": 211843, "per_episode_reward": -229.71, "episode_reward_trend_value": 0.07657620630164134, "biggest_recent_change": 2.7221649310888267},
Step 3162 0 visits [877.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2043 q_vals: [-8.302, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3163 0 visits [878.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2044 q_vals: [-8.293, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3164 0 visits [879.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2044 q_vals: [-8.301, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3165 0 visits [880.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2044 q_vals: [-8.291, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3166 0 visits [881.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2044 q_vals: [-8.299, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3167 0 visits [882.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2044 q_vals: [-8.289, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3168 0 visits [883.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2044 q_vals: [-8.28, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3169 0 visits [884.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2045 q_vals: [-8.271, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3170 0 visits [885.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2048 q_vals: [-8.261, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3171 0 visits [886.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2049 q_vals: [-8.269, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3172 0 visits [887.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2049 q_vals: [-8.26, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3173 0 visits [888.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2050 q_vals: [-8.25, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3174 0 visits [889.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2050 q_vals: [-8.241, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3175 0 visits [890.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2050 q_vals: [-8.232, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3176 0 visits [891.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2051 q_vals: [-8.222, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3177 0 visits [892.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2052 q_vals: [-8.213, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 2053, "number_of_timesteps": 212937, "per_episode_reward": -229.3, "episode_reward_trend_value": 0.05082693379358053, "biggest_recent_change": 0.915098046747886},
Step 3178 0 visits [893.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2053 q_vals: [-8.204, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3179 0 visits [894.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2053 q_vals: [-8.195, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3180 0 visits [895.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2055 q_vals: [-8.202, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3181 0 visits [896.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2055 q_vals: [-8.21, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3182 0 visits [897.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2056 q_vals: [-8.218, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3183 0 visits [898.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2058 q_vals: [-8.225, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3184 0 visits [899.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2059 q_vals: [-8.216, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3185 0 visits [900.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2060 q_vals: [-8.207, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3186 0 visits [901.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2060 q_vals: [-8.198, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
[-8.205, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3188 0 visits [903.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2062 q_vals: [-8.213, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3189 0 visits [904.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2062 q_vals: [-8.22, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3190 0 visits [905.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2062 q_vals: [-8.228, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 2063, "number_of_timesteps": 214026, "per_episode_reward": -228.85, "episode_reward_trend_value": 0.04565229534836798, "biggest_recent_change": 0.8744034145568378},
Step 3191 0 visits [906.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2063 q_vals: [-8.219, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3192 0 visits [907.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2064 q_vals: [-8.226, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3193 0 visits [908.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2064 q_vals: [-8.234, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3194 0 visits [909.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2066 q_vals: [-8.225, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3195 0 visits [910.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2066 q_vals: [-8.216, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3196 0 visits [911.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2066 q_vals: [-8.223, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3197 0 visits [912.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2066 q_vals: [-8.214, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3198 0 visits [913.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2066 q_vals: [-8.205, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3199 0 visits [914.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2067 q_vals: [-8.212, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3200 0 visits [915.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2069 q_vals: [-8.22, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3201 0 visits [916.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2069 q_vals: [-8.211, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3202 0 visits [917.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2069 q_vals: [-8.202, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3203 0 visits [918.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2069 q_vals: [-8.193, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3204 0 visits [919.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2070 q_vals: [-8.184, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3205 0 visits [920.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2072 q_vals: [-8.192, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3206 0 visits [921.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2072 q_vals: [-8.199, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3207 0 visits [922.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2072 q_vals: [-8.206, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3208 0 visits [923.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2072 q_vals: [-8.197, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 2073, "number_of_timesteps": 215196, "per_episode_reward": -228.01, "episode_reward_trend_value": 0.048542577737949774, "biggest_recent_change": 0.8744034145568378},
Step 3209 0 visits [924.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2073 q_vals: [-8.205, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3210 0 visits [925.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2076 q_vals: [-8.196, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3211 0 visits [926.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2076 q_vals: [-8.187, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3212 0 visits [927.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2076 q_vals: [-8.178, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3213 0 visits [928.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2077 q_vals: [-8.186, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3214 0 visits [929.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2077 q_vals: [-8.193, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3215 0 visits [930.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2077 q_vals: [-8.2, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3216 0 visits [931.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2078 q_vals: [-8.208, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3217 0 visits [932.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2078 q_vals: [-8.199, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3218 0 visits [933.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2078 q_vals: [-8.206, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3219 0 visits [934.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2079 q_vals: [-8.213, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3220 0 visits [935.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2081 q_vals: [-8.221, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3221 0 visits [936.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2082 q_vals: [-8.212, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3222 0 visits [937.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2082 q_vals: [-8.203, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 2083, "number_of_timesteps": 216265, "per_episode_reward": -228.53, "episode_reward_trend_value": 0.03848164674302931, "biggest_recent_change": 0.8744034145568378},
Step 3223 0 visits [938.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2083 q_vals: [-8.21, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3224 0 visits [939.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2083 q_vals: [-8.217, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3225 0 visits [940.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2083 q_vals: [-8.225, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3226 0 visits [941.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2084 q_vals: [-8.232, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3227 0 visits [942.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2084 q_vals: [-8.239, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3228 0 visits [943.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2084 q_vals: [-8.246, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3229 0 visits [944.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2084 q_vals: [-8.253, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3230 0 visits [945.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2084 q_vals: [-8.261, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3231 0 visits [946.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2084 q_vals: [-8.267, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3232 0 visits [947.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2085 q_vals: [-8.274, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3233 0 visits [948.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2086 q_vals: [-8.266, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3234 0 visits [949.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2086 q_vals: [-8.273, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3235 0 visits [950.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2088 q_vals: [-8.28, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3236 0 visits [951.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2089 q_vals: [-8.285, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3237 0 visits [952.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2090 q_vals: [-8.292, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3238 0 visits [953.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2090 q_vals: [-8.299, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3239 0 visits [954.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2091 q_vals: [-8.306, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3240 0 visits [955.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2092 q_vals: [-8.297, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3241 0 visits [956.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2092 q_vals: [-8.304, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 2094, "number_of_timesteps": 217611, "per_episode_reward": -226.83, "episode_reward_trend_value": 0.05446379169968433, "biggest_recent_change": 1.6941677460683593},
Step 3242 0 visits [957.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2094 q_vals: [-8.295, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3243 0 visits [958.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2095 q_vals: [-8.302, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3244 0 visits [959.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2095 q_vals: [-8.294, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3245 0 visits [960.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2096 q_vals: [-8.301, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3246 0 visits [961.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2098 q_vals: [-8.292, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3247 0 visits [962.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2098 q_vals: [-8.292, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3248 0 visits [963.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2098 q_vals: [-8.283, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3249 0 visits [964.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2099 q_vals: [-8.274, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3250 0 visits [965.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2100 q_vals: [-8.281, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3251 0 visits [966.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2100 q_vals: [-8.288, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3252 0 visits [967.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2100 q_vals: [-8.28, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3253 0 visits [968.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2101 q_vals: [-8.287, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3254 0 visits [969.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2102 q_vals: [-8.278, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3255 0 visits [970.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2103 q_vals: [-8.285, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3256 0 visits [971.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2103 q_vals: [-8.277, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3257 0 visits [972.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2103 q_vals: [-8.268, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 2104, "number_of_timesteps": 218498, "per_episode_reward": -226.22, "episode_reward_trend_value": 0.05161016333754118, "biggest_recent_change": 1.6941677460683593},
Step 3258 0 visits [973.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2104 q_vals: [-8.26, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3259 0 visits [974.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2104 q_vals: [-8.251, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3260 0 visits [975.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2104 q_vals: [-8.258, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3261 0 visits [976.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2106 q_vals: [-8.25, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3262 0 visits [977.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2107 q_vals: [-8.256, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3263 0 visits [978.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2109 q_vals: [-8.263, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3264 0 visits [979.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2110 q_vals: [-8.255, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3265 0 visits [980.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2110 q_vals: [-8.246, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3266 0 visits [981.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2111 q_vals: [-8.238, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3267 0 visits [982.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2111 q_vals: [-8.23, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3268 0 visits [983.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2111 q_vals: [-8.237, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3269 0 visits [984.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2112 q_vals: [-8.241, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3270 0 visits [985.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2113 q_vals: [-8.248, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 2114, "number_of_timesteps": 219448, "per_episode_reward": -225.71, "episode_reward_trend_value": 0.04759662841000723, "biggest_recent_change": 1.6941677460683593},
Step 3271 0 visits [986.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2114 q_vals: [-8.255, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3272 0 visits [987.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2115 q_vals: [-8.262, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3273 0 visits [988.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2116 q_vals: [-8.269, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3274 0 visits [989.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2117 q_vals: [-8.276, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3275 0 visits [990.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2117 q_vals: [-8.267, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3276 0 visits [991.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2117 q_vals: [-8.274, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3277 0 visits [992.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2119 q_vals: [-8.281, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3278 0 visits [993.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2120 q_vals: [-8.272, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3279 0 visits [994.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2120 q_vals: [-8.264, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3280 0 visits [995.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2121 q_vals: [-8.271, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3281 0 visits [996.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2121 q_vals: [-8.263, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3282 0 visits [997.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2123 q_vals: [-8.254, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3283 0 visits [998.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2123 q_vals: [-8.261, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
{"total_number_of_episodes": 2124, "number_of_timesteps": 220355, "per_episode_reward": -224.92, "episode_reward_trend_value": 0.0517098955774685, "biggest_recent_change": 1.6941677460683593},
Step 3284 0 visits [999.0, 1.0, 1000.0, 1.0, 1.0, 4.0, 1000.0]  episode_count: 2124 q_vals: [-8.268, -15.0, -inf, -15.0, -15.0, -11.25, -inf]
Step 3285 0 visits [1000.0, 0.0, 1000.0, 0.0, 0.0, 0.0, 1000.0]  episode_count: 2124 q_vals: [-inf, 0.0, -inf, 0.0, 0.0, 0.0, -inf]
{"total_number_of_episodes": 2135, "number_of_timesteps": 221690, "per_episode_reward": -180.18, "episode_reward_trend_value": 0.5502582114716915, "biggest_recent_change": 44.73293148053412},
{"total_number_of_episodes": 2146, "number_of_timesteps": 223060, "per_episode_reward": -179.67, "episode_reward_trend_value": 0.551500255397732, "biggest_recent_change": 44.73293148053412},
{"total_number_of_episodes": 2156, "number_of_timesteps": 224119, "per_episode_reward": -178.84, "episode_reward_trend_value": 0.5556828313793302, "biggest_recent_change": 44.73293148053412},
{"total_number_of_episodes": 2166, "number_of_timesteps": 225302, "per_episode_reward": -178.58, "episode_reward_trend_value": 0.5491592302023895, "biggest_recent_change": 44.73293148053412},
{"total_number_of_episodes": 2176, "number_of_timesteps": 226952, "per_episode_reward": -178.06, "episode_reward_trend_value": 0.5607734222832603, "biggest_recent_change": 44.73293148053412},
{"total_number_of_episodes": 2187, "number_of_timesteps": 228149, "per_episode_reward": -177.5, "episode_reward_trend_value": 0.5481195571714926, "biggest_recent_change": 44.73293148053412},
{"total_number_of_episodes": 2197, "number_of_timesteps": 229129, "per_episode_reward": -177.15, "episode_reward_trend_value": 0.5451346306573208, "biggest_recent_change": 44.73293148053412},
{"total_number_of_episodes": 2207, "number_of_timesteps": 230281, "per_episode_reward": -177.89, "episode_reward_trend_value": 0.5313467482921649, "biggest_recent_change": 44.73293148053412},
{"total_number_of_episodes": 2217, "number_of_timesteps": 231510, "per_episode_reward": -176.78, "episode_reward_trend_value": 0.5348363244705651, "biggest_recent_change": 44.73293148053412},
{"total_number_of_episodes": 2227, "number_of_timesteps": 233030, "per_episode_reward": -176.63, "episode_reward_trend_value": 0.03949746115913229, "biggest_recent_change": 1.1114171387787906},
{"total_number_of_episodes": 2237, "number_of_timesteps": 233987, "per_episode_reward": -176.53, "episode_reward_trend_value": 0.03485467722401868, "biggest_recent_change": 1.1114171387787906},
{"total_number_of_episodes": 2247, "number_of_timesteps": 235076, "per_episode_reward": -176.42, "episode_reward_trend_value": 0.026881057027650472, "biggest_recent_change": 1.1114171387787906},
{"total_number_of_episodes": 2257, "number_of_timesteps": 236352, "per_episode_reward": -176.32, "episode_reward_trend_value": 0.02517726984293884, "biggest_recent_change": 1.1114171387787906},
{"total_number_of_episodes": 2267, "number_of_timesteps": 237382, "per_episode_reward": -176.25, "episode_reward_trend_value": 0.02012423131302544, "biggest_recent_change": 1.1114171387787906},
{"total_number_of_episodes": 2277, "number_of_timesteps": 238775, "per_episode_reward": -176.0, "episode_reward_trend_value": 0.016717430396332767, "biggest_recent_change": 1.1114171387787906},
{"total_number_of_episodes": 2287, "number_of_timesteps": 239831, "per_episode_reward": -176.18, "episode_reward_trend_value": 0.01079247606496886, "biggest_recent_change": 1.1114171387787906},
{"total_number_of_episodes": 2297, "number_of_timesteps": 241123, "per_episode_reward": -175.88, "episode_reward_trend_value": 0.0223347105561146, "biggest_recent_change": 1.1114171387787906},
{"total_number_of_episodes": 2307, "number_of_timesteps": 242193, "per_episode_reward": -175.71, "episode_reward_trend_value": 0.011849609076387917, "biggest_recent_change": 0.30065770178001117},
{"total_number_of_episodes": 2318, "number_of_timesteps": 243642, "per_episode_reward": -175.6, "episode_reward_trend_value": 0.011374709375986135, "biggest_recent_change": 0.30065770178001117},
{"total_number_of_episodes": 2328, "number_of_timesteps": 244885, "per_episode_reward": -175.33, "episode_reward_trend_value": 0.01330546485063735, "biggest_recent_change": 0.30065770178001117},
{"total_number_of_episodes": 2338, "number_of_timesteps": 245885, "per_episode_reward": -174.76, "episode_reward_trend_value": 0.018446445315407484, "biggest_recent_change": 0.5708748491787787},
{"total_number_of_episodes": 2349, "number_of_timesteps": 247120, "per_episode_reward": -175.01, "episode_reward_trend_value": 0.014573498144186361, "biggest_recent_change": 0.5708748491787787},
{"total_number_of_episodes": 2359, "number_of_timesteps": 248070, "per_episode_reward": -173.97, "episode_reward_trend_value": 0.025334254214191925, "biggest_recent_change": 1.039801665220267},
{"total_number_of_episodes": 2369, "number_of_timesteps": 249430, "per_episode_reward": -174.14, "episode_reward_trend_value": 0.020645965662910725, "biggest_recent_change": 1.039801665220267},
{"total_number_of_episodes": 2379, "number_of_timesteps": 250748, "per_episode_reward": -173.58, "episode_reward_trend_value": 0.02887341304944944, "biggest_recent_change": 1.039801665220267},
{"total_number_of_episodes": 2390, "number_of_timesteps": 251888, "per_episode_reward": -173.85, "episode_reward_trend_value": 0.02252509229934358, "biggest_recent_change": 1.039801665220267},
{"total_number_of_episodes": 2401, "number_of_timesteps": 252980, "per_episode_reward": -173.56, "episode_reward_trend_value": 0.023967672012517167, "biggest_recent_change": 1.039801665220267},
{"total_number_of_episodes": 2411, "number_of_timesteps": 254278, "per_episode_reward": -173.39, "episode_reward_trend_value": 0.024561025939786103, "biggest_recent_change": 1.039801665220267},
{"total_number_of_episodes": 2421, "number_of_timesteps": 255567, "per_episode_reward": -174.0, "episode_reward_trend_value": 0.01481472097617124, "biggest_recent_change": 1.039801665220267},
{"total_number_of_episodes": 2431, "number_of_timesteps": 257170, "per_episode_reward": -174.29, "episode_reward_trend_value": 0.0052701436136380325, "biggest_recent_change": 1.039801665220267},
{"total_number_of_episodes": 2442, "number_of_timesteps": 258744, "per_episode_reward": -173.85, "episode_reward_trend_value": 0.012800335378184336, "biggest_recent_change": 1.039801665220267},
{"total_number_of_episodes": 2452, "number_of_timesteps": 260044, "per_episode_reward": -174.33, "episode_reward_trend_value": -0.004087711374788543, "biggest_recent_change": 0.6047356494599683},
{"total_number_of_episodes": 2462, "number_of_timesteps": 261245, "per_episode_reward": -173.46, "episode_reward_trend_value": 0.007573950641949839, "biggest_recent_change": 0.876311415398078},
{"total_number_of_episodes": 2473, "number_of_timesteps": 262469, "per_episode_reward": -173.5, "episode_reward_trend_value": 0.0008861193720990614, "biggest_recent_change": 0.876311415398078},
{"total_number_of_episodes": 2483, "number_of_timesteps": 263644, "per_episode_reward": -173.59, "episode_reward_trend_value": 0.0029166801441972566, "biggest_recent_change": 0.876311415398078},
{"total_number_of_episodes": 2493, "number_of_timesteps": 265020, "per_episode_reward": -173.87, "episode_reward_trend_value": -0.0035217024089266463, "biggest_recent_change": 0.876311415398078},
{"total_number_of_episodes": 2505, "number_of_timesteps": 266304, "per_episode_reward": -173.43, "episode_reward_trend_value": -0.00043411087996155905, "biggest_recent_change": 0.876311415398078},
{"total_number_of_episodes": 2515, "number_of_timesteps": 267351, "per_episode_reward": -172.47, "episode_reward_trend_value": 0.01693364649062706, "biggest_recent_change": 0.9583625138930074},
{"total_number_of_episodes": 2525, "number_of_timesteps": 268788, "per_episode_reward": -172.26, "episode_reward_trend_value": 0.022530139088133044, "biggest_recent_change": 0.9583625138930074},
{"total_number_of_episodes": 2535, "number_of_timesteps": 269784, "per_episode_reward": -172.1, "episode_reward_trend_value": 0.019507357772440375, "biggest_recent_change": 0.9583625138930074},
{"total_number_of_episodes": 2546, "number_of_timesteps": 270955, "per_episode_reward": -171.79, "episode_reward_trend_value": 0.0282685619685089, "biggest_recent_change": 0.9583625138930074},
{"total_number_of_episodes": 2556, "number_of_timesteps": 271995, "per_episode_reward": -171.62, "episode_reward_trend_value": 0.020388924067583504, "biggest_recent_change": 0.9583625138930074},
{"total_number_of_episodes": 2566, "number_of_timesteps": 272901, "per_episode_reward": -171.33, "episode_reward_trend_value": 0.024130173376393158, "biggest_recent_change": 0.9583625138930074},
{"total_number_of_episodes": 2576, "number_of_timesteps": 273950, "per_episode_reward": -171.13, "episode_reward_trend_value": 0.027325011414705436, "biggest_recent_change": 0.9583625138930074},
{"total_number_of_episodes": 2586, "number_of_timesteps": 275221, "per_episode_reward": -171.32, "episode_reward_trend_value": 0.028396012181365726, "biggest_recent_change": 0.9583625138930074},
{"total_number_of_episodes": 2596, "number_of_timesteps": 276465, "per_episode_reward": -170.77, "episode_reward_trend_value": 0.029617870674290243, "biggest_recent_change": 0.9583625138930074},
{"total_number_of_episodes": 2606, "number_of_timesteps": 277635, "per_episode_reward": -170.47, "episode_reward_trend_value": 0.02231874112376728, "biggest_recent_change": 0.5509451648932782},
{"total_number_of_episodes": 2616, "number_of_timesteps": 278906, "per_episode_reward": -170.49, "episode_reward_trend_value": 0.019612551263360777, "biggest_recent_change": 0.5509451648932782},
{"total_number_of_episodes": 2626, "number_of_timesteps": 280070, "per_episode_reward": -170.52, "episode_reward_trend_value": 0.017563497369752035, "biggest_recent_change": 0.5509451648932782},
{"total_number_of_episodes": 2636, "number_of_timesteps": 281148, "per_episode_reward": -170.32, "episode_reward_trend_value": 0.016296294380148246, "biggest_recent_change": 0.5509451648932782},
{"total_number_of_episodes": 2646, "number_of_timesteps": 282278, "per_episode_reward": -170.35, "episode_reward_trend_value": 0.014152751260803597, "biggest_recent_change": 0.5509451648932782},
{"total_number_of_episodes": 2656, "number_of_timesteps": 283458, "per_episode_reward": -170.37, "episode_reward_trend_value": 0.010663460308651274, "biggest_recent_change": 0.5509451648932782},
{"total_number_of_episodes": 2666, "number_of_timesteps": 284750, "per_episode_reward": -170.4, "episode_reward_trend_value": 0.008111191846407134, "biggest_recent_change": 0.5509451648932782},
{"total_number_of_episodes": 2676, "number_of_timesteps": 285875, "per_episode_reward": -170.03, "episode_reward_trend_value": 0.014301858680640735, "biggest_recent_change": 0.5509451648932782},
{"total_number_of_episodes": 2687, "number_of_timesteps": 287516, "per_episode_reward": -170.04, "episode_reward_trend_value": 0.008104076325459333, "biggest_recent_change": 0.3716858340883107},
{"total_number_of_episodes": 2697, "number_of_timesteps": 289532, "per_episode_reward": -169.73, "episode_reward_trend_value": 0.008219546769021866, "biggest_recent_change": 0.3716858340883107},
{"total_number_of_episodes": 2707, "number_of_timesteps": 290518, "per_episode_reward": -169.18, "episode_reward_trend_value": 0.01461102733097606, "biggest_recent_change": 0.5472233834656208},
{"total_number_of_episodes": 2717, "number_of_timesteps": 291506, "per_episode_reward": -168.62, "episode_reward_trend_value": 0.021122326493403103, "biggest_recent_change": 0.5617396759782594},
{"total_number_of_episodes": 2728, "number_of_timesteps": 292600, "per_episode_reward": -168.51, "episode_reward_trend_value": 0.020164965508725964, "biggest_recent_change": 0.5617396759782594},
{"total_number_of_episodes": 2738, "number_of_timesteps": 293615, "per_episode_reward": -168.59, "episode_reward_trend_value": 0.019513370009899708, "biggest_recent_change": 0.5617396759782594},
{"total_number_of_episodes": 2748, "number_of_timesteps": 294726, "per_episode_reward": -167.93, "episode_reward_trend_value": 0.027160903234027006, "biggest_recent_change": 0.6652072786382632},
{"total_number_of_episodes": 2758, "number_of_timesteps": 295919, "per_episode_reward": -168.02, "episode_reward_trend_value": 0.02645419403364776, "biggest_recent_change": 0.6652072786382632},
{"total_number_of_episodes": 2769, "number_of_timesteps": 297174, "per_episode_reward": -167.62, "episode_reward_trend_value": 0.02677081222876565, "biggest_recent_change": 0.6652072786382632},
{"total_number_of_episodes": 2779, "number_of_timesteps": 298003, "per_episode_reward": -167.29, "episode_reward_trend_value": 0.030486022403450698, "biggest_recent_change": 0.6652072786382632},
{"total_number_of_episodes": 2789, "number_of_timesteps": 299072, "per_episode_reward": -167.02, "episode_reward_trend_value": 0.030048620982906803, "biggest_recent_change": 0.6652072786382632},
{"total_number_of_episodes": 2800, "number_of_timesteps": 300357, "per_episode_reward": -167.33, "episode_reward_trend_value": 0.02053482565338085, "biggest_recent_change": 0.6652072786382632},
{"total_number_of_episodes": 2810, "number_of_timesteps": 301735, "per_episode_reward": -167.09, "episode_reward_trend_value": 0.01696767399981935, "biggest_recent_change": 0.6652072786382632},
{"total_number_of_episodes": 2820, "number_of_timesteps": 302953, "per_episode_reward": -166.97, "episode_reward_trend_value": 0.017150829293753292, "biggest_recent_change": 0.6652072786382632},
{"total_number_of_episodes": 2830, "number_of_timesteps": 304107, "per_episode_reward": -167.08, "episode_reward_trend_value": 0.016799744034200457, "biggest_recent_change": 0.6652072786382632},
{"total_number_of_episodes": 2840, "number_of_timesteps": 305051, "per_episode_reward": -167.11, "episode_reward_trend_value": 0.009124295707023104, "biggest_recent_change": 0.4001814716489207},
{"total_number_of_episodes": 2850, "number_of_timesteps": 306131, "per_episode_reward": -167.06, "episode_reward_trend_value": 0.010634340446493222, "biggest_recent_change": 0.4001814716489207},
{"total_number_of_episodes": 2861, "number_of_timesteps": 307420, "per_episode_reward": -167.12, "episode_reward_trend_value": 0.005523764565932273, "biggest_recent_change": 0.3275136686486064},
{"total_number_of_episodes": 2871, "number_of_timesteps": 308679, "per_episode_reward": -167.74, "episode_reward_trend_value": -0.004983826954208818, "biggest_recent_change": 0.6181695681640917},
{"total_number_of_episodes": 2881, "number_of_timesteps": 309638, "per_episode_reward": -167.5, "episode_reward_trend_value": -0.00535968837305821, "biggest_recent_change": 0.6181695681640917},
{"total_number_of_episodes": 2893, "number_of_timesteps": 310806, "per_episode_reward": -166.58, "episode_reward_trend_value": 0.008283578386509779, "biggest_recent_change": 0.9188758121694036},
{"total_number_of_episodes": 2904, "number_of_timesteps": 312198, "per_episode_reward": -166.79, "episode_reward_trend_value": 0.0033712931160140317, "biggest_recent_change": 0.9188758121694036},
{"total_number_of_episodes": 2914, "number_of_timesteps": 313453, "per_episode_reward": -166.52, "episode_reward_trend_value": 0.0049598752273703264, "biggest_recent_change": 0.9188758121694036},
{"total_number_of_episodes": 2924, "number_of_timesteps": 314539, "per_episode_reward": -166.29, "episode_reward_trend_value": 0.00879594107811954, "biggest_recent_change": 0.9188758121694036},
{"total_number_of_episodes": 2934, "number_of_timesteps": 315507, "per_episode_reward": -165.74, "episode_reward_trend_value": 0.01519207463164586, "biggest_recent_change": 0.9188758121694036},
{"total_number_of_episodes": 2945, "number_of_timesteps": 316725, "per_episode_reward": -165.76, "episode_reward_trend_value": 0.014443311044621826, "biggest_recent_change": 0.9188758121694036},
{"total_number_of_episodes": 2955, "number_of_timesteps": 317857, "per_episode_reward": -166.04, "episode_reward_trend_value": 0.012044471053851187, "biggest_recent_change": 0.9188758121694036},
{"total_number_of_episodes": 2965, "number_of_timesteps": 318926, "per_episode_reward": -165.97, "episode_reward_trend_value": 0.01967752563609445, "biggest_recent_change": 0.9188758121694036},
{"total_number_of_episodes": 2975, "number_of_timesteps": 320104, "per_episode_reward": -166.25, "episode_reward_trend_value": 0.013925306064582957, "biggest_recent_change": 0.9188758121694036},
{"total_number_of_episodes": 2985, "number_of_timesteps": 320954, "per_episode_reward": -165.8, "episode_reward_trend_value": 0.008705509034663174, "biggest_recent_change": 0.5500689490096704},
{"total_number_of_episodes": 2995, "number_of_timesteps": 322049, "per_episode_reward": -165.94, "episode_reward_trend_value": 0.009441609431793393, "biggest_recent_change": 0.5500689490096704},
{"total_number_of_episodes": 3005, "number_of_timesteps": 323304, "per_episode_reward": -166.08, "episode_reward_trend_value": 0.004916559898635834, "biggest_recent_change": 0.5500689490096704},
{"total_number_of_episodes": 3015, "number_of_timesteps": 324446, "per_episode_reward": -165.52, "episode_reward_trend_value": 0.008496072880911736, "biggest_recent_change": 0.5513859502919161},
{"total_number_of_episodes": 3025, "number_of_timesteps": 325670, "per_episode_reward": -165.3, "episode_reward_trend_value": 0.004890158148968579, "biggest_recent_change": 0.5513859502919161},
{"total_number_of_episodes": 3035, "number_of_timesteps": 326682, "per_episode_reward": -165.1, "episode_reward_trend_value": 0.00742789686447054, "biggest_recent_change": 0.5513859502919161},
{"total_number_of_episodes": 3046, "number_of_timesteps": 328018, "per_episode_reward": -165.26, "episode_reward_trend_value": 0.008627091298801777, "biggest_recent_change": 0.5513859502919161},
{"total_number_of_episodes": 3056, "number_of_timesteps": 328981, "per_episode_reward": -165.1, "episode_reward_trend_value": 0.009701894905423893, "biggest_recent_change": 0.5513859502919161},
{"total_number_of_episodes": 3067, "number_of_timesteps": 329988, "per_episode_reward": -164.73, "episode_reward_trend_value": 0.016923292535032098, "biggest_recent_change": 0.5513859502919161},
{"total_number_of_episodes": 3078, "number_of_timesteps": 331113, "per_episode_reward": -164.52, "episode_reward_trend_value": 0.014249120782778213, "biggest_recent_change": 0.5513859502919161},
{"total_number_of_episodes": 3088, "number_of_timesteps": 332033, "per_episode_reward": -164.47, "episode_reward_trend_value": 0.016278378565309344, "biggest_recent_change": 0.5513859502919161},
{"total_number_of_episodes": 3099, "number_of_timesteps": 333182, "per_episode_reward": -164.49, "episode_reward_trend_value": 0.01761003176311533, "biggest_recent_change": 0.5513859502919161},
{"total_number_of_episodes": 3109, "number_of_timesteps": 334330, "per_episode_reward": -164.44, "episode_reward_trend_value": 0.012077193591843777, "biggest_recent_change": 0.37086556394987724},
{"total_number_of_episodes": 3120, "number_of_timesteps": 335488, "per_episode_reward": -164.35, "episode_reward_trend_value": 0.010572179856215296, "biggest_recent_change": 0.37086556394987724},
{"total_number_of_episodes": 3130, "number_of_timesteps": 336542, "per_episode_reward": -163.48, "episode_reward_trend_value": 0.01793920928122803, "biggest_recent_change": 0.8662311739377913},
{"total_number_of_episodes": 3140, "number_of_timesteps": 337558, "per_episode_reward": -163.44, "episode_reward_trend_value": 0.02021441562417926, "biggest_recent_change": 0.8662311739377913},
{"total_number_of_episodes": 3150, "number_of_timesteps": 338765, "per_episode_reward": -163.29, "episode_reward_trend_value": 0.02010749975017916, "biggest_recent_change": 0.8662311739377913},
{"total_number_of_episodes": 3160, "number_of_timesteps": 340320, "per_episode_reward": -163.26, "episode_reward_trend_value": 0.01635495464370567, "biggest_recent_change": 0.8662311739377913},
{"total_number_of_episodes": 3170, "number_of_timesteps": 341646, "per_episode_reward": -163.18, "episode_reward_trend_value": 0.01489107804480783, "biggest_recent_change": 0.8662311739377913},
{"total_number_of_episodes": 3180, "number_of_timesteps": 342596, "per_episode_reward": -162.96, "episode_reward_trend_value": 0.016766073688936622, "biggest_recent_change": 0.8662311739377913},
{"total_number_of_episodes": 3192, "number_of_timesteps": 344013, "per_episode_reward": -162.82, "episode_reward_trend_value": 0.018549824763436126, "biggest_recent_change": 0.8662311739377913},
{"total_number_of_episodes": 3202, "number_of_timesteps": 345077, "per_episode_reward": -162.72, "episode_reward_trend_value": 0.01906852465136492, "biggest_recent_change": 0.8662311739377913},
{"total_number_of_episodes": 3212, "number_of_timesteps": 346250, "per_episode_reward": -162.56, "episode_reward_trend_value": 0.019815203085317357, "biggest_recent_change": 0.8662311739377913},
{"total_number_of_episodes": 3222, "number_of_timesteps": 347472, "per_episode_reward": -162.55, "episode_reward_trend_value": 0.010343821757035066, "biggest_recent_change": 0.21622219695422018},
{"total_number_of_episodes": 3233, "number_of_timesteps": 348495, "per_episode_reward": -162.45, "episode_reward_trend_value": 0.011017171238519394, "biggest_recent_change": 0.21622219695422018},
{"total_number_of_episodes": 3243, "number_of_timesteps": 349763, "per_episode_reward": -162.47, "episode_reward_trend_value": 0.009110188012581313, "biggest_recent_change": 0.21622219695422018},
{"total_number_of_episodes": 3254, "number_of_timesteps": 351515, "per_episode_reward": -162.43, "episode_reward_trend_value": 0.009162479030888132, "biggest_recent_change": 0.21622219695422018},
{"total_number_of_episodes": 3264, "number_of_timesteps": 352859, "per_episode_reward": -163.08, "episode_reward_trend_value": 0.0011381158568408664, "biggest_recent_change": 0.645522957791286},
{"total_number_of_episodes": 3275, "number_of_timesteps": 354238, "per_episode_reward": -162.85, "episode_reward_trend_value": 0.0012255117680777202, "biggest_recent_change": 0.645522957791286},
{"total_number_of_episodes": 3285, "number_of_timesteps": 355890, "per_episode_reward": -163.02, "episode_reward_trend_value": -0.002230964298323733, "biggest_recent_change": 0.645522957791286},
{"total_number_of_episodes": 3296, "number_of_timesteps": 357017, "per_episode_reward": -162.67, "episode_reward_trend_value": 0.000621986839070448, "biggest_recent_change": 0.645522957791286},
{"total_number_of_episodes": 3306, "number_of_timesteps": 358092, "per_episode_reward": -162.84, "episode_reward_trend_value": -0.0031037049924170406, "biggest_recent_change": 0.645522957791286},
{"total_number_of_episodes": 3317, "number_of_timesteps": 359872, "per_episode_reward": -162.77, "episode_reward_trend_value": -0.0024658142665755474, "biggest_recent_change": 0.645522957791286},
{"total_number_of_episodes": 3327, "number_of_timesteps": 360980, "per_episode_reward": -162.79, "episode_reward_trend_value": -0.0037383907168292456, "biggest_recent_change": 0.645522957791286},
{"total_number_of_episodes": 3339, "number_of_timesteps": 362546, "per_episode_reward": -162.83, "episode_reward_trend_value": -0.003984819426242818, "biggest_recent_change": 0.645522957791286},
{"total_number_of_episodes": 3349, "number_of_timesteps": 363466, "per_episode_reward": -162.56, "episode_reward_trend_value": -0.001392223321422787, "biggest_recent_change": 0.645522957791286},
{"total_number_of_episodes": 3359, "number_of_timesteps": 364502, "per_episode_reward": -162.45, "episode_reward_trend_value": 0.006965848338008287, "biggest_recent_change": 0.35687910715654425},
{"total_number_of_episodes": 3369, "number_of_timesteps": 365823, "per_episode_reward": -162.43, "episode_reward_trend_value": 0.004718813872632824, "biggest_recent_change": 0.35687910715654425},
{"total_number_of_episodes": 3379, "number_of_timesteps": 366770, "per_episode_reward": -162.1, "episode_reward_trend_value": 0.010231909101578809, "biggest_recent_change": 0.35687910715654425},
{"total_number_of_episodes": 3389, "number_of_timesteps": 367930, "per_episode_reward": -162.43, "episode_reward_trend_value": 0.0026459290771501604, "biggest_recent_change": 0.32585909504203414},
{"total_number_of_episodes": 3399, "number_of_timesteps": 368833, "per_episode_reward": -161.97, "episode_reward_trend_value": 0.00972901746039775, "biggest_recent_change": 0.4594521356423513},
{"total_number_of_episodes": 3409, "number_of_timesteps": 369659, "per_episode_reward": -161.57, "episode_reward_trend_value": 0.013405396745184501, "biggest_recent_change": 0.4594521356423513},
{"total_number_of_episodes": 3419, "number_of_timesteps": 370554, "per_episode_reward": -161.18, "episode_reward_trend_value": 0.017886304908140322, "biggest_recent_change": 0.4594521356423513},
{"total_number_of_episodes": 3429, "number_of_timesteps": 371883, "per_episode_reward": -161.26, "episode_reward_trend_value": 0.017450156351443032, "biggest_recent_change": 0.4594521356423513},
{"total_number_of_episodes": 3439, "number_of_timesteps": 372705, "per_episode_reward": -161.1, "episode_reward_trend_value": 0.016143319051388973, "biggest_recent_change": 0.4594521356423513},
{"total_number_of_episodes": 3449, "number_of_timesteps": 373666, "per_episode_reward": -160.94, "episode_reward_trend_value": 0.016789343125869195, "biggest_recent_change": 0.4594521356423513},
{"total_number_of_episodes": 3459, "number_of_timesteps": 374739, "per_episode_reward": -160.98, "episode_reward_trend_value": 0.016075925513103093, "biggest_recent_change": 0.4594521356423513},
{"total_number_of_episodes": 3470, "number_of_timesteps": 375885, "per_episode_reward": -160.77, "episode_reward_trend_value": 0.014768446800878918, "biggest_recent_change": 0.4594521356423513},
{"total_number_of_episodes": 3480, "number_of_timesteps": 376975, "per_episode_reward": -161.07, "episode_reward_trend_value": 0.01506721373895093, "biggest_recent_change": 0.4594521356423513},
{"total_number_of_episodes": 3491, "number_of_timesteps": 378325, "per_episode_reward": -161.12, "episode_reward_trend_value": 0.009407220983363926, "biggest_recent_change": 0.40209115534892703},
{"total_number_of_episodes": 3501, "number_of_timesteps": 379508, "per_episode_reward": -160.61, "episode_reward_trend_value": 0.010584368618328061, "biggest_recent_change": 0.5080344424956991},
{"total_number_of_episodes": 3511, "number_of_timesteps": 380679, "per_episode_reward": -161.12, "episode_reward_trend_value": 0.0006464145832505134, "biggest_recent_change": 0.5080344424956991},
{"total_number_of_episodes": 3521, "number_of_timesteps": 381966, "per_episode_reward": -161.25, "episode_reward_trend_value": 5.6839636526559735e-05, "biggest_recent_change": 0.5080344424956991},
{"total_number_of_episodes": 3531, "number_of_timesteps": 383149, "per_episode_reward": -161.22, "episode_reward_trend_value": -0.001292803749150077, "biggest_recent_change": 0.5080344424956991},
{"total_number_of_episodes": 3541, "number_of_timesteps": 384227, "per_episode_reward": -161.08, "episode_reward_trend_value": -0.0016203423738166596, "biggest_recent_change": 0.5080344424956991},
{"total_number_of_episodes": 3551, "number_of_timesteps": 385471, "per_episode_reward": -160.92, "episode_reward_trend_value": 0.0007256930047680676, "biggest_recent_change": 0.5080344424956991},
{"total_number_of_episodes": 3561, "number_of_timesteps": 386521, "per_episode_reward": -160.57, "episode_reward_trend_value": 0.002221693579670614, "biggest_recent_change": 0.5080344424956991},
{"total_number_of_episodes": 3572, "number_of_timesteps": 388287, "per_episode_reward": -160.52, "episode_reward_trend_value": 0.006175032021325756, "biggest_recent_change": 0.5080344424956991},
{"total_number_of_episodes": 3582, "number_of_timesteps": 389788, "per_episode_reward": -160.3, "episode_reward_trend_value": 0.009178731448449816, "biggest_recent_change": 0.5080344424956991},
{"total_number_of_episodes": 3592, "number_of_timesteps": 390845, "per_episode_reward": -160.07, "episode_reward_trend_value": 0.006014194537081291, "biggest_recent_change": 0.5080344424956991},
{"total_number_of_episodes": 3602, "number_of_timesteps": 392027, "per_episode_reward": -160.09, "episode_reward_trend_value": 0.011505848968441038, "biggest_recent_change": 0.3428260626830877},
{"total_number_of_episodes": 3612, "number_of_timesteps": 393228, "per_episode_reward": -160.34, "episode_reward_trend_value": 0.010079152730694495, "biggest_recent_change": 0.3428260626830877},
{"total_number_of_episodes": 3622, "number_of_timesteps": 394189, "per_episode_reward": -160.05, "episode_reward_trend_value": 0.012957637166670111, "biggest_recent_change": 0.3428260626830877},
{"total_number_of_episodes": 3632, "number_of_timesteps": 395227, "per_episode_reward": -159.77, "episode_reward_trend_value": 0.0145551890110634, "biggest_recent_change": 0.3428260626830877},
{"total_number_of_episodes": 3642, "number_of_timesteps": 396430, "per_episode_reward": -159.79, "episode_reward_trend_value": 0.012550557319179412, "biggest_recent_change": 0.3428260626830877},
{"total_number_of_episodes": 3652, "number_of_timesteps": 397583, "per_episode_reward": -159.6, "episode_reward_trend_value": 0.010846412241807633, "biggest_recent_change": 0.2911566829707226},
{"total_number_of_episodes": 3662, "number_of_timesteps": 399047, "per_episode_reward": -159.65, "episode_reward_trend_value": 0.009661870096612625, "biggest_recent_change": 0.2911566829707226},
{"total_number_of_episodes": 3672, "number_of_timesteps": 400174, "per_episode_reward": -159.31, "episode_reward_trend_value": 0.01099633358862775, "biggest_recent_change": 0.34048745036204764},
{"total_number_of_episodes": 3683, "number_of_timesteps": 401357, "per_episode_reward": -159.05, "episode_reward_trend_value": 0.011341376479779796, "biggest_recent_change": 0.34048745036204764},
{"total_number_of_episodes": 3694, "number_of_timesteps": 402333, "per_episode_reward": -158.95, "episode_reward_trend_value": 0.012565655379444252, "biggest_recent_change": 0.34048745036204764},
{"total_number_of_episodes": 3704, "number_of_timesteps": 403222, "per_episode_reward": -158.52, "episode_reward_trend_value": 0.020298014388806487, "biggest_recent_change": 0.437302700129635},
{"total_number_of_episodes": 3714, "number_of_timesteps": 404274, "per_episode_reward": -158.43, "episode_reward_trend_value": 0.017991078755230837, "biggest_recent_change": 0.437302700129635},
{"total_number_of_episodes": 3724, "number_of_timesteps": 405494, "per_episode_reward": -158.38, "episode_reward_trend_value": 0.015485855217536305, "biggest_recent_change": 0.437302700129635},
{"total_number_of_episodes": 3734, "number_of_timesteps": 406851, "per_episode_reward": -158.42, "episode_reward_trend_value": 0.015193017607218608, "biggest_recent_change": 0.437302700129635},
{"total_number_of_episodes": 3744, "number_of_timesteps": 408315, "per_episode_reward": -158.41, "episode_reward_trend_value": 0.013163620746562466, "biggest_recent_change": 0.437302700129635},
{"total_number_of_episodes": 3754, "number_of_timesteps": 409427, "per_episode_reward": -158.36, "episode_reward_trend_value": 0.014342784660239102, "biggest_recent_change": 0.437302700129635},
{"total_number_of_episodes": 3764, "number_of_timesteps": 410760, "per_episode_reward": -158.33, "episode_reward_trend_value": 0.010880951049451444, "biggest_recent_change": 0.437302700129635},
{"total_number_of_episodes": 3774, "number_of_timesteps": 412124, "per_episode_reward": -158.3, "episode_reward_trend_value": 0.008367808793061234, "biggest_recent_change": 0.437302700129635},
{"total_number_of_episodes": 3784, "number_of_timesteps": 413423, "per_episode_reward": -158.51, "episode_reward_trend_value": 0.004905786003436674, "biggest_recent_change": 0.437302700129635},
{"total_number_of_episodes": 3794, "number_of_timesteps": 414375, "per_episode_reward": -158.4, "episode_reward_trend_value": 0.0013578459161199892, "biggest_recent_change": 0.2151824937697313},
{"total_number_of_episodes": 3804, "number_of_timesteps": 415606, "per_episode_reward": -158.27, "episode_reward_trend_value": 0.0018762110293408796, "biggest_recent_change": 0.2151824937697313},
{"total_number_of_episodes": 3814, "number_of_timesteps": 416712, "per_episode_reward": -158.31, "episode_reward_trend_value": 0.0007623633192868813, "biggest_recent_change": 0.2151824937697313},
{"total_number_of_episodes": 3824, "number_of_timesteps": 417766, "per_episode_reward": -158.24, "episode_reward_trend_value": 0.002006895822725912, "biggest_recent_change": 0.2151824937697313},
{"total_number_of_episodes": 3836, "number_of_timesteps": 419096, "per_episode_reward": -158.08, "episode_reward_trend_value": 0.0037094004701370095, "biggest_recent_change": 0.2151824937697313},
{"total_number_of_episodes": 3846, "number_of_timesteps": 420228, "per_episode_reward": -157.89, "episode_reward_trend_value": 0.005219323188474808, "biggest_recent_change": 0.2151824937697313},
{"total_number_of_episodes": 3856, "number_of_timesteps": 421327, "per_episode_reward": -157.84, "episode_reward_trend_value": 0.005408622834692286, "biggest_recent_change": 0.2151824937697313},
{"total_number_of_episodes": 3866, "number_of_timesteps": 422708, "per_episode_reward": -157.68, "episode_reward_trend_value": 0.006906864640276922, "biggest_recent_change": 0.2151824937697313},
{"total_number_of_episodes": 3876, "number_of_timesteps": 424099, "per_episode_reward": -157.75, "episode_reward_trend_value": 0.00849074796327803, "biggest_recent_change": 0.1922393929471582},
{"total_number_of_episodes": 3886, "number_of_timesteps": 424974, "per_episode_reward": -157.51, "episode_reward_trend_value": 0.009881485487337865, "biggest_recent_change": 0.24315446943651864},
{"total_number_of_episodes": 3896, "number_of_timesteps": 425927, "per_episode_reward": -157.4, "episode_reward_trend_value": 0.009591799234110947, "biggest_recent_change": 0.24315446943651864},

{"total_number_of_episodes": 3906, "number_of_timesteps": 427141, "per_episode_reward": -157.59, "episode_reward_trend_value": 0.00803235304669272, "biggest_recent_change": 0.24315446943651864},
{"total_number_of_episodes": 3916, "number_of_timesteps": 428260, "per_episode_reward": -157.56, "episode_reward_trend_value": 0.007564730665518482, "biggest_recent_change": 0.24315446943651864},
{"total_number_of_episodes": 3926, "number_of_timesteps": 429501, "per_episode_reward": -157.61, "episode_reward_trend_value": 0.005156849958394913, "biggest_recent_change": 0.24315446943651864},
{"total_number_of_episodes": 3936, "number_of_timesteps": 430772, "per_episode_reward": -157.64, "episode_reward_trend_value": 0.0027400577442181074, "biggest_recent_change": 0.24315446943651864},
{"total_number_of_episodes": 3946, "number_of_timesteps": 431720, "per_episode_reward": -157.39, "episode_reward_trend_value": 0.004981609144526703, "biggest_recent_change": 0.24769901957850493},
{"total_number_of_episodes": 3956, "number_of_timesteps": 432621, "per_episode_reward": -157.28, "episode_reward_trend_value": 0.004396977583700038, "biggest_recent_change": 0.24769901957850493},
{"total_number_of_episodes": 3966, "number_of_timesteps": 433842, "per_episode_reward": -157.26, "episode_reward_trend_value": 0.005445595135860357, "biggest_recent_change": 0.24769901957850493},
{"total_number_of_episodes": 3976, "number_of_timesteps": 434920, "per_episode_reward": -157.16, "episode_reward_trend_value": 0.00388913630950564, "biggest_recent_change": 0.24769901957850493},
{"total_number_of_episodes": 3986, "number_of_timesteps": 435959, "per_episode_reward": -157.09, "episode_reward_trend_value": 0.003498362344112138, "biggest_recent_change": 0.24769901957850493},
{"total_number_of_episodes": 3996, "number_of_timesteps": 436995, "per_episode_reward": -156.96, "episode_reward_trend_value": 0.007041493465565117, "biggest_recent_change": 0.24769901957850493},
{"total_number_of_episodes": 4006, "number_of_timesteps": 438020, "per_episode_reward": -156.93, "episode_reward_trend_value": 0.006964218205994637, "biggest_recent_change": 0.24769901957850493},
{"total_number_of_episodes": 4016, "number_of_timesteps": 439033, "per_episode_reward": -156.96, "episode_reward_trend_value": 0.007263173329181427, "biggest_recent_change": 0.24769901957850493},
{"total_number_of_episodes": 4027, "number_of_timesteps": 440614, "per_episode_reward": -157.0, "episode_reward_trend_value": 0.007141694657931591, "biggest_recent_change": 0.24769901957850493},
{"total_number_of_episodes": 4039, "number_of_timesteps": 441600, "per_episode_reward": -156.92, "episode_reward_trend_value": 0.005233091741780842, "biggest_recent_change": 0.13196207980189456},
{"total_number_of_episodes": 4049, "number_of_timesteps": 442430, "per_episode_reward": -156.5, "episode_reward_trend_value": 0.008697195547496664, "biggest_recent_change": 0.4220914421437385},
{"total_number_of_episodes": 4060, "number_of_timesteps": 443484, "per_episode_reward": -156.45, "episode_reward_trend_value": 0.008938879717871056, "biggest_recent_change": 0.4220914421437385},
{"total_number_of_episodes": 4071, "number_of_timesteps": 444916, "per_episode_reward": -156.54, "episode_reward_trend_value": 0.006879817178270603, "biggest_recent_change": 0.4220914421437385},
{"total_number_of_episodes": 4081, "number_of_timesteps": 446141, "per_episode_reward": -156.75, "episode_reward_trend_value": 0.003712266318734376, "biggest_recent_change": 0.4220914421437385},
{"total_number_of_episodes": 4092, "number_of_timesteps": 447553, "per_episode_reward": -156.86, "episode_reward_trend_value": 0.0010962022991299768, "biggest_recent_change": 0.4220914421437385},
{"total_number_of_episodes": 4102, "number_of_timesteps": 448474, "per_episode_reward": -156.66, "episode_reward_trend_value": 0.003008817508406183, "biggest_recent_change": 0.4220914421437385},
{"total_number_of_episodes": 4112, "number_of_timesteps": 449231, "per_episode_reward": -156.41, "episode_reward_trend_value": 0.0060892003922134565, "biggest_recent_change": 0.4220914421437385},
{"total_number_of_episodes": 4122, "number_of_timesteps": 450261, "per_episode_reward": -156.47, "episode_reward_trend_value": 0.005866385116177576, "biggest_recent_change": 0.4220914421437385},
{"total_number_of_episodes": 4132, "number_of_timesteps": 451307, "per_episode_reward": -156.38, "episode_reward_trend_value": 0.005957936300872132, "biggest_recent_change": 0.4220914421437385},
{"total_number_of_episodes": 4142, "number_of_timesteps": 452509, "per_episode_reward": -156.52, "episode_reward_trend_value": -0.00029643591863425125, "biggest_recent_change": 0.2474638635159181},
{"total_number_of_episodes": 4153, "number_of_timesteps": 454367, "per_episode_reward": -156.4, "episode_reward_trend_value": 0.0005792169714118877, "biggest_recent_change": 0.2474638635159181},
{"total_number_of_episodes": 4163, "number_of_timesteps": 455148, "per_episode_reward": -156.21, "episode_reward_trend_value": 0.003635663027744348, "biggest_recent_change": 0.2474638635159181},
{"total_number_of_episodes": 4173, "number_of_timesteps": 455852, "per_episode_reward": -155.47, "episode_reward_trend_value": 0.01424525417087826, "biggest_recent_change": 0.7387275419867478},
{"total_number_of_episodes": 4184, "number_of_timesteps": 456676, "per_episode_reward": -155.19, "episode_reward_trend_value": 0.018529572276311353, "biggest_recent_change": 0.7387275419867478},
{"total_number_of_episodes": 4194, "number_of_timesteps": 457578, "per_episode_reward": -154.97, "episode_reward_trend_value": 0.0188138203305259, "biggest_recent_change": 0.7387275419867478},
{"total_number_of_episodes": 4204, "number_of_timesteps": 458596, "per_episode_reward": -155.06, "episode_reward_trend_value": 0.014987465087111218, "biggest_recent_change": 0.7387275419867478},
{"total_number_of_episodes": 4214, "number_of_timesteps": 460012, "per_episode_reward": -154.94, "episode_reward_trend_value": 0.01693965526042468, "biggest_recent_change": 0.7387275419867478},
{"total_number_of_episodes": 4224, "number_of_timesteps": 461020, "per_episode_reward": -154.66, "episode_reward_trend_value": 0.019196618657231726, "biggest_recent_change": 0.7387275419867478},
{"total_number_of_episodes": 4234, "number_of_timesteps": 461935, "per_episode_reward": -154.36, "episode_reward_trend_value": 0.024073138249049306, "biggest_recent_change": 0.7387275419867478},
{"total_number_of_episodes": 4245, "number_of_timesteps": 463231, "per_episode_reward": -154.24, "episode_reward_trend_value": 0.02397722759615072, "biggest_recent_change": 0.7387275419867478},
{"total_number_of_episodes": 4255, "number_of_timesteps": 464405, "per_episode_reward": -154.27, "episode_reward_trend_value": 0.021547161023412777, "biggest_recent_change": 0.7387275419867478},
{"total_number_of_episodes": 4265, "number_of_timesteps": 465452, "per_episode_reward": -154.17, "episode_reward_trend_value": 0.014412340679413344, "biggest_recent_change": 0.29808470565174616},
{"total_number_of_episodes": 4275, "number_of_timesteps": 466702, "per_episode_reward": -154.32, "episode_reward_trend_value": 0.009692724837597035, "biggest_recent_change": 0.29808470565174616},
{"total_number_of_episodes": 4285, "number_of_timesteps": 467945, "per_episode_reward": -154.21, "episode_reward_trend_value": 0.008414489671766823, "biggest_recent_change": 0.29808470565174616},
{"total_number_of_episodes": 4296, "number_of_timesteps": 469525, "per_episode_reward": -154.05, "episode_reward_trend_value": 0.011285770444628598, "biggest_recent_change": 0.29808470565174616},
{"total_number_of_episodes": 4306, "number_of_timesteps": 470490, "per_episode_reward": -153.96, "episode_reward_trend_value": 0.010946214276092154, "biggest_recent_change": 0.29808470565174616},
{"total_number_of_episodes": 4316, "number_of_timesteps": 471697, "per_episode_reward": -153.95, "episode_reward_trend_value": 0.00788063532299677, "biggest_recent_change": 0.29808470565174616},
{"total_number_of_episodes": 4326, "number_of_timesteps": 473171, "per_episode_reward": -153.96, "episode_reward_trend_value": 0.0044420389970718415, "biggest_recent_change": 0.16150716116615627},
{"total_number_of_episodes": 4337, "number_of_timesteps": 474390, "per_episode_reward": -153.87, "episode_reward_trend_value": 0.0041068252476675424, "biggest_recent_change": 0.16150716116615627},
{"total_number_of_episodes": 4348, "number_of_timesteps": 475322, "per_episode_reward": -153.8, "episode_reward_trend_value": 0.005179305077833066, "biggest_recent_change": 0.16150716116615627},
{"total_number_of_episodes": 4359, "number_of_timesteps": 476250, "per_episode_reward": -153.72, "episode_reward_trend_value": 0.005060934384145968, "biggest_recent_change": 0.16150716116615627},
{"total_number_of_episodes": 4369, "number_of_timesteps": 477210, "per_episode_reward": -153.69, "episode_reward_trend_value": 0.006976887623566894, "biggest_recent_change": 0.16150716116615627},
{"total_number_of_episodes": 4379, "number_of_timesteps": 478303, "per_episode_reward": -153.6, "episode_reward_trend_value": 0.006817426672438387, "biggest_recent_change": 0.16150716116615627},
{"total_number_of_episodes": 4389, "number_of_timesteps": 479425, "per_episode_reward": -153.73, "episode_reward_trend_value": 0.0035036834519555924, "biggest_recent_change": 0.13672972867729527},
{"total_number_of_episodes": 4400, "number_of_timesteps": 480774, "per_episode_reward": -153.68, "episode_reward_trend_value": 0.0031173523760559064, "biggest_recent_change": 0.13672972867729527},
{"total_number_of_episodes": 4411, "number_of_timesteps": 482044, "per_episode_reward": -153.56, "episode_reward_trend_value": 0.004276924219287695, "biggest_recent_change": 0.13672972867729527},
{"total_number_of_episodes": 4421, "number_of_timesteps": 482944, "per_episode_reward": -153.54, "episode_reward_trend_value": 0.004695675254692193, "biggest_recent_change": 0.13672972867729527},
{"total_number_of_episodes": 4431, "number_of_timesteps": 483852, "per_episode_reward": -153.39, "episode_reward_trend_value": 0.00538526307718933, "biggest_recent_change": 0.14556462825012773},
{"total_number_of_episodes": 4442, "number_of_timesteps": 485041, "per_episode_reward": -153.23, "episode_reward_trend_value": 0.0063700129259309, "biggest_recent_change": 0.15928237112569832},
{"total_number_of_episodes": 4452, "number_of_timesteps": 486132, "per_episode_reward": -153.29, "episode_reward_trend_value": 0.004713910093090274, "biggest_recent_change": 0.15928237112569832},
{"total_number_of_episodes": 4463, "number_of_timesteps": 488195, "per_episode_reward": -153.5, "episode_reward_trend_value": 0.0020675017084796662, "biggest_recent_change": 0.20840144130406202},
{"total_number_of_episodes": 4475, "number_of_timesteps": 489243, "per_episode_reward": -153.33, "episode_reward_trend_value": 0.0029795762839373513, "biggest_recent_change": 0.20840144130406202},
{"total_number_of_episodes": 4485, "number_of_timesteps": 490371, "per_episode_reward": -153.29, "episode_reward_trend_value": 0.00487044243406716, "biggest_recent_change": 0.20840144130406202},
{"total_number_of_episodes": 4495, "number_of_timesteps": 492171, "per_episode_reward": -153.37, "episode_reward_trend_value": 0.003409490505355469, "biggest_recent_change": 0.20840144130406202},
{"total_number_of_episodes": 4506, "number_of_timesteps": 493480, "per_episode_reward": -153.24, "episode_reward_trend_value": 0.0036176130587572664, "biggest_recent_change": 0.20840144130406202},
{"total_number_of_episodes": 4517, "number_of_timesteps": 494687, "per_episode_reward": -153.03, "episode_reward_trend_value": 0.0056187605778685815, "biggest_recent_change": 0.20840144130406202},
{"total_number_of_episodes": 4527, "number_of_timesteps": 495999, "per_episode_reward": -152.78, "episode_reward_trend_value": 0.006796055351964014, "biggest_recent_change": 0.25152115791871665},
{"total_number_of_episodes": 4538, "number_of_timesteps": 497163, "per_episode_reward": -152.57, "episode_reward_trend_value": 0.007370846240781425, "biggest_recent_change": 0.25152115791871665},
{"total_number_of_episodes": 4548, "number_of_timesteps": 498152, "per_episode_reward": -152.62, "episode_reward_trend_value": 0.007479676927100816, "biggest_recent_change": 0.25152115791871665},
{"total_number_of_episodes": 4558, "number_of_timesteps": 499110, "per_episode_reward": -152.54, "episode_reward_trend_value": 0.01068733201386749, "biggest_recent_change": 0.25152115791871665},
{"total_number_of_episodes": 4569, "number_of_timesteps": 500507, "per_episode_reward": -152.54, "episode_reward_trend_value": 0.008787039579821807, "biggest_recent_change": 0.25152115791871665},
{"total_number_of_episodes": 4579, "number_of_timesteps": 501712, "per_episode_reward": -152.77, "episode_reward_trend_value": 0.0058701649869991315, "biggest_recent_change": 0.25152115791871665},
{"total_number_of_episodes": 4589, "number_of_timesteps": 502832, "per_episode_reward": -152.6, "episode_reward_trend_value": 0.008604467634229233, "biggest_recent_change": 0.25152115791871665},
{"total_number_of_episodes": 4601, "number_of_timesteps": 504146, "per_episode_reward": -152.26, "episode_reward_trend_value": 0.010857779606136358, "biggest_recent_change": 0.3372795368501613},
{"total_number_of_episodes": 4611, "number_of_timesteps": 505323, "per_episode_reward": -152.51, "episode_reward_trend_value": 0.0057418333129678305, "biggest_recent_change": 0.3372795368501613},
{"total_number_of_episodes": 4621, "number_of_timesteps": 506346, "per_episode_reward": -152.67, "episode_reward_trend_value": 0.0012012773877257941, "biggest_recent_change": 0.3372795368501613},
{"total_number_of_episodes": 4631, "number_of_timesteps": 507581, "per_episode_reward": -152.59, "episode_reward_trend_value": -0.00029719509732204744, "biggest_recent_change": 0.3372795368501613},
{"total_number_of_episodes": 4643, "number_of_timesteps": 508792, "per_episode_reward": -152.44, "episode_reward_trend_value": 0.002041060679845133, "biggest_recent_change": 0.3372795368501613},
{"total_number_of_episodes": 4654, "number_of_timesteps": 510103, "per_episode_reward": -152.24, "episode_reward_trend_value": 0.0033110889526732816, "biggest_recent_change": 0.3372795368501613},
{"total_number_of_episodes": 4664, "number_of_timesteps": 511664, "per_episode_reward": -152.21, "episode_reward_trend_value": 0.003589339819371023, "biggest_recent_change": 0.3372795368501613},
{"total_number_of_episodes": 4674, "number_of_timesteps": 512751, "per_episode_reward": -152.08, "episode_reward_trend_value": 0.0076420488692065195, "biggest_recent_change": 0.3372795368501613},
{"total_number_of_episodes": 4686, "number_of_timesteps": 513675, "per_episode_reward": -151.87, "episode_reward_trend_value": 0.008020298423658308, "biggest_recent_change": 0.3372795368501613},
{"total_number_of_episodes": 4696, "number_of_timesteps": 514494, "per_episode_reward": -151.05, "episode_reward_trend_value": 0.013409064187619103, "biggest_recent_change": 0.8222684556066326},
{"total_number_of_episodes": 4706, "number_of_timesteps": 515465, "per_episode_reward": -151.03, "episode_reward_trend_value": 0.016514986642636766, "biggest_recent_change": 0.8222684556066326},
{"total_number_of_episodes": 4716, "number_of_timesteps": 516546, "per_episode_reward": -151.02, "episode_reward_trend_value": 0.018300459116082697, "biggest_recent_change": 0.8222684556066326},
{"total_number_of_episodes": 4727, "number_of_timesteps": 517670, "per_episode_reward": -150.81, "episode_reward_trend_value": 0.019807650108652788, "biggest_recent_change": 0.8222684556066326},
{"total_number_of_episodes": 4737, "number_of_timesteps": 518614, "per_episode_reward": -150.76, "episode_reward_trend_value": 0.018684967727054098, "biggest_recent_change": 0.8222684556066326},
{"total_number_of_episodes": 4747, "number_of_timesteps": 519849, "per_episode_reward": -151.09, "episode_reward_trend_value": 0.012824171069236615, "biggest_recent_change": 0.8222684556066326},
{"total_number_of_episodes": 4757, "number_of_timesteps": 521192, "per_episode_reward": -150.84, "episode_reward_trend_value": 0.015303363340812049, "biggest_recent_change": 0.8222684556066326},
{"total_number_of_episodes": 4767, "number_of_timesteps": 522464, "per_episode_reward": -151.21, "episode_reward_trend_value": 0.009617253037475848, "biggest_recent_change": 0.8222684556066326},
{"total_number_of_episodes": 4777, "number_of_timesteps": 523536, "per_episode_reward": -151.29, "episode_reward_trend_value": 0.006551899145686156, "biggest_recent_change": 0.8222684556066326},
{"total_number_of_episodes": 4787, "number_of_timesteps": 524481, "per_episode_reward": -151.12, "episode_reward_trend_value": -0.0007049145062492496, "biggest_recent_change": 0.37607660133471654},
{"total_number_of_episodes": 4797, "number_of_timesteps": 525356, "per_episode_reward": -150.67, "episode_reward_trend_value": 0.0039855309388959394, "biggest_recent_change": 0.44763985085441504},
{"total_number_of_episodes": 4807, "number_of_timesteps": 526744, "per_episode_reward": -151.06, "episode_reward_trend_value": -0.0004505390550418851, "biggest_recent_change": 0.44763985085441504},
{"total_number_of_episodes": 4818, "number_of_timesteps": 528392, "per_episode_reward": -150.62, "episode_reward_trend_value": 0.002084648744894303, "biggest_recent_change": 0.44763985085441504},
{"total_number_of_episodes": 4828, "number_of_timesteps": 529857, "per_episode_reward": -150.58, "episode_reward_trend_value": 0.0019947762486800177, "biggest_recent_change": 0.44763985085441504},
{"total_number_of_episodes": 4839, "number_of_timesteps": 531160, "per_episode_reward": -150.5, "episode_reward_trend_value": 0.006559590274028121, "biggest_recent_change": 0.44763985085441504},
{"total_number_of_episodes": 4849, "number_of_timesteps": 532534, "per_episode_reward": -150.44, "episode_reward_trend_value": 0.004429757370415485, "biggest_recent_change": 0.44763985085441504},
{"total_number_of_episodes": 4859, "number_of_timesteps": 533702, "per_episode_reward": -150.62, "episode_reward_trend_value": 0.006567694310610427, "biggest_recent_change": 0.44763985085441504},
{"total_number_of_episodes": 4869, "number_of_timesteps": 534874, "per_episode_reward": -150.49, "episode_reward_trend_value": 0.008800270579733175, "biggest_recent_change": 0.44763985085441504},
{"total_number_of_episodes": 4879, "number_of_timesteps": 535892, "per_episode_reward": -150.33, "episode_reward_trend_value": 0.008766884433741337, "biggest_recent_change": 0.44763985085441504},
{"total_number_of_episodes": 4890, "number_of_timesteps": 537239, "per_episode_reward": -150.16, "episode_reward_trend_value": 0.005672452130931699, "biggest_recent_change": 0.4399651187905249},
{"total_number_of_episodes": 4900, "number_of_timesteps": 538560, "per_episode_reward": -150.32, "episode_reward_trend_value": 0.008257687102324478, "biggest_recent_change": 0.4399651187905249},
{"total_number_of_episodes": 4912, "number_of_timesteps": 539925, "per_episode_reward": -150.3, "episode_reward_trend_value": 0.0036463467252082814, "biggest_recent_change": 0.18366227671717184},
{"total_number_of_episodes": 4922, "number_of_timesteps": 540684, "per_episode_reward": -149.97, "episode_reward_trend_value": 0.0067249760353358095, "biggest_recent_change": 0.32507557426140465},
{"total_number_of_episodes": 4932, "number_of_timesteps": 541727, "per_episode_reward": -149.72, "episode_reward_trend_value": 0.008660754675295203, "biggest_recent_change": 0.32507557426140465},
{"total_number_of_episodes": 4942, "number_of_timesteps": 542791, "per_episode_reward": -149.64, "episode_reward_trend_value": 0.008856781063605644, "biggest_recent_change": 0.32507557426140465},
{"total_number_of_episodes": 4952, "number_of_timesteps": 544007, "per_episode_reward": -149.94, "episode_reward_trend_value": 0.007559423268493346, "biggest_recent_change": 0.32507557426140465},
{"total_number_of_episodes": 4962, "number_of_timesteps": 545094, "per_episode_reward": -149.92, "episode_reward_trend_value": 0.006319858149791774, "biggest_recent_change": 0.32507557426140465},
{"total_number_of_episodes": 4972, "number_of_timesteps": 546408, "per_episode_reward": -149.9, "episode_reward_trend_value": 0.004714593102204074, "biggest_recent_change": 0.32507557426140465},
{"total_number_of_episodes": 4983, "number_of_timesteps": 547828, "per_episode_reward": -149.9, "episode_reward_trend_value": 0.0028352492844091, "biggest_recent_change": 0.32507557426140465},
{"total_number_of_episodes": 4994, "number_of_timesteps": 549215, "per_episode_reward": -149.72, "episode_reward_trend_value": 0.006692164690735719, "biggest_recent_change": 0.32507557426140465},
{"total_number_of_episodes": 5004, "number_of_timesteps": 550225, "per_episode_reward": -149.57, "episode_reward_trend_value": 0.008116823967063485, "biggest_recent_change": 0.32507557426140465},
{"total_number_of_episodes": 5014, "number_of_timesteps": 551350, "per_episode_reward": -149.47, "episode_reward_trend_value": 0.005543990377993345, "biggest_recent_change": 0.3004244782772787},
{"total_number_of_episodes": 5025, "number_of_timesteps": 552744, "per_episode_reward": -149.4, "episode_reward_trend_value": 0.003550040599345531, "biggest_recent_change": 0.3004244782772787},
{"total_number_of_episodes": 5035, "number_of_timesteps": 553763, "per_episode_reward": -149.2, "episode_reward_trend_value": 0.00486318119673178, "biggest_recent_change": 0.3004244782772787},
{"total_number_of_episodes": 5045, "number_of_timesteps": 555009, "per_episode_reward": -149.34, "episode_reward_trend_value": 0.006693949040962049, "biggest_recent_change": 0.1966806121968716},
{"total_number_of_episodes": 5057, "number_of_timesteps": 556395, "per_episode_reward": -149.34, "episode_reward_trend_value": 0.006519282456294996, "biggest_recent_change": 0.1966806121968716},
{"total_number_of_episodes": 5068, "number_of_timesteps": 557470, "per_episode_reward": -149.05, "episode_reward_trend_value": 0.009493877550135544, "biggest_recent_change": 0.28939017795593713},
{"total_number_of_episodes": 5078, "number_of_timesteps": 558507, "per_episode_reward": -149.23, "episode_reward_trend_value": 0.0074936188824295865, "biggest_recent_change": 0.28939017795593713},
{"total_number_of_episodes": 5088, "number_of_timesteps": 559594, "per_episode_reward": -149.05, "episode_reward_trend_value": 0.007448201085719891, "biggest_recent_change": 0.28939017795593713},
{"total_number_of_episodes": 5099, "number_of_timesteps": 560947, "per_episode_reward": -148.77, "episode_reward_trend_value": 0.008850741632125885, "biggest_recent_change": 0.28939017795593713},
{"total_number_of_episodes": 5109, "number_of_timesteps": 561978, "per_episode_reward": -148.64, "episode_reward_trend_value": 0.009245574603514545, "biggest_recent_change": 0.28939017795593713},
{"total_number_of_episodes": 5119, "number_of_timesteps": 562955, "per_episode_reward": -148.51, "episode_reward_trend_value": 0.009872216521926526, "biggest_recent_change": 0.28939017795593713},
{"total_number_of_episodes": 5129, "number_of_timesteps": 564157, "per_episode_reward": -148.42, "episode_reward_trend_value": 0.008670867096735594, "biggest_recent_change": 0.28939017795593713},
{"total_number_of_episodes": 5140, "number_of_timesteps": 565344, "per_episode_reward": -147.92, "episode_reward_trend_value": 0.015799588522999543, "biggest_recent_change": 0.5059295560672012},
{"total_number_of_episodes": 5150, "number_of_timesteps": 566556, "per_episode_reward": -147.75, "episode_reward_trend_value": 0.017594623622672303, "biggest_recent_change": 0.5059295560672012},
{"total_number_of_episodes": 5160, "number_of_timesteps": 567755, "per_episode_reward": -148.03, "episode_reward_trend_value": 0.011283018526643849, "biggest_recent_change": 0.5059295560672012},
{"total_number_of_episodes": 5171, "number_of_timesteps": 569065, "per_episode_reward": -148.2, "episode_reward_trend_value": 0.011408523792992595, "biggest_recent_change": 0.5059295560672012},
{"total_number_of_episodes": 5182, "number_of_timesteps": 570281, "per_episode_reward": -148.1, "episode_reward_trend_value": 0.010563676113192678, "biggest_recent_change": 0.5059295560672012},
{"total_number_of_episodes": 5192, "number_of_timesteps": 571364, "per_episode_reward": -147.96, "episode_reward_trend_value": 0.008977764690692742, "biggest_recent_change": 0.5059295560672012},
{"total_number_of_episodes": 5203, "number_of_timesteps": 572872, "per_episode_reward": -147.68, "episode_reward_trend_value": 0.010658154424614787, "biggest_recent_change": 0.5059295560672012},
{"total_number_of_episodes": 5213, "number_of_timesteps": 573808, "per_episode_reward": -147.91, "episode_reward_trend_value": 0.006697963341000939, "biggest_recent_change": 0.5059295560672012},
{"total_number_of_episodes": 5223, "number_of_timesteps": 575026, "per_episode_reward": -148.12, "episode_reward_trend_value": 0.0033403628250201537, "biggest_recent_change": 0.5059295560672012},
{"total_number_of_episodes": 5233, "number_of_timesteps": 576141, "per_episode_reward": -148.34, "episode_reward_trend_value": -0.004690486729763974, "biggest_recent_change": 0.2802905947230556},
{"total_number_of_episodes": 5243, "number_of_timesteps": 577418, "per_episode_reward": -148.76, "episode_reward_trend_value": -0.011216910089178907, "biggest_recent_change": 0.4253028561381882},
{"total_number_of_episodes": 5254, "number_of_timesteps": 578464, "per_episode_reward": -148.51, "episode_reward_trend_value": -0.005336207083277284, "biggest_recent_change": 0.4253028561381882},
{"total_number_of_episodes": 5264, "number_of_timesteps": 579470, "per_episode_reward": -148.43, "episode_reward_trend_value": -0.002502723277195666, "biggest_recent_change": 0.4253028561381882},
{"total_number_of_episodes": 5274, "number_of_timesteps": 580769, "per_episode_reward": -148.26, "episode_reward_trend_value": -0.0017758795658933321, "biggest_recent_change": 0.4253028561381882},
{"total_number_of_episodes": 5284, "number_of_timesteps": 581732, "per_episode_reward": -148.52, "episode_reward_trend_value": -0.006254239729541193, "biggest_recent_change": 0.4253028561381882},
{"total_number_of_episodes": 5294, "number_of_timesteps": 582902, "per_episode_reward": -148.29, "episode_reward_trend_value": -0.006766465955715261, "biggest_recent_change": 0.4253028561381882},
{"total_number_of_episodes": 5304, "number_of_timesteps": 584153, "per_episode_reward": -147.97, "episode_reward_trend_value": -0.0006965135819942563, "biggest_recent_change": 0.4253028561381882},
{"total_number_of_episodes": 5314, "number_of_timesteps": 585328, "per_episode_reward": -147.81, "episode_reward_trend_value": 0.0034951637085517484, "biggest_recent_change": 0.4253028561381882},
{"total_number_of_episodes": 5324, "number_of_timesteps": 586370, "per_episode_reward": -147.68, "episode_reward_trend_value": 0.0073386052734491615, "biggest_recent_change": 0.4253028561381882},
{"total_number_of_episodes": 5334, "number_of_timesteps": 587389, "per_episode_reward": -147.6, "episode_reward_trend_value": 0.012959649019741606, "biggest_recent_change": 0.3189925104219924},
{"total_number_of_episodes": 5344, "number_of_timesteps": 588254, "per_episode_reward": -146.84, "episode_reward_trend_value": 0.018569491067720555, "biggest_recent_change": 0.7554947741626279},
{"total_number_of_episodes": 5354, "number_of_timesteps": 589223, "per_episode_reward": -146.81, "episode_reward_trend_value": 0.018003085972997546, "biggest_recent_change": 0.7554947741626279},
{"total_number_of_episodes": 5364, "number_of_timesteps": 590568, "per_episode_reward": -146.79, "episode_reward_trend_value": 0.016326091719635213, "biggest_recent_change": 0.7554947741626279},
{"total_number_of_episodes": 5374, "number_of_timesteps": 591877, "per_episode_reward": -147.16, "episode_reward_trend_value": 0.015150345871459572, "biggest_recent_change": 0.7554947741626279},
{"total_number_of_episodes": 5384, "number_of_timesteps": 592963, "per_episode_reward": -146.93, "episode_reward_trend_value": 0.015070862891278758, "biggest_recent_change": 0.7554947741626279},
{"total_number_of_episodes": 5396, "number_of_timesteps": 594439, "per_episode_reward": -147.09, "episode_reward_trend_value": 0.009811446955631216, "biggest_recent_change": 0.7554947741626279},
{"total_number_of_episodes": 5406, "number_of_timesteps": 595652, "per_episode_reward": -147.16, "episode_reward_trend_value": 0.0071604434756153525, "biggest_recent_change": 0.7554947741626279},
{"total_number_of_episodes": 5416, "number_of_timesteps": 596553, "per_episode_reward": -147.13, "episode_reward_trend_value": 0.006119913955778758, "biggest_recent_change": 0.7554947741626279},
{"total_number_of_episodes": 5427, "number_of_timesteps": 597571, "per_episode_reward": -146.86, "episode_reward_trend_value": 0.008138658406145144, "biggest_recent_change": 0.7554947741626279},
{"total_number_of_episodes": 5437, "number_of_timesteps": 598764, "per_episode_reward": -147.18, "episode_reward_trend_value": -0.0038092234064925554, "biggest_recent_change": 0.3722091001930039},
{"total_number_of_episodes": 5447, "number_of_timesteps": 599844, "per_episode_reward": -147.14, "episode_reward_trend_value": -0.0037532077537295863, "biggest_recent_change": 0.3722091001930039},
{"total_number_of_episodes": 5458, "number_of_timesteps": 600923, "per_episode_reward": -146.7, "episode_reward_trend_value": 0.0010315182458242589, "biggest_recent_change": 0.4490987800859898},
{"total_number_of_episodes": 5469, "number_of_timesteps": 602190, "per_episode_reward": -146.68, "episode_reward_trend_value": 0.00532428510329876, "biggest_recent_change": 0.4490987800859898},
{"total_number_of_episodes": 5479, "number_of_timesteps": 603244, "per_episode_reward": -146.45, "episode_reward_trend_value": 0.005403647372909543, "biggest_recent_change": 0.4490987800859898},
{"total_number_of_episodes": 5489, "number_of_timesteps": 604583, "per_episode_reward": -146.4, "episode_reward_trend_value": 0.007625129278190456, "biggest_recent_change": 0.4490987800859898},
{"total_number_of_episodes": 5499, "number_of_timesteps": 605693, "per_episode_reward": -146.41, "episode_reward_trend_value": 0.008315344076327039, "biggest_recent_change": 0.4490987800859898},
{"total_number_of_episodes": 5510, "number_of_timesteps": 607027, "per_episode_reward": -146.39, "episode_reward_trend_value": 0.00820728446816127, "biggest_recent_change": 0.4490987800859898},
{"total_number_of_episodes": 5520, "number_of_timesteps": 608363, "per_episode_reward": -146.44, "episode_reward_trend_value": 0.0047369861150722645, "biggest_recent_change": 0.4490987800859898},
{"total_number_of_episodes": 5530, "number_of_timesteps": 609669, "per_episode_reward": -146.55, "episode_reward_trend_value": 0.007050341734895621, "biggest_recent_change": 0.4490987800859898},
{"total_number_of_episodes": 5540, "number_of_timesteps": 610847, "per_episode_reward": -146.34, "episode_reward_trend_value": 0.008906917181668127, "biggest_recent_change": 0.4490987800859898},
{"total_number_of_episodes": 5550, "number_of_timesteps": 611694, "per_episode_reward": -146.01, "episode_reward_trend_value": 0.0075664570451550615, "biggest_recent_change": 0.32845736779981394},
{"total_number_of_episodes": 5560, "number_of_timesteps": 612770, "per_episode_reward": -145.94, "episode_reward_trend_value": 0.008235352171991256, "biggest_recent_change": 0.32845736779981394},
{"total_number_of_episodes": 5570, "number_of_timesteps": 614006, "per_episode_reward": -145.97, "episode_reward_trend_value": 0.005305833928251661, "biggest_recent_change": 0.32845736779981394},
{"total_number_of_episodes": 5580, "number_of_timesteps": 615477, "per_episode_reward": -145.96, "episode_reward_trend_value": 0.0048663403535869065, "biggest_recent_change": 0.32845736779981394},
{"total_number_of_episodes": 5590, "number_of_timesteps": 616697, "per_episode_reward": -146.1, "episode_reward_trend_value": 0.0035343960468758777, "biggest_recent_change": 0.32845736779981394},
{"total_number_of_episodes": 5600, "number_of_timesteps": 617916, "per_episode_reward": -146.05, "episode_reward_trend_value": 0.0037408758437689157, "biggest_recent_change": 0.32845736779981394},
{"total_number_of_episodes": 5610, "number_of_timesteps": 618964, "per_episode_reward": -145.96, "episode_reward_trend_value": 0.005284681382427594, "biggest_recent_change": 0.32845736779981394},
{"total_number_of_episodes": 5620, "number_of_timesteps": 619927, "per_episode_reward": -145.69, "episode_reward_trend_value": 0.009534463399082762, "biggest_recent_change": 0.32845736779981394},
{"total_number_of_episodes": 5631, "number_of_timesteps": 621391, "per_episode_reward": -145.71, "episode_reward_trend_value": 0.0070801909845073395, "biggest_recent_change": 0.32845736779981394},
{"total_number_of_episodes": 5641, "number_of_timesteps": 622541, "per_episode_reward": -145.42, "episode_reward_trend_value": 0.006611097765309005, "biggest_recent_change": 0.28623897807196386},
{"total_number_of_episodes": 5652, "number_of_timesteps": 623685, "per_episode_reward": -145.02, "episode_reward_trend_value": 0.010268632620304174, "biggest_recent_change": 0.4035186153445238},
{"total_number_of_episodes": 5662, "number_of_timesteps": 624703, "per_episode_reward": -145.25, "episode_reward_trend_value": 0.008041261553379463, "biggest_recent_change": 0.4035186153445238},
{"total_number_of_episodes": 5673, "number_of_timesteps": 626160, "per_episode_reward": -145.79, "episode_reward_trend_value": 0.0018898744644259423, "biggest_recent_change": 0.5476008120366487},
{"total_number_of_episodes": 5683, "number_of_timesteps": 627344, "per_episode_reward": -145.71, "episode_reward_trend_value": 0.004287824832853618, "biggest_recent_change": 0.5476008120366487},
{"total_number_of_episodes": 5693, "number_of_timesteps": 628562, "per_episode_reward": -145.83, "episode_reward_trend_value": 0.002446253509699482, "biggest_recent_change": 0.5476008120366487},
{"total_number_of_episodes": 5704, "number_of_timesteps": 629943, "per_episode_reward": -146.35, "episode_reward_trend_value": -0.0043494948456943424, "biggest_recent_change": 0.5476008120366487},
{"total_number_of_episodes": 5715, "number_of_timesteps": 631239, "per_episode_reward": -146.18, "episode_reward_trend_value": -0.005470796138090527, "biggest_recent_change": 0.5476008120366487},
{"total_number_of_episodes": 5725, "number_of_timesteps": 632126, "per_episode_reward": -145.75, "episode_reward_trend_value": -0.00047391853521156055, "biggest_recent_change": 0.5476008120366487},
{"total_number_of_episodes": 5735, "number_of_timesteps": 633273, "per_episode_reward": -145.21, "episode_reward_trend_value": 0.0023235561745675822, "biggest_recent_change": 0.5476008120366487},
{"total_number_of_episodes": 5745, "number_of_timesteps": 634126, "per_episode_reward": -145.02, "episode_reward_trend_value": -0.00010327047069943598, "biggest_recent_change": 0.5476008120366487},
{"total_number_of_episodes": 5755, "number_of_timesteps": 635031, "per_episode_reward": -144.92, "episode_reward_trend_value": 0.003649598343957905, "biggest_recent_change": 0.5476008120366487},
{"total_number_of_episodes": 5765, "number_of_timesteps": 636381, "per_episode_reward": -144.92, "episode_reward_trend_value": 0.009712872139280964, "biggest_recent_change": 0.5380117019520867},
{"total_number_of_episodes": 5775, "number_of_timesteps": 637796, "per_episode_reward": -145.06, "episode_reward_trend_value": 0.007252179156671762, "biggest_recent_change": 0.5380117019520867},
{"total_number_of_episodes": 5785, "number_of_timesteps": 638636, "per_episode_reward": -144.87, "episode_reward_trend_value": 0.010679517368685904, "biggest_recent_change": 0.5380117019520867},
{"total_number_of_episodes": 5796, "number_of_timesteps": 639531, "per_episode_reward": -144.78, "episode_reward_trend_value": 0.0174539687739143, "biggest_recent_change": 0.5380117019520867},
{"total_number_of_episodes": 5806, "number_of_timesteps": 640799, "per_episode_reward": -144.84, "episode_reward_trend_value": 0.014938652330506999, "biggest_recent_change": 0.5380117019520867},
{"total_number_of_episodes": 5816, "number_of_timesteps": 642124, "per_episode_reward": -144.84, "episode_reward_trend_value": 0.010140858951071625, "biggest_recent_change": 0.5380117019520867},
{"total_number_of_episodes": 5826, "number_of_timesteps": 643607, "per_episode_reward": -145.04, "episode_reward_trend_value": 0.001896891321670877, "biggest_recent_change": 0.2039453846939807},
{"total_number_of_episodes": 5838, "number_of_timesteps": 644987, "per_episode_reward": -145.44, "episode_reward_trend_value": -0.004666135464559792, "biggest_recent_change": 0.40556819349026796},
{"total_number_of_episodes": 5848, "number_of_timesteps": 646270, "per_episode_reward": -145.32, "episode_reward_trend_value": -0.004473919284218494, "biggest_recent_change": 0.40556819349026796},
{"total_number_of_episodes": 5858, "number_of_timesteps": 647563, "per_episode_reward": -145.29, "episode_reward_trend_value": -0.004097308587379997, "biggest_recent_change": 0.40556819349026796},
{"total_number_of_episodes": 5868, "number_of_timesteps": 648719, "per_episode_reward": -145.17, "episode_reward_trend_value": -0.0012722423808254589, "biggest_recent_change": 0.40556819349026796},
{"total_number_of_episodes": 5879, "number_of_timesteps": 650096, "per_episode_reward": -145.22, "episode_reward_trend_value": -0.003889716679098064, "biggest_recent_change": 0.40556819349026796},
{"total_number_of_episodes": 5889, "number_of_timesteps": 651314, "per_episode_reward": -145.35, "episode_reward_trend_value": -0.006309421311162408, "biggest_recent_change": 0.40556819349026796},
{"total_number_of_episodes": 5899, "number_of_timesteps": 652526, "per_episode_reward": -145.29, "episode_reward_trend_value": -0.0049787343929715965, "biggest_recent_change": 0.40556819349026796},
{"total_number_of_episodes": 5909, "number_of_timesteps": 653700, "per_episode_reward": -145.21, "episode_reward_trend_value": -0.004142670434143269, "biggest_recent_change": 0.40556819349026796},
{"total_number_of_episodes": 5919, "number_of_timesteps": 654901, "per_episode_reward": -144.91, "episode_reward_trend_value": 0.0014113683607080122, "biggest_recent_change": 0.40556819349026796},
{"total_number_of_episodes": 5929, "number_of_timesteps": 656033, "per_episode_reward": -145.03, "episode_reward_trend_value": 0.00456194792513587, "biggest_recent_change": 0.29591810684263464},
{"total_number_of_episodes": 5939, "number_of_timesteps": 657357, "per_episode_reward": -145.46, "episode_reward_trend_value": -0.0015044544886276552, "biggest_recent_change": 0.4208592352325411},
{"total_number_of_episodes": 5949, "number_of_timesteps": 658472, "per_episode_reward": -145.22, "episode_reward_trend_value": 0.0007728251834666683, "biggest_recent_change": 0.4208592352325411},
{"total_number_of_episodes": 5960, "number_of_timesteps": 659644, "per_episode_reward": -145.14, "episode_reward_trend_value": 0.00031986937076706253, "biggest_recent_change": 0.4208592352325411},
{"total_number_of_episodes": 5970, "number_of_timesteps": 660915, "per_episode_reward": -144.83, "episode_reward_trend_value": 0.004329714345656851, "biggest_recent_change": 0.4208592352325411},
{"total_number_of_episodes": 5981, "number_of_timesteps": 661986, "per_episode_reward": -144.96, "episode_reward_trend_value": 0.004355182016226422, "biggest_recent_change": 0.4208592352325411},
{"total_number_of_episodes": 5991, "number_of_timesteps": 663216, "per_episode_reward": -144.76, "episode_reward_trend_value": 0.005896202071258788, "biggest_recent_change": 0.4208592352325411},
{"total_number_of_episodes": 6001, "number_of_timesteps": 664289, "per_episode_reward": -145.0, "episode_reward_trend_value": 0.0023676339486358856, "biggest_recent_change": 0.4208592352325411},
{"total_number_of_episodes": 6011, "number_of_timesteps": 665340, "per_episode_reward": -144.7, "episode_reward_trend_value": 0.0023530995139992685, "biggest_recent_change": 0.4208592352325411},
{"total_number_of_episodes": 6021, "number_of_timesteps": 666260, "per_episode_reward": -144.64, "episode_reward_trend_value": 0.004392248192203851, "biggest_recent_change": 0.4208592352325411},
{"total_number_of_episodes": 6032, "number_of_timesteps": 667448, "per_episode_reward": -144.46, "episode_reward_trend_value": 0.01111183421128285, "biggest_recent_change": 0.31230537807050496},
{"total_number_of_episodes": 6042, "number_of_timesteps": 668392, "per_episode_reward": -144.26, "episode_reward_trend_value": 0.010602502938480838, "biggest_recent_change": 0.31230537807050496},
{"total_number_of_episodes": 6053, "number_of_timesteps": 669549, "per_episode_reward": -144.25, "episode_reward_trend_value": 0.009892487089323115, "biggest_recent_change": 0.31230537807050496},
{"total_number_of_episodes": 6063, "number_of_timesteps": 670583, "per_episode_reward": -144.34, "episode_reward_trend_value": 0.005457760670680361, "biggest_recent_change": 0.2946100077253391},
{"total_number_of_episodes": 6073, "number_of_timesteps": 671491, "per_episode_reward": -144.26, "episode_reward_trend_value": 0.007750475818887518, "biggest_recent_change": 0.2946100077253391},
{"total_number_of_episodes": 6083, "number_of_timesteps": 673104, "per_episode_reward": -144.23, "episode_reward_trend_value": 0.0058566102840289765, "biggest_recent_change": 0.2946100077253391},
{"total_number_of_episodes": 6093, "number_of_timesteps": 674291, "per_episode_reward": -144.21, "episode_reward_trend_value": 0.008710201633347008, "biggest_recent_change": 0.2946100077253391},
{"total_number_of_episodes": 6103, "number_of_timesteps": 675607, "per_episode_reward": -144.2, "episode_reward_trend_value": 0.005562522751820135, "biggest_recent_change": 0.1911041481941993},
{"total_number_of_episodes": 6113, "number_of_timesteps": 676994, "per_episode_reward": -144.02, "episode_reward_trend_value": 0.00689534281095108, "biggest_recent_change": 0.1911041481941993},
{"total_number_of_episodes": 6123, "number_of_timesteps": 678745, "per_episode_reward": -144.22, "episode_reward_trend_value": 0.0026104000288133494, "biggest_recent_change": 0.20174134390782683},
{"total_number_of_episodes": 6134, "number_of_timesteps": 679845, "per_episode_reward": -144.0, "episode_reward_trend_value": 0.0029496635293058816, "biggest_recent_change": 0.2216378632385272},
{"total_number_of_episodes": 6144, "number_of_timesteps": 681033, "per_episode_reward": -144.13, "episode_reward_trend_value": 0.0013868369086654612, "biggest_recent_change": 0.2216378632385272},
{"total_number_of_episodes": 6154, "number_of_timesteps": 682265, "per_episode_reward": -144.09, "episode_reward_trend_value": 0.002738232311099548, "biggest_recent_change": 0.2216378632385272},
{"total_number_of_episodes": 6165, "number_of_timesteps": 683513, "per_episode_reward": -143.98, "episode_reward_trend_value": 0.0031703279188298613, "biggest_recent_change": 0.2216378632385272},
{"total_number_of_episodes": 6175, "number_of_timesteps": 684596, "per_episode_reward": -143.97, "episode_reward_trend_value": 0.0028918945278475247, "biggest_recent_change": 0.2216378632385272},
{"total_number_of_episodes": 6185, "number_of_timesteps": 685694, "per_episode_reward": -143.98, "episode_reward_trend_value": 0.0025839723245768354, "biggest_recent_change": 0.2216378632385272},
{"total_number_of_episodes": 6195, "number_of_timesteps": 686803, "per_episode_reward": -144.05, "episode_reward_trend_value": 0.0016386809177829618, "biggest_recent_change": 0.2216378632385272},

{"total_number_of_episodes": 6206, "number_of_timesteps": 687985, "per_episode_reward": -144.09, "episode_reward_trend_value": -0.0007409896088315944, "biggest_recent_change": 0.2216378632385272},
{"total_number_of_episodes": 6216, "number_of_timesteps": 689116, "per_episode_reward": -144.24, "episode_reward_trend_value": -0.00019366375592539954, "biggest_recent_change": 0.2216378632385272},
{"total_number_of_episodes": 6226, "number_of_timesteps": 690213, "per_episode_reward": -144.28, "episode_reward_trend_value": -0.003075123021302299, "biggest_recent_change": 0.1524820171462693},
{"total_number_of_episodes": 6236, "number_of_timesteps": 691170, "per_episode_reward": -144.13, "episode_reward_trend_value": -5.206590350199905e-05, "biggest_recent_change": 0.1524820171462693},
{"total_number_of_episodes": 6246, "number_of_timesteps": 692652, "per_episode_reward": -144.53, "episode_reward_trend_value": -0.004897581162635826, "biggest_recent_change": 0.4012907867103195},
{"total_number_of_episodes": 6257, "number_of_timesteps": 694349, "per_episode_reward": -144.56, "episode_reward_trend_value": -0.006510220821202653, "biggest_recent_change": 0.4012907867103195},
{"total_number_of_episodes": 6268, "number_of_timesteps": 695610, "per_episode_reward": -144.55, "episode_reward_trend_value": -0.0064859625877059235, "biggest_recent_change": 0.4012907867103195},
{"total_number_of_episodes": 6278, "number_of_timesteps": 696686, "per_episode_reward": -144.54, "episode_reward_trend_value": -0.0062397010203937954, "biggest_recent_change": 0.4012907867103195},
{"total_number_of_episodes": 6288, "number_of_timesteps": 697874, "per_episode_reward": -144.62, "episode_reward_trend_value": -0.00629741501801896, "biggest_recent_change": 0.4012907867103195},
{"total_number_of_episodes": 6298, "number_of_timesteps": 699155, "per_episode_reward": -144.84, "episode_reward_trend_value": -0.008415187788735541, "biggest_recent_change": 0.4012907867103195},
{"total_number_of_episodes": 6308, "number_of_timesteps": 700399, "per_episode_reward": -144.65, "episode_reward_trend_value": -0.004603443911335287, "biggest_recent_change": 0.4012907867103195},
{"total_number_of_episodes": 6319, "number_of_timesteps": 701715, "per_episode_reward": -144.64, "episode_reward_trend_value": -0.0040562868681253885, "biggest_recent_change": 0.4012907867103195},
{"total_number_of_episodes": 6329, "number_of_timesteps": 702689, "per_episode_reward": -144.61, "episode_reward_trend_value": -0.005328189395718318, "biggest_recent_change": 0.4012907867103195},
{"total_number_of_episodes": 6340, "number_of_timesteps": 704009, "per_episode_reward": -144.72, "episode_reward_trend_value": -0.0020261269297025012, "biggest_recent_change": 0.2233087430913656},
{"total_number_of_episodes": 6351, "number_of_timesteps": 705283, "per_episode_reward": -144.63, "episode_reward_trend_value": -0.0007797598672011772, "biggest_recent_change": 0.2233087430913656},
{"total_number_of_episodes": 6362, "number_of_timesteps": 706434, "per_episode_reward": -144.47, "episode_reward_trend_value": 0.0009144641820742865, "biggest_recent_change": 0.2233087430913656},
{"total_number_of_episodes": 6372, "number_of_timesteps": 707544, "per_episode_reward": -144.46, "episode_reward_trend_value": 0.0008678149374664676, "biggest_recent_change": 0.2233087430913656},
{"total_number_of_episodes": 6383, "number_of_timesteps": 708690, "per_episode_reward": -144.46, "episode_reward_trend_value": 0.0017450546931308333, "biggest_recent_change": 0.2233087430913656},
{"total_number_of_episodes": 6393, "number_of_timesteps": 709973, "per_episode_reward": -144.52, "episode_reward_trend_value": 0.0035790069775253467, "biggest_recent_change": 0.1905749318197536},
{"total_number_of_episodes": 6406, "number_of_timesteps": 711275, "per_episode_reward": -144.29, "episode_reward_trend_value": 0.00404405437997784, "biggest_recent_change": 0.232429198040478},
{"total_number_of_episodes": 6416, "number_of_timesteps": 712183, "per_episode_reward": -144.06, "episode_reward_trend_value": 0.006464654323531249, "biggest_recent_change": 0.232429198040478},
{"total_number_of_episodes": 6427, "number_of_timesteps": 713447, "per_episode_reward": -144.17, "episode_reward_trend_value": 0.00488961070019924, "biggest_recent_change": 0.232429198040478},
{"total_number_of_episodes": 6438, "number_of_timesteps": 714905, "per_episode_reward": -144.26, "episode_reward_trend_value": 0.00504714396951758, "biggest_recent_change": 0.232429198040478},

{"total_number_of_episodes": 6448, "number_of_timesteps": 716188, "per_episode_reward": -144.38, "episode_reward_trend_value": 0.002797418307984698, "biggest_recent_change": 0.232429198040478},
{"total_number_of_episodes": 6458, "number_of_timesteps": 717497, "per_episode_reward": -144.45, "episode_reward_trend_value": 0.00022058274437913245, "biggest_recent_change": 0.232429198040478},
{"total_number_of_episodes": 6468, "number_of_timesteps": 718814, "per_episode_reward": -144.48, "episode_reward_trend_value": -0.00016848420660677574, "biggest_recent_change": 0.232429198040478},
{"total_number_of_episodes": 6478, "number_of_timesteps": 719605, "per_episode_reward": -144.24, "episode_reward_trend_value": 0.0024336528419379674, "biggest_recent_change": 0.23419233436902687},
{"total_number_of_episodes": 6489, "number_of_timesteps": 720608, "per_episode_reward": -144.06, "episode_reward_trend_value": 0.005139324816263663, "biggest_recent_change": 0.23419233436902687},
{"total_number_of_episodes": 6500, "number_of_timesteps": 721629, "per_episode_reward": -143.99, "episode_reward_trend_value": 0.0032901616660369532, "biggest_recent_change": 0.23419233436902687},
{"total_number_of_episodes": 6510, "number_of_timesteps": 722717, "per_episode_reward": -144.27, "episode_reward_trend_value": -0.002339964837172993, "biggest_recent_change": 0.2773067271255911},
{"total_number_of_episodes": 6521, "number_of_timesteps": 724005, "per_episode_reward": -144.26, "episode_reward_trend_value": -0.0009485474488352943, "biggest_recent_change": 0.2773067271255911},
{"total_number_of_episodes": 6531, "number_of_timesteps": 725132, "per_episode_reward": -144.11, "episode_reward_trend_value": 0.0016715730835124357, "biggest_recent_change": 0.2773067271255911},
{"total_number_of_episodes": 6541, "number_of_timesteps": 726401, "per_episode_reward": -144.22, "episode_reward_trend_value": 0.0017586452048542849, "biggest_recent_change": 0.2773067271255911},
{"total_number_of_episodes": 6551, "number_of_timesteps": 727534, "per_episode_reward": -143.93, "episode_reward_trend_value": 0.005739265549202817, "biggest_recent_change": 0.28752296206675965},
{"total_number_of_episodes": 6561, "number_of_timesteps": 728689, "per_episode_reward": -143.9, "episode_reward_trend_value": 0.006447465125530824, "biggest_recent_change": 0.28752296206675965},
{"total_number_of_episodes": 6574, "number_of_timesteps": 729930, "per_episode_reward": -144.1, "episode_reward_trend_value": 0.0016352478883413194, "biggest_recent_change": 0.28752296206675965},
{"total_number_of_episodes": 6584, "number_of_timesteps": 731127, "per_episode_reward": -144.08, "episode_reward_trend_value": -0.00020322842304096867, "biggest_recent_change": 0.28752296206675965},
{"total_number_of_episodes": 6594, "number_of_timesteps": 731855, "per_episode_reward": -143.75, "episode_reward_trend_value": 0.0027108004353607385, "biggest_recent_change": 0.3282671117762277},
{"total_number_of_episodes": 6604, "number_of_timesteps": 732730, "per_episode_reward": -143.49, "episode_reward_trend_value": 0.00862591673637433, "biggest_recent_change": 0.3282671117762277},
{"total_number_of_episodes": 6615, "number_of_timesteps": 734082, "per_episode_reward": -143.73, "episode_reward_trend_value": 0.005817470038631553, "biggest_recent_change": 0.3282671117762277},
{"total_number_of_episodes": 6626, "number_of_timesteps": 735428, "per_episode_reward": -143.82, "episode_reward_trend_value": 0.003192267801363692, "biggest_recent_change": 0.3282671117762277},
{"total_number_of_episodes": 6636, "number_of_timesteps": 736606, "per_episode_reward": -143.75, "episode_reward_trend_value": 0.005205592321120081, "biggest_recent_change": 0.3282671117762277},
{"total_number_of_episodes": 6646, "number_of_timesteps": 737834, "per_episode_reward": -144.02, "episode_reward_trend_value": -0.000979392049516529, "biggest_recent_change": 0.3282671117762277},
{"total_number_of_episodes": 6656, "number_of_timesteps": 739077, "per_episode_reward": -143.95, "episode_reward_trend_value": -0.0005931589239057505, "biggest_recent_change": 0.3282671117762277},
{"total_number_of_episodes": 6667, "number_of_timesteps": 740423, "per_episode_reward": -144.2, "episode_reward_trend_value": -0.0011197237136251993, "biggest_recent_change": 0.3282671117762277},
{"total_number_of_episodes": 6678, "number_of_timesteps": 741761, "per_episode_reward": -144.22, "episode_reward_trend_value": -0.001598774969502554, "biggest_recent_change": 0.3282671117762277},
{"total_number_of_episodes": 6688, "number_of_timesteps": 742826, "per_episode_reward": -144.08, "episode_reward_trend_value": -0.0036514609773184424, "biggest_recent_change": 0.26912563129053524},
{"total_number_of_episodes": 6699, "number_of_timesteps": 744064, "per_episode_reward": -143.82, "episode_reward_trend_value": -0.0036310217334946373, "biggest_recent_change": 0.26912563129053524},
{"total_number_of_episodes": 6709, "number_of_timesteps": 745271, "per_episode_reward": -143.35, "episode_reward_trend_value": 0.004266896225851408, "biggest_recent_change": 0.46969734806967267},
{"total_number_of_episodes": 6719, "number_of_timesteps": 746615, "per_episode_reward": -143.31, "episode_reward_trend_value": 0.005755713463750251, "biggest_recent_change": 0.46969734806967267},
{"total_number_of_episodes": 6729, "number_of_timesteps": 747650, "per_episode_reward": -143.34, "episode_reward_trend_value": 0.0046537220715098075, "biggest_recent_change": 0.46969734806967267},
{"total_number_of_episodes": 6739, "number_of_timesteps": 748575, "per_episode_reward": -143.3, "episode_reward_trend_value": 0.008034709231287707, "biggest_recent_change": 0.46969734806967267},
{"total_number_of_episodes": 6749, "number_of_timesteps": 749993, "per_episode_reward": -143.36, "episode_reward_trend_value": 0.006511607387388886, "biggest_recent_change": 0.46969734806967267},
{"total_number_of_episodes": 6759, "number_of_timesteps": 750852, "per_episode_reward": -143.05, "episode_reward_trend_value": 0.01269596369021681, "biggest_recent_change": 0.46969734806967267},
{"total_number_of_episodes": 6769, "number_of_timesteps": 752135, "per_episode_reward": -143.29, "episode_reward_trend_value": 0.010294967834206166, "biggest_recent_change": 0.46969734806967267},
{"total_number_of_episodes": 6779, "number_of_timesteps": 753458, "per_episode_reward": -143.41, "episode_reward_trend_value": 0.007422649074261914, "biggest_recent_change": 0.46969734806967267},
{"total_number_of_episodes": 6789, "number_of_timesteps": 754837, "per_episode_reward": -143.43, "episode_reward_trend_value": 0.004305119197015807, "biggest_recent_change": 0.46969734806967267},
{"total_number_of_episodes": 6799, "number_of_timesteps": 756179, "per_episode_reward": -143.46, "episode_reward_trend_value": -0.0012430796828466681, "biggest_recent_change": 0.3102940192017343},
{"total_number_of_episodes": 6809, "number_of_timesteps": 757203, "per_episode_reward": -143.52, "episode_reward_trend_value": -0.0023893811392427878, "biggest_recent_change": 0.3102940192017343},
{"total_number_of_episodes": 6819, "number_of_timesteps": 758546, "per_episode_reward": -143.24, "episode_reward_trend_value": 0.0010223212736286138, "biggest_recent_change": 0.3102940192017343},
{"total_number_of_episodes": 6829, "number_of_timesteps": 759747, "per_episode_reward": -143.14, "episode_reward_trend_value": 0.0017687911900433543, "biggest_recent_change": 0.3102940192017343},
{"total_number_of_episodes": 6839, "number_of_timesteps": 760913, "per_episode_reward": -143.27, "episode_reward_trend_value": 0.00106710273964552, "biggest_recent_change": 0.3102940192017343},
{"total_number_of_episodes": 6849, "number_of_timesteps": 762154, "per_episode_reward": -143.53, "episode_reward_trend_value": -0.005286434887644494, "biggest_recent_change": 0.2781984906191042},
{"total_number_of_episodes": 6859, "number_of_timesteps": 763484, "per_episode_reward": -143.53, "episode_reward_trend_value": -0.0026544747828451264, "biggest_recent_change": 0.2781984906191042},
{"total_number_of_episodes": 6869, "number_of_timesteps": 764733, "per_episode_reward": -143.57, "episode_reward_trend_value": -0.0017918221181594794, "biggest_recent_change": 0.2781984906191042},
{"total_number_of_episodes": 6879, "number_of_timesteps": 765943, "per_episode_reward": -143.3, "episode_reward_trend_value": 0.0014178364120668776, "biggest_recent_change": 0.2781984906191042},
{"total_number_of_episodes": 6889, "number_of_timesteps": 767024, "per_episode_reward": -143.46, "episode_reward_trend_value": -2.8513334928308923e-05, "biggest_recent_change": 0.2781984906191042},
{"total_number_of_episodes": 6899, "number_of_timesteps": 768459, "per_episode_reward": -143.3, "episode_reward_trend_value": 0.0024584205842516993, "biggest_recent_change": 0.2781984906191042},
{"total_number_of_episodes": 6909, "number_of_timesteps": 769500, "per_episode_reward": -143.26, "episode_reward_trend_value": -0.00023769865607966445, "biggest_recent_change": 0.265184850677997},
{"total_number_of_episodes": 6919, "number_of_timesteps": 770579, "per_episode_reward": -143.19, "episode_reward_trend_value": -0.0005979181598484552, "biggest_recent_change": 0.265184850677997},
{"total_number_of_episodes": 6930, "number_of_timesteps": 771778, "per_episode_reward": -143.27, "episode_reward_trend_value": -4.858589622200624e-05, "biggest_recent_change": 0.265184850677997},
{"total_number_of_episodes": 6940, "number_of_timesteps": 772898, "per_episode_reward": -143.29, "episode_reward_trend_value": 0.002643701821163644, "biggest_recent_change": 0.265184850677997},
{"total_number_of_episodes": 6950, "number_of_timesteps": 774444, "per_episode_reward": -143.33, "episode_reward_trend_value": 0.0022640630273432156, "biggest_recent_change": 0.265184850677997},
{"total_number_of_episodes": 6960, "number_of_timesteps": 775381, "per_episode_reward": -143.4, "episode_reward_trend_value": 0.0018436571474028242, "biggest_recent_change": 0.265184850677997},
{"total_number_of_episodes": 6970, "number_of_timesteps": 776209, "per_episode_reward": -143.22, "episode_reward_trend_value": 0.0008937276549229663, "biggest_recent_change": 0.1796911963548098},
{"total_number_of_episodes": 6980, "number_of_timesteps": 777213, "per_episode_reward": -143.16, "episode_reward_trend_value": 0.0033599535911703364, "biggest_recent_change": 0.1796911963548098},
{"total_number_of_episodes": 6990, "number_of_timesteps": 778660, "per_episode_reward": -143.11, "episode_reward_trend_value": 0.0020889595271518777, "biggest_recent_change": 0.1796911963548098},
{"total_number_of_episodes": 7000, "number_of_timesteps": 779616, "per_episode_reward": -143.24, "episode_reward_trend_value": 0.0003071929689835113, "biggest_recent_change": 0.1796911963548098},
{"total_number_of_episodes": 7010, "number_of_timesteps": 780729, "per_episode_reward": -143.04, "episode_reward_trend_value": 0.0017679958299172288, "biggest_recent_change": 0.20139800771164573},
{"total_number_of_episodes": 7020, "number_of_timesteps": 781901, "per_episode_reward": -142.98, "episode_reward_trend_value": 0.0032041842273530267, "biggest_recent_change": 0.20139800771164573},
{"total_number_of_episodes": 7030, "number_of_timesteps": 783133, "per_episode_reward": -143.29, "episode_reward_trend_value": 3.061829991205893e-05, "biggest_recent_change": 0.30483940615934557},
{"total_number_of_episodes": 7040, "number_of_timesteps": 784260, "per_episode_reward": -143.13, "episode_reward_trend_value": 0.002171023985999909, "biggest_recent_change": 0.30483940615934557},
{"total_number_of_episodes": 7050, "number_of_timesteps": 785188, "per_episode_reward": -142.9, "episode_reward_trend_value": 0.005564978425207477, "biggest_recent_change": 0.30483940615934557},
{"total_number_of_episodes": 7060, "number_of_timesteps": 786465, "per_episode_reward": -143.27, "episode_reward_trend_value": -0.0005025308181447802, "biggest_recent_change": 0.3663846355468934},
{"total_number_of_episodes": 7071, "number_of_timesteps": 787793, "per_episode_reward": -143.28, "episode_reward_trend_value": -0.001366051593150688, "biggest_recent_change": 0.3663846355468934},
{"total_number_of_episodes": 7081, "number_of_timesteps": 788838, "per_episode_reward": -143.24, "episode_reward_trend_value": -0.0013857724678909258, "biggest_recent_change": 0.3663846355468934},
{"total_number_of_episodes": 7091, "number_of_timesteps": 790147, "per_episode_reward": -143.27, "episode_reward_trend_value": -0.00040389286583351555, "biggest_recent_change": 0.3663846355468934},
{"total_number_of_episodes": 7102, "number_of_timesteps": 791764, "per_episode_reward": -143.54, "episode_reward_trend_value": -0.005599671949650226, "biggest_recent_change": 0.3663846355468934},
{"total_number_of_episodes": 7112, "number_of_timesteps": 792933, "per_episode_reward": -143.52, "episode_reward_trend_value": -0.0059115735392077165, "biggest_recent_change": 0.3663846355468934},
{"total_number_of_episodes": 7124, "number_of_timesteps": 794528, "per_episode_reward": -143.84, "episode_reward_trend_value": -0.006123371947014297, "biggest_recent_change": 0.3663846355468934},
{"total_number_of_episodes": 7135, "number_of_timesteps": 795662, "per_episode_reward": -143.67, "episode_reward_trend_value": -0.005947142577561711, "biggest_recent_change": 0.3663846355468934},
{"total_number_of_episodes": 7145, "number_of_timesteps": 796780, "per_episode_reward": -143.67, "episode_reward_trend_value": -0.00853865998040817, "biggest_recent_change": 0.3663846355468934},
{"total_number_of_episodes": 7155, "number_of_timesteps": 797939, "per_episode_reward": -144.01, "episode_reward_trend_value": -0.008209935702172782, "biggest_recent_change": 0.33679945050570836},
{"total_number_of_episodes": 7165, "number_of_timesteps": 799056, "per_episode_reward": -143.99, "episode_reward_trend_value": -0.007869984593956917, "biggest_recent_change": 0.33679945050570836},
{"total_number_of_episodes": 7175, "number_of_timesteps": 800244, "per_episode_reward": -144.07, "episode_reward_trend_value": -0.0092711454879675, "biggest_recent_change": 0.33679945050570836},
{"total_number_of_episodes": 7185, "number_of_timesteps": 801747, "per_episode_reward": -144.13, "episode_reward_trend_value": -0.00950916498656448, "biggest_recent_change": 0.33679945050570836},
{"total_number_of_episodes": 7195, "number_of_timesteps": 802702, "per_episode_reward": -143.96, "episode_reward_trend_value": -0.004639913707845898, "biggest_recent_change": 0.33679945050570836},

{"total_number_of_episodes": 7205, "number_of_timesteps": 803829, "per_episode_reward": -143.97, "episode_reward_trend_value": -0.0050486157589422955, "biggest_recent_change": 0.33679945050570836},
{"total_number_of_episodes": 7215, "number_of_timesteps": 804864, "per_episode_reward": -143.82, "episode_reward_trend_value": 0.00018731173288825983, "biggest_recent_change": 0.33679945050570836},
{"total_number_of_episodes": 7225, "number_of_timesteps": 806277, "per_episode_reward": -143.54, "episode_reward_trend_value": 0.0014103711791992484, "biggest_recent_change": 0.33679945050570836},
{"total_number_of_episodes": 7236, "number_of_timesteps": 807330, "per_episode_reward": -143.49, "episode_reward_trend_value": 0.0020152272253277995, "biggest_recent_change": 0.33679945050570836},
{"total_number_of_episodes": 7246, "number_of_timesteps": 808508, "per_episode_reward": -143.78, "episode_reward_trend_value": 0.002544467256675236, "biggest_recent_change": 0.28916784768443904},
{"total_number_of_episodes": 7256, "number_of_timesteps": 809300, "per_episode_reward": -143.78, "episode_reward_trend_value": 0.0024201422163877676, "biggest_recent_change": 0.28916784768443904},
{"total_number_of_episodes": 7267, "number_of_timesteps": 810463, "per_episode_reward": -143.8, "episode_reward_trend_value": 0.002978053573879278, "biggest_recent_change": 0.28916784768443904},
{"total_number_of_episodes": 7277, "number_of_timesteps": 811629, "per_episode_reward": -143.95, "episode_reward_trend_value": 0.0019386485875391673, "biggest_recent_change": 0.28916784768443904},
{"total_number_of_episodes": 7287, "number_of_timesteps": 812903, "per_episode_reward": -143.74, "episode_reward_trend_value": 0.002449982156391191, "biggest_recent_change": 0.28916784768443904},
{"total_number_of_episodes": 7297, "number_of_timesteps": 813983, "per_episode_reward": -143.73, "episode_reward_trend_value": 0.002700576523716336, "biggest_recent_change": 0.28916784768443904},
{"total_number_of_episodes": 7307, "number_of_timesteps": 815336, "per_episode_reward": -143.84, "episode_reward_trend_value": -0.00022794510462441998, "biggest_recent_change": 0.28916784768443904},
{"total_number_of_episodes": 7317, "number_of_timesteps": 816488, "per_episode_reward": -143.62, "episode_reward_trend_value": -0.0008599960194727727, "biggest_recent_change": 0.28916784768443904},
{"total_number_of_episodes": 7327, "number_of_timesteps": 817937, "per_episode_reward": -143.67, "episode_reward_trend_value": -0.0020406548431534726, "biggest_recent_change": 0.28916784768443904},
{"total_number_of_episodes": 7338, "number_of_timesteps": 818984, "per_episode_reward": -143.51, "episode_reward_trend_value": 0.0029864338289339936, "biggest_recent_change": 0.22498717291750836},
{"total_number_of_episodes": 7348, "number_of_timesteps": 819961, "per_episode_reward": -143.43, "episode_reward_trend_value": 0.0038910109565178015, "biggest_recent_change": 0.22498717291750836},
{"total_number_of_episodes": 7358, "number_of_timesteps": 821147, "per_episode_reward": -143.38, "episode_reward_trend_value": 0.004652221568726607, "biggest_recent_change": 0.22498717291750836},
{"total_number_of_episodes": 7369, "number_of_timesteps": 822281, "per_episode_reward": -143.39, "episode_reward_trend_value": 0.0062424180293520395, "biggest_recent_change": 0.22498717291750836},
{"total_number_of_episodes": 7379, "number_of_timesteps": 823650, "per_episode_reward": -143.4, "episode_reward_trend_value": 0.0037791073240195294, "biggest_recent_change": 0.22498717291750836},
{"total_number_of_episodes": 7389, "number_of_timesteps": 825558, "per_episode_reward": -143.45, "episode_reward_trend_value": 0.0031072481878418835, "biggest_recent_change": 0.22498717291750836},
{"total_number_of_episodes": 7399, "number_of_timesteps": 826808, "per_episode_reward": -143.79, "episode_reward_trend_value": 0.0006036119330625904, "biggest_recent_change": 0.34156199807799226},
{"total_number_of_episodes": 7410, "number_of_timesteps": 828097, "per_episode_reward": -143.61, "episode_reward_trend_value": 9.602614132846712e-05, "biggest_recent_change": 0.34156199807799226},
{"total_number_of_episodes": 7420, "number_of_timesteps": 829356, "per_episode_reward": -143.47, "episode_reward_trend_value": 0.002300414298112388, "biggest_recent_change": 0.34156199807799226},
{"total_number_of_episodes": 7431, "number_of_timesteps": 831161, "per_episode_reward": -143.56, "episode_reward_trend_value": -0.0005976504246439794, "biggest_recent_change": 0.34156199807799226},
{"total_number_of_episodes": 7441, "number_of_timesteps": 832443, "per_episode_reward": -143.64, "episode_reward_trend_value": -0.0024313166879974487, "biggest_recent_change": 0.34156199807799226},
{"total_number_of_episodes": 7451, "number_of_timesteps": 833387, "per_episode_reward": -143.46, "episode_reward_trend_value": -0.0008796482244924341, "biggest_recent_change": 0.34156199807799226},
{"total_number_of_episodes": 7461, "number_of_timesteps": 834347, "per_episode_reward": -143.45, "episode_reward_trend_value": -0.0006022799410168823, "biggest_recent_change": 0.34156199807799226},
{"total_number_of_episodes": 7472, "number_of_timesteps": 835647, "per_episode_reward": -143.35, "episode_reward_trend_value": 0.0004905323457699574, "biggest_recent_change": 0.34156199807799226},
{"total_number_of_episodes": 7482, "number_of_timesteps": 836460, "per_episode_reward": -143.07, "episode_reward_trend_value": 0.0041774879205396095, "biggest_recent_change": 0.34156199807799226},
{"total_number_of_episodes": 7492, "number_of_timesteps": 837384, "per_episode_reward": -142.87, "episode_reward_trend_value": 0.010237598141169871, "biggest_recent_change": 0.2802319925709469},
{"total_number_of_episodes": 7503, "number_of_timesteps": 838634, "per_episode_reward": -142.79, "episode_reward_trend_value": 0.009151912097278923, "biggest_recent_change": 0.2802319925709469},
{"total_number_of_episodes": 7513, "number_of_timesteps": 839531, "per_episode_reward": -142.69, "episode_reward_trend_value": 0.008579895712541467, "biggest_recent_change": 0.2802319925709469},
{"total_number_of_episodes": 7523, "number_of_timesteps": 840515, "per_episode_reward": -142.62, "episode_reward_trend_value": 0.010481448234313323, "biggest_recent_change": 0.2802319925709469},
{"total_number_of_episodes": 7534, "number_of_timesteps": 841541, "per_episode_reward": -142.69, "episode_reward_trend_value": 0.010577926016012876, "biggest_recent_change": 0.2802319925709469},
{"total_number_of_episodes": 7544, "number_of_timesteps": 842949, "per_episode_reward": -142.69, "episode_reward_trend_value": 0.008645427114608613, "biggest_recent_change": 0.2802319925709469},
{"total_number_of_episodes": 7555, "number_of_timesteps": 844400, "per_episode_reward": -142.7, "episode_reward_trend_value": 0.008287859086974929, "biggest_recent_change": 0.2802319925709469},
{"total_number_of_episodes": 7565, "number_of_timesteps": 845353, "per_episode_reward": -142.69, "episode_reward_trend_value": 0.007392702703066965, "biggest_recent_change": 0.2802319925709469},
{"total_number_of_episodes": 7575, "number_of_timesteps": 846760, "per_episode_reward": -142.8, "episode_reward_trend_value": 0.0030526962654088647, "biggest_recent_change": 0.20384792177873123},
{"total_number_of_episodes": 7585, "number_of_timesteps": 848007, "per_episode_reward": -142.93, "episode_reward_trend_value": -0.0007358003979779444, "biggest_recent_change": 0.13711677792608157},
{"total_number_of_episodes": 7595, "number_of_timesteps": 848830, "per_episode_reward": -142.73, "episode_reward_trend_value": 0.0006056998783088198, "biggest_recent_change": 0.20232773257706071},
{"total_number_of_episodes": 7606, "number_of_timesteps": 849685, "per_episode_reward": -142.58, "episode_reward_trend_value": 0.0012694547162377982, "biggest_recent_change": 0.20232773257706071},
{"total_number_of_episodes": 7616, "number_of_timesteps": 850493, "per_episode_reward": -142.47, "episode_reward_trend_value": 0.0016922243215153304, "biggest_recent_change": 0.20232773257706071},
{"total_number_of_episodes": 7626, "number_of_timesteps": 851341, "per_episode_reward": -142.39, "episode_reward_trend_value": 0.003391046450611649, "biggest_recent_change": 0.20232773257706071},
{"total_number_of_episodes": 7636, "number_of_timesteps": 852617, "per_episode_reward": -142.19, "episode_reward_trend_value": 0.005452030979577671, "biggest_recent_change": 0.20232773257706071},
{"total_number_of_episodes": 7646, "number_of_timesteps": 853415, "per_episode_reward": -142.01, "episode_reward_trend_value": 0.007627214433852852, "biggest_recent_change": 0.20232773257706071},
{"total_number_of_episodes": 7656, "number_of_timesteps": 854369, "per_episode_reward": -141.94, "episode_reward_trend_value": 0.008355043627984553, "biggest_recent_change": 0.20232773257706071},
{"total_number_of_episodes": 7666, "number_of_timesteps": 855447, "per_episode_reward": -141.95, "episode_reward_trend_value": 0.009373440233895912, "biggest_recent_change": 0.20232773257706071},
{"total_number_of_episodes": 7676, "number_of_timesteps": 856628, "per_episode_reward": -142.11, "episode_reward_trend_value": 0.009137974987377282, "biggest_recent_change": 0.20232773257706071},
{"total_number_of_episodes": 7686, "number_of_timesteps": 857874, "per_episode_reward": -142.21, "episode_reward_trend_value": 0.0058141939514816466, "biggest_recent_change": 0.19193196960819137},
{"total_number_of_episodes": 7696, "number_of_timesteps": 859009, "per_episode_reward": -142.4, "episode_reward_trend_value": 0.001981824540713875, "biggest_recent_change": 0.19304587547361507},
{"total_number_of_episodes": 7706, "number_of_timesteps": 860085, "per_episode_reward": -142.51, "episode_reward_trend_value": -0.00047956597265713045, "biggest_recent_change": 0.19304587547361507},
{"total_number_of_episodes": 7716, "number_of_timesteps": 861477, "per_episode_reward": -142.48, "episode_reward_trend_value": -0.0010029819621558368, "biggest_recent_change": 0.19304587547361507},
{"total_number_of_episodes": 7726, "number_of_timesteps": 862539, "per_episode_reward": -142.38, "episode_reward_trend_value": -0.0021102484069397557, "biggest_recent_change": 0.19304587547361507},
{"total_number_of_episodes": 7736, "number_of_timesteps": 863466, "per_episode_reward": -142.35, "episode_reward_trend_value": -0.0037255632850553234, "biggest_recent_change": 0.19304587547361507},
{"total_number_of_episodes": 7746, "number_of_timesteps": 864749, "per_episode_reward": -142.38, "episode_reward_trend_value": -0.004959870811560702, "biggest_recent_change": 0.19304587547361507},
{"total_number_of_episodes": 7756, "number_of_timesteps": 865951, "per_episode_reward": -142.39, "episode_reward_trend_value": -0.004798836008222907, "biggest_recent_change": 0.19304587547361507},
{"total_number_of_episodes": 7766, "number_of_timesteps": 867159, "per_episode_reward": -142.48, "episode_reward_trend_value": -0.004100143666777791, "biggest_recent_change": 0.19304587547361507},
{"total_number_of_episodes": 7776, "number_of_timesteps": 868644, "per_episode_reward": -142.55, "episode_reward_trend_value": -0.003769100079629576, "biggest_recent_change": 0.19304587547361507},
{"total_number_of_episodes": 7786, "number_of_timesteps": 870279, "per_episode_reward": -142.68, "episode_reward_trend_value": -0.003074602334561089, "biggest_recent_change": 0.13054107841745122},
{"total_number_of_episodes": 7796, "number_of_timesteps": 871357, "per_episode_reward": -142.65, "episode_reward_trend_value": -0.0014922076397210857, "biggest_recent_change": 0.13054107841745122},

{"total_number_of_episodes": 7807, "number_of_timesteps": 872506, "per_episode_reward": -142.48, "episode_reward_trend_value": -6.051009713006453e-06, "biggest_recent_change": 0.16844340967597304},
{"total_number_of_episodes": 7817, "number_of_timesteps": 874018, "per_episode_reward": -142.64, "episode_reward_trend_value": -0.002817060933050344, "biggest_recent_change": 0.16844340967597304},
{"total_number_of_episodes": 7827, "number_of_timesteps": 874914, "per_episode_reward": -142.65, "episode_reward_trend_value": -0.0033212035849632887, "biggest_recent_change": 0.16844340967597304},
{"total_number_of_episodes": 7838, "number_of_timesteps": 875823, "per_episode_reward": -142.54, "episode_reward_trend_value": -0.0017619042678054103, "biggest_recent_change": 0.16844340967597304},
{"total_number_of_episodes": 7848, "number_of_timesteps": 876876, "per_episode_reward": -142.48, "episode_reward_trend_value": -0.0010803773963349132, "biggest_recent_change": 0.16844340967597304},
{"total_number_of_episodes": 7858, "number_of_timesteps": 878095, "per_episode_reward": -142.6, "episode_reward_trend_value": -0.001311918257598816, "biggest_recent_change": 0.16844340967597304},
{"total_number_of_episodes": 7868, "number_of_timesteps": 879136, "per_episode_reward": -142.62, "episode_reward_trend_value": -0.0007659863605741495, "biggest_recent_change": 0.16844340967597304},
{"total_number_of_episodes": 7879, "number_of_timesteps": 880496, "per_episode_reward": -142.65, "episode_reward_trend_value": 0.00026633612625851633, "biggest_recent_change": 0.16844340967597304},
{"total_number_of_episodes": 7889, "number_of_timesteps": 881621, "per_episode_reward": -142.68, "episode_reward_trend_value": -0.00042661648185489615, "biggest_recent_change": 0.16844340967597304},
{"total_number_of_episodes": 7899, "number_of_timesteps": 882886, "per_episode_reward": -142.59, "episode_reward_trend_value": -0.0012347061865559303, "biggest_recent_change": 0.16071290352272172},
{"total_number_of_episodes": 7909, "number_of_timesteps": 884014, "per_episode_reward": -142.66, "episode_reward_trend_value": -0.00019148490155329354, "biggest_recent_change": 0.11626501689644897},
{"total_number_of_episodes": 7919, "number_of_timesteps": 885210, "per_episode_reward": -142.66, "episode_reward_trend_value": -8.840656179340081e-05, "biggest_recent_change": 0.11626501689644897},
{"total_number_of_episodes": 7929, "number_of_timesteps": 886210, "per_episode_reward": -142.64, "episode_reward_trend_value": -0.0011634604654517488, "biggest_recent_change": 0.11626501689644897},
{"total_number_of_episodes": 7939, "number_of_timesteps": 887636, "per_episode_reward": -142.79, "episode_reward_trend_value": -0.003437904097706084, "biggest_recent_change": 0.14758226845640365},
{"total_number_of_episodes": 7949, "number_of_timesteps": 888975, "per_episode_reward": -142.8, "episode_reward_trend_value": -0.0022231525510985903, "biggest_recent_change": 0.14758226845640365},
{"total_number_of_episodes": 7959, "number_of_timesteps": 889859, "per_episode_reward": -142.69, "episode_reward_trend_value": -0.0008134063656393033, "biggest_recent_change": 0.14758226845640365},
{"total_number_of_episodes": 7969, "number_of_timesteps": 890527, "per_episode_reward": -142.54, "episode_reward_trend_value": 0.0013013000134021822, "biggest_recent_change": 0.1526915195112224},
{"total_number_of_episodes": 7979, "number_of_timesteps": 891305, "per_episode_reward": -142.46, "episode_reward_trend_value": 0.0025488359722039096, "biggest_recent_change": 0.1526915195112224},
{"total_number_of_episodes": 7989, "number_of_timesteps": 892266, "per_episode_reward": -142.43, "episode_reward_trend_value": 0.0017289935613174774, "biggest_recent_change": 0.1526915195112224},
{"total_number_of_episodes": 7999, "number_of_timesteps": 893561, "per_episode_reward": -142.47, "episode_reward_trend_value": 0.002103373376162191, "biggest_recent_change": 0.1526915195112224},
{"total_number_of_episodes": 8010, "number_of_timesteps": 894850, "per_episode_reward": -142.29, "episode_reward_trend_value": 0.004117640613057776, "biggest_recent_change": 0.18006586885820752},
{"total_number_of_episodes": 8020, "number_of_timesteps": 895823, "per_episode_reward": -142.42, "episode_reward_trend_value": 0.002522672506071583, "biggest_recent_change": 0.18006586885820752},
{"total_number_of_episodes": 8031, "number_of_timesteps": 897285, "per_episode_reward": -142.52, "episode_reward_trend_value": 0.003057832184266039, "biggest_recent_change": 0.18006586885820752},
{"total_number_of_episodes": 8042, "number_of_timesteps": 898687, "per_episode_reward": -142.45, "episode_reward_trend_value": 0.003835440294230668, "biggest_recent_change": 0.18006586885820752},
{"total_number_of_episodes": 8052, "number_of_timesteps": 899802, "per_episode_reward": -142.41, "episode_reward_trend_value": 0.0030937833675251467, "biggest_recent_change": 0.18006586885820752},
{"total_number_of_episodes": 8063, "number_of_timesteps": 901030, "per_episode_reward": -142.35, "episode_reward_trend_value": 0.002122764977778502, "biggest_recent_change": 0.18006586885820752},
{"total_number_of_episodes": 8073, "number_of_timesteps": 902138, "per_episode_reward": -142.26, "episode_reward_trend_value": 0.002172240714802519, "biggest_recent_change": 0.18006586885820752},
{"total_number_of_episodes": 8083, "number_of_timesteps": 903189, "per_episode_reward": -142.25, "episode_reward_trend_value": 0.0019929289651344105, "biggest_recent_change": 0.18006586885820752},
{"total_number_of_episodes": 8093, "number_of_timesteps": 904291, "per_episode_reward": -142.42, "episode_reward_trend_value": 0.0004894444686429879, "biggest_recent_change": 0.18006586885820752},
{"total_number_of_episodes": 8103, "number_of_timesteps": 905244, "per_episode_reward": -142.37, "episode_reward_trend_value": -0.0009845427669798964, "biggest_recent_change": 0.1684424092206882},
{"total_number_of_episodes": 8113, "number_of_timesteps": 906368, "per_episode_reward": -142.35, "episode_reward_trend_value": 0.0007373628244301421, "biggest_recent_change": 0.1684424092206882},
{"total_number_of_episodes": 8124, "number_of_timesteps": 907627, "per_episode_reward": -142.36, "episode_reward_trend_value": 0.0017873370401635686, "biggest_recent_change": 0.1684424092206882},
{"total_number_of_episodes": 8134, "number_of_timesteps": 909155, "per_episode_reward": -142.28, "episode_reward_trend_value": 0.001982141919009766, "biggest_recent_change": 0.1684424092206882},
{"total_number_of_episodes": 8144, "number_of_timesteps": 910215, "per_episode_reward": -142.26, "episode_reward_trend_value": 0.0017230210675260576, "biggest_recent_change": 0.1684424092206882},
{"total_number_of_episodes": 8154, "number_of_timesteps": 911032, "per_episode_reward": -142.02, "episode_reward_trend_value": 0.0035883996014171595, "biggest_recent_change": 0.23318393248422353},
{"total_number_of_episodes": 8164, "number_of_timesteps": 912143, "per_episode_reward": -142.12, "episode_reward_trend_value": 0.0015623669072349837, "biggest_recent_change": 0.23318393248422353},
{"total_number_of_episodes": 8174, "number_of_timesteps": 913361, "per_episode_reward": -142.0, "episode_reward_trend_value": 0.0028321963333960793, "biggest_recent_change": 0.23318393248422353},
{"total_number_of_episodes": 8184, "number_of_timesteps": 914256, "per_episode_reward": -141.85, "episode_reward_trend_value": 0.006330627798237111, "biggest_recent_change": 0.23318393248422353},
{"total_number_of_episodes": 8194, "number_of_timesteps": 915111, "per_episode_reward": -141.82, "episode_reward_trend_value": 0.006126928901994373, "biggest_recent_change": 0.23318393248422353},
{"total_number_of_episodes": 8204, "number_of_timesteps": 916146, "per_episode_reward": -141.79, "episode_reward_trend_value": 0.006254357508555586, "biggest_recent_change": 0.23318393248422353},
{"total_number_of_episodes": 8214, "number_of_timesteps": 917492, "per_episode_reward": -141.83, "episode_reward_trend_value": 0.005891167982865871, "biggest_recent_change": 0.23318393248422353},
{"total_number_of_episodes": 8224, "number_of_timesteps": 918409, "per_episode_reward": -141.85, "episode_reward_trend_value": 0.004682083616822928, "biggest_recent_change": 0.23318393248422353},
{"total_number_of_episodes": 8234, "number_of_timesteps": 920049, "per_episode_reward": -141.8, "episode_reward_trend_value": 0.005088157711949748, "biggest_recent_change": 0.23318393248422353},
{"total_number_of_episodes": 8245, "number_of_timesteps": 921533, "per_episode_reward": -141.96, "episode_reward_trend_value": 0.0007179378612129818, "biggest_recent_change": 0.16013585408208542},
{"total_number_of_episodes": 8255, "number_of_timesteps": 922899, "per_episode_reward": -141.86, "episode_reward_trend_value": 0.0028418030813374645, "biggest_recent_change": 0.16013585408208542},
{"total_number_of_episodes": 8265, "number_of_timesteps": 923683, "per_episode_reward": -141.72, "episode_reward_trend_value": 0.003044605161610371, "biggest_recent_change": 0.16013585408208542},
{"total_number_of_episodes": 8276, "number_of_timesteps": 924757, "per_episode_reward": -141.62, "episode_reward_trend_value": 0.0026257954298061904, "biggest_recent_change": 0.16013585408208542},
{"total_number_of_episodes": 8286, "number_of_timesteps": 926601, "per_episode_reward": -141.75, "episode_reward_trend_value": 0.0008261988890855795, "biggest_recent_change": 0.16013585408208542},
{"total_number_of_episodes": 8297, "number_of_timesteps": 927748, "per_episode_reward": -141.82, "episode_reward_trend_value": -0.0003608906518647043, "biggest_recent_change": 0.16013585408208542},
{"total_number_of_episodes": 8307, "number_of_timesteps": 928781, "per_episode_reward": -141.77, "episode_reward_trend_value": 0.0006262825035248751, "biggest_recent_change": 0.16013585408208542},
{"total_number_of_episodes": 8317, "number_of_timesteps": 929830, "per_episode_reward": -141.82, "episode_reward_trend_value": 0.0003580976568419677, "biggest_recent_change": 0.16013585408208542},
{"total_number_of_episodes": 8328, "number_of_timesteps": 930961, "per_episode_reward": -141.64, "episode_reward_trend_value": 0.0018024544149287496, "biggest_recent_change": 0.18546116636554189},
{"total_number_of_episodes": 8338, "number_of_timesteps": 932035, "per_episode_reward": -141.59, "episode_reward_trend_value": 0.004134740149240833, "biggest_recent_change": 0.18546116636554189},
{"total_number_of_episodes": 8348, "number_of_timesteps": 933473, "per_episode_reward": -141.6, "episode_reward_trend_value": 0.002893651298382199, "biggest_recent_change": 0.18546116636554189},
{"total_number_of_episodes": 8358, "number_of_timesteps": 935177, "per_episode_reward": -141.76, "episode_reward_trend_value": -0.0004158778863733737, "biggest_recent_change": 0.18546116636554189},
{"total_number_of_episodes": 8368, "number_of_timesteps": 936120, "per_episode_reward": -141.69, "episode_reward_trend_value": -0.0007732583115287955, "biggest_recent_change": 0.18546116636554189},
{"total_number_of_episodes": 8378, "number_of_timesteps": 937370, "per_episode_reward": -141.74, "episode_reward_trend_value": 9.513426093248097e-05, "biggest_recent_change": 0.18546116636554189},
{"total_number_of_episodes": 8388, "number_of_timesteps": 939024, "per_episode_reward": -141.82, "episode_reward_trend_value": 6.331143432115974e-05, "biggest_recent_change": 0.18546116636554189},
{"total_number_of_episodes": 8398, "number_of_timesteps": 940465, "per_episode_reward": -141.8, "episode_reward_trend_value": -0.0003874937538531261, "biggest_recent_change": 0.18546116636554189},
{"total_number_of_episodes": 8408, "number_of_timesteps": 941415, "per_episode_reward": -141.61, "episode_reward_trend_value": 0.0024010628805582555, "biggest_recent_change": 0.19859565924289768},
{"total_number_of_episodes": 8418, "number_of_timesteps": 942421, "per_episode_reward": -141.44, "episode_reward_trend_value": 0.0021293069669446316, "biggest_recent_change": 0.19859565924289768},
{"total_number_of_episodes": 8428, "number_of_timesteps": 943249, "per_episode_reward": -141.32, "episode_reward_trend_value": 0.0029312610625222787, "biggest_recent_change": 0.19859565924289768},
{"total_number_of_episodes": 8438, "number_of_timesteps": 944251, "per_episode_reward": -141.26, "episode_reward_trend_value": 0.003831075374621188, "biggest_recent_change": 0.19859565924289768},
{"total_number_of_episodes": 8449, "number_of_timesteps": 945263, "per_episode_reward": -141.26, "episode_reward_trend_value": 0.0055877211839872295, "biggest_recent_change": 0.19859565924289768},
{"total_number_of_episodes": 8459, "number_of_timesteps": 946509, "per_episode_reward": -141.58, "episode_reward_trend_value": 0.0011572025674644868, "biggest_recent_change": 0.32218736699840633},
{"total_number_of_episodes": 8469, "number_of_timesteps": 948075, "per_episode_reward": -141.41, "episode_reward_trend_value": 0.0037199563843014656, "biggest_recent_change": 0.32218736699840633},
{"total_number_of_episodes": 8479, "number_of_timesteps": 949391, "per_episode_reward": -141.54, "episode_reward_trend_value": 0.0030276989318701276, "biggest_recent_change": 0.32218736699840633},
{"total_number_of_episodes": 8489, "number_of_timesteps": 950669, "per_episode_reward": -141.55, "episode_reward_trend_value": 0.002836576450344018, "biggest_recent_change": 0.32218736699840633},
{"total_number_of_episodes": 8499, "number_of_timesteps": 951723, "per_episode_reward": -141.43, "episode_reward_trend_value": 0.0019144184582804275, "biggest_recent_change": 0.32218736699840633},
{"total_number_of_episodes": 8510, "number_of_timesteps": 952879, "per_episode_reward": -141.62, "episode_reward_trend_value": -0.001948977870182489, "biggest_recent_change": 0.32218736699840633},
{"total_number_of_episodes": 8520, "number_of_timesteps": 953777, "per_episode_reward": -141.49, "episode_reward_trend_value": -0.0018626620769591935, "biggest_recent_change": 0.32218736699840633},
{"total_number_of_episodes": 8530, "number_of_timesteps": 954873, "per_episode_reward": -141.45, "episode_reward_trend_value": -0.002162081428472283, "biggest_recent_change": 0.32218736699840633},
{"total_number_of_episodes": 8543, "number_of_timesteps": 957254, "per_episode_reward": -141.47, "episode_reward_trend_value": -0.002339793998234225, "biggest_recent_change": 0.32218736699840633},
{"total_number_of_episodes": 8553, "number_of_timesteps": 958330, "per_episode_reward": -141.59, "episode_reward_trend_value": -8.218984557812645e-05, "biggest_recent_change": 0.18670253542134674},
{"total_number_of_episodes": 8564, "number_of_timesteps": 959717, "per_episode_reward": -141.73, "episode_reward_trend_value": -0.003640258687551699, "biggest_recent_change": 0.18670253542134674},
{"total_number_of_episodes": 8575, "number_of_timesteps": 961001, "per_episode_reward": -141.46, "episode_reward_trend_value": 0.0009215648273036928, "biggest_recent_change": 0.2735724122562715},
{"total_number_of_episodes": 8585, "number_of_timesteps": 961919, "per_episode_reward": -141.4, "episode_reward_trend_value": 0.0016344404068658175, "biggest_recent_change": 0.2735724122562715},
{"total_number_of_episodes": 8595, "number_of_timesteps": 963073, "per_episode_reward": -141.58, "episode_reward_trend_value": -0.0015736645442065839, "biggest_recent_change": 0.2735724122562715},
{"total_number_of_episodes": 8605, "number_of_timesteps": 964488, "per_episode_reward": -141.47, "episode_reward_trend_value": 0.001675489191246508, "biggest_recent_change": 0.2735724122562715},
{"total_number_of_episodes": 8616, "number_of_timesteps": 965968, "per_episode_reward": -141.72, "episode_reward_trend_value": -0.002592139799812306, "biggest_recent_change": 0.2735724122562715},
{"total_number_of_episodes": 8626, "number_of_timesteps": 967427, "per_episode_reward": -141.91, "episode_reward_trend_value": -0.0050563620452471186, "biggest_recent_change": 0.2735724122562715},
{"total_number_of_episodes": 8637, "number_of_timesteps": 968746, "per_episode_reward": -141.88, "episode_reward_trend_value": -0.004500929736561766, "biggest_recent_change": 0.2735724122562715},
{"total_number_of_episodes": 8647, "number_of_timesteps": 969924, "per_episode_reward": -142.03, "episode_reward_trend_value": -0.00486461285531195, "biggest_recent_change": 0.2735724122562715},
{"total_number_of_episodes": 8657, "number_of_timesteps": 971055, "per_episode_reward": -142.29, "episode_reward_trend_value": -0.006142444237385311, "biggest_recent_change": 0.2735724122562715},
{"total_number_of_episodes": 8670, "number_of_timesteps": 972558, "per_episode_reward": -142.39, "episode_reward_trend_value": -0.010387608966392589, "biggest_recent_change": 0.25931741680193454},
{"total_number_of_episodes": 8680, "number_of_timesteps": 973395, "per_episode_reward": -142.22, "episode_reward_trend_value": -0.009036929691985544, "biggest_recent_change": 0.25931741680193454},
{"total_number_of_episodes": 8690, "number_of_timesteps": 974473, "per_episode_reward": -142.05, "episode_reward_trend_value": -0.005288776125372389, "biggest_recent_change": 0.25931741680193454},
{"total_number_of_episodes": 8700, "number_of_timesteps": 975506, "per_episode_reward": -142.27, "episode_reward_trend_value": -0.008868613649524567, "biggest_recent_change": 0.25931741680193454},
{"total_number_of_episodes": 8710, "number_of_timesteps": 976467, "per_episode_reward": -141.95, "episode_reward_trend_value": -0.0025365350398791025, "biggest_recent_change": 0.3155146176708854},
{"total_number_of_episodes": 8720, "number_of_timesteps": 977961, "per_episode_reward": -141.96, "episode_reward_trend_value": -0.0005313017110590106, "biggest_recent_change": 0.3155146176708854},
{"total_number_of_episodes": 8732, "number_of_timesteps": 979104, "per_episode_reward": -141.85, "episode_reward_trend_value": 0.00028538977389555635, "biggest_recent_change": 0.3155146176708854},
{"total_number_of_episodes": 8742, "number_of_timesteps": 980348, "per_episode_reward": -142.02, "episode_reward_trend_value": 3.514950745492721e-05, "biggest_recent_change": 0.3155146176708854},
{"total_number_of_episodes": 8752, "number_of_timesteps": 982103, "per_episode_reward": -141.96, "episode_reward_trend_value": 0.003640390649953752, "biggest_recent_change": 0.3155146176708854},
{"total_number_of_episodes": 8762, "number_of_timesteps": 983121, "per_episode_reward": -141.92, "episode_reward_trend_value": 0.005278131419995841, "biggest_recent_change": 0.3155146176708854},
{"total_number_of_episodes": 8772, "number_of_timesteps": 984368, "per_episode_reward": -142.01, "episode_reward_trend_value": 0.0022747007624474235, "biggest_recent_change": 0.3155146176708854},
{"total_number_of_episodes": 8782, "number_of_timesteps": 985381, "per_episode_reward": -141.93, "episode_reward_trend_value": 0.0013573953992410755, "biggest_recent_change": 0.3155146176708854},
{"total_number_of_episodes": 8792, "number_of_timesteps": 986658, "per_episode_reward": -141.91, "episode_reward_trend_value": 0.00392376470591829, "biggest_recent_change": 0.3155146176708854},
{"total_number_of_episodes": 8802, "number_of_timesteps": 988374, "per_episode_reward": -141.98, "episode_reward_trend_value": -0.00027266335942657507, "biggest_recent_change": 0.17425609792653063},
{"total_number_of_episodes": 8813, "number_of_timesteps": 989822, "per_episode_reward": -141.96, "episode_reward_trend_value": -5.6898987238835417e-05, "biggest_recent_change": 0.17425609792653063},
{"total_number_of_episodes": 8823, "number_of_timesteps": 991046, "per_episode_reward": -142.02, "episode_reward_trend_value": -0.0019043446708618857, "biggest_recent_change": 0.17425609792653063},
{"total_number_of_episodes": 8833, "number_of_timesteps": 992392, "per_episode_reward": -142.07, "episode_reward_trend_value": -0.0005093590198609061, "biggest_recent_change": 0.09112400392507425},
{"total_number_of_episodes": 8844, "number_of_timesteps": 993430, "per_episode_reward": -141.95, "episode_reward_trend_value": 5.604473951260994e-05, "biggest_recent_change": 0.11604062436657614},
{"total_number_of_episodes": 8854, "number_of_timesteps": 994530, "per_episode_reward": -141.93, "episode_reward_trend_value": -8.412101878876558e-05, "biggest_recent_change": 0.11604062436657614},
{"total_number_of_episodes": 8864, "number_of_timesteps": 995851, "per_episode_reward": -141.68, "episode_reward_trend_value": 0.003640191491863397, "biggest_recent_change": 0.24406412203362038},
{"total_number_of_episodes": 8874, "number_of_timesteps": 996957, "per_episode_reward": -141.72, "episode_reward_trend_value": 0.002320208211609219, "biggest_recent_change": 0.24406412203362038},
{"total_number_of_episodes": 8886, "number_of_timesteps": 998350, "per_episode_reward": -141.76, "episode_reward_trend_value": 0.0017607977622292183, "biggest_recent_change": 0.24406412203362038},
{"total_number_of_episodes": 8896, "number_of_timesteps": 999396, "per_episode_reward": -141.72, "episode_reward_trend_value": 0.0028974228720787523, "biggest_recent_change": 0.24406412203362038},
{"total_number_of_episodes": 8906, "number_of_timesteps": 1000497, "per_episode_reward": -141.8, "episode_reward_trend_value": 0.001735295829354931, "biggest_recent_change": 0.24406412203362038},
{"total_number_of_episodes": 8916, "number_of_timesteps": 1001729, "per_episode_reward": -142.07, "episode_reward_trend_value": -0.0005908446394278776, "biggest_recent_change": 0.2695569499705357},
{"total_number_of_episodes": 8926, "number_of_timesteps": 1002953, "per_episode_reward": -142.0, "episode_reward_trend_value": 0.0007921894011035293, "biggest_recent_change": 0.2695569499705357},
{"total_number_of_episodes": 8936, "number_of_timesteps": 1003941, "per_episode_reward": -141.85, "episode_reward_trend_value": 0.0012047679758309313, "biggest_recent_change": 0.2695569499705357},
{"total_number_of_episodes": 8947, "number_of_timesteps": 1005116, "per_episode_reward": -141.79, "episode_reward_trend_value": 0.0015316607202941492, "biggest_recent_change": 0.2695569499705357},
{"total_number_of_episodes": 8957, "number_of_timesteps": 1006025, "per_episode_reward": -141.7, "episode_reward_trend_value": -0.000188285860564166, "biggest_recent_change": 0.2695569499705357},
{"total_number_of_episodes": 8968, "number_of_timesteps": 1007128, "per_episode_reward": -141.69, "episode_reward_trend_value": 0.0002951613438107693, "biggest_recent_change": 0.2695569499705357},
{"total_number_of_episodes": 8978, "number_of_timesteps": 1008574, "per_episode_reward": -142.02, "episode_reward_trend_value": -0.002927833758120515, "biggest_recent_change": 0.3259073384213309},
{"total_number_of_episodes": 8988, "number_of_timesteps": 1009718, "per_episode_reward": -141.9, "episode_reward_trend_value": -0.0020117981582858293, "biggest_recent_change": 0.3259073384213309},
{"total_number_of_episodes": 8998, "number_of_timesteps": 1010707, "per_episode_reward": -141.83, "episode_reward_trend_value": -0.0002491189196503127, "biggest_recent_change": 0.3259073384213309},
{"total_number_of_episodes": 9008, "number_of_timesteps": 1011772, "per_episode_reward": -141.89, "episode_reward_trend_value": 0.0020705686302606966, "biggest_recent_change": 0.3259073384213309},
{"total_number_of_episodes": 9018, "number_of_timesteps": 1012894, "per_episode_reward": -142.0, "episode_reward_trend_value": -1.3216564011663145e-05, "biggest_recent_change": 0.3259073384213309},
{"total_number_of_episodes": 9028, "number_of_timesteps": 1013763, "per_episode_reward": -141.86, "episode_reward_trend_value": -0.0002116697606750348, "biggest_recent_change": 0.3259073384213309},
{"total_number_of_episodes": 9038, "number_of_timesteps": 1014910, "per_episode_reward": -141.84, "episode_reward_trend_value": -0.0005223514578397549, "biggest_recent_change": 0.3259073384213309},
{"total_number_of_episodes": 9048, "number_of_timesteps": 1016060, "per_episode_reward": -141.98, "episode_reward_trend_value": -0.003117726227393784, "biggest_recent_change": 0.3259073384213309},
{"total_number_of_episodes": 9058, "number_of_timesteps": 1017346, "per_episode_reward": -141.89, "episode_reward_trend_value": -0.0021508747081690495, "biggest_recent_change": 0.3259073384213309},
{"total_number_of_episodes": 9068, "number_of_timesteps": 1018435, "per_episode_reward": -141.82, "episode_reward_trend_value": 0.0022183469442697717, "biggest_recent_change": 0.14431479950349058},
{"total_number_of_episodes": 9078, "number_of_timesteps": 1019608, "per_episode_reward": -141.72, "episode_reward_trend_value": 0.001994966005126268, "biggest_recent_change": 0.14431479950349058},
{"total_number_of_episodes": 9089, "number_of_timesteps": 1021823, "per_episode_reward": -141.72, "episode_reward_trend_value": 0.0012050192214372955, "biggest_recent_change": 0.14431479950349058},
{"total_number_of_episodes": 9099, "number_of_timesteps": 1023384, "per_episode_reward": -141.68, "episode_reward_trend_value": 0.002263694813157397, "biggest_recent_change": 0.14431479950349058},
{"total_number_of_episodes": 9109, "number_of_timesteps": 1024481, "per_episode_reward": -141.31, "episode_reward_trend_value": 0.007683328994061059, "biggest_recent_change": 0.3759920831082013},
{"total_number_of_episodes": 9119, "number_of_timesteps": 1025607, "per_episode_reward": -141.34, "episode_reward_trend_value": 0.00584450545332705, "biggest_recent_change": 0.3759920831082013},
{"total_number_of_episodes": 9129, "number_of_timesteps": 1026982, "per_episode_reward": -141.52, "episode_reward_trend_value": 0.0034708372664634148, "biggest_recent_change": 0.3759920831082013},
{"total_number_of_episodes": 9139, "number_of_timesteps": 1029266, "per_episode_reward": -141.81, "episode_reward_trend_value": 0.0019032017689969254, "biggest_recent_change": 0.3759920831082013},
{"total_number_of_episodes": 9150, "number_of_timesteps": 1030510, "per_episode_reward": -141.63, "episode_reward_trend_value": 0.002902958501271276, "biggest_recent_change": 0.3759920831082013},
{"total_number_of_episodes": 9160, "number_of_timesteps": 1031576, "per_episode_reward": -141.44, "episode_reward_trend_value": 0.004232273886315675, "biggest_recent_change": 0.3759920831082013},
{"total_number_of_episodes": 9170, "number_of_timesteps": 1033069, "per_episode_reward": -141.43, "episode_reward_trend_value": 0.003177456772478612, "biggest_recent_change": 0.3759920831082013},
{"total_number_of_episodes": 9181, "number_of_timesteps": 1034039, "per_episode_reward": -141.37, "episode_reward_trend_value": 0.003859069299487475, "biggest_recent_change": 0.3759920831082013},
{"total_number_of_episodes": 9191, "number_of_timesteps": 1035302, "per_episode_reward": -141.38, "episode_reward_trend_value": 0.0034242783488375983, "biggest_recent_change": 0.3759920831082013},
{"total_number_of_episodes": 9202, "number_of_timesteps": 1036758, "per_episode_reward": -141.37, "episode_reward_trend_value": -0.0006978618433123529, "biggest_recent_change": 0.28540199427547464},
{"total_number_of_episodes": 9213, "number_of_timesteps": 1037889, "per_episode_reward": -141.38, "episode_reward_trend_value": -0.00047086365492121884, "biggest_recent_change": 0.28540199427547464},
{"total_number_of_episodes": 9223, "number_of_timesteps": 1039313, "per_episode_reward": -141.28, "episode_reward_trend_value": 0.0027090831338565774, "biggest_recent_change": 0.28540199427547464},
{"total_number_of_episodes": 9233, "number_of_timesteps": 1040552, "per_episode_reward": -141.26, "episode_reward_trend_value": 0.006154697196545081, "biggest_recent_change": 0.1869609949521589},
{"total_number_of_episodes": 9243, "number_of_timesteps": 1041772, "per_episode_reward": -141.24, "episode_reward_trend_value": 0.004296797896874535, "biggest_recent_change": 0.1869609949521589},
{"total_number_of_episodes": 9253, "number_of_timesteps": 1042810, "per_episode_reward": -141.3, "episode_reward_trend_value": 0.001590234019670965, "biggest_recent_change": 0.10031340613141992},
{"total_number_of_episodes": 9263, "number_of_timesteps": 1043958, "per_episode_reward": -141.24, "episode_reward_trend_value": 0.0021619933506267825, "biggest_recent_change": 0.10031340613141992},
{"total_number_of_episodes": 9273, "number_of_timesteps": 1044882, "per_episode_reward": -141.19, "episode_reward_trend_value": 0.001985263322171073, "biggest_recent_change": 0.10031340613141992},
{"total_number_of_episodes": 9283, "number_of_timesteps": 1046122, "per_episode_reward": -141.22, "episode_reward_trend_value": 0.0017699729307180533, "biggest_recent_change": 0.10031340613141992},
{"total_number_of_episodes": 9293, "number_of_timesteps": 1047308, "per_episode_reward": -141.15, "episode_reward_trend_value": 0.002448089664424755, "biggest_recent_change": 0.10031340613141992},
{"total_number_of_episodes": 9303, "number_of_timesteps": 1048570, "per_episode_reward": -141.15, "episode_reward_trend_value": 0.0025564493679638644, "biggest_recent_change": 0.10031340613141992},
{"total_number_of_episodes": 9313, "number_of_timesteps": 1049955, "per_episode_reward": -141.21, "episode_reward_trend_value": 0.0008335122930538495, "biggest_recent_change": 0.06602997184830883},
{"total_number_of_episodes": 9323, "number_of_timesteps": 1050957, "per_episode_reward": -141.11, "episode_reward_trend_value": 0.0016238821175360526, "biggest_recent_change": 0.09583655556988901},
{"total_number_of_episodes": 9333, "number_of_timesteps": 1052114, "per_episode_reward": -141.04, "episode_reward_trend_value": 0.0022254805525765025, "biggest_recent_change": 0.09583655556988901},
{"total_number_of_episodes": 9345, "number_of_timesteps": 1053500, "per_episode_reward": -141.03, "episode_reward_trend_value": 0.003008933482778452, "biggest_recent_change": 0.09583655556988901},
{"total_number_of_episodes": 9356, "number_of_timesteps": 1054808, "per_episode_reward": -141.01, "episode_reward_trend_value": 0.002520362140021209, "biggest_recent_change": 0.09583655556988901},
{"total_number_of_episodes": 9367, "number_of_timesteps": 1056108, "per_episode_reward": -141.25, "episode_reward_trend_value": -0.0006674899985976405, "biggest_recent_change": 0.24237151887791697},
{"total_number_of_episodes": 9377, "number_of_timesteps": 1057162, "per_episode_reward": -141.29, "episode_reward_trend_value": -0.0008662332066958496, "biggest_recent_change": 0.24237151887791697},
{"total_number_of_episodes": 9387, "number_of_timesteps": 1058170, "per_episode_reward": -141.27, "episode_reward_trend_value": -0.0013825441989802636, "biggest_recent_change": 0.24237151887791697},
{"total_number_of_episodes": 9398, "number_of_timesteps": 1059677, "per_episode_reward": -141.55, "episode_reward_trend_value": -0.004469320270573639, "biggest_recent_change": 0.2778098464434038},
{"total_number_of_episodes": 9408, "number_of_timesteps": 1060938, "per_episode_reward": -141.37, "episode_reward_trend_value": -0.0018378390325488505, "biggest_recent_change": 0.2778098464434038},
{"total_number_of_episodes": 9418, "number_of_timesteps": 1062089, "per_episode_reward": -141.58, "episode_reward_trend_value": -0.0052147984102766205, "biggest_recent_change": 0.2778098464434038},
{"total_number_of_episodes": 9428, "number_of_timesteps": 1063343, "per_episode_reward": -141.61, "episode_reward_trend_value": -0.00638335937606674, "biggest_recent_change": 0.2778098464434038},
{"total_number_of_episodes": 9438, "number_of_timesteps": 1064488, "per_episode_reward": -141.41, "episode_reward_trend_value": -0.004225484057137881, "biggest_recent_change": 0.2778098464434038},
{"total_number_of_episodes": 9448, "number_of_timesteps": 1065608, "per_episode_reward": -141.3, "episode_reward_trend_value": -0.003229980373989684, "biggest_recent_change": 0.2778098464434038},
{"total_number_of_episodes": 9458, "number_of_timesteps": 1067455, "per_episode_reward": -141.3, "episode_reward_trend_value": -0.0004925081015231727, "biggest_recent_change": 0.2778098464434038},
{"total_number_of_episodes": 9468, "number_of_timesteps": 1068669, "per_episode_reward": -141.09, "episode_reward_trend_value": 0.0022626681444213167, "biggest_recent_change": 0.2778098464434038},
{"total_number_of_episodes": 9478, "number_of_timesteps": 1069779, "per_episode_reward": -141.01, "episode_reward_trend_value": 0.002966952260025045, "biggest_recent_change": 0.2778098464434038},
{"total_number_of_episodes": 9488, "number_of_timesteps": 1071083, "per_episode_reward": -141.23, "episode_reward_trend_value": 0.0036347782765530053, "biggest_recent_change": 0.21770550495588736},
{"total_number_of_episodes": 9498, "number_of_timesteps": 1072301, "per_episode_reward": -141.26, "episode_reward_trend_value": 0.001176509615698112, "biggest_recent_change": 0.21770550495588736},
{"total_number_of_episodes": 9508, "number_of_timesteps": 1073622, "per_episode_reward": -141.14, "episode_reward_trend_value": 0.00486676286401967, "biggest_recent_change": 0.21770550495588736},
{"total_number_of_episodes": 9518, "number_of_timesteps": 1074814, "per_episode_reward": -141.07, "episode_reward_trend_value": 0.005995152149048976, "biggest_recent_change": 0.21770550495588736},
{"total_number_of_episodes": 9528, "number_of_timesteps": 1076335, "per_episode_reward": -141.18, "episode_reward_trend_value": 0.002554276442235922, "biggest_recent_change": 0.21770550495588736},
{"total_number_of_episodes": 9538, "number_of_timesteps": 1077418, "per_episode_reward": -141.17, "episode_reward_trend_value": 0.0014474236940464557, "biggest_recent_change": 0.21770550495588736},
{"total_number_of_episodes": 9548, "number_of_timesteps": 1078647, "per_episode_reward": -141.05, "episode_reward_trend_value": 0.002756071213744033, "biggest_recent_change": 0.21770550495588736},
{"total_number_of_episodes": 9558, "number_of_timesteps": 1079853, "per_episode_reward": -141.0, "episode_reward_trend_value": 0.0009886928296591832, "biggest_recent_change": 0.21770550495588736},
{"total_number_of_episodes": 9570, "number_of_timesteps": 1081254, "per_episode_reward": -141.01, "episode_reward_trend_value": 2.0345239038495797e-05, "biggest_recent_change": 0.21770550495588736},
{"total_number_of_episodes": 9580, "number_of_timesteps": 1082470, "per_episode_reward": -140.98, "episode_reward_trend_value": 0.0027754888336788655, "biggest_recent_change": 0.12403300392332994},
{"total_number_of_episodes": 9590, "number_of_timesteps": 1083404, "per_episode_reward": -140.94, "episode_reward_trend_value": 0.0036345542366581817, "biggest_recent_change": 0.12403300392332994},
{"total_number_of_episodes": 9600, "number_of_timesteps": 1084508, "per_episode_reward": -140.94, "episode_reward_trend_value": 0.002271903569269461, "biggest_recent_change": 0.121779262416851},
{"total_number_of_episodes": 9611, "number_of_timesteps": 1085352, "per_episode_reward": -140.89, "episode_reward_trend_value": 0.0020978567760250953, "biggest_recent_change": 0.121779262416851},
{"total_number_of_episodes": 9621, "number_of_timesteps": 1086398, "per_episode_reward": -140.82, "episode_reward_trend_value": 0.003990760354421101, "biggest_recent_change": 0.121779262416851},
{"total_number_of_episodes": 9632, "number_of_timesteps": 1087574, "per_episode_reward": -140.77, "episode_reward_trend_value": 0.0044756016115318036, "biggest_recent_change": 0.121779262416851},
{"total_number_of_episodes": 9642, "number_of_timesteps": 1089102, "per_episode_reward": -140.82, "episode_reward_trend_value": 0.002534842560252868, "biggest_recent_change": 0.06877229686807595},
{"total_number_of_episodes": 9652, "number_of_timesteps": 1090656, "per_episode_reward": -140.92, "episode_reward_trend_value": 0.000906121667244343, "biggest_recent_change": 0.0995815495452348},
{"total_number_of_episodes": 9662, "number_of_timesteps": 1091650, "per_episode_reward": -140.78, "episode_reward_trend_value": 0.0024923392516825516, "biggest_recent_change": 0.13855585239062407},
{"total_number_of_episodes": 9672, "number_of_timesteps": 1092876, "per_episode_reward": -140.91, "episode_reward_trend_value": 0.0007125657395663312, "biggest_recent_change": 0.13855585239062407},
{"total_number_of_episodes": 9682, "number_of_timesteps": 1094114, "per_episode_reward": -140.79, "episode_reward_trend_value": 0.0016472659947077597, "biggest_recent_change": 0.13855585239062407},
{"total_number_of_episodes": 9692, "number_of_timesteps": 1095026, "per_episode_reward": -140.8, "episode_reward_trend_value": 0.0015517962637829896, "biggest_recent_change": 0.13855585239062407},
{"total_number_of_episodes": 9702, "number_of_timesteps": 1096033, "per_episode_reward": -140.76, "episode_reward_trend_value": 0.0014371589225855056, "biggest_recent_change": 0.13855585239062407},
{"total_number_of_episodes": 9713, "number_of_timesteps": 1097038, "per_episode_reward": -140.74, "episode_reward_trend_value": 0.0007993442516556747, "biggest_recent_change": 0.13855585239062407},
{"total_number_of_episodes": 9724, "number_of_timesteps": 1098242, "per_episode_reward": -140.75, "episode_reward_trend_value": 0.00015506211986083447, "biggest_recent_change": 0.13855585239062407},
{"total_number_of_episodes": 9734, "number_of_timesteps": 1099195, "per_episode_reward": -140.72, "episode_reward_trend_value": 0.001067717260914315, "biggest_recent_change": 0.13855585239062407},
{"total_number_of_episodes": 9744, "number_of_timesteps": 1100249, "per_episode_reward": -140.68, "episode_reward_trend_value": 0.0026197339094646095, "biggest_recent_change": 0.13855585239062407},
{"total_number_of_episodes": 9754, "number_of_timesteps": 1101183, "per_episode_reward": -140.55, "episode_reward_trend_value": 0.002543492679631577, "biggest_recent_change": 0.1316941417056512},
{"total_number_of_episodes": 9764, "number_of_timesteps": 1102267, "per_episode_reward": -140.32, "episode_reward_trend_value": 0.006525928303974145, "biggest_recent_change": 0.2284970086621172},
{"total_number_of_episodes": 9774, "number_of_timesteps": 1103597, "per_episode_reward": -140.37, "episode_reward_trend_value": 0.004635688408250379, "biggest_recent_change": 0.2284970086621172},
{"total_number_of_episodes": 9785, "number_of_timesteps": 1104936, "per_episode_reward": -140.45, "episode_reward_trend_value": 0.0038957484381945224, "biggest_recent_change": 0.2284970086621172},
{"total_number_of_episodes": 9796, "number_of_timesteps": 1106557, "per_episode_reward": -140.34, "episode_reward_trend_value": 0.004586664727367267, "biggest_recent_change": 0.2284970086621172},
{"total_number_of_episodes": 9806, "number_of_timesteps": 1107684, "per_episode_reward": -140.3, "episode_reward_trend_value": 0.004945985873020062, "biggest_recent_change": 0.2284970086621172},
{"total_number_of_episodes": 9816, "number_of_timesteps": 1108545, "per_episode_reward": -140.24, "episode_reward_trend_value": 0.0057002397022984045, "biggest_recent_change": 0.2284970086621172},
{"total_number_of_episodes": 9826, "number_of_timesteps": 1109298, "per_episode_reward": -140.05, "episode_reward_trend_value": 0.007546979419633242, "biggest_recent_change": 0.2284970086621172},
{"total_number_of_episodes": 9836, "number_of_timesteps": 1110273, "per_episode_reward": -140.0, "episode_reward_trend_value": 0.007617224259959382, "biggest_recent_change": 0.2284970086621172},
{"total_number_of_episodes": 9847, "number_of_timesteps": 1111375, "per_episode_reward": -139.98, "episode_reward_trend_value": 0.006417367082705204, "biggest_recent_change": 0.2284970086621172},
{"total_number_of_episodes": 9857, "number_of_timesteps": 1112947, "per_episode_reward": -139.98, "episode_reward_trend_value": 0.0038666910260316293, "biggest_recent_change": 0.19545648505669533},
{"total_number_of_episodes": 9867, "number_of_timesteps": 1114015, "per_episode_reward": -139.95, "episode_reward_trend_value": 0.004638031771332546, "biggest_recent_change": 0.19545648505669533},
{"total_number_of_episodes": 9877, "number_of_timesteps": 1115081, "per_episode_reward": -139.87, "episode_reward_trend_value": 0.006385809053251516, "biggest_recent_change": 0.19545648505669533},
{"total_number_of_episodes": 9888, "number_of_timesteps": 1116093, "per_episode_reward": -139.82, "episode_reward_trend_value": 0.005825046063713065, "biggest_recent_change": 0.19545648505669533},
{"total_number_of_episodes": 9899, "number_of_timesteps": 1117275, "per_episode_reward": -139.73, "episode_reward_trend_value": 0.0063280823056566585, "biggest_recent_change": 0.19545648505669533},
{"total_number_of_episodes": 9909, "number_of_timesteps": 1118190, "per_episode_reward": -139.69, "episode_reward_trend_value": 0.006098760128327285, "biggest_recent_change": 0.19545648505669533},
{"total_number_of_episodes": 9919, "number_of_timesteps": 1119119, "per_episode_reward": -139.67, "episode_reward_trend_value": 0.004150939883793904, "biggest_recent_change": 0.08898114136806612},
{"total_number_of_episodes": 9929, "number_of_timesteps": 1120316, "per_episode_reward": -139.74, "episode_reward_trend_value": 0.002930066728454032, "biggest_recent_change": 0.08898114136806612},
{"total_number_of_episodes": 9939, "number_of_timesteps": 1121586, "per_episode_reward": -139.68, "episode_reward_trend_value": 0.003245726008734411, "biggest_recent_change": 0.08898114136806612},
{"total_number_of_episodes": 9950, "number_of_timesteps": 1122593, "per_episode_reward": -139.61, "episode_reward_trend_value": 0.0040717313415797205, "biggest_recent_change": 0.08898114136806612},
{"total_number_of_episodes": 9960, "number_of_timesteps": 1123610, "per_episode_reward": -139.65, "episode_reward_trend_value": 0.0033800401320670894, "biggest_recent_change": 0.08898114136806612},
{"total_number_of_episodes": 9972, "number_of_timesteps": 1125185, "per_episode_reward": -139.59, "episode_reward_trend_value": 0.0031245808528236945, "biggest_recent_change": 0.08898114136806612},
{"total_number_of_episodes": 9982, "number_of_timesteps": 1126069, "per_episode_reward": -139.55, "episode_reward_trend_value": 0.00299612238322311, "biggest_recent_change": 0.08898114136806612},
{"total_number_of_episodes": 9992, "number_of_timesteps": 1127003, "per_episode_reward": -139.59, "episode_reward_trend_value": 0.0015280241009747897, "biggest_recent_change": 0.07327664351757335},
{"total_number_of_episodes": 10003, "number_of_timesteps": 1128191, "per_episode_reward": -139.53, "episode_reward_trend_value": 0.0017547612831252638, "biggest_recent_change": 0.07327664351757335},
{"total_number_of_episodes": 10013, "number_of_timesteps": 1129319, "per_episode_reward": -139.55, "episode_reward_trend_value": 0.0013279530730872895, "biggest_recent_change": 0.07327664351757335},
{"total_number_of_episodes": 10023, "number_of_timesteps": 1130591, "per_episode_reward": -139.58, "episode_reward_trend_value": 0.0016827851443417155, "biggest_recent_change": 0.07327664351757335},
{"total_number_of_episodes": 10033, "number_of_timesteps": 1131556, "per_episode_reward": -139.61, "episode_reward_trend_value": 0.000789416466772271, "biggest_recent_change": 0.07327664351757335},
{"total_number_of_episodes": 10043, "number_of_timesteps": 1132538, "per_episode_reward": -139.58, "episode_reward_trend_value": 0.0003731173860567575, "biggest_recent_change": 0.06051619101089045},
{"total_number_of_episodes": 10053, "number_of_timesteps": 1133725, "per_episode_reward": -139.58, "episode_reward_trend_value": 0.0007589899807246386, "biggest_recent_change": 0.06051619101089045},
{"total_number_of_episodes": 10064, "number_of_timesteps": 1135454, "per_episode_reward": -139.55, "episode_reward_trend_value": 0.00042951046791712445, "biggest_recent_change": 0.058303750324711245},
{"total_number_of_episodes": 10074, "number_of_timesteps": 1136365, "per_episode_reward": -139.5, "episode_reward_trend_value": 0.0005241612057343698, "biggest_recent_change": 0.058303750324711245},
{"total_number_of_episodes": 10084, "number_of_timesteps": 1137223, "per_episode_reward": -139.41, "episode_reward_trend_value": 0.0020600812024772113, "biggest_recent_change": 0.09508509567257306},
{"total_number_of_episodes": 10094, "number_of_timesteps": 1138317, "per_episode_reward": -139.39, "episode_reward_trend_value": 0.0016022125967493947, "biggest_recent_change": 0.09508509567257306},
{"total_number_of_episodes": 10104, "number_of_timesteps": 1139465, "per_episode_reward": -139.38, "episode_reward_trend_value": 0.0018644514811244207, "biggest_recent_change": 0.09508509567257306},
{"total_number_of_episodes": 10114, "number_of_timesteps": 1140754, "per_episode_reward": -139.35, "episode_reward_trend_value": 0.0025509731555918807, "biggest_recent_change": 0.09508509567257306},
{"total_number_of_episodes": 10124, "number_of_timesteps": 1141939, "per_episode_reward": -139.37, "episode_reward_trend_value": 0.0027389207938426805, "biggest_recent_change": 0.09508509567257306},
{"total_number_of_episodes": 10135, "number_of_timesteps": 1143216, "per_episode_reward": -139.34, "episode_reward_trend_value": 0.0025917293938688443, "biggest_recent_change": 0.09508509567257306},
{"total_number_of_episodes": 10145, "number_of_timesteps": 1144258, "per_episode_reward": -139.3, "episode_reward_trend_value": 0.00315139382951107, "biggest_recent_change": 0.09508509567257306},
{"total_number_of_episodes": 10155, "number_of_timesteps": 1145168, "per_episode_reward": -139.29, "episode_reward_trend_value": 0.002937484584481985, "biggest_recent_change": 0.09508509567257306},
{"total_number_of_episodes": 10165, "number_of_timesteps": 1146301, "per_episode_reward": -139.29, "episode_reward_trend_value": 0.0023580220416417005, "biggest_recent_change": 0.09508509567257306},
{"total_number_of_episodes": 10175, "number_of_timesteps": 1147426, "per_episode_reward": -139.26, "episode_reward_trend_value": 0.0016602602346978302, "biggest_recent_change": 0.044422310899392414},
{"total_number_of_episodes": 10185, "number_of_timesteps": 1148422, "per_episode_reward": -139.27, "episode_reward_trend_value": 0.0013738880622737623, "biggest_recent_change": 0.044422310899392414},
{"total_number_of_episodes": 10195, "number_of_timesteps": 1149486, "per_episode_reward": -139.27, "episode_reward_trend_value": 0.0012484899816279772, "biggest_recent_change": 0.044422310899392414},
{"total_number_of_episodes": 10205, "number_of_timesteps": 1150431, "per_episode_reward": -139.24, "episode_reward_trend_value": 0.0012183256940444507, "biggest_recent_change": 0.044422310899392414},
{"total_number_of_episodes": 10215, "number_of_timesteps": 1151473, "per_episode_reward": -139.25, "episode_reward_trend_value": 0.0013041161490753616, "biggest_recent_change": 0.044422310899392414},
{"total_number_of_episodes": 10225, "number_of_timesteps": 1152573, "per_episode_reward": -139.21, "episode_reward_trend_value": 0.00145454987267802, "biggest_recent_change": 0.044422310899392414},
{"total_number_of_episodes": 10235, "number_of_timesteps": 1153707, "per_episode_reward": -139.14, "episode_reward_trend_value": 0.0018125495653366543, "biggest_recent_change": 0.0766422832386695},
{"total_number_of_episodes": 10245, "number_of_timesteps": 1154762, "per_episode_reward": -139.12, "episode_reward_trend_value": 0.0019070872289543358, "biggest_recent_change": 0.0766422832386695},
{"total_number_of_episodes": 10255, "number_of_timesteps": 1156058, "per_episode_reward": -139.07, "episode_reward_trend_value": 0.00248807737086578, "biggest_recent_change": 0.0766422832386695},
{"total_number_of_episodes": 10265, "number_of_timesteps": 1157293, "per_episode_reward": -139.11, "episode_reward_trend_value": 0.0016591954859443883, "biggest_recent_change": 0.0766422832386695},
{"total_number_of_episodes": 10276, "number_of_timesteps": 1158343, "per_episode_reward": -139.09, "episode_reward_trend_value": 0.0019676607254053933, "biggest_recent_change": 0.0766422832386695},
{"total_number_of_episodes": 10288, "number_of_timesteps": 1159667, "per_episode_reward": -139.15, "episode_reward_trend_value": 0.00131008283284757, "biggest_recent_change": 0.0766422832386695},
{"total_number_of_episodes": 10298, "number_of_timesteps": 1160747, "per_episode_reward": -139.13, "episode_reward_trend_value": 0.001282975309298864, "biggest_recent_change": 0.0766422832386695},
{"total_number_of_episodes": 10309, "number_of_timesteps": 1161923, "per_episode_reward": -139.09, "episode_reward_trend_value": 0.0017329090962255752, "biggest_recent_change": 0.0766422832386695},
{"total_number_of_episodes": 10319, "number_of_timesteps": 1162945, "per_episode_reward": -139.09, "episode_reward_trend_value": 0.001354287798974004, "biggest_recent_change": 0.0766422832386695},
{"total_number_of_episodes": 10329, "number_of_timesteps": 1164326, "per_episode_reward": -139.13, "episode_reward_trend_value": 1.0669567140869023e-05, "biggest_recent_change": 0.06512641384929907},
{"total_number_of_episodes": 10339, "number_of_timesteps": 1165508, "per_episode_reward": -139.13, "episode_reward_trend_value": -0.00019871168810602237, "biggest_recent_change": 0.06512641384929907},
{"total_number_of_episodes": 10349, "number_of_timesteps": 1166482, "per_episode_reward": -139.09, "episode_reward_trend_value": -0.00031861493502623894, "biggest_recent_change": 0.06512641384929907},
{"total_number_of_episodes": 10359, "number_of_timesteps": 1167509, "per_episode_reward": -139.03, "episode_reward_trend_value": 0.0008140590863301136, "biggest_recent_change": 0.06512641384929907},
{"total_number_of_episodes": 10369, "number_of_timesteps": 1168703, "per_episode_reward": -139.03, "episode_reward_trend_value": 0.0006466404058777976, "biggest_recent_change": 0.06512641384929907},
{"total_number_of_episodes": 10379, "number_of_timesteps": 1169822, "per_episode_reward": -139.01, "episode_reward_trend_value": 0.0016467315735841086, "biggest_recent_change": 0.059627825326771244},
{"total_number_of_episodes": 10390, "number_of_timesteps": 1171022, "per_episode_reward": -138.97, "episode_reward_trend_value": 0.0017556780582260166, "biggest_recent_change": 0.059627825326771244},
{"total_number_of_episodes": 10401, "number_of_timesteps": 1172688, "per_episode_reward": -138.98, "episode_reward_trend_value": 0.0012829745491750879, "biggest_recent_change": 0.059627825326771244},
{"total_number_of_episodes": 10411, "number_of_timesteps": 1174039, "per_episode_reward": -138.88, "episode_reward_trend_value": 0.0023148780920198278, "biggest_recent_change": 0.09489693748315631},
{"total_number_of_episodes": 10421, "number_of_timesteps": 1175138, "per_episode_reward": -138.95, "episode_reward_trend_value": 0.0020354317711792193, "biggest_recent_change": 0.09489693748315631},
{"total_number_of_episodes": 10431, "number_of_timesteps": 1176642, "per_episode_reward": -138.96, "episode_reward_trend_value": 0.0018961886796009567, "biggest_recent_change": 0.09489693748315631},
{"total_number_of_episodes": 10441, "number_of_timesteps": 1177824, "per_episode_reward": -138.94, "episode_reward_trend_value": 0.0016894586719599955, "biggest_recent_change": 0.09489693748315631},
{"total_number_of_episodes": 10451, "number_of_timesteps": 1179037, "per_episode_reward": -138.99, "episode_reward_trend_value": 0.0005209584250283999, "biggest_recent_change": 0.09489693748315631},
{"total_number_of_episodes": 10461, "number_of_timesteps": 1180306, "per_episode_reward": -139.0, "episode_reward_trend_value": 0.0003512061066497078, "biggest_recent_change": 0.09489693748315631},
{"total_number_of_episodes": 10471, "number_of_timesteps": 1181531, "per_episode_reward": -138.96, "episode_reward_trend_value": 0.0005274768497697677, "biggest_recent_change": 0.09489693748315631},
{"total_number_of_episodes": 10481, "number_of_timesteps": 1182609, "per_episode_reward": -138.99, "episode_reward_trend_value": -0.00016502632036766347, "biggest_recent_change": 0.09489693748315631},
{"total_number_of_episodes": 10491, "number_of_timesteps": 1184215, "per_episode_reward": -139.07, "episode_reward_trend_value": -0.001026943345151052, "biggest_recent_change": 0.09489693748315631},
{"total_number_of_episodes": 10501, "number_of_timesteps": 1185565, "per_episode_reward": -139.12, "episode_reward_trend_value": -0.0026495189034625986, "biggest_recent_change": 0.0832722288295713},
{"total_number_of_episodes": 10513, "number_of_timesteps": 1186933, "per_episode_reward": -139.13, "episode_reward_trend_value": -0.001937836431404902, "biggest_recent_change": 0.0832722288295713},
{"total_number_of_episodes": 10523, "number_of_timesteps": 1187807, "per_episode_reward": -139.11, "episode_reward_trend_value": -0.0016809336097430281, "biggest_recent_change": 0.0832722288295713},
{"total_number_of_episodes": 10533, "number_of_timesteps": 1188822, "per_episode_reward": -139.11, "episode_reward_trend_value": -0.0019171371993754367, "biggest_recent_change": 0.0832722288295713},
{"total_number_of_episodes": 10543, "number_of_timesteps": 1190111, "per_episode_reward": -139.1, "episode_reward_trend_value": -0.0012925291422640661, "biggest_recent_change": 0.0832722288295713},
{"total_number_of_episodes": 10553, "number_of_timesteps": 1190942, "per_episode_reward": -139.06, "episode_reward_trend_value": -0.0007245174661527976, "biggest_recent_change": 0.0832722288295713},
{"total_number_of_episodes": 10564, "number_of_timesteps": 1191988, "per_episode_reward": -139.0, "episode_reward_trend_value": -0.0004243616019755968, "biggest_recent_change": 0.0832722288295713},
{"total_number_of_episodes": 10574, "number_of_timesteps": 1193798, "per_episode_reward": -139.06, "episode_reward_trend_value": -0.0008126098046053207, "biggest_recent_change": 0.0832722288295713},
{"total_number_of_episodes": 10584, "number_of_timesteps": 1194741, "per_episode_reward": -139.05, "episode_reward_trend_value": 0.0001903873757227201, "biggest_recent_change": 0.0677601859010224},
{"total_number_of_episodes": 10594, "number_of_timesteps": 1195818, "per_episode_reward": -139.03, "episode_reward_trend_value": 0.0010170650916889045, "biggest_recent_change": 0.0677601859010224},
{"total_number_of_episodes": 10604, "number_of_timesteps": 1196942, "per_episode_reward": -139.03, "episode_reward_trend_value": 0.0010768662474308459, "biggest_recent_change": 0.0677601859010224},
{"total_number_of_episodes": 10614, "number_of_timesteps": 1198334, "per_episode_reward": -139.0, "episode_reward_trend_value": 0.0012606812492492736, "biggest_recent_change": 0.0677601859010224},
{"total_number_of_episodes": 10624, "number_of_timesteps": 1199612, "per_episode_reward": -139.1, "episode_reward_trend_value": 0.00015557304621943837, "biggest_recent_change": 0.10061574193900924},
{"total_number_of_episodes": 10634, "number_of_timesteps": 1200813, "per_episode_reward": -139.09, "episode_reward_trend_value": 0.00014509048225256214, "biggest_recent_change": 0.10061574193900924},
{"total_number_of_episodes": 10644, "number_of_timesteps": 1201859, "per_episode_reward": -138.99, "episode_reward_trend_value": 0.0008696665716384031, "biggest_recent_change": 0.1050714608424812},
{"total_number_of_episodes": 10654, "number_of_timesteps": 1202944, "per_episode_reward": -139.01, "episode_reward_trend_value": -0.00012763428619690684, "biggest_recent_change": 0.1050714608424812},
{"total_number_of_episodes": 10665, "number_of_timesteps": 1204526, "per_episode_reward": -138.91, "episode_reward_trend_value": 0.0016431494243884497, "biggest_recent_change": 0.1050714608424812},
{"total_number_of_episodes": 10675, "number_of_timesteps": 1205601, "per_episode_reward": -138.84, "episode_reward_trend_value": 0.002301628394613431, "biggest_recent_change": 0.1050714608424812},
{"total_number_of_episodes": 10685, "number_of_timesteps": 1206738, "per_episode_reward": -138.85, "episode_reward_trend_value": 0.0019591230866397935, "biggest_recent_change": 0.1050714608424812},
{"total_number_of_episodes": 10696, "number_of_timesteps": 1207995, "per_episode_reward": -138.86, "episode_reward_trend_value": 0.001909099166644839, "biggest_recent_change": 0.1050714608424812},
{"total_number_of_episodes": 10706, "number_of_timesteps": 1209071, "per_episode_reward": -138.91, "episode_reward_trend_value": 0.000978746607645083, "biggest_recent_change": 0.1050714608424812},
{"total_number_of_episodes": 10716, "number_of_timesteps": 1209883, "per_episode_reward": -138.85, "episode_reward_trend_value": 0.002817702962315454, "biggest_recent_change": 0.1050714608424812},
{"total_number_of_episodes": 10726, "number_of_timesteps": 1210872, "per_episode_reward": -138.89, "episode_reward_trend_value": 0.002232926352129046, "biggest_recent_change": 0.1050714608424812},
{"total_number_of_episodes": 10736, "number_of_timesteps": 1212135, "per_episode_reward": -138.92, "episode_reward_trend_value": 0.0007339216930855881, "biggest_recent_change": 0.09701886860753461},
{"total_number_of_episodes": 10747, "number_of_timesteps": 1213823, "per_episode_reward": -138.91, "episode_reward_trend_value": 0.0011211769018065827, "biggest_recent_change": 0.09701886860753461},
{"total_number_of_episodes": 10757, "number_of_timesteps": 1214746, "per_episode_reward": -138.84, "episode_reward_trend_value": 0.0007408832530412863, "biggest_recent_change": 0.06626062472020067},
{"total_number_of_episodes": 10767, "number_of_timesteps": 1215582, "per_episode_reward": -138.81, "episode_reward_trend_value": 0.0003898692970286296, "biggest_recent_change": 0.06489032998132416},
{"total_number_of_episodes": 10777, "number_of_timesteps": 1216446, "per_episode_reward": -138.78, "episode_reward_trend_value": 0.0008349467413681724, "biggest_recent_change": 0.06489032998132416},
{"total_number_of_episodes": 10787, "number_of_timesteps": 1217377, "per_episode_reward": -138.72, "episode_reward_trend_value": 0.0014795504111333457, "biggest_recent_change": 0.06489032998132416},
{"total_number_of_episodes": 10797, "number_of_timesteps": 1218457, "per_episode_reward": -139.0, "episode_reward_trend_value": -0.0009486509854784546, "biggest_recent_change": 0.2738618505748889},
{"total_number_of_episodes": 10807, "number_of_timesteps": 1219645, "per_episode_reward": -139.03, "episode_reward_trend_value": -0.002050152601707585, "biggest_recent_change": 0.2738618505748889},
{"total_number_of_episodes": 10818, "number_of_timesteps": 1221110, "per_episode_reward": -139.07, "episode_reward_trend_value": -0.001968148775910726, "biggest_recent_change": 0.2738618505748889},
{"total_number_of_episodes": 10828, "number_of_timesteps": 1222327, "per_episode_reward": -139.07, "episode_reward_trend_value": -0.0017028153934641448, "biggest_recent_change": 0.2738618505748889},
{"total_number_of_episodes": 10838, "number_of_timesteps": 1223763, "per_episode_reward": -139.08, "episode_reward_trend_value": -0.001960905534743536, "biggest_recent_change": 0.2738618505748889},
{"total_number_of_episodes": 10848, "number_of_timesteps": 1224819, "per_episode_reward": -139.07, "episode_reward_trend_value": -0.0024643952196555575, "biggest_recent_change": 0.2738618505748889},
{"total_number_of_episodes": 10858, "number_of_timesteps": 1225887, "per_episode_reward": -139.05, "episode_reward_trend_value": -0.0026908507082718343, "biggest_recent_change": 0.2738618505748889},
{"total_number_of_episodes": 10868, "number_of_timesteps": 1226773, "per_episode_reward": -139.05, "episode_reward_trend_value": -0.0030733552499801436, "biggest_recent_change": 0.2738618505748889},
{"total_number_of_episodes": 10878, "number_of_timesteps": 1227767, "per_episode_reward": -138.98, "episode_reward_trend_value": -0.002879230041283323, "biggest_recent_change": 0.2738618505748889},
{"total_number_of_episodes": 10889, "number_of_timesteps": 1229043, "per_episode_reward": -138.96, "episode_reward_trend_value": 0.00037855886668486014, "biggest_recent_change": 0.07098344626203357},
{"total_number_of_episodes": 10899, "number_of_timesteps": 1231036, "per_episode_reward": -139.0, "episode_reward_trend_value": 0.0003800768471617428, "biggest_recent_change": 0.07098344626203357},
{"total_number_of_episodes": 10909, "number_of_timesteps": 1231943, "per_episode_reward": -138.96, "episode_reward_trend_value": 0.0012364374881185668, "biggest_recent_change": 0.07098344626203357},
{"total_number_of_episodes": 10919, "number_of_timesteps": 1232893, "per_episode_reward": -138.89, "episode_reward_trend_value": 0.0020127487726647867, "biggest_recent_change": 0.07098344626203357},
{"total_number_of_episodes": 10929, "number_of_timesteps": 1234532, "per_episode_reward": -139.15, "episode_reward_trend_value": -0.0007137813738473319, "biggest_recent_change": 0.25575974842050186},
{"total_number_of_episodes": 10939, "number_of_timesteps": 1235633, "per_episode_reward": -139.15, "episode_reward_trend_value": -0.0009839045903832912, "biggest_recent_change": 0.25575974842050186},
{"total_number_of_episodes": 10949, "number_of_timesteps": 1236821, "per_episode_reward": -139.11, "episode_reward_trend_value": -0.0006223313602381115, "biggest_recent_change": 0.25575974842050186},
{"total_number_of_episodes": 10959, "number_of_timesteps": 1238259, "per_episode_reward": -139.1, "episode_reward_trend_value": -0.0005418441511740942, "biggest_recent_change": 0.25575974842050186},
{"total_number_of_episodes": 10969, "number_of_timesteps": 1239795, "per_episode_reward": -139.09, "episode_reward_trend_value": -0.0011709617040486996, "biggest_recent_change": 0.25575974842050186},
{"total_number_of_episodes": 10979, "number_of_timesteps": 1240952, "per_episode_reward": -139.07, "episode_reward_trend_value": -0.00119169814987793, "biggest_recent_change": 0.25575974842050186},
{"total_number_of_episodes": 10989, "number_of_timesteps": 1241918, "per_episode_reward": -139.02, "episode_reward_trend_value": -0.0002893727845357969, "biggest_recent_change": 0.25575974842050186},
{"total_number_of_episodes": 10999, "number_of_timesteps": 1242985, "per_episode_reward": -139.01, "episode_reward_trend_value": -0.0005875693305025859, "biggest_recent_change": 0.25575974842050186},
{"total_number_of_episodes": 11009, "number_of_timesteps": 1244312, "per_episode_reward": -139.06, "episode_reward_trend_value": -0.0018775011892178857, "biggest_recent_change": 0.25575974842050186},
{"total_number_of_episodes": 11020, "number_of_timesteps": 1245649, "per_episode_reward": -139.02, "episode_reward_trend_value": 0.0014339340771534303, "biggest_recent_change": 0.0521848057264549},
{"total_number_of_episodes": 11030, "number_of_timesteps": 1246688, "per_episode_reward": -138.99, "episode_reward_trend_value": 0.0018591253018027172, "biggest_recent_change": 0.0521848057264549},
{"total_number_of_episodes": 11040, "number_of_timesteps": 1248004, "per_episode_reward": -139.01, "episode_reward_trend_value": 0.0010866256124112774, "biggest_recent_change": 0.0521848057264549},
{"total_number_of_episodes": 11050, "number_of_timesteps": 1249067, "per_episode_reward": -139.01, "episode_reward_trend_value": 0.001020342287766122, "biggest_recent_change": 0.0521848057264549},
{"total_number_of_episodes": 11060, "number_of_timesteps": 1250076, "per_episode_reward": -139.0, "episode_reward_trend_value": 0.001024302831506437, "biggest_recent_change": 0.0521848057264549},
{"total_number_of_episodes": 11070, "number_of_timesteps": 1251089, "per_episode_reward": -139.0, "episode_reward_trend_value": 0.0008253084670551894, "biggest_recent_change": 0.0521848057264549},
{"total_number_of_episodes": 11081, "number_of_timesteps": 1252089, "per_episode_reward": -138.98, "episode_reward_trend_value": 0.0005096195472412369, "biggest_recent_change": 0.0521848057264549},
{"total_number_of_episodes": 11091, "number_of_timesteps": 1253119, "per_episode_reward": -138.99, "episode_reward_trend_value": 0.00018252364857542286, "biggest_recent_change": 0.0521848057264549},
{"total_number_of_episodes": 11101, "number_of_timesteps": 1254537, "per_episode_reward": -138.93, "episode_reward_trend_value": 0.001437801519080987, "biggest_recent_change": 0.060790202619045886},
{"total_number_of_episodes": 11111, "number_of_timesteps": 1255710, "per_episode_reward": -138.94, "episode_reward_trend_value": 0.0009193924388070072, "biggest_recent_change": 0.060790202619045886},
{"total_number_of_episodes": 11121, "number_of_timesteps": 1256825, "per_episode_reward": -138.94, "episode_reward_trend_value": 0.0005608151331810202, "biggest_recent_change": 0.060790202619045886},
{"total_number_of_episodes": 11132, "number_of_timesteps": 1258165, "per_episode_reward": -138.88, "episode_reward_trend_value": 0.0014092409762030103, "biggest_recent_change": 0.060790202619045886},
{"total_number_of_episodes": 11142, "number_of_timesteps": 1259598, "per_episode_reward": -138.87, "episode_reward_trend_value": 0.001528256918263398, "biggest_recent_change": 0.060790202619045886},
{"total_number_of_episodes": 11152, "number_of_timesteps": 1261040, "per_episode_reward": -138.91, "episode_reward_trend_value": 0.0009308516415223444, "biggest_recent_change": 0.060790202619045886},
{"total_number_of_episodes": 11162, "number_of_timesteps": 1262208, "per_episode_reward": -138.86, "episode_reward_trend_value": 0.0015185052978498308, "biggest_recent_change": 0.060790202619045886},
{"total_number_of_episodes": 11172, "number_of_timesteps": 1263336, "per_episode_reward": -138.97, "episode_reward_trend_value": 0.00010294258299362961, "biggest_recent_change": 0.1087115614759},
{"total_number_of_episodes": 11182, "number_of_timesteps": 1264464, "per_episode_reward": -139.05, "episode_reward_trend_value": -0.0006047466951378687, "biggest_recent_change": 0.1087115614759},
{"total_number_of_episodes": 11192, "number_of_timesteps": 1265729, "per_episode_reward": -139.06, "episode_reward_trend_value": -0.0013835290098029418, "biggest_recent_change": 0.1087115614759},
{"total_number_of_episodes": 11204, "number_of_timesteps": 1267174, "per_episode_reward": -139.06, "episode_reward_trend_value": -0.0013269546372372235, "biggest_recent_change": 0.1087115614759},
{"total_number_of_episodes": 11215, "number_of_timesteps": 1268342, "per_episode_reward": -139.04, "episode_reward_trend_value": -0.001107061912374421, "biggest_recent_change": 0.1087115614759},
{"total_number_of_episodes": 11225, "number_of_timesteps": 1269558, "per_episode_reward": -139.06, "episode_reward_trend_value": -0.00196393245771939, "biggest_recent_change": 0.1087115614759},
{"total_number_of_episodes": 11236, "number_of_timesteps": 1270385, "per_episode_reward": -138.99, "episode_reward_trend_value": -0.0012533715995724985, "biggest_recent_change": 0.1087115614759},
{"total_number_of_episodes": 11247, "number_of_timesteps": 1271420, "per_episode_reward": -139.02, "episode_reward_trend_value": -0.0011442490977597371, "biggest_recent_change": 0.1087115614759},
{"total_number_of_episodes": 11259, "number_of_timesteps": 1273231, "per_episode_reward": -139.04, "episode_reward_trend_value": -0.001956824809532678, "biggest_recent_change": 0.1087115614759},
{"total_number_of_episodes": 11272, "number_of_timesteps": 1274552, "per_episode_reward": -139.01, "episode_reward_trend_value": -0.00048453387960560373, "biggest_recent_change": 0.07841135047178227},
{"total_number_of_episodes": 11283, "number_of_timesteps": 1275309, "per_episode_reward": -138.92, "episode_reward_trend_value": 0.0014191241163325054, "biggest_recent_change": 0.09291786916264755},
{"total_number_of_episodes": 11293, "number_of_timesteps": 1276185, "per_episode_reward": -138.9, "episode_reward_trend_value": 0.001738239623630812, "biggest_recent_change": 0.09291786916264755},
{"total_number_of_episodes": 11303, "number_of_timesteps": 1277157, "per_episode_reward": -138.89, "episode_reward_trend_value": 0.001892090859128517, "biggest_recent_change": 0.09291786916264755},
{"total_number_of_episodes": 11313, "number_of_timesteps": 1278134, "per_episode_reward": -138.8, "episode_reward_trend_value": 0.0026195197716336652, "biggest_recent_change": 0.09291786916264755},
{"total_number_of_episodes": 11323, "number_of_timesteps": 1279219, "per_episode_reward": -138.92, "episode_reward_trend_value": 0.0015751489078787192, "biggest_recent_change": 0.11744840757557995},
{"total_number_of_episodes": 11333, "number_of_timesteps": 1280798, "per_episode_reward": -138.85, "episode_reward_trend_value": 0.001459506542520709, "biggest_recent_change": 0.11744840757557995},
{"total_number_of_episodes": 11343, "number_of_timesteps": 1282007, "per_episode_reward": -138.88, "episode_reward_trend_value": 0.0014631514800211361, "biggest_recent_change": 0.11744840757557995},
{"total_number_of_episodes": 11353, "number_of_timesteps": 1283594, "per_episode_reward": -138.84, "episode_reward_trend_value": 0.002136078513004236, "biggest_recent_change": 0.11744840757557995},
{"total_number_of_episodes": 11364, "number_of_timesteps": 1285174, "per_episode_reward": -138.89, "episode_reward_trend_value": 0.0013423562297137752, "biggest_recent_change": 0.11744840757557995},
{"total_number_of_episodes": 11374, "number_of_timesteps": 1286350, "per_episode_reward": -138.86, "episode_reward_trend_value": 0.0006261466350088717, "biggest_recent_change": 0.11744840757557995},
{"total_number_of_episodes": 11384, "number_of_timesteps": 1287082, "per_episode_reward": -138.84, "episode_reward_trend_value": 0.0007189990882459875, "biggest_recent_change": 0.11744840757557995},
{"total_number_of_episodes": 11394, "number_of_timesteps": 1287887, "per_episode_reward": -138.83, "episode_reward_trend_value": 0.0006257201032165464, "biggest_recent_change": 0.11744840757557995},
{"total_number_of_episodes": 11404, "number_of_timesteps": 1288834, "per_episode_reward": -138.71, "episode_reward_trend_value": 0.0009981964830239399, "biggest_recent_change": 0.11794435334621767},
{"total_number_of_episodes": 11416, "number_of_timesteps": 1290038, "per_episode_reward": -138.6, "episode_reward_trend_value": 0.0035110862543139853, "biggest_recent_change": 0.11794435334621767},
{"total_number_of_episodes": 11426, "number_of_timesteps": 1291069, "per_episode_reward": -138.55, "episode_reward_trend_value": 0.003335882859390912, "biggest_recent_change": 0.11794435334621767},
{"total_number_of_episodes": 11436, "number_of_timesteps": 1292220, "per_episode_reward": -138.44, "episode_reward_trend_value": 0.004982627639041147, "biggest_recent_change": 0.11930894023996075},
{"total_number_of_episodes": 11446, "number_of_timesteps": 1293030, "per_episode_reward": -138.39, "episode_reward_trend_value": 0.005018434114148186, "biggest_recent_change": 0.11930894023996075},
{"total_number_of_episodes": 11456, "number_of_timesteps": 1293937, "per_episode_reward": -138.25, "episode_reward_trend_value": 0.007178402355698823, "biggest_recent_change": 0.1467567584609526},
{"total_number_of_episodes": 11467, "number_of_timesteps": 1295562, "per_episode_reward": -138.31, "episode_reward_trend_value": 0.00614794288720696, "biggest_recent_change": 0.1467567584609526},
{"total_number_of_episodes": 11477, "number_of_timesteps": 1296738, "per_episode_reward": -138.49, "episode_reward_trend_value": 0.0038485700173222564, "biggest_recent_change": 0.17916664754224598},
{"total_number_of_episodes": 11487, "number_of_timesteps": 1297896, "per_episode_reward": -138.6, "episode_reward_trend_value": 0.0024913417895574084, "biggest_recent_change": 0.17916664754224598},
{"total_number_of_episodes": 11497, "number_of_timesteps": 1298646, "per_episode_reward": -138.4, "episode_reward_trend_value": 0.003506123966399678, "biggest_recent_change": 0.20927474926202194},
{"total_number_of_episodes": 11507, "number_of_timesteps": 1299475, "per_episode_reward": -138.32, "episode_reward_trend_value": 0.0031159073050616827, "biggest_recent_change": 0.20927474926202194},
{"total_number_of_episodes": 11517, "number_of_timesteps": 1300343, "per_episode_reward": -138.22, "episode_reward_trend_value": 0.003671205090818338, "biggest_recent_change": 0.20927474926202194},
{"total_number_of_episodes": 11527, "number_of_timesteps": 1301407, "per_episode_reward": -138.23, "episode_reward_trend_value": 0.0022555529058274084, "biggest_recent_change": 0.20927474926202194},
{"total_number_of_episodes": 11537, "number_of_timesteps": 1303202, "per_episode_reward": -138.22, "episode_reward_trend_value": 0.001950196591021975, "biggest_recent_change": 0.20927474926202194},
{"total_number_of_episodes": 11547, "number_of_timesteps": 1304586, "per_episode_reward": -138.36, "episode_reward_trend_value": -0.0012949159721933434, "biggest_recent_change": 0.20927474926202194},
{"total_number_of_episodes": 11557, "number_of_timesteps": 1306008, "per_episode_reward": -138.42, "episode_reward_trend_value": -0.0012501120393314598, "biggest_recent_change": 0.20927474926202194},
{"total_number_of_episodes": 11567, "number_of_timesteps": 1307267, "per_episode_reward": -138.37, "episode_reward_trend_value": 0.001285774211229788, "biggest_recent_change": 0.20927474926202194},
{"total_number_of_episodes": 11577, "number_of_timesteps": 1308645, "per_episode_reward": -138.44, "episode_reward_trend_value": 0.0018718137955314913, "biggest_recent_change": 0.20927474926202194},
{"total_number_of_episodes": 11587, "number_of_timesteps": 1309836, "per_episode_reward": -138.41, "episode_reward_trend_value": -0.0001286957773714903, "biggest_recent_change": 0.14530337222842604},
{"total_number_of_episodes": 11597, "number_of_timesteps": 1311143, "per_episode_reward": -138.45, "episode_reward_trend_value": -0.0014066950315989543, "biggest_recent_change": 0.14530337222842604},
{"total_number_of_episodes": 11607, "number_of_timesteps": 1312368, "per_episode_reward": -138.42, "episode_reward_trend_value": -0.0021420714370239896, "biggest_recent_change": 0.14530337222842604},
{"total_number_of_episodes": 11618, "number_of_timesteps": 1313674, "per_episode_reward": -138.4, "episode_reward_trend_value": -0.0018781962886533974, "biggest_recent_change": 0.14530337222842604},
{"total_number_of_episodes": 11628, "number_of_timesteps": 1314634, "per_episode_reward": -138.39, "episode_reward_trend_value": -0.001897951239977955, "biggest_recent_change": 0.14530337222842604},
{"total_number_of_episodes": 11638, "number_of_timesteps": 1315565, "per_episode_reward": -138.27, "episode_reward_trend_value": 0.0010032546806703142, "biggest_recent_change": 0.11580516062991819},
{"total_number_of_episodes": 11648, "number_of_timesteps": 1317026, "per_episode_reward": -138.45, "episode_reward_trend_value": -0.00031424087723179483, "biggest_recent_change": 0.1788245927786818},
{"total_number_of_episodes": 11658, "number_of_timesteps": 1318426, "per_episode_reward": -138.38, "episode_reward_trend_value": -0.00011047178537984968, "biggest_recent_change": 0.1788245927786818},
{"total_number_of_episodes": 11668, "number_of_timesteps": 1319554, "per_episode_reward": -138.26, "episode_reward_trend_value": 0.0019189140757478954, "biggest_recent_change": 0.1788245927786818},
{"total_number_of_episodes": 11678, "number_of_timesteps": 1320611, "per_episode_reward": -138.47, "episode_reward_trend_value": -0.0007508360459663916, "biggest_recent_change": 0.21104862325353224},
{"total_number_of_episodes": 11688, "number_of_timesteps": 1321923, "per_episode_reward": -138.52, "episode_reward_trend_value": -0.0007779895349446836, "biggest_recent_change": 0.21104862325353224},
{"total_number_of_episodes": 11698, "number_of_timesteps": 1322819, "per_episode_reward": -138.31, "episode_reward_trend_value": 0.001157874911738885, "biggest_recent_change": 0.21104862325353224},
{"total_number_of_episodes": 11709, "number_of_timesteps": 1324007, "per_episode_reward": -138.54, "episode_reward_trend_value": -0.0015006805117091441, "biggest_recent_change": 0.22362098116619222},
{"total_number_of_episodes": 11719, "number_of_timesteps": 1325186, "per_episode_reward": -138.66, "episode_reward_trend_value": -0.0030274687701074125, "biggest_recent_change": 0.22362098116619222},
{"total_number_of_episodes": 11729, "number_of_timesteps": 1326293, "per_episode_reward": -138.67, "episode_reward_trend_value": -0.004424871817200129, "biggest_recent_change": 0.22362098116619222},
{"total_number_of_episodes": 11740, "number_of_timesteps": 1328021, "per_episode_reward": -138.6, "episode_reward_trend_value": -0.0016812645451526325, "biggest_recent_change": 0.22362098116619222},
{"total_number_of_episodes": 11750, "number_of_timesteps": 1328913, "per_episode_reward": -138.6, "episode_reward_trend_value": -0.002394766965084551, "biggest_recent_change": 0.22362098116619222},
{"total_number_of_episodes": 11760, "number_of_timesteps": 1329925, "per_episode_reward": -138.52, "episode_reward_trend_value": -0.0029036966119317894, "biggest_recent_change": 0.22362098116619222},
{"total_number_of_episodes": 11770, "number_of_timesteps": 1331110, "per_episode_reward": -138.57, "episode_reward_trend_value": -0.0010506875221737901, "biggest_recent_change": 0.22362098116619222},
{"total_number_of_episodes": 11780, "number_of_timesteps": 1332296, "per_episode_reward": -138.65, "episode_reward_trend_value": -0.0014962093873091616, "biggest_recent_change": 0.22362098116619222},
{"total_number_of_episodes": 11790, "number_of_timesteps": 1333467, "per_episode_reward": -138.59, "episode_reward_trend_value": -0.003031181670906828, "biggest_recent_change": 0.22362098116619222},
{"total_number_of_episodes": 11801, "number_of_timesteps": 1334724, "per_episode_reward": -138.64, "episode_reward_trend_value": -0.001146156847591505, "biggest_recent_change": 0.12356454825251717},
{"total_number_of_episodes": 11811, "number_of_timesteps": 1336079, "per_episode_reward": -138.64, "episode_reward_trend_value": 0.00016632633519072392, "biggest_recent_change": 0.08396854243059693},
{"total_number_of_episodes": 11821, "number_of_timesteps": 1337502, "per_episode_reward": -138.66, "episode_reward_trend_value": 5.832045569794294e-05, "biggest_recent_change": 0.08396854243059693},
{"total_number_of_episodes": 11831, "number_of_timesteps": 1338465, "per_episode_reward": -138.58, "episode_reward_trend_value": 0.0002346369081976718, "biggest_recent_change": 0.08396854243059693},
{"total_number_of_episodes": 11841, "number_of_timesteps": 1339416, "per_episode_reward": -138.58, "episode_reward_trend_value": 0.0001992245139635745, "biggest_recent_change": 0.08396854243059693},
{"total_number_of_episodes": 11851, "number_of_timesteps": 1340592, "per_episode_reward": -138.49, "episode_reward_trend_value": 0.0003334850681268462, "biggest_recent_change": 0.0856733356495738},
{"total_number_of_episodes": 11861, "number_of_timesteps": 1341554, "per_episode_reward": -138.45, "episode_reward_trend_value": 0.00131274753113928, "biggest_recent_change": 0.0856733356495738},
{"total_number_of_episodes": 11871, "number_of_timesteps": 1342690, "per_episode_reward": -138.44, "episode_reward_trend_value": 0.0023349387380840704, "biggest_recent_change": 0.0856733356495738},
{"total_number_of_episodes": 11881, "number_of_timesteps": 1343687, "per_episode_reward": -138.39, "episode_reward_trend_value": 0.0022219949585550896, "biggest_recent_change": 0.0856733356495738},
{"total_number_of_episodes": 11891, "number_of_timesteps": 1344601, "per_episode_reward": -138.38, "episode_reward_trend_value": 0.0029301622535510006, "biggest_recent_change": 0.0856733356495738},
{"total_number_of_episodes": 11901, "number_of_timesteps": 1345528, "per_episode_reward": -138.33, "episode_reward_trend_value": 0.003467834639327331, "biggest_recent_change": 0.0856733356495738},
{"total_number_of_episodes": 11911, "number_of_timesteps": 1346552, "per_episode_reward": -138.31, "episode_reward_trend_value": 0.003975597939140761, "biggest_recent_change": 0.0856733356495738},
{"total_number_of_episodes": 11921, "number_of_timesteps": 1347459, "per_episode_reward": -138.18, "episode_reward_trend_value": 0.004453806118966478, "biggest_recent_change": 0.12700727861488303},
{"total_number_of_episodes": 11931, "number_of_timesteps": 1348665, "per_episode_reward": -138.34, "episode_reward_trend_value": 0.002718754301715699, "biggest_recent_change": 0.15615466355257013},
{"total_number_of_episodes": 11942, "number_of_timesteps": 1349964, "per_episode_reward": -138.31, "episode_reward_trend_value": 0.0020947360386180157, "biggest_recent_change": 0.15615466355257013},
{"total_number_of_episodes": 11952, "number_of_timesteps": 1350848, "per_episode_reward": -138.28, "episode_reward_trend_value": 0.0018764857161231575, "biggest_recent_change": 0.15615466355257013},
{"total_number_of_episodes": 11962, "number_of_timesteps": 1351674, "per_episode_reward": -138.22, "episode_reward_trend_value": 0.00251196255616277, "biggest_recent_change": 0.15615466355257013},
{"total_number_of_episodes": 11972, "number_of_timesteps": 1352523, "per_episode_reward": -138.02, "episode_reward_trend_value": 0.004078624305714129, "biggest_recent_change": 0.19854419459190353},
{"total_number_of_episodes": 11983, "number_of_timesteps": 1354012, "per_episode_reward": -137.98, "episode_reward_trend_value": 0.0044326994582721425, "biggest_recent_change": 0.19854419459190353},
{"total_number_of_episodes": 11993, "number_of_timesteps": 1354985, "per_episode_reward": -137.91, "episode_reward_trend_value": 0.0047076390911841935, "biggest_recent_change": 0.19854419459190353},
{"total_number_of_episodes": 12003, "number_of_timesteps": 1356839, "per_episode_reward": -137.99, "episode_reward_trend_value": 0.0034700386514957575, "biggest_recent_change": 0.19854419459190353},
{"total_number_of_episodes": 12013, "number_of_timesteps": 1358001, "per_episode_reward": -137.91, "episode_reward_trend_value": 0.0030389463609559976, "biggest_recent_change": 0.19854419459190353},
{"total_number_of_episodes": 12023, "number_of_timesteps": 1359076, "per_episode_reward": -137.93, "episode_reward_trend_value": 0.004547999563263577, "biggest_recent_change": 0.19854419459190353},
{"total_number_of_episodes": 12033, "number_of_timesteps": 1360294, "per_episode_reward": -138.08, "episode_reward_trend_value": 0.002518959609549635, "biggest_recent_change": 0.19854419459190353},
{"total_number_of_episodes": 12043, "number_of_timesteps": 1361602, "per_episode_reward": -138.08, "episode_reward_trend_value": 0.0022116310875898333, "biggest_recent_change": 0.19854419459190353},
{"total_number_of_episodes": 12053, "number_of_timesteps": 1363048, "per_episode_reward": -137.98, "episode_reward_trend_value": 0.0026407084321075696, "biggest_recent_change": 0.19854419459190353},
{"total_number_of_episodes": 12064, "number_of_timesteps": 1364141, "per_episode_reward": -137.98, "episode_reward_trend_value": 0.00038484474076483366, "biggest_recent_change": 0.15310190386347244},
{"total_number_of_episodes": 12074, "number_of_timesteps": 1365169, "per_episode_reward": -138.01, "episode_reward_trend_value": -0.00038385694117361405, "biggest_recent_change": 0.15310190386347244},
{"total_number_of_episodes": 12085, "number_of_timesteps": 1366612, "per_episode_reward": -138.06, "episode_reward_trend_value": -0.0017149905288827466, "biggest_recent_change": 0.15310190386347244},
{"total_number_of_episodes": 12095, "number_of_timesteps": 1368103, "per_episode_reward": -138.01, "episode_reward_trend_value": -0.00019293010689630643, "biggest_recent_change": 0.15310190386347244},
{"total_number_of_episodes": 12105, "number_of_timesteps": 1369240, "per_episode_reward": -137.87, "episode_reward_trend_value": 0.00042270413450909113, "biggest_recent_change": 0.15310190386347244},
{"total_number_of_episodes": 12115, "number_of_timesteps": 1370413, "per_episode_reward": -138.04, "episode_reward_trend_value": -0.001282530630792975, "biggest_recent_change": 0.17381100422207396},
{"total_number_of_episodes": 12125, "number_of_timesteps": 1371672, "per_episode_reward": -138.05, "episode_reward_trend_value": 0.00028329074280324877, "biggest_recent_change": 0.17381100422207396},
{"total_number_of_episodes": 12137, "number_of_timesteps": 1372594, "per_episode_reward": -137.9, "episode_reward_trend_value": 0.002014482058244956, "biggest_recent_change": 0.17381100422207396},
{"total_number_of_episodes": 12148, "number_of_timesteps": 1373640, "per_episode_reward": -137.74, "episode_reward_trend_value": 0.0026561001469408057, "biggest_recent_change": 0.17381100422207396},
{"total_number_of_episodes": 12158, "number_of_timesteps": 1374547, "per_episode_reward": -137.66, "episode_reward_trend_value": 0.0035507792337253047, "biggest_recent_change": 0.17381100422207396},
{"total_number_of_episodes": 12168, "number_of_timesteps": 1375573, "per_episode_reward": -137.65, "episode_reward_trend_value": 0.004023541493755703, "biggest_recent_change": 0.17381100422207396},
{"total_number_of_episodes": 12179, "number_of_timesteps": 1377216, "per_episode_reward": -137.83, "episode_reward_trend_value": 0.0025796411390940775, "biggest_recent_change": 0.18205903493353048},
{"total_number_of_episodes": 12189, "number_of_timesteps": 1378708, "per_episode_reward": -137.8, "episode_reward_trend_value": 0.002319804713986034, "biggest_recent_change": 0.18205903493353048},
{"total_number_of_episodes": 12199, "number_of_timesteps": 1379771, "per_episode_reward": -137.73, "episode_reward_trend_value": 0.0015445887484102313, "biggest_recent_change": 0.18205903493353048},
{"total_number_of_episodes": 12209, "number_of_timesteps": 1380768, "per_episode_reward": -137.82, "episode_reward_trend_value": 0.0024834458962730978, "biggest_recent_change": 0.18205903493353048},
{"total_number_of_episodes": 12220, "number_of_timesteps": 1382018, "per_episode_reward": -137.91, "episode_reward_trend_value": 0.001605394032263992, "biggest_recent_change": 0.18205903493353048},
{"total_number_of_episodes": 12230, "number_of_timesteps": 1383468, "per_episode_reward": -137.85, "episode_reward_trend_value": 0.0005591348262887171, "biggest_recent_change": 0.18205903493353048},
{"total_number_of_episodes": 12240, "number_of_timesteps": 1384552, "per_episode_reward": -137.76, "episode_reward_trend_value": -0.00022908659610310325, "biggest_recent_change": 0.18205903493353048},
{"total_number_of_episodes": 12250, "number_of_timesteps": 1385658, "per_episode_reward": -137.8, "episode_reward_trend_value": -0.0015142095238938206, "biggest_recent_change": 0.18205903493353048},
{"total_number_of_episodes": 12261, "number_of_timesteps": 1386760, "per_episode_reward": -137.73, "episode_reward_trend_value": -0.0008882135281611328, "biggest_recent_change": 0.18205903493353048},
{"total_number_of_episodes": 12271, "number_of_timesteps": 1387828, "per_episode_reward": -137.74, "episode_reward_trend_value": 0.0009680143573190334, "biggest_recent_change": 0.09120264800063183},
{"total_number_of_episodes": 12281, "number_of_timesteps": 1388738, "per_episode_reward": -137.69, "episode_reward_trend_value": 0.0012306653361419094, "biggest_recent_change": 0.09120264800063183},
{"total_number_of_episodes": 12291, "number_of_timesteps": 1389953, "per_episode_reward": -137.72, "episode_reward_trend_value": 0.00014780892290136512, "biggest_recent_change": 0.09120264800063183},
{"total_number_of_episodes": 12301, "number_of_timesteps": 1391366, "per_episode_reward": -137.86, "episode_reward_trend_value": -0.00046942035317461733, "biggest_recent_change": 0.14486449576125437},
{"total_number_of_episodes": 12311, "number_of_timesteps": 1392333, "per_episode_reward": -137.85, "episode_reward_trend_value": 0.0006632976492382013, "biggest_recent_change": 0.14486449576125437},
{"total_number_of_episodes": 12321, "number_of_timesteps": 1393798, "per_episode_reward": -137.83, "episode_reward_trend_value": 0.00026877980328094965, "biggest_recent_change": 0.14486449576125437},
{"total_number_of_episodes": 12331, "number_of_timesteps": 1395056, "per_episode_reward": -137.92, "episode_reward_trend_value": -0.0017422805290762098, "biggest_recent_change": 0.14486449576125437},
{"total_number_of_episodes": 12341, "number_of_timesteps": 1396161, "per_episode_reward": -137.83, "episode_reward_trend_value": -0.00031196154835129165, "biggest_recent_change": 0.14486449576125437},
{"total_number_of_episodes": 12351, "number_of_timesteps": 1397436, "per_episode_reward": -137.9, "episode_reward_trend_value": -0.0019311886614821736, "biggest_recent_change": 0.14486449576125437},
{"total_number_of_episodes": 12361, "number_of_timesteps": 1398545, "per_episode_reward": -137.87, "episode_reward_trend_value": -0.0013701536951963868, "biggest_recent_change": 0.14486449576125437},
{"total_number_of_episodes": 12371, "number_of_timesteps": 1399681, "per_episode_reward": -137.82, "episode_reward_trend_value": -0.0014227214743499418, "biggest_recent_change": 0.14486449576125437},
{"total_number_of_episodes": 12381, "number_of_timesteps": 1400809, "per_episode_reward": -137.74, "episode_reward_trend_value": -0.0002647016361692067, "biggest_recent_change": 0.14486449576125437},
{"total_number_of_episodes": 12391, "number_of_timesteps": 1402122, "per_episode_reward": -137.8, "episode_reward_trend_value": 0.0006701631532106628, "biggest_recent_change": 0.09035118714018608},
{"total_number_of_episodes": 12402, "number_of_timesteps": 1403856, "per_episode_reward": -137.75, "episode_reward_trend_value": 0.0011253152357637772, "biggest_recent_change": 0.09035118714018608},
{"total_number_of_episodes": 12413, "number_of_timesteps": 1405134, "per_episode_reward": -137.78, "episode_reward_trend_value": 0.0005438288100041038, "biggest_recent_change": 0.09035118714018608},
{"total_number_of_episodes": 12423, "number_of_timesteps": 1406689, "per_episode_reward": -137.82, "episode_reward_trend_value": 0.0010491839122172071, "biggest_recent_change": 0.08910522494574025},
{"total_number_of_episodes": 12433, "number_of_timesteps": 1407520, "per_episode_reward": -137.71, "episode_reward_trend_value": 0.0013078087833059094, "biggest_recent_change": 0.11238146334372345},
{"total_number_of_episodes": 12443, "number_of_timesteps": 1408651, "per_episode_reward": -137.67, "episode_reward_trend_value": 0.002637700946561318, "biggest_recent_change": 0.11238146334372345},
{"total_number_of_episodes": 12453, "number_of_timesteps": 1409900, "per_episode_reward": -137.69, "episode_reward_trend_value": 0.0020071383194337814, "biggest_recent_change": 0.11238146334372345},
{"total_number_of_episodes": 12463, "number_of_timesteps": 1411333, "per_episode_reward": -137.67, "episode_reward_trend_value": 0.0017188788354799399, "biggest_recent_change": 0.11238146334372345},
{"total_number_of_episodes": 12474, "number_of_timesteps": 1412608, "per_episode_reward": -137.72, "episode_reward_trend_value": 0.0001833732763262535, "biggest_recent_change": 0.11238146334372345},
{"total_number_of_episodes": 12484, "number_of_timesteps": 1413804, "per_episode_reward": -137.66, "episode_reward_trend_value": 0.0015712034406634404, "biggest_recent_change": 0.11238146334372345},
{"total_number_of_episodes": 12495, "number_of_timesteps": 1415069, "per_episode_reward": -137.8, "episode_reward_trend_value": -0.0005885397960415478, "biggest_recent_change": 0.1426712316571468},
{"total_number_of_episodes": 12505, "number_of_timesteps": 1416334, "per_episode_reward": -137.77, "episode_reward_trend_value": 0.0001407008305878637, "biggest_recent_change": 0.1426712316571468},
{"total_number_of_episodes": 12516, "number_of_timesteps": 1417761, "per_episode_reward": -137.7, "episode_reward_trend_value": 0.0013220058463281879, "biggest_recent_change": 0.1426712316571468},
{"total_number_of_episodes": 12526, "number_of_timesteps": 1418957, "per_episode_reward": -137.73, "episode_reward_trend_value": -0.00022530812276373683, "biggest_recent_change": 0.1426712316571468},
{"total_number_of_episodes": 12536, "number_of_timesteps": 1419933, "per_episode_reward": -137.67, "episode_reward_trend_value": -2.8230726978348585e-05, "biggest_recent_change": 0.1426712316571468},
{"total_number_of_episodes": 12546, "number_of_timesteps": 1420995, "per_episode_reward": -137.67, "episode_reward_trend_value": 0.00018175120837327086, "biggest_recent_change": 0.1426712316571468},
{"total_number_of_episodes": 12556, "number_of_timesteps": 1422134, "per_episode_reward": -137.58, "episode_reward_trend_value": 0.0009447877059020331, "biggest_recent_change": 0.1426712316571468},
{"total_number_of_episodes": 12566, "number_of_timesteps": 1423366, "per_episode_reward": -137.62, "episode_reward_trend_value": 0.001137925283505423, "biggest_recent_change": 0.1426712316571468},
{"total_number_of_episodes": 12577, "number_of_timesteps": 1424746, "per_episode_reward": -137.72, "episode_reward_trend_value": -0.0006227344359258623, "biggest_recent_change": 0.1426712316571468},
{"total_number_of_episodes": 12587, "number_of_timesteps": 1426140, "per_episode_reward": -137.72, "episode_reward_trend_value": 0.0008966595247462313, "biggest_recent_change": 0.09428132467553496},
{"total_number_of_episodes": 12597, "number_of_timesteps": 1427043, "per_episode_reward": -137.59, "episode_reward_trend_value": 0.0019330835629062903, "biggest_recent_change": 0.1292670457233953},
{"total_number_of_episodes": 12607, "number_of_timesteps": 1427777, "per_episode_reward": -137.46, "episode_reward_trend_value": 0.002673612176670935, "biggest_recent_change": 0.1292670457233953},
{"total_number_of_episodes": 12618, "number_of_timesteps": 1428957, "per_episode_reward": -137.4, "episode_reward_trend_value": 0.0036961876885303327, "biggest_recent_change": 0.1292670457233953},
{"total_number_of_episodes": 12628, "number_of_timesteps": 1430145, "per_episode_reward": -137.58, "episode_reward_trend_value": 0.0010307591441766641, "biggest_recent_change": 0.17685358400368045},
{"total_number_of_episodes": 12638, "number_of_timesteps": 1431617, "per_episode_reward": -137.48, "episode_reward_trend_value": 0.0020645231704223633, "biggest_recent_change": 0.17685358400368045},
{"total_number_of_episodes": 12648, "number_of_timesteps": 1432849, "per_episode_reward": -137.41, "episode_reward_trend_value": 0.0019162557569997161, "biggest_recent_change": 0.17685358400368045},
{"total_number_of_episodes": 12658, "number_of_timesteps": 1434036, "per_episode_reward": -137.31, "episode_reward_trend_value": 0.0034074259825666157, "biggest_recent_change": 0.17685358400368045},
{"total_number_of_episodes": 12669, "number_of_timesteps": 1435518, "per_episode_reward": -137.22, "episode_reward_trend_value": 0.005552354522557342, "biggest_recent_change": 0.17685358400368045},
{"total_number_of_episodes": 12679, "number_of_timesteps": 1436494, "per_episode_reward": -137.22, "episode_reward_trend_value": 0.005585138595658792, "biggest_recent_change": 0.17685358400368045},
{"total_number_of_episodes": 12689, "number_of_timesteps": 1437785, "per_episode_reward": -137.31, "episode_reward_trend_value": 0.0030843036775678456, "biggest_recent_change": 0.17685358400368045},
{"total_number_of_episodes": 12699, "number_of_timesteps": 1438939, "per_episode_reward": -137.4, "episode_reward_trend_value": 0.00069622487754278, "biggest_recent_change": 0.17685358400368045},
{"total_number_of_episodes": 12709, "number_of_timesteps": 1440221, "per_episode_reward": -137.39, "episode_reward_trend_value": 0.00013692871147681114, "biggest_recent_change": 0.17685358400368045},
{"total_number_of_episodes": 12719, "number_of_timesteps": 1441381, "per_episode_reward": -137.37, "episode_reward_trend_value": 0.002320510673069975, "biggest_recent_change": 0.09876224392363042},
{"total_number_of_episodes": 12729, "number_of_timesteps": 1442251, "per_episode_reward": -137.32, "episode_reward_trend_value": 0.0018256480348377915, "biggest_recent_change": 0.09876224392363042},
{"total_number_of_episodes": 12739, "number_of_timesteps": 1443371, "per_episode_reward": -137.34, "episode_reward_trend_value": 0.000767310669130931, "biggest_recent_change": 0.09876224392363042},
{"total_number_of_episodes": 12749, "number_of_timesteps": 1444521, "per_episode_reward": -137.15, "episode_reward_trend_value": 0.001814849226979239, "biggest_recent_change": 0.18828199770342735},
{"total_number_of_episodes": 12760, "number_of_timesteps": 1445492, "per_episode_reward": -137.14, "episode_reward_trend_value": 0.0007853964819983302, "biggest_recent_change": 0.18828199770342735},
{"total_number_of_episodes": 12770, "number_of_timesteps": 1446760, "per_episode_reward": -137.17, "episode_reward_trend_value": 0.0005780000813211296, "biggest_recent_change": 0.18828199770342735},
{"total_number_of_episodes": 12781, "number_of_timesteps": 1448017, "per_episode_reward": -137.18, "episode_reward_trend_value": 0.0015113168172951595, "biggest_recent_change": 0.18828199770342735},
{"total_number_of_episodes": 12791, "number_of_timesteps": 1449113, "per_episode_reward": -137.27, "episode_reward_trend_value": 0.0014239145359027817, "biggest_recent_change": 0.18828199770342735},
{"total_number_of_episodes": 12802, "number_of_timesteps": 1450513, "per_episode_reward": -137.26, "episode_reward_trend_value": 0.00136782207319786, "biggest_recent_change": 0.18828199770342735},
{"total_number_of_episodes": 12812, "number_of_timesteps": 1451530, "per_episode_reward": -137.24, "episode_reward_trend_value": 0.0014368142747504939, "biggest_recent_change": 0.18828199770342735},
{"total_number_of_episodes": 12823, "number_of_timesteps": 1452508, "per_episode_reward": -137.22, "episode_reward_trend_value": 0.0011696624629495191, "biggest_recent_change": 0.18828199770342735},
{"total_number_of_episodes": 12833, "number_of_timesteps": 1453428, "per_episode_reward": -137.16, "episode_reward_trend_value": 0.0019902556407493596, "biggest_recent_change": 0.18828199770342735},
{"total_number_of_episodes": 12843, "number_of_timesteps": 1454267, "per_episode_reward": -137.06, "episode_reward_trend_value": 0.00095897181091118, "biggest_recent_change": 0.09546645301799117},
{"total_number_of_episodes": 12853, "number_of_timesteps": 1455347, "per_episode_reward": -137.07, "episode_reward_trend_value": 0.0008586980003713052, "biggest_recent_change": 0.09546645301799117},
{"total_number_of_episodes": 12863, "number_of_timesteps": 1456630, "per_episode_reward": -137.12, "episode_reward_trend_value": 0.0005318601571805933, "biggest_recent_change": 0.09546645301799117},
{"total_number_of_episodes": 12873, "number_of_timesteps": 1457888, "per_episode_reward": -137.15, "episode_reward_trend_value": 0.000309820401628258, "biggest_recent_change": 0.09546645301799117},
{"total_number_of_episodes": 12883, "number_of_timesteps": 1458673, "per_episode_reward": -137.06, "episode_reward_trend_value": 0.0024092713491705177, "biggest_recent_change": 0.09546645301799117},
{"total_number_of_episodes": 12893, "number_of_timesteps": 1459501, "per_episode_reward": -136.98, "episode_reward_trend_value": 0.0031300472234114017, "biggest_recent_change": 0.09546645301799117},
{"total_number_of_episodes": 12903, "number_of_timesteps": 1460400, "per_episode_reward": -136.88, "episode_reward_trend_value": 0.0039580577581145035, "biggest_recent_change": 0.1003990388027205},
{"total_number_of_episodes": 12914, "number_of_timesteps": 1461617, "per_episode_reward": -136.96, "episode_reward_trend_value": 0.002873702331462861, "biggest_recent_change": 0.1003990388027205},
{"total_number_of_episodes": 12924, "number_of_timesteps": 1462928, "per_episode_reward": -136.99, "episode_reward_trend_value": 0.0019399090527732216, "biggest_recent_change": 0.1003990388027205},
{"total_number_of_episodes": 12936, "number_of_timesteps": 1464174, "per_episode_reward": -136.87, "episode_reward_trend_value": 0.0021233109212595814, "biggest_recent_change": 0.11197262118176354},
{"total_number_of_episodes": 12946, "number_of_timesteps": 1465241, "per_episode_reward": -136.83, "episode_reward_trend_value": 0.002614215213327182, "biggest_recent_change": 0.11197262118176354},
{"total_number_of_episodes": 12956, "number_of_timesteps": 1466429, "per_episode_reward": -136.87, "episode_reward_trend_value": 0.002756488195187343, "biggest_recent_change": 0.11197262118176354},
{"total_number_of_episodes": 12966, "number_of_timesteps": 1467451, "per_episode_reward": -136.79, "episode_reward_trend_value": 0.004008956283927824, "biggest_recent_change": 0.11197262118176354},
{"total_number_of_episodes": 12977, "number_of_timesteps": 1468372, "per_episode_reward": -136.71, "episode_reward_trend_value": 0.0038638774866699226, "biggest_recent_change": 0.11197262118176354},
{"total_number_of_episodes": 12988, "number_of_timesteps": 1469497, "per_episode_reward": -136.65, "episode_reward_trend_value": 0.0037113736202046416, "biggest_recent_change": 0.11197262118176354},
{"total_number_of_episodes": 12998, "number_of_timesteps": 1470550, "per_episode_reward": -136.64, "episode_reward_trend_value": 0.002652110666076308, "biggest_recent_change": 0.11197262118176354},
{"total_number_of_episodes": 13008, "number_of_timesteps": 1472036, "per_episode_reward": -136.73, "episode_reward_trend_value": 0.002469410322110674, "biggest_recent_change": 0.11197262118176354},
{"total_number_of_episodes": 13019, "number_of_timesteps": 1473109, "per_episode_reward": -136.82, "episode_reward_trend_value": 0.0018722631140065005, "biggest_recent_change": 0.11197262118176354},
{"total_number_of_episodes": 13030, "number_of_timesteps": 1474149, "per_episode_reward": -136.67, "episode_reward_trend_value": 0.002247841947670774, "biggest_recent_change": 0.14577471621154814},
{"total_number_of_episodes": 13040, "number_of_timesteps": 1475050, "per_episode_reward": -136.66, "episode_reward_trend_value": 0.0019232040086222923, "biggest_recent_change": 0.14577471621154814},
{"total_number_of_episodes": 13050, "number_of_timesteps": 1476289, "per_episode_reward": -136.87, "episode_reward_trend_value": 4.0607532690728475e-05, "biggest_recent_change": 0.20768540503206623},
{"total_number_of_episodes": 13061, "number_of_timesteps": 1477832, "per_episode_reward": -136.72, "episode_reward_trend_value": 0.0007663149765013107, "biggest_recent_change": 0.20768540503206623},
{"total_number_of_episodes": 13071, "number_of_timesteps": 1478805, "per_episode_reward": -136.62, "episode_reward_trend_value": 0.000977962409912594, "biggest_recent_change": 0.20768540503206623},
{"total_number_of_episodes": 13082, "number_of_timesteps": 1479832, "per_episode_reward": -136.62, "episode_reward_trend_value": 0.00030640052357695265, "biggest_recent_change": 0.20768540503206623},
{"total_number_of_episodes": 13092, "number_of_timesteps": 1480940, "per_episode_reward": -136.74, "episode_reward_trend_value": -0.0010825206956863239, "biggest_recent_change": 0.20768540503206623},
{"total_number_of_episodes": 13102, "number_of_timesteps": 1481975, "per_episode_reward": -136.64, "episode_reward_trend_value": 0.0010664303959168188, "biggest_recent_change": 0.20768540503206623},
{"total_number_of_episodes": 13112, "number_of_timesteps": 1483247, "per_episode_reward": -136.6, "episode_reward_trend_value": 0.002375150379985611, "biggest_recent_change": 0.20768540503206623},
{"total_number_of_episodes": 13122, "number_of_timesteps": 1484530, "per_episode_reward": -136.57, "episode_reward_trend_value": 0.0011258253458546758, "biggest_recent_change": 0.20768540503206623},
{"total_number_of_episodes": 13132, "number_of_timesteps": 1485493, "per_episode_reward": -136.48, "episode_reward_trend_value": 0.0019697879422497836, "biggest_recent_change": 0.20768540503206623},
{"total_number_of_episodes": 13142, "number_of_timesteps": 1486733, "per_episode_reward": -136.25, "episode_reward_trend_value": 0.006857718742354438, "biggest_recent_change": 0.2322283669773526},
{"total_number_of_episodes": 13153, "number_of_timesteps": 1488221, "per_episode_reward": -136.42, "episode_reward_trend_value": 0.003322640315453719, "biggest_recent_change": 0.2322283669773526},
{"total_number_of_episodes": 13164, "number_of_timesteps": 1489539, "per_episode_reward": -136.47, "episode_reward_trend_value": 0.0016241525857588438, "biggest_recent_change": 0.2322283669773526},
{"total_number_of_episodes": 13174, "number_of_timesteps": 1490595, "per_episode_reward": -136.37, "episode_reward_trend_value": 0.0028298545474241465, "biggest_recent_change": 0.2322283669773526},
{"total_number_of_episodes": 13185, "number_of_timesteps": 1492101, "per_episode_reward": -136.46, "episode_reward_trend_value": 0.0031513117282593664, "biggest_recent_change": 0.2322283669773526},
{"total_number_of_episodes": 13196, "number_of_timesteps": 1493687, "per_episode_reward": -136.43, "episode_reward_trend_value": 0.0023050393710886082, "biggest_recent_change": 0.2322283669773526},
{"total_number_of_episodes": 13206, "number_of_timesteps": 1494838, "per_episode_reward": -136.35, "episode_reward_trend_value": 0.0027873023192869243, "biggest_recent_change": 0.2322283669773526},
{"total_number_of_episodes": 13216, "number_of_timesteps": 1495878, "per_episode_reward": -136.27, "episode_reward_trend_value": 0.003305628793403849, "biggest_recent_change": 0.2322283669773526},
{"total_number_of_episodes": 13227, "number_of_timesteps": 1496949, "per_episode_reward": -136.38, "episode_reward_trend_value": 0.0011089979793395186, "biggest_recent_change": 0.2322283669773526},
{"total_number_of_episodes": 13237, "number_of_timesteps": 1498254, "per_episode_reward": -136.39, "episode_reward_trend_value": -0.001510385694511582, "biggest_recent_change": 0.17191442915830635},
{"total_number_of_episodes": 13248, "number_of_timesteps": 1499755, "per_episode_reward": -136.51, "episode_reward_trend_value": -0.0010370087856298622, "biggest_recent_change": 0.12931050735895155},
{"total_number_of_episodes": 13258, "number_of_timesteps": 1500780, "per_episode_reward": -136.42, "episode_reward_trend_value": 0.0005911836941786912, "biggest_recent_change": 0.12931050735895155},
{"total_number_of_episodes": 13268, "number_of_timesteps": 1501899, "per_episode_reward": -136.41, "episode_reward_trend_value": -0.0004728710510107703, "biggest_recent_change": 0.12931050735895155},
{"total_number_of_episodes": 13278, "number_of_timesteps": 1503059, "per_episode_reward": -136.47, "episode_reward_trend_value": -0.00015661537839201225, "biggest_recent_change": 0.12931050735895155},
{"total_number_of_episodes": 13288, "number_of_timesteps": 1504301, "per_episode_reward": -136.54, "episode_reward_trend_value": -0.001250687443514822, "biggest_recent_change": 0.12931050735895155},
{"total_number_of_episodes": 13298, "number_of_timesteps": 1505212, "per_episode_reward": -136.45, "episode_reward_trend_value": -0.0010924212862379237, "biggest_recent_change": 0.12931050735895155},
{"total_number_of_episodes": 13308, "number_of_timesteps": 1506286, "per_episode_reward": -136.42, "episode_reward_trend_value": -0.0016867924075051458, "biggest_recent_change": 0.12931050735895155},
{"total_number_of_episodes": 13318, "number_of_timesteps": 1507463, "per_episode_reward": -136.47, "episode_reward_trend_value": -0.001033964004255318, "biggest_recent_change": 0.12931050735895155},
{"total_number_of_episodes": 13328, "number_of_timesteps": 1508522, "per_episode_reward": -136.45, "episode_reward_trend_value": -0.0007452011158935395, "biggest_recent_change": 0.12931050735895155},
{"total_number_of_episodes": 13339, "number_of_timesteps": 1509757, "per_episode_reward": -136.42, "episode_reward_trend_value": 0.001030875801941041, "biggest_recent_change": 0.0939176914297093},
{"total_number_of_episodes": 13349, "number_of_timesteps": 1510806, "per_episode_reward": -136.46, "episode_reward_trend_value": -0.0003960847169088942, "biggest_recent_change": 0.0927773236873577},
{"total_number_of_episodes": 13359, "number_of_timesteps": 1511932, "per_episode_reward": -136.5, "episode_reward_trend_value": -0.0010099776525407834, "biggest_recent_change": 0.0927773236873577},
{"total_number_of_episodes": 13369, "number_of_timesteps": 1512962, "per_episode_reward": -136.42, "episode_reward_trend_value": 0.0005118429926893795, "biggest_recent_change": 0.0927773236873577},
{"total_number_of_episodes": 13379, "number_of_timesteps": 1513961, "per_episode_reward": -136.36, "episode_reward_trend_value": 0.0020146557778013456, "biggest_recent_change": 0.0927773236873577},
{"total_number_of_episodes": 13389, "number_of_timesteps": 1515138, "per_episode_reward": -136.29, "episode_reward_trend_value": 0.0018191904330624059, "biggest_recent_change": 0.07518544266085314},
{"total_number_of_episodes": 13400, "number_of_timesteps": 1516231, "per_episode_reward": -136.28, "episode_reward_trend_value": 0.0016077302700769752, "biggest_recent_change": 0.07518544266085314},
{"total_number_of_episodes": 13410, "number_of_timesteps": 1517093, "per_episode_reward": -136.19, "episode_reward_trend_value": 0.0032145277203413673, "biggest_recent_change": 0.09367701292453035},
{"total_number_of_episodes": 13420, "number_of_timesteps": 1517947, "per_episode_reward": -136.14, "episode_reward_trend_value": 0.0035128495192803177, "biggest_recent_change": 0.09367701292453035},
{"total_number_of_episodes": 13431, "number_of_timesteps": 1519112, "per_episode_reward": -136.14, "episode_reward_trend_value": 0.00315769959546262, "biggest_recent_change": 0.09367701292453035},
{"total_number_of_episodes": 13441, "number_of_timesteps": 1520061, "per_episode_reward": -136.09, "episode_reward_trend_value": 0.004030806606689907, "biggest_recent_change": 0.09367701292453035},
{"total_number_of_episodes": 13451, "number_of_timesteps": 1521037, "per_episode_reward": -136.06, "episode_reward_trend_value": 0.0049239293511132275, "biggest_recent_change": 0.09367701292453035},
{"total_number_of_episodes": 13461, "number_of_timesteps": 1522240, "per_episode_reward": -136.07, "episode_reward_trend_value": 0.003896237766516227, "biggest_recent_change": 0.09367701292453035},
{"total_number_of_episodes": 13471, "number_of_timesteps": 1523433, "per_episode_reward": -136.13, "episode_reward_trend_value": 0.002626549939411562, "biggest_recent_change": 0.09367701292453035},
{"total_number_of_episodes": 13481, "number_of_timesteps": 1524329, "per_episode_reward": -136.11, "episode_reward_trend_value": 0.0019996673725835813, "biggest_recent_change": 0.09367701292453035},
{"total_number_of_episodes": 13491, "number_of_timesteps": 1525228, "per_episode_reward": -135.99, "episode_reward_trend_value": 0.0031718685469441094, "biggest_recent_change": 0.11295813591999604},
{"total_number_of_episodes": 13501, "number_of_timesteps": 1526208, "per_episode_reward": -136.02, "episode_reward_trend_value": 0.0018856856784916925, "biggest_recent_change": 0.11295813591999604},
{"total_number_of_episodes": 13511, "number_of_timesteps": 1527592, "per_episode_reward": -136.07, "episode_reward_trend_value": 0.0007407674999399205, "biggest_recent_change": 0.11295813591999604},
{"total_number_of_episodes": 13521, "number_of_timesteps": 1529121, "per_episode_reward": -136.09, "episode_reward_trend_value": 0.0005437530878541313, "biggest_recent_change": 0.11295813591999604},
{"total_number_of_episodes": 13532, "number_of_timesteps": 1530288, "per_episode_reward": -136.11, "episode_reward_trend_value": -0.00017086560990738536, "biggest_recent_change": 0.11295813591999604},
{"total_number_of_episodes": 13542, "number_of_timesteps": 1531214, "per_episode_reward": -136.1, "episode_reward_trend_value": -0.0004971601262468539, "biggest_recent_change": 0.11295813591999604},
{"total_number_of_episodes": 13552, "number_of_timesteps": 1532311, "per_episode_reward": -136.08, "episode_reward_trend_value": -0.00010371401013773923, "biggest_recent_change": 0.11295813591999604},
{"total_number_of_episodes": 13562, "number_of_timesteps": 1533042, "per_episode_reward": -135.98, "episode_reward_trend_value": 0.0016657404849831261, "biggest_recent_change": 0.11295813591999604},
{"total_number_of_episodes": 13572, "number_of_timesteps": 1534305, "per_episode_reward": -136.03, "episode_reward_trend_value": 0.0008835298868338744, "biggest_recent_change": 0.11295813591999604},
{"total_number_of_episodes": 13582, "number_of_timesteps": 1535561, "per_episode_reward": -136.03, "episode_reward_trend_value": -0.00037647056421058597, "biggest_recent_change": 0.10707155298854332},
{"total_number_of_episodes": 13592, "number_of_timesteps": 1536632, "per_episode_reward": -136.05, "episode_reward_trend_value": -0.0003957486430266499, "biggest_recent_change": 0.10707155298854332},
{"total_number_of_episodes": 13603, "number_of_timesteps": 1538073, "per_episode_reward": -136.07, "episode_reward_trend_value": -3.58035073535095e-05, "biggest_recent_change": 0.10707155298854332},
{"total_number_of_episodes": 13614, "number_of_timesteps": 1539303, "per_episode_reward": -136.05, "episode_reward_trend_value": 0.0004343358331927523, "biggest_recent_change": 0.10707155298854332},

{"total_number_of_episodes": 13624, "number_of_timesteps": 1540530, "per_episode_reward": -136.01, "episode_reward_trend_value": 0.0011247419490732428, "biggest_recent_change": 0.10707155298854332},
{"total_number_of_episodes": 13634, "number_of_timesteps": 1541886, "per_episode_reward": -136.09, "episode_reward_trend_value": 0.00012582770465125275, "biggest_recent_change": 0.10707155298854332},
{"total_number_of_episodes": 13644, "number_of_timesteps": 1542802, "per_episode_reward": -136.06, "episode_reward_trend_value": 0.0002066408499271372, "biggest_recent_change": 0.10707155298854332},
{"total_number_of_episodes": 13654, "number_of_timesteps": 1543990, "per_episode_reward": -136.05, "episode_reward_trend_value": -0.0008652998337112195, "biggest_recent_change": 0.08091591966146439},
{"total_number_of_episodes": 13664, "number_of_timesteps": 1545015, "per_episode_reward": -135.91, "episode_reward_trend_value": 0.0013316381980637794, "biggest_recent_change": 0.1460914806726521},
{"total_number_of_episodes": 13675, "number_of_timesteps": 1546533, "per_episode_reward": -135.89, "episode_reward_trend_value": 0.0015350053934952256, "biggest_recent_change": 0.1460914806726521},
{"total_number_of_episodes": 13685, "number_of_timesteps": 1548056, "per_episode_reward": -135.99, "episode_reward_trend_value": 0.0007345410037512718, "biggest_recent_change": 0.1460914806726521},
{"total_number_of_episodes": 13695, "number_of_timesteps": 1549591, "per_episode_reward": -136.16, "episode_reward_trend_value": -0.0009148590740093394, "biggest_recent_change": 0.16977212266971264},
{"total_number_of_episodes": 13706, "number_of_timesteps": 1550904, "per_episode_reward": -136.06, "episode_reward_trend_value": -0.00014282161969624162, "biggest_recent_change": 0.16977212266971264},
{"total_number_of_episodes": 13716, "number_of_timesteps": 1552191, "per_episode_reward": -136.18, "episode_reward_trend_value": -0.0019179835913759134, "biggest_recent_change": 0.16977212266971264},
{"total_number_of_episodes": 13726, "number_of_timesteps": 1553434, "per_episode_reward": -136.2, "episode_reward_trend_value": -0.0012184058502773118, "biggest_recent_change": 0.16977212266971264},
{"total_number_of_episodes": 13736, "number_of_timesteps": 1554416, "per_episode_reward": -136.17, "episode_reward_trend_value": -0.0011313825063780313, "biggest_recent_change": 0.16977212266971264},
{"total_number_of_episodes": 13746, "number_of_timesteps": 1555897, "per_episode_reward": -136.21, "episode_reward_trend_value": -0.0016926527657091129, "biggest_recent_change": 0.16977212266971264},
{"total_number_of_episodes": 13756, "number_of_timesteps": 1556921, "per_episode_reward": -136.21, "episode_reward_trend_value": -0.0033363822255795287, "biggest_recent_change": 0.16977212266971264},
{"total_number_of_episodes": 13766, "number_of_timesteps": 1558260, "per_episode_reward": -136.19, "episode_reward_trend_value": -0.003311071412383626, "biggest_recent_change": 0.16977212266971264},
{"total_number_of_episodes": 13776, "number_of_timesteps": 1559110, "per_episode_reward": -136.12, "episode_reward_trend_value": -0.0014472906711688438, "biggest_recent_change": 0.16977212266971264},
{"total_number_of_episodes": 13786, "number_of_timesteps": 1560205, "per_episode_reward": -136.14, "episode_reward_trend_value": 0.00019923601079862386, "biggest_recent_change": 0.11787283407679183},
{"total_number_of_episodes": 13796, "number_of_timesteps": 1561813, "per_episode_reward": -136.14, "episode_reward_trend_value": -0.0008514820478410457, "biggest_recent_change": 0.11787283407679183},
{"total_number_of_episodes": 13809, "number_of_timesteps": 1563569, "per_episode_reward": -136.24, "episode_reward_trend_value": -0.0006620335589543755, "biggest_recent_change": 0.10082247007699152},
{"total_number_of_episodes": 13819, "number_of_timesteps": 1564484, "per_episode_reward": -136.21, "episode_reward_trend_value": -0.00014254313451355453, "biggest_recent_change": 0.10082247007699152},
{"total_number_of_episodes": 13829, "number_of_timesteps": 1565530, "per_episode_reward": -136.18, "episode_reward_trend_value": -0.0002073838504862301, "biggest_recent_change": 0.10082247007699152},
{"total_number_of_episodes": 13839, "number_of_timesteps": 1566634, "per_episode_reward": -136.16, "episode_reward_trend_value": 0.0004922996747805226, "biggest_recent_change": 0.10082247007699152},
{"total_number_of_episodes": 13849, "number_of_timesteps": 1567873, "per_episode_reward": -136.12, "episode_reward_trend_value": 0.0009443660840575931, "biggest_recent_change": 0.10082247007699152},
{"total_number_of_episodes": 13859, "number_of_timesteps": 1569632, "per_episode_reward": -136.07, "episode_reward_trend_value": 0.0012864858123568486, "biggest_recent_change": 0.10082247007699152},
{"total_number_of_episodes": 13869, "number_of_timesteps": 1570981, "per_episode_reward": -136.12, "episode_reward_trend_value": -1.9051302621796316e-06, "biggest_recent_change": 0.10082247007699152},
{"total_number_of_episodes": 13879, "number_of_timesteps": 1572345, "per_episode_reward": -136.17, "episode_reward_trend_value": -0.00033023024769091887, "biggest_recent_change": 0.10082247007699152},
{"total_number_of_episodes": 13891, "number_of_timesteps": 1573457, "per_episode_reward": -136.12, "episode_reward_trend_value": 0.0002231464640491115, "biggest_recent_change": 0.10082247007699152},
{"total_number_of_episodes": 13902, "number_of_timesteps": 1574606, "per_episode_reward": -136.12, "episode_reward_trend_value": 0.001293944070276767, "biggest_recent_change": 0.051133981861227085},
{"total_number_of_episodes": 13912, "number_of_timesteps": 1575665, "per_episode_reward": -136.2, "episode_reward_trend_value": 0.0001153520091602584, "biggest_recent_change": 0.07727307026340213},
{"total_number_of_episodes": 13923, "number_of_timesteps": 1576738, "per_episode_reward": -135.99, "episode_reward_trend_value": 0.0021680621795370472, "biggest_recent_change": 0.2113519208372736},
{"total_number_of_episodes": 13933, "number_of_timesteps": 1577594, "per_episode_reward": -135.9, "episode_reward_trend_value": 0.0029214264214544984, "biggest_recent_change": 0.2113519208372736},
{"total_number_of_episodes": 13943, "number_of_timesteps": 1578392, "per_episode_reward": -135.82, "episode_reward_trend_value": 0.003382601740345434, "biggest_recent_change": 0.2113519208372736},

{"total_number_of_episodes": 13953, "number_of_timesteps": 1579257, "per_episode_reward": -135.79, "episode_reward_trend_value": 0.0030971062500697146, "biggest_recent_change": 0.2113519208372736},
{"total_number_of_episodes": 13965, "number_of_timesteps": 1580924, "per_episode_reward": -135.66, "episode_reward_trend_value": 0.005103622684544638, "biggest_recent_change": 0.2113519208372736},
{"total_number_of_episodes": 13975, "number_of_timesteps": 1582256, "per_episode_reward": -135.74, "episode_reward_trend_value": 0.004722905896339727, "biggest_recent_change": 0.2113519208372736},
{"total_number_of_episodes": 13985, "number_of_timesteps": 1583894, "per_episode_reward": -135.75, "episode_reward_trend_value": 0.004071546275478491, "biggest_recent_change": 0.2113519208372736},
{"total_number_of_episodes": 13995, "number_of_timesteps": 1585050, "per_episode_reward": -135.71, "episode_reward_trend_value": 0.004643955323840348, "biggest_recent_change": 0.2113519208372736},
{"total_number_of_episodes": 14005, "number_of_timesteps": 1586275, "per_episode_reward": -135.86, "episode_reward_trend_value": 0.0038038307819659974, "biggest_recent_change": 0.2113519208372736},
{"total_number_of_episodes": 14016, "number_of_timesteps": 1587602, "per_episode_reward": -135.85, "episode_reward_trend_value": 0.001503646093365142, "biggest_recent_change": 0.15288427903209367},
{"total_number_of_episodes": 14026, "number_of_timesteps": 1588651, "per_episode_reward": -135.88, "episode_reward_trend_value": 0.00025101120807562437, "biggest_recent_change": 0.15288427903209367},
{"total_number_of_episodes": 14036, "number_of_timesteps": 1589509, "per_episode_reward": -135.8, "episode_reward_trend_value": 0.00015771328625236139, "biggest_recent_change": 0.15288427903209367},
{"total_number_of_episodes": 14047, "number_of_timesteps": 1590784, "per_episode_reward": -135.71, "episode_reward_trend_value": 0.0008840239059632419, "biggest_recent_change": 0.15288427903209367},
{"total_number_of_episodes": 14057, "number_of_timesteps": 1591840, "per_episode_reward": -135.72, "episode_reward_trend_value": -0.0007341492767267254, "biggest_recent_change": 0.15288427903209367},
{"total_number_of_episodes": 14067, "number_of_timesteps": 1592867, "per_episode_reward": -135.61, "episode_reward_trend_value": 0.001444196036623819, "biggest_recent_change": 0.15288427903209367},
{"total_number_of_episodes": 14077, "number_of_timesteps": 1594076, "per_episode_reward": -135.6, "episode_reward_trend_value": 0.0017258628855576792, "biggest_recent_change": 0.15288427903209367},
{"total_number_of_episodes": 14087, "number_of_timesteps": 1595261, "per_episode_reward": -135.63, "episode_reward_trend_value": 0.0008493928970437992, "biggest_recent_change": 0.15288427903209367},
{"total_number_of_episodes": 14097, "number_of_timesteps": 1596414, "per_episode_reward": -135.66, "episode_reward_trend_value": 0.002154043694710279, "biggest_recent_change": 0.11065258540187983},
{"total_number_of_episodes": 14107, "number_of_timesteps": 1597712, "per_episode_reward": -135.64, "episode_reward_trend_value": 0.0023400977431600094, "biggest_recent_change": 0.11065258540187983},
{"total_number_of_episodes": 14117, "number_of_timesteps": 1598873, "per_episode_reward": -135.65, "episode_reward_trend_value": 0.0025100910754108302, "biggest_recent_change": 0.11065258540187983},
{"total_number_of_episodes": 14127, "number_of_timesteps": 1600831, "per_episode_reward": -135.71, "episode_reward_trend_value": 0.001072079782882598, "biggest_recent_change": 0.11065258540187983},
{"total_number_of_episodes": 14138, "number_of_timesteps": 1602078, "per_episode_reward": -135.65, "episode_reward_trend_value": 0.0006847379521167972, "biggest_recent_change": 0.11065258540187983},
{"total_number_of_episodes": 14148, "number_of_timesteps": 1603052, "per_episode_reward": -135.59, "episode_reward_trend_value": 0.0014315680150231301, "biggest_recent_change": 0.11065258540187983},
{"total_number_of_episodes": 14158, "number_of_timesteps": 1604283, "per_episode_reward": -135.66, "episode_reward_trend_value": -0.0005607843894352982, "biggest_recent_change": 0.0686591309993787},
{"total_number_of_episodes": 14168, "number_of_timesteps": 1605631, "per_episode_reward": -135.7, "episode_reward_trend_value": -0.0011946804814016332, "biggest_recent_change": 0.0686591309993787},
{"total_number_of_episodes": 14178, "number_of_timesteps": 1606622, "per_episode_reward": -135.66, "episode_reward_trend_value": -0.00034004369169748667, "biggest_recent_change": 0.0686591309993787},
{"total_number_of_episodes": 14188, "number_of_timesteps": 1607665, "per_episode_reward": -135.63, "episode_reward_trend_value": 0.0003665706784741158, "biggest_recent_change": 0.0686591309993787},
{"total_number_of_episodes": 14198, "number_of_timesteps": 1608841, "per_episode_reward": -135.56, "episode_reward_trend_value": 0.000960788483778035, "biggest_recent_change": 0.07455976570102507},
{"total_number_of_episodes": 14208, "number_of_timesteps": 1609845, "per_episode_reward": -135.59, "episode_reward_trend_value": 0.0007213583341366657, "biggest_recent_change": 0.07455976570102507},
{"total_number_of_episodes": 14218, "number_of_timesteps": 1610934, "per_episode_reward": -135.59, "episode_reward_trend_value": 0.0013541928190641606, "biggest_recent_change": 0.07455976570102507},
{"total_number_of_episodes": 14228, "number_of_timesteps": 1611838, "per_episode_reward": -135.54, "episode_reward_trend_value": 0.0012714057074166222, "biggest_recent_change": 0.07455976570102507},
{"total_number_of_episodes": 14238, "number_of_timesteps": 1612936, "per_episode_reward": -135.5, "episode_reward_trend_value": 0.0010631317619865083, "biggest_recent_change": 0.07455976570102507},
{"total_number_of_episodes": 14248, "number_of_timesteps": 1614142, "per_episode_reward": -135.49, "episode_reward_trend_value": 0.0019711905271650367, "biggest_recent_change": 0.07455976570102507},
{"total_number_of_episodes": 14258, "number_of_timesteps": 1614965, "per_episode_reward": -135.44, "episode_reward_trend_value": 0.002907885948872667, "biggest_recent_change": 0.07455976570102507},
{"total_number_of_episodes": 14268, "number_of_timesteps": 1616070, "per_episode_reward": -135.52, "episode_reward_trend_value": 0.0015197033640409548, "biggest_recent_change": 0.07983529169166559},
{"total_number_of_episodes": 14278, "number_of_timesteps": 1617289, "per_episode_reward": -135.46, "episode_reward_trend_value": 0.0018632568170937071, "biggest_recent_change": 0.07983529169166559},
{"total_number_of_episodes": 14289, "number_of_timesteps": 1618596, "per_episode_reward": -135.48, "episode_reward_trend_value": 0.0008925944225410376, "biggest_recent_change": 0.07983529169166559},
{"total_number_of_episodes": 14300, "number_of_timesteps": 1620026, "per_episode_reward": -135.49, "episode_reward_trend_value": 0.0010100489762227957, "biggest_recent_change": 0.07983529169166559},
{"total_number_of_episodes": 14310, "number_of_timesteps": 1621080, "per_episode_reward": -135.32, "episode_reward_trend_value": 0.0029866572702047733, "biggest_recent_change": 0.17737960562965327},
{"total_number_of_episodes": 14321, "number_of_timesteps": 1622464, "per_episode_reward": -135.36, "episode_reward_trend_value": 0.0019396233301601268, "biggest_recent_change": 0.17737960562965327},
{"total_number_of_episodes": 14331, "number_of_timesteps": 1623601, "per_episode_reward": -135.36, "episode_reward_trend_value": 0.0015373752707773746, "biggest_recent_change": 0.17737960562965327},
{"total_number_of_episodes": 14341, "number_of_timesteps": 1625086, "per_episode_reward": -135.34, "episode_reward_trend_value": 0.0015872921416138926, "biggest_recent_change": 0.17737960562965327},
{"total_number_of_episodes": 14351, "number_of_timesteps": 1626569, "per_episode_reward": -135.44, "episode_reward_trend_value": 5.125425591706466e-05, "biggest_recent_change": 0.17737960562965327},
{"total_number_of_episodes": 14362, "number_of_timesteps": 1628165, "per_episode_reward": -135.58, "episode_reward_trend_value": -0.0005980515275009819, "biggest_recent_change": 0.17737960562965327},
{"total_number_of_episodes": 14373, "number_of_timesteps": 1629153, "per_episode_reward": -135.51, "episode_reward_trend_value": -0.0004784604188112477, "biggest_recent_change": 0.17737960562965327},
{"total_number_of_episodes": 14384, "number_of_timesteps": 1630104, "per_episode_reward": -135.42, "episode_reward_trend_value": 0.0006195255991867852, "biggest_recent_change": 0.17737960562965327},
{"total_number_of_episodes": 14394, "number_of_timesteps": 1631246, "per_episode_reward": -135.39, "episode_reward_trend_value": 0.0011141531110183678, "biggest_recent_change": 0.17737960562965327},
{"total_number_of_episodes": 14404, "number_of_timesteps": 1632280, "per_episode_reward": -135.39, "episode_reward_trend_value": -0.000821759925354589, "biggest_recent_change": 0.13827281219928977},
{"total_number_of_episodes": 14415, "number_of_timesteps": 1633563, "per_episode_reward": -135.41, "episode_reward_trend_value": -0.0005295989859838022, "biggest_recent_change": 0.13827281219928977},
{"total_number_of_episodes": 14425, "number_of_timesteps": 1634888, "per_episode_reward": -135.47, "episode_reward_trend_value": -0.00125796432142522, "biggest_recent_change": 0.13827281219928977},
{"total_number_of_episodes": 14435, "number_of_timesteps": 1636464, "per_episode_reward": -135.57, "episode_reward_trend_value": -0.002499836287795334, "biggest_recent_change": 0.13827281219928977},
{"total_number_of_episodes": 14446, "number_of_timesteps": 1638366, "per_episode_reward": -135.71, "episode_reward_trend_value": -0.0030268372737828663, "biggest_recent_change": 0.14381709291711786},
{"total_number_of_episodes": 14456, "number_of_timesteps": 1639683, "per_episode_reward": -135.68, "episode_reward_trend_value": -0.0010969504273096694, "biggest_recent_change": 0.14381709291711786},
{"total_number_of_episodes": 14467, "number_of_timesteps": 1640611, "per_episode_reward": -135.58, "episode_reward_trend_value": -0.000775695518112861, "biggest_recent_change": 0.14381709291711786},
{"total_number_of_episodes": 14477, "number_of_timesteps": 1641307, "per_episode_reward": -135.43, "episode_reward_trend_value": -0.00013387559674148027, "biggest_recent_change": 0.14381709291711786},
{"total_number_of_episodes": 14487, "number_of_timesteps": 1642222, "per_episode_reward": -135.43, "episode_reward_trend_value": -0.00039786403520988893, "biggest_recent_change": 0.14381709291711786},
{"total_number_of_episodes": 14498, "number_of_timesteps": 1643700, "per_episode_reward": -135.49, "episode_reward_trend_value": -0.0010484314263695498, "biggest_recent_change": 0.14381709291711786},
{"total_number_of_episodes": 14508, "number_of_timesteps": 1644681, "per_episode_reward": -135.48, "episode_reward_trend_value": -0.0007401270777254215, "biggest_recent_change": 0.14381709291711786},
{"total_number_of_episodes": 14518, "number_of_timesteps": 1645402, "per_episode_reward": -135.4, "episode_reward_trend_value": 0.0008573213598443393, "biggest_recent_change": 0.14381709291711786},
{"total_number_of_episodes": 14528, "number_of_timesteps": 1646334, "per_episode_reward": -135.3, "episode_reward_trend_value": 0.0029153678323900244, "biggest_recent_change": 0.14381709291711786},
{"total_number_of_episodes": 14538, "number_of_timesteps": 1647336, "per_episode_reward": -135.23, "episode_reward_trend_value": 0.005328028220970143, "biggest_recent_change": 0.14378268473453204},
{"total_number_of_episodes": 14548, "number_of_timesteps": 1648613, "per_episode_reward": -135.23, "episode_reward_trend_value": 0.004943726913983445, "biggest_recent_change": 0.14378268473453204},
{"total_number_of_episodes": 14558, "number_of_timesteps": 1650066, "per_episode_reward": -135.22, "episode_reward_trend_value": 0.003967003937850046, "biggest_recent_change": 0.14378268473453204},
{"total_number_of_episodes": 14568, "number_of_timesteps": 1651024, "per_episode_reward": -135.25, "episode_reward_trend_value": 0.0020769728591754225, "biggest_recent_change": 0.09101438179777688},
{"total_number_of_episodes": 14579, "number_of_timesteps": 1652366, "per_episode_reward": -135.41, "episode_reward_trend_value": 0.00023029009157274536, "biggest_recent_change": 0.16300260872353078},
{"total_number_of_episodes": 14589, "number_of_timesteps": 1653615, "per_episode_reward": -135.31, "episode_reward_trend_value": 0.001894926914305807, "biggest_recent_change": 0.16300260872353078},
{"total_number_of_episodes": 14599, "number_of_timesteps": 1654805, "per_episode_reward": -135.38, "episode_reward_trend_value": 0.0011000625747783488, "biggest_recent_change": 0.16300260872353078},
{"total_number_of_episodes": 14609, "number_of_timesteps": 1655902, "per_episode_reward": -135.25, "episode_reward_trend_value": 0.0016632669041112221, "biggest_recent_change": 0.16300260872353078},
{"total_number_of_episodes": 14619, "number_of_timesteps": 1657066, "per_episode_reward": -135.34, "episode_reward_trend_value": -0.00034167558252136133, "biggest_recent_change": 0.16300260872353078},
{"total_number_of_episodes": 14629, "number_of_timesteps": 1658452, "per_episode_reward": -135.27, "episode_reward_trend_value": -0.00044751126575369606, "biggest_recent_change": 0.16300260872353078},
{"total_number_of_episodes": 14639, "number_of_timesteps": 1659648, "per_episode_reward": -135.27, "episode_reward_trend_value": -0.00045673222524808603, "biggest_recent_change": 0.16300260872353078},
{"total_number_of_episodes": 14649, "number_of_timesteps": 1660950, "per_episode_reward": -135.34, "episode_reward_trend_value": -0.001340915394880287, "biggest_recent_change": 0.16300260872353078},
{"total_number_of_episodes": 14659, "number_of_timesteps": 1662881, "per_episode_reward": -135.3, "episode_reward_trend_value": -0.0006162419174046363, "biggest_recent_change": 0.16300260872353078},
{"total_number_of_episodes": 14669, "number_of_timesteps": 1663732, "per_episode_reward": -135.27, "episode_reward_trend_value": 0.0015628539146796863, "biggest_recent_change": 0.13205330118759662},
{"total_number_of_episodes": 14679, "number_of_timesteps": 1664780, "per_episode_reward": -135.33, "episode_reward_trend_value": -0.00013046587760293782, "biggest_recent_change": 0.13205330118759662},
{"total_number_of_episodes": 14689, "number_of_timesteps": 1665866, "per_episode_reward": -135.37, "episode_reward_trend_value": 7.631517361990822e-05, "biggest_recent_change": 0.13205330118759662},
{"total_number_of_episodes": 14699, "number_of_timesteps": 1667006, "per_episode_reward": -135.33, "episode_reward_trend_value": -0.0009157402318436425, "biggest_recent_change": 0.08943044199915562},
{"total_number_of_episodes": 14709, "number_of_timesteps": 1668633, "per_episode_reward": -135.26, "episode_reward_trend_value": 0.0008555102190863787, "biggest_recent_change": 0.06998209858454629},
{"total_number_of_episodes": 14720, "number_of_timesteps": 1669790, "per_episode_reward": -135.23, "episode_reward_trend_value": 0.0004899215650858146, "biggest_recent_change": 0.06998209858454629},
{"total_number_of_episodes": 14730, "number_of_timesteps": 1671110, "per_episode_reward": -135.3, "episode_reward_trend_value": -0.00033478678073777245, "biggest_recent_change": 0.07422375112412283},
{"total_number_of_episodes": 14740, "number_of_timesteps": 1672179, "per_episode_reward": -135.28, "episode_reward_trend_value": 0.0006429006793483595, "biggest_recent_change": 0.07422375112412283},
{"total_number_of_episodes": 14750, "number_of_timesteps": 1673023, "per_episode_reward": -135.25, "episode_reward_trend_value": 0.0006135225956436822, "biggest_recent_change": 0.07422375112412283},
{"total_number_of_episodes": 14760, "number_of_timesteps": 1674124, "per_episode_reward": -135.25, "episode_reward_trend_value": 0.0002301632130439657, "biggest_recent_change": 0.07422375112412283},
{"total_number_of_episodes": 14770, "number_of_timesteps": 1675753, "per_episode_reward": -135.27, "episode_reward_trend_value": 0.000669167797468933, "biggest_recent_change": 0.07422375112412283},
{"total_number_of_episodes": 14780, "number_of_timesteps": 1677127, "per_episode_reward": -135.28, "episode_reward_trend_value": 0.0010111109527343842, "biggest_recent_change": 0.07422375112412283},
{"total_number_of_episodes": 14790, "number_of_timesteps": 1678298, "per_episode_reward": -135.27, "episode_reward_trend_value": 0.0006176322448150511, "biggest_recent_change": 0.07422375112412283},
{"total_number_of_episodes": 14800, "number_of_timesteps": 1679428, "per_episode_reward": -135.4, "episode_reward_trend_value": -0.0015701296978189957, "biggest_recent_change": 0.1269164762525179},
{"total_number_of_episodes": 14811, "number_of_timesteps": 1680693, "per_episode_reward": -135.46, "episode_reward_trend_value": -0.0026049942139179747, "biggest_recent_change": 0.1269164762525179},
{"total_number_of_episodes": 14822, "number_of_timesteps": 1681878, "per_episode_reward": -135.5, "episode_reward_trend_value": -0.0021743492818956157, "biggest_recent_change": 0.1269164762525179},
{"total_number_of_episodes": 14832, "number_of_timesteps": 1683124, "per_episode_reward": -135.53, "episode_reward_trend_value": -0.0027500840411909797, "biggest_recent_change": 0.1269164762525179},
{"total_number_of_episodes": 14844, "number_of_timesteps": 1684283, "per_episode_reward": -135.5, "episode_reward_trend_value": -0.002792504436362088, "biggest_recent_change": 0.1269164762525179},
{"total_number_of_episodes": 14854, "number_of_timesteps": 1685378, "per_episode_reward": -135.51, "episode_reward_trend_value": -0.002866028650437771, "biggest_recent_change": 0.1269164762525179},
{"total_number_of_episodes": 14864, "number_of_timesteps": 1686773, "per_episode_reward": -135.46, "episode_reward_trend_value": -0.002097832322662738, "biggest_recent_change": 0.1269164762525179},
{"total_number_of_episodes": 14874, "number_of_timesteps": 1687770, "per_episode_reward": -135.46, "episode_reward_trend_value": -0.0020144210338404237, "biggest_recent_change": 0.1269164762525179},
{"total_number_of_episodes": 14884, "number_of_timesteps": 1689171, "per_episode_reward": -135.52, "episode_reward_trend_value": -0.0027936265069800786, "biggest_recent_change": 0.1269164762525179},
{"total_number_of_episodes": 14894, "number_of_timesteps": 1690302, "per_episode_reward": -135.43, "episode_reward_trend_value": -0.00028444110686096894, "biggest_recent_change": 0.09891020975820197},
{"total_number_of_episodes": 14905, "number_of_timesteps": 1691671, "per_episode_reward": -135.4, "episode_reward_trend_value": 0.0007299914224176973, "biggest_recent_change": 0.09891020975820197},
{"total_number_of_episodes": 14915, "number_of_timesteps": 1692979, "per_episode_reward": -135.36, "episode_reward_trend_value": 0.001533117306489531, "biggest_recent_change": 0.09891020975820197},
{"total_number_of_episodes": 14926, "number_of_timesteps": 1694453, "per_episode_reward": -135.35, "episode_reward_trend_value": 0.0019865844891632555, "biggest_recent_change": 0.09891020975820197},
{"total_number_of_episodes": 14937, "number_of_timesteps": 1695309, "per_episode_reward": -135.27, "episode_reward_trend_value": 0.0025106992868952857, "biggest_recent_change": 0.09891020975820197},
{"total_number_of_episodes": 14948, "number_of_timesteps": 1696362, "per_episode_reward": -135.26, "episode_reward_trend_value": 0.0027626257896126087, "biggest_recent_change": 0.09891020975820197},
{"total_number_of_episodes": 14958, "number_of_timesteps": 1697294, "per_episode_reward": -135.12, "episode_reward_trend_value": 0.0037231962370795043, "biggest_recent_change": 0.1371143222622777},
{"total_number_of_episodes": 14969, "number_of_timesteps": 1698237, "per_episode_reward": -135.08, "episode_reward_trend_value": 0.004259151605793616, "biggest_recent_change": 0.1371143222622777},
{"total_number_of_episodes": 14979, "number_of_timesteps": 1699260, "per_episode_reward": -135.05, "episode_reward_trend_value": 0.005242358324040058, "biggest_recent_change": 0.1371143222622777},
{"total_number_of_episodes": 14989, "number_of_timesteps": 1700797, "per_episode_reward": -135.07, "episode_reward_trend_value": 0.003962261001864439, "biggest_recent_change": 0.1371143222622777},
{"total_number_of_episodes": 14999, "number_of_timesteps": 1702215, "per_episode_reward": -135.13, "episode_reward_trend_value": 0.00296964844851099, "biggest_recent_change": 0.1371143222622777},
{"total_number_of_episodes": 15009, "number_of_timesteps": 1704010, "per_episode_reward": -135.29, "episode_reward_trend_value": 0.0007554149621537615, "biggest_recent_change": 0.16246539144779604},
{"total_number_of_episodes": 15019, "number_of_timesteps": 1705076, "per_episode_reward": -135.39, "episode_reward_trend_value": -0.00047589477477774585, "biggest_recent_change": 0.16246539144779604},
{"total_number_of_episodes": 15029, "number_of_timesteps": 1706546, "per_episode_reward": -135.35, "episode_reward_trend_value": -0.0008994308716394371, "biggest_recent_change": 0.16246539144779604},
{"total_number_of_episodes": 15039, "number_of_timesteps": 1707600, "per_episode_reward": -135.3, "episode_reward_trend_value": -0.0005057441739223931, "biggest_recent_change": 0.16246539144779604},
{"total_number_of_episodes": 15049, "number_of_timesteps": 1708737, "per_episode_reward": -135.38, "episode_reward_trend_value": -0.0028522331793580076, "biggest_recent_change": 0.16246539144779604},
{"total_number_of_episodes": 15059, "number_of_timesteps": 1709930, "per_episode_reward": -135.41, "episode_reward_trend_value": -0.0036725310041491517, "biggest_recent_change": 0.16246539144779604},
{"total_number_of_episodes": 15069, "number_of_timesteps": 1710947, "per_episode_reward": -135.3, "episode_reward_trend_value": -0.002728812380555547, "biggest_recent_change": 0.16246539144779604},
{"total_number_of_episodes": 15080, "number_of_timesteps": 1712210, "per_episode_reward": -135.32, "episode_reward_trend_value": -0.0027449005705774553, "biggest_recent_change": 0.16246539144779604},
{"total_number_of_episodes": 15090, "number_of_timesteps": 1713483, "per_episode_reward": -135.68, "episode_reward_trend_value": -0.006105060383012529, "biggest_recent_change": 0.3626942400306632},
{"total_number_of_episodes": 15103, "number_of_timesteps": 1714612, "per_episode_reward": -135.47, "episode_reward_trend_value": -0.001971832175121651, "biggest_recent_change": 0.3626942400306632},
{"total_number_of_episodes": 15113, "number_of_timesteps": 1715518, "per_episode_reward": -135.42, "episode_reward_trend_value": -0.0003188238982378127, "biggest_recent_change": 0.3626942400306632},
{"total_number_of_episodes": 15123, "number_of_timesteps": 1716633, "per_episode_reward": -135.44, "episode_reward_trend_value": -0.0009373174416655021, "biggest_recent_change": 0.3626942400306632},
{"total_number_of_episodes": 15133, "number_of_timesteps": 1717622, "per_episode_reward": -135.37, "episode_reward_trend_value": -0.0006986612070161552, "biggest_recent_change": 0.3626942400306632},
{"total_number_of_episodes": 15143, "number_of_timesteps": 1718610, "per_episode_reward": -135.32, "episode_reward_trend_value": 0.0006789853335324854, "biggest_recent_change": 0.3626942400306632},
{"total_number_of_episodes": 15153, "number_of_timesteps": 1719840, "per_episode_reward": -135.28, "episode_reward_trend_value": 0.0013755323651638365, "biggest_recent_change": 0.3626942400306632},
{"total_number_of_episodes": 15163, "number_of_timesteps": 1721074, "per_episode_reward": -135.34, "episode_reward_trend_value": -0.0004945331346934583, "biggest_recent_change": 0.3626942400306632},
{"total_number_of_episodes": 15173, "number_of_timesteps": 1722348, "per_episode_reward": -135.27, "episode_reward_trend_value": 0.0004648458585213196, "biggest_recent_change": 0.3626942400306632},
{"total_number_of_episodes": 15183, "number_of_timesteps": 1723404, "per_episode_reward": -135.28, "episode_reward_trend_value": 0.004386889671076548, "biggest_recent_change": 0.20952514726238292},
{"total_number_of_episodes": 15193, "number_of_timesteps": 1724568, "per_episode_reward": -135.44, "episode_reward_trend_value": 0.00029459142547333763, "biggest_recent_change": 0.15878169484190607},
{"total_number_of_episodes": 15203, "number_of_timesteps": 1725833, "per_episode_reward": -135.49, "episode_reward_trend_value": -0.000706352221964658, "biggest_recent_change": 0.15878169484190607},
{"total_number_of_episodes": 15213, "number_of_timesteps": 1727140, "per_episode_reward": -135.55, "episode_reward_trend_value": -0.001229770577002872, "biggest_recent_change": 0.15878169484190607},
{"total_number_of_episodes": 15223, "number_of_timesteps": 1728149, "per_episode_reward": -135.37, "episode_reward_trend_value": -3.836630171084228e-05, "biggest_recent_change": 0.17880712639708918},
{"total_number_of_episodes": 15233, "number_of_timesteps": 1729502, "per_episode_reward": -135.57, "episode_reward_trend_value": -0.0027777608076854044, "biggest_recent_change": 0.19662700511526054},
{"total_number_of_episodes": 15243, "number_of_timesteps": 1730742, "per_episode_reward": -135.72, "episode_reward_trend_value": -0.004878450262481553, "biggest_recent_change": 0.19662700511526054},
{"total_number_of_episodes": 15253, "number_of_timesteps": 1731992, "per_episode_reward": -135.61, "episode_reward_trend_value": -0.0029725404567209858, "biggest_recent_change": 0.19662700511526054},
{"total_number_of_episodes": 15263, "number_of_timesteps": 1733181, "per_episode_reward": -135.64, "episode_reward_trend_value": -0.0041198333582517285, "biggest_recent_change": 0.19662700511526054},
{"total_number_of_episodes": 15273, "number_of_timesteps": 1734489, "per_episode_reward": -135.71, "episode_reward_trend_value": -0.004699723061282018, "biggest_recent_change": 0.19662700511526054},
{"total_number_of_episodes": 15283, "number_of_timesteps": 1735612, "per_episode_reward": -135.63, "episode_reward_trend_value": -0.0021192749127405047, "biggest_recent_change": 0.19662700511526054},
{"total_number_of_episodes": 15294, "number_of_timesteps": 1736935, "per_episode_reward": -135.68, "episode_reward_trend_value": -0.0021687879790679037, "biggest_recent_change": 0.19662700511526054},
{"total_number_of_episodes": 15304, "number_of_timesteps": 1738164, "per_episode_reward": -135.58, "episode_reward_trend_value": -0.00031186915157693166, "biggest_recent_change": 0.19662700511526054},
{"total_number_of_episodes": 15314, "number_of_timesteps": 1739095, "per_episode_reward": -135.56, "episode_reward_trend_value": -0.0020943592354806624, "biggest_recent_change": 0.19662700511526054},
{"total_number_of_episodes": 15324, "number_of_timesteps": 1740388, "per_episode_reward": -135.62, "episode_reward_trend_value": -0.0006176739993217476, "biggest_recent_change": 0.15850876531260383},
{"total_number_of_episodes": 15334, "number_of_timesteps": 1741702, "per_episode_reward": -135.7, "episode_reward_trend_value": 0.00029260529035563345, "biggest_recent_change": 0.11387600669746689},
{"total_number_of_episodes": 15344, "number_of_timesteps": 1742715, "per_episode_reward": -135.71, "episode_reward_trend_value": -0.0010767180241992315, "biggest_recent_change": 0.10584134421839053},
{"total_number_of_episodes": 15354, "number_of_timesteps": 1744212, "per_episode_reward": -135.64, "episode_reward_trend_value": 3.876482274891815e-05, "biggest_recent_change": 0.10584134421839053},
{"total_number_of_episodes": 15364, "number_of_timesteps": 1745096, "per_episode_reward": -135.48, "episode_reward_trend_value": 0.0024775545749457077, "biggest_recent_change": 0.15759070752429238},
{"total_number_of_episodes": 15374, "number_of_timesteps": 1746084, "per_episode_reward": -135.49, "episode_reward_trend_value": 0.0016067424406824356, "biggest_recent_change": 0.15759070752429238},
{"total_number_of_episodes": 15384, "number_of_timesteps": 1747182, "per_episode_reward": -135.63, "episode_reward_trend_value": 0.0005626820157592267, "biggest_recent_change": 0.15759070752429238},
{"total_number_of_episodes": 15395, "number_of_timesteps": 1748504, "per_episode_reward": -135.7, "episode_reward_trend_value": -0.0014151098053919971, "biggest_recent_change": 0.15759070752429238},
{"total_number_of_episodes": 15405, "number_of_timesteps": 1749445, "per_episode_reward": -135.55, "episode_reward_trend_value": 9.866331724373999e-05, "biggest_recent_change": 0.15759070752429238},
{"total_number_of_episodes": 15415, "number_of_timesteps": 1750212, "per_episode_reward": -135.45, "episode_reward_trend_value": 0.0018900529487467566, "biggest_recent_change": 0.15759070752429238},
{"total_number_of_episodes": 15426, "number_of_timesteps": 1751376, "per_episode_reward": -135.36, "episode_reward_trend_value": 0.00378514714545967, "biggest_recent_change": 0.15759070752429238},
{"total_number_of_episodes": 15436, "number_of_timesteps": 1752187, "per_episode_reward": -135.26, "episode_reward_trend_value": 0.0050014021044511815, "biggest_recent_change": 0.15759070752429238},
{"total_number_of_episodes": 15446, "number_of_timesteps": 1753361, "per_episode_reward": -135.31, "episode_reward_trend_value": 0.0036402028873283145, "biggest_recent_change": 0.15759070752429238},
{"total_number_of_episodes": 15456, "number_of_timesteps": 1754484, "per_episode_reward": -135.33, "episode_reward_trend_value": 0.001731573169207776, "biggest_recent_change": 0.15462259988296978},
{"total_number_of_episodes": 15466, "number_of_timesteps": 1755928, "per_episode_reward": -135.38, "episode_reward_trend_value": 0.0011647901125842156, "biggest_recent_change": 0.15462259988296978},
{"total_number_of_episodes": 15476, "number_of_timesteps": 1756976, "per_episode_reward": -135.66, "episode_reward_trend_value": -0.0003114773929224965, "biggest_recent_change": 0.27518597453109805},
{"total_number_of_episodes": 15486, "number_of_timesteps": 1758829, "per_episode_reward": -135.74, "episode_reward_trend_value": -0.0004378454428976713, "biggest_recent_change": 0.27518597453109805},
{"total_number_of_episodes": 15496, "number_of_timesteps": 1760056, "per_episode_reward": -135.69, "episode_reward_trend_value": -0.001580024314732024, "biggest_recent_change": 0.27518597453109805},
{"total_number_of_episodes": 15506, "number_of_timesteps": 1761239, "per_episode_reward": -135.8, "episode_reward_trend_value": -0.0038513022592825213, "biggest_recent_change": 0.27518597453109805},
{"total_number_of_episodes": 15517, "number_of_timesteps": 1762514, "per_episode_reward": -135.91, "episode_reward_trend_value": -0.006184929770534432, "biggest_recent_change": 0.27518597453109805},
{"total_number_of_episodes": 15528, "number_of_timesteps": 1763282, "per_episode_reward": -135.83, "episode_reward_trend_value": -0.006402813967344262, "biggest_recent_change": 0.27518597453109805},
{"total_number_of_episodes": 15538, "number_of_timesteps": 1764021, "per_episode_reward": -135.66, "episode_reward_trend_value": -0.003901608261695502, "biggest_recent_change": 0.27518597453109805},
{"total_number_of_episodes": 15549, "number_of_timesteps": 1765201, "per_episode_reward": -135.62, "episode_reward_trend_value": -0.003219370596718818, "biggest_recent_change": 0.27518597453109805},
{"total_number_of_episodes": 15559, "number_of_timesteps": 1766190, "per_episode_reward": -135.5, "episode_reward_trend_value": -0.001321053178745362, "biggest_recent_change": 0.27518597453109805},
{"total_number_of_episodes": 15570, "number_of_timesteps": 1767562, "per_episode_reward": -135.62, "episode_reward_trend_value": 0.00039012878736804804, "biggest_recent_change": 0.16833530210465142},
{"total_number_of_episodes": 15582, "number_of_timesteps": 1768774, "per_episode_reward": -135.51, "episode_reward_trend_value": 0.0025850046525723275, "biggest_recent_change": 0.16833530210465142},
{"total_number_of_episodes": 15593, "number_of_timesteps": 1769727, "per_episode_reward": -135.46, "episode_reward_trend_value": 0.00252688310019001, "biggest_recent_change": 0.16833530210465142},
{"total_number_of_episodes": 15603, "number_of_timesteps": 1770699, "per_episode_reward": -135.42, "episode_reward_trend_value": 0.00416576039629351, "biggest_recent_change": 0.16833530210465142},
{"total_number_of_episodes": 15613, "number_of_timesteps": 1771467, "per_episode_reward": -135.36, "episode_reward_trend_value": 0.006207384190203255, "biggest_recent_change": 0.16833530210465142},
{"total_number_of_episodes": 15623, "number_of_timesteps": 1772524, "per_episode_reward": -135.34, "episode_reward_trend_value": 0.005434478202703493, "biggest_recent_change": 0.16833530210465142},
{"total_number_of_episodes": 15633, "number_of_timesteps": 1774075, "per_episode_reward": -135.36, "episode_reward_trend_value": 0.0034426555336640125, "biggest_recent_change": 0.12117959758089114},
{"total_number_of_episodes": 15643, "number_of_timesteps": 1775332, "per_episode_reward": -135.4, "episode_reward_trend_value": 0.002428962936187102, "biggest_recent_change": 0.12117959758089114},
{"total_number_of_episodes": 15653, "number_of_timesteps": 1776430, "per_episode_reward": -135.32, "episode_reward_trend_value": 0.0020351322686470515, "biggest_recent_change": 0.12117959758089114},
{"total_number_of_episodes": 15664, "number_of_timesteps": 1777614, "per_episode_reward": -135.39, "episode_reward_trend_value": 0.002547674538927759, "biggest_recent_change": 0.11400578368539982},
{"total_number_of_episodes": 15674, "number_of_timesteps": 1779105, "per_episode_reward": -135.41, "episode_reward_trend_value": 0.0010929774102805823, "biggest_recent_change": 0.07947887888602168},
{"total_number_of_episodes": 15684, "number_of_timesteps": 1780360, "per_episode_reward": -135.39, "episode_reward_trend_value": 0.0008143628390538677, "biggest_recent_change": 0.07947887888602168},
{"total_number_of_episodes": 15694, "number_of_timesteps": 1781728, "per_episode_reward": -135.4, "episode_reward_trend_value": 0.00022491898360467783, "biggest_recent_change": 0.07947887888602168},
{"total_number_of_episodes": 15704, "number_of_timesteps": 1782904, "per_episode_reward": -135.37, "episode_reward_trend_value": -0.0001510131755010333, "biggest_recent_change": 0.07947887888602168},
{"total_number_of_episodes": 15715, "number_of_timesteps": 1783916, "per_episode_reward": -135.33, "episode_reward_trend_value": 0.00013101009326451024, "biggest_recent_change": 0.07947887888602168},
{"total_number_of_episodes": 15726, "number_of_timesteps": 1785147, "per_episode_reward": -135.4, "episode_reward_trend_value": -0.0005538614267613361, "biggest_recent_change": 0.07947887888602168},
{"total_number_of_episodes": 15736, "number_of_timesteps": 1786146, "per_episode_reward": -135.33, "episode_reward_trend_value": 0.0007199410613604111, "biggest_recent_change": 0.07947887888602168},
{"total_number_of_episodes": 15746, "number_of_timesteps": 1787392, "per_episode_reward": -135.26, "episode_reward_trend_value": 0.00061262045971849, "biggest_recent_change": 0.07505079325562747},
{"total_number_of_episodes": 15756, "number_of_timesteps": 1788504, "per_episode_reward": -135.39, "episode_reward_trend_value": 8.172589981162068e-05, "biggest_recent_change": 0.1228313036472457},
{"total_number_of_episodes": 15767, "number_of_timesteps": 1789745, "per_episode_reward": -135.41, "episode_reward_trend_value": 3.568049422458191e-05, "biggest_recent_change": 0.1228313036472457},
{"total_number_of_episodes": 15777, "number_of_timesteps": 1791075, "per_episode_reward": -135.3, "episode_reward_trend_value": 0.0009506524559798081, "biggest_recent_change": 0.1228313036472457},
{"total_number_of_episodes": 15788, "number_of_timesteps": 1792265, "per_episode_reward": -135.28, "episode_reward_trend_value": 0.0013877975577107312, "biggest_recent_change": 0.1228313036472457},
{"total_number_of_episodes": 15798, "number_of_timesteps": 1793452, "per_episode_reward": -135.33, "episode_reward_trend_value": 0.0004056010940214744, "biggest_recent_change": 0.1228313036472457},
{"total_number_of_episodes": 15808, "number_of_timesteps": 1794487, "per_episode_reward": -135.27, "episode_reward_trend_value": 0.0007066052878315077, "biggest_recent_change": 0.1228313036472457},
{"total_number_of_episodes": 15818, "number_of_timesteps": 1795670, "per_episode_reward": -135.31, "episode_reward_trend_value": 0.0010624407645637903, "biggest_recent_change": 0.1228313036472457},
{"total_number_of_episodes": 15829, "number_of_timesteps": 1797255, "per_episode_reward": -135.43, "episode_reward_trend_value": -0.0010718076617447676, "biggest_recent_change": 0.1228313036472457},
{"total_number_of_episodes": 15840, "number_of_timesteps": 1798784, "per_episode_reward": -135.53, "episode_reward_trend_value": -0.002992903906547895, "biggest_recent_change": 0.1228313036472457},
{"total_number_of_episodes": 15851, "number_of_timesteps": 1800113, "per_episode_reward": -135.45, "episode_reward_trend_value": -0.0006864062170592433, "biggest_recent_change": 0.12145704546838942},
{"total_number_of_episodes": 15861, "number_of_timesteps": 1801150, "per_episode_reward": -135.45, "episode_reward_trend_value": -0.0004630796779666626, "biggest_recent_change": 0.12145704546838942},
{"total_number_of_episodes": 15872, "number_of_timesteps": 1802362, "per_episode_reward": -135.47, "episode_reward_trend_value": -0.0018937959638741912, "biggest_recent_change": 0.12145704546838942},
{"total_number_of_episodes": 15882, "number_of_timesteps": 1803547, "per_episode_reward": -135.5, "episode_reward_trend_value": -0.0025238074586657906, "biggest_recent_change": 0.12145704546838942},
{"total_number_of_episodes": 15892, "number_of_timesteps": 1804726, "per_episode_reward": -135.53, "episode_reward_trend_value": -0.0022004194385352267, "biggest_recent_change": 0.12145704546838942},
{"total_number_of_episodes": 15903, "number_of_timesteps": 1805748, "per_episode_reward": -135.48, "episode_reward_trend_value": -0.0024006594917835855, "biggest_recent_change": 0.12145704546838942},
{"total_number_of_episodes": 15913, "number_of_timesteps": 1806854, "per_episode_reward": -135.46, "episode_reward_trend_value": -0.0017166205982404234, "biggest_recent_change": 0.12145704546838942},
{"total_number_of_episodes": 15923, "number_of_timesteps": 1808042, "per_episode_reward": -135.43, "episode_reward_trend_value": -1.2356438907722299e-05, "biggest_recent_change": 0.10307863729403266},
{"total_number_of_episodes": 15933, "number_of_timesteps": 1809215, "per_episode_reward": -135.35, "episode_reward_trend_value": 0.002077179015193388, "biggest_recent_change": 0.08497955357506726},
{"total_number_of_episodes": 15943, "number_of_timesteps": 1810429, "per_episode_reward": -135.31, "episode_reward_trend_value": 0.0015689358798684654, "biggest_recent_change": 0.08497955357506726},
{"total_number_of_episodes": 15953, "number_of_timesteps": 1811396, "per_episode_reward": -135.3, "episode_reward_trend_value": 0.0016953229311714797, "biggest_recent_change": 0.08497955357506726},
{"total_number_of_episodes": 15964, "number_of_timesteps": 1812770, "per_episode_reward": -135.25, "episode_reward_trend_value": 0.002546471012471506, "biggest_recent_change": 0.08497955357506726},
{"total_number_of_episodes": 15975, "number_of_timesteps": 1813913, "per_episode_reward": -135.29, "episode_reward_trend_value": 0.0023648963221748745, "biggest_recent_change": 0.08497955357506726},
{"total_number_of_episodes": 15985, "number_of_timesteps": 1815246, "per_episode_reward": -135.29, "episode_reward_trend_value": 0.002706516502073618, "biggest_recent_change": 0.08497955357506726},
{"total_number_of_episodes": 15995, "number_of_timesteps": 1816604, "per_episode_reward": -135.24, "episode_reward_trend_value": 0.0027185283626449874, "biggest_recent_change": 0.08497955357506726},
{"total_number_of_episodes": 16005, "number_of_timesteps": 1817666, "per_episode_reward": -135.23, "episode_reward_trend_value": 0.0025436394585230775, "biggest_recent_change": 0.08497955357506726},
{"total_number_of_episodes": 16016, "number_of_timesteps": 1819123, "per_episode_reward": -135.24, "episode_reward_trend_value": 0.0021511027182343568, "biggest_recent_change": 0.08497955357506726},
{"total_number_of_episodes": 16026, "number_of_timesteps": 1820051, "per_episode_reward": -135.21, "episode_reward_trend_value": 0.001491972634579497, "biggest_recent_change": 0.051706588436360335},
{"total_number_of_episodes": 16036, "number_of_timesteps": 1821242, "per_episode_reward": -135.23, "episode_reward_trend_value": 0.0008928697039029506, "biggest_recent_change": 0.051706588436360335},
{"total_number_of_episodes": 16046, "number_of_timesteps": 1822838, "per_episode_reward": -135.31, "episode_reward_trend_value": -0.0001389297381801195, "biggest_recent_change": 0.08244877104755233},
{"total_number_of_episodes": 16056, "number_of_timesteps": 1823837, "per_episode_reward": -135.29, "episode_reward_trend_value": -0.0005156075788594055, "biggest_recent_change": 0.08244877104755233},
{"total_number_of_episodes": 16066, "number_of_timesteps": 1824796, "per_episode_reward": -135.31, "episode_reward_trend_value": -0.00018378052843483298, "biggest_recent_change": 0.08244877104755233},
{"total_number_of_episodes": 16077, "number_of_timesteps": 1826064, "per_episode_reward": -135.32, "episode_reward_trend_value": -0.00039092644528169427, "biggest_recent_change": 0.08244877104755233},
{"total_number_of_episodes": 16088, "number_of_timesteps": 1827143, "per_episode_reward": -135.24, "episode_reward_trend_value": -1.8132865693903314e-05, "biggest_recent_change": 0.08244877104755233},
{"total_number_of_episodes": 16098, "number_of_timesteps": 1828366, "per_episode_reward": -135.17, "episode_reward_trend_value": 0.000690893320375431, "biggest_recent_change": 0.08244877104755233},
{"total_number_of_episodes": 16108, "number_of_timesteps": 1829441, "per_episode_reward": -135.24, "episode_reward_trend_value": -3.802671900467027e-05, "biggest_recent_change": 0.08244877104755233},
{"total_number_of_episodes": 16119, "number_of_timesteps": 1830612, "per_episode_reward": -135.11, "episode_reward_trend_value": 0.0011801961789091012, "biggest_recent_change": 0.1352979068583693},
{"total_number_of_episodes": 16129, "number_of_timesteps": 1831700, "per_episode_reward": -135.04, "episode_reward_trend_value": 0.0020450705299465553, "biggest_recent_change": 0.1352979068583693},
{"total_number_of_episodes": 16139, "number_of_timesteps": 1832945, "per_episode_reward": -135.05, "episode_reward_trend_value": 0.0028396956302351047, "biggest_recent_change": 0.1352979068583693},
{"total_number_of_episodes": 16149, "number_of_timesteps": 1834378, "per_episode_reward": -135.09, "episode_reward_trend_value": 0.0022025437879812496, "biggest_recent_change": 0.1352979068583693},
{"total_number_of_episodes": 16160, "number_of_timesteps": 1835779, "per_episode_reward": -135.12, "episode_reward_trend_value": 0.002053947766223827, "biggest_recent_change": 0.1352979068583693},
{"total_number_of_episodes": 16170, "number_of_timesteps": 1836906, "per_episode_reward": -135.13, "episode_reward_trend_value": 0.0021122055291992107, "biggest_recent_change": 0.1352979068583693},
{"total_number_of_episodes": 16181, "number_of_timesteps": 1838261, "per_episode_reward": -135.29, "episode_reward_trend_value": -0.0005549420667702204, "biggest_recent_change": 0.16003118907457292},
{"total_number_of_episodes": 16191, "number_of_timesteps": 1839514, "per_episode_reward": -135.27, "episode_reward_trend_value": -0.001028161740493753, "biggest_recent_change": 0.16003118907457292},
{"total_number_of_episodes": 16201, "number_of_timesteps": 1841115, "per_episode_reward": -135.22, "episode_reward_trend_value": 0.00019840453472347186, "biggest_recent_change": 0.16003118907457292},
{"total_number_of_episodes": 16211, "number_of_timesteps": 1842244, "per_episode_reward": -135.21, "episode_reward_trend_value": -0.0011988223002677816, "biggest_recent_change": 0.16003118907457292},
{"total_number_of_episodes": 16221, "number_of_timesteps": 1844216, "per_episode_reward": -135.2, "episode_reward_trend_value": -0.001686337324330604, "biggest_recent_change": 0.16003118907457292},
{"total_number_of_episodes": 16232, "number_of_timesteps": 1845231, "per_episode_reward": -135.14, "episode_reward_trend_value": -0.0009811285852998077, "biggest_recent_change": 0.16003118907457292},
{"total_number_of_episodes": 16242, "number_of_timesteps": 1846077, "per_episode_reward": -135.1, "episode_reward_trend_value": -9.173116028572773e-05, "biggest_recent_change": 0.16003118907457292},
{"total_number_of_episodes": 16252, "number_of_timesteps": 1846882, "per_episode_reward": -135.03, "episode_reward_trend_value": 0.0010815627732540633, "biggest_recent_change": 0.16003118907457292},
{"total_number_of_episodes": 16262, "number_of_timesteps": 1848077, "per_episode_reward": -135.05, "episode_reward_trend_value": 0.000851996124316972, "biggest_recent_change": 0.16003118907457292},
{"total_number_of_episodes": 16272, "number_of_timesteps": 1849367, "per_episode_reward": -135.08, "episode_reward_trend_value": 0.0023740674042913826, "biggest_recent_change": 0.07592127672012339},
{"total_number_of_episodes": 16282, "number_of_timesteps": 1850434, "per_episode_reward": -135.08, "episode_reward_trend_value": 0.0020214391951134934, "biggest_recent_change": 0.07592127672012339},
{"total_number_of_episodes": 16292, "number_of_timesteps": 1851710, "per_episode_reward": -135.08, "episode_reward_trend_value": 0.0016482455449271863, "biggest_recent_change": 0.07592127672012339},
{"total_number_of_episodes": 16302, "number_of_timesteps": 1852866, "per_episode_reward": -135.08, "episode_reward_trend_value": 0.0015365243899831663, "biggest_recent_change": 0.07592127672012339},
{"total_number_of_episodes": 16312, "number_of_timesteps": 1854562, "per_episode_reward": -135.11, "episode_reward_trend_value": 0.0009212947296987295, "biggest_recent_change": 0.07592127672012339},
{"total_number_of_episodes": 16322, "number_of_timesteps": 1855780, "per_episode_reward": -135.14, "episode_reward_trend_value": 5.059884864806463e-05, "biggest_recent_change": 0.07592127672012339},
{"total_number_of_episodes": 16333, "number_of_timesteps": 1857566, "per_episode_reward": -135.12, "episode_reward_trend_value": -0.00015549867725957888, "biggest_recent_change": 0.07592127672012339},

{"total_number_of_episodes": 16343, "number_of_timesteps": 1858530, "per_episode_reward": -135.1, "episode_reward_trend_value": -0.0007780190794060597, "biggest_recent_change": 0.036315987531281735},
{"total_number_of_episodes": 16353, "number_of_timesteps": 1859816, "per_episode_reward": -135.1, "episode_reward_trend_value": -0.0004818766823439723, "biggest_recent_change": 0.036315987531281735},
{"total_number_of_episodes": 16363, "number_of_timesteps": 1860926, "per_episode_reward": -135.09, "episode_reward_trend_value": -0.0001702042912360942, "biggest_recent_change": 0.036315987531281735},
{"total_number_of_episodes": 16373, "number_of_timesteps": 1862318, "per_episode_reward": -135.12, "episode_reward_trend_value": -0.00045470699530862174, "biggest_recent_change": 0.036315987531281735},
{"total_number_of_episodes": 16384, "number_of_timesteps": 1863376, "per_episode_reward": -135.11, "episode_reward_trend_value": -0.0003468284684054702, "biggest_recent_change": 0.036315987531281735},
{"total_number_of_episodes": 16394, "number_of_timesteps": 1864239, "per_episode_reward": -135.07, "episode_reward_trend_value": 6.125726176233254e-05, "biggest_recent_change": 0.036315987531281735},
{"total_number_of_episodes": 16404, "number_of_timesteps": 1865175, "per_episode_reward": -135.01, "episode_reward_trend_value": 0.0010982762479996053, "biggest_recent_change": 0.05701572123007281},
{"total_number_of_episodes": 16414, "number_of_timesteps": 1866284, "per_episode_reward": -135.01, "episode_reward_trend_value": 0.001385235745814839, "biggest_recent_change": 0.05701572123007281},
{"total_number_of_episodes": 16424, "number_of_timesteps": 1868231, "per_episode_reward": -134.96, "episode_reward_trend_value": 0.0017042761952881038, "biggest_recent_change": 0.05701572123007281},
{"total_number_of_episodes": 16434, "number_of_timesteps": 1869025, "per_episode_reward": -134.89, "episode_reward_trend_value": 0.002340851135601775, "biggest_recent_change": 0.0771861851551705},
{"total_number_of_episodes": 16444, "number_of_timesteps": 1869753, "per_episode_reward": -134.8, "episode_reward_trend_value": 0.003350667833316518, "biggest_recent_change": 0.08878906212996185},
{"total_number_of_episodes": 16454, "number_of_timesteps": 1870725, "per_episode_reward": -134.77, "episode_reward_trend_value": 0.0035684372332317102, "biggest_recent_change": 0.08878906212996185},
{"total_number_of_episodes": 16464, "number_of_timesteps": 1871686, "per_episode_reward": -134.84, "episode_reward_trend_value": 0.003207147926084354, "biggest_recent_change": 0.08878906212996185},
{"total_number_of_episodes": 16474, "number_of_timesteps": 1872518, "per_episode_reward": -134.77, "episode_reward_trend_value": 0.0037343679243242098, "biggest_recent_change": 0.08878906212996185},
{"total_number_of_episodes": 16484, "number_of_timesteps": 1873581, "per_episode_reward": -134.72, "episode_reward_trend_value": 0.003910216648924032, "biggest_recent_change": 0.08878906212996185},
{"total_number_of_episodes": 16494, "number_of_timesteps": 1874706, "per_episode_reward": -134.72, "episode_reward_trend_value": 0.003232655824609449, "biggest_recent_change": 0.08878906212996185},
{"total_number_of_episodes": 16504, "number_of_timesteps": 1875671, "per_episode_reward": -134.68, "episode_reward_trend_value": 0.003740394259590908, "biggest_recent_change": 0.08878906212996185},
{"total_number_of_episodes": 16514, "number_of_timesteps": 1876883, "per_episode_reward": -134.72, "episode_reward_trend_value": 0.0027119908264062868, "biggest_recent_change": 0.08878906212996185},
{"total_number_of_episodes": 16525, "number_of_timesteps": 1878148, "per_episode_reward": -134.74, "episode_reward_trend_value": 0.001566695183537566, "biggest_recent_change": 0.08878906212996185},
{"total_number_of_episodes": 16535, "number_of_timesteps": 1879323, "per_episode_reward": -134.73, "episode_reward_trend_value": 0.0007594638440830674, "biggest_recent_change": 0.06495802221701297},
{"total_number_of_episodes": 16545, "number_of_timesteps": 1880500, "per_episode_reward": -134.76, "episode_reward_trend_value": 0.00011700135512108369, "biggest_recent_change": 0.06495802221701297},
{"total_number_of_episodes": 16555, "number_of_timesteps": 1881764, "per_episode_reward": -134.81, "episode_reward_trend_value": 0.0002600681415553178, "biggest_recent_change": 0.06495802221701297},
{"total_number_of_episodes": 16566, "number_of_timesteps": 1883277, "per_episode_reward": -134.85, "episode_reward_trend_value": -0.000879400372163117, "biggest_recent_change": 0.052046688693280885},
{"total_number_of_episodes": 16577, "number_of_timesteps": 1884362, "per_episode_reward": -134.83, "episode_reward_trend_value": -0.0012632080749799316, "biggest_recent_change": 0.050477705903006154},
{"total_number_of_episodes": 16588, "number_of_timesteps": 1885255, "per_episode_reward": -134.79, "episode_reward_trend_value": -0.0007009193072096625, "biggest_recent_change": 0.050477705903006154},
{"total_number_of_episodes": 16598, "number_of_timesteps": 1886455, "per_episode_reward": -134.84, "episode_reward_trend_value": -0.0018082960769627715, "biggest_recent_change": 0.05396745012944848},
{"total_number_of_episodes": 16608, "number_of_timesteps": 1887289, "per_episode_reward": -134.86, "episode_reward_trend_value": -0.0015169931310468755, "biggest_recent_change": 0.05396745012944848},
{"total_number_of_episodes": 16618, "number_of_timesteps": 1888325, "per_episode_reward": -134.85, "episode_reward_trend_value": -0.001144516466467217, "biggest_recent_change": 0.05396745012944848},
{"total_number_of_episodes": 16628, "number_of_timesteps": 1889527, "per_episode_reward": -134.81, "episode_reward_trend_value": -0.0008534915470262503, "biggest_recent_change": 0.05396745012944848},
{"total_number_of_episodes": 16639, "number_of_timesteps": 1890468, "per_episode_reward": -134.77, "episode_reward_trend_value": -0.00011318458536430222, "biggest_recent_change": 0.05396745012944848},
{"total_number_of_episodes": 16649, "number_of_timesteps": 1891632, "per_episode_reward": -134.76, "episode_reward_trend_value": 0.0005618268131876726, "biggest_recent_change": 0.05396745012944848},
{"total_number_of_episodes": 16659, "number_of_timesteps": 1893135, "per_episode_reward": -134.81, "episode_reward_trend_value": 0.0004718817385177469, "biggest_recent_change": 0.05396745012944848},
{"total_number_of_episodes": 16670, "number_of_timesteps": 1894549, "per_episode_reward": -134.83, "episode_reward_trend_value": 3.272511915244852e-05, "biggest_recent_change": 0.05396745012944848},
{"total_number_of_episodes": 16680, "number_of_timesteps": 1895631, "per_episode_reward": -134.81, "episode_reward_trend_value": -0.0002876990862224223, "biggest_recent_change": 0.05396745012944848},
{"total_number_of_episodes": 16690, "number_of_timesteps": 1896804, "per_episode_reward": -134.78, "episode_reward_trend_value": 0.0006189757769937564, "biggest_recent_change": 0.04568920073793947},
{"total_number_of_episodes": 16701, "number_of_timesteps": 1898182, "per_episode_reward": -134.82, "episode_reward_trend_value": 0.00043421443753320296, "biggest_recent_change": 0.04568920073793947},
{"total_number_of_episodes": 16713, "number_of_timesteps": 1899301, "per_episode_reward": -134.82, "episode_reward_trend_value": 0.00035038819555287167, "biggest_recent_change": 0.04568920073793947},
{"total_number_of_episodes": 16723, "number_of_timesteps": 1900257, "per_episode_reward": -134.77, "episode_reward_trend_value": 0.00043180703526767656, "biggest_recent_change": 0.049658179903076416},
{"total_number_of_episodes": 16733, "number_of_timesteps": 1901367, "per_episode_reward": -134.8, "episode_reward_trend_value": -0.0003329059888247659, "biggest_recent_change": 0.049658179903076416},
{"total_number_of_episodes": 16743, "number_of_timesteps": 1903803, "per_episode_reward": -134.77, "episode_reward_trend_value": -0.00011531023005741442, "biggest_recent_change": 0.049658179903076416},
{"total_number_of_episodes": 16753, "number_of_timesteps": 1904941, "per_episode_reward": -134.76, "episode_reward_trend_value": 0.0005774666631588666, "biggest_recent_change": 0.049658179903076416},
{"total_number_of_episodes": 16763, "number_of_timesteps": 1905837, "per_episode_reward": -134.75, "episode_reward_trend_value": 0.0009070099048108836, "biggest_recent_change": 0.049658179903076416},
{"total_number_of_episodes": 16774, "number_of_timesteps": 1907314, "per_episode_reward": -134.78, "episode_reward_trend_value": 0.00036633139900490937, "biggest_recent_change": 0.049658179903076416},
{"total_number_of_episodes": 16785, "number_of_timesteps": 1908573, "per_episode_reward": -134.79, "episode_reward_trend_value": -0.0001065291106805767, "biggest_recent_change": 0.049658179903076416},
{"total_number_of_episodes": 16796, "number_of_timesteps": 1909619, "per_episode_reward": -134.78, "episode_reward_trend_value": 0.00043260879612982235, "biggest_recent_change": 0.049658179903076416},
{"total_number_of_episodes": 16806, "number_of_timesteps": 1910358, "per_episode_reward": -134.72, "episode_reward_trend_value": 0.0010869079305406456, "biggest_recent_change": 0.058975037427899224},
{"total_number_of_episodes": 16816, "number_of_timesteps": 1911690, "per_episode_reward": -134.72, "episode_reward_trend_value": 0.000526471622645709, "biggest_recent_change": 0.058975037427899224},
{"total_number_of_episodes": 16827, "number_of_timesteps": 1912913, "per_episode_reward": -134.69, "episode_reward_trend_value": 0.0012047178597271112, "biggest_recent_change": 0.058975037427899224},
{"total_number_of_episodes": 16837, "number_of_timesteps": 1914262, "per_episode_reward": -134.66, "episode_reward_trend_value": 0.0012435553584673976, "biggest_recent_change": 0.058975037427899224},
{"total_number_of_episodes": 16849, "number_of_timesteps": 1915745, "per_episode_reward": -134.67, "episode_reward_trend_value": 0.0009232327380336377, "biggest_recent_change": 0.058975037427899224},
{"total_number_of_episodes": 16859, "number_of_timesteps": 1916893, "per_episode_reward": -134.67, "episode_reward_trend_value": 0.000901081309459073, "biggest_recent_change": 0.058975037427899224},
{"total_number_of_episodes": 16869, "number_of_timesteps": 1918007, "per_episode_reward": -134.66, "episode_reward_trend_value": 0.0013260440184555793, "biggest_recent_change": 0.058975037427899224},
{"total_number_of_episodes": 16879, "number_of_timesteps": 1919412, "per_episode_reward": -134.7, "episode_reward_trend_value": 0.0010710329781586678, "biggest_recent_change": 0.058975037427899224},
{"total_number_of_episodes": 16889, "number_of_timesteps": 1920541, "per_episode_reward": -134.67, "episode_reward_trend_value": 0.0012301612270274771, "biggest_recent_change": 0.058975037427899224},
{"total_number_of_episodes": 16899, "number_of_timesteps": 1921268, "per_episode_reward": -134.64, "episode_reward_trend_value": 0.0008907801021182295, "biggest_recent_change": 0.03787515193840818},
{"total_number_of_episodes": 16909, "number_of_timesteps": 1922124, "per_episode_reward": -134.61, "episode_reward_trend_value": 0.0011913044467516127, "biggest_recent_change": 0.03787515193840818},
{"total_number_of_episodes": 16921, "number_of_timesteps": 1923628, "per_episode_reward": -134.59, "episode_reward_trend_value": 0.001189258815162475, "biggest_recent_change": 0.03787515193840818},
{"total_number_of_episodes": 16931, "number_of_timesteps": 1924793, "per_episode_reward": -134.59, "episode_reward_trend_value": 0.0007966167384943724, "biggest_recent_change": 0.03787515193840818},
{"total_number_of_episodes": 16941, "number_of_timesteps": 1925809, "per_episode_reward": -134.57, "episode_reward_trend_value": 0.0011511144828947155, "biggest_recent_change": 0.03787515193840818},
{"total_number_of_episodes": 16951, "number_of_timesteps": 1926745, "per_episode_reward": -134.54, "episode_reward_trend_value": 0.001409289348673484, "biggest_recent_change": 0.03787515193840818},
{"total_number_of_episodes": 16961, "number_of_timesteps": 1927960, "per_episode_reward": -134.56, "episode_reward_trend_value": 0.0011170330255999437, "biggest_recent_change": 0.03787515193840818},
{"total_number_of_episodes": 16971, "number_of_timesteps": 1929236, "per_episode_reward": -134.55, "episode_reward_trend_value": 0.0016362268730615724, "biggest_recent_change": 0.03054893795004432},
{"total_number_of_episodes": 16981, "number_of_timesteps": 1930148, "per_episode_reward": -134.46, "episode_reward_trend_value": 0.0023449143030407843, "biggest_recent_change": 0.0943308066481734},
{"total_number_of_episodes": 16992, "number_of_timesteps": 1931451, "per_episode_reward": -134.53, "episode_reward_trend_value": 0.0011647869954720769, "biggest_recent_change": 0.0943308066481734},
{"total_number_of_episodes": 17002, "number_of_timesteps": 1932413, "per_episode_reward": -134.5, "episode_reward_trend_value": 0.0012334783233591729, "biggest_recent_change": 0.0943308066481734},
{"total_number_of_episodes": 17012, "number_of_timesteps": 1933793, "per_episode_reward": -134.58, "episode_reward_trend_value": 9.776016307291178e-05, "biggest_recent_change": 0.0943308066481734},
{"total_number_of_episodes": 17022, "number_of_timesteps": 1935434, "per_episode_reward": -134.62, "episode_reward_trend_value": -0.0003141961678867094, "biggest_recent_change": 0.0943308066481734},
{"total_number_of_episodes": 17032, "number_of_timesteps": 1936572, "per_episode_reward": -134.68, "episode_reward_trend_value": -0.0012868870293731207, "biggest_recent_change": 0.0943308066481734},
{"total_number_of_episodes": 17043, "number_of_timesteps": 1937955, "per_episode_reward": -134.8, "episode_reward_trend_value": -0.0028514648550665494, "biggest_recent_change": 0.11193110351845803},
{"total_number_of_episodes": 17053, "number_of_timesteps": 1938959, "per_episode_reward": -134.78, "episode_reward_trend_value": -0.0024087746423788305, "biggest_recent_change": 0.11193110351845803},
{"total_number_of_episodes": 17064, "number_of_timesteps": 1940722, "per_episode_reward": -134.73, "episode_reward_trend_value": -0.0020270716314905084, "biggest_recent_change": 0.11193110351845803},
{"total_number_of_episodes": 17074, "number_of_timesteps": 1941973, "per_episode_reward": -134.8, "episode_reward_trend_value": -0.003776593975115361, "biggest_recent_change": 0.11193110351845803},
{"total_number_of_episodes": 17084, "number_of_timesteps": 1943200, "per_episode_reward": -134.94, "episode_reward_trend_value": -0.004550423277520584, "biggest_recent_change": 0.1474253587115868},
{"total_number_of_episodes": 17094, "number_of_timesteps": 1944472, "per_episode_reward": -134.89, "episode_reward_trend_value": -0.004315605099259616, "biggest_recent_change": 0.1474253587115868},

{"total_number_of_episodes": 17104, "number_of_timesteps": 1945914, "per_episode_reward": -134.94, "episode_reward_trend_value": -0.0039799552174745005, "biggest_recent_change": 0.1474253587115868},
{"total_number_of_episodes": 17114, "number_of_timesteps": 1947065, "per_episode_reward": -134.93, "episode_reward_trend_value": -0.003526978688316894, "biggest_recent_change": 0.1474253587115868},
{"total_number_of_episodes": 17124, "number_of_timesteps": 1948090, "per_episode_reward": -134.95, "episode_reward_trend_value": -0.0029419055912591656, "biggest_recent_change": 0.1474253587115868},
{"total_number_of_episodes": 17134, "number_of_timesteps": 1949849, "per_episode_reward": -134.87, "episode_reward_trend_value": -0.0007967229685947232, "biggest_recent_change": 0.1474253587115868},
{"total_number_of_episodes": 17144, "number_of_timesteps": 1950950, "per_episode_reward": -134.92, "episode_reward_trend_value": -0.0015960526653565747, "biggest_recent_change": 0.1474253587115868},
{"total_number_of_episodes": 17155, "number_of_timesteps": 1952709, "per_episode_reward": -134.94, "episode_reward_trend_value": -0.0022765668108171945, "biggest_recent_change": 0.1474253587115868},
{"total_number_of_episodes": 17165, "number_of_timesteps": 1953750, "per_episode_reward": -134.93, "episode_reward_trend_value": -0.001500871893512428, "biggest_recent_change": 0.1474253587115868},
{"total_number_of_episodes": 17175, "number_of_timesteps": 1954773, "per_episode_reward": -134.89, "episode_reward_trend_value": 0.0005463723411142812, "biggest_recent_change": 0.08113533252134175},
{"total_number_of_episodes": 17185, "number_of_timesteps": 1955821, "per_episode_reward": -134.9, "episode_reward_trend_value": -8.592916331622291e-05, "biggest_recent_change": 0.08113533252134175},
{"total_number_of_episodes": 17195, "number_of_timesteps": 1957001, "per_episode_reward": -134.87, "episode_reward_trend_value": 0.0006804383736247625, "biggest_recent_change": 0.08113533252134175},
{"total_number_of_episodes": 17206, "number_of_timesteps": 1958464, "per_episode_reward": -134.9, "episode_reward_trend_value": 0.0004165356510943259, "biggest_recent_change": 0.08113533252134175},
{"total_number_of_episodes": 17216, "number_of_timesteps": 1959538, "per_episode_reward": -134.99, "episode_reward_trend_value": -0.0004473538047104992, "biggest_recent_change": 0.0928991690124974},
{"total_number_of_episodes": 17226, "number_of_timesteps": 1961308, "per_episode_reward": -135.04, "episode_reward_trend_value": -0.0019376535239028197, "biggest_recent_change": 0.0928991690124974},
{"total_number_of_episodes": 17236, "number_of_timesteps": 1962630, "per_episode_reward": -135.0, "episode_reward_trend_value": -0.0009105223139607056, "biggest_recent_change": 0.0928991690124974},
{"total_number_of_episodes": 17247, "number_of_timesteps": 1963640, "per_episode_reward": -134.93, "episode_reward_trend_value": 3.8916413815096954e-05, "biggest_recent_change": 0.0928991690124974},
{"total_number_of_episodes": 17257, "number_of_timesteps": 1964400, "per_episode_reward": -134.83, "episode_reward_trend_value": 0.0011228697245027459, "biggest_recent_change": 0.104242136241254},
{"total_number_of_episodes": 17268, "number_of_timesteps": 1965365, "per_episode_reward": -134.76, "episode_reward_trend_value": 0.0014749739496538595, "biggest_recent_change": 0.104242136241254},
{"total_number_of_episodes": 17278, "number_of_timesteps": 1966575, "per_episode_reward": -134.79, "episode_reward_trend_value": 0.0011566752910378377, "biggest_recent_change": 0.104242136241254},
{"total_number_of_episodes": 17288, "number_of_timesteps": 1967531, "per_episode_reward": -134.72, "episode_reward_trend_value": 0.001717768329032765, "biggest_recent_change": 0.104242136241254},
{"total_number_of_episodes": 17298, "number_of_timesteps": 1968630, "per_episode_reward": -134.76, "episode_reward_trend_value": 0.0015078436400961614, "biggest_recent_change": 0.104242136241254},
{"total_number_of_episodes": 17309, "number_of_timesteps": 1970226, "per_episode_reward": -134.73, "episode_reward_trend_value": 0.002882398363780049, "biggest_recent_change": 0.104242136241254},
{"total_number_of_episodes": 17319, "number_of_timesteps": 1971364, "per_episode_reward": -134.75, "episode_reward_trend_value": 0.003194484133447241, "biggest_recent_change": 0.104242136241254},
{"total_number_of_episodes": 17329, "number_of_timesteps": 1972509, "per_episode_reward": -134.76, "episode_reward_trend_value": 0.00269497600802361, "biggest_recent_change": 0.104242136241254},
{"total_number_of_episodes": 17339, "number_of_timesteps": 1973337, "per_episode_reward": -134.71, "episode_reward_trend_value": 0.0024976402626843237, "biggest_recent_change": 0.104242136241254},
{"total_number_of_episodes": 17349, "number_of_timesteps": 1974483, "per_episode_reward": -134.76, "episode_reward_trend_value": 0.0007766502262806323, "biggest_recent_change": 0.0729101788633102},
{"total_number_of_episodes": 17359, "number_of_timesteps": 1975764, "per_episode_reward": -134.8, "episode_reward_trend_value": -0.0004278592534322772, "biggest_recent_change": 0.0729101788633102},
{"total_number_of_episodes": 17370, "number_of_timesteps": 1977016, "per_episode_reward": -134.79, "episode_reward_trend_value": 8.204352178766941e-05, "biggest_recent_change": 0.0729101788633102},
{"total_number_of_episodes": 17381, "number_of_timesteps": 1978137, "per_episode_reward": -134.76, "episode_reward_trend_value": -0.0004130955466204493, "biggest_recent_change": 0.050646967035078205},
{"total_number_of_episodes": 17392, "number_of_timesteps": 1979304, "per_episode_reward": -134.71, "episode_reward_trend_value": 0.0005607467032730382, "biggest_recent_change": 0.050646967035078205},
{"total_number_of_episodes": 17402, "number_of_timesteps": 1981048, "per_episode_reward": -134.68, "episode_reward_trend_value": 0.0005865169897431441, "biggest_recent_change": 0.050646967035078205},
{"total_number_of_episodes": 17413, "number_of_timesteps": 1982479, "per_episode_reward": -134.77, "episode_reward_trend_value": -0.00013483283668575848, "biggest_recent_change": 0.08982540731452104},
{"total_number_of_episodes": 17423, "number_of_timesteps": 1983880, "per_episode_reward": -134.74, "episode_reward_trend_value": 0.00023782819917812504, "biggest_recent_change": 0.08982540731452104},
{"total_number_of_episodes": 17433, "number_of_timesteps": 1984773, "per_episode_reward": -134.77, "episode_reward_trend_value": -0.0006473067427833712, "biggest_recent_change": 0.08982540731452104},
{"total_number_of_episodes": 17443, "number_of_timesteps": 1985806, "per_episode_reward": -134.72, "episode_reward_trend_value": 0.0004252477499073216, "biggest_recent_change": 0.08982540731452104},
{"total_number_of_episodes": 17453, "number_of_timesteps": 1987070, "per_episode_reward": -134.72, "episode_reward_trend_value": 0.0009144799717240125, "biggest_recent_change": 0.08982540731452104},
{"total_number_of_episodes": 17463, "number_of_timesteps": 1988283, "per_episode_reward": -134.71, "episode_reward_trend_value": 0.0008038332178699648, "biggest_recent_change": 0.08982540731452104},
{"total_number_of_episodes": 17473, "number_of_timesteps": 1989288, "per_episode_reward": -134.7, "episode_reward_trend_value": 0.0006480658843862052, "biggest_recent_change": 0.08982540731452104},
{"total_number_of_episodes": 17484, "number_of_timesteps": 1990678, "per_episode_reward": -134.76, "episode_reward_trend_value": -0.0005786718183928643, "biggest_recent_change": 0.08982540731452104},
{"total_number_of_episodes": 17494, "number_of_timesteps": 1991817, "per_episode_reward": -134.81, "episode_reward_trend_value": -0.0014267571169505624, "biggest_recent_change": 0.08982540731452104},
{"total_number_of_episodes": 17504, "number_of_timesteps": 1993051, "per_episode_reward": -134.8, "episode_reward_trend_value": -0.0003426385024981629, "biggest_recent_change": 0.06369871371168756},
{"total_number_of_episodes": 17515, "number_of_timesteps": 1994560, "per_episode_reward": -134.81, "episode_reward_trend_value": -0.0008316959979494086, "biggest_recent_change": 0.06369871371168756},
{"total_number_of_episodes": 17525, "number_of_timesteps": 1995789, "per_episode_reward": -134.84, "episode_reward_trend_value": -0.0008131054237566105, "biggest_recent_change": 0.06369871371168756},
{"total_number_of_episodes": 17535, "number_of_timesteps": 1996786, "per_episode_reward": -134.81, "episode_reward_trend_value": -0.0009685946901710294, "biggest_recent_change": 0.06369871371168756},
{"total_number_of_episodes": 17545, "number_of_timesteps": 1998196, "per_episode_reward": -134.83, "episode_reward_trend_value": -0.0012153290083486152, "biggest_recent_change": 0.06369871371168756},
{"total_number_of_episodes": 17556, "number_of_timesteps": 1999279, "per_episode_reward": -134.84, "episode_reward_trend_value": -0.0014544353541418155, "biggest_recent_change": 0.06369871371168756},
{"total_number_of_episodes": 17567, "number_of_timesteps": 2000565, "per_episode_reward": -134.83, "episode_reward_trend_value": -0.001436503142202936, "biggest_recent_change": 0.06369871371168756},
{"total_number_of_episodes": 17577, "number_of_timesteps": 2001830, "per_episode_reward": -134.82, "episode_reward_trend_value": -0.0006032892438990226, "biggest_recent_change": 0.0431975949688308},
{"total_number_of_episodes": 17587, "number_of_timesteps": 2003078, "per_episode_reward": -134.92, "episode_reward_trend_value": -0.0013128855271168681, "biggest_recent_change": 0.10706126045843689},
{"total_number_of_episodes": 17597, "number_of_timesteps": 2004661, "per_episode_reward": -134.93, "episode_reward_trend_value": -0.0015021864462754467, "biggest_recent_change": 0.10706126045843689},
{"total_number_of_episodes": 17607, "number_of_timesteps": 2005449, "per_episode_reward": -134.88, "episode_reward_trend_value": -0.0007459556840833177, "biggest_recent_change": 0.10706126045843689},
{"total_number_of_episodes": 17617, "number_of_timesteps": 2006267, "per_episode_reward": -134.83, "episode_reward_trend_value": 0.00012171611187075844, "biggest_recent_change": 0.10706126045843689},
{"total_number_of_episodes": 17627, "number_of_timesteps": 2007346, "per_episode_reward": -134.85, "episode_reward_trend_value": -0.0004384395195523262, "biggest_recent_change": 0.10706126045843689},
{"total_number_of_episodes": 17637, "number_of_timesteps": 2008580, "per_episode_reward": -134.85, "episode_reward_trend_value": -0.00027463054855635013, "biggest_recent_change": 0.10706126045843689},
{"total_number_of_episodes": 17647, "number_of_timesteps": 2010142, "per_episode_reward": -134.87, "episode_reward_trend_value": -0.0002768781587939707, "biggest_recent_change": 0.10706126045843689},
{"total_number_of_episodes": 17658, "number_of_timesteps": 2011635, "per_episode_reward": -134.85, "episode_reward_trend_value": -0.00024585621794288826, "biggest_recent_change": 0.10706126045843689},
{"total_number_of_episodes": 17669, "number_of_timesteps": 2012464, "per_episode_reward": -134.79, "episode_reward_trend_value": 0.00027302037328303817, "biggest_recent_change": 0.10706126045843689},
{"total_number_of_episodes": 17679, "number_of_timesteps": 2013463, "per_episode_reward": -134.79, "episode_reward_trend_value": 0.0014789422855689812, "biggest_recent_change": 0.057989430345998016},
{"total_number_of_episodes": 17690, "number_of_timesteps": 2014732, "per_episode_reward": -134.91, "episode_reward_trend_value": 0.0003103962052579037, "biggest_recent_change": 0.11446096196607414},
{"total_number_of_episodes": 17700, "number_of_timesteps": 2015894, "per_episode_reward": -134.91, "episode_reward_trend_value": -0.0003794369977135325, "biggest_recent_change": 0.11446096196607414},
{"total_number_of_episodes": 17711, "number_of_timesteps": 2016894, "per_episode_reward": -134.9, "episode_reward_trend_value": -0.0007440196086703408, "biggest_recent_change": 0.11446096196607414},
{"total_number_of_episodes": 17721, "number_of_timesteps": 2017936, "per_episode_reward": -134.9, "episode_reward_trend_value": -0.0005796096649536114, "biggest_recent_change": 0.11446096196607414},
{"total_number_of_episodes": 17731, "number_of_timesteps": 2018768, "per_episode_reward": -134.82, "episode_reward_trend_value": 0.00032597037748492615, "biggest_recent_change": 0.11446096196607414},
{"total_number_of_episodes": 17741, "number_of_timesteps": 2019646, "per_episode_reward": -134.79, "episode_reward_trend_value": 0.0008732413510447005, "biggest_recent_change": 0.11446096196607414},
{"total_number_of_episodes": 17751, "number_of_timesteps": 2020813, "per_episode_reward": -134.87, "episode_reward_trend_value": -0.00023217246626706535, "biggest_recent_change": 0.11446096196607414},
{"total_number_of_episodes": 17762, "number_of_timesteps": 2022313, "per_episode_reward": -134.87, "episode_reward_trend_value": -0.0008134196395613143, "biggest_recent_change": 0.11446096196607414},
{"total_number_of_episodes": 17772, "number_of_timesteps": 2023319, "per_episode_reward": -134.85, "episode_reward_trend_value": -0.0006648392847068863, "biggest_recent_change": 0.11446096196607414},
{"total_number_of_episodes": 17782, "number_of_timesteps": 2024488, "per_episode_reward": -134.88, "episode_reward_trend_value": 0.00025713755928317517, "biggest_recent_change": 0.08075276711392121},
{"total_number_of_episodes": 17792, "number_of_timesteps": 2025627, "per_episode_reward": -134.85, "episode_reward_trend_value": 0.0007092883934130138, "biggest_recent_change": 0.08075276711392121},
{"total_number_of_episodes": 17802, "number_of_timesteps": 2026423, "per_episode_reward": -134.76, "episode_reward_trend_value": 0.0015295656597752818, "biggest_recent_change": 0.09076254816409346},
{"total_number_of_episodes": 17813, "number_of_timesteps": 2027629, "per_episode_reward": -134.73, "episode_reward_trend_value": 0.0018865831999202482, "biggest_recent_change": 0.09076254816409346},
{"total_number_of_episodes": 17823, "number_of_timesteps": 2029125, "per_episode_reward": -134.95, "episode_reward_trend_value": -0.0013952033973822608, "biggest_recent_change": 0.21718082172634467},
{"total_number_of_episodes": 17833, "number_of_timesteps": 2030193, "per_episode_reward": -134.91, "episode_reward_trend_value": -0.0013814676056827895, "biggest_recent_change": 0.21718082172634467},
{"total_number_of_episodes": 17843, "number_of_timesteps": 2031348, "per_episode_reward": -134.89, "episode_reward_trend_value": -0.00016924060767691015, "biggest_recent_change": 0.21718082172634467},
{"total_number_of_episodes": 17853, "number_of_timesteps": 2032998, "per_episode_reward": -134.9, "episode_reward_trend_value": -0.0003632841332656906, "biggest_recent_change": 0.21718082172634467},
{"total_number_of_episodes": 17863, "number_of_timesteps": 2033915, "per_episode_reward": -134.9, "episode_reward_trend_value": -0.0005345600390196776, "biggest_recent_change": 0.21718082172634467},
{"total_number_of_episodes": 17873, "number_of_timesteps": 2034774, "per_episode_reward": -134.87, "episode_reward_trend_value": 0.00018800575808484155, "biggest_recent_change": 0.21718082172634467},
{"total_number_of_episodes": 17883, "number_of_timesteps": 2036006, "per_episode_reward": -134.79, "episode_reward_trend_value": 0.0006204127918298101, "biggest_recent_change": 0.21718082172634467},
{"total_number_of_episodes": 17894, "number_of_timesteps": 2037515, "per_episode_reward": -134.7, "episode_reward_trend_value": 0.0006093983467764019, "biggest_recent_change": 0.21718082172634467},
{"total_number_of_episodes": 17904, "number_of_timesteps": 2039539, "per_episode_reward": -134.68, "episode_reward_trend_value": 0.0006018659597025868, "biggest_recent_change": 0.21718082172634467},
{"total_number_of_episodes": 17914, "number_of_timesteps": 2040842, "per_episode_reward": -134.76, "episode_reward_trend_value": 0.002070475336335499, "biggest_recent_change": 0.08977124810928672},
{"total_number_of_episodes": 17924, "number_of_timesteps": 2041953, "per_episode_reward": -134.77, "episode_reward_trend_value": 0.0015701396123859012, "biggest_recent_change": 0.08977124810928672},
{"total_number_of_episodes": 17934, "number_of_timesteps": 2043288, "per_episode_reward": -134.83, "episode_reward_trend_value": 0.0005779105681802498, "biggest_recent_change": 0.08977124810928672},
{"total_number_of_episodes": 17944, "number_of_timesteps": 2044355, "per_episode_reward": -134.83, "episode_reward_trend_value": 0.000736429682457482, "biggest_recent_change": 0.08977124810928672},
{"total_number_of_episodes": 17954, "number_of_timesteps": 2045548, "per_episode_reward": -134.81, "episode_reward_trend_value": 0.0009943144744271296, "biggest_recent_change": 0.08977124810928672},
{"total_number_of_episodes": 17965, "number_of_timesteps": 2047044, "per_episode_reward": -134.84, "episode_reward_trend_value": 0.00032390294974252105, "biggest_recent_change": 0.08977124810928672},
{"total_number_of_episodes": 17976, "number_of_timesteps": 2048179, "per_episode_reward": -134.76, "episode_reward_trend_value": 0.00041162486737296905, "biggest_recent_change": 0.08977124810928672},
{"total_number_of_episodes": 17987, "number_of_timesteps": 2049296, "per_episode_reward": -134.76, "episode_reward_trend_value": -0.0006043693602470689, "biggest_recent_change": 0.08500597782938257},
{"total_number_of_episodes": 17997, "number_of_timesteps": 2050202, "per_episode_reward": -134.71, "episode_reward_trend_value": -0.0003309806123003985, "biggest_recent_change": 0.08500597782938257},
{"total_number_of_episodes": 18008, "number_of_timesteps": 2051671, "per_episode_reward": -134.79, "episode_reward_trend_value": -0.0002691942893708049, "biggest_recent_change": 0.07947937057033982},
{"total_number_of_episodes": 18018, "number_of_timesteps": 2052841, "per_episode_reward": -134.75, "episode_reward_trend_value": 0.00022673441571170212, "biggest_recent_change": 0.07947937057033982},
{"total_number_of_episodes": 18028, "number_of_timesteps": 2053667, "per_episode_reward": -134.66, "episode_reward_trend_value": 0.0018924389647625931, "biggest_recent_change": 0.0889604581426795},
{"total_number_of_episodes": 18038, "number_of_timesteps": 2054978, "per_episode_reward": -134.69, "episode_reward_trend_value": 0.0016148044976754742, "biggest_recent_change": 0.0889604581426795},
{"total_number_of_episodes": 18048, "number_of_timesteps": 2056062, "per_episode_reward": -134.66, "episode_reward_trend_value": 0.0017124388859804814, "biggest_recent_change": 0.0889604581426795},
{"total_number_of_episodes": 18058, "number_of_timesteps": 2057344, "per_episode_reward": -134.66, "episode_reward_trend_value": 0.0019886348737859156, "biggest_recent_change": 0.0889604581426795},
{"total_number_of_episodes": 18068, "number_of_timesteps": 2058475, "per_episode_reward": -134.6, "episode_reward_trend_value": 0.0017171929984414191, "biggest_recent_change": 0.0889604581426795},
{"total_number_of_episodes": 18078, "number_of_timesteps": 2059359, "per_episode_reward": -134.51, "episode_reward_trend_value": 0.002753477441296405, "biggest_recent_change": 0.09159736748043201},
{"total_number_of_episodes": 18088, "number_of_timesteps": 2060240, "per_episode_reward": -134.5, "episode_reward_trend_value": 0.002234920881173568, "biggest_recent_change": 0.09159736748043201},
{"total_number_of_episodes": 18099, "number_of_timesteps": 2061695, "per_episode_reward": -134.51, "episode_reward_trend_value": 0.0030138380260546506, "biggest_recent_change": 0.09159736748043201},
{"total_number_of_episodes": 18109, "number_of_timesteps": 2062891, "per_episode_reward": -134.53, "episode_reward_trend_value": 0.002490672993036785, "biggest_recent_change": 0.09159736748043201},
{"total_number_of_episodes": 18119, "number_of_timesteps": 2064006, "per_episode_reward": -134.49, "episode_reward_trend_value": 0.0019874133369092483, "biggest_recent_change": 0.09159736748043201},
{"total_number_of_episodes": 18130, "number_of_timesteps": 2065091, "per_episode_reward": -134.4, "episode_reward_trend_value": 0.003131689849701047, "biggest_recent_change": 0.09159736748043201},
{"total_number_of_episodes": 18140, "number_of_timesteps": 2065935, "per_episode_reward": -134.34, "episode_reward_trend_value": 0.0034692804780083485, "biggest_recent_change": 0.09159736748043201},
{"total_number_of_episodes": 18151, "number_of_timesteps": 2066907, "per_episode_reward": -134.35, "episode_reward_trend_value": 0.003452790074747883, "biggest_recent_change": 0.09159736748043201},
{"total_number_of_episodes": 18161, "number_of_timesteps": 2067853, "per_episode_reward": -134.37, "episode_reward_trend_value": 0.0025423237601573745, "biggest_recent_change": 0.09159736748043201},
{"total_number_of_episodes": 18171, "number_of_timesteps": 2069934, "per_episode_reward": -134.36, "episode_reward_trend_value": 0.0016459171109551736, "biggest_recent_change": 0.08047777184489746},
{"total_number_of_episodes": 18181, "number_of_timesteps": 2070765, "per_episode_reward": -134.33, "episode_reward_trend_value": 0.0019764247904933857, "biggest_recent_change": 0.08047777184489746},
{"total_number_of_episodes": 18192, "number_of_timesteps": 2071630, "per_episode_reward": -134.27, "episode_reward_trend_value": 0.0026556864808687424, "biggest_recent_change": 0.08047777184489746},
{"total_number_of_episodes": 18203, "number_of_timesteps": 2072657, "per_episode_reward": -134.27, "episode_reward_trend_value": 0.002848757951989948, "biggest_recent_change": 0.08047777184489746},
{"total_number_of_episodes": 18213, "number_of_timesteps": 2073446, "per_episode_reward": -134.03, "episode_reward_trend_value": 0.005045065937702967, "biggest_recent_change": 0.24133480780537298},
{"total_number_of_episodes": 18223, "number_of_timesteps": 2074315, "per_episode_reward": -133.96, "episode_reward_trend_value": 0.004943007994713059, "biggest_recent_change": 0.24133480780537298},
{"total_number_of_episodes": 18233, "number_of_timesteps": 2075350, "per_episode_reward": -133.92, "episode_reward_trend_value": 0.004671970335009393, "biggest_recent_change": 0.24133480780537298},
{"total_number_of_episodes": 18243, "number_of_timesteps": 2076707, "per_episode_reward": -133.94, "episode_reward_trend_value": 0.004507877158808861, "biggest_recent_change": 0.24133480780537298},
{"total_number_of_episodes": 18254, "number_of_timesteps": 2078154, "per_episode_reward": -133.96, "episode_reward_trend_value": 0.00453855941907193, "biggest_recent_change": 0.24133480780537298},
{"total_number_of_episodes": 18264, "number_of_timesteps": 2079424, "per_episode_reward": -134.05, "episode_reward_trend_value": 0.0035185241162426764, "biggest_recent_change": 0.24133480780537298},
{"total_number_of_episodes": 18274, "number_of_timesteps": 2080491, "per_episode_reward": -134.07, "episode_reward_trend_value": 0.002831053409111127, "biggest_recent_change": 0.24133480780537298},
{"total_number_of_episodes": 18284, "number_of_timesteps": 2081744, "per_episode_reward": -134.1, "episode_reward_trend_value": 0.0019442102809067465, "biggest_recent_change": 0.24133480780537298},
{"total_number_of_episodes": 18295, "number_of_timesteps": 2082833, "per_episode_reward": -134.11, "episode_reward_trend_value": 0.0018242892375537976, "biggest_recent_change": 0.24133480780537298},
{"total_number_of_episodes": 18305, "number_of_timesteps": 2084015, "per_episode_reward": -134.13, "episode_reward_trend_value": -0.001130003937776299, "biggest_recent_change": 0.08088240820239889},
{"total_number_of_episodes": 18315, "number_of_timesteps": 2085033, "per_episode_reward": -134.09, "episode_reward_trend_value": -0.0014553106869631923, "biggest_recent_change": 0.08088240820239889},
{"total_number_of_episodes": 18325, "number_of_timesteps": 2085962, "per_episode_reward": -134.05, "episode_reward_trend_value": -0.0014548595434181126, "biggest_recent_change": 0.08088240820239889},
{"total_number_of_episodes": 18335, "number_of_timesteps": 2087621, "per_episode_reward": -133.98, "episode_reward_trend_value": -0.0004793402205545287, "biggest_recent_change": 0.08088240820239889},
{"total_number_of_episodes": 18345, "number_of_timesteps": 2088781, "per_episode_reward": -133.95, "episode_reward_trend_value": 0.00014470127870222564, "biggest_recent_change": 0.08088240820239889},
{"total_number_of_episodes": 18355, "number_of_timesteps": 2089818, "per_episode_reward": -133.98, "episode_reward_trend_value": 0.0007194110680668725, "biggest_recent_change": 0.0696126943195452},
{"total_number_of_episodes": 18365, "number_of_timesteps": 2090948, "per_episode_reward": -133.99, "episode_reward_trend_value": 0.000913873706272423, "biggest_recent_change": 0.0696126943195452},
{"total_number_of_episodes": 18375, "number_of_timesteps": 2091888, "per_episode_reward": -133.96, "episode_reward_trend_value": 0.0015324689212241715, "biggest_recent_change": 0.0696126943195452},
{"total_number_of_episodes": 18385, "number_of_timesteps": 2093081, "per_episode_reward": -133.98, "episode_reward_trend_value": 0.0014447925658275709, "biggest_recent_change": 0.0696126943195452},
{"total_number_of_episodes": 18395, "number_of_timesteps": 2094277, "per_episode_reward": -134.02, "episode_reward_trend_value": 0.0012804176632758729, "biggest_recent_change": 0.0696126943195452},
{"total_number_of_episodes": 18405, "number_of_timesteps": 2095645, "per_episode_reward": -134.08, "episode_reward_trend_value": 0.0001501078249699756, "biggest_recent_change": 0.0696126943195452},
{"total_number_of_episodes": 18415, "number_of_timesteps": 2097258, "per_episode_reward": -134.08, "episode_reward_trend_value": -0.0002788038147675328, "biggest_recent_change": 0.0696126943195452},
{"total_number_of_episodes": 18425, "number_of_timesteps": 2098131, "per_episode_reward": -134.06, "episode_reward_trend_value": -0.0008909174198890923, "biggest_recent_change": 0.05971293589854554},
{"total_number_of_episodes": 18435, "number_of_timesteps": 2099081, "per_episode_reward": -133.97, "episode_reward_trend_value": -0.00015083908749633995, "biggest_recent_change": 0.09863982174832131},
{"total_number_of_episodes": 18445, "number_of_timesteps": 2100074, "per_episode_reward": -133.97, "episode_reward_trend_value": 0.00010339183223303887, "biggest_recent_change": 0.09863982174832131},
{"total_number_of_episodes": 18455, "number_of_timesteps": 2101217, "per_episode_reward": -133.94, "episode_reward_trend_value": 0.0005364170017578039, "biggest_recent_change": 0.09863982174832131},
{"total_number_of_episodes": 18465, "number_of_timesteps": 2102221, "per_episode_reward": -133.96, "episode_reward_trend_value": 4.13908082413804e-05, "biggest_recent_change": 0.09863982174832131},
{"total_number_of_episodes": 18475, "number_of_timesteps": 2103217, "per_episode_reward": -134.04, "episode_reward_trend_value": -0.0006413303553541836, "biggest_recent_change": 0.09863982174832131},
{"total_number_of_episodes": 18485, "number_of_timesteps": 2104314, "per_episode_reward": -134.04, "episode_reward_trend_value": -0.00024732322322872986, "biggest_recent_change": 0.09863982174832131},
{"total_number_of_episodes": 18495, "number_of_timesteps": 2105587, "per_episode_reward": -134.07, "episode_reward_trend_value": 0.00013041754118350786, "biggest_recent_change": 0.09863982174832131},
{"total_number_of_episodes": 18505, "number_of_timesteps": 2106404, "per_episode_reward": -133.94, "episode_reward_trend_value": 0.0014925926827316972, "biggest_recent_change": 0.12144992354740225},
{"total_number_of_episodes": 18516, "number_of_timesteps": 2107365, "per_episode_reward": -133.9, "episode_reward_trend_value": 0.0018733964707798299, "biggest_recent_change": 0.12144992354740225},
{"total_number_of_episodes": 18526, "number_of_timesteps": 2108480, "per_episode_reward": -133.88, "episode_reward_trend_value": 0.0009123044584065888, "biggest_recent_change": 0.12144992354740225},
{"total_number_of_episodes": 18537, "number_of_timesteps": 2109742, "per_episode_reward": -133.91, "episode_reward_trend_value": 0.0007002978721828868, "biggest_recent_change": 0.12144992354740225},
{"total_number_of_episodes": 18548, "number_of_timesteps": 2111528, "per_episode_reward": -133.92, "episode_reward_trend_value": 0.0002787067065459799, "biggest_recent_change": 0.12144992354740225},
{"total_number_of_episodes": 18558, "number_of_timesteps": 2112540, "per_episode_reward": -133.92, "episode_reward_trend_value": 0.0003921471458018762, "biggest_recent_change": 0.12144992354740225},
{"total_number_of_episodes": 18568, "number_of_timesteps": 2113623, "per_episode_reward": -133.96, "episode_reward_trend_value": 0.0008054656596338342, "biggest_recent_change": 0.12144992354740225},
{"total_number_of_episodes": 18578, "number_of_timesteps": 2114429, "per_episode_reward": -133.9, "episode_reward_trend_value": 0.0015114151242190447, "biggest_recent_change": 0.12144992354740225},
{"total_number_of_episodes": 18588, "number_of_timesteps": 2115756, "per_episode_reward": -133.97, "episode_reward_trend_value": 0.0010846322912796166, "biggest_recent_change": 0.12144992354740225},
{"total_number_of_episodes": 18598, "number_of_timesteps": 2117408, "per_episode_reward": -134.04, "episode_reward_trend_value": -0.0010815964987699544, "biggest_recent_change": 0.07351066755705915},
{"total_number_of_episodes": 18608, "number_of_timesteps": 2118370, "per_episode_reward": -134.13, "episode_reward_trend_value": -0.002618316670144496, "biggest_recent_change": 0.08951000464077197},
{"total_number_of_episodes": 18618, "number_of_timesteps": 2119681, "per_episode_reward": -134.19, "episode_reward_trend_value": -0.0034171921002669908, "biggest_recent_change": 0.08951000464077197},
{"total_number_of_episodes": 18628, "number_of_timesteps": 2120760, "per_episode_reward": -134.2, "episode_reward_trend_value": -0.00322647212266784, "biggest_recent_change": 0.08951000464077197},
{"total_number_of_episodes": 18639, "number_of_timesteps": 2122197, "per_episode_reward": -134.16, "episode_reward_trend_value": -0.0027138452382176738, "biggest_recent_change": 0.08951000464077197},
{"total_number_of_episodes": 18649, "number_of_timesteps": 2123330, "per_episode_reward": -134.07, "episode_reward_trend_value": -0.0016000127023419156, "biggest_recent_change": 0.09355078455999433},
{"total_number_of_episodes": 18659, "number_of_timesteps": 2124414, "per_episode_reward": -134.09, "episode_reward_trend_value": -0.0013589663102670279, "biggest_recent_change": 0.09355078455999433},
{"total_number_of_episodes": 18669, "number_of_timesteps": 2125510, "per_episode_reward": -134.03, "episode_reward_trend_value": -0.0013860867792427852, "biggest_recent_change": 0.09355078455999433},
{"total_number_of_episodes": 18679, "number_of_timesteps": 2126762, "per_episode_reward": -133.92, "episode_reward_trend_value": 0.0005528605492072656, "biggest_recent_change": 0.11037853749451187},
{"total_number_of_episodes": 18689, "number_of_timesteps": 2127813, "per_episode_reward": -133.87, "episode_reward_trend_value": 0.0019405107803714197, "biggest_recent_change": 0.11037853749451187},
{"total_number_of_episodes": 18699, "number_of_timesteps": 2128807, "per_episode_reward": -133.97, "episode_reward_trend_value": 0.0017502378224387865, "biggest_recent_change": 0.11037853749451187},
{"total_number_of_episodes": 18709, "number_of_timesteps": 2130145, "per_episode_reward": -133.94, "episode_reward_trend_value": 0.002778421447704381, "biggest_recent_change": 0.11037853749451187},
{"total_number_of_episodes": 18719, "number_of_timesteps": 2131289, "per_episode_reward": -133.89, "episode_reward_trend_value": 0.003470570420029162, "biggest_recent_change": 0.11037853749451187},
{"total_number_of_episodes": 18730, "number_of_timesteps": 2132219, "per_episode_reward": -133.81, "episode_reward_trend_value": 0.003885867227985626, "biggest_recent_change": 0.11037853749451187},
{"total_number_of_episodes": 18741, "number_of_timesteps": 2133443, "per_episode_reward": -133.76, "episode_reward_trend_value": 0.0033862360478650543, "biggest_recent_change": 0.11037853749451187},
{"total_number_of_episodes": 18752, "number_of_timesteps": 2134889, "per_episode_reward": -133.78, "episode_reward_trend_value": 0.003357646416570345, "biggest_recent_change": 0.11037853749451187},
{"total_number_of_episodes": 18762, "number_of_timesteps": 2136143, "per_episode_reward": -133.78, "episode_reward_trend_value": 0.002781672393426662, "biggest_recent_change": 0.11037853749451187},
{"total_number_of_episodes": 18773, "number_of_timesteps": 2137409, "per_episode_reward": -133.77, "episode_reward_trend_value": 0.0016151179607425722, "biggest_recent_change": 0.10663457085470895},
{"total_number_of_episodes": 18784, "number_of_timesteps": 2138530, "per_episode_reward": -133.81, "episode_reward_trend_value": 0.0006524762378126702, "biggest_recent_change": 0.10663457085470895},
{"total_number_of_episodes": 18796, "number_of_timesteps": 2140073, "per_episode_reward": -133.8, "episode_reward_trend_value": 0.001978464964420507, "biggest_recent_change": 0.07557750973836619},
{"total_number_of_episodes": 18806, "number_of_timesteps": 2141137, "per_episode_reward": -133.8, "episode_reward_trend_value": 0.0015922079259793362, "biggest_recent_change": 0.07557750973836619},
{"total_number_of_episodes": 18816, "number_of_timesteps": 2142522, "per_episode_reward": -133.82, "episode_reward_trend_value": 0.0007899355271474759, "biggest_recent_change": 0.07557750973836619},

{"total_number_of_episodes": 18826, "number_of_timesteps": 2143696, "per_episode_reward": -133.79, "episode_reward_trend_value": 0.00019876614391212876, "biggest_recent_change": 0.04858397834914285},
{"total_number_of_episodes": 18837, "number_of_timesteps": 2145194, "per_episode_reward": -133.79, "episode_reward_trend_value": -0.0003501177511269462, "biggest_recent_change": 0.03525990181597649},
{"total_number_of_episodes": 18847, "number_of_timesteps": 2146725, "per_episode_reward": -133.77, "episode_reward_trend_value": 0.00010290511590843227, "biggest_recent_change": 0.03525990181597649},
{"total_number_of_episodes": 18857, "number_of_timesteps": 2147829, "per_episode_reward": -133.79, "episode_reward_trend_value": -0.00015057610058054, "biggest_recent_change": 0.03525990181597649},
{"total_number_of_episodes": 18867, "number_of_timesteps": 2148833, "per_episode_reward": -133.78, "episode_reward_trend_value": -4.77652866316526e-05, "biggest_recent_change": 0.03525990181597649},
{"total_number_of_episodes": 18877, "number_of_timesteps": 2149992, "per_episode_reward": -133.81, "episode_reward_trend_value": 1.7165223205337398e-05, "biggest_recent_change": 0.029416155930647392},
{"total_number_of_episodes": 18887, "number_of_timesteps": 2151264, "per_episode_reward": -133.87, "episode_reward_trend_value": -0.0008453140323363565, "biggest_recent_change": 0.06491871845875608},
{"total_number_of_episodes": 18897, "number_of_timesteps": 2152166, "per_episode_reward": -133.82, "episode_reward_trend_value": -0.00022751631081455848, "biggest_recent_change": 0.06491871845875608},
{"total_number_of_episodes": 18907, "number_of_timesteps": 2152978, "per_episode_reward": -133.8, "episode_reward_trend_value": 0.00016883824721863522, "biggest_recent_change": 0.06491871845875608},
{"total_number_of_episodes": 18918, "number_of_timesteps": 2153945, "per_episode_reward": -133.74, "episode_reward_trend_value": 0.0005688177988342129, "biggest_recent_change": 0.06491871845875608},
{"total_number_of_episodes": 18928, "number_of_timesteps": 2154940, "per_episode_reward": -133.78, "episode_reward_trend_value": 0.00012634461662533643, "biggest_recent_change": 0.06491871845875608},
{"total_number_of_episodes": 18938, "number_of_timesteps": 2156170, "per_episode_reward": -133.78, "episode_reward_trend_value": -4.253140153309687e-05, "biggest_recent_change": 0.06491871845875608},
{"total_number_of_episodes": 18948, "number_of_timesteps": 2157253, "per_episode_reward": -133.79, "episode_reward_trend_value": 4.461739779344498e-05, "biggest_recent_change": 0.06491871845875608},
{"total_number_of_episodes": 18958, "number_of_timesteps": 2158415, "per_episode_reward": -133.76, "episode_reward_trend_value": 0.0002313205558348525, "biggest_recent_change": 0.06491871845875608},
{"total_number_of_episodes": 18968, "number_of_timesteps": 2159396, "per_episode_reward": -133.75, "episode_reward_trend_value": 0.0005844028905961018, "biggest_recent_change": 0.06491871845875608},
{"total_number_of_episodes": 18978, "number_of_timesteps": 2161069, "per_episode_reward": -133.77, "episode_reward_trend_value": 0.0011173004249504478, "biggest_recent_change": 0.058370424892586925},
{"total_number_of_episodes": 18988, "number_of_timesteps": 2162152, "per_episode_reward": -133.73, "episode_reward_trend_value": 0.0009438037504531217, "biggest_recent_change": 0.058370424892586925},
{"total_number_of_episodes": 18998, "number_of_timesteps": 2163268, "per_episode_reward": -133.72, "episode_reward_trend_value": 0.0008701850506478573, "biggest_recent_change": 0.058370424892586925},
{"total_number_of_episodes": 19009, "number_of_timesteps": 2164398, "per_episode_reward": -133.7, "episode_reward_trend_value": 0.00042413509802119936, "biggest_recent_change": 0.04063815860317277},
{"total_number_of_episodes": 19019, "number_of_timesteps": 2165537, "per_episode_reward": -133.61, "episode_reward_trend_value": 0.0019443335792576337, "biggest_recent_change": 0.09617970470810633},
{"total_number_of_episodes": 19030, "number_of_timesteps": 2166952, "per_episode_reward": -133.63, "episode_reward_trend_value": 0.0016393764911141616, "biggest_recent_change": 0.09617970470810633},
{"total_number_of_episodes": 19040, "number_of_timesteps": 2167969, "per_episode_reward": -133.59, "episode_reward_trend_value": 0.0021529821471479712, "biggest_recent_change": 0.09617970470810633},
{"total_number_of_episodes": 19050, "number_of_timesteps": 2168855, "per_episode_reward": -133.57, "episode_reward_trend_value": 0.002047581529677384, "biggest_recent_change": 0.09617970470810633},
{"total_number_of_episodes": 19060, "number_of_timesteps": 2170030, "per_episode_reward": -133.57, "episode_reward_trend_value": 0.002056712348000171, "biggest_recent_change": 0.09617970470810633},
{"total_number_of_episodes": 19071, "number_of_timesteps": 2171755, "per_episode_reward": -133.6, "episode_reward_trend_value": 0.00194757393577984, "biggest_recent_change": 0.09617970470810633},
{"total_number_of_episodes": 19081, "number_of_timesteps": 2172779, "per_episode_reward": -133.55, "episode_reward_trend_value": 0.002019030355043583, "biggest_recent_change": 0.09617970470810633},
{"total_number_of_episodes": 19091, "number_of_timesteps": 2173609, "per_episode_reward": -133.5, "episode_reward_trend_value": 0.002461116769739786, "biggest_recent_change": 0.09617970470810633},
{"total_number_of_episodes": 19101, "number_of_timesteps": 2174575, "per_episode_reward": -133.44, "episode_reward_trend_value": 0.0029823056160214237, "biggest_recent_change": 0.09617970470810633},
{"total_number_of_episodes": 19111, "number_of_timesteps": 2175879, "per_episode_reward": -133.48, "episode_reward_trend_value": 0.0014130119948330528, "biggest_recent_change": 0.06513292532153514},
{"total_number_of_episodes": 19121, "number_of_timesteps": 2177291, "per_episode_reward": -133.59, "episode_reward_trend_value": 0.0004157718498103375, "biggest_recent_change": 0.1128087439085732},
{"total_number_of_episodes": 19131, "number_of_timesteps": 2178629, "per_episode_reward": -133.63, "episode_reward_trend_value": -0.00044679836275855045, "biggest_recent_change": 0.1128087439085732},
{"total_number_of_episodes": 19141, "number_of_timesteps": 2180007, "per_episode_reward": -133.63, "episode_reward_trend_value": -0.0006948107846773787, "biggest_recent_change": 0.1128087439085732},
{"total_number_of_episodes": 19151, "number_of_timesteps": 2181053, "per_episode_reward": -133.6, "episode_reward_trend_value": -0.0002975599718521633, "biggest_recent_change": 0.1128087439085732},
{"total_number_of_episodes": 19161, "number_of_timesteps": 2182111, "per_episode_reward": -133.59, "episode_reward_trend_value": 7.936395124595998e-05, "biggest_recent_change": 0.1128087439085732},
{"total_number_of_episodes": 19171, "number_of_timesteps": 2183481, "per_episode_reward": -133.59, "episode_reward_trend_value": -0.0004047747983337204, "biggest_recent_change": 0.1128087439085732},
{"total_number_of_episodes": 19182, "number_of_timesteps": 2184607, "per_episode_reward": -133.55, "episode_reward_trend_value": -0.0005747256891090223, "biggest_recent_change": 0.1128087439085732},
{"total_number_of_episodes": 19192, "number_of_timesteps": 2186065, "per_episode_reward": -133.58, "episode_reward_trend_value": -0.0016454465816757927, "biggest_recent_change": 0.1128087439085732},
{"total_number_of_episodes": 19204, "number_of_timesteps": 2187212, "per_episode_reward": -133.67, "episode_reward_trend_value": -0.0020861827917040424, "biggest_recent_change": 0.1128087439085732},
{"total_number_of_episodes": 19214, "number_of_timesteps": 2188164, "per_episode_reward": -133.63, "episode_reward_trend_value": -0.00043141474734132617, "biggest_recent_change": 0.08472298010138957},
{"total_number_of_episodes": 19225, "number_of_timesteps": 2189395, "per_episode_reward": -133.58, "episode_reward_trend_value": 0.0006062774806110838, "biggest_recent_change": 0.08472298010138957},
{"total_number_of_episodes": 19236, "number_of_timesteps": 2190561, "per_episode_reward": -133.55, "episode_reward_trend_value": 0.0009423269207278255, "biggest_recent_change": 0.08472298010138957},
{"total_number_of_episodes": 19246, "number_of_timesteps": 2191666, "per_episode_reward": -133.55, "episode_reward_trend_value": 0.000511082322092054, "biggest_recent_change": 0.08472298010138957},
{"total_number_of_episodes": 19257, "number_of_timesteps": 2192712, "per_episode_reward": -133.5, "episode_reward_trend_value": 0.001013808592462182, "biggest_recent_change": 0.08472298010138957},
{"total_number_of_episodes": 19267, "number_of_timesteps": 2193829, "per_episode_reward": -133.56, "episode_reward_trend_value": 0.0002843831414408113, "biggest_recent_change": 0.08472298010138957},
{"total_number_of_episodes": 19277, "number_of_timesteps": 2195188, "per_episode_reward": -133.61, "episode_reward_trend_value": -0.0006090762813064051, "biggest_recent_change": 0.08472298010138957},
{"total_number_of_episodes": 19288, "number_of_timesteps": 2196347, "per_episode_reward": -133.57, "episode_reward_trend_value": 0.00014121222504917972, "biggest_recent_change": 0.08472298010138957},
{"total_number_of_episodes": 19298, "number_of_timesteps": 2197469, "per_episode_reward": -133.57, "episode_reward_trend_value": 0.0010472116945436482, "biggest_recent_change": 0.06478646135025201},
{"total_number_of_episodes": 19308, "number_of_timesteps": 2199012, "per_episode_reward": -133.62, "episode_reward_trend_value": 0.00010534199287645959, "biggest_recent_change": 0.06478646135025201},
{"total_number_of_episodes": 19318, "number_of_timesteps": 2200256, "per_episode_reward": -133.56, "episode_reward_trend_value": 0.00024039490108217855, "biggest_recent_change": 0.06478646135025201},
{"total_number_of_episodes": 19328, "number_of_timesteps": 2201614, "per_episode_reward": -133.57, "episode_reward_trend_value": -0.00022535241329914394, "biggest_recent_change": 0.06478646135025201},
{"total_number_of_episodes": 19338, "number_of_timesteps": 2202953, "per_episode_reward": -133.6, "episode_reward_trend_value": -0.0005377449701335814, "biggest_recent_change": 0.06478646135025201},
{"total_number_of_episodes": 19349, "number_of_timesteps": 2204147, "per_episode_reward": -133.63, "episode_reward_trend_value": -0.0015298538961963635, "biggest_recent_change": 0.06478646135025201},
{"total_number_of_episodes": 19359, "number_of_timesteps": 2205307, "per_episode_reward": -133.61, "episode_reward_trend_value": -0.0005548300094296287, "biggest_recent_change": 0.06454260483067742},
{"total_number_of_episodes": 19369, "number_of_timesteps": 2206111, "per_episode_reward": -133.57, "episode_reward_trend_value": 0.00039165675975583425, "biggest_recent_change": 0.06454260483067742},
{"total_number_of_episodes": 19380, "number_of_timesteps": 2207101, "per_episode_reward": -133.55, "episode_reward_trend_value": 0.00023960262730232293, "biggest_recent_change": 0.06454260483067742},
{"total_number_of_episodes": 19390, "number_of_timesteps": 2208300, "per_episode_reward": -133.57, "episode_reward_trend_value": 6.858992244423866e-05, "biggest_recent_change": 0.06454260483067742},
{"total_number_of_episodes": 19401, "number_of_timesteps": 2209628, "per_episode_reward": -133.54, "episode_reward_trend_value": 0.0008847744581133712, "biggest_recent_change": 0.06454260483067742},
{"total_number_of_episodes": 19411, "number_of_timesteps": 2210940, "per_episode_reward": -133.57, "episode_reward_trend_value": -0.00018467624432124313, "biggest_recent_change": 0.04020623802705359},
{"total_number_of_episodes": 19421, "number_of_timesteps": 2212136, "per_episode_reward": -133.54, "episode_reward_trend_value": 0.00029029141770990917, "biggest_recent_change": 0.04020623802705359},
{"total_number_of_episodes": 19431, "number_of_timesteps": 2213269, "per_episode_reward": -133.56, "episode_reward_trend_value": 0.00039515894658121754, "biggest_recent_change": 0.04020623802705359},
{"total_number_of_episodes": 19442, "number_of_timesteps": 2214886, "per_episode_reward": -133.61, "episode_reward_trend_value": 0.00022189992673860262, "biggest_recent_change": 0.05249499518603784},
{"total_number_of_episodes": 19452, "number_of_timesteps": 2215980, "per_episode_reward": -133.6, "episode_reward_trend_value": 0.00015022569455804083, "biggest_recent_change": 0.05249499518603784},
{"total_number_of_episodes": 19462, "number_of_timesteps": 2217301, "per_episode_reward": -133.64, "episode_reward_trend_value": -0.0008018044659596372, "biggest_recent_change": 0.05249499518603784},
{"total_number_of_episodes": 19472, "number_of_timesteps": 2218258, "per_episode_reward": -133.66, "episode_reward_trend_value": -0.0012365373390155001, "biggest_recent_change": 0.05249499518603784},
{"total_number_of_episodes": 19482, "number_of_timesteps": 2219554, "per_episode_reward": -133.68, "episode_reward_trend_value": -0.0012242238570043659, "biggest_recent_change": 0.05249499518603784},
{"total_number_of_episodes": 19492, "number_of_timesteps": 2220728, "per_episode_reward": -133.66, "episode_reward_trend_value": -0.0013408162402760758, "biggest_recent_change": 0.05249499518603784},
{"total_number_of_episodes": 19502, "number_of_timesteps": 2221658, "per_episode_reward": -133.63, "episode_reward_trend_value": -0.0005845027325926189, "biggest_recent_change": 0.05249499518603784},
{"total_number_of_episodes": 19512, "number_of_timesteps": 2222692, "per_episode_reward": -133.66, "episode_reward_trend_value": -0.0012618222277195755, "biggest_recent_change": 0.05249499518603784},
{"total_number_of_episodes": 19523, "number_of_timesteps": 2223887, "per_episode_reward": -133.67, "episode_reward_trend_value": -0.0012513426504581402, "biggest_recent_change": 0.05249499518603784},
{"total_number_of_episodes": 19533, "number_of_timesteps": 2225034, "per_episode_reward": -133.69, "episode_reward_trend_value": -0.0008723756688485511, "biggest_recent_change": 0.04547647641953745},
{"total_number_of_episodes": 19543, "number_of_timesteps": 2226466, "per_episode_reward": -133.76, "episode_reward_trend_value": -0.0018110868922905058, "biggest_recent_change": 0.06796900254727234},
{"total_number_of_episodes": 19553, "number_of_timesteps": 2227557, "per_episode_reward": -133.79, "episode_reward_trend_value": -0.001634633349217375, "biggest_recent_change": 0.06796900254727234},
{"total_number_of_episodes": 19564, "number_of_timesteps": 2228913, "per_episode_reward": -133.75, "episode_reward_trend_value": -0.001037486945660741, "biggest_recent_change": 0.06796900254727234},
{"total_number_of_episodes": 19574, "number_of_timesteps": 2230080, "per_episode_reward": -133.73, "episode_reward_trend_value": -0.0006009859765182707, "biggest_recent_change": 0.06796900254727234},
{"total_number_of_episodes": 19584, "number_of_timesteps": 2231165, "per_episode_reward": -133.68, "episode_reward_trend_value": -0.00013055903115710205, "biggest_recent_change": 0.06796900254727234},
{"total_number_of_episodes": 19594, "number_of_timesteps": 2232275, "per_episode_reward": -133.68, "episode_reward_trend_value": -0.0005630628661429506, "biggest_recent_change": 0.06796900254727234},
{"total_number_of_episodes": 19605, "number_of_timesteps": 2233528, "per_episode_reward": -133.7, "episode_reward_trend_value": -0.0004787356757668072, "biggest_recent_change": 0.06796900254727234},
{"total_number_of_episodes": 19616, "number_of_timesteps": 2235146, "per_episode_reward": -133.68, "episode_reward_trend_value": -0.00010974948482953551, "biggest_recent_change": 0.06796900254727234},
{"total_number_of_episodes": 19626, "number_of_timesteps": 2236216, "per_episode_reward": -133.71, "episode_reward_trend_value": -0.00023994924113866192, "biggest_recent_change": 0.06796900254727234},
{"total_number_of_episodes": 19636, "number_of_timesteps": 2237706, "per_episode_reward": -133.71, "episode_reward_trend_value": 0.0006020186472988421, "biggest_recent_change": 0.05665382573229749},
{"total_number_of_episodes": 19647, "number_of_timesteps": 2239079, "per_episode_reward": -133.76, "episode_reward_trend_value": 0.00033257673595256973, "biggest_recent_change": 0.05665382573229749},
{"total_number_of_episodes": 19657, "number_of_timesteps": 2240043, "per_episode_reward": -133.74, "episode_reward_trend_value": 0.00018065718722179251, "biggest_recent_change": 0.05665382573229749},
{"total_number_of_episodes": 19667, "number_of_timesteps": 2241209, "per_episode_reward": -133.74, "episode_reward_trend_value": -9.277329094238161e-05, "biggest_recent_change": 0.05665382573229749},
{"total_number_of_episodes": 19677, "number_of_timesteps": 2242441, "per_episode_reward": -133.74, "episode_reward_trend_value": -0.0007437169805269959, "biggest_recent_change": 0.053845429564120195},
{"total_number_of_episodes": 19687, "number_of_timesteps": 2243583, "per_episode_reward": -133.79, "episode_reward_trend_value": -0.001224622946071463, "biggest_recent_change": 0.053845429564120195},
{"total_number_of_episodes": 19697, "number_of_timesteps": 2244793, "per_episode_reward": -133.83, "episode_reward_trend_value": -0.0014483157841836045, "biggest_recent_change": 0.053845429564120195},
{"total_number_of_episodes": 19707, "number_of_timesteps": 2246238, "per_episode_reward": -133.84, "episode_reward_trend_value": -0.0017545501246868551, "biggest_recent_change": 0.053845429564120195},
{"total_number_of_episodes": 19717, "number_of_timesteps": 2247565, "per_episode_reward": -133.87, "episode_reward_trend_value": -0.0017269026238933647, "biggest_recent_change": 0.053845429564120195},
{"total_number_of_episodes": 19727, "number_of_timesteps": 2248620, "per_episode_reward": -133.91, "episode_reward_trend_value": -0.00225038906974204, "biggest_recent_change": 0.053845429564120195},
{"total_number_of_episodes": 19737, "number_of_timesteps": 2249851, "per_episode_reward": -133.95, "episode_reward_trend_value": -0.0020589347360179823, "biggest_recent_change": 0.04584662474465517},
{"total_number_of_episodes": 19747, "number_of_timesteps": 2251023, "per_episode_reward": -133.93, "episode_reward_trend_value": -0.002179956040233972, "biggest_recent_change": 0.04584662474465517},
{"total_number_of_episodes": 19757, "number_of_timesteps": 2251839, "per_episode_reward": -133.89, "episode_reward_trend_value": -0.0017145303904638038, "biggest_recent_change": 0.04584662474465517},
{"total_number_of_episodes": 19767, "number_of_timesteps": 2253023, "per_episode_reward": -133.9, "episode_reward_trend_value": -0.0017208489228399532, "biggest_recent_change": 0.04584662474465517},
{"total_number_of_episodes": 19777, "number_of_timesteps": 2253862, "per_episode_reward": -133.77, "episode_reward_trend_value": 0.00018552207293680566, "biggest_recent_change": 0.12572676487525314},
{"total_number_of_episodes": 19787, "number_of_timesteps": 2254747, "per_episode_reward": -133.77, "episode_reward_trend_value": 0.0006458761136570957, "biggest_recent_change": 0.12572676487525314},
{"total_number_of_episodes": 19797, "number_of_timesteps": 2255751, "per_episode_reward": -133.78, "episode_reward_trend_value": 0.0007394674254865347, "biggest_recent_change": 0.12572676487525314},
{"total_number_of_episodes": 19807, "number_of_timesteps": 2256894, "per_episode_reward": -133.78, "episode_reward_trend_value": 0.0009702006301390989, "biggest_recent_change": 0.12572676487525314},
{"total_number_of_episodes": 19817, "number_of_timesteps": 2257861, "per_episode_reward": -133.8, "episode_reward_trend_value": 0.001166682332969218, "biggest_recent_change": 0.12572676487525314},
{"total_number_of_episodes": 19829, "number_of_timesteps": 2259046, "per_episode_reward": -133.76, "episode_reward_trend_value": 0.0020243417794606304, "biggest_recent_change": 0.12572676487525314},
{"total_number_of_episodes": 19839, "number_of_timesteps": 2260143, "per_episode_reward": -133.77, "episode_reward_trend_value": 0.001811961236655672, "biggest_recent_change": 0.12572676487525314},
{"total_number_of_episodes": 19849, "number_of_timesteps": 2261338, "per_episode_reward": -133.78, "episode_reward_trend_value": 0.001312380135997652, "biggest_recent_change": 0.12572676487525314},
{"total_number_of_episodes": 19859, "number_of_timesteps": 2262567, "per_episode_reward": -133.75, "episode_reward_trend_value": 0.0015892083544817599, "biggest_recent_change": 0.12572676487525314},
{"total_number_of_episodes": 19869, "number_of_timesteps": 2263631, "per_episode_reward": -133.79, "episode_reward_trend_value": -0.0001831129478934675, "biggest_recent_change": 0.04057481065527213},
{"total_number_of_episodes": 19879, "number_of_timesteps": 2264859, "per_episode_reward": -133.78, "episode_reward_trend_value": -0.0001099613702643233, "biggest_recent_change": 0.04057481065527213},
{"total_number_of_episodes": 19889, "number_of_timesteps": 2266184, "per_episode_reward": -133.8, "episode_reward_trend_value": -0.00026250617904869007, "biggest_recent_change": 0.04057481065527213},
{"total_number_of_episodes": 19900, "number_of_timesteps": 2267396, "per_episode_reward": -133.76, "episode_reward_trend_value": 0.00023335009436998964, "biggest_recent_change": 0.04057481065527213},
{"total_number_of_episodes": 19910, "number_of_timesteps": 2268431, "per_episode_reward": -133.74, "episode_reward_trend_value": 0.0007058091112153559, "biggest_recent_change": 0.04057481065527213},
{"total_number_of_episodes": 19921, "number_of_timesteps": 2269599, "per_episode_reward": -133.77, "episode_reward_trend_value": -4.059046404923568e-05, "biggest_recent_change": 0.03777538318882989},
{"total_number_of_episodes": 19931, "number_of_timesteps": 2270771, "per_episode_reward": -133.78, "episode_reward_trend_value": -8.674799688574492e-05, "biggest_recent_change": 0.03777538318882989},
{"total_number_of_episodes": 19942, "number_of_timesteps": 2271843, "per_episode_reward": -133.72, "episode_reward_trend_value": 0.0006063943282119529, "biggest_recent_change": 0.0565192049638199},
{"total_number_of_episodes": 19952, "number_of_timesteps": 2272944, "per_episode_reward": -133.78, "episode_reward_trend_value": -0.0002763103602028928, "biggest_recent_change": 0.05702865653793765},
{"total_number_of_episodes": 19962, "number_of_timesteps": 2274281, "per_episode_reward": -133.78, "episode_reward_trend_value": 7.054591194035867e-05, "biggest_recent_change": 0.05702865653793765},
{"total_number_of_episodes": 19972, "number_of_timesteps": 2275277, "per_episode_reward": -133.69, "episode_reward_trend_value": 0.0010116444793008363, "biggest_recent_change": 0.0899247172422406},
{"total_number_of_episodes": 19983, "number_of_timesteps": 2276645, "per_episode_reward": -133.68, "episode_reward_trend_value": 0.0012883039289660145, "biggest_recent_change": 0.0899247172422406},
{"total_number_of_episodes": 19993, "number_of_timesteps": 2277885, "per_episode_reward": -133.68, "episode_reward_trend_value": 0.0009223611477428525, "biggest_recent_change": 0.0899247172422406},
{"total_number_of_episodes": 20004, "number_of_timesteps": 2279389, "per_episode_reward": -133.67, "episode_reward_trend_value": 0.000841666533244418, "biggest_recent_change": 0.0899247172422406},
{"total_number_of_episodes": 20014, "number_of_timesteps": 2280697, "per_episode_reward": -133.64, "episode_reward_trend_value": 0.0014713882769702498, "biggest_recent_change": 0.0899247172422406},
{"total_number_of_episodes": 20024, "number_of_timesteps": 2281824, "per_episode_reward": -133.69, "episode_reward_trend_value": 0.0009858503700374715, "biggest_recent_change": 0.0899247172422406},
{"total_number_of_episodes": 20034, "number_of_timesteps": 2283070, "per_episode_reward": -133.68, "episode_reward_trend_value": 0.0004335425370369548, "biggest_recent_change": 0.0899247172422406},
{"total_number_of_episodes": 20045, "number_of_timesteps": 2284281, "per_episode_reward": -133.72, "episode_reward_trend_value": 0.0006572345991331631, "biggest_recent_change": 0.0899247172422406},
{"total_number_of_episodes": 20055, "number_of_timesteps": 2285293, "per_episode_reward": -133.67, "episode_reward_trend_value": 0.0012808311302560723, "biggest_recent_change": 0.0899247172422406},

{"total_number_of_episodes": 20065, "number_of_timesteps": 2286139, "per_episode_reward": -133.65, "episode_reward_trend_value": 0.0005163365781189416, "biggest_recent_change": 0.05430515881010933},
{"total_number_of_episodes": 20075, "number_of_timesteps": 2287296, "per_episode_reward": -133.66, "episode_reward_trend_value": 0.0002164687802939448, "biggest_recent_change": 0.05430515881010933},
{"total_number_of_episodes": 20085, "number_of_timesteps": 2288469, "per_episode_reward": -133.72, "episode_reward_trend_value": -0.0005029508626250845, "biggest_recent_change": 0.05990723498396733},
{"total_number_of_episodes": 20095, "number_of_timesteps": 2289805, "per_episode_reward": -133.74, "episode_reward_trend_value": -0.0008612983409063999, "biggest_recent_change": 0.05990723498396733},
{"total_number_of_episodes": 20105, "number_of_timesteps": 2290630, "per_episode_reward": -133.68, "episode_reward_trend_value": -0.00044661788428628467, "biggest_recent_change": 0.06739504691259413},
{"total_number_of_episodes": 20116, "number_of_timesteps": 2291778, "per_episode_reward": -133.67, "episode_reward_trend_value": 0.000248331784955427, "biggest_recent_change": 0.06739504691259413},
{"total_number_of_episodes": 20126, "number_of_timesteps": 2292854, "per_episode_reward": -133.67, "episode_reward_trend_value": 0.0001399566456854018, "biggest_recent_change": 0.06739504691259413},
{"total_number_of_episodes": 20136, "number_of_timesteps": 2293958, "per_episode_reward": -133.69, "episode_reward_trend_value": 0.0003568435431011115, "biggest_recent_change": 0.06739504691259413},
{"total_number_of_episodes": 20146, "number_of_timesteps": 2294950, "per_episode_reward": -133.69, "episode_reward_trend_value": -0.0002865864994172777, "biggest_recent_change": 0.06739504691259413},
{"total_number_of_episodes": 20156, "number_of_timesteps": 2296028, "per_episode_reward": -133.63, "episode_reward_trend_value": 0.00017610430087257908, "biggest_recent_change": 0.06739504691259413},
{"total_number_of_episodes": 20166, "number_of_timesteps": 2296990, "per_episode_reward": -133.68, "episode_reward_trend_value": -0.000145459086300232, "biggest_recent_change": 0.06739504691259413},
{"total_number_of_episodes": 20177, "number_of_timesteps": 2298035, "per_episode_reward": -133.64, "episode_reward_trend_value": 0.0009256914912135194, "biggest_recent_change": 0.06739504691259413},
{"total_number_of_episodes": 20187, "number_of_timesteps": 2299621, "per_episode_reward": -133.71, "episode_reward_trend_value": 0.000367891300903188, "biggest_recent_change": 0.0688168134215914},
{"total_number_of_episodes": 20198, "number_of_timesteps": 2301114, "per_episode_reward": -133.71, "episode_reward_trend_value": -0.00042923210770437795, "biggest_recent_change": 0.0688168134215914},
{"total_number_of_episodes": 20208, "number_of_timesteps": 2302128, "per_episode_reward": -133.69, "episode_reward_trend_value": -0.00030771634049339507, "biggest_recent_change": 0.0688168134215914},
{"total_number_of_episodes": 20219, "number_of_timesteps": 2303400, "per_episode_reward": -133.67, "episode_reward_trend_value": 3.738237367088004e-05, "biggest_recent_change": 0.0688168134215914},
{"total_number_of_episodes": 20229, "number_of_timesteps": 2304558, "per_episode_reward": -133.63, "episode_reward_trend_value": 0.0006116689773335793, "biggest_recent_change": 0.0688168134215914},
{"total_number_of_episodes": 20240, "number_of_timesteps": 2305918, "per_episode_reward": -133.67, "episode_reward_trend_value": 0.00027878964092735713, "biggest_recent_change": 0.0688168134215914},
{"total_number_of_episodes": 20251, "number_of_timesteps": 2307750, "per_episode_reward": -133.65, "episode_reward_trend_value": -0.0002619448252087548, "biggest_recent_change": 0.0688168134215914},
{"total_number_of_episodes": 20261, "number_of_timesteps": 2308923, "per_episode_reward": -133.67, "episode_reward_trend_value": 0.00011007765210706566, "biggest_recent_change": 0.0688168134215914},
{"total_number_of_episodes": 20271, "number_of_timesteps": 2309975, "per_episode_reward": -133.62, "episode_reward_trend_value": 0.000254939134036489, "biggest_recent_change": 0.0688168134215914},
{"total_number_of_episodes": 20282, "number_of_timesteps": 2311446, "per_episode_reward": -133.59, "episode_reward_trend_value": 0.0013459568456858683, "biggest_recent_change": 0.0495338503659184},
{"total_number_of_episodes": 20292, "number_of_timesteps": 2312647, "per_episode_reward": -133.62, "episode_reward_trend_value": 0.0010130325758448558, "biggest_recent_change": 0.0495338503659184},
{"total_number_of_episodes": 20302, "number_of_timesteps": 2313764, "per_episode_reward": -133.64, "episode_reward_trend_value": 0.0006383432896519203, "biggest_recent_change": 0.0495338503659184},
{"total_number_of_episodes": 20313, "number_of_timesteps": 2315021, "per_episode_reward": -133.68, "episode_reward_trend_value": -0.00010532217635336059, "biggest_recent_change": 0.0495338503659184},
{"total_number_of_episodes": 20323, "number_of_timesteps": 2316036, "per_episode_reward": -133.66, "episode_reward_trend_value": -0.00032608782281897677, "biggest_recent_change": 0.0495338503659184},
{"total_number_of_episodes": 20333, "number_of_timesteps": 2317406, "per_episode_reward": -133.68, "episode_reward_trend_value": -0.0001685860963195612, "biggest_recent_change": 0.0495338503659184},
{"total_number_of_episodes": 20344, "number_of_timesteps": 2318653, "per_episode_reward": -133.63, "episode_reward_trend_value": 0.0002619448252087548, "biggest_recent_change": 0.05284406056128432},
{"total_number_of_episodes": 20354, "number_of_timesteps": 2319662, "per_episode_reward": -133.61, "episode_reward_trend_value": 0.0006505682167367393, "biggest_recent_change": 0.05284406056128432},
{"total_number_of_episodes": 20364, "number_of_timesteps": 2320697, "per_episode_reward": -133.59, "episode_reward_trend_value": 0.0002729546153637507, "biggest_recent_change": 0.05284406056128432},
{"total_number_of_episodes": 20374, "number_of_timesteps": 2321857, "per_episode_reward": -133.59, "episode_reward_trend_value": -5.242442906844897e-07, "biggest_recent_change": 0.05284406056128432},
{"total_number_of_episodes": 20384, "number_of_timesteps": 2322813, "per_episode_reward": -133.58, "episode_reward_trend_value": 0.0004926261456161127, "biggest_recent_change": 0.05284406056128432},
{"total_number_of_episodes": 20394, "number_of_timesteps": 2324231, "per_episode_reward": -133.56, "episode_reward_trend_value": 0.0008310359254942847, "biggest_recent_change": 0.05284406056128432},
{"total_number_of_episodes": 20405, "number_of_timesteps": 2325288, "per_episode_reward": -133.58, "episode_reward_trend_value": 0.0011154468927514927, "biggest_recent_change": 0.05284406056128432},
{"total_number_of_episodes": 20416, "number_of_timesteps": 2326718, "per_episode_reward": -133.57, "episode_reward_trend_value": 0.0010379928863594992, "biggest_recent_change": 0.05284406056128432},
{"total_number_of_episodes": 20426, "number_of_timesteps": 2327572, "per_episode_reward": -133.48, "episode_reward_trend_value": 0.0022692041644265574, "biggest_recent_change": 0.09067492626320472},
{"total_number_of_episodes": 20436, "number_of_timesteps": 2328723, "per_episode_reward": -133.5, "episode_reward_trend_value": 0.0014062281976871796, "biggest_recent_change": 0.09067492626320472},
{"total_number_of_episodes": 20446, "number_of_timesteps": 2329807, "per_episode_reward": -133.49, "episode_reward_trend_value": 0.0013744505469847784, "biggest_recent_change": 0.09067492626320472},
{"total_number_of_episodes": 20456, "number_of_timesteps": 2331048, "per_episode_reward": -133.46, "episode_reward_trend_value": 0.0014380600777823501, "biggest_recent_change": 0.09067492626320472},
{"total_number_of_episodes": 20468, "number_of_timesteps": 2332192, "per_episode_reward": -133.45, "episode_reward_trend_value": 0.0015790864140096043, "biggest_recent_change": 0.09067492626320472},
{"total_number_of_episodes": 20478, "number_of_timesteps": 2333336, "per_episode_reward": -133.45, "episode_reward_trend_value": 0.001438082002064789, "biggest_recent_change": 0.09067492626320472},
{"total_number_of_episodes": 20489, "number_of_timesteps": 2335099, "per_episode_reward": -133.47, "episode_reward_trend_value": 0.0010419069225763324, "biggest_recent_change": 0.09067492626320472},
{"total_number_of_episodes": 20499, "number_of_timesteps": 2336211, "per_episode_reward": -133.47, "episode_reward_trend_value": 0.001160688148331701, "biggest_recent_change": 0.09067492626320472},
{"total_number_of_episodes": 20510, "number_of_timesteps": 2337362, "per_episode_reward": -133.47, "episode_reward_trend_value": 0.0011130609534016382, "biggest_recent_change": 0.09067492626320472},
{"total_number_of_episodes": 20520, "number_of_timesteps": 2338452, "per_episode_reward": -133.48, "episode_reward_trend_value": -4.222774530483599e-05, "biggest_recent_change": 0.024823776445259682},
{"total_number_of_episodes": 20530, "number_of_timesteps": 2339465, "per_episode_reward": -133.45, "episode_reward_trend_value": 0.0005531328650625432, "biggest_recent_change": 0.028758678487804445},
{"total_number_of_episodes": 20541, "number_of_timesteps": 2340592, "per_episode_reward": -133.46, "episode_reward_trend_value": 0.00024261771595995973, "biggest_recent_change": 0.028758678487804445},
{"total_number_of_episodes": 20552, "number_of_timesteps": 2342032, "per_episode_reward": -133.46, "episode_reward_trend_value": 3.781282269225509e-06, "biggest_recent_change": 0.028758678487804445},
{"total_number_of_episodes": 20562, "number_of_timesteps": 2343081, "per_episode_reward": -133.46, "episode_reward_trend_value": -0.00010940750294234174, "biggest_recent_change": 0.028758678487804445},
{"total_number_of_episodes": 20572, "number_of_timesteps": 2344307, "per_episode_reward": -133.45, "episode_reward_trend_value": 3.404180946107418e-05, "biggest_recent_change": 0.028758678487804445},
{"total_number_of_episodes": 20582, "number_of_timesteps": 2345793, "per_episode_reward": -133.44, "episode_reward_trend_value": 0.00027362746571794915, "biggest_recent_change": 0.028758678487804445},
{"total_number_of_episodes": 20593, "number_of_timesteps": 2346764, "per_episode_reward": -133.42, "episode_reward_trend_value": 0.000624712479897956, "biggest_recent_change": 0.029071678441113136},
{"total_number_of_episodes": 20603, "number_of_timesteps": 2347597, "per_episode_reward": -133.41, "episode_reward_trend_value": 0.0006811685929660725, "biggest_recent_change": 0.029071678441113136},
{"total_number_of_episodes": 20613, "number_of_timesteps": 2348720, "per_episode_reward": -133.37, "episode_reward_trend_value": 0.001201106344041768, "biggest_recent_change": 0.03349334097643464},
{"total_number_of_episodes": 20623, "number_of_timesteps": 2350055, "per_episode_reward": -133.36, "episode_reward_trend_value": 0.0009840564623797518, "biggest_recent_change": 0.03349334097643464},
{"total_number_of_episodes": 20633, "number_of_timesteps": 2351108, "per_episode_reward": -133.34, "episode_reward_trend_value": 0.0013413329799984949, "biggest_recent_change": 0.03349334097643464},
{"total_number_of_episodes": 20644, "number_of_timesteps": 2352453, "per_episode_reward": -133.41, "episode_reward_trend_value": 0.0005464939292983849, "biggest_recent_change": 0.07175730958104509},
{"total_number_of_episodes": 20654, "number_of_timesteps": 2353719, "per_episode_reward": -133.41, "episode_reward_trend_value": 0.0005610468648443303, "biggest_recent_change": 0.07175730958104509},
{"total_number_of_episodes": 20664, "number_of_timesteps": 2354862, "per_episode_reward": -133.39, "episode_reward_trend_value": 0.0006065432892717758, "biggest_recent_change": 0.07175730958104509},
{"total_number_of_episodes": 20674, "number_of_timesteps": 2356078, "per_episode_reward": -133.44, "episode_reward_trend_value": 3.653065286073343e-05, "biggest_recent_change": 0.07175730958104509},
{"total_number_of_episodes": 20684, "number_of_timesteps": 2357332, "per_episode_reward": -133.46, "episode_reward_trend_value": -0.0004795782925593055, "biggest_recent_change": 0.07175730958104509},
{"total_number_of_episodes": 20694, "number_of_timesteps": 2358333, "per_episode_reward": -133.46, "episode_reward_trend_value": -0.0005929028065404889, "biggest_recent_change": 0.07175730958104509},
{"total_number_of_episodes": 20704, "number_of_timesteps": 2359430, "per_episode_reward": -133.46, "episode_reward_trend_value": -0.0009765532203033445, "biggest_recent_change": 0.07175730958104509},
{"total_number_of_episodes": 20714, "number_of_timesteps": 2360464, "per_episode_reward": -133.43, "episode_reward_trend_value": -0.0007057455843617314, "biggest_recent_change": 0.07175730958104509},
{"total_number_of_episodes": 20724, "number_of_timesteps": 2361429, "per_episode_reward": -133.42, "episode_reward_trend_value": -0.0009045752882378287, "biggest_recent_change": 0.07175730958104509},
{"total_number_of_episodes": 20734, "number_of_timesteps": 2362279, "per_episode_reward": -133.4, "episode_reward_trend_value": 0.00014598524160192028, "biggest_recent_change": 0.04948261046553171},
{"total_number_of_episodes": 20744, "number_of_timesteps": 2363381, "per_episode_reward": -133.34, "episode_reward_trend_value": 0.0007012448340428061, "biggest_recent_change": 0.05855019036818021},
{"total_number_of_episodes": 20755, "number_of_timesteps": 2364640, "per_episode_reward": -133.31, "episode_reward_trend_value": 0.0009369433199639034, "biggest_recent_change": 0.05855019036818021},
{"total_number_of_episodes": 20766, "number_of_timesteps": 2365968, "per_episode_reward": -133.26, "episode_reward_trend_value": 0.0020646755520620746, "biggest_recent_change": 0.05855019036818021},
{"total_number_of_episodes": 20776, "number_of_timesteps": 2366957, "per_episode_reward": -133.27, "episode_reward_trend_value": 0.002110470602206584, "biggest_recent_change": 0.05855019036818021},
{"total_number_of_episodes": 20786, "number_of_timesteps": 2368039, "per_episode_reward": -133.3, "episode_reward_trend_value": 0.001790187993124606, "biggest_recent_change": 0.05855019036818021},
{"total_number_of_episodes": 20796, "number_of_timesteps": 2369178, "per_episode_reward": -133.29, "episode_reward_trend_value": 0.001856061231839274, "biggest_recent_change": 0.05855019036818021},
{"total_number_of_episodes": 20807, "number_of_timesteps": 2370518, "per_episode_reward": -133.24, "episode_reward_trend_value": 0.0020885659367160594, "biggest_recent_change": 0.05855019036818021},
{"total_number_of_episodes": 20817, "number_of_timesteps": 2371719, "per_episode_reward": -133.22, "episode_reward_trend_value": 0.002225351433133306, "biggest_recent_change": 0.05855019036818021},
{"total_number_of_episodes": 20828, "number_of_timesteps": 2372873, "per_episode_reward": -133.27, "episode_reward_trend_value": 0.0014084175030373244, "biggest_recent_change": 0.05855019036818021},
{"total_number_of_episodes": 20838, "number_of_timesteps": 2374012, "per_episode_reward": -133.3, "episode_reward_trend_value": 0.00047285441868230766, "biggest_recent_change": 0.05452229981187884},
{"total_number_of_episodes": 20848, "number_of_timesteps": 2375068, "per_episode_reward": -133.26, "episode_reward_trend_value": 0.00047072741571159643, "biggest_recent_change": 0.05452229981187884},
{"total_number_of_episodes": 20858, "number_of_timesteps": 2375995, "per_episode_reward": -133.31, "episode_reward_trend_value": -0.0006429071816041996, "biggest_recent_change": 0.05452229981187884},
{"total_number_of_episodes": 20869, "number_of_timesteps": 2376922, "per_episode_reward": -133.23, "episode_reward_trend_value": 0.00042413797112601516, "biggest_recent_change": 0.08277749161203474},
{"total_number_of_episodes": 20879, "number_of_timesteps": 2377960, "per_episode_reward": -133.26, "episode_reward_trend_value": 0.0004289193888158454, "biggest_recent_change": 0.08277749161203474},
{"total_number_of_episodes": 20889, "number_of_timesteps": 2379103, "per_episode_reward": -133.2, "episode_reward_trend_value": 0.0010950199645306056, "biggest_recent_change": 0.08277749161203474},
{"total_number_of_episodes": 20899, "number_of_timesteps": 2380215, "per_episode_reward": -133.2, "episode_reward_trend_value": 0.000465840568620024, "biggest_recent_change": 0.08277749161203474},
{"total_number_of_episodes": 20909, "number_of_timesteps": 2381358, "per_episode_reward": -133.15, "episode_reward_trend_value": 0.000815854090900656, "biggest_recent_change": 0.08277749161203474},
{"total_number_of_episodes": 20919, "number_of_timesteps": 2382484, "per_episode_reward": -133.16, "episode_reward_trend_value": 0.0013178637863900475, "biggest_recent_change": 0.08277749161203474},
{"total_number_of_episodes": 20929, "number_of_timesteps": 2383545, "per_episode_reward": -133.19, "episode_reward_trend_value": 0.0012457506888040371, "biggest_recent_change": 0.08277749161203474},
{"total_number_of_episodes": 20939, "number_of_timesteps": 2384668, "per_episode_reward": -133.08, "episode_reward_trend_value": 0.0020652156035715226, "biggest_recent_change": 0.10916228597818645},
{"total_number_of_episodes": 20949, "number_of_timesteps": 2385787, "per_episode_reward": -133.09, "episode_reward_trend_value": 0.002521925582630994, "biggest_recent_change": 0.10916228597818645},
{"total_number_of_episodes": 20960, "number_of_timesteps": 2387102, "per_episode_reward": -133.08, "episode_reward_trend_value": 0.0016396148916552674, "biggest_recent_change": 0.10916228597818645},
{"total_number_of_episodes": 20970, "number_of_timesteps": 2388337, "per_episode_reward": -133.06, "episode_reward_trend_value": 0.002233206652635684, "biggest_recent_change": 0.10916228597818645},
{"total_number_of_episodes": 20980, "number_of_timesteps": 2389400, "per_episode_reward": -133.06, "episode_reward_trend_value": 0.0015267909386352586, "biggest_recent_change": 0.10916228597818645},
{"total_number_of_episodes": 20990, "number_of_timesteps": 2390604, "per_episode_reward": -133.09, "episode_reward_trend_value": 0.001194474215141857, "biggest_recent_change": 0.10916228597818645},
{"total_number_of_episodes": 21001, "number_of_timesteps": 2391944, "per_episode_reward": -133.13, "episode_reward_trend_value": 0.00019389337454356337, "biggest_recent_change": 0.10916228597818645},
{"total_number_of_episodes": 21012, "number_of_timesteps": 2393154, "per_episode_reward": -133.08, "episode_reward_trend_value": 0.0008364522100199187, "biggest_recent_change": 0.10916228597818645},
{"total_number_of_episodes": 21023, "number_of_timesteps": 2394324, "per_episode_reward": -133.15, "episode_reward_trend_value": 0.0004160096347719546, "biggest_recent_change": 0.10916228597818645},
{"total_number_of_episodes": 21033, "number_of_timesteps": 2395374, "per_episode_reward": -133.15, "episode_reward_trend_value": -0.0007708782188504731, "biggest_recent_change": 0.06998049777882898},
{"total_number_of_episodes": 21043, "number_of_timesteps": 2396605, "per_episode_reward": -133.16, "episode_reward_trend_value": -0.000770408868943188, "biggest_recent_change": 0.06998049777882898},
{"total_number_of_episodes": 21053, "number_of_timesteps": 2397809, "per_episode_reward": -133.16, "episode_reward_trend_value": -0.0008067762096980383, "biggest_recent_change": 0.06998049777882898},
{"total_number_of_episodes": 21063, "number_of_timesteps": 2399087, "per_episode_reward": -133.21, "episode_reward_trend_value": -0.001722899232456459, "biggest_recent_change": 0.06998049777882898},
{"total_number_of_episodes": 21074, "number_of_timesteps": 2400317, "per_episode_reward": -133.25, "episode_reward_trend_value": -0.0020886292694989885, "biggest_recent_change": 0.06998049777882898},
{"total_number_of_episodes": 21084, "number_of_timesteps": 2401546, "per_episode_reward": -133.28, "episode_reward_trend_value": -0.0020596716888055273, "biggest_recent_change": 0.06998049777882898},
{"total_number_of_episodes": 21094, "number_of_timesteps": 2402658, "per_episode_reward": -133.22, "episode_reward_trend_value": -0.0009583466811307062, "biggest_recent_change": 0.06998049777882898},
{"total_number_of_episodes": 21104, "number_of_timesteps": 2403698, "per_episode_reward": -133.22, "episode_reward_trend_value": -0.0015129866799624223, "biggest_recent_change": 0.06998049777882898},
{"total_number_of_episodes": 21114, "number_of_timesteps": 2404811, "per_episode_reward": -133.21, "episode_reward_trend_value": -0.0007008411540498274, "biggest_recent_change": 0.059358049020602266},
{"total_number_of_episodes": 21124, "number_of_timesteps": 2406038, "per_episode_reward": -133.21, "episode_reward_trend_value": -0.0006393828023776551, "biggest_recent_change": 0.059358049020602266},
{"total_number_of_episodes": 21134, "number_of_timesteps": 2407341, "per_episode_reward": -133.23, "episode_reward_trend_value": -0.0008148845830517202, "biggest_recent_change": 0.059358049020602266},
{"total_number_of_episodes": 21144, "number_of_timesteps": 2408412, "per_episode_reward": -133.21, "episode_reward_trend_value": -0.0005727983188156334, "biggest_recent_change": 0.059358049020602266},
{"total_number_of_episodes": 21154, "number_of_timesteps": 2409172, "per_episode_reward": -133.14, "episode_reward_trend_value": 0.0007898886916109405, "biggest_recent_change": 0.06328378191778938},
{"total_number_of_episodes": 21165, "number_of_timesteps": 2410429, "per_episode_reward": -133.17, "episode_reward_trend_value": 0.0008772874737714018, "biggest_recent_change": 0.06328378191778938},
{"total_number_of_episodes": 21177, "number_of_timesteps": 2412027, "per_episode_reward": -133.13, "episode_reward_trend_value": 0.0016321894926540556, "biggest_recent_change": 0.06328378191778938},
{"total_number_of_episodes": 21187, "number_of_timesteps": 2413298, "per_episode_reward": -133.15, "episode_reward_trend_value": 0.0008003928842005811, "biggest_recent_change": 0.06328378191778938},
{"total_number_of_episodes": 21198, "number_of_timesteps": 2414423, "per_episode_reward": -133.15, "episode_reward_trend_value": 0.000695666191822713, "biggest_recent_change": 0.06328378191778938},
{"total_number_of_episodes": 21208, "number_of_timesteps": 2415926, "per_episode_reward": -133.13, "episode_reward_trend_value": 0.0008875743714841948, "biggest_recent_change": 0.06328378191778938},
{"total_number_of_episodes": 21220, "number_of_timesteps": 2417296, "per_episode_reward": -133.14, "episode_reward_trend_value": 0.0007088029387284046, "biggest_recent_change": 0.06328378191778938},
{"total_number_of_episodes": 21231, "number_of_timesteps": 2418350, "per_episode_reward": -133.14, "episode_reward_trend_value": 0.0009756299262022594, "biggest_recent_change": 0.06328378191778938},
{"total_number_of_episodes": 21241, "number_of_timesteps": 2419581, "per_episode_reward": -133.15, "episode_reward_trend_value": 0.0006185569761467175, "biggest_recent_change": 0.06328378191778938},
{"total_number_of_episodes": 21251, "number_of_timesteps": 2420709, "per_episode_reward": -133.17, "episode_reward_trend_value": -0.00025960227962589975, "biggest_recent_change": 0.038535013027370724},
{"total_number_of_episodes": 21261, "number_of_timesteps": 2421672, "per_episode_reward": -133.14, "episode_reward_trend_value": 0.0003502607751882023, "biggest_recent_change": 0.038535013027370724},
{"total_number_of_episodes": 21271, "number_of_timesteps": 2422665, "per_episode_reward": -133.13, "episode_reward_trend_value": -5.527787153722682e-05, "biggest_recent_change": 0.03110289477027095},
{"total_number_of_episodes": 21281, "number_of_timesteps": 2423764, "per_episode_reward": -133.14, "episode_reward_trend_value": 5.79456227673821e-05, "biggest_recent_change": 0.03110289477027095},
{"total_number_of_episodes": 21292, "number_of_timesteps": 2425525, "per_episode_reward": -133.15, "episode_reward_trend_value": 4.4921596352133344e-05, "biggest_recent_change": 0.03110289477027095},
{"total_number_of_episodes": 21302, "number_of_timesteps": 2426700, "per_episode_reward": -133.13, "episode_reward_trend_value": 4.279713503731526e-05, "biggest_recent_change": 0.03110289477027095},

{"total_number_of_episodes": 21312, "number_of_timesteps": 2427695, "per_episode_reward": -133.12, "episode_reward_trend_value": 0.0002698728316592754, "biggest_recent_change": 0.03110289477027095},
{"total_number_of_episodes": 21322, "number_of_timesteps": 2428798, "per_episode_reward": -133.13, "episode_reward_trend_value": 0.0001547433709359009, "biggest_recent_change": 0.03110289477027095},
{"total_number_of_episodes": 21333, "number_of_timesteps": 2430264, "per_episode_reward": -133.23, "episode_reward_trend_value": -0.0009080989538539875, "biggest_recent_change": 0.10590814219855815},
{"total_number_of_episodes": 21343, "number_of_timesteps": 2431337, "per_episode_reward": -133.24, "episode_reward_trend_value": -0.0008344760667572219, "biggest_recent_change": 0.10590814219855815},
{"total_number_of_episodes": 21353, "number_of_timesteps": 2432296, "per_episode_reward": -133.22, "episode_reward_trend_value": -0.0009577521039416424, "biggest_recent_change": 0.10590814219855815},
{"total_number_of_episodes": 21363, "number_of_timesteps": 2433637, "per_episode_reward": -133.23, "episode_reward_trend_value": -0.0010920115283084898, "biggest_recent_change": 0.10590814219855815},
{"total_number_of_episodes": 21373, "number_of_timesteps": 2434760, "per_episode_reward": -133.37, "episode_reward_trend_value": -0.0025207909046113426, "biggest_recent_change": 0.13676895577663117},
{"total_number_of_episodes": 21383, "number_of_timesteps": 2435918, "per_episode_reward": -133.35, "episode_reward_trend_value": -0.0021753017298098915, "biggest_recent_change": 0.13676895577663117},
{"total_number_of_episodes": 21393, "number_of_timesteps": 2437120, "per_episode_reward": -133.31, "episode_reward_trend_value": -0.002011772613634359, "biggest_recent_change": 0.13676895577663117},
{"total_number_of_episodes": 21403, "number_of_timesteps": 2438055, "per_episode_reward": -133.23, "episode_reward_trend_value": -0.0012588996007720098, "biggest_recent_change": 0.13676895577663117},
{"total_number_of_episodes": 21414, "number_of_timesteps": 2439113, "per_episode_reward": -133.21, "episode_reward_trend_value": -0.0009516015187525935, "biggest_recent_change": 0.13676895577663117},
{"total_number_of_episodes": 21424, "number_of_timesteps": 2439854, "per_episode_reward": -133.19, "episode_reward_trend_value": 0.00045381953775000105, "biggest_recent_change": 0.13676895577663117},
{"total_number_of_episodes": 21434, "number_of_timesteps": 2440854, "per_episode_reward": -133.18, "episode_reward_trend_value": 0.0007244581549785935, "biggest_recent_change": 0.13676895577663117},
{"total_number_of_episodes": 21444, "number_of_timesteps": 2441977, "per_episode_reward": -133.15, "episode_reward_trend_value": 0.0007620679997599053, "biggest_recent_change": 0.13676895577663117},
{"total_number_of_episodes": 21454, "number_of_timesteps": 2444132, "per_episode_reward": -133.14, "episode_reward_trend_value": 0.0010624793569244653, "biggest_recent_change": 0.13676895577663117},
{"total_number_of_episodes": 21464, "number_of_timesteps": 2445244, "per_episode_reward": -133.11, "episode_reward_trend_value": 0.002838085211202686, "biggest_recent_change": 0.07997958570823016},
{"total_number_of_episodes": 21475, "number_of_timesteps": 2446861, "per_episode_reward": -133.14, "episode_reward_trend_value": 0.0023137212942354306, "biggest_recent_change": 0.07997958570823016},
{"total_number_of_episodes": 21485, "number_of_timesteps": 2448007, "per_episode_reward": -133.12, "episode_reward_trend_value": 0.002152938433738427, "biggest_recent_change": 0.07997958570823016},
{"total_number_of_episodes": 21497, "number_of_timesteps": 2449533, "per_episode_reward": -133.12, "episode_reward_trend_value": 0.0012326286695510033, "biggest_recent_change": 0.02433363919834619},
{"total_number_of_episodes": 21507, "number_of_timesteps": 2450917, "per_episode_reward": -133.16, "episode_reward_trend_value": 0.0005492552441549176, "biggest_recent_change": 0.04305684748513272},
{"total_number_of_episodes": 21518, "number_of_timesteps": 2452233, "per_episode_reward": -133.22, "episode_reward_trend_value": -0.00027586899239477386, "biggest_recent_change": 0.05368142840279688},
{"total_number_of_episodes": 21528, "number_of_timesteps": 2453491, "per_episode_reward": -133.19, "episode_reward_trend_value": -0.0001813993120094892, "biggest_recent_change": 0.05368142840279688},
{"total_number_of_episodes": 21538, "number_of_timesteps": 2454646, "per_episode_reward": -133.17, "episode_reward_trend_value": -0.00021000277219103384, "biggest_recent_change": 0.05368142840279688},
{"total_number_of_episodes": 21549, "number_of_timesteps": 2455660, "per_episode_reward": -133.16, "episode_reward_trend_value": -0.0003080234000047236, "biggest_recent_change": 0.05368142840279688},
{"total_number_of_episodes": 21559, "number_of_timesteps": 2457329, "per_episode_reward": -133.16, "episode_reward_trend_value": -0.0005639741900981537, "biggest_recent_change": 0.05368142840279688},
{"total_number_of_episodes": 21569, "number_of_timesteps": 2458440, "per_episode_reward": -133.16, "episode_reward_trend_value": -0.0002504908391276533, "biggest_recent_change": 0.05368142840279688},
{"total_number_of_episodes": 21579, "number_of_timesteps": 2459748, "per_episode_reward": -133.13, "episode_reward_trend_value": -0.00014819591388888715, "biggest_recent_change": 0.05368142840279688},
{"total_number_of_episodes": 21589, "number_of_timesteps": 2460721, "per_episode_reward": -133.18, "episode_reward_trend_value": -0.0006994717560887566, "biggest_recent_change": 0.05368142840279688},
{"total_number_of_episodes": 21599, "number_of_timesteps": 2461845, "per_episode_reward": -133.2, "episode_reward_trend_value": -0.00041693761341687403, "biggest_recent_change": 0.05368142840279688},
{"total_number_of_episodes": 21609, "number_of_timesteps": 2464035, "per_episode_reward": -133.24, "episode_reward_trend_value": -0.00022374781925533523, "biggest_recent_change": 0.052463118866626246},
{"total_number_of_episodes": 21619, "number_of_timesteps": 2464996, "per_episode_reward": -133.2, "episode_reward_trend_value": -5.12160755868586e-05, "biggest_recent_change": 0.052463118866626246},
{"total_number_of_episodes": 21629, "number_of_timesteps": 2466021, "per_episode_reward": -133.19, "episode_reward_trend_value": -0.00017586895551460202, "biggest_recent_change": 0.052463118866626246},
{"total_number_of_episodes": 21640, "number_of_timesteps": 2467130, "per_episode_reward": -133.23, "episode_reward_trend_value": -0.0007337455755990479, "biggest_recent_change": 0.052463118866626246},
{"total_number_of_episodes": 21652, "number_of_timesteps": 2468711, "per_episode_reward": -133.21, "episode_reward_trend_value": -0.0004890843113757783, "biggest_recent_change": 0.052463118866626246},
{"total_number_of_episodes": 21662, "number_of_timesteps": 2469651, "per_episode_reward": -133.2, "episode_reward_trend_value": -0.0004305868572326214, "biggest_recent_change": 0.052463118866626246},
{"total_number_of_episodes": 21672, "number_of_timesteps": 2470686, "per_episode_reward": -133.21, "episode_reward_trend_value": -0.0008417965015149144, "biggest_recent_change": 0.052463118866626246},
{"total_number_of_episodes": 21683, "number_of_timesteps": 2471727, "per_episode_reward": -133.17, "episode_reward_trend_value": 0.00019611443688347663, "biggest_recent_change": 0.042040543536955965},
{"total_number_of_episodes": 21693, "number_of_timesteps": 2472778, "per_episode_reward": -133.08, "episode_reward_trend_value": 0.0013378155136921223, "biggest_recent_change": 0.08512432226811484},
{"total_number_of_episodes": 21704, "number_of_timesteps": 2474376, "per_episode_reward": -133.1, "episode_reward_trend_value": 0.0014729989180779057, "biggest_recent_change": 0.08512432226811484},
{"total_number_of_episodes": 21714, "number_of_timesteps": 2475365, "per_episode_reward": -133.05, "episode_reward_trend_value": 0.0016841623764094038, "biggest_recent_change": 0.08512432226811484},
{"total_number_of_episodes": 21724, "number_of_timesteps": 2476409, "per_episode_reward": -133.07, "episode_reward_trend_value": 0.0012598314383843166, "biggest_recent_change": 0.08512432226811484},
{"total_number_of_episodes": 21735, "number_of_timesteps": 2477680, "per_episode_reward": -133.07, "episode_reward_trend_value": 0.0017716548892811562, "biggest_recent_change": 0.08512432226811484},
{"total_number_of_episodes": 21745, "number_of_timesteps": 2478553, "per_episode_reward": -133.03, "episode_reward_trend_value": 0.002026158268297864, "biggest_recent_change": 0.08512432226811484},
{"total_number_of_episodes": 21755, "number_of_timesteps": 2479648, "per_episode_reward": -133.0, "episode_reward_trend_value": 0.002170971428559988, "biggest_recent_change": 0.08512432226811484},
{"total_number_of_episodes": 21767, "number_of_timesteps": 2481229, "per_episode_reward": -133.0, "episode_reward_trend_value": 0.00228447814162962, "biggest_recent_change": 0.08512432226811484},
{"total_number_of_episodes": 21777, "number_of_timesteps": 2482261, "per_episode_reward": -132.95, "episode_reward_trend_value": 0.002412540706786596, "biggest_recent_change": 0.08512432226811484},
{"total_number_of_episodes": 21788, "number_of_timesteps": 2483423, "per_episode_reward": -132.96, "episode_reward_trend_value": 0.001293178524126246, "biggest_recent_change": 0.0582678237022094},
{"total_number_of_episodes": 21798, "number_of_timesteps": 2484190, "per_episode_reward": -132.89, "episode_reward_trend_value": 0.0023776774653132154, "biggest_recent_change": 0.07347706417328936},
{"total_number_of_episodes": 21809, "number_of_timesteps": 2485245, "per_episode_reward": -132.9, "episode_reward_trend_value": 0.0015740276490674888, "biggest_recent_change": 0.07347706417328936},
{"total_number_of_episodes": 21821, "number_of_timesteps": 2486492, "per_episode_reward": -132.89, "episode_reward_trend_value": 0.00201960737718265, "biggest_recent_change": 0.07347706417328936},
{"total_number_of_episodes": 21831, "number_of_timesteps": 2487314, "per_episode_reward": -132.88, "episode_reward_trend_value": 0.0021308460509866715, "biggest_recent_change": 0.07347706417328936},
{"total_number_of_episodes": 21841, "number_of_timesteps": 2488217, "per_episode_reward": -132.84, "episode_reward_trend_value": 0.002072727055696709, "biggest_recent_change": 0.07347706417328936},
{"total_number_of_episodes": 21852, "number_of_timesteps": 2489450, "per_episode_reward": -132.93, "episode_reward_trend_value": 0.0008712530361309392, "biggest_recent_change": 0.08595484407544518},
{"total_number_of_episodes": 21863, "number_of_timesteps": 2490420, "per_episode_reward": -132.9, "episode_reward_trend_value": 0.001068959193054929, "biggest_recent_change": 0.08595484407544518},
{"total_number_of_episodes": 21873, "number_of_timesteps": 2491328, "per_episode_reward": -132.86, "episode_reward_trend_value": 0.001018031875513101, "biggest_recent_change": 0.08595484407544518},
{"total_number_of_episodes": 21883, "number_of_timesteps": 2492632, "per_episode_reward": -132.89, "episode_reward_trend_value": 0.0007897266596239028, "biggest_recent_change": 0.08595484407544518},
{"total_number_of_episodes": 21893, "number_of_timesteps": 2493751, "per_episode_reward": -132.89, "episode_reward_trend_value": 3.2509157176718875e-05, "biggest_recent_change": 0.08595484407544518},
{"total_number_of_episodes": 21903, "number_of_timesteps": 2494912, "per_episode_reward": -132.86, "episode_reward_trend_value": 0.0004792598266887025, "biggest_recent_change": 0.08595484407544518},
{"total_number_of_episodes": 21913, "number_of_timesteps": 2495951, "per_episode_reward": -132.83, "episode_reward_trend_value": 0.0006514314625570073, "biggest_recent_change": 0.08595484407544518},
{"total_number_of_episodes": 21923, "number_of_timesteps": 2496992, "per_episode_reward": -132.84, "episode_reward_trend_value": 0.0004661218133249021, "biggest_recent_change": 0.08595484407544518},
{"total_number_of_episodes": 21933, "number_of_timesteps": 2498295, "per_episode_reward": -132.86, "episode_reward_trend_value": -0.0002647239733581349, "biggest_recent_change": 0.08595484407544518},
{"total_number_of_episodes": 21943, "number_of_timesteps": 2499397, "per_episode_reward": -132.86, "episode_reward_trend_value": 0.0007045704359408471, "biggest_recent_change": 0.04789103787459226},
{"total_number_of_episodes": 21953, "number_of_timesteps": 2500704, "per_episode_reward": -132.93, "episode_reward_trend_value": -0.00029381477441650834, "biggest_recent_change": 0.06920753813108149},
{"total_number_of_episodes": 21963, "number_of_timesteps": 2501885, "per_episode_reward": -132.89, "episode_reward_trend_value": -0.00037935625956322385, "biggest_recent_change": 0.06920753813108149},
{"total_number_of_episodes": 21973, "number_of_timesteps": 2502867, "per_episode_reward": -132.83, "episode_reward_trend_value": 0.0007467184195746768, "biggest_recent_change": 0.06920753813108149},
{"total_number_of_episodes": 21983, "number_of_timesteps": 2504113, "per_episode_reward": -132.82, "episode_reward_trend_value": 0.0007580466123272344, "biggest_recent_change": 0.06920753813108149},
{"total_number_of_episodes": 21995, "number_of_timesteps": 2505664, "per_episode_reward": -132.73, "episode_reward_trend_value": 0.0015007945288873416, "biggest_recent_change": 0.09299421298658217},
{"total_number_of_episodes": 22005, "number_of_timesteps": 2506566, "per_episode_reward": -132.68, "episode_reward_trend_value": 0.0017603415313320486, "biggest_recent_change": 0.09299421298658217},
{"total_number_of_episodes": 22015, "number_of_timesteps": 2508124, "per_episode_reward": -132.75, "episode_reward_trend_value": 0.0009641602685405814, "biggest_recent_change": 0.09299421298658217},
{"total_number_of_episodes": 22025, "number_of_timesteps": 2509224, "per_episode_reward": -132.68, "episode_reward_trend_value": 0.0020455575803010914, "biggest_recent_change": 0.09299421298658217},
{"total_number_of_episodes": 22035, "number_of_timesteps": 2510340, "per_episode_reward": -132.76, "episode_reward_trend_value": 0.0011676728723184877, "biggest_recent_change": 0.09299421298658217},
{"total_number_of_episodes": 22045, "number_of_timesteps": 2511754, "per_episode_reward": -132.78, "episode_reward_trend_value": 0.0017181256173987296, "biggest_recent_change": 0.09299421298658217},
{"total_number_of_episodes": 22055, "number_of_timesteps": 2512943, "per_episode_reward": -132.71, "episode_reward_trend_value": 0.0019723879271017113, "biggest_recent_change": 0.09299421298658217},
{"total_number_of_episodes": 22065, "number_of_timesteps": 2514009, "per_episode_reward": -132.7, "episode_reward_trend_value": 0.0014036552544919485, "biggest_recent_change": 0.09299421298658217},
{"total_number_of_episodes": 22075, "number_of_timesteps": 2515552, "per_episode_reward": -132.7, "episode_reward_trend_value": 0.0012858707199863298, "biggest_recent_change": 0.09299421298658217},
{"total_number_of_episodes": 22085, "number_of_timesteps": 2516715, "per_episode_reward": -132.65, "episode_reward_trend_value": 0.0009001332729054765, "biggest_recent_change": 0.07772797095697115},
{"total_number_of_episodes": 22095, "number_of_timesteps": 2517857, "per_episode_reward": -132.64, "episode_reward_trend_value": 0.0004190304765460142, "biggest_recent_change": 0.07772797095697115},
{"total_number_of_episodes": 22105, "number_of_timesteps": 2519732, "per_episode_reward": -132.82, "episode_reward_trend_value": -0.0008032524668073569, "biggest_recent_change": 0.1843045992978034},
{"total_number_of_episodes": 22115, "number_of_timesteps": 2520833, "per_episode_reward": -132.84, "episode_reward_trend_value": -0.0018363659643041627, "biggest_recent_change": 0.1843045992978034},
{"total_number_of_episodes": 22125, "number_of_timesteps": 2522035, "per_episode_reward": -132.83, "episode_reward_trend_value": -0.0008214504642517619, "biggest_recent_change": 0.1843045992978034},
{"total_number_of_episodes": 22136, "number_of_timesteps": 2523584, "per_episode_reward": -132.84, "episode_reward_trend_value": -0.0007464437132676317, "biggest_recent_change": 0.1843045992978034},
{"total_number_of_episodes": 22146, "number_of_timesteps": 2524713, "per_episode_reward": -132.84, "episode_reward_trend_value": -0.0014145956370842643, "biggest_recent_change": 0.1843045992978034},
{"total_number_of_episodes": 22156, "number_of_timesteps": 2526143, "per_episode_reward": -132.81, "episode_reward_trend_value": -0.0012140159372383626, "biggest_recent_change": 0.1843045992978034},
{"total_number_of_episodes": 22166, "number_of_timesteps": 2527397, "per_episode_reward": -132.74, "episode_reward_trend_value": -0.0003739550588843738, "biggest_recent_change": 0.1843045992978034},
{"total_number_of_episodes": 22176, "number_of_timesteps": 2528114, "per_episode_reward": -132.66, "episode_reward_trend_value": -0.00018910454871116952, "biggest_recent_change": 0.1843045992978034},
{"total_number_of_episodes": 22186, "number_of_timesteps": 2528929, "per_episode_reward": -132.61, "episode_reward_trend_value": 0.00035549287240017847, "biggest_recent_change": 0.1843045992978034},
{"total_number_of_episodes": 22196, "number_of_timesteps": 2530181, "per_episode_reward": -132.63, "episode_reward_trend_value": 0.0021377742602788257, "biggest_recent_change": 0.07491438866489375},
{"total_number_of_episodes": 22206, "number_of_timesteps": 2531242, "per_episode_reward": -132.62, "episode_reward_trend_value": 0.0024886432687376706, "biggest_recent_change": 0.07491438866489375},
{"total_number_of_episodes": 22216, "number_of_timesteps": 2532456, "per_episode_reward": -132.73, "episode_reward_trend_value": 0.0011660203592867902, "biggest_recent_change": 0.10542163780283431},
{"total_number_of_episodes": 22226, "number_of_timesteps": 2533804, "per_episode_reward": -132.78, "episode_reward_trend_value": 0.0007100387467943392, "biggest_recent_change": 0.10542163780283431},
{"total_number_of_episodes": 22237, "number_of_timesteps": 2535134, "per_episode_reward": -132.92, "episode_reward_trend_value": -0.0008780395539657902, "biggest_recent_change": 0.13998480812725234},
{"total_number_of_episodes": 22247, "number_of_timesteps": 2536648, "per_episode_reward": -132.9, "episode_reward_trend_value": -0.001063802052775663, "biggest_recent_change": 0.13998480812725234},
{"total_number_of_episodes": 22257, "number_of_timesteps": 2537777, "per_episode_reward": -132.89, "episode_reward_trend_value": -0.0016444942053712767, "biggest_recent_change": 0.13998480812725234},
{"total_number_of_episodes": 22267, "number_of_timesteps": 2538680, "per_episode_reward": -132.89, "episode_reward_trend_value": -0.002540897293181388, "biggest_recent_change": 0.13998480812725234},
{"total_number_of_episodes": 22278, "number_of_timesteps": 2539892, "per_episode_reward": -132.87, "episode_reward_trend_value": -0.0029145318697974035, "biggest_recent_change": 0.13998480812725234},
{"total_number_of_episodes": 22288, "number_of_timesteps": 2541056, "per_episode_reward": -132.89, "episode_reward_trend_value": -0.0028338144837521087, "biggest_recent_change": 0.13998480812725234},
{"total_number_of_episodes": 22299, "number_of_timesteps": 2542075, "per_episode_reward": -132.87, "episode_reward_trend_value": -0.002755978681506753, "biggest_recent_change": 0.13998480812725234},
{"total_number_of_episodes": 22309, "number_of_timesteps": 2542971, "per_episode_reward": -132.86, "episode_reward_trend_value": -0.0015368548154542495, "biggest_recent_change": 0.13998480812725234},
{"total_number_of_episodes": 22319, "number_of_timesteps": 2544120, "per_episode_reward": -132.88, "episode_reward_trend_value": -0.0010632218656408238, "biggest_recent_change": 0.13998480812725234},
{"total_number_of_episodes": 22330, "number_of_timesteps": 2545322, "per_episode_reward": -132.88, "episode_reward_trend_value": 0.00045462951836567657, "biggest_recent_change": 0.02245433973266131},
{"total_number_of_episodes": 22340, "number_of_timesteps": 2546307, "per_episode_reward": -132.87, "episode_reward_trend_value": 0.000360356434799769, "biggest_recent_change": 0.02245433973266131},
{"total_number_of_episodes": 22350, "number_of_timesteps": 2547220, "per_episode_reward": -132.87, "episode_reward_trend_value": 0.00011847119599729517, "biggest_recent_change": 0.02245433973266131},
{"total_number_of_episodes": 22360, "number_of_timesteps": 2548079, "per_episode_reward": -132.85, "episode_reward_trend_value": 0.000446058623727039, "biggest_recent_change": 0.0237209792576607},
{"total_number_of_episodes": 22370, "number_of_timesteps": 2548887, "per_episode_reward": -132.8, "episode_reward_trend_value": 0.0007617795343031099, "biggest_recent_change": 0.05086922168450769},
{"total_number_of_episodes": 22380, "number_of_timesteps": 2549749, "per_episode_reward": -132.78, "episode_reward_trend_value": 0.001132555313982506, "biggest_recent_change": 0.05086922168450769},
{"total_number_of_episodes": 22391, "number_of_timesteps": 2550798, "per_episode_reward": -132.75, "episode_reward_trend_value": 0.0012631041400766208, "biggest_recent_change": 0.05086922168450769},
{"total_number_of_episodes": 22401, "number_of_timesteps": 2551744, "per_episode_reward": -132.79, "episode_reward_trend_value": 0.0008127283035232975, "biggest_recent_change": 0.05086922168450769},
{"total_number_of_episodes": 22411, "number_of_timesteps": 2552800, "per_episode_reward": -132.83, "episode_reward_trend_value": 0.00050170962302079, "biggest_recent_change": 0.05086922168450769},
{"total_number_of_episodes": 22421, "number_of_timesteps": 2554226, "per_episode_reward": -132.83, "episode_reward_trend_value": 0.0005317705965391421, "biggest_recent_change": 0.05086922168450769},
{"total_number_of_episodes": 22432, "number_of_timesteps": 2555765, "per_episode_reward": -132.83, "episode_reward_trend_value": 0.0004366175050803476, "biggest_recent_change": 0.05086922168450769},
{"total_number_of_episodes": 22442, "number_of_timesteps": 2556813, "per_episode_reward": -132.82, "episode_reward_trend_value": 0.000572019623977048, "biggest_recent_change": 0.05086922168450769},
{"total_number_of_episodes": 22452, "number_of_timesteps": 2558388, "per_episode_reward": -132.79, "episode_reward_trend_value": 0.0006433018575516295, "biggest_recent_change": 0.05086922168450769},
{"total_number_of_episodes": 22462, "number_of_timesteps": 2559420, "per_episode_reward": -132.78, "episode_reward_trend_value": 0.00026556093466499283, "biggest_recent_change": 0.03931924437162593},
{"total_number_of_episodes": 22472, "number_of_timesteps": 2560374, "per_episode_reward": -132.75, "episode_reward_trend_value": 0.0003355058524359972, "biggest_recent_change": 0.03931924437162593},
{"total_number_of_episodes": 22482, "number_of_timesteps": 2561833, "per_episode_reward": -132.78, "episode_reward_trend_value": -0.00023235935866365606, "biggest_recent_change": 0.03931924437162593},
{"total_number_of_episodes": 22492, "number_of_timesteps": 2563218, "per_episode_reward": -132.77, "episode_reward_trend_value": 0.0002768472092968624, "biggest_recent_change": 0.03931924437162593},
{"total_number_of_episodes": 22503, "number_of_timesteps": 2564480, "per_episode_reward": -132.8, "episode_reward_trend_value": 0.0003183581031085699, "biggest_recent_change": 0.03558326392857225},
{"total_number_of_episodes": 22513, "number_of_timesteps": 2565687, "per_episode_reward": -132.84, "episode_reward_trend_value": -0.00010244677701633817, "biggest_recent_change": 0.03854513516125735},
{"total_number_of_episodes": 22524, "number_of_timesteps": 2566939, "per_episode_reward": -132.83, "episode_reward_trend_value": -1.5058197605968517e-05, "biggest_recent_change": 0.03854513516125735},
{"total_number_of_episodes": 22534, "number_of_timesteps": 2568067, "per_episode_reward": -132.83, "episode_reward_trend_value": -5.457495436537051e-05, "biggest_recent_change": 0.03854513516125735},
{"total_number_of_episodes": 22545, "number_of_timesteps": 2569779, "per_episode_reward": -132.83, "episode_reward_trend_value": -0.00045810991805126375, "biggest_recent_change": 0.03854513516125735},
{"total_number_of_episodes": 22555, "number_of_timesteps": 2570704, "per_episode_reward": -132.81, "episode_reward_trend_value": -0.000346018546531468, "biggest_recent_change": 0.03854513516125735},
{"total_number_of_episodes": 22565, "number_of_timesteps": 2571647, "per_episode_reward": -132.81, "episode_reward_trend_value": -0.0006719738840028337, "biggest_recent_change": 0.03854513516125735},
{"total_number_of_episodes": 22575, "number_of_timesteps": 2572918, "per_episode_reward": -132.8, "episode_reward_trend_value": -0.0003138488806563878, "biggest_recent_change": 0.03854513516125735},
{"total_number_of_episodes": 22585, "number_of_timesteps": 2573834, "per_episode_reward": -132.76, "episode_reward_trend_value": 5.7168390102270276e-05, "biggest_recent_change": 0.0429858303368178},
{"total_number_of_episodes": 22596, "number_of_timesteps": 2575122, "per_episode_reward": -132.79, "episode_reward_trend_value": 0.00017046410499688136, "biggest_recent_change": 0.0429858303368178},
{"total_number_of_episodes": 22606, "number_of_timesteps": 2576488, "per_episode_reward": -132.82, "episode_reward_trend_value": 0.0002392903045615766, "biggest_recent_change": 0.0429858303368178},
{"total_number_of_episodes": 22616, "number_of_timesteps": 2577404, "per_episode_reward": -132.78, "episode_reward_trend_value": 0.0005699115067683478, "biggest_recent_change": 0.0429858303368178},
{"total_number_of_episodes": 22626, "number_of_timesteps": 2578710, "per_episode_reward": -132.84, "episode_reward_trend_value": -0.0001644455389513016, "biggest_recent_change": 0.060142519501113156},
{"total_number_of_episodes": 22636, "number_of_timesteps": 2579676, "per_episode_reward": -132.83, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.060142519501113156},
{"total_number_of_episodes": 22646, "number_of_timesteps": 2580663, "per_episode_reward": -132.82, "episode_reward_trend_value": -0.0001841251584102742, "biggest_recent_change": 0.060142519501113156},
{"total_number_of_episodes": 22656, "number_of_timesteps": 2581975, "per_episode_reward": -132.83, "episode_reward_trend_value": -0.00023165789651437128, "biggest_recent_change": 0.060142519501113156},
{"total_number_of_episodes": 22666, "number_of_timesteps": 2583849, "per_episode_reward": -132.81, "episode_reward_trend_value": -0.0001088899591144986, "biggest_recent_change": 0.060142519501113156},
{"total_number_of_episodes": 22677, "number_of_timesteps": 2585076, "per_episode_reward": -132.81, "episode_reward_trend_value": -0.0004938401717822672, "biggest_recent_change": 0.060142519501113156},
{"total_number_of_episodes": 22687, "number_of_timesteps": 2586234, "per_episode_reward": -132.78, "episode_reward_trend_value": 3.593907772641261e-05, "biggest_recent_change": 0.060142519501113156},
{"total_number_of_episodes": 22697, "number_of_timesteps": 2587761, "per_episode_reward": -132.81, "episode_reward_trend_value": 0.00014217949139031639, "biggest_recent_change": 0.060142519501113156},
{"total_number_of_episodes": 22707, "number_of_timesteps": 2589027, "per_episode_reward": -132.84, "episode_reward_trend_value": -0.00066903943766887, "biggest_recent_change": 0.060142519501113156},
{"total_number_of_episodes": 22717, "number_of_timesteps": 2590355, "per_episode_reward": -132.9, "episode_reward_trend_value": -0.0006406826309636749, "biggest_recent_change": 0.05759040689764561},
{"total_number_of_episodes": 22727, "number_of_timesteps": 2591535, "per_episode_reward": -132.94, "episode_reward_trend_value": -0.0011295479960886545, "biggest_recent_change": 0.05759040689764561},
{"total_number_of_episodes": 22737, "number_of_timesteps": 2593005, "per_episode_reward": -132.93, "episode_reward_trend_value": -0.001199042338967931, "biggest_recent_change": 0.05759040689764561},
{"total_number_of_episodes": 22747, "number_of_timesteps": 2594030, "per_episode_reward": -132.93, "episode_reward_trend_value": -0.0010908896426049827, "biggest_recent_change": 0.05759040689764561},
{"total_number_of_episodes": 22757, "number_of_timesteps": 2594933, "per_episode_reward": -132.92, "episode_reward_trend_value": -0.0011320032672314383, "biggest_recent_change": 0.05759040689764561},
{"total_number_of_episodes": 22767, "number_of_timesteps": 2595744, "per_episode_reward": -132.86, "episode_reward_trend_value": -0.0005758677888429197, "biggest_recent_change": 0.058392504251685295},
{"total_number_of_episodes": 22778, "number_of_timesteps": 2596993, "per_episode_reward": -132.85, "episode_reward_trend_value": -0.000762445348141859, "biggest_recent_change": 0.058392504251685295},
{"total_number_of_episodes": 22788, "number_of_timesteps": 2598151, "per_episode_reward": -132.82, "episode_reward_trend_value": -0.00012439025867807787, "biggest_recent_change": 0.058392504251685295},
{"total_number_of_episodes": 22798, "number_of_timesteps": 2599200, "per_episode_reward": -132.8, "episode_reward_trend_value": 0.0004719720575963038, "biggest_recent_change": 0.058392504251685295},
{"total_number_of_episodes": 22810, "number_of_timesteps": 2600466, "per_episode_reward": -132.79, "episode_reward_trend_value": 0.0012081882726413873, "biggest_recent_change": 0.058392504251685295},
{"total_number_of_episodes": 22820, "number_of_timesteps": 2601578, "per_episode_reward": -132.77, "episode_reward_trend_value": 0.0018504122104568903, "biggest_recent_change": 0.058392504251685295},
{"total_number_of_episodes": 22830, "number_of_timesteps": 2603533, "per_episode_reward": -132.81, "episode_reward_trend_value": 0.0013396256655009134, "biggest_recent_change": 0.058392504251685295},
{"total_number_of_episodes": 22840, "number_of_timesteps": 2604456, "per_episode_reward": -132.79, "episode_reward_trend_value": 0.0016337290972311773, "biggest_recent_change": 0.058392504251685295},
{"total_number_of_episodes": 22850, "number_of_timesteps": 2605565, "per_episode_reward": -132.74, "episode_reward_trend_value": 0.002004550767093052, "biggest_recent_change": 0.058392504251685295},
{"total_number_of_episodes": 22860, "number_of_timesteps": 2607021, "per_episode_reward": -132.73, "episode_reward_trend_value": 0.001390509926078999, "biggest_recent_change": 0.050442577848997416},
{"total_number_of_episodes": 22870, "number_of_timesteps": 2608039, "per_episode_reward": -132.72, "episode_reward_trend_value": 0.0014638243570854255, "biggest_recent_change": 0.050442577848997416},
{"total_number_of_episodes": 22880, "number_of_timesteps": 2608950, "per_episode_reward": -132.71, "episode_reward_trend_value": 0.0011862706788557868, "biggest_recent_change": 0.050442577848997416},
{"total_number_of_episodes": 22890, "number_of_timesteps": 2609908, "per_episode_reward": -132.58, "episode_reward_trend_value": 0.002445674584803707, "biggest_recent_change": 0.12991036605743034},
{"total_number_of_episodes": 22900, "number_of_timesteps": 2610939, "per_episode_reward": -132.53, "episode_reward_trend_value": 0.0029385059558203848, "biggest_recent_change": 0.12991036605743034},
{"total_number_of_episodes": 22910, "number_of_timesteps": 2612034, "per_episode_reward": -132.55, "episode_reward_trend_value": 0.0024346337192503774, "biggest_recent_change": 0.12991036605743034},
{"total_number_of_episodes": 22920, "number_of_timesteps": 2613038, "per_episode_reward": -132.53, "episode_reward_trend_value": 0.003084763505613195, "biggest_recent_change": 0.12991036605743034},
{"total_number_of_episodes": 22930, "number_of_timesteps": 2614284, "per_episode_reward": -132.59, "episode_reward_trend_value": 0.002194031267053889, "biggest_recent_change": 0.12991036605743034},
{"total_number_of_episodes": 22940, "number_of_timesteps": 2615434, "per_episode_reward": -132.61, "episode_reward_trend_value": 0.001368681790476166, "biggest_recent_change": 0.12991036605743034},
{"total_number_of_episodes": 22951, "number_of_timesteps": 2616526, "per_episode_reward": -132.58, "episode_reward_trend_value": 0.0016468730947912665, "biggest_recent_change": 0.12991036605743034},
{"total_number_of_episodes": 22961, "number_of_timesteps": 2617977, "per_episode_reward": -132.63, "episode_reward_trend_value": 0.0010272887037842792, "biggest_recent_change": 0.12991036605743034},
{"total_number_of_episodes": 22972, "number_of_timesteps": 2619282, "per_episode_reward": -132.63, "episode_reward_trend_value": 0.0008904294086647724, "biggest_recent_change": 0.12991036605743034},
{"total_number_of_episodes": 22982, "number_of_timesteps": 2620571, "per_episode_reward": -132.68, "episode_reward_trend_value": -0.001052146280007883, "biggest_recent_change": 0.054546623617852674},
{"total_number_of_episodes": 22992, "number_of_timesteps": 2621818, "per_episode_reward": -132.66, "episode_reward_trend_value": -0.0014744558166278744, "biggest_recent_change": 0.054546623617852674},
{"total_number_of_episodes": 23002, "number_of_timesteps": 2622953, "per_episode_reward": -132.62, "episode_reward_trend_value": -0.0007725446733998196, "biggest_recent_change": 0.054546623617852674},
{"total_number_of_episodes": 23012, "number_of_timesteps": 2624075, "per_episode_reward": -132.61, "episode_reward_trend_value": -0.0007987389739320684, "biggest_recent_change": 0.054546623617852674},
{"total_number_of_episodes": 23023, "number_of_timesteps": 2625559, "per_episode_reward": -132.58, "episode_reward_trend_value": 0.0001373383931855364, "biggest_recent_change": 0.04492144592310865},
{"total_number_of_episodes": 23033, "number_of_timesteps": 2626566, "per_episode_reward": -132.58, "episode_reward_trend_value": 0.00039050548226037386, "biggest_recent_change": 0.04492144592310865},
{"total_number_of_episodes": 23044, "number_of_timesteps": 2627750, "per_episode_reward": -132.56, "episode_reward_trend_value": 0.00022006271053195782, "biggest_recent_change": 0.04492144592310865},
{"total_number_of_episodes": 23054, "number_of_timesteps": 2628669, "per_episode_reward": -132.55, "episode_reward_trend_value": 0.0008993290441986169, "biggest_recent_change": 0.04492144592310865},
{"total_number_of_episodes": 23064, "number_of_timesteps": 2629890, "per_episode_reward": -132.58, "episode_reward_trend_value": 0.0005399839933791857, "biggest_recent_change": 0.04492144592310865},
{"total_number_of_episodes": 23074, "number_of_timesteps": 2631036, "per_episode_reward": -132.58, "episode_reward_trend_value": 0.001108783401091134, "biggest_recent_change": 0.040244105194631175},
{"total_number_of_episodes": 23084, "number_of_timesteps": 2632147, "per_episode_reward": -132.54, "episode_reward_trend_value": 0.001294499345432756, "biggest_recent_change": 0.040244105194631175},
{"total_number_of_episodes": 23094, "number_of_timesteps": 2633237, "per_episode_reward": -132.58, "episode_reward_trend_value": 0.0003929639786207417, "biggest_recent_change": 0.040894077818450114},
{"total_number_of_episodes": 23104, "number_of_timesteps": 2634544, "per_episode_reward": -132.59, "episode_reward_trend_value": 0.00013402736935069645, "biggest_recent_change": 0.040894077818450114},
{"total_number_of_episodes": 23118, "number_of_timesteps": 2635913, "per_episode_reward": -132.58, "episode_reward_trend_value": -6.59944873041872e-05, "biggest_recent_change": 0.040894077818450114},
{"total_number_of_episodes": 23129, "number_of_timesteps": 2636885, "per_episode_reward": -132.56, "episode_reward_trend_value": 0.00019764708559743361, "biggest_recent_change": 0.040894077818450114},
{"total_number_of_episodes": 23139, "number_of_timesteps": 2637696, "per_episode_reward": -132.53, "episode_reward_trend_value": 0.00043043452738894913, "biggest_recent_change": 0.040894077818450114},
{"total_number_of_episodes": 23150, "number_of_timesteps": 2638806, "per_episode_reward": -132.52, "episode_reward_trend_value": 0.0002836821270670321, "biggest_recent_change": 0.040894077818450114},
{"total_number_of_episodes": 23160, "number_of_timesteps": 2640161, "per_episode_reward": -132.53, "episode_reward_trend_value": 0.0005382629407910776, "biggest_recent_change": 0.040894077818450114},
{"total_number_of_episodes": 23170, "number_of_timesteps": 2641484, "per_episode_reward": -132.55, "episode_reward_trend_value": 0.00030764794799564594, "biggest_recent_change": 0.040894077818450114},
{"total_number_of_episodes": 23180, "number_of_timesteps": 2642535, "per_episode_reward": -132.53, "episode_reward_trend_value": 0.00012189855717110731, "biggest_recent_change": 0.040894077818450114},
{"total_number_of_episodes": 23191, "number_of_timesteps": 2644094, "per_episode_reward": -132.54, "episode_reward_trend_value": 0.0005253713262975326, "biggest_recent_change": 0.03377706625445853},
{"total_number_of_episodes": 23204, "number_of_timesteps": 2645404, "per_episode_reward": -132.48, "episode_reward_trend_value": 0.0012463861807399705, "biggest_recent_change": 0.055905453689661044},
{"total_number_of_episodes": 23214, "number_of_timesteps": 2646273, "per_episode_reward": -132.45, "episode_reward_trend_value": 0.0014121470065532548, "biggest_recent_change": 0.055905453689661044},
{"total_number_of_episodes": 23224, "number_of_timesteps": 2647279, "per_episode_reward": -132.42, "episode_reward_trend_value": 0.0015431243359984137, "biggest_recent_change": 0.055905453689661044},
{"total_number_of_episodes": 23234, "number_of_timesteps": 2648571, "per_episode_reward": -132.38, "episode_reward_trend_value": 0.0015696027410383648, "biggest_recent_change": 0.055905453689661044},
{"total_number_of_episodes": 23245, "number_of_timesteps": 2650155, "per_episode_reward": -132.41, "episode_reward_trend_value": 0.0012789874518063017, "biggest_recent_change": 0.055905453689661044},
{"total_number_of_episodes": 23255, "number_of_timesteps": 2651421, "per_episode_reward": -132.39, "episode_reward_trend_value": 0.0015445135242117658, "biggest_recent_change": 0.055905453689661044},
{"total_number_of_episodes": 23265, "number_of_timesteps": 2653193, "per_episode_reward": -132.42, "episode_reward_trend_value": 0.001403480736498371, "biggest_recent_change": 0.055905453689661044},
{"total_number_of_episodes": 23275, "number_of_timesteps": 2654356, "per_episode_reward": -132.4, "episode_reward_trend_value": 0.0014243225328925747, "biggest_recent_change": 0.055905453689661044},
{"total_number_of_episodes": 23286, "number_of_timesteps": 2655517, "per_episode_reward": -132.4, "episode_reward_trend_value": 0.0015459630571168898, "biggest_recent_change": 0.055905453689661044},
{"total_number_of_episodes": 23296, "number_of_timesteps": 2656346, "per_episode_reward": -132.33, "episode_reward_trend_value": 0.00165922725500612, "biggest_recent_change": 0.06609923149969177},
{"total_number_of_episodes": 23306, "number_of_timesteps": 2657300, "per_episode_reward": -132.25, "episode_reward_trend_value": 0.0022811658268782112, "biggest_recent_change": 0.08259131811547604},
{"total_number_of_episodes": 23316, "number_of_timesteps": 2658462, "per_episode_reward": -132.26, "episode_reward_trend_value": 0.0017332271367343486, "biggest_recent_change": 0.08259131811547604},
{"total_number_of_episodes": 23327, "number_of_timesteps": 2659679, "per_episode_reward": -132.33, "episode_reward_trend_value": 0.000549618403963829, "biggest_recent_change": 0.08259131811547604},
{"total_number_of_episodes": 23337, "number_of_timesteps": 2661145, "per_episode_reward": -132.28, "episode_reward_trend_value": 0.00143145592769574, "biggest_recent_change": 0.08259131811547604},
{"total_number_of_episodes": 23347, "number_of_timesteps": 2662259, "per_episode_reward": -132.26, "episode_reward_trend_value": 0.0014378805780580705, "biggest_recent_change": 0.08259131811547604},
{"total_number_of_episodes": 23358, "number_of_timesteps": 2663447, "per_episode_reward": -132.26, "episode_reward_trend_value": 0.0017880641285128404, "biggest_recent_change": 0.08259131811547604},
{"total_number_of_episodes": 23368, "number_of_timesteps": 2664732, "per_episode_reward": -132.32, "episode_reward_trend_value": 0.0009400349006420406, "biggest_recent_change": 0.08259131811547604},
{"total_number_of_episodes": 23378, "number_of_timesteps": 2665966, "per_episode_reward": -132.27, "episode_reward_trend_value": 0.00142645420436496, "biggest_recent_change": 0.08259131811547604},
{"total_number_of_episodes": 23388, "number_of_timesteps": 2666910, "per_episode_reward": -132.23, "episode_reward_trend_value": 0.001159803871048363, "biggest_recent_change": 0.08259131811547604},
{"total_number_of_episodes": 23398, "number_of_timesteps": 2667964, "per_episode_reward": -132.24, "episode_reward_trend_value": 0.000155500410957643, "biggest_recent_change": 0.07036466324129265},
{"total_number_of_episodes": 23408, "number_of_timesteps": 2669420, "per_episode_reward": -132.25, "episode_reward_trend_value": 0.00016502908808888606, "biggest_recent_change": 0.07036466324129265},
{"total_number_of_episodes": 23418, "number_of_timesteps": 2670924, "per_episode_reward": -132.27, "episode_reward_trend_value": 0.0006868020144764842, "biggest_recent_change": 0.059433861464242455},
{"total_number_of_episodes": 23428, "number_of_timesteps": 2672565, "per_episode_reward": -132.36, "episode_reward_trend_value": -0.0009440232616261332, "biggest_recent_change": 0.08930081361245357},
{"total_number_of_episodes": 23438, "number_of_timesteps": 2673826, "per_episode_reward": -132.45, "episode_reward_trend_value": -0.002014068571350612, "biggest_recent_change": 0.08930081361245357},
{"total_number_of_episodes": 23448, "number_of_timesteps": 2675078, "per_episode_reward": -132.44, "episode_reward_trend_value": -0.002046672533109965, "biggest_recent_change": 0.08930081361245357},
{"total_number_of_episodes": 23458, "number_of_timesteps": 2676322, "per_episode_reward": -132.48, "episode_reward_trend_value": -0.0017536097193622407, "biggest_recent_change": 0.08930081361245357},
{"total_number_of_episodes": 23469, "number_of_timesteps": 2677717, "per_episode_reward": -132.43, "episode_reward_trend_value": -0.0017800197927180586, "biggest_recent_change": 0.08930081361245357},
{"total_number_of_episodes": 23479, "number_of_timesteps": 2678688, "per_episode_reward": -132.4, "episode_reward_trend_value": -0.0019627062705423115, "biggest_recent_change": 0.08930081361245357},
{"total_number_of_episodes": 23489, "number_of_timesteps": 2679952, "per_episode_reward": -132.45, "episode_reward_trend_value": -0.0023767361467185487, "biggest_recent_change": 0.08930081361245357},
{"total_number_of_episodes": 23499, "number_of_timesteps": 2681016, "per_episode_reward": -132.41, "episode_reward_trend_value": -0.0017866905409287409, "biggest_recent_change": 0.08930081361245357},
{"total_number_of_episodes": 23509, "number_of_timesteps": 2682667, "per_episode_reward": -132.44, "episode_reward_trend_value": -0.0018613375786167632, "biggest_recent_change": 0.08930081361245357},
{"total_number_of_episodes": 23519, "number_of_timesteps": 2684287, "per_episode_reward": -132.45, "episode_reward_trend_value": -0.0009484324895620629, "biggest_recent_change": 0.08391864368505253},
{"total_number_of_episodes": 23529, "number_of_timesteps": 2685429, "per_episode_reward": -132.43, "episode_reward_trend_value": 0.0001416806220384438, "biggest_recent_change": 0.04776694931615566},
{"total_number_of_episodes": 23539, "number_of_timesteps": 2686403, "per_episode_reward": -132.35, "episode_reward_trend_value": 0.0010814885778523198, "biggest_recent_change": 0.0859870795310087},
{"total_number_of_episodes": 23549, "number_of_timesteps": 2687687, "per_episode_reward": -132.38, "episode_reward_trend_value": 0.001110332722316798, "biggest_recent_change": 0.0859870795310087},
{"total_number_of_episodes": 23559, "number_of_timesteps": 2688839, "per_episode_reward": -132.39, "episode_reward_trend_value": 0.0004251254377436453, "biggest_recent_change": 0.0859870795310087},
{"total_number_of_episodes": 23569, "number_of_timesteps": 2689994, "per_episode_reward": -132.39, "episode_reward_trend_value": 0.00018333741718063517, "biggest_recent_change": 0.0859870795310087},
{"total_number_of_episodes": 23579, "number_of_timesteps": 2691298, "per_episode_reward": -132.41, "episode_reward_trend_value": 0.00038361495028595984, "biggest_recent_change": 0.0859870795310087},
{"total_number_of_episodes": 23589, "number_of_timesteps": 2692908, "per_episode_reward": -132.36, "episode_reward_trend_value": 0.0006115273489503655, "biggest_recent_change": 0.0859870795310087},
{"total_number_of_episodes": 23599, "number_of_timesteps": 2694178, "per_episode_reward": -132.43, "episode_reward_trend_value": 0.00013646857723238604, "biggest_recent_change": 0.0859870795310087},
{"total_number_of_episodes": 23610, "number_of_timesteps": 2695584, "per_episode_reward": -132.39, "episode_reward_trend_value": 0.0006441740658857497, "biggest_recent_change": 0.0859870795310087},
{"total_number_of_episodes": 23620, "number_of_timesteps": 2696813, "per_episode_reward": -132.4, "episode_reward_trend_value": 0.00032305987201652897, "biggest_recent_change": 0.0859870795310087},
{"total_number_of_episodes": 23630, "number_of_timesteps": 2698342, "per_episode_reward": -132.43, "episode_reward_trend_value": -0.0009275858869630029, "biggest_recent_change": 0.07287862271294898},
{"total_number_of_episodes": 23640, "number_of_timesteps": 2699597, "per_episode_reward": -132.43, "episode_reward_trend_value": -0.000534237661731317, "biggest_recent_change": 0.07287862271294898},
{"total_number_of_episodes": 23651, "number_of_timesteps": 2701088, "per_episode_reward": -132.41, "episode_reward_trend_value": -0.00023211949121086187, "biggest_recent_change": 0.07287862271294898},
{"total_number_of_episodes": 23661, "number_of_timesteps": 2702360, "per_episode_reward": -132.46, "episode_reward_trend_value": -0.0008202390546510211, "biggest_recent_change": 0.07287862271294898},
{"total_number_of_episodes": 23671, "number_of_timesteps": 2703500, "per_episode_reward": -132.55, "episode_reward_trend_value": -0.00150501691671631, "biggest_recent_change": 0.08866371175494692},

{"total_number_of_episodes": 23682, "number_of_timesteps": 2704320, "per_episode_reward": -132.52, "episode_reward_trend_value": -0.0018253115265432977, "biggest_recent_change": 0.08866371175494692},
{"total_number_of_episodes": 23694, "number_of_timesteps": 2705315, "per_episode_reward": -132.46, "episode_reward_trend_value": -0.00033316875037914744, "biggest_recent_change": 0.08866371175494692},
{"total_number_of_episodes": 23705, "number_of_timesteps": 2706310, "per_episode_reward": -132.42, "episode_reward_trend_value": -0.00031583837884423044, "biggest_recent_change": 0.08866371175494692},
{"total_number_of_episodes": 23715, "number_of_timesteps": 2707231, "per_episode_reward": -132.4, "episode_reward_trend_value": 7.005693117952836e-05, "biggest_recent_change": 0.08866371175494692},
{"total_number_of_episodes": 23725, "number_of_timesteps": 2708311, "per_episode_reward": -132.4, "episode_reward_trend_value": 0.0002991176347980703, "biggest_recent_change": 0.08866371175494692},
{"total_number_of_episodes": 23736, "number_of_timesteps": 2709291, "per_episode_reward": -132.38, "episode_reward_trend_value": 0.0005037691594449395, "biggest_recent_change": 0.08866371175494692},
{"total_number_of_episodes": 23746, "number_of_timesteps": 2710382, "per_episode_reward": -132.38, "episode_reward_trend_value": 0.0003266901060641203, "biggest_recent_change": 0.08866371175494692},
{"total_number_of_episodes": 23756, "number_of_timesteps": 2711427, "per_episode_reward": -132.35, "episode_reward_trend_value": 0.0012438549527723176, "biggest_recent_change": 0.08866371175494692},
{"total_number_of_episodes": 23766, "number_of_timesteps": 2712299, "per_episode_reward": -132.31, "episode_reward_trend_value": 0.002679944368146418, "biggest_recent_change": 0.06141422714182454},
{"total_number_of_episodes": 23776, "number_of_timesteps": 2713365, "per_episode_reward": -132.27, "episode_reward_trend_value": 0.002732831612397351, "biggest_recent_change": 0.06141422714182454},
{"total_number_of_episodes": 23786, "number_of_timesteps": 2714531, "per_episode_reward": -132.24, "episode_reward_trend_value": 0.0024439258575635375, "biggest_recent_change": 0.0405843356287221},
{"total_number_of_episodes": 23797, "number_of_timesteps": 2715718, "per_episode_reward": -132.22, "episode_reward_trend_value": 0.0021566959332479504, "biggest_recent_change": 0.0405843356287221},
{"total_number_of_episodes": 23807, "number_of_timesteps": 2716800, "per_episode_reward": -132.25, "episode_reward_trend_value": 0.0016562863246731593, "biggest_recent_change": 0.0405843356287221},
{"total_number_of_episodes": 23817, "number_of_timesteps": 2717868, "per_episode_reward": -132.23, "episode_reward_trend_value": 0.0019201562414906449, "biggest_recent_change": 0.0405843356287221},
{"total_number_of_episodes": 23828, "number_of_timesteps": 2719098, "per_episode_reward": -132.27, "episode_reward_trend_value": 0.0011730091500387137, "biggest_recent_change": 0.04388549596674807},
{"total_number_of_episodes": 23838, "number_of_timesteps": 2720012, "per_episode_reward": -132.28, "episode_reward_trend_value": 0.0011338133275229565, "biggest_recent_change": 0.04388549596674807},
{"total_number_of_episodes": 23848, "number_of_timesteps": 2721204, "per_episode_reward": -132.27, "episode_reward_trend_value": 0.0009359110579866738, "biggest_recent_change": 0.04388549596674807},
{"total_number_of_episodes": 23858, "number_of_timesteps": 2722698, "per_episode_reward": -132.28, "episode_reward_trend_value": 0.0003386337052230854, "biggest_recent_change": 0.04388549596674807},
{"total_number_of_episodes": 23869, "number_of_timesteps": 2723888, "per_episode_reward": -132.26, "episode_reward_trend_value": 0.00014628655409454596, "biggest_recent_change": 0.04388549596674807},
{"total_number_of_episodes": 23879, "number_of_timesteps": 2725277, "per_episode_reward": -132.26, "episode_reward_trend_value": -0.00021308254517009572, "biggest_recent_change": 0.04388549596674807},
{"total_number_of_episodes": 23889, "number_of_timesteps": 2726239, "per_episode_reward": -132.25, "episode_reward_trend_value": -0.00032911087953664265, "biggest_recent_change": 0.04388549596674807},
{"total_number_of_episodes": 23899, "number_of_timesteps": 2727295, "per_episode_reward": -132.28, "episode_reward_trend_value": -0.00032499101918119776, "biggest_recent_change": 0.04388549596674807},
{"total_number_of_episodes": 23910, "number_of_timesteps": 2729417, "per_episode_reward": -132.3, "episode_reward_trend_value": -0.0007609273863816194, "biggest_recent_change": 0.04388549596674807},
{"total_number_of_episodes": 23920, "number_of_timesteps": 2730438, "per_episode_reward": -132.3, "episode_reward_trend_value": -0.0003073703500604097, "biggest_recent_change": 0.024644240526839667},
{"total_number_of_episodes": 23932, "number_of_timesteps": 2731971, "per_episode_reward": -132.39, "episode_reward_trend_value": -0.0011573878456949337, "biggest_recent_change": 0.08267738438638617},
{"total_number_of_episodes": 23942, "number_of_timesteps": 2733100, "per_episode_reward": -132.36, "episode_reward_trend_value": -0.0010593293154679865, "biggest_recent_change": 0.08267738438638617},
{"total_number_of_episodes": 23952, "number_of_timesteps": 2734042, "per_episode_reward": -132.35, "episode_reward_trend_value": -0.0008437601993888519, "biggest_recent_change": 0.08267738438638617},
{"total_number_of_episodes": 23962, "number_of_timesteps": 2735041, "per_episode_reward": -132.35, "episode_reward_trend_value": -0.0009973853349811812, "biggest_recent_change": 0.08267738438638617},
{"total_number_of_episodes": 23972, "number_of_timesteps": 2736282, "per_episode_reward": -132.38, "episode_reward_trend_value": -0.0013663988047890522, "biggest_recent_change": 0.08267738438638617},
{"total_number_of_episodes": 23982, "number_of_timesteps": 2737338, "per_episode_reward": -132.39, "episode_reward_trend_value": -0.0015517611038960567, "biggest_recent_change": 0.08267738438638617},
{"total_number_of_episodes": 23992, "number_of_timesteps": 2738362, "per_episode_reward": -132.39, "episode_reward_trend_value": -0.0012590262394035613, "biggest_recent_change": 0.08267738438638617},
{"total_number_of_episodes": 24004, "number_of_timesteps": 2739772, "per_episode_reward": -132.35, "episode_reward_trend_value": -0.0005764943620287492, "biggest_recent_change": 0.08267738438638617},
{"total_number_of_episodes": 24014, "number_of_timesteps": 2740789, "per_episode_reward": -132.37, "episode_reward_trend_value": -0.0007841277335431743, "biggest_recent_change": 0.08267738438638617},
{"total_number_of_episodes": 24024, "number_of_timesteps": 2742051, "per_episode_reward": -132.38, "episode_reward_trend_value": 3.746967606414526e-05, "biggest_recent_change": 0.03998631297778843},
{"total_number_of_episodes": 24035, "number_of_timesteps": 2743181, "per_episode_reward": -132.36, "episode_reward_trend_value": 5.111152828571145e-05, "biggest_recent_change": 0.03998631297778843},
{"total_number_of_episodes": 24045, "number_of_timesteps": 2744240, "per_episode_reward": -132.37, "episode_reward_trend_value": -0.00020468058098812333, "biggest_recent_change": 0.03998631297778843},
{"total_number_of_episodes": 24055, "number_of_timesteps": 2745476, "per_episode_reward": -132.38, "episode_reward_trend_value": -0.00030460560064998136, "biggest_recent_change": 0.03998631297778843},
{"total_number_of_episodes": 24065, "number_of_timesteps": 2746762, "per_episode_reward": -132.37, "episode_reward_trend_value": 0.0001559421197770108, "biggest_recent_change": 0.03998631297778843},
{"total_number_of_episodes": 24075, "number_of_timesteps": 2747897, "per_episode_reward": -132.35, "episode_reward_trend_value": 0.0005248837815467293, "biggest_recent_change": 0.03998631297778843},
{"total_number_of_episodes": 24085, "number_of_timesteps": 2749130, "per_episode_reward": -132.35, "episode_reward_trend_value": 0.00042154534943234824, "biggest_recent_change": 0.03998631297778843},
{"total_number_of_episodes": 24095, "number_of_timesteps": 2750295, "per_episode_reward": -132.36, "episode_reward_trend_value": -7.047924336297405e-05, "biggest_recent_change": 0.025753902302568576},
{"total_number_of_episodes": 24105, "number_of_timesteps": 2751480, "per_episode_reward": -132.37, "episode_reward_trend_value": 8.501503070748287e-05, "biggest_recent_change": 0.025753902302568576},
{"total_number_of_episodes": 24115, "number_of_timesteps": 2752491, "per_episode_reward": -132.35, "episode_reward_trend_value": 0.0003817616148823946, "biggest_recent_change": 0.025753902302568576},
{"total_number_of_episodes": 24127, "number_of_timesteps": 2753841, "per_episode_reward": -132.37, "episode_reward_trend_value": -0.00012840805335782886, "biggest_recent_change": 0.02034277117766692},
{"total_number_of_episodes": 24137, "number_of_timesteps": 2754852, "per_episode_reward": -132.34, "episode_reward_trend_value": 0.00036782048006153267, "biggest_recent_change": 0.027869872500218662},
{"total_number_of_episodes": 24147, "number_of_timesteps": 2755872, "per_episode_reward": -132.34, "episode_reward_trend_value": 0.0003768021253307552, "biggest_recent_change": 0.027869872500218662},
{"total_number_of_episodes": 24157, "number_of_timesteps": 2757037, "per_episode_reward": -132.34, "episode_reward_trend_value": 0.00023603054926708307, "biggest_recent_change": 0.027869872500218662},
{"total_number_of_episodes": 24167, "number_of_timesteps": 2758195, "per_episode_reward": -132.37, "episode_reward_trend_value": -0.00023463700394820032, "biggest_recent_change": 0.027869872500218662},
{"total_number_of_episodes": 24177, "number_of_timesteps": 2759218, "per_episode_reward": -132.33, "episode_reward_trend_value": 0.00025593215513689904, "biggest_recent_change": 0.03655266270484958},
{"total_number_of_episodes": 24187, "number_of_timesteps": 2760255, "per_episode_reward": -132.34, "episode_reward_trend_value": 0.00019915775830428275, "biggest_recent_change": 0.03655266270484958},
{"total_number_of_episodes": 24198, "number_of_timesteps": 2761780, "per_episode_reward": -132.37, "episode_reward_trend_value": -8.231187525432738e-05, "biggest_recent_change": 0.03655266270484958},
{"total_number_of_episodes": 24208, "number_of_timesteps": 2763444, "per_episode_reward": -132.4, "episode_reward_trend_value": -0.000582596756391101, "biggest_recent_change": 0.03655266270484958},
{"total_number_of_episodes": 24219, "number_of_timesteps": 2764683, "per_episode_reward": -132.39, "episode_reward_trend_value": -0.00026000543973118007, "biggest_recent_change": 0.03655266270484958},
{"total_number_of_episodes": 24229, "number_of_timesteps": 2765507, "per_episode_reward": -132.37, "episode_reward_trend_value": -0.0002951692419281294, "biggest_recent_change": 0.03655266270484958},
{"total_number_of_episodes": 24239, "number_of_timesteps": 2766545, "per_episode_reward": -132.34, "episode_reward_trend_value": 7.923079567401853e-05, "biggest_recent_change": 0.03655266270484958},
{"total_number_of_episodes": 24249, "number_of_timesteps": 2767680, "per_episode_reward": -132.39, "episode_reward_trend_value": -0.0005499822141956656, "biggest_recent_change": 0.05799103990531762},
{"total_number_of_episodes": 24259, "number_of_timesteps": 2768979, "per_episode_reward": -132.43, "episode_reward_trend_value": -0.0007215892161130771, "biggest_recent_change": 0.05799103990531762},
{"total_number_of_episodes": 24269, "number_of_timesteps": 2770218, "per_episode_reward": -132.42, "episode_reward_trend_value": -0.001042190244067519, "biggest_recent_change": 0.05799103990531762},
{"total_number_of_episodes": 24279, "number_of_timesteps": 2771034, "per_episode_reward": -132.39, "episode_reward_trend_value": -0.0005546661483846391, "biggest_recent_change": 0.05799103990531762},
{"total_number_of_episodes": 24289, "number_of_timesteps": 2772496, "per_episode_reward": -132.41, "episode_reward_trend_value": -0.0004160106616565271, "biggest_recent_change": 0.05799103990531762},
{"total_number_of_episodes": 24299, "number_of_timesteps": 2773609, "per_episode_reward": -132.41, "episode_reward_trend_value": -0.00016145353407763548, "biggest_recent_change": 0.05799103990531762},
{"total_number_of_episodes": 24309, "number_of_timesteps": 2775028, "per_episode_reward": -132.47, "episode_reward_trend_value": -0.0009092805540398608, "biggest_recent_change": 0.05843258113625893},
{"total_number_of_episodes": 24319, "number_of_timesteps": 2776230, "per_episode_reward": -132.46, "episode_reward_trend_value": -0.0010664268125023253, "biggest_recent_change": 0.05843258113625893},
{"total_number_of_episodes": 24329, "number_of_timesteps": 2777176, "per_episode_reward": -132.46, "episode_reward_trend_value": -0.0013906543449729092, "biggest_recent_change": 0.05843258113625893},
{"total_number_of_episodes": 24339, "number_of_timesteps": 2778366, "per_episode_reward": -132.45, "episode_reward_trend_value": -0.0006136610454205993, "biggest_recent_change": 0.05843258113625893},
{"total_number_of_episodes": 24349, "number_of_timesteps": 2779285, "per_episode_reward": -132.42, "episode_reward_trend_value": 0.00011807910215900897, "biggest_recent_change": 0.05843258113625893},
{"total_number_of_episodes": 24359, "number_of_timesteps": 2780331, "per_episode_reward": -132.41, "episode_reward_trend_value": 0.00020627234486501796, "biggest_recent_change": 0.05843258113625893},
{"total_number_of_episodes": 24369, "number_of_timesteps": 2781596, "per_episode_reward": -132.42, "episode_reward_trend_value": -0.0002921859046116045, "biggest_recent_change": 0.05843258113625893},
{"total_number_of_episodes": 24379, "number_of_timesteps": 2782832, "per_episode_reward": -132.44, "episode_reward_trend_value": -0.0002961420054864069, "biggest_recent_change": 0.05843258113625893},
{"total_number_of_episodes": 24389, "number_of_timesteps": 2784008, "per_episode_reward": -132.43, "episode_reward_trend_value": -0.0001525193172107543, "biggest_recent_change": 0.05843258113625893},
{"total_number_of_episodes": 24399, "number_of_timesteps": 2784983, "per_episode_reward": -132.43, "episode_reward_trend_value": 0.0005205954693726274, "biggest_recent_change": 0.028394674497889127},
{"total_number_of_episodes": 24410, "number_of_timesteps": 2786052, "per_episode_reward": -132.41, "episode_reward_trend_value": 0.0005995511370230133, "biggest_recent_change": 0.028394674497889127},
{"total_number_of_episodes": 24420, "number_of_timesteps": 2787266, "per_episode_reward": -132.46, "episode_reward_trend_value": -3.3104416829764376e-05, "biggest_recent_change": 0.05619136337227815},
{"total_number_of_episodes": 24430, "number_of_timesteps": 2788563, "per_episode_reward": -132.46, "episode_reward_trend_value": -0.0001321173959111219, "biggest_recent_change": 0.05619136337227815},
{"total_number_of_episodes": 24440, "number_of_timesteps": 2789456, "per_episode_reward": -132.44, "episode_reward_trend_value": -0.0002442111895154161, "biggest_recent_change": 0.05619136337227815},

{"total_number_of_episodes": 24450, "number_of_timesteps": 2790332, "per_episode_reward": -132.44, "episode_reward_trend_value": -0.00040122184082381156, "biggest_recent_change": 0.05619136337227815},
{"total_number_of_episodes": 24460, "number_of_timesteps": 2791246, "per_episode_reward": -132.41, "episode_reward_trend_value": 7.999120486614528e-05, "biggest_recent_change": 0.05619136337227815},
{"total_number_of_episodes": 24471, "number_of_timesteps": 2792295, "per_episode_reward": -132.4, "episode_reward_trend_value": 0.00038470866982688926, "biggest_recent_change": 0.05619136337227815},
{"total_number_of_episodes": 24481, "number_of_timesteps": 2793206, "per_episode_reward": -132.4, "episode_reward_trend_value": 0.0003168858787170671, "biggest_recent_change": 0.05619136337227815},
{"total_number_of_episodes": 24491, "number_of_timesteps": 2794014, "per_episode_reward": -132.35, "episode_reward_trend_value": 0.0008169506984305345, "biggest_recent_change": 0.05619136337227815},
{"total_number_of_episodes": 24501, "number_of_timesteps": 2795105, "per_episode_reward": -132.35, "episode_reward_trend_value": 0.0006444357621625664, "biggest_recent_change": 0.05619136337227815},
{"total_number_of_episodes": 24512, "number_of_timesteps": 2796343, "per_episode_reward": -132.4, "episode_reward_trend_value": 0.0007210596185684735, "biggest_recent_change": 0.04929521629574651},
{"total_number_of_episodes": 24522, "number_of_timesteps": 2797700, "per_episode_reward": -132.41, "episode_reward_trend_value": 0.0005840338613211316, "biggest_recent_change": 0.04929521629574651},
{"total_number_of_episodes": 24533, "number_of_timesteps": 2799412, "per_episode_reward": -132.43, "episode_reward_trend_value": 0.00016233362598604294, "biggest_recent_change": 0.04929521629574651},
{"total_number_of_episodes": 24543, "number_of_timesteps": 2800612, "per_episode_reward": -132.39, "episode_reward_trend_value": 0.0005739139686404037, "biggest_recent_change": 0.04929521629574651},
{"total_number_of_episodes": 24553, "number_of_timesteps": 2801703, "per_episode_reward": -132.38, "episode_reward_trend_value": 0.00028210773842229426, "biggest_recent_change": 0.04929521629574651},
{"total_number_of_episodes": 24563, "number_of_timesteps": 2802789, "per_episode_reward": -132.37, "episode_reward_trend_value": 0.000335757551309257, "biggest_recent_change": 0.04929521629574651},
{"total_number_of_episodes": 24573, "number_of_timesteps": 2803875, "per_episode_reward": -132.36, "episode_reward_trend_value": 0.00043990992756322257, "biggest_recent_change": 0.04929521629574651},
{"total_number_of_episodes": 24583, "number_of_timesteps": 2805331, "per_episode_reward": -132.38, "episode_reward_trend_value": -0.00033806861722054135, "biggest_recent_change": 0.04929521629574651},
{"total_number_of_episodes": 24594, "number_of_timesteps": 2806392, "per_episode_reward": -132.35, "episode_reward_trend_value": 4.972645776414689e-05, "biggest_recent_change": 0.04929521629574651},
{"total_number_of_episodes": 24604, "number_of_timesteps": 2807241, "per_episode_reward": -132.32, "episode_reward_trend_value": 0.0008621632676389859, "biggest_recent_change": 0.038547234253627494},
{"total_number_of_episodes": 24614, "number_of_timesteps": 2808051, "per_episode_reward": -132.3, "episode_reward_trend_value": 0.0011777739165766989, "biggest_recent_change": 0.038547234253627494},
{"total_number_of_episodes": 24624, "number_of_timesteps": 2809129, "per_episode_reward": -132.28, "episode_reward_trend_value": 0.001678732233247615, "biggest_recent_change": 0.038547234253627494},
{"total_number_of_episodes": 24635, "number_of_timesteps": 2810325, "per_episode_reward": -132.29, "episode_reward_trend_value": 0.0010829733889168992, "biggest_recent_change": 0.037043189613910954},
{"total_number_of_episodes": 24645, "number_of_timesteps": 2811422, "per_episode_reward": -132.31, "episode_reward_trend_value": 0.0007904891238840466, "biggest_recent_change": 0.037043189613910954},
{"total_number_of_episodes": 24655, "number_of_timesteps": 2812266, "per_episode_reward": -132.26, "episode_reward_trend_value": 0.001194099087513223, "biggest_recent_change": 0.047610747971646106},
{"total_number_of_episodes": 24665, "number_of_timesteps": 2813184, "per_episode_reward": -132.28, "episode_reward_trend_value": 0.0009031991320647926, "biggest_recent_change": 0.047610747971646106},
{"total_number_of_episodes": 24675, "number_of_timesteps": 2814392, "per_episode_reward": -132.3, "episode_reward_trend_value": 0.0008871049040168246, "biggest_recent_change": 0.047610747971646106},
{"total_number_of_episodes": 24686, "number_of_timesteps": 2815860, "per_episode_reward": -132.29, "episode_reward_trend_value": 0.0006024704945133408, "biggest_recent_change": 0.047610747971646106},
{"total_number_of_episodes": 24697, "number_of_timesteps": 2817055, "per_episode_reward": -132.27, "episode_reward_trend_value": 0.0006078076880719942, "biggest_recent_change": 0.047610747971646106},
{"total_number_of_episodes": 24707, "number_of_timesteps": 2818225, "per_episode_reward": -132.29, "episode_reward_trend_value": 0.0001740893889809235, "biggest_recent_change": 0.047610747971646106},
{"total_number_of_episodes": 24718, "number_of_timesteps": 2819846, "per_episode_reward": -132.31, "episode_reward_trend_value": -0.00036764419736464837, "biggest_recent_change": 0.047610747971646106},
{"total_number_of_episodes": 24729, "number_of_timesteps": 2820793, "per_episode_reward": -132.29, "episode_reward_trend_value": 7.913259198157144e-05, "biggest_recent_change": 0.047610747971646106},
{"total_number_of_episodes": 24739, "number_of_timesteps": 2821657, "per_episode_reward": -132.24, "episode_reward_trend_value": 0.0008002991026583257, "biggest_recent_change": 0.047610747971646106},
{"total_number_of_episodes": 24749, "number_of_timesteps": 2822702, "per_episode_reward": -132.28, "episode_reward_trend_value": -0.00018632816296783655, "biggest_recent_change": 0.04523834557025452},
{"total_number_of_episodes": 24759, "number_of_timesteps": 2824083, "per_episode_reward": -132.28, "episode_reward_trend_value": 1.01787008753086e-05, "biggest_recent_change": 0.04523834557025452},
{"total_number_of_episodes": 24769, "number_of_timesteps": 2825479, "per_episode_reward": -132.28, "episode_reward_trend_value": 0.00022677350186957787, "biggest_recent_change": 0.04523834557025452},
{"total_number_of_episodes": 24779, "number_of_timesteps": 2826545, "per_episode_reward": -132.28, "episode_reward_trend_value": 8.927189544654842e-05, "biggest_recent_change": 0.04523834557025452},
{"total_number_of_episodes": 24789, "number_of_timesteps": 2827755, "per_episode_reward": -132.28, "episode_reward_trend_value": -0.00018271586433829475, "biggest_recent_change": 0.04523834557025452},
{"total_number_of_episodes": 24799, "number_of_timesteps": 2828923, "per_episode_reward": -132.29, "episode_reward_trend_value": -4.327454978118163e-05, "biggest_recent_change": 0.04523834557025452},
{"total_number_of_episodes": 24810, "number_of_timesteps": 2830183, "per_episode_reward": -132.28, "episode_reward_trend_value": 0.0003437726256224652, "biggest_recent_change": 0.04523834557025452},
{"total_number_of_episodes": 24821, "number_of_timesteps": 2831482, "per_episode_reward": -132.31, "episode_reward_trend_value": -0.0002391715758433419, "biggest_recent_change": 0.04523834557025452},
{"total_number_of_episodes": 24832, "number_of_timesteps": 2832959, "per_episode_reward": -132.31, "episode_reward_trend_value": -0.0008268059549247179, "biggest_recent_change": 0.041185705934708494},
{"total_number_of_episodes": 24842, "number_of_timesteps": 2834324, "per_episode_reward": -132.4, "episode_reward_trend_value": -0.0012972030991297363, "biggest_recent_change": 0.08352144891316016},
{"total_number_of_episodes": 24853, "number_of_timesteps": 2835379, "per_episode_reward": -132.39, "episode_reward_trend_value": -0.0011977740662397689, "biggest_recent_change": 0.08352144891316016},
{"total_number_of_episodes": 24863, "number_of_timesteps": 2836386, "per_episode_reward": -132.39, "episode_reward_trend_value": -0.001175242679160091, "biggest_recent_change": 0.08352144891316016},
{"total_number_of_episodes": 24874, "number_of_timesteps": 2837708, "per_episode_reward": -132.39, "episode_reward_trend_value": -0.0011735381204838783, "biggest_recent_change": 0.08352144891316016},
{"total_number_of_episodes": 24884, "number_of_timesteps": 2838707, "per_episode_reward": -132.38, "episode_reward_trend_value": -0.0010776319019025018, "biggest_recent_change": 0.08352144891316016},
{"total_number_of_episodes": 24895, "number_of_timesteps": 2840058, "per_episode_reward": -132.42, "episode_reward_trend_value": -0.0014302199521457246, "biggest_recent_change": 0.08352144891316016},
{"total_number_of_episodes": 24905, "number_of_timesteps": 2841232, "per_episode_reward": -132.4, "episode_reward_trend_value": -0.0013108152673882816, "biggest_recent_change": 0.08352144891316016},
{"total_number_of_episodes": 24915, "number_of_timesteps": 2842830, "per_episode_reward": -132.4, "episode_reward_trend_value": -0.0010479846424052161, "biggest_recent_change": 0.08352144891316016},
{"total_number_of_episodes": 24925, "number_of_timesteps": 2844132, "per_episode_reward": -132.43, "episode_reward_trend_value": -0.0013370409957982727, "biggest_recent_change": 0.08352144891316016},
{"total_number_of_episodes": 24935, "number_of_timesteps": 2845254, "per_episode_reward": -132.4, "episode_reward_trend_value": -1.468505612460073e-05, "biggest_recent_change": 0.039118023940744706},
{"total_number_of_episodes": 24945, "number_of_timesteps": 2846430, "per_episode_reward": -132.43, "episode_reward_trend_value": -0.0005471024626991216, "biggest_recent_change": 0.039118023940744706},
{"total_number_of_episodes": 24956, "number_of_timesteps": 2847723, "per_episode_reward": -132.43, "episode_reward_trend_value": -0.0004614120585996615, "biggest_recent_change": 0.039118023940744706},
{"total_number_of_episodes": 24966, "number_of_timesteps": 2849102, "per_episode_reward": -132.54, "episode_reward_trend_value": -0.0016309464107757145, "biggest_recent_change": 0.10605373323446088},
{"total_number_of_episodes": 24976, "number_of_timesteps": 2850411, "per_episode_reward": -132.54, "episode_reward_trend_value": -0.0017642337217094136, "biggest_recent_change": 0.10605373323446088},
{"total_number_of_episodes": 24986, "number_of_timesteps": 2851437, "per_episode_reward": -132.53, "episode_reward_trend_value": -0.0012001748673295906, "biggest_recent_change": 0.10605373323446088},
{"total_number_of_episodes": 24996, "number_of_timesteps": 2852894, "per_episode_reward": -132.54, "episode_reward_trend_value": -0.00155802091205904, "biggest_recent_change": 0.10605373323446088},
{"total_number_of_episodes": 25007, "number_of_timesteps": 2854256, "per_episode_reward": -132.52, "episode_reward_trend_value": -0.001344272748192389, "biggest_recent_change": 0.10605373323446088},
{"total_number_of_episodes": 25018, "number_of_timesteps": 2855634, "per_episode_reward": -132.55, "episode_reward_trend_value": -0.0012715512654608574, "biggest_recent_change": 0.10605373323446088},
{"total_number_of_episodes": 25028, "number_of_timesteps": 2856908, "per_episode_reward": -132.59, "episode_reward_trend_value": -0.0020767360558105945, "biggest_recent_change": 0.10605373323446088},
{"total_number_of_episodes": 25038, "number_of_timesteps": 2858018, "per_episode_reward": -132.6, "episode_reward_trend_value": -0.0018091934792775217, "biggest_recent_change": 0.10605373323446088},
{"total_number_of_episodes": 25048, "number_of_timesteps": 2859301, "per_episode_reward": -132.6, "episode_reward_trend_value": -0.0018542860539671184, "biggest_recent_change": 0.10605373323446088},
{"total_number_of_episodes": 25058, "number_of_timesteps": 2860406, "per_episode_reward": -132.59, "episode_reward_trend_value": -0.0006330857470989788, "biggest_recent_change": 0.036976045474006014},
{"total_number_of_episodes": 25068, "number_of_timesteps": 2862059, "per_episode_reward": -132.61, "episode_reward_trend_value": -0.000730538451752712, "biggest_recent_change": 0.036976045474006014},
{"total_number_of_episodes": 25078, "number_of_timesteps": 2863022, "per_episode_reward": -132.57, "episode_reward_trend_value": -0.0004927658142002478, "biggest_recent_change": 0.036976045474006014},
{"total_number_of_episodes": 25089, "number_of_timesteps": 2864630, "per_episode_reward": -132.57, "episode_reward_trend_value": -0.0003077940437584125, "biggest_recent_change": 0.036976045474006014},
{"total_number_of_episodes": 25099, "number_of_timesteps": 2865807, "per_episode_reward": -132.69, "episode_reward_trend_value": -0.001870227992299394, "biggest_recent_change": 0.12505309319911362},
{"total_number_of_episodes": 25110, "number_of_timesteps": 2867416, "per_episode_reward": -132.7, "episode_reward_trend_value": -0.001624877590846394, "biggest_recent_change": 0.12505309319911362},
{"total_number_of_episodes": 25121, "number_of_timesteps": 2868787, "per_episode_reward": -132.65, "episode_reward_trend_value": -0.0006806770657482907, "biggest_recent_change": 0.12505309319911362},
{"total_number_of_episodes": 25132, "number_of_timesteps": 2870121, "per_episode_reward": -132.7, "episode_reward_trend_value": -0.0011297643434387637, "biggest_recent_change": 0.12505309319911362},
{"total_number_of_episodes": 25143, "number_of_timesteps": 2871165, "per_episode_reward": -132.68, "episode_reward_trend_value": -0.0009221003529240256, "biggest_recent_change": 0.12505309319911362},
{"total_number_of_episodes": 25153, "number_of_timesteps": 2872079, "per_episode_reward": -132.67, "episode_reward_trend_value": -0.0008193902655534657, "biggest_recent_change": 0.12505309319911362},
{"total_number_of_episodes": 25163, "number_of_timesteps": 2873119, "per_episode_reward": -132.72, "episode_reward_trend_value": -0.0013092225096913682, "biggest_recent_change": 0.12505309319911362},
{"total_number_of_episodes": 25173, "number_of_timesteps": 2874554, "per_episode_reward": -132.76, "episode_reward_trend_value": -0.002072132796803632, "biggest_recent_change": 0.12505309319911362},
{"total_number_of_episodes": 25183, "number_of_timesteps": 2875670, "per_episode_reward": -132.76, "episode_reward_trend_value": -0.0021777328553030076, "biggest_recent_change": 0.12505309319911362},
{"total_number_of_episodes": 25193, "number_of_timesteps": 2876677, "per_episode_reward": -132.73, "episode_reward_trend_value": -0.00039333712936442884, "biggest_recent_change": 0.056394398070324314},
{"total_number_of_episodes": 25203, "number_of_timesteps": 2878067, "per_episode_reward": -132.73, "episode_reward_trend_value": -0.00037839913415306606, "biggest_recent_change": 0.056394398070324314},
{"total_number_of_episodes": 25213, "number_of_timesteps": 2879203, "per_episode_reward": -132.72, "episode_reward_trend_value": -0.0007593142727611419, "biggest_recent_change": 0.056394398070324314},
{"total_number_of_episodes": 25223, "number_of_timesteps": 2880844, "per_episode_reward": -132.68, "episode_reward_trend_value": 0.0002005778248553093, "biggest_recent_change": 0.056394398070324314},
{"total_number_of_episodes": 25233, "number_of_timesteps": 2882201, "per_episode_reward": -132.72, "episode_reward_trend_value": -0.0004666907993813159, "biggest_recent_change": 0.056394398070324314},
{"total_number_of_episodes": 25245, "number_of_timesteps": 2883676, "per_episode_reward": -132.74, "episode_reward_trend_value": -0.0008331021221020289, "biggest_recent_change": 0.056394398070324314},
{"total_number_of_episodes": 25255, "number_of_timesteps": 2884754, "per_episode_reward": -132.72, "episode_reward_trend_value": -1.77934763649369e-05, "biggest_recent_change": 0.04050222158582528},
{"total_number_of_episodes": 25265, "number_of_timesteps": 2885717, "per_episode_reward": -132.73, "episode_reward_trend_value": 0.00035117209290578763, "biggest_recent_change": 0.04050222158582528},
{"total_number_of_episodes": 25275, "number_of_timesteps": 2886807, "per_episode_reward": -132.72, "episode_reward_trend_value": 0.00046013721833415073, "biggest_recent_change": 0.04050222158582528},
{"total_number_of_episodes": 25285, "number_of_timesteps": 2887758, "per_episode_reward": -132.71, "episode_reward_trend_value": 0.00015624645617593716, "biggest_recent_change": 0.04050222158582528},
{"total_number_of_episodes": 25295, "number_of_timesteps": 2889001, "per_episode_reward": -132.72, "episode_reward_trend_value": 5.699012414797582e-05, "biggest_recent_change": 0.04050222158582528},
{"total_number_of_episodes": 25305, "number_of_timesteps": 2889910, "per_episode_reward": -132.69, "episode_reward_trend_value": 0.00023403182551362534, "biggest_recent_change": 0.04050222158582528},
{"total_number_of_episodes": 25315, "number_of_timesteps": 2890847, "per_episode_reward": -132.67, "episode_reward_trend_value": 0.00010992173541871528, "biggest_recent_change": 0.04050222158582528},
{"total_number_of_episodes": 25325, "number_of_timesteps": 2891841, "per_episode_reward": -132.65, "episode_reward_trend_value": 0.0007541865323588582, "biggest_recent_change": 0.02965339243300491},
{"total_number_of_episodes": 25336, "number_of_timesteps": 2893084, "per_episode_reward": -132.65, "episode_reward_trend_value": 0.0010011592655937798, "biggest_recent_change": 0.02965339243300491},
{"total_number_of_episodes": 25346, "number_of_timesteps": 2894288, "per_episode_reward": -132.66, "episode_reward_trend_value": 0.0007727133253726808, "biggest_recent_change": 0.02965339243300491},
{"total_number_of_episodes": 25356, "number_of_timesteps": 2895503, "per_episode_reward": -132.67, "episode_reward_trend_value": 0.0006106684924592148, "biggest_recent_change": 0.02965339243300491},
{"total_number_of_episodes": 25367, "number_of_timesteps": 2896756, "per_episode_reward": -132.62, "episode_reward_trend_value": 0.0011473083414803872, "biggest_recent_change": 0.05530586278675287},
{"total_number_of_episodes": 25377, "number_of_timesteps": 2898004, "per_episode_reward": -132.63, "episode_reward_trend_value": 0.000936134078201197, "biggest_recent_change": 0.05530586278675287},
{"total_number_of_episodes": 25387, "number_of_timesteps": 2899135, "per_episode_reward": -132.59, "episode_reward_trend_value": 0.0014712758041405829, "biggest_recent_change": 0.05530586278675287},
{"total_number_of_episodes": 25397, "number_of_timesteps": 2899952, "per_episode_reward": -132.6, "episode_reward_trend_value": 0.0010846079556829282, "biggest_recent_change": 0.05530586278675287},
{"total_number_of_episodes": 25407, "number_of_timesteps": 2900836, "per_episode_reward": -132.57, "episode_reward_trend_value": 0.0011556335085581774, "biggest_recent_change": 0.05530586278675287},
{"total_number_of_episodes": 25417, "number_of_timesteps": 2902061, "per_episode_reward": -132.58, "episode_reward_trend_value": 0.0008020563211317722, "biggest_recent_change": 0.05530586278675287},
{"total_number_of_episodes": 25427, "number_of_timesteps": 2903051, "per_episode_reward": -132.52, "episode_reward_trend_value": 0.0014680952744006012, "biggest_recent_change": 0.062292234987495476},
{"total_number_of_episodes": 25437, "number_of_timesteps": 2904398, "per_episode_reward": -132.53, "episode_reward_trend_value": 0.0013756885524764408, "biggest_recent_change": 0.062292234987495476},
{"total_number_of_episodes": 25447, "number_of_timesteps": 2905794, "per_episode_reward": -132.53, "episode_reward_trend_value": 0.001588608536068313, "biggest_recent_change": 0.062292234987495476},
{"total_number_of_episodes": 25457, "number_of_timesteps": 2906760, "per_episode_reward": -132.52, "episode_reward_trend_value": 0.001061918301275, "biggest_recent_change": 0.062292234987495476},
{"total_number_of_episodes": 25468, "number_of_timesteps": 2908207, "per_episode_reward": -132.55, "episode_reward_trend_value": 0.0008289798047895955, "biggest_recent_change": 0.062292234987495476},
{"total_number_of_episodes": 25478, "number_of_timesteps": 2909754, "per_episode_reward": -132.59, "episode_reward_trend_value": -1.4034407984316508e-05, "biggest_recent_change": 0.062292234987495476},
{"total_number_of_episodes": 25488, "number_of_timesteps": 2910884, "per_episode_reward": -132.57, "episode_reward_trend_value": 0.0003361766184282386, "biggest_recent_change": 0.062292234987495476},
{"total_number_of_episodes": 25498, "number_of_timesteps": 2911964, "per_episode_reward": -132.56, "episode_reward_trend_value": 0.00012804353238651502, "biggest_recent_change": 0.062292234987495476},
{"total_number_of_episodes": 25508, "number_of_timesteps": 2913317, "per_episode_reward": -132.56, "episode_reward_trend_value": 0.0002807858484582463, "biggest_recent_change": 0.062292234987495476},
{"total_number_of_episodes": 25518, "number_of_timesteps": 2914945, "per_episode_reward": -132.57, "episode_reward_trend_value": -0.0005914594718417574, "biggest_recent_change": 0.040334524904437785},
{"total_number_of_episodes": 25528, "number_of_timesteps": 2915967, "per_episode_reward": -132.53, "episode_reward_trend_value": -6.494850628276557e-06, "biggest_recent_change": 0.040753456362153884},
{"total_number_of_episodes": 25538, "number_of_timesteps": 2917069, "per_episode_reward": -132.55, "episode_reward_trend_value": -0.00025716327152925565, "biggest_recent_change": 0.040753456362153884},
{"total_number_of_episodes": 25548, "number_of_timesteps": 2918444, "per_episode_reward": -132.54, "episode_reward_trend_value": -0.00015705332544908084, "biggest_recent_change": 0.040753456362153884},
{"total_number_of_episodes": 25558, "number_of_timesteps": 2919578, "per_episode_reward": -132.52, "episode_reward_trend_value": 0.00038525668767874777, "biggest_recent_change": 0.040753456362153884},
{"total_number_of_episodes": 25568, "number_of_timesteps": 2920637, "per_episode_reward": -132.49, "episode_reward_trend_value": 0.0011179461377120484, "biggest_recent_change": 0.040753456362153884},
{"total_number_of_episodes": 25579, "number_of_timesteps": 2921605, "per_episode_reward": -132.43, "episode_reward_trend_value": 0.0015433328434268233, "biggest_recent_change": 0.06465708196327569},
{"total_number_of_episodes": 25589, "number_of_timesteps": 2922710, "per_episode_reward": -132.46, "episode_reward_trend_value": 0.0010279544514857106, "biggest_recent_change": 0.06465708196327569},
{"total_number_of_episodes": 25599, "number_of_timesteps": 2923817, "per_episode_reward": -132.4, "episode_reward_trend_value": 0.0017335808232729732, "biggest_recent_change": 0.06465708196327569},
{"total_number_of_episodes": 25610, "number_of_timesteps": 2925025, "per_episode_reward": -132.43, "episode_reward_trend_value": 0.001555918504074801, "biggest_recent_change": 0.06465708196327569},
{"total_number_of_episodes": 25621, "number_of_timesteps": 2926315, "per_episode_reward": -132.47, "episode_reward_trend_value": 0.0007138777789003194, "biggest_recent_change": 0.06465708196327569},
{"total_number_of_episodes": 25631, "number_of_timesteps": 2927742, "per_episode_reward": -132.48, "episode_reward_trend_value": 0.0007481965400845385, "biggest_recent_change": 0.06465708196327569},
{"total_number_of_episodes": 25641, "number_of_timesteps": 2929013, "per_episode_reward": -132.49, "episode_reward_trend_value": 0.0004809115405631953, "biggest_recent_change": 0.06465708196327569},
{"total_number_of_episodes": 25651, "number_of_timesteps": 2930308, "per_episode_reward": -132.49, "episode_reward_trend_value": 0.00033301931745831505, "biggest_recent_change": 0.06465708196327569},
{"total_number_of_episodes": 25661, "number_of_timesteps": 2931519, "per_episode_reward": -132.51, "episode_reward_trend_value": -0.00021068947478144968, "biggest_recent_change": 0.06465708196327569},
{"total_number_of_episodes": 25671, "number_of_timesteps": 2932898, "per_episode_reward": -132.54, "episode_reward_trend_value": -0.0012639388939113083, "biggest_recent_change": 0.06291284517772056},
{"total_number_of_episodes": 25681, "number_of_timesteps": 2934297, "per_episode_reward": -132.56, "episode_reward_trend_value": -0.0010946364112966321, "biggest_recent_change": 0.06291284517772056},
{"total_number_of_episodes": 25692, "number_of_timesteps": 2935641, "per_episode_reward": -132.58, "episode_reward_trend_value": -0.001972005169155169, "biggest_recent_change": 0.035030208903549465},
{"total_number_of_episodes": 25702, "number_of_timesteps": 2936911, "per_episode_reward": -132.57, "episode_reward_trend_value": -0.0015571794451729047, "biggest_recent_change": 0.035030208903549465},
{"total_number_of_episodes": 25712, "number_of_timesteps": 2938330, "per_episode_reward": -132.6, "episode_reward_trend_value": -0.0014651512600288975, "biggest_recent_change": 0.03013536575841158},
{"total_number_of_episodes": 25722, "number_of_timesteps": 2939659, "per_episode_reward": -132.58, "episode_reward_trend_value": -0.0010923381435828914, "biggest_recent_change": 0.03013536575841158},
{"total_number_of_episodes": 25732, "number_of_timesteps": 2941222, "per_episode_reward": -132.6, "episode_reward_trend_value": -0.0011685604814936647, "biggest_recent_change": 0.03013536575841158},
{"total_number_of_episodes": 25743, "number_of_timesteps": 2942400, "per_episode_reward": -132.57, "episode_reward_trend_value": -0.0008682594771897811, "biggest_recent_change": 0.03074689665172059},
{"total_number_of_episodes": 25753, "number_of_timesteps": 2943558, "per_episode_reward": -132.56, "episode_reward_trend_value": -0.0005194962935269763, "biggest_recent_change": 0.03074689665172059},
{"total_number_of_episodes": 25763, "number_of_timesteps": 2944922, "per_episode_reward": -132.59, "episode_reward_trend_value": -0.0005679496190582414, "biggest_recent_change": 0.034496165056225436},
{"total_number_of_episodes": 25773, "number_of_timesteps": 2945883, "per_episode_reward": -132.57, "episode_reward_trend_value": -7.102930938426906e-05, "biggest_recent_change": 0.034496165056225436},
{"total_number_of_episodes": 25783, "number_of_timesteps": 2946802, "per_episode_reward": -132.56, "episode_reward_trend_value": 0.0002481639075906767, "biggest_recent_change": 0.034496165056225436},
{"total_number_of_episodes": 25793, "number_of_timesteps": 2948096, "per_episode_reward": -132.53, "episode_reward_trend_value": 0.0004605095376187289, "biggest_recent_change": 0.034496165056225436},
{"total_number_of_episodes": 25803, "number_of_timesteps": 2949394, "per_episode_reward": -132.51, "episode_reward_trend_value": 0.0009408427403981377, "biggest_recent_change": 0.034496165056225436},
{"total_number_of_episodes": 25813, "number_of_timesteps": 2950394, "per_episode_reward": -132.53, "episode_reward_trend_value": 0.0005515377729564206, "biggest_recent_change": 0.034496165056225436},
{"total_number_of_episodes": 25823, "number_of_timesteps": 2951464, "per_episode_reward": -132.5, "episode_reward_trend_value": 0.0010955157488429753, "biggest_recent_change": 0.03495599426346985},
{"total_number_of_episodes": 25833, "number_of_timesteps": 2952756, "per_episode_reward": -132.52, "episode_reward_trend_value": 0.0005047694657488616, "biggest_recent_change": 0.03495599426346985},
{"total_number_of_episodes": 25844, "number_of_timesteps": 2953942, "per_episode_reward": -132.51, "episode_reward_trend_value": 0.000484625470329863, "biggest_recent_change": 0.03495599426346985},
{"total_number_of_episodes": 25854, "number_of_timesteps": 2955072, "per_episode_reward": -132.44, "episode_reward_trend_value": 0.0017336719521435068, "biggest_recent_change": 0.07791801830700251},
{"total_number_of_episodes": 25864, "number_of_timesteps": 2956520, "per_episode_reward": -132.49, "episode_reward_trend_value": 0.000886413784348545, "biggest_recent_change": 0.07791801830700251},
{"total_number_of_episodes": 25875, "number_of_timesteps": 2957879, "per_episode_reward": -132.43, "episode_reward_trend_value": 0.0014250132420569471, "biggest_recent_change": 0.07791801830700251},
{"total_number_of_episodes": 25885, "number_of_timesteps": 2958756, "per_episode_reward": -132.37, "episode_reward_trend_value": 0.0017381162398310026, "biggest_recent_change": 0.07791801830700251},
{"total_number_of_episodes": 25895, "number_of_timesteps": 2959883, "per_episode_reward": -132.39, "episode_reward_trend_value": 0.001388230852320602, "biggest_recent_change": 0.07791801830700251},
{"total_number_of_episodes": 25905, "number_of_timesteps": 2961187, "per_episode_reward": -132.41, "episode_reward_trend_value": 0.0013809342839680185, "biggest_recent_change": 0.07791801830700251},
{"total_number_of_episodes": 25916, "number_of_timesteps": 2962402, "per_episode_reward": -132.42, "episode_reward_trend_value": 0.0008532079360473214, "biggest_recent_change": 0.07791801830700251},
{"total_number_of_episodes": 25926, "number_of_timesteps": 2963439, "per_episode_reward": -132.42, "episode_reward_trend_value": 0.0010782048198055665, "biggest_recent_change": 0.07791801830700251},
{"total_number_of_episodes": 25936, "number_of_timesteps": 2964410, "per_episode_reward": -132.43, "episode_reward_trend_value": 0.0009759966952736299, "biggest_recent_change": 0.07791801830700251},
{"total_number_of_episodes": 25947, "number_of_timesteps": 2965689, "per_episode_reward": -132.42, "episode_reward_trend_value": 0.00017049045826935424, "biggest_recent_change": 0.061150997691953535},
{"total_number_of_episodes": 25957, "number_of_timesteps": 2966982, "per_episode_reward": -132.45, "episode_reward_trend_value": 0.0003950355164669695, "biggest_recent_change": 0.061150997691953535},
{"total_number_of_episodes": 25967, "number_of_timesteps": 2968080, "per_episode_reward": -132.45, "episode_reward_trend_value": -0.0002564559278833182, "biggest_recent_change": 0.05242523909325314},
{"total_number_of_episodes": 25977, "number_of_timesteps": 2969147, "per_episode_reward": -132.39, "episode_reward_trend_value": -0.0002206626683213623, "biggest_recent_change": 0.05564663245382917},
{"total_number_of_episodes": 25987, "number_of_timesteps": 2970360, "per_episode_reward": -132.39, "episode_reward_trend_value": -2.5517676961802255e-05, "biggest_recent_change": 0.05564663245382917},
{"total_number_of_episodes": 25997, "number_of_timesteps": 2971623, "per_episode_reward": -132.39, "episode_reward_trend_value": 0.0002026195944921483, "biggest_recent_change": 0.05564663245382917},
{"total_number_of_episodes": 26007, "number_of_timesteps": 2972469, "per_episode_reward": -132.33, "episode_reward_trend_value": 0.0009879134759115814, "biggest_recent_change": 0.05813707227835607},
{"total_number_of_episodes": 26017, "number_of_timesteps": 2973840, "per_episode_reward": -132.34, "episode_reward_trend_value": 0.0009480973376484927, "biggest_recent_change": 0.05813707227835607},
{"total_number_of_episodes": 26029, "number_of_timesteps": 2975437, "per_episode_reward": -132.37, "episode_reward_trend_value": 0.0005879860638325833, "biggest_recent_change": 0.05813707227835607},
{"total_number_of_episodes": 26039, "number_of_timesteps": 2976425, "per_episode_reward": -132.37, "episode_reward_trend_value": 0.0005472828914100268, "biggest_recent_change": 0.05813707227835607},
{"total_number_of_episodes": 26050, "number_of_timesteps": 2977885, "per_episode_reward": -132.38, "episode_reward_trend_value": 0.0008161094651512712, "biggest_recent_change": 0.05813707227835607},
{"total_number_of_episodes": 26060, "number_of_timesteps": 2978985, "per_episode_reward": -132.34, "episode_reward_trend_value": 0.0012674403323406599, "biggest_recent_change": 0.05813707227835607},
{"total_number_of_episodes": 26070, "number_of_timesteps": 2980163, "per_episode_reward": -132.28, "episode_reward_trend_value": 0.001233990321544651, "biggest_recent_change": 0.05813707227835607},
{"total_number_of_episodes": 26080, "number_of_timesteps": 2981121, "per_episode_reward": -132.31, "episode_reward_trend_value": 0.0009366882610047847, "biggest_recent_change": 0.05813707227835607},
{"total_number_of_episodes": 26090, "number_of_timesteps": 2982190, "per_episode_reward": -132.3, "episode_reward_trend_value": 0.0009760657448036151, "biggest_recent_change": 0.05813707227835607},
{"total_number_of_episodes": 26101, "number_of_timesteps": 2983535, "per_episode_reward": -132.29, "episode_reward_trend_value": 0.00047712063938137005, "biggest_recent_change": 0.052636131482188375},
{"total_number_of_episodes": 26111, "number_of_timesteps": 2984836, "per_episode_reward": -132.34, "episode_reward_trend_value": -5.9008306780267756e-05, "biggest_recent_change": 0.05400560688673295},
{"total_number_of_episodes": 26121, "number_of_timesteps": 2986095, "per_episode_reward": -132.37, "episode_reward_trend_value": 4.761974256963539e-05, "biggest_recent_change": 0.05400560688673295},
{"total_number_of_episodes": 26132, "number_of_timesteps": 2987300, "per_episode_reward": -132.41, "episode_reward_trend_value": -0.0004519426052679718, "biggest_recent_change": 0.05400560688673295},
{"total_number_of_episodes": 26142, "number_of_timesteps": 2988764, "per_episode_reward": -132.46, "episode_reward_trend_value": -0.0009161042586830112, "biggest_recent_change": 0.05400560688673295},
{"total_number_of_episodes": 26153, "number_of_timesteps": 2990235, "per_episode_reward": -132.42, "episode_reward_trend_value": -0.0008750450157716868, "biggest_recent_change": 0.05400560688673295},
{"total_number_of_episodes": 26164, "number_of_timesteps": 2991498, "per_episode_reward": -132.43, "episode_reward_trend_value": -0.0015920767980977264, "biggest_recent_change": 0.05400560688673295},
{"total_number_of_episodes": 26176, "number_of_timesteps": 2992813, "per_episode_reward": -132.39, "episode_reward_trend_value": -0.0009230482292344454, "biggest_recent_change": 0.05400560688673295},
{"total_number_of_episodes": 26187, "number_of_timesteps": 2993739, "per_episode_reward": -132.41, "episode_reward_trend_value": -0.0012355574952547638, "biggest_recent_change": 0.05400560688673295},
{"total_number_of_episodes": 26197, "number_of_timesteps": 2994901, "per_episode_reward": -132.44, "episode_reward_trend_value": -0.001683072159422573, "biggest_recent_change": 0.05400560688673295},
{"total_number_of_episodes": 26207, "number_of_timesteps": 2996599, "per_episode_reward": -132.49, "episode_reward_trend_value": -0.0016407081113028552, "biggest_recent_change": 0.05019284255595835},
{"total_number_of_episodes": 26217, "number_of_timesteps": 2997898, "per_episode_reward": -132.52, "episode_reward_trend_value": -0.0016943385193482325, "biggest_recent_change": 0.05019284255595835},
{"total_number_of_episodes": 26228, "number_of_timesteps": 2999234, "per_episode_reward": -132.53, "episode_reward_trend_value": -0.0012592119736682308, "biggest_recent_change": 0.05019284255595835},
{"total_number_of_episodes": 26238, "number_of_timesteps": 3000254, "per_episode_reward": -132.57, "episode_reward_trend_value": -0.0011887376550706423, "biggest_recent_change": 0.05019284255595835},
{"total_number_of_episodes": 26249, "number_of_timesteps": 3001311, "per_episode_reward": -132.58, "episode_reward_trend_value": -0.0018073771490583744, "biggest_recent_change": 0.05019284255595835},
{"total_number_of_episodes": 26259, "number_of_timesteps": 3002404, "per_episode_reward": -132.61, "episode_reward_trend_value": -0.0020772588402659647, "biggest_recent_change": 0.05019284255595835},
{"total_number_of_episodes": 26271, "number_of_timesteps": 3003694, "per_episode_reward": -132.61, "episode_reward_trend_value": -0.0023906273772265904, "biggest_recent_change": 0.05019284255595835},
{"total_number_of_episodes": 26281, "number_of_timesteps": 3004584, "per_episode_reward": -132.55, "episode_reward_trend_value": -0.001498972464850744, "biggest_recent_change": 0.05675755831737206},
{"total_number_of_episodes": 26291, "number_of_timesteps": 3005501, "per_episode_reward": -132.51, "episode_reward_trend_value": -0.0008016768772200243, "biggest_recent_change": 0.05675755831737206},
{"total_number_of_episodes": 26301, "number_of_timesteps": 3006555, "per_episode_reward": -132.56, "episode_reward_trend_value": -0.0007504461257257036, "biggest_recent_change": 0.05675755831737206},
{"total_number_of_episodes": 26311, "number_of_timesteps": 3007665, "per_episode_reward": -132.57, "episode_reward_trend_value": -0.0005827489148973402, "biggest_recent_change": 0.05675755831737206},
{"total_number_of_episodes": 26321, "number_of_timesteps": 3009084, "per_episode_reward": -132.59, "episode_reward_trend_value": -0.0007158032368367786, "biggest_recent_change": 0.05675755831737206},
{"total_number_of_episodes": 26331, "number_of_timesteps": 3009922, "per_episode_reward": -132.56, "episode_reward_trend_value": 0.00010737687879232756, "biggest_recent_change": 0.05675755831737206},
{"total_number_of_episodes": 26342, "number_of_timesteps": 3011010, "per_episode_reward": -132.5, "episode_reward_trend_value": 0.000851402281516774, "biggest_recent_change": 0.058116609395796104},
{"total_number_of_episodes": 26353, "number_of_timesteps": 3012357, "per_episode_reward": -132.54, "episode_reward_trend_value": 0.0008078410541612711, "biggest_recent_change": 0.058116609395796104},
{"total_number_of_episodes": 26363, "number_of_timesteps": 3013268, "per_episode_reward": -132.49, "episode_reward_trend_value": 0.0012392208408771113, "biggest_recent_change": 0.058116609395796104},
{"total_number_of_episodes": 26373, "number_of_timesteps": 3014349, "per_episode_reward": -132.49, "episode_reward_trend_value": 0.0006932292485945229, "biggest_recent_change": 0.058116609395796104},
{"total_number_of_episodes": 26383, "number_of_timesteps": 3015438, "per_episode_reward": -132.46, "episode_reward_trend_value": 0.0006244062802106024, "biggest_recent_change": 0.058116609395796104},
{"total_number_of_episodes": 26393, "number_of_timesteps": 3016300, "per_episode_reward": -132.45, "episode_reward_trend_value": 0.0011838726880644876, "biggest_recent_change": 0.058116609395796104},
{"total_number_of_episodes": 26403, "number_of_timesteps": 3017566, "per_episode_reward": -132.47, "episode_reward_trend_value": 0.0011820910242148683, "biggest_recent_change": 0.058116609395796104},
{"total_number_of_episodes": 26413, "number_of_timesteps": 3018472, "per_episode_reward": -132.46, "episode_reward_trend_value": 0.0014773078153151827, "biggest_recent_change": 0.058116609395796104},
{"total_number_of_episodes": 26423, "number_of_timesteps": 3019901, "per_episode_reward": -132.51, "episode_reward_trend_value": 0.0005924537869147015, "biggest_recent_change": 0.058116609395796104},
{"total_number_of_episodes": 26433, "number_of_timesteps": 3021249, "per_episode_reward": -132.5, "episode_reward_trend_value": 6.599957844868084e-05, "biggest_recent_change": 0.04812517492547386},
{"total_number_of_episodes": 26444, "number_of_timesteps": 3022353, "per_episode_reward": -132.49, "episode_reward_trend_value": 0.000583560374382033, "biggest_recent_change": 0.04812517492547386},
{"total_number_of_episodes": 26454, "number_of_timesteps": 3023480, "per_episode_reward": -132.5, "episode_reward_trend_value": -7.798110481694998e-05, "biggest_recent_change": 0.04812517492547386},
{"total_number_of_episodes": 26464, "number_of_timesteps": 3024580, "per_episode_reward": -132.46, "episode_reward_trend_value": 0.00026479239286661345, "biggest_recent_change": 0.04812517492547386},
{"total_number_of_episodes": 26474, "number_of_timesteps": 3025423, "per_episode_reward": -132.44, "episode_reward_trend_value": 0.0002400337027779642, "biggest_recent_change": 0.04812517492547386},
{"total_number_of_episodes": 26485, "number_of_timesteps": 3026698, "per_episode_reward": -132.45, "episode_reward_trend_value": 4.396436533542985e-05, "biggest_recent_change": 0.04812517492547386},
{"total_number_of_episodes": 26495, "number_of_timesteps": 3028219, "per_episode_reward": -132.45, "episode_reward_trend_value": 0.00020378103336579693, "biggest_recent_change": 0.04812517492547386},

{"total_number_of_episodes": 26515, "number_of_timesteps": 3030747, "per_episode_reward": -132.44, "episode_reward_trend_value": 0.0007357178983868253, "biggest_recent_change": 0.03846792980345981},
{"total_number_of_episodes": 26526, "number_of_timesteps": 3032086, "per_episode_reward": -132.49, "episode_reward_trend_value": 7.99180644375181e-05, "biggest_recent_change": 0.04828625442158341},
{"total_number_of_episodes": 26536, "number_of_timesteps": 3033245, "per_episode_reward": -132.48, "episode_reward_trend_value": 0.00011963313741982045, "biggest_recent_change": 0.04828625442158341},
{"total_number_of_episodes": 26546, "number_of_timesteps": 3034391, "per_episode_reward": -132.48, "episode_reward_trend_value": 0.00022959082079852225, "biggest_recent_change": 0.04828625442158341},
{"total_number_of_episodes": 26556, "number_of_timesteps": 3035513, "per_episode_reward": -132.47, "episode_reward_trend_value": -9.28651819385272e-05, "biggest_recent_change": 0.04828625442158341},
{"total_number_of_episodes": 26566, "number_of_timesteps": 3036638, "per_episode_reward": -132.49, "episode_reward_trend_value": -0.0006081658638827826, "biggest_recent_change": 0.04828625442158341},
{"total_number_of_episodes": 26577, "number_of_timesteps": 3037658, "per_episode_reward": -132.43, "episode_reward_trend_value": 0.00018139973059558338, "biggest_recent_change": 0.05818456491860502},
{"total_number_of_episodes": 26587, "number_of_timesteps": 3038918, "per_episode_reward": -132.44, "episode_reward_trend_value": 8.585907933327993e-05, "biggest_recent_change": 0.05818456491860502},
{"total_number_of_episodes": 26597, "number_of_timesteps": 3039807, "per_episode_reward": -132.39, "episode_reward_trend_value": 0.0003918539324306241, "biggest_recent_change": 0.05818456491860502},
{"total_number_of_episodes": 26609, "number_of_timesteps": 3041191, "per_episode_reward": -132.44, "episode_reward_trend_value": -5.69489540582582e-05, "biggest_recent_change": 0.05818456491860502},
{"total_number_of_episodes": 26620, "number_of_timesteps": 3042114, "per_episode_reward": -132.39, "episode_reward_trend_value": 0.0010748801896233494, "biggest_recent_change": 0.05818456491860502},
{"total_number_of_episodes": 26630, "number_of_timesteps": 3043157, "per_episode_reward": -132.43, "episode_reward_trend_value": 0.0005843942118685972, "biggest_recent_change": 0.05818456491860502},
{"total_number_of_episodes": 26641, "number_of_timesteps": 3044298, "per_episode_reward": -132.38, "episode_reward_trend_value": 0.0010932889347316176, "biggest_recent_change": 0.05818456491860502},
{"total_number_of_episodes": 26651, "number_of_timesteps": 3045187, "per_episode_reward": -132.36, "episode_reward_trend_value": 0.0012657120953485268, "biggest_recent_change": 0.05818456491860502},
{"total_number_of_episodes": 26662, "number_of_timesteps": 3046636, "per_episode_reward": -132.38, "episode_reward_trend_value": 0.0011828817362221065, "biggest_recent_change": 0.05818456491860502},
{"total_number_of_episodes": 26674, "number_of_timesteps": 3047917, "per_episode_reward": -132.43, "episode_reward_trend_value": 4.5922858047396805e-05, "biggest_recent_change": 0.053578368509761276},

{"total_number_of_episodes": 26684, "number_of_timesteps": 3049183, "per_episode_reward": -132.44, "episode_reward_trend_value": 5.362393142370871e-05, "biggest_recent_change": 0.053578368509761276},
{"total_number_of_episodes": 26694, "number_of_timesteps": 3050095, "per_episode_reward": -132.43, "episode_reward_trend_value": -0.0004554886151469064, "biggest_recent_change": 0.053578368509761276},
{"total_number_of_episodes": 26704, "number_of_timesteps": 3050951, "per_episode_reward": -132.42, "episode_reward_trend_value": 0.0002701204588772852, "biggest_recent_change": 0.053578368509761276},
{"total_number_of_episodes": 26714, "number_of_timesteps": 3051898, "per_episode_reward": -132.39, "episode_reward_trend_value": 3.5616445242049446e-05, "biggest_recent_change": 0.04414173411711886},
{"total_number_of_episodes": 26724, "number_of_timesteps": 3052888, "per_episode_reward": -132.39, "episode_reward_trend_value": 0.0003627178796405259, "biggest_recent_change": 0.04414173411711886},
{"total_number_of_episodes": 26734, "number_of_timesteps": 3053822, "per_episode_reward": -132.41, "episode_reward_trend_value": -0.00030787493619439173, "biggest_recent_change": 0.04414173411711886},
{"total_number_of_episodes": 26744, "number_of_timesteps": 3054816, "per_episode_reward": -132.41, "episode_reward_trend_value": -0.0006167745602883517, "biggest_recent_change": 0.04414173411711886},
{"total_number_of_episodes": 26754, "number_of_timesteps": 3055723, "per_episode_reward": -132.37, "episode_reward_trend_value": 0.00018714864390795407, "biggest_recent_change": 0.045811241320791396},
{"total_number_of_episodes": 26764, "number_of_timesteps": 3056767, "per_episode_reward": -132.35, "episode_reward_trend_value": 0.0008202654255939024, "biggest_recent_change": 0.045811241320791396},
{"total_number_of_episodes": 26775, "number_of_timesteps": 3058149, "per_episode_reward": -132.41, "episode_reward_trend_value": 0.00025442598531621264, "biggest_recent_change": 0.060104709178887106},
{"total_number_of_episodes": 26787, "number_of_timesteps": 3059474, "per_episode_reward": -132.41, "episode_reward_trend_value": 0.000306182926196483, "biggest_recent_change": 0.060104709178887106},
{"total_number_of_episodes": 26797, "number_of_timesteps": 3060407, "per_episode_reward": -132.39, "episode_reward_trend_value": 0.00032272315492510494, "biggest_recent_change": 0.060104709178887106},
{"total_number_of_episodes": 26807, "number_of_timesteps": 3061439, "per_episode_reward": -132.4, "episode_reward_trend_value": -0.00013404349215401606, "biggest_recent_change": 0.060104709178887106},
{"total_number_of_episodes": 26817, "number_of_timesteps": 3062574, "per_episode_reward": -132.4, "episode_reward_trend_value": -8.230602218191052e-05, "biggest_recent_change": 0.060104709178887106},
{"total_number_of_episodes": 26828, "number_of_timesteps": 3064209, "per_episode_reward": -132.42, "episode_reward_trend_value": -5.9081974835193144e-05, "biggest_recent_change": 0.060104709178887106},
{"total_number_of_episodes": 26838, "number_of_timesteps": 3065010, "per_episode_reward": -132.38, "episode_reward_trend_value": 0.000388312080542303, "biggest_recent_change": 0.060104709178887106},
{"total_number_of_episodes": 26848, "number_of_timesteps": 3065897, "per_episode_reward": -132.35, "episode_reward_trend_value": 0.0002108129916378074, "biggest_recent_change": 0.060104709178887106},
{"total_number_of_episodes": 26860, "number_of_timesteps": 3067364, "per_episode_reward": -132.37, "episode_reward_trend_value": -0.00021621104027707994, "biggest_recent_change": 0.060104709178887106},
{"total_number_of_episodes": 26870, "number_of_timesteps": 3068838, "per_episode_reward": -132.39, "episode_reward_trend_value": 0.00024864181660986005, "biggest_recent_change": 0.037429472828165444},
{"total_number_of_episodes": 26880, "number_of_timesteps": 3070190, "per_episode_reward": -132.43, "episode_reward_trend_value": -0.00023425297820646543, "biggest_recent_change": 0.037429472828165444},
{"total_number_of_episodes": 26890, "number_of_timesteps": 3071167, "per_episode_reward": -132.42, "episode_reward_trend_value": -0.0002614856983857155, "biggest_recent_change": 0.037429472828165444},
{"total_number_of_episodes": 26901, "number_of_timesteps": 3072417, "per_episode_reward": -132.44, "episode_reward_trend_value": -0.0004597746880569452, "biggest_recent_change": 0.037429472828165444},
{"total_number_of_episodes": 26912, "number_of_timesteps": 3073987, "per_episode_reward": -132.47, "episode_reward_trend_value": -0.0007364914434557729, "biggest_recent_change": 0.037429472828165444},
{"total_number_of_episodes": 26922, "number_of_timesteps": 3074749, "per_episode_reward": -132.44, "episode_reward_trend_value": -0.00030882354544069636, "biggest_recent_change": 0.037429472828165444},
{"total_number_of_episodes": 26932, "number_of_timesteps": 3075497, "per_episode_reward": -132.42, "episode_reward_trend_value": -0.00044115363959475775, "biggest_recent_change": 0.033985147410191985},
{"total_number_of_episodes": 26942, "number_of_timesteps": 3076281, "per_episode_reward": -132.37, "episode_reward_trend_value": -0.0002111193802752117, "biggest_recent_change": 0.050539406658145936},
{"total_number_of_episodes": 26954, "number_of_timesteps": 3077367, "per_episode_reward": -132.31, "episode_reward_trend_value": 0.0006964946219401075, "biggest_recent_change": 0.05609187356165535},
{"total_number_of_episodes": 26967, "number_of_timesteps": 3078773, "per_episode_reward": -132.27, "episode_reward_trend_value": 0.00138150908128662, "biggest_recent_change": 0.05609187356165535},
{"total_number_of_episodes": 26977, "number_of_timesteps": 3079787, "per_episode_reward": -132.22, "episode_reward_trend_value": 0.002246865062650411, "biggest_recent_change": 0.05609187356165535},
{"total_number_of_episodes": 26987, "number_of_timesteps": 3080935, "per_episode_reward": -132.24, "episode_reward_trend_value": 0.0019149762903977162, "biggest_recent_change": 0.05609187356165535},
{"total_number_of_episodes": 26997, "number_of_timesteps": 3082365, "per_episode_reward": -132.3, "episode_reward_trend_value": 0.0015500390100454651, "biggest_recent_change": 0.05932635525664409},
{"total_number_of_episodes": 27008, "number_of_timesteps": 3083551, "per_episode_reward": -132.24, "episode_reward_trend_value": 0.0025312895873317604, "biggest_recent_change": 0.0634080439698721},
{"total_number_of_episodes": 27018, "number_of_timesteps": 3084537, "per_episode_reward": -132.18, "episode_reward_trend_value": 0.0029354767887118287, "biggest_recent_change": 0.0634080439698721},
{"total_number_of_episodes": 27030, "number_of_timesteps": 3085745, "per_episode_reward": -132.2, "episode_reward_trend_value": 0.0023679536984818443, "biggest_recent_change": 0.0634080439698721},
{"total_number_of_episodes": 27040, "number_of_timesteps": 3086643, "per_episode_reward": -132.13, "episode_reward_trend_value": 0.0025837029496149928, "biggest_recent_change": 0.0699568392601293},
{"total_number_of_episodes": 27050, "number_of_timesteps": 3087989, "per_episode_reward": -132.15, "episode_reward_trend_value": 0.0017510894612832492, "biggest_recent_change": 0.0699568392601293},
{"total_number_of_episodes": 27061, "number_of_timesteps": 3089212, "per_episode_reward": -132.14, "episode_reward_trend_value": 0.0014053840290497673, "biggest_recent_change": 0.0699568392601293},
{"total_number_of_episodes": 27073, "number_of_timesteps": 3090892, "per_episode_reward": -132.08, "episode_reward_trend_value": 0.0016302469623863344, "biggest_recent_change": 0.0699568392601293},
{"total_number_of_episodes": 27083, "number_of_timesteps": 3091891, "per_episode_reward": -132.04, "episode_reward_trend_value": 0.0022996869398727742, "biggest_recent_change": 0.0699568392601293},
{"total_number_of_episodes": 27093, "number_of_timesteps": 3092888, "per_episode_reward": -132.04, "episode_reward_trend_value": 0.0028945289939722825, "biggest_recent_change": 0.0699568392601293},
{"total_number_of_episodes": 27104, "number_of_timesteps": 3094127, "per_episode_reward": -132.05, "episode_reward_trend_value": 0.0020403614156000076, "biggest_recent_change": 0.0699568392601293},
{"total_number_of_episodes": 27115, "number_of_timesteps": 3095331, "per_episode_reward": -132.01, "episode_reward_trend_value": 0.0019153701399492067, "biggest_recent_change": 0.0699568392601293},
{"total_number_of_episodes": 27125, "number_of_timesteps": 3096482, "per_episode_reward": -132.01, "episode_reward_trend_value": 0.002135775313435791, "biggest_recent_change": 0.0699568392601293},
{"total_number_of_episodes": 27135, "number_of_timesteps": 3097512, "per_episode_reward": -131.98, "episode_reward_trend_value": 0.0016666424386193688, "biggest_recent_change": 0.06413455491284026},
{"total_number_of_episodes": 27145, "number_of_timesteps": 3098496, "per_episode_reward": -131.97, "episode_reward_trend_value": 0.002087945939875466, "biggest_recent_change": 0.06413455491284026},
{"total_number_of_episodes": 27155, "number_of_timesteps": 3099815, "per_episode_reward": -131.97, "episode_reward_trend_value": 0.00188775098077877, "biggest_recent_change": 0.06413455491284026},
{"total_number_of_episodes": 27166, "number_of_timesteps": 3101305, "per_episode_reward": -131.99, "episode_reward_trend_value": 0.000977194367344383, "biggest_recent_change": 0.04814461698995842},
{"total_number_of_episodes": 27177, "number_of_timesteps": 3102305, "per_episode_reward": -131.87, "episode_reward_trend_value": 0.0017976689212484114, "biggest_recent_change": 0.11537841352867417},
{"total_number_of_episodes": 27187, "number_of_timesteps": 3103173, "per_episode_reward": -131.84, "episode_reward_trend_value": 0.002227239566181854, "biggest_recent_change": 0.11537841352867417},
{"total_number_of_episodes": 27197, "number_of_timesteps": 3104347, "per_episode_reward": -131.83, "episode_reward_trend_value": 0.002475170082984985, "biggest_recent_change": 0.11537841352867417},
{"total_number_of_episodes": 27207, "number_of_timesteps": 3105637, "per_episode_reward": -131.86, "episode_reward_trend_value": 0.0016550869357966273, "biggest_recent_change": 0.11537841352867417},
{"total_number_of_episodes": 27217, "number_of_timesteps": 3107166, "per_episode_reward": -131.9, "episode_reward_trend_value": 0.001241884991744276, "biggest_recent_change": 0.11537841352867417},
{"total_number_of_episodes": 27227, "number_of_timesteps": 3108533, "per_episode_reward": -131.91, "episode_reward_trend_value": 0.0007886264531369611, "biggest_recent_change": 0.11537841352867417},
{"total_number_of_episodes": 27237, "number_of_timesteps": 3109794, "per_episode_reward": -131.88, "episode_reward_trend_value": 0.0010071014156876699, "biggest_recent_change": 0.11537841352867417},
{"total_number_of_episodes": 27247, "number_of_timesteps": 3110634, "per_episode_reward": -131.87, "episode_reward_trend_value": 0.0010985606095065097, "biggest_recent_change": 0.11537841352867417},
{"total_number_of_episodes": 27257, "number_of_timesteps": 3111670, "per_episode_reward": -131.84, "episode_reward_trend_value": 0.0016719681613131519, "biggest_recent_change": 0.11537841352867417},
{"total_number_of_episodes": 27267, "number_of_timesteps": 3112670, "per_episode_reward": -131.85, "episode_reward_trend_value": 0.00031721853476811805, "biggest_recent_change": 0.0429090231173177},
{"total_number_of_episodes": 27278, "number_of_timesteps": 3113470, "per_episode_reward": -131.83, "episode_reward_trend_value": 0.0001414977626584207, "biggest_recent_change": 0.0429090231173177},
{"total_number_of_episodes": 27288, "number_of_timesteps": 3114319, "per_episode_reward": -131.81, "episode_reward_trend_value": 0.00019877056016860526, "biggest_recent_change": 0.0429090231173177},
{"total_number_of_episodes": 27298, "number_of_timesteps": 3115306, "per_episode_reward": -131.81, "episode_reward_trend_value": 0.0005263398294191448, "biggest_recent_change": 0.0429090231173177},
{"total_number_of_episodes": 27308, "number_of_timesteps": 3116335, "per_episode_reward": -131.82, "episode_reward_trend_value": 0.0008519484377990871, "biggest_recent_change": 0.038736721354410975},
{"total_number_of_episodes": 27318, "number_of_timesteps": 3117481, "per_episode_reward": -131.83, "episode_reward_trend_value": 0.0009070030813590948, "biggest_recent_change": 0.038736721354410975},
{"total_number_of_episodes": 27329, "number_of_timesteps": 3118901, "per_episode_reward": -131.83, "episode_reward_trend_value": 0.000448840393030044, "biggest_recent_change": 0.03379113936634326},
{"total_number_of_episodes": 27339, "number_of_timesteps": 3120032, "per_episode_reward": -131.84, "episode_reward_trend_value": 0.00040325396920195546, "biggest_recent_change": 0.03379113936634326},
{"total_number_of_episodes": 27349, "number_of_timesteps": 3120958, "per_episode_reward": -131.81, "episode_reward_trend_value": 0.0003434860928652799, "biggest_recent_change": 0.028412030496042462},
{"total_number_of_episodes": 27359, "number_of_timesteps": 3121895, "per_episode_reward": -131.79, "episode_reward_trend_value": 0.0006490394323495568, "biggest_recent_change": 0.028412030496042462},
{"total_number_of_episodes": 27370, "number_of_timesteps": 3123150, "per_episode_reward": -131.82, "episode_reward_trend_value": 0.00014198010883951105, "biggest_recent_change": 0.028579420949455425},
{"total_number_of_episodes": 27380, "number_of_timesteps": 3123976, "per_episode_reward": -131.78, "episode_reward_trend_value": 0.0004226605749298389, "biggest_recent_change": 0.03926250215269533},
{"total_number_of_episodes": 27390, "number_of_timesteps": 3125122, "per_episode_reward": -131.81, "episode_reward_trend_value": -4.951044576999822e-05, "biggest_recent_change": 0.03926250215269533},
{"total_number_of_episodes": 27400, "number_of_timesteps": 3126406, "per_episode_reward": -131.79, "episode_reward_trend_value": 0.0003822121109727227, "biggest_recent_change": 0.03926250215269533},
{"total_number_of_episodes": 27410, "number_of_timesteps": 3127258, "per_episode_reward": -131.78, "episode_reward_trend_value": 0.0005531466649734461, "biggest_recent_change": 0.03926250215269533},
{"total_number_of_episodes": 27420, "number_of_timesteps": 3128534, "per_episode_reward": -131.82, "episode_reward_trend_value": 0.0001993787400800152, "biggest_recent_change": 0.03926250215269533},
{"total_number_of_episodes": 27431, "number_of_timesteps": 3130097, "per_episode_reward": -131.81, "episode_reward_trend_value": 0.0003359531626380708, "biggest_recent_change": 0.03926250215269533},
{"total_number_of_episodes": 27442, "number_of_timesteps": 3130939, "per_episode_reward": -131.67, "episode_reward_trend_value": 0.0014961076078239758, "biggest_recent_change": 0.13282593056277392},
{"total_number_of_episodes": 27452, "number_of_timesteps": 3132272, "per_episode_reward": -131.66, "episode_reward_trend_value": 0.001362832836238681, "biggest_recent_change": 0.13282593056277392},
{"total_number_of_episodes": 27462, "number_of_timesteps": 3133289, "per_episode_reward": -131.66, "episode_reward_trend_value": 0.0017770061874519644, "biggest_recent_change": 0.13282593056277392},
{"total_number_of_episodes": 27472, "number_of_timesteps": 3134758, "per_episode_reward": -131.67, "episode_reward_trend_value": 0.001220284261099399, "biggest_recent_change": 0.13282593056277392},
{"total_number_of_episodes": 27482, "number_of_timesteps": 3135646, "per_episode_reward": -131.66, "episode_reward_trend_value": 0.0017499309527724764, "biggest_recent_change": 0.13282593056277392},
{"total_number_of_episodes": 27492, "number_of_timesteps": 3136639, "per_episode_reward": -131.67, "episode_reward_trend_value": 0.0013129321323857666, "biggest_recent_change": 0.13282593056277392},
{"total_number_of_episodes": 27503, "number_of_timesteps": 3137945, "per_episode_reward": -131.69, "episode_reward_trend_value": 0.0010719212443029214, "biggest_recent_change": 0.13282593056277392},
{"total_number_of_episodes": 27513, "number_of_timesteps": 3139085, "per_episode_reward": -131.69, "episode_reward_trend_value": 0.0013979479285088322, "biggest_recent_change": 0.13282593056277392},
{"total_number_of_episodes": 27524, "number_of_timesteps": 3140277, "per_episode_reward": -131.69, "episode_reward_trend_value": 0.0013268308959355738, "biggest_recent_change": 0.13282593056277392},
{"total_number_of_episodes": 27535, "number_of_timesteps": 3141487, "per_episode_reward": -131.65, "episode_reward_trend_value": 0.00023609689901604725, "biggest_recent_change": 0.03465987084001654},
{"total_number_of_episodes": 27546, "number_of_timesteps": 3142626, "per_episode_reward": -131.66, "episode_reward_trend_value": 4.8100427742446704e-05, "biggest_recent_change": 0.03465987084001654},
{"total_number_of_episodes": 27556, "number_of_timesteps": 3143679, "per_episode_reward": -131.66, "episode_reward_trend_value": -6.0818713438000794e-05, "biggest_recent_change": 0.03465987084001654},
{"total_number_of_episodes": 27566, "number_of_timesteps": 3144852, "per_episode_reward": -131.69, "episode_reward_trend_value": -0.00023697132962594323, "biggest_recent_change": 0.03465987084001654},
{"total_number_of_episodes": 27576, "number_of_timesteps": 3145845, "per_episode_reward": -131.7, "episode_reward_trend_value": -0.00045699511502290437, "biggest_recent_change": 0.03465987084001654},
{"total_number_of_episodes": 27586, "number_of_timesteps": 3146793, "per_episode_reward": -131.69, "episode_reward_trend_value": -0.00025477509183089196, "biggest_recent_change": 0.03465987084001654},
{"total_number_of_episodes": 27596, "number_of_timesteps": 3147814, "per_episode_reward": -131.69, "episode_reward_trend_value": -4.759000156424362e-05, "biggest_recent_change": 0.03465987084001654},
{"total_number_of_episodes": 27607, "number_of_timesteps": 3149002, "per_episode_reward": -131.67, "episode_reward_trend_value": 0.00020660820621761408, "biggest_recent_change": 0.03465987084001654},
{"total_number_of_episodes": 27617, "number_of_timesteps": 3150407, "per_episode_reward": -131.75, "episode_reward_trend_value": -0.0006628751279227648, "biggest_recent_change": 0.07398147161242719},
{"total_number_of_episodes": 27627, "number_of_timesteps": 3151772, "per_episode_reward": -131.78, "episode_reward_trend_value": -0.0013970689854217097, "biggest_recent_change": 0.07398147161242719},
{"total_number_of_episodes": 27637, "number_of_timesteps": 3153526, "per_episode_reward": -131.8, "episode_reward_trend_value": -0.0015129728408058755, "biggest_recent_change": 0.07398147161242719},
{"total_number_of_episodes": 27648, "number_of_timesteps": 3154324, "per_episode_reward": -131.74, "episode_reward_trend_value": -0.0009279129404098462, "biggest_recent_change": 0.07398147161242719},
{"total_number_of_episodes": 27660, "number_of_timesteps": 3155112, "per_episode_reward": -131.62, "episode_reward_trend_value": 0.0007098469488359645, "biggest_recent_change": 0.12070218335617255},
{"total_number_of_episodes": 27670, "number_of_timesteps": 3155937, "per_episode_reward": -131.62, "episode_reward_trend_value": 0.0009142611701384517, "biggest_recent_change": 0.12070218335617255},
{"total_number_of_episodes": 27680, "number_of_timesteps": 3156995, "per_episode_reward": -131.71, "episode_reward_trend_value": -0.00015206459410042802, "biggest_recent_change": 0.12070218335617255},
{"total_number_of_episodes": 27690, "number_of_timesteps": 3158081, "per_episode_reward": -131.74, "episode_reward_trend_value": -0.0006003539714536525, "biggest_recent_change": 0.12070218335617255},
{"total_number_of_episodes": 27700, "number_of_timesteps": 3159646, "per_episode_reward": -131.72, "episode_reward_trend_value": -0.0005768657808516764, "biggest_recent_change": 0.12070218335617255},
{"total_number_of_episodes": 27712, "number_of_timesteps": 3161065, "per_episode_reward": -131.8, "episode_reward_trend_value": -0.0005830935551188077, "biggest_recent_change": 0.12070218335617255},
{"total_number_of_episodes": 27722, "number_of_timesteps": 3162095, "per_episode_reward": -131.79, "episode_reward_trend_value": -0.00010159685111293333, "biggest_recent_change": 0.12070218335617255},
{"total_number_of_episodes": 27732, "number_of_timesteps": 3163169, "per_episode_reward": -131.75, "episode_reward_trend_value": 0.0005296182457091921, "biggest_recent_change": 0.12070218335617255},
{"total_number_of_episodes": 27742, "number_of_timesteps": 3164345, "per_episode_reward": -131.75, "episode_reward_trend_value": -1.2997254016985002e-05, "biggest_recent_change": 0.12070218335617255},
{"total_number_of_episodes": 27752, "number_of_timesteps": 3166017, "per_episode_reward": -131.75, "episode_reward_trend_value": -0.0013843565468012761, "biggest_recent_change": 0.09184862878529998},
{"total_number_of_episodes": 27762, "number_of_timesteps": 3167300, "per_episode_reward": -131.72, "episode_reward_trend_value": -0.0011937834585820737, "biggest_recent_change": 0.09184862878529998},
{"total_number_of_episodes": 27773, "number_of_timesteps": 3168481, "per_episode_reward": -131.69, "episode_reward_trend_value": 0.0002394800789488727, "biggest_recent_change": 0.074541971296469},
{"total_number_of_episodes": 27784, "number_of_timesteps": 3170507, "per_episode_reward": -131.65, "episode_reward_trend_value": 0.001005286197996232, "biggest_recent_change": 0.074541971296469},
{"total_number_of_episodes": 27794, "number_of_timesteps": 3171514, "per_episode_reward": -131.63, "episode_reward_trend_value": 0.0010665852877145376, "biggest_recent_change": 0.074541971296469},
{"total_number_of_episodes": 27804, "number_of_timesteps": 3172978, "per_episode_reward": -131.58, "episode_reward_trend_value": 0.0024867064132785624, "biggest_recent_change": 0.053268930004293225},
{"total_number_of_episodes": 27814, "number_of_timesteps": 3174053, "per_episode_reward": -131.63, "episode_reward_trend_value": 0.0017623626755490958, "biggest_recent_change": 0.053273809370011804},
{"total_number_of_episodes": 27824, "number_of_timesteps": 3175328, "per_episode_reward": -131.68, "episode_reward_trend_value": 0.0007814712394835825, "biggest_recent_change": 0.053273809370011804},
{"total_number_of_episodes": 27834, "number_of_timesteps": 3176612, "per_episode_reward": -131.59, "episode_reward_trend_value": 0.0016805430686228345, "biggest_recent_change": 0.08362991863631919},
{"total_number_of_episodes": 27845, "number_of_timesteps": 3177955, "per_episode_reward": -131.63, "episode_reward_trend_value": 0.0013538042497689023, "biggest_recent_change": 0.08362991863631919},
{"total_number_of_episodes": 27856, "number_of_timesteps": 3179499, "per_episode_reward": -131.63, "episode_reward_trend_value": 0.0009987761767465346, "biggest_recent_change": 0.08362991863631919},
{"total_number_of_episodes": 27867, "number_of_timesteps": 3180361, "per_episode_reward": -131.6, "episode_reward_trend_value": 0.0010013858637020374, "biggest_recent_change": 0.08362991863631919},
{"total_number_of_episodes": 27878, "number_of_timesteps": 3181651, "per_episode_reward": -131.62, "episode_reward_trend_value": 0.00041041124721093386, "biggest_recent_change": 0.08362991863631919},
{"total_number_of_episodes": 27888, "number_of_timesteps": 3182871, "per_episode_reward": -131.63, "episode_reward_trend_value": -9.236787309734811e-06, "biggest_recent_change": 0.08362991863631919},
{"total_number_of_episodes": 27899, "number_of_timesteps": 3184348, "per_episode_reward": -131.61, "episode_reward_trend_value": -0.00036063878489724424, "biggest_recent_change": 0.08362991863631919},
{"total_number_of_episodes": 27909, "number_of_timesteps": 3185514, "per_episode_reward": -131.58, "episode_reward_trend_value": 0.0004987143458398198, "biggest_recent_change": 0.08362991863631919},
{"total_number_of_episodes": 27919, "number_of_timesteps": 3186461, "per_episode_reward": -131.57, "episode_reward_trend_value": 0.0012110789456067374, "biggest_recent_change": 0.08362991863631919},
{"total_number_of_episodes": 27930, "number_of_timesteps": 3187697, "per_episode_reward": -131.56, "episode_reward_trend_value": 0.00034865682576960605, "biggest_recent_change": 0.037379961418480434},
{"total_number_of_episodes": 27940, "number_of_timesteps": 3188842, "per_episode_reward": -131.58, "episode_reward_trend_value": 0.0004981898598111279, "biggest_recent_change": 0.037379961418480434},
{"total_number_of_episodes": 27952, "number_of_timesteps": 3190481, "per_episode_reward": -131.59, "episode_reward_trend_value": 0.0005193457612351595, "biggest_recent_change": 0.037379961418480434},
{"total_number_of_episodes": 27963, "number_of_timesteps": 3191495, "per_episode_reward": -131.55, "episode_reward_trend_value": 0.0005165556489114604, "biggest_recent_change": 0.03712885130934751},
{"total_number_of_episodes": 27973, "number_of_timesteps": 3192436, "per_episode_reward": -131.51, "episode_reward_trend_value": 0.0011836114480896893, "biggest_recent_change": 0.039660131223314465},
{"total_number_of_episodes": 27983, "number_of_timesteps": 3193504, "per_episode_reward": -131.57, "episode_reward_trend_value": 0.0007102405719494855, "biggest_recent_change": 0.054857640287366394},
{"total_number_of_episodes": 27993, "number_of_timesteps": 3194673, "per_episode_reward": -131.55, "episode_reward_trend_value": 0.0006526997524553558, "biggest_recent_change": 0.054857640287366394},
{"total_number_of_episodes": 28003, "number_of_timesteps": 3195601, "per_episode_reward": -131.52, "episode_reward_trend_value": 0.0006881275131051881, "biggest_recent_change": 0.054857640287366394},
{"total_number_of_episodes": 28013, "number_of_timesteps": 3196373, "per_episode_reward": -131.47, "episode_reward_trend_value": 0.001075072988282639, "biggest_recent_change": 0.054857640287366394},
{"total_number_of_episodes": 28024, "number_of_timesteps": 3197596, "per_episode_reward": -131.49, "episode_reward_trend_value": 0.0008612352102488785, "biggest_recent_change": 0.054857640287366394},
{"total_number_of_episodes": 28034, "number_of_timesteps": 3198681, "per_episode_reward": -131.5, "episode_reward_trend_value": 0.000936268511759724, "biggest_recent_change": 0.054857640287366394},
{"total_number_of_episodes": 28045, "number_of_timesteps": 3199998, "per_episode_reward": -131.48, "episode_reward_trend_value": 0.0011735891827726163, "biggest_recent_change": 0.054857640287366394},
{"total_number_of_episodes": 28055, "number_of_timesteps": 3201720, "per_episode_reward": -131.5, "episode_reward_trend_value": 0.0005368402283728023, "biggest_recent_change": 0.054857640287366394},
{"total_number_of_episodes": 28065, "number_of_timesteps": 3202591, "per_episode_reward": -131.47, "episode_reward_trend_value": 0.0005015852380852139, "biggest_recent_change": 0.054857640287366394},
{"total_number_of_episodes": 28075, "number_of_timesteps": 3203423, "per_episode_reward": -131.46, "episode_reward_trend_value": 0.0011321204467306088, "biggest_recent_change": 0.04907202506441877},
{"total_number_of_episodes": 28085, "number_of_timesteps": 3204141, "per_episode_reward": -131.44, "episode_reward_trend_value": 0.0011712960975463224, "biggest_recent_change": 0.04907202506441877},
{"total_number_of_episodes": 28097, "number_of_timesteps": 3205340, "per_episode_reward": -131.45, "episode_reward_trend_value": 0.0008274710726362223, "biggest_recent_change": 0.04907202506441877},
{"total_number_of_episodes": 28107, "number_of_timesteps": 3206542, "per_episode_reward": -131.48, "episode_reward_trend_value": -9.030516897389084e-05, "biggest_recent_change": 0.036487182097431514},
{"total_number_of_episodes": 28117, "number_of_timesteps": 3207824, "per_episode_reward": -131.48, "episode_reward_trend_value": 0.00010740238445079184, "biggest_recent_change": 0.036487182097431514},
{"total_number_of_episodes": 28127, "number_of_timesteps": 3208825, "per_episode_reward": -131.43, "episode_reward_trend_value": 0.0007123398072656705, "biggest_recent_change": 0.042528691561784626},
{"total_number_of_episodes": 28137, "number_of_timesteps": 3209780, "per_episode_reward": -131.4, "episode_reward_trend_value": 0.0009466586090582041, "biggest_recent_change": 0.042528691561784626},
{"total_number_of_episodes": 28148, "number_of_timesteps": 3210784, "per_episode_reward": -131.38, "episode_reward_trend_value": 0.0013621492032440427, "biggest_recent_change": 0.042528691561784626},
{"total_number_of_episodes": 28159, "number_of_timesteps": 3212161, "per_episode_reward": -131.38, "episode_reward_trend_value": 0.0009234885678867814, "biggest_recent_change": 0.042528691561784626},
{"total_number_of_episodes": 28169, "number_of_timesteps": 3213154, "per_episode_reward": -131.35, "episode_reward_trend_value": 0.0012229720816650217, "biggest_recent_change": 0.042528691561784626},
{"total_number_of_episodes": 28179, "number_of_timesteps": 3214430, "per_episode_reward": -131.37, "episode_reward_trend_value": 0.000829241599669217, "biggest_recent_change": 0.042528691561784626},
{"total_number_of_episodes": 28189, "number_of_timesteps": 3215560, "per_episode_reward": -131.36, "episode_reward_trend_value": 0.0009264170631104839, "biggest_recent_change": 0.042528691561784626},
{"total_number_of_episodes": 28199, "number_of_timesteps": 3216740, "per_episode_reward": -131.32, "episode_reward_trend_value": 0.0018249459723386333, "biggest_recent_change": 0.04733976515004201},
{"total_number_of_episodes": 28209, "number_of_timesteps": 3217675, "per_episode_reward": -131.3, "episode_reward_trend_value": 0.0019647187086683795, "biggest_recent_change": 0.04733976515004201},
{"total_number_of_episodes": 28219, "number_of_timesteps": 3218787, "per_episode_reward": -131.27, "episode_reward_trend_value": 0.0017789535031684837, "biggest_recent_change": 0.04733976515004201},
{"total_number_of_episodes": 28229, "number_of_timesteps": 3219846, "per_episode_reward": -131.32, "episode_reward_trend_value": 0.0009000925814967155, "biggest_recent_change": 0.04733976515004201},
{"total_number_of_episodes": 28239, "number_of_timesteps": 3221280, "per_episode_reward": -131.34, "episode_reward_trend_value": 0.0004631966421824372, "biggest_recent_change": 0.04733976515004201},
{"total_number_of_episodes": 28249, "number_of_timesteps": 3222602, "per_episode_reward": -131.39, "episode_reward_trend_value": -9.056480418413078e-05, "biggest_recent_change": 0.05283080525771311},
{"total_number_of_episodes": 28259, "number_of_timesteps": 3223711, "per_episode_reward": -131.39, "episode_reward_trend_value": -0.000399129687053485, "biggest_recent_change": 0.05283080525771311},
{"total_number_of_episodes": 28270, "number_of_timesteps": 3225187, "per_episode_reward": -131.41, "episode_reward_trend_value": -0.00045073035373945915, "biggest_recent_change": 0.05283080525771311},
{"total_number_of_episodes": 28280, "number_of_timesteps": 3226217, "per_episode_reward": -131.41, "episode_reward_trend_value": -0.0005700479051515433, "biggest_recent_change": 0.05283080525771311},
{"total_number_of_episodes": 28290, "number_of_timesteps": 3227213, "per_episode_reward": -131.4, "episode_reward_trend_value": -0.0009085723664526313, "biggest_recent_change": 0.05283080525771311},
{"total_number_of_episodes": 28300, "number_of_timesteps": 3228546, "per_episode_reward": -131.41, "episode_reward_trend_value": -0.001260032990141566, "biggest_recent_change": 0.05283080525771311},
{"total_number_of_episodes": 28310, "number_of_timesteps": 3229980, "per_episode_reward": -131.43, "episode_reward_trend_value": -0.0017032768562791664, "biggest_recent_change": 0.05283080525771311},
{"total_number_of_episodes": 28320, "number_of_timesteps": 3231028, "per_episode_reward": -131.44, "episode_reward_trend_value": -0.0013940024898475814, "biggest_recent_change": 0.05283080525771311},
{"total_number_of_episodes": 28330, "number_of_timesteps": 3232019, "per_episode_reward": -131.39, "episode_reward_trend_value": -0.0006067459551347711, "biggest_recent_change": 0.05283080525771311},
{"total_number_of_episodes": 28340, "number_of_timesteps": 3232974, "per_episode_reward": -131.37, "episode_reward_trend_value": 0.00021541349018087253, "biggest_recent_change": 0.04874805247595759},
{"total_number_of_episodes": 28350, "number_of_timesteps": 3233806, "per_episode_reward": -131.34, "episode_reward_trend_value": 0.0005572726936460665, "biggest_recent_change": 0.04874805247595759},
{"total_number_of_episodes": 28360, "number_of_timesteps": 3234682, "per_episode_reward": -131.33, "episode_reward_trend_value": 0.000857634187424752, "biggest_recent_change": 0.04874805247595759},
{"total_number_of_episodes": 28370, "number_of_timesteps": 3235783, "per_episode_reward": -131.38, "episode_reward_trend_value": 0.00038955979918063756, "biggest_recent_change": 0.04874805247595759},
{"total_number_of_episodes": 28380, "number_of_timesteps": 3237005, "per_episode_reward": -131.4, "episode_reward_trend_value": -2.303290183805176e-05, "biggest_recent_change": 0.04874805247595759},
{"total_number_of_episodes": 28390, "number_of_timesteps": 3238439, "per_episode_reward": -131.45, "episode_reward_trend_value": -0.00042303082212811203, "biggest_recent_change": 0.05049151505227201},
{"total_number_of_episodes": 28400, "number_of_timesteps": 3239773, "per_episode_reward": -131.43, "episode_reward_trend_value": -1.4767841689907377e-05, "biggest_recent_change": 0.05049151505227201},
{"total_number_of_episodes": 28410, "number_of_timesteps": 3240654, "per_episode_reward": -131.4, "episode_reward_trend_value": 0.00045377131135321887, "biggest_recent_change": 0.05049151505227201},
{"total_number_of_episodes": 28420, "number_of_timesteps": 3241765, "per_episode_reward": -131.44, "episode_reward_trend_value": -0.0004987410960432549, "biggest_recent_change": 0.05049151505227201},
{"total_number_of_episodes": 28431, "number_of_timesteps": 3243105, "per_episode_reward": -131.42, "episode_reward_trend_value": -0.0005174119222134423, "biggest_recent_change": 0.05049151505227201},
{"total_number_of_episodes": 28441, "number_of_timesteps": 3244191, "per_episode_reward": -131.42, "episode_reward_trend_value": -0.0009045743125808612, "biggest_recent_change": 0.05049151505227201},
{"total_number_of_episodes": 28451, "number_of_timesteps": 3245162, "per_episode_reward": -131.39, "episode_reward_trend_value": -0.000653879542106021, "biggest_recent_change": 0.05049151505227201},
{"total_number_of_episodes": 28461, "number_of_timesteps": 3246187, "per_episode_reward": -131.38, "episode_reward_trend_value": -1.8112961681835156e-06, "biggest_recent_change": 0.05049151505227201},
{"total_number_of_episodes": 28471, "number_of_timesteps": 3247562, "per_episode_reward": -131.38, "episode_reward_trend_value": 0.00021094716821734336, "biggest_recent_change": 0.05049151505227201},
{"total_number_of_episodes": 28481, "number_of_timesteps": 3248253, "per_episode_reward": -131.27, "episode_reward_trend_value": 0.002056058003554047, "biggest_recent_change": 0.11556846012803135},
{"total_number_of_episodes": 28491, "number_of_timesteps": 3249148, "per_episode_reward": -131.25, "episode_reward_trend_value": 0.0019728928107105677, "biggest_recent_change": 0.11556846012803135},
{"total_number_of_episodes": 28502, "number_of_timesteps": 3250313, "per_episode_reward": -131.24, "episode_reward_trend_value": 0.0017591958785468857, "biggest_recent_change": 0.11556846012803135},
{"total_number_of_episodes": 28512, "number_of_timesteps": 3251338, "per_episode_reward": -131.25, "episode_reward_trend_value": 0.0020378038105194366, "biggest_recent_change": 0.11556846012803135},
{"total_number_of_episodes": 28522, "number_of_timesteps": 3252453, "per_episode_reward": -131.26, "episode_reward_trend_value": 0.0017995042207038143, "biggest_recent_change": 0.11556846012803135},
{"total_number_of_episodes": 28532, "number_of_timesteps": 3253361, "per_episode_reward": -131.22, "episode_reward_trend_value": 0.0022103291405471738, "biggest_recent_change": 0.11556846012803135},
{"total_number_of_episodes": 28542, "number_of_timesteps": 3254198, "per_episode_reward": -131.2, "episode_reward_trend_value": 0.0021589915893097593, "biggest_recent_change": 0.11556846012803135},
{"total_number_of_episodes": 28552, "number_of_timesteps": 3255142, "per_episode_reward": -131.19, "episode_reward_trend_value": 0.002086176117667391, "biggest_recent_change": 0.11556846012803135},
{"total_number_of_episodes": 28562, "number_of_timesteps": 3256340, "per_episode_reward": -131.19, "episode_reward_trend_value": 0.002073884905737739, "biggest_recent_change": 0.11556846012803135},
{"total_number_of_episodes": 28572, "number_of_timesteps": 3257622, "per_episode_reward": -131.21, "episode_reward_trend_value": 0.0005690761332642878, "biggest_recent_change": 0.033970161237220964},
{"total_number_of_episodes": 28582, "number_of_timesteps": 3258650, "per_episode_reward": -131.22, "episode_reward_trend_value": 0.00037024861957206666, "biggest_recent_change": 0.033970161237220964},
{"total_number_of_episodes": 28592, "number_of_timesteps": 3259704, "per_episode_reward": -131.21, "episode_reward_trend_value": 0.00038472625744974365, "biggest_recent_change": 0.033970161237220964},
{"total_number_of_episodes": 28602, "number_of_timesteps": 3260741, "per_episode_reward": -131.19, "episode_reward_trend_value": 0.0006947739737540815, "biggest_recent_change": 0.033970161237220964},
{"total_number_of_episodes": 28612, "number_of_timesteps": 3262017, "per_episode_reward": -131.21, "episode_reward_trend_value": 0.0005516520308128115, "biggest_recent_change": 0.033970161237220964},
{"total_number_of_episodes": 28623, "number_of_timesteps": 3263272, "per_episode_reward": -131.19, "episode_reward_trend_value": 0.0003041840941790497, "biggest_recent_change": 0.02488476583044985},
{"total_number_of_episodes": 28633, "number_of_timesteps": 3264299, "per_episode_reward": -131.17, "episode_reward_trend_value": 0.00024658913921705837, "biggest_recent_change": 0.019864329394579272},
{"total_number_of_episodes": 28643, "number_of_timesteps": 3265721, "per_episode_reward": -131.18, "episode_reward_trend_value": 8.955092482160075e-05, "biggest_recent_change": 0.019864329394579272},
{"total_number_of_episodes": 28653, "number_of_timesteps": 3266723, "per_episode_reward": -131.16, "episode_reward_trend_value": 0.0003957122255346551, "biggest_recent_change": 0.025335790326465712},
{"total_number_of_episodes": 28663, "number_of_timesteps": 3267989, "per_episode_reward": -131.13, "episode_reward_trend_value": 0.0009078892698609151, "biggest_recent_change": 0.02623160459478413},
{"total_number_of_episodes": 28674, "number_of_timesteps": 3269192, "per_episode_reward": -131.11, "episode_reward_trend_value": 0.0011693059727987374, "biggest_recent_change": 0.02623160459478413},
{"total_number_of_episodes": 28684, "number_of_timesteps": 3270280, "per_episode_reward": -131.22, "episode_reward_trend_value": -0.00010130082922993704, "biggest_recent_change": 0.1042416622230462},
{"total_number_of_episodes": 28694, "number_of_timesteps": 3271203, "per_episode_reward": -131.1, "episode_reward_trend_value": 0.001004085840283627, "biggest_recent_change": 0.11548574441141568},
{"total_number_of_episodes": 28704, "number_of_timesteps": 3272295, "per_episode_reward": -131.12, "episode_reward_trend_value": 0.000909130881474122, "biggest_recent_change": 0.11548574441141568},
{"total_number_of_episodes": 28715, "number_of_timesteps": 3273588, "per_episode_reward": -131.09, "episode_reward_trend_value": 0.0011678195454531228, "biggest_recent_change": 0.11548574441141568},
{"total_number_of_episodes": 28726, "number_of_timesteps": 3274780, "per_episode_reward": -131.1, "episode_reward_trend_value": 0.000812316832384378, "biggest_recent_change": 0.11548574441141568},
{"total_number_of_episodes": 28736, "number_of_timesteps": 3276154, "per_episode_reward": -131.11, "episode_reward_trend_value": 0.0008142350967700749, "biggest_recent_change": 0.11548574441141568},
{"total_number_of_episodes": 28747, "number_of_timesteps": 3277593, "per_episode_reward": -131.13, "episode_reward_trend_value": 0.0003445989610987176, "biggest_recent_change": 0.11548574441141568},
{"total_number_of_episodes": 28757, "number_of_timesteps": 3278820, "per_episode_reward": -131.16, "episode_reward_trend_value": -0.0002784328959661606, "biggest_recent_change": 0.11548574441141568},
{"total_number_of_episodes": 28768, "number_of_timesteps": 3280128, "per_episode_reward": -131.15, "episode_reward_trend_value": -0.00043009150481875875, "biggest_recent_change": 0.11548574441141568},
{"total_number_of_episodes": 28778, "number_of_timesteps": 3281120, "per_episode_reward": -131.19, "episode_reward_trend_value": 0.0003379678202034281, "biggest_recent_change": 0.11548574441141568},
{"total_number_of_episodes": 28789, "number_of_timesteps": 3282457, "per_episode_reward": -131.2, "episode_reward_trend_value": -0.0011101971768391018, "biggest_recent_change": 0.035116322971049385},
{"total_number_of_episodes": 28799, "number_of_timesteps": 3283827, "per_episode_reward": -131.2, "episode_reward_trend_value": -0.0008668281531116564, "biggest_recent_change": 0.035116322971049385},
{"total_number_of_episodes": 28809, "number_of_timesteps": 3285157, "per_episode_reward": -131.21, "episode_reward_trend_value": -0.0013165458938885876, "biggest_recent_change": 0.035116322971049385},
{"total_number_of_episodes": 28819, "number_of_timesteps": 3286185, "per_episode_reward": -131.17, "episode_reward_trend_value": -0.0008118144577470806, "biggest_recent_change": 0.035116322971049385},
{"total_number_of_episodes": 28829, "number_of_timesteps": 3287180, "per_episode_reward": -131.15, "episode_reward_trend_value": -0.0004700050728811473, "biggest_recent_change": 0.035116322971049385},
{"total_number_of_episodes": 28840, "number_of_timesteps": 3288494, "per_episode_reward": -131.15, "episode_reward_trend_value": -0.0002776945287611928, "biggest_recent_change": 0.035116322971049385},
{"total_number_of_episodes": 28850, "number_of_timesteps": 3289654, "per_episode_reward": -131.15, "episode_reward_trend_value": 6.637609226092738e-05, "biggest_recent_change": 0.035116322971049385},
{"total_number_of_episodes": 28860, "number_of_timesteps": 3291068, "per_episode_reward": -131.18, "episode_reward_trend_value": -0.0003292630386978443, "biggest_recent_change": 0.035116322971049385},
{"total_number_of_episodes": 28870, "number_of_timesteps": 3292488, "per_episode_reward": -131.21, "episode_reward_trend_value": -0.000320546568511304, "biggest_recent_change": 0.03433184065426076},
{"total_number_of_episodes": 28880, "number_of_timesteps": 3293821, "per_episode_reward": -131.22, "episode_reward_trend_value": -0.00020865842519255138, "biggest_recent_change": 0.03433184065426076},
{"total_number_of_episodes": 28890, "number_of_timesteps": 3295164, "per_episode_reward": -131.22, "episode_reward_trend_value": -0.00015438959120154372, "biggest_recent_change": 0.03433184065426076},
{"total_number_of_episodes": 28900, "number_of_timesteps": 3295938, "per_episode_reward": -131.19, "episode_reward_trend_value": 0.00024812242673798813, "biggest_recent_change": 0.03433184065426076},
{"total_number_of_episodes": 28910, "number_of_timesteps": 3296777, "per_episode_reward": -131.16, "episode_reward_trend_value": 0.0001279737718290461, "biggest_recent_change": 0.03433184065426076},
{"total_number_of_episodes": 28920, "number_of_timesteps": 3297731, "per_episode_reward": -131.17, "episode_reward_trend_value": -0.00018022268477548348, "biggest_recent_change": 0.03433184065426076},
{"total_number_of_episodes": 28930, "number_of_timesteps": 3298951, "per_episode_reward": -131.18, "episode_reward_trend_value": -0.00034289677087713245, "biggest_recent_change": 0.03433184065426076},
{"total_number_of_episodes": 28940, "number_of_timesteps": 3299922, "per_episode_reward": -131.16, "episode_reward_trend_value": -0.00010078501319191622, "biggest_recent_change": 0.03433184065426076},
{"total_number_of_episodes": 28950, "number_of_timesteps": 3300880, "per_episode_reward": -131.14, "episode_reward_trend_value": 0.00042481216997442874, "biggest_recent_change": 0.03433184065426076},
{"total_number_of_episodes": 28960, "number_of_timesteps": 3301787, "per_episode_reward": -131.09, "episode_reward_trend_value": 0.0013287057660739442, "biggest_recent_change": 0.047018582994695635},
{"total_number_of_episodes": 28971, "number_of_timesteps": 3302773, "per_episode_reward": -131.06, "episode_reward_trend_value": 0.0017682789861456487, "biggest_recent_change": 0.047018582994695635},
{"total_number_of_episodes": 28981, "number_of_timesteps": 3304789, "per_episode_reward": -131.04, "episode_reward_trend_value": 0.0019592390860007454, "biggest_recent_change": 0.047018582994695635},
{"total_number_of_episodes": 28991, "number_of_timesteps": 3305575, "per_episode_reward": -130.98, "episode_reward_trend_value": 0.002278807328070798, "biggest_recent_change": 0.05949265342923127},
{"total_number_of_episodes": 29002, "number_of_timesteps": 3306564, "per_episode_reward": -130.9, "episode_reward_trend_value": 0.0029322816265246526, "biggest_recent_change": 0.0811311128794614},
{"total_number_of_episodes": 29012, "number_of_timesteps": 3308030, "per_episode_reward": -130.92, "episode_reward_trend_value": 0.0028015815362095963, "biggest_recent_change": 0.0811311128794614},
{"total_number_of_episodes": 29022, "number_of_timesteps": 3309163, "per_episode_reward": -130.9, "episode_reward_trend_value": 0.0031352369577297796, "biggest_recent_change": 0.0811311128794614},
{"total_number_of_episodes": 29032, "number_of_timesteps": 3310415, "per_episode_reward": -130.89, "episode_reward_trend_value": 0.003046620317151236, "biggest_recent_change": 0.0811311128794614},
{"total_number_of_episodes": 29042, "number_of_timesteps": 3311493, "per_episode_reward": -130.93, "episode_reward_trend_value": 0.002379505802219721, "biggest_recent_change": 0.0811311128794614},
{"total_number_of_episodes": 29052, "number_of_timesteps": 3312578, "per_episode_reward": -130.92, "episode_reward_trend_value": 0.0019029996891399986, "biggest_recent_change": 0.0811311128794614},
{"total_number_of_episodes": 29062, "number_of_timesteps": 3313901, "per_episode_reward": -130.97, "episode_reward_trend_value": 0.0009483925855537083, "biggest_recent_change": 0.0811311128794614},
{"total_number_of_episodes": 29072, "number_of_timesteps": 3315067, "per_episode_reward": -130.96, "episode_reward_trend_value": 0.0008784494398507073, "biggest_recent_change": 0.0811311128794614},
{"total_number_of_episodes": 29083, "number_of_timesteps": 3315949, "per_episode_reward": -130.9, "episode_reward_trend_value": 0.0008445512372471993, "biggest_recent_change": 0.0811311128794614},
{"total_number_of_episodes": 29093, "number_of_timesteps": 3316960, "per_episode_reward": -130.95, "episode_reward_trend_value": -0.0005587476992136291, "biggest_recent_change": 0.056441815194915534},
{"total_number_of_episodes": 29103, "number_of_timesteps": 3318068, "per_episode_reward": -130.97, "episode_reward_trend_value": -0.0006401844712763073, "biggest_recent_change": 0.056441815194915534},
{"total_number_of_episodes": 29113, "number_of_timesteps": 3319151, "per_episode_reward": -130.97, "episode_reward_trend_value": -0.0008108362299730565, "biggest_recent_change": 0.056441815194915534},
{"total_number_of_episodes": 29123, "number_of_timesteps": 3320103, "per_episode_reward": -130.94, "episode_reward_trend_value": -0.0005968426224143286, "biggest_recent_change": 0.056441815194915534},
{"total_number_of_episodes": 29134, "number_of_timesteps": 3321317, "per_episode_reward": -130.92, "episode_reward_trend_value": 6.58083624977558e-05, "biggest_recent_change": 0.056441815194915534},
{"total_number_of_episodes": 29144, "number_of_timesteps": 3322397, "per_episode_reward": -130.96, "episode_reward_trend_value": -0.00034916623847828355, "biggest_recent_change": 0.056441815194915534},
{"total_number_of_episodes": 29154, "number_of_timesteps": 3323379, "per_episode_reward": -130.97, "episode_reward_trend_value": 7.4897437561579254e-06, "biggest_recent_change": 0.056441815194915534},
{"total_number_of_episodes": 29164, "number_of_timesteps": 3324190, "per_episode_reward": -130.91, "episode_reward_trend_value": 0.0005568899995915267, "biggest_recent_change": 0.06373424231793479},
{"total_number_of_episodes": 29174, "number_of_timesteps": 3325088, "per_episode_reward": -130.89, "episode_reward_trend_value": 0.00011430655248274332, "biggest_recent_change": 0.06373424231793479},
{"total_number_of_episodes": 29184, "number_of_timesteps": 3326099, "per_episode_reward": -130.86, "episode_reward_trend_value": 0.0009868567466943053, "biggest_recent_change": 0.06373424231793479},
{"total_number_of_episodes": 29194, "number_of_timesteps": 3327192, "per_episode_reward": -130.85, "episode_reward_trend_value": 0.0014044773925358336, "biggest_recent_change": 0.06373424231793479},
{"total_number_of_episodes": 29204, "number_of_timesteps": 3328684, "per_episode_reward": -130.89, "episode_reward_trend_value": 0.0009259222331523788, "biggest_recent_change": 0.06373424231793479},
{"total_number_of_episodes": 29214, "number_of_timesteps": 3329876, "per_episode_reward": -130.95, "episode_reward_trend_value": -8.859318189580436e-05, "biggest_recent_change": 0.06373424231793479},
{"total_number_of_episodes": 29224, "number_of_timesteps": 3330980, "per_episode_reward": -130.98, "episode_reward_trend_value": -0.000652948955086193, "biggest_recent_change": 0.06373424231793479},
{"total_number_of_episodes": 29234, "number_of_timesteps": 3332162, "per_episode_reward": -130.98, "episode_reward_trend_value": -0.000305797761095366, "biggest_recent_change": 0.06373424231793479},
{"total_number_of_episodes": 29245, "number_of_timesteps": 3333138, "per_episode_reward": -130.93, "episode_reward_trend_value": 0.0005066400630075426, "biggest_recent_change": 0.06373424231793479},
{"total_number_of_episodes": 29256, "number_of_timesteps": 3334164, "per_episode_reward": -130.94, "episode_reward_trend_value": -0.00033918628363570255, "biggest_recent_change": 0.057107308783514554},
{"total_number_of_episodes": 29266, "number_of_timesteps": 3335153, "per_episode_reward": -130.89, "episode_reward_trend_value": 1.8754134461889607e-05, "biggest_recent_change": 0.057107308783514554},
{"total_number_of_episodes": 29276, "number_of_timesteps": 3336468, "per_episode_reward": -130.92, "episode_reward_trend_value": -0.0006273639585316459, "biggest_recent_change": 0.057107308783514554},
{"total_number_of_episodes": 29286, "number_of_timesteps": 3337543, "per_episode_reward": -130.89, "episode_reward_trend_value": -0.000471274258226294, "biggest_recent_change": 0.057107308783514554},
{"total_number_of_episodes": 29296, "number_of_timesteps": 3339021, "per_episode_reward": -130.93, "episode_reward_trend_value": -0.00038357539270034776, "biggest_recent_change": 0.057107308783514554},
{"total_number_of_episodes": 29306, "number_of_timesteps": 3340508, "per_episode_reward": -130.91, "episode_reward_trend_value": 0.0003939933114477551, "biggest_recent_change": 0.05408622063032453},
{"total_number_of_episodes": 29317, "number_of_timesteps": 3341547, "per_episode_reward": -130.88, "episode_reward_trend_value": 0.0011105404148565867, "biggest_recent_change": 0.05408622063032453},
{"total_number_of_episodes": 29327, "number_of_timesteps": 3342572, "per_episode_reward": -130.88, "episode_reward_trend_value": 0.0011107446835520959, "biggest_recent_change": 0.05408622063032453},
{"total_number_of_episodes": 29337, "number_of_timesteps": 3344068, "per_episode_reward": -130.9, "episode_reward_trend_value": 0.00028150171731750913, "biggest_recent_change": 0.04882394258390832},
{"total_number_of_episodes": 29347, "number_of_timesteps": 3345593, "per_episode_reward": -130.92, "episode_reward_trend_value": 0.0002185455524113422, "biggest_recent_change": 0.04882394258390832},
{"total_number_of_episodes": 29358, "number_of_timesteps": 3347140, "per_episode_reward": -130.98, "episode_reward_trend_value": -0.00095112571049722, "biggest_recent_change": 0.05644647107786227},
{"total_number_of_episodes": 29368, "number_of_timesteps": 3348267, "per_episode_reward": -130.97, "episode_reward_trend_value": -0.0006198793709125362, "biggest_recent_change": 0.05644647107786227},
{"total_number_of_episodes": 29378, "number_of_timesteps": 3349239, "per_episode_reward": -130.95, "episode_reward_trend_value": -0.0006438679465629902, "biggest_recent_change": 0.05644647107786227},
{"total_number_of_episodes": 29388, "number_of_timesteps": 3350160, "per_episode_reward": -130.92, "episode_reward_trend_value": 0.00010083858911116294, "biggest_recent_change": 0.05644647107786227},
{"total_number_of_episodes": 29399, "number_of_timesteps": 3351261, "per_episode_reward": -130.92, "episode_reward_trend_value": -6.118111474412065e-05, "biggest_recent_change": 0.05644647107786227},
{"total_number_of_episodes": 29409, "number_of_timesteps": 3352435, "per_episode_reward": -130.94, "episode_reward_trend_value": -0.0006083575872038536, "biggest_recent_change": 0.05644647107786227},
{"total_number_of_episodes": 29419, "number_of_timesteps": 3353527, "per_episode_reward": -130.9, "episode_reward_trend_value": -0.0002033749652108933, "biggest_recent_change": 0.05644647107786227},
{"total_number_of_episodes": 29429, "number_of_timesteps": 3354417, "per_episode_reward": -130.9, "episode_reward_trend_value": -3.853422597267632e-06, "biggest_recent_change": 0.05644647107786227},
{"total_number_of_episodes": 29439, "number_of_timesteps": 3355376, "per_episode_reward": -130.89, "episode_reward_trend_value": 0.00030123632198303266, "biggest_recent_change": 0.05644647107786227},
{"total_number_of_episodes": 29449, "number_of_timesteps": 3356641, "per_episode_reward": -130.92, "episode_reward_trend_value": 0.0006945714463007056, "biggest_recent_change": 0.03449574635081376},
{"total_number_of_episodes": 29459, "number_of_timesteps": 3357743, "per_episode_reward": -130.91, "episode_reward_trend_value": 0.0007006634940817473, "biggest_recent_change": 0.03449574635081376},
{"total_number_of_episodes": 29469, "number_of_timesteps": 3358712, "per_episode_reward": -130.89, "episode_reward_trend_value": 0.0006867644744419168, "biggest_recent_change": 0.03449574635081376},
{"total_number_of_episodes": 29479, "number_of_timesteps": 3359820, "per_episode_reward": -130.88, "episode_reward_trend_value": 0.0004161027015830617, "biggest_recent_change": 0.03449574635081376},
{"total_number_of_episodes": 29490, "number_of_timesteps": 3361175, "per_episode_reward": -130.9, "episode_reward_trend_value": 0.00023062057164193245, "biggest_recent_change": 0.03449574635081376},
{"total_number_of_episodes": 29500, "number_of_timesteps": 3362363, "per_episode_reward": -130.9, "episode_reward_trend_value": 0.000400468594930064, "biggest_recent_change": 0.03449574635081376},
{"total_number_of_episodes": 29510, "number_of_timesteps": 3363429, "per_episode_reward": -130.94, "episode_reward_trend_value": -0.0004070902831668061, "biggest_recent_change": 0.03818455267790455},
{"total_number_of_episodes": 29521, "number_of_timesteps": 3364944, "per_episode_reward": -130.97, "episode_reward_trend_value": -0.0007722681749202012, "biggest_recent_change": 0.03818455267790455},
{"total_number_of_episodes": 29531, "number_of_timesteps": 3366422, "per_episode_reward": -131.0, "episode_reward_trend_value": -0.0011911544063214782, "biggest_recent_change": 0.03818455267790455},
{"total_number_of_episodes": 29542, "number_of_timesteps": 3367842, "per_episode_reward": -130.98, "episode_reward_trend_value": -0.0007227469043609997, "biggest_recent_change": 0.03818455267790455},
{"total_number_of_episodes": 29552, "number_of_timesteps": 3368885, "per_episode_reward": -130.96, "episode_reward_trend_value": -0.0005233977661472662, "biggest_recent_change": 0.03818455267790455},
{"total_number_of_episodes": 29563, "number_of_timesteps": 3370210, "per_episode_reward": -130.95, "episode_reward_trend_value": -0.0007166490776831501, "biggest_recent_change": 0.03818455267790455},
{"total_number_of_episodes": 29573, "number_of_timesteps": 3371484, "per_episode_reward": -130.96, "episode_reward_trend_value": -0.0008552696082647218, "biggest_recent_change": 0.03818455267790455},
{"total_number_of_episodes": 29584, "number_of_timesteps": 3372672, "per_episode_reward": -130.95, "episode_reward_trend_value": -0.00061735134029435, "biggest_recent_change": 0.03818455267790455},
{"total_number_of_episodes": 29595, "number_of_timesteps": 3373658, "per_episode_reward": -130.91, "episode_reward_trend_value": -0.00012537428945146682, "biggest_recent_change": 0.04247052910031357},
{"total_number_of_episodes": 29606, "number_of_timesteps": 3374524, "per_episode_reward": -130.88, "episode_reward_trend_value": 0.000593408204265226, "biggest_recent_change": 0.04247052910031357},
{"total_number_of_episodes": 29616, "number_of_timesteps": 3375575, "per_episode_reward": -130.87, "episode_reward_trend_value": 0.001126390656252675, "biggest_recent_change": 0.04247052910031357},
{"total_number_of_episodes": 29627, "number_of_timesteps": 3376732, "per_episode_reward": -130.89, "episode_reward_trend_value": 0.0012793934340875365, "biggest_recent_change": 0.04247052910031357},
{"total_number_of_episodes": 29638, "number_of_timesteps": 3377893, "per_episode_reward": -130.85, "episode_reward_trend_value": 0.00143519358053652, "biggest_recent_change": 0.04247052910031357},
{"total_number_of_episodes": 29648, "number_of_timesteps": 3378839, "per_episode_reward": -130.77, "episode_reward_trend_value": 0.0020941233043904124, "biggest_recent_change": 0.08281865015661083},
{"total_number_of_episodes": 29658, "number_of_timesteps": 3380307, "per_episode_reward": -130.82, "episode_reward_trend_value": 0.0014557578899980525, "biggest_recent_change": 0.08281865015661083},
{"total_number_of_episodes": 29668, "number_of_timesteps": 3381857, "per_episode_reward": -130.82, "episode_reward_trend_value": 0.0015354112331042162, "biggest_recent_change": 0.08281865015661083},
{"total_number_of_episodes": 29678, "number_of_timesteps": 3382976, "per_episode_reward": -130.81, "episode_reward_trend_value": 0.0015932910185038434, "biggest_recent_change": 0.08281865015661083},
{"total_number_of_episodes": 29689, "number_of_timesteps": 3384439, "per_episode_reward": -130.82, "episode_reward_trend_value": 0.0009565148033061632, "biggest_recent_change": 0.08281865015661083},
{"total_number_of_episodes": 29699, "number_of_timesteps": 3385549, "per_episode_reward": -130.84, "episode_reward_trend_value": 0.0004425196937868729, "biggest_recent_change": 0.08281865015661083},
{"total_number_of_episodes": 29709, "number_of_timesteps": 3386811, "per_episode_reward": -130.84, "episode_reward_trend_value": 0.0003941167246081376, "biggest_recent_change": 0.08281865015661083},
{"total_number_of_episodes": 29719, "number_of_timesteps": 3387833, "per_episode_reward": -130.84, "episode_reward_trend_value": 0.0005338381457382486, "biggest_recent_change": 0.08281865015661083},
{"total_number_of_episodes": 29729, "number_of_timesteps": 3389224, "per_episode_reward": -130.84, "episode_reward_trend_value": 8.584511477130894e-05, "biggest_recent_change": 0.08281865015661083},
{"total_number_of_episodes": 29739, "number_of_timesteps": 3390279, "per_episode_reward": -130.83, "episode_reward_trend_value": -0.0006663200019434928, "biggest_recent_change": 0.05232392188764834},
{"total_number_of_episodes": 29749, "number_of_timesteps": 3391221, "per_episode_reward": -130.78, "episode_reward_trend_value": 0.0005052670174712325, "biggest_recent_change": 0.05311890985967693},
{"total_number_of_episodes": 29759, "number_of_timesteps": 3392282, "per_episode_reward": -130.79, "episode_reward_trend_value": 0.00033629840708992255, "biggest_recent_change": 0.05311890985967693},
{"total_number_of_episodes": 29770, "number_of_timesteps": 3393699, "per_episode_reward": -130.79, "episode_reward_trend_value": 0.00024495913651839554, "biggest_recent_change": 0.05311890985967693},
{"total_number_of_episodes": 29780, "number_of_timesteps": 3394564, "per_episode_reward": -130.77, "episode_reward_trend_value": 0.0006225184290589898, "biggest_recent_change": 0.05311890985967693},
{"total_number_of_episodes": 29791, "number_of_timesteps": 3395785, "per_episode_reward": -130.74, "episode_reward_trend_value": 0.001177525273615111, "biggest_recent_change": 0.05311890985967693},
{"total_number_of_episodes": 29801, "number_of_timesteps": 3396828, "per_episode_reward": -130.72, "episode_reward_trend_value": 0.0013426578797224112, "biggest_recent_change": 0.05311890985967693},
{"total_number_of_episodes": 29811, "number_of_timesteps": 3397905, "per_episode_reward": -130.72, "episode_reward_trend_value": 0.0013176558172877625, "biggest_recent_change": 0.05311890985967693},
{"total_number_of_episodes": 29821, "number_of_timesteps": 3399171, "per_episode_reward": -130.74, "episode_reward_trend_value": 0.0011117902010353317, "biggest_recent_change": 0.05311890985967693},
{"total_number_of_episodes": 29831, "number_of_timesteps": 3400540, "per_episode_reward": -130.82, "episode_reward_trend_value": 6.407886695380209e-05, "biggest_recent_change": 0.079170230415059},
{"total_number_of_episodes": 29841, "number_of_timesteps": 3402261, "per_episode_reward": -130.84, "episode_reward_trend_value": -0.0007462181450171733, "biggest_recent_change": 0.079170230415059},
{"total_number_of_episodes": 29852, "number_of_timesteps": 3403598, "per_episode_reward": -130.84, "episode_reward_trend_value": -0.0006348263229259348, "biggest_recent_change": 0.079170230415059},
{"total_number_of_episodes": 29862, "number_of_timesteps": 3404702, "per_episode_reward": -130.87, "episode_reward_trend_value": -0.0009409599641843316, "biggest_recent_change": 0.079170230415059},
{"total_number_of_episodes": 29873, "number_of_timesteps": 3405888, "per_episode_reward": -130.84, "episode_reward_trend_value": -0.0007519989020317375, "biggest_recent_change": 0.079170230415059},
{"total_number_of_episodes": 29883, "number_of_timesteps": 3407019, "per_episode_reward": -130.85, "episode_reward_trend_value": -0.0012790117556313084, "biggest_recent_change": 0.079170230415059},
{"total_number_of_episodes": 29894, "number_of_timesteps": 3408468, "per_episode_reward": -130.86, "episode_reward_trend_value": -0.0016410354335619104, "biggest_recent_change": 0.079170230415059},
{"total_number_of_episodes": 29904, "number_of_timesteps": 3409440, "per_episode_reward": -130.83, "episode_reward_trend_value": -0.0012636570739905058, "biggest_recent_change": 0.079170230415059},
{"total_number_of_episodes": 29915, "number_of_timesteps": 3410485, "per_episode_reward": -130.79, "episode_reward_trend_value": -0.0005303797178748305, "biggest_recent_change": 0.079170230415059},
{"total_number_of_episodes": 29925, "number_of_timesteps": 3411569, "per_episode_reward": -130.76, "episode_reward_trend_value": 0.0006732522784211091, "biggest_recent_change": 0.04228006226824732},
{"total_number_of_episodes": 29935, "number_of_timesteps": 3412677, "per_episode_reward": -130.79, "episode_reward_trend_value": 0.0005825416438385546, "biggest_recent_change": 0.04228006226824732},
{"total_number_of_episodes": 29945, "number_of_timesteps": 3413836, "per_episode_reward": -130.8, "episode_reward_trend_value": 0.00046148993064163183, "biggest_recent_change": 0.04228006226824732},
{"total_number_of_episodes": 29957, "number_of_timesteps": 3415278, "per_episode_reward": -130.83, "episode_reward_trend_value": 0.00043332508239094143, "biggest_recent_change": 0.04228006226824732},
{"total_number_of_episodes": 29969, "number_of_timesteps": 3416367, "per_episode_reward": -130.81, "episode_reward_trend_value": 0.0003375829921035726, "biggest_recent_change": 0.04228006226824732},
{"total_number_of_episodes": 29980, "number_of_timesteps": 3417567, "per_episode_reward": -130.82, "episode_reward_trend_value": 0.0004230516581843504, "biggest_recent_change": 0.04228006226824732},
{"total_number_of_episodes": 29990, "number_of_timesteps": 3418824, "per_episode_reward": -130.82, "episode_reward_trend_value": 0.00043655501301821507, "biggest_recent_change": 0.04228006226824732},
{"total_number_of_episodes": 30002, "number_of_timesteps": 3419952, "per_episode_reward": -130.81, "episode_reward_trend_value": 0.00022854648363256227, "biggest_recent_change": 0.04228006226824732},
{"total_number_of_episodes": 30012, "number_of_timesteps": 3420775, "per_episode_reward": -130.78, "episode_reward_trend_value": 8.532715716569328e-05, "biggest_recent_change": 0.03008686405581784},
{"total_number_of_episodes": 30022, "number_of_timesteps": 3421905, "per_episode_reward": -130.73, "episode_reward_trend_value": 0.0004037266939052288, "biggest_recent_change": 0.05781260755813378},
{"total_number_of_episodes": 30032, "number_of_timesteps": 3423002, "per_episode_reward": -130.71, "episode_reward_trend_value": 0.0008505849130222663, "biggest_recent_change": 0.05781260755813378},
{"total_number_of_episodes": 30042, "number_of_timesteps": 3424122, "per_episode_reward": -130.7, "episode_reward_trend_value": 0.0011426443290282072, "biggest_recent_change": 0.05781260755813378},
{"total_number_of_episodes": 30053, "number_of_timesteps": 3425178, "per_episode_reward": -130.69, "episode_reward_trend_value": 0.001581787935445315, "biggest_recent_change": 0.05781260755813378},
{"total_number_of_episodes": 30063, "number_of_timesteps": 3426095, "per_episode_reward": -130.68, "episode_reward_trend_value": 0.0014502108128851888, "biggest_recent_change": 0.05781260755813378},
{"total_number_of_episodes": 30073, "number_of_timesteps": 3427216, "per_episode_reward": -130.68, "episode_reward_trend_value": 0.0014850723181707634, "biggest_recent_change": 0.05781260755813378},
{"total_number_of_episodes": 30083, "number_of_timesteps": 3428434, "per_episode_reward": -130.68, "episode_reward_trend_value": 0.0015774165438838534, "biggest_recent_change": 0.05781260755813378},
{"total_number_of_episodes": 30093, "number_of_timesteps": 3429513, "per_episode_reward": -130.71, "episode_reward_trend_value": 0.0011702476163855458, "biggest_recent_change": 0.05781260755813378},
{"total_number_of_episodes": 30103, "number_of_timesteps": 3430652, "per_episode_reward": -130.72, "episode_reward_trend_value": 0.0007262649129437983, "biggest_recent_change": 0.05781260755813378},
{"total_number_of_episodes": 30113, "number_of_timesteps": 3431761, "per_episode_reward": -130.73, "episode_reward_trend_value": -2.204056513587855e-05, "biggest_recent_change": 0.025604794005801068},
{"total_number_of_episodes": 30124, "number_of_timesteps": 3433330, "per_episode_reward": -130.75, "episode_reward_trend_value": -0.0004411480106843631, "biggest_recent_change": 0.025604794005801068},
{"total_number_of_episodes": 30134, "number_of_timesteps": 3434648, "per_episode_reward": -130.81, "episode_reward_trend_value": -0.001264340332681968, "biggest_recent_change": 0.061292462347864785},
{"total_number_of_episodes": 30144, "number_of_timesteps": 3435930, "per_episode_reward": -130.78, "episode_reward_trend_value": -0.0009832474658370276, "biggest_recent_change": 0.061292462347864785},
{"total_number_of_episodes": 30154, "number_of_timesteps": 3437394, "per_episode_reward": -130.79, "episode_reward_trend_value": -0.001264792336053549, "biggest_recent_change": 0.061292462347864785},
{"total_number_of_episodes": 30164, "number_of_timesteps": 3438176, "per_episode_reward": -130.77, "episode_reward_trend_value": -0.0009343584745326753, "biggest_recent_change": 0.061292462347864785},
{"total_number_of_episodes": 30175, "number_of_timesteps": 3439553, "per_episode_reward": -130.75, "episode_reward_trend_value": -0.0007231615064625885, "biggest_recent_change": 0.061292462347864785},
{"total_number_of_episodes": 30185, "number_of_timesteps": 3440792, "per_episode_reward": -130.75, "episode_reward_trend_value": -0.00042358841526114093, "biggest_recent_change": 0.061292462347864785},
{"total_number_of_episodes": 30195, "number_of_timesteps": 3441886, "per_episode_reward": -130.71, "episode_reward_trend_value": 0.00013293574579083473, "biggest_recent_change": 0.061292462347864785},
{"total_number_of_episodes": 30205, "number_of_timesteps": 3442975, "per_episode_reward": -130.72, "episode_reward_trend_value": 0.00012581843466124258, "biggest_recent_change": 0.061292462347864785},
{"total_number_of_episodes": 30215, "number_of_timesteps": 3444126, "per_episode_reward": -130.72, "episode_reward_trend_value": 0.0003682468490416745, "biggest_recent_change": 0.061292462347864785},
{"total_number_of_episodes": 30225, "number_of_timesteps": 3445912, "per_episode_reward": -130.74, "episode_reward_trend_value": 0.0007799904156061959, "biggest_recent_change": 0.03951905407114964},
{"total_number_of_episodes": 30235, "number_of_timesteps": 3446856, "per_episode_reward": -130.72, "episode_reward_trend_value": 0.0006694792995419775, "biggest_recent_change": 0.03951905407114964},
{"total_number_of_episodes": 30245, "number_of_timesteps": 3448128, "per_episode_reward": -130.68, "episode_reward_trend_value": 0.0012563901787905883, "biggest_recent_change": 0.04317171331152281},
{"total_number_of_episodes": 30255, "number_of_timesteps": 3449559, "per_episode_reward": -130.71, "episode_reward_trend_value": 0.0005688718852537831, "biggest_recent_change": 0.04317171331152281},
{"total_number_of_episodes": 30265, "number_of_timesteps": 3450729, "per_episode_reward": -130.74, "episode_reward_trend_value": 0.00010761361062697637, "biggest_recent_change": 0.04317171331152281},
{"total_number_of_episodes": 30275, "number_of_timesteps": 3451928, "per_episode_reward": -130.72, "episode_reward_trend_value": 0.0002853259425390004, "biggest_recent_change": 0.04317171331152281},
{"total_number_of_episodes": 30285, "number_of_timesteps": 3452817, "per_episode_reward": -130.72, "episode_reward_trend_value": -0.0001648920544182728, "biggest_recent_change": 0.04317171331152281},
{"total_number_of_episodes": 30295, "number_of_timesteps": 3454010, "per_episode_reward": -130.72, "episode_reward_trend_value": -9.700954437713941e-05, "biggest_recent_change": 0.04317171331152281},
{"total_number_of_episodes": 30305, "number_of_timesteps": 3455174, "per_episode_reward": -130.75, "episode_reward_trend_value": -0.00031394019970131616, "biggest_recent_change": 0.04317171331152281},
{"total_number_of_episodes": 30315, "number_of_timesteps": 3456225, "per_episode_reward": -130.72, "episode_reward_trend_value": 0.00021692260907255127, "biggest_recent_change": 0.04317171331152281},
{"total_number_of_episodes": 30325, "number_of_timesteps": 3457129, "per_episode_reward": -130.68, "episode_reward_trend_value": 0.00043236762812013144, "biggest_recent_change": 0.04417846980626905},
{"total_number_of_episodes": 30335, "number_of_timesteps": 3458303, "per_episode_reward": -130.68, "episode_reward_trend_value": -3.214391712857731e-05, "biggest_recent_change": 0.04417846980626905},
{"total_number_of_episodes": 30345, "number_of_timesteps": 3459943, "per_episode_reward": -130.67, "episode_reward_trend_value": 0.0005241592310795795, "biggest_recent_change": 0.04417846980626905},
{"total_number_of_episodes": 30355, "number_of_timesteps": 3461195, "per_episode_reward": -130.7, "episode_reward_trend_value": 0.00043609362039313105, "biggest_recent_change": 0.04417846980626905},
{"total_number_of_episodes": 30366, "number_of_timesteps": 3462529, "per_episode_reward": -130.73, "episode_reward_trend_value": -0.00014446572443457877, "biggest_recent_change": 0.04417846980626905},
{"total_number_of_episodes": 30378, "number_of_timesteps": 3464268, "per_episode_reward": -130.75, "episode_reward_trend_value": -0.00032217102316312523, "biggest_recent_change": 0.04417846980626905},
{"total_number_of_episodes": 30388, "number_of_timesteps": 3465525, "per_episode_reward": -130.76, "episode_reward_trend_value": -0.00035834979988496544, "biggest_recent_change": 0.04417846980626905},
{"total_number_of_episodes": 30399, "number_of_timesteps": 3466697, "per_episode_reward": -130.77, "episode_reward_trend_value": -0.0002627871024395113, "biggest_recent_change": 0.04417846980626905},
{"total_number_of_episodes": 30409, "number_of_timesteps": 3467794, "per_episode_reward": -130.76, "episode_reward_trend_value": -0.0004046654032139132, "biggest_recent_change": 0.04417846980626905},
{"total_number_of_episodes": 30419, "number_of_timesteps": 3469046, "per_episode_reward": -130.79, "episode_reward_trend_value": -0.0012473886929383424, "biggest_recent_change": 0.034899446960082514},
{"total_number_of_episodes": 30429, "number_of_timesteps": 3470144, "per_episode_reward": -130.82, "episode_reward_trend_value": -0.0015274406786090823, "biggest_recent_change": 0.034899446960082514},
{"total_number_of_episodes": 30439, "number_of_timesteps": 3471303, "per_episode_reward": -130.82, "episode_reward_trend_value": -0.0016845831274913, "biggest_recent_change": 0.034899446960082514},
{"total_number_of_episodes": 30449, "number_of_timesteps": 3472410, "per_episode_reward": -130.84, "episode_reward_trend_value": -0.0015894742989584327, "biggest_recent_change": 0.034899446960082514},
{"total_number_of_episodes": 30459, "number_of_timesteps": 3473655, "per_episode_reward": -130.84, "episode_reward_trend_value": -0.0011419443695915433, "biggest_recent_change": 0.031666626268929576},
{"total_number_of_episodes": 30469, "number_of_timesteps": 3474863, "per_episode_reward": -130.81, "episode_reward_trend_value": -0.0006728364637041296, "biggest_recent_change": 0.031666626268929576},
{"total_number_of_episodes": 30479, "number_of_timesteps": 3476377, "per_episode_reward": -130.79, "episode_reward_trend_value": -0.0003874544720035702, "biggest_recent_change": 0.031666626268929576},
{"total_number_of_episodes": 30489, "number_of_timesteps": 3477825, "per_episode_reward": -130.8, "episode_reward_trend_value": -0.00028863628078062856, "biggest_recent_change": 0.031666626268929576},
{"total_number_of_episodes": 30499, "number_of_timesteps": 3478766, "per_episode_reward": -130.78, "episode_reward_trend_value": -0.00016642837420748595, "biggest_recent_change": 0.031666626268929576},
{"total_number_of_episodes": 30510, "number_of_timesteps": 3479979, "per_episode_reward": -130.77, "episode_reward_trend_value": 0.0002866627478618334, "biggest_recent_change": 0.025225668989293126},
{"total_number_of_episodes": 30520, "number_of_timesteps": 3481084, "per_episode_reward": -130.77, "episode_reward_trend_value": 0.0005674271134779474, "biggest_recent_change": 0.025225668989293126},
{"total_number_of_episodes": 30530, "number_of_timesteps": 3482438, "per_episode_reward": -130.81, "episode_reward_trend_value": 8.621718990424495e-05, "biggest_recent_change": 0.04592654255480966},
{"total_number_of_episodes": 30541, "number_of_timesteps": 3483482, "per_episode_reward": -130.78, "episode_reward_trend_value": 0.0006975623963597855, "biggest_recent_change": 0.04592654255480966},
{"total_number_of_episodes": 30551, "number_of_timesteps": 3484452, "per_episode_reward": -130.75, "episode_reward_trend_value": 0.0009660925788965516, "biggest_recent_change": 0.04592654255480966},
{"total_number_of_episodes": 30561, "number_of_timesteps": 3485313, "per_episode_reward": -130.7, "episode_reward_trend_value": 0.0012760392216904393, "biggest_recent_change": 0.05312086684074302},
{"total_number_of_episodes": 30571, "number_of_timesteps": 3486483, "per_episode_reward": -130.69, "episode_reward_trend_value": 0.0011707957441624709, "biggest_recent_change": 0.05312086684074302},
{"total_number_of_episodes": 30581, "number_of_timesteps": 3487838, "per_episode_reward": -130.71, "episode_reward_trend_value": 0.000980190803408555, "biggest_recent_change": 0.05312086684074302},
{"total_number_of_episodes": 30591, "number_of_timesteps": 3488911, "per_episode_reward": -130.72, "episode_reward_trend_value": 0.0006512542918348647, "biggest_recent_change": 0.05312086684074302},
{"total_number_of_episodes": 30601, "number_of_timesteps": 3489941, "per_episode_reward": -130.74, "episode_reward_trend_value": 0.0002496876509537868, "biggest_recent_change": 0.05312086684074302},
{"total_number_of_episodes": 30611, "number_of_timesteps": 3491039, "per_episode_reward": -130.72, "episode_reward_trend_value": 0.0004568127879685512, "biggest_recent_change": 0.05312086684074302},
{"total_number_of_episodes": 30621, "number_of_timesteps": 3492288, "per_episode_reward": -130.76, "episode_reward_trend_value": 0.000582485890225194, "biggest_recent_change": 0.05312086684074302},
{"total_number_of_episodes": 30633, "number_of_timesteps": 3493840, "per_episode_reward": -130.78, "episode_reward_trend_value": 2.4708113082599286e-05, "biggest_recent_change": 0.05312086684074302},
{"total_number_of_episodes": 30643, "number_of_timesteps": 3495404, "per_episode_reward": -130.76, "episode_reward_trend_value": -0.0001459784723768583, "biggest_recent_change": 0.05312086684074302},
{"total_number_of_episodes": 30654, "number_of_timesteps": 3496470, "per_episode_reward": -130.78, "episode_reward_trend_value": -0.0009882820757733648, "biggest_recent_change": 0.0346159633517118},
{"total_number_of_episodes": 30664, "number_of_timesteps": 3497391, "per_episode_reward": -130.75, "episode_reward_trend_value": -0.0006490771211502989, "biggest_recent_change": 0.039418804719645095},
{"total_number_of_episodes": 30674, "number_of_timesteps": 3498368, "per_episode_reward": -130.76, "episode_reward_trend_value": -0.0005172068972812995, "biggest_recent_change": 0.039418804719645095},
{"total_number_of_episodes": 30685, "number_of_timesteps": 3499488, "per_episode_reward": -130.76, "episode_reward_trend_value": -0.0004779731034005863, "biggest_recent_change": 0.039418804719645095},
{"total_number_of_episodes": 30697, "number_of_timesteps": 3500746, "per_episode_reward": -130.7, "episode_reward_trend_value": 0.0005079964533059132, "biggest_recent_change": 0.06170783714159711},
{"total_number_of_episodes": 30707, "number_of_timesteps": 3501927, "per_episode_reward": -130.7, "episode_reward_trend_value": 0.0002694270960230622, "biggest_recent_change": 0.06170783714159711},
{"total_number_of_episodes": 30718, "number_of_timesteps": 3503191, "per_episode_reward": -130.68, "episode_reward_trend_value": 0.0009154948455214176, "biggest_recent_change": 0.06170783714159711},
{"total_number_of_episodes": 30728, "number_of_timesteps": 3504348, "per_episode_reward": -130.62, "episode_reward_trend_value": 0.001737831948602775, "biggest_recent_change": 0.06170783714159711},
{"total_number_of_episodes": 30738, "number_of_timesteps": 3505519, "per_episode_reward": -130.64, "episode_reward_trend_value": 0.0013903173576282925, "biggest_recent_change": 0.06170783714159711},
{"total_number_of_episodes": 30749, "number_of_timesteps": 3507444, "per_episode_reward": -130.65, "episode_reward_trend_value": 0.0015053033213926407, "biggest_recent_change": 0.06170783714159711},
{"total_number_of_episodes": 30759, "number_of_timesteps": 3508423, "per_episode_reward": -130.63, "episode_reward_trend_value": 0.0012573105347671444, "biggest_recent_change": 0.06170783714159711},
{"total_number_of_episodes": 30769, "number_of_timesteps": 3509429, "per_episode_reward": -130.62, "episode_reward_trend_value": 0.0014851573302097324, "biggest_recent_change": 0.06170783714159711},
{"total_number_of_episodes": 30779, "number_of_timesteps": 3510643, "per_episode_reward": -130.62, "episode_reward_trend_value": 0.0015186289825490148, "biggest_recent_change": 0.06170783714159711},
{"total_number_of_episodes": 30789, "number_of_timesteps": 3511737, "per_episode_reward": -130.61, "episode_reward_trend_value": 0.0009626286328600347, "biggest_recent_change": 0.05692330141610569},
{"total_number_of_episodes": 30799, "number_of_timesteps": 3513185, "per_episode_reward": -130.62, "episode_reward_trend_value": 0.0009287898349924717, "biggest_recent_change": 0.05692330141610569},
{"total_number_of_episodes": 30809, "number_of_timesteps": 3514195, "per_episode_reward": -130.69, "episode_reward_trend_value": -0.00015336996110117221, "biggest_recent_change": 0.07386424754528775},
{"total_number_of_episodes": 30819, "number_of_timesteps": 3515409, "per_episode_reward": -130.7, "episode_reward_trend_value": -0.0009319007715712738, "biggest_recent_change": 0.07386424754528775},
{"total_number_of_episodes": 30829, "number_of_timesteps": 3516470, "per_episode_reward": -130.71, "episode_reward_trend_value": -0.0008483777100069447, "biggest_recent_change": 0.07386424754528775},
{"total_number_of_episodes": 30839, "number_of_timesteps": 3517407, "per_episode_reward": -130.7, "episode_reward_trend_value": -0.0005986185149655259, "biggest_recent_change": 0.07386424754528775},
{"total_number_of_episodes": 30849, "number_of_timesteps": 3518782, "per_episode_reward": -130.73, "episode_reward_trend_value": -0.0011211209188982392, "biggest_recent_change": 0.07386424754528775},
{"total_number_of_episodes": 30860, "number_of_timesteps": 3520105, "per_episode_reward": -130.69, "episode_reward_trend_value": -0.0007989227525579659, "biggest_recent_change": 0.07386424754528775},
{"total_number_of_episodes": 30870, "number_of_timesteps": 3521598, "per_episode_reward": -130.69, "episode_reward_trend_value": -0.0006819225953689865, "biggest_recent_change": 0.07386424754528775},
{"total_number_of_episodes": 30880, "number_of_timesteps": 3522561, "per_episode_reward": -130.7, "episode_reward_trend_value": -0.0009277881009621877, "biggest_recent_change": 0.07386424754528775},
{"total_number_of_episodes": 30890, "number_of_timesteps": 3523957, "per_episode_reward": -130.67, "episode_reward_trend_value": -0.0005669256776147651, "biggest_recent_change": 0.07386424754528775},
{"total_number_of_episodes": 30900, "number_of_timesteps": 3525177, "per_episode_reward": -130.61, "episode_reward_trend_value": 0.0008733054238506257, "biggest_recent_change": 0.055756551586597425},
{"total_number_of_episodes": 30911, "number_of_timesteps": 3526220, "per_episode_reward": -130.59, "episode_reward_trend_value": 0.0012522109621591602, "biggest_recent_change": 0.055756551586597425},
{"total_number_of_episodes": 30921, "number_of_timesteps": 3526966, "per_episode_reward": -130.56, "episode_reward_trend_value": 0.0017098082130950667, "biggest_recent_change": 0.055756551586597425},
{"total_number_of_episodes": 30931, "number_of_timesteps": 3527958, "per_episode_reward": -130.54, "episode_reward_trend_value": 0.0017731531463953034, "biggest_recent_change": 0.055756551586597425},
{"total_number_of_episodes": 30941, "number_of_timesteps": 3529144, "per_episode_reward": -130.55, "episode_reward_trend_value": 0.0020845063615392216, "biggest_recent_change": 0.055756551586597425},
{"total_number_of_episodes": 30952, "number_of_timesteps": 3530490, "per_episode_reward": -130.58, "episode_reward_trend_value": 0.001231401018168299, "biggest_recent_change": 0.055756551586597425},
{"total_number_of_episodes": 30962, "number_of_timesteps": 3531604, "per_episode_reward": -130.56, "episode_reward_trend_value": 0.0013823719867348118, "biggest_recent_change": 0.055756551586597425},
{"total_number_of_episodes": 30972, "number_of_timesteps": 3532700, "per_episode_reward": -130.59, "episode_reward_trend_value": 0.001171720163782513, "biggest_recent_change": 0.055756551586597425},
{"total_number_of_episodes": 30984, "number_of_timesteps": 3534292, "per_episode_reward": -130.55, "episode_reward_trend_value": 0.0012878861440902432, "biggest_recent_change": 0.055756551586597425},
{"total_number_of_episodes": 30994, "number_of_timesteps": 3535339, "per_episode_reward": -130.56, "episode_reward_trend_value": 0.0006147093262433778, "biggest_recent_change": 0.03848687313097798},
{"total_number_of_episodes": 31004, "number_of_timesteps": 3536649, "per_episode_reward": -130.63, "episode_reward_trend_value": -0.00043699527650649844, "biggest_recent_change": 0.0736963873259242},
{"total_number_of_episodes": 31014, "number_of_timesteps": 3538111, "per_episode_reward": -130.64, "episode_reward_trend_value": -0.0009488548613512017, "biggest_recent_change": 0.0736963873259242},
{"total_number_of_episodes": 31024, "number_of_timesteps": 3539286, "per_episode_reward": -130.58, "episode_reward_trend_value": -0.0003893463944788462, "biggest_recent_change": 0.0736963873259242},
{"total_number_of_episodes": 31034, "number_of_timesteps": 3540365, "per_episode_reward": -130.5, "episode_reward_trend_value": 0.0005359837550959885, "biggest_recent_change": 0.08137574039409401},
{"total_number_of_episodes": 31045, "number_of_timesteps": 3541750, "per_episode_reward": -130.6, "episode_reward_trend_value": -0.00016595307527009277, "biggest_recent_change": 0.10142100400926779},
{"total_number_of_episodes": 31055, "number_of_timesteps": 3542959, "per_episode_reward": -130.58, "episode_reward_trend_value": -0.00018255416247162277, "biggest_recent_change": 0.10142100400926779},
{"total_number_of_episodes": 31066, "number_of_timesteps": 3544349, "per_episode_reward": -130.62, "episode_reward_trend_value": -0.0002905507621205869, "biggest_recent_change": 0.10142100400926779},
{"total_number_of_episodes": 31076, "number_of_timesteps": 3545780, "per_episode_reward": -130.65, "episode_reward_trend_value": -0.0010388871164934699, "biggest_recent_change": 0.10142100400926779},
{"total_number_of_episodes": 31086, "number_of_timesteps": 3546951, "per_episode_reward": -130.68, "episode_reward_trend_value": -0.0013693288980479994, "biggest_recent_change": 0.10142100400926779},
{"total_number_of_episodes": 31096, "number_of_timesteps": 3548246, "per_episode_reward": -130.68, "episode_reward_trend_value": -0.000548376637574519, "biggest_recent_change": 0.10142100400926779},
{"total_number_of_episodes": 31106, "number_of_timesteps": 3549447, "per_episode_reward": -130.68, "episode_reward_trend_value": -0.00040403807717426487, "biggest_recent_change": 0.10142100400926779},
{"total_number_of_episodes": 31116, "number_of_timesteps": 3550503, "per_episode_reward": -130.69, "episode_reward_trend_value": -0.0012538239241517127, "biggest_recent_change": 0.10142100400926779},
{"total_number_of_episodes": 31126, "number_of_timesteps": 3551933, "per_episode_reward": -130.73, "episode_reward_trend_value": -0.0025663145638468955, "biggest_recent_change": 0.10142100400926779},
{"total_number_of_episodes": 31136, "number_of_timesteps": 3553534, "per_episode_reward": -130.72, "episode_reward_trend_value": -0.0013323482361676674, "biggest_recent_change": 0.03913844786791287},
{"total_number_of_episodes": 31146, "number_of_timesteps": 3554864, "per_episode_reward": -130.79, "episode_reward_trend_value": -0.0023249474919149788, "biggest_recent_change": 0.067999649474757},
{"total_number_of_episodes": 31157, "number_of_timesteps": 3556498, "per_episode_reward": -130.82, "episode_reward_trend_value": -0.00221143043968305, "biggest_recent_change": 0.067999649474757},
{"total_number_of_episodes": 31169, "number_of_timesteps": 3557733, "per_episode_reward": -130.84, "episode_reward_trend_value": -0.0021839305202626573, "biggest_recent_change": 0.067999649474757},
{"total_number_of_episodes": 31179, "number_of_timesteps": 3558540, "per_episode_reward": -130.79, "episode_reward_trend_value": -0.0012479259418689203, "biggest_recent_change": 0.067999649474757},
{"total_number_of_episodes": 31189, "number_of_timesteps": 3559493, "per_episode_reward": -130.8, "episode_reward_trend_value": -0.0013055280504678042, "biggest_recent_change": 0.067999649474757},
{"total_number_of_episodes": 31199, "number_of_timesteps": 3560656, "per_episode_reward": -130.78, "episode_reward_trend_value": -0.001051347315040453, "biggest_recent_change": 0.067999649474757},
{"total_number_of_episodes": 31209, "number_of_timesteps": 3561661, "per_episode_reward": -130.74, "episode_reward_trend_value": -0.0005168693261636135, "biggest_recent_change": 0.067999649474757},
{"total_number_of_episodes": 31219, "number_of_timesteps": 3562708, "per_episode_reward": -130.75, "episode_reward_trend_value": -0.00028950609117291354, "biggest_recent_change": 0.067999649474757},
{"total_number_of_episodes": 31230, "number_of_timesteps": 3563837, "per_episode_reward": -130.73, "episode_reward_trend_value": -0.00014287632936284606, "biggest_recent_change": 0.067999649474757},
{"total_number_of_episodes": 31240, "number_of_timesteps": 3564919, "per_episode_reward": -130.74, "episode_reward_trend_value": 0.00046084456043489453, "biggest_recent_change": 0.04967128969590817},
{"total_number_of_episodes": 31250, "number_of_timesteps": 3566040, "per_episode_reward": -130.8, "episode_reward_trend_value": 0.00013944217155470697, "biggest_recent_change": 0.057848128166256174},
{"total_number_of_episodes": 31260, "number_of_timesteps": 3567454, "per_episode_reward": -130.82, "episode_reward_trend_value": 0.0002700382993130764, "biggest_recent_change": 0.057848128166256174},
{"total_number_of_episodes": 31270, "number_of_timesteps": 3568708, "per_episode_reward": -130.83, "episode_reward_trend_value": -0.0004118432188657077, "biggest_recent_change": 0.057848128166256174},
{"total_number_of_episodes": 31280, "number_of_timesteps": 3569839, "per_episode_reward": -130.83, "episode_reward_trend_value": -0.00034117046446182383, "biggest_recent_change": 0.057848128166256174},
{"total_number_of_episodes": 31292, "number_of_timesteps": 3571307, "per_episode_reward": -130.84, "episode_reward_trend_value": -0.0007597384149991942, "biggest_recent_change": 0.057848128166256174},
{"total_number_of_episodes": 31302, "number_of_timesteps": 3572361, "per_episode_reward": -130.84, "episode_reward_trend_value": -0.0011307159230729744, "biggest_recent_change": 0.057848128166256174},
{"total_number_of_episodes": 31312, "number_of_timesteps": 3573391, "per_episode_reward": -130.83, "episode_reward_trend_value": -0.0008509130293298817, "biggest_recent_change": 0.057848128166256174},
{"total_number_of_episodes": 31322, "number_of_timesteps": 3574695, "per_episode_reward": -130.77, "episode_reward_trend_value": -0.0004456155508074112, "biggest_recent_change": 0.05930941711179116},
{"total_number_of_episodes": 31334, "number_of_timesteps": 3576034, "per_episode_reward": -130.77, "episode_reward_trend_value": -0.0002640074699823142, "biggest_recent_change": 0.05930941711179116},
{"total_number_of_episodes": 31344, "number_of_timesteps": 3576869, "per_episode_reward": -130.72, "episode_reward_trend_value": 0.0009495857735626285, "biggest_recent_change": 0.05930941711179116},
{"total_number_of_episodes": 31354, "number_of_timesteps": 3577965, "per_episode_reward": -130.74, "episode_reward_trend_value": 0.0008450700518216713, "biggest_recent_change": 0.05930941711179116},
{"total_number_of_episodes": 31365, "number_of_timesteps": 3579176, "per_episode_reward": -130.71, "episode_reward_trend_value": 0.0013057488009337703, "biggest_recent_change": 0.05930941711179116},
{"total_number_of_episodes": 31376, "number_of_timesteps": 3580291, "per_episode_reward": -130.7, "episode_reward_trend_value": 0.0014304273187339808, "biggest_recent_change": 0.05930941711179116},
{"total_number_of_episodes": 31386, "number_of_timesteps": 3581517, "per_episode_reward": -130.69, "episode_reward_trend_value": 0.0016574362565172072, "biggest_recent_change": 0.05930941711179116},
{"total_number_of_episodes": 31396, "number_of_timesteps": 3582997, "per_episode_reward": -130.76, "episode_reward_trend_value": 0.0008910357182634875, "biggest_recent_change": 0.06454431855541998},
{"total_number_of_episodes": 31406, "number_of_timesteps": 3584372, "per_episode_reward": -130.78, "episode_reward_trend_value": 0.0005165771336540577, "biggest_recent_change": 0.06454431855541998},
{"total_number_of_episodes": 31416, "number_of_timesteps": 3585501, "per_episode_reward": -130.73, "episode_reward_trend_value": 0.00051014841401569, "biggest_recent_change": 0.06454431855541998},
{"total_number_of_episodes": 31426, "number_of_timesteps": 3586562, "per_episode_reward": -130.78, "episode_reward_trend_value": -0.00013940634135565234, "biggest_recent_change": 0.06454431855541998},
{"total_number_of_episodes": 31436, "number_of_timesteps": 3587676, "per_episode_reward": -130.76, "episode_reward_trend_value": -0.00047923767357802813, "biggest_recent_change": 0.06454431855541998},
{"total_number_of_episodes": 31446, "number_of_timesteps": 3588642, "per_episode_reward": -130.74, "episode_reward_trend_value": 1.3690861475702654e-05, "biggest_recent_change": 0.06454431855541998},
{"total_number_of_episodes": 31456, "number_of_timesteps": 3589748, "per_episode_reward": -130.75, "episode_reward_trend_value": -0.0003865486469379675, "biggest_recent_change": 0.06454431855541998},
{"total_number_of_episodes": 31467, "number_of_timesteps": 3591056, "per_episode_reward": -130.69, "episode_reward_trend_value": 5.123110765181435e-05, "biggest_recent_change": 0.06454431855541998},
{"total_number_of_episodes": 31477, "number_of_timesteps": 3591972, "per_episode_reward": -130.73, "episode_reward_trend_value": -0.00035174809986150045, "biggest_recent_change": 0.06454431855541998},
{"total_number_of_episodes": 31487, "number_of_timesteps": 3593198, "per_episode_reward": -130.72, "episode_reward_trend_value": 0.00040440912477271874, "biggest_recent_change": 0.05873083234433807},
{"total_number_of_episodes": 31497, "number_of_timesteps": 3594693, "per_episode_reward": -130.73, "episode_reward_trend_value": 0.0005770078933592358, "biggest_recent_change": 0.05873083234433807},
{"total_number_of_episodes": 31507, "number_of_timesteps": 3595652, "per_episode_reward": -130.7, "episode_reward_trend_value": 0.0002313537546310979, "biggest_recent_change": 0.055779970102122434},
{"total_number_of_episodes": 31517, "number_of_timesteps": 3596515, "per_episode_reward": -130.68, "episode_reward_trend_value": 0.0010960139228972012, "biggest_recent_change": 0.05198691875423833},
{"total_number_of_episodes": 31527, "number_of_timesteps": 3597667, "per_episode_reward": -130.73, "episode_reward_trend_value": 0.0003891103667225732, "biggest_recent_change": 0.05198691875423833},
{"total_number_of_episodes": 31537, "number_of_timesteps": 3599025, "per_episode_reward": -130.72, "episode_reward_trend_value": 0.00021852940697013106, "biggest_recent_change": 0.05198691875423833},
{"total_number_of_episodes": 31547, "number_of_timesteps": 3600385, "per_episode_reward": -130.7, "episode_reward_trend_value": 0.0004785395342051086, "biggest_recent_change": 0.05198691875423833},
{"total_number_of_episodes": 31557, "number_of_timesteps": 3601415, "per_episode_reward": -130.68, "episode_reward_trend_value": 0.0001349337155144465, "biggest_recent_change": 0.04283087620294168},
{"total_number_of_episodes": 31567, "number_of_timesteps": 3602540, "per_episode_reward": -130.71, "episode_reward_trend_value": 0.00016459232990971234, "biggest_recent_change": 0.04283087620294168},
{"total_number_of_episodes": 31578, "number_of_timesteps": 3604132, "per_episode_reward": -130.75, "episode_reward_trend_value": -0.0002951916992502548, "biggest_recent_change": 0.04283087620294168},
{"total_number_of_episodes": 31588, "number_of_timesteps": 3605174, "per_episode_reward": -130.71, "episode_reward_trend_value": 0.00019131619884989152, "biggest_recent_change": 0.04283087620294168},
{"total_number_of_episodes": 31598, "number_of_timesteps": 3606308, "per_episode_reward": -130.72, "episode_reward_trend_value": -0.0002202205830934013, "biggest_recent_change": 0.04283087620294168},
{"total_number_of_episodes": 31608, "number_of_timesteps": 3607411, "per_episode_reward": -130.69, "episode_reward_trend_value": -7.795479969558982e-05, "biggest_recent_change": 0.04283087620294168},
{"total_number_of_episodes": 31618, "number_of_timesteps": 3608252, "per_episode_reward": -130.63, "episode_reward_trend_value": 0.0010061481414324034, "biggest_recent_change": 0.054738388498577706},
{"total_number_of_episodes": 31631, "number_of_timesteps": 3609552, "per_episode_reward": -130.58, "episode_reward_trend_value": 0.0015912533606470762, "biggest_recent_change": 0.05762958203325752},
{"total_number_of_episodes": 31642, "number_of_timesteps": 3610803, "per_episode_reward": -130.58, "episode_reward_trend_value": 0.0013673597759195546, "biggest_recent_change": 0.05762958203325752},
{"total_number_of_episodes": 31653, "number_of_timesteps": 3612227, "per_episode_reward": -130.56, "episode_reward_trend_value": 0.0013716441045065469, "biggest_recent_change": 0.05762958203325752},
{"total_number_of_episodes": 31663, "number_of_timesteps": 3613353, "per_episode_reward": -130.52, "episode_reward_trend_value": 0.00208851621191065, "biggest_recent_change": 0.05762958203325752},
{"total_number_of_episodes": 31673, "number_of_timesteps": 3614442, "per_episode_reward": -130.51, "episode_reward_trend_value": 0.0026132533127193056, "biggest_recent_change": 0.05762958203325752},
{"total_number_of_episodes": 31683, "number_of_timesteps": 3615630, "per_episode_reward": -130.51, "episode_reward_trend_value": 0.002250878741140304, "biggest_recent_change": 0.05762958203325752},
{"total_number_of_episodes": 31693, "number_of_timesteps": 3617496, "per_episode_reward": -130.52, "episode_reward_trend_value": 0.0022244800293666203, "biggest_recent_change": 0.05762958203325752},
{"total_number_of_episodes": 31703, "number_of_timesteps": 3618771, "per_episode_reward": -130.58, "episode_reward_trend_value": 0.0012006925619652343, "biggest_recent_change": 0.05762958203325752},
{"total_number_of_episodes": 31713, "number_of_timesteps": 3619987, "per_episode_reward": -130.61, "episode_reward_trend_value": 0.00022388139016540107, "biggest_recent_change": 0.05762958203325752},
{"total_number_of_episodes": 31724, "number_of_timesteps": 3621305, "per_episode_reward": -130.62, "episode_reward_trend_value": -0.0004788430632367459, "biggest_recent_change": 0.057297506518494856},
{"total_number_of_episodes": 31734, "number_of_timesteps": 3622417, "per_episode_reward": -130.68, "episode_reward_trend_value": -0.0011575586454875342, "biggest_recent_change": 0.06409242885422373},
{"total_number_of_episodes": 31744, "number_of_timesteps": 3623780, "per_episode_reward": -130.72, "episode_reward_trend_value": -0.0017906612074931952, "biggest_recent_change": 0.06409242885422373},
{"total_number_of_episodes": 31755, "number_of_timesteps": 3624741, "per_episode_reward": -130.71, "episode_reward_trend_value": -0.0020298357891527356, "biggest_recent_change": 0.06409242885422373},
{"total_number_of_episodes": 31765, "number_of_timesteps": 3625549, "per_episode_reward": -130.65, "episode_reward_trend_value": -0.001538408456371106, "biggest_recent_change": 0.06409242885422373},
{"total_number_of_episodes": 31775, "number_of_timesteps": 3626621, "per_episode_reward": -130.69, "episode_reward_trend_value": -0.002003704278151493, "biggest_recent_change": 0.06409242885422373},
{"total_number_of_episodes": 31785, "number_of_timesteps": 3627712, "per_episode_reward": -130.64, "episode_reward_trend_value": -0.0013348443776477678, "biggest_recent_change": 0.06409242885422373},
{"total_number_of_episodes": 31795, "number_of_timesteps": 3628726, "per_episode_reward": -130.64, "episode_reward_trend_value": -0.0006275636358702109, "biggest_recent_change": 0.06409242885422373},
{"total_number_of_episodes": 31805, "number_of_timesteps": 3629595, "per_episode_reward": -130.62, "episode_reward_trend_value": -9.457278522278203e-05, "biggest_recent_change": 0.06409242885422373},
{"total_number_of_episodes": 31815, "number_of_timesteps": 3630491, "per_episode_reward": -130.6, "episode_reward_trend_value": 0.0002547502260670045, "biggest_recent_change": 0.06409242885422373},
{"total_number_of_episodes": 31826, "number_of_timesteps": 3631671, "per_episode_reward": -130.61, "episode_reward_trend_value": 0.000816281837709059, "biggest_recent_change": 0.05358406806038829},
{"total_number_of_episodes": 31836, "number_of_timesteps": 3632889, "per_episode_reward": -130.64, "episode_reward_trend_value": 0.0008904829362885872, "biggest_recent_change": 0.05358406806038829},
{"total_number_of_episodes": 31846, "number_of_timesteps": 3634340, "per_episode_reward": -130.69, "episode_reward_trend_value": 0.00020875271439832786, "biggest_recent_change": 0.05358406806038829},
{"total_number_of_episodes": 31856, "number_of_timesteps": 3635258, "per_episode_reward": -130.62, "episode_reward_trend_value": 0.00039404689542866183, "biggest_recent_change": 0.07026054435311835},
{"total_number_of_episodes": 31866, "number_of_timesteps": 3636215, "per_episode_reward": -130.66, "episode_reward_trend_value": 0.0003971697903741263, "biggest_recent_change": 0.07026054435311835},
{"total_number_of_episodes": 31876, "number_of_timesteps": 3637307, "per_episode_reward": -130.66, "episode_reward_trend_value": -0.00013507315660585089, "biggest_recent_change": 0.07026054435311835},
{"total_number_of_episodes": 31886, "number_of_timesteps": 3638219, "per_episode_reward": -130.63, "episode_reward_trend_value": 6.0921013325949185e-05, "biggest_recent_change": 0.07026054435311835},
{"total_number_of_episodes": 31896, "number_of_timesteps": 3639230, "per_episode_reward": -130.56, "episode_reward_trend_value": 0.0007016652667721878, "biggest_recent_change": 0.07246154240502278},
{"total_number_of_episodes": 31906, "number_of_timesteps": 3640367, "per_episode_reward": -130.61, "episode_reward_trend_value": -0.0001755568846824139, "biggest_recent_change": 0.07246154240502278},
{"total_number_of_episodes": 31916, "number_of_timesteps": 3641350, "per_episode_reward": -130.59, "episode_reward_trend_value": 0.00018316025672188767, "biggest_recent_change": 0.07246154240502278},
{"total_number_of_episodes": 31926, "number_of_timesteps": 3642719, "per_episode_reward": -130.59, "episode_reward_trend_value": 0.000533484376300761, "biggest_recent_change": 0.07246154240502278},
{"total_number_of_episodes": 31936, "number_of_timesteps": 3643628, "per_episode_reward": -130.59, "episode_reward_trend_value": 0.001138243059416608, "biggest_recent_change": 0.07246154240502278},
{"total_number_of_episodes": 31946, "number_of_timesteps": 3644580, "per_episode_reward": -130.58, "episode_reward_trend_value": 0.00039697880640435164, "biggest_recent_change": 0.07246154240502278},
{"total_number_of_episodes": 31956, "number_of_timesteps": 3645950, "per_episode_reward": -130.61, "episode_reward_trend_value": 0.000493379442838836, "biggest_recent_change": 0.07246154240502278},
{"total_number_of_episodes": 31966, "number_of_timesteps": 3646932, "per_episode_reward": -130.6, "episode_reward_trend_value": 0.0005799769675986808, "biggest_recent_change": 0.07246154240502278},
{"total_number_of_episodes": 31976, "number_of_timesteps": 3647705, "per_episode_reward": -130.57, "episode_reward_trend_value": 0.0006437888665071039, "biggest_recent_change": 0.07246154240502278},
{"total_number_of_episodes": 31986, "number_of_timesteps": 3648885, "per_episode_reward": -130.58, "episode_reward_trend_value": -0.0002576323069095881, "biggest_recent_change": 0.053126541387769066},
{"total_number_of_episodes": 31996, "number_of_timesteps": 3650315, "per_episode_reward": -130.63, "episode_reward_trend_value": -0.00017883467860334198, "biggest_recent_change": 0.046034754840206915},
{"total_number_of_episodes": 32006, "number_of_timesteps": 3651452, "per_episode_reward": -130.63, "episode_reward_trend_value": -0.0003772867786055814, "biggest_recent_change": 0.046034754840206915},
{"total_number_of_episodes": 32016, "number_of_timesteps": 3652579, "per_episode_reward": -130.65, "episode_reward_trend_value": -0.0006776892665704458, "biggest_recent_change": 0.046034754840206915},
{"total_number_of_episodes": 32026, "number_of_timesteps": 3653538, "per_episode_reward": -130.61, "episode_reward_trend_value": -0.00025771967991722203, "biggest_recent_change": 0.046034754840206915},
{"total_number_of_episodes": 32036, "number_of_timesteps": 3654659, "per_episode_reward": -130.61, "episode_reward_trend_value": -0.00026957958995410536, "biggest_recent_change": 0.046034754840206915},
{"total_number_of_episodes": 32046, "number_of_timesteps": 3655708, "per_episode_reward": -130.61, "episode_reward_trend_value": 6.612131013052173e-05, "biggest_recent_change": 0.046034754840206915},
{"total_number_of_episodes": 32056, "number_of_timesteps": 3656742, "per_episode_reward": -130.59, "episode_reward_trend_value": 0.0001235545847322328, "biggest_recent_change": 0.046034754840206915},
{"total_number_of_episodes": 32066, "number_of_timesteps": 3657967, "per_episode_reward": -130.61, "episode_reward_trend_value": -0.0003820795246033034, "biggest_recent_change": 0.046034754840206915},
{"total_number_of_episodes": 32076, "number_of_timesteps": 3659240, "per_episode_reward": -130.63, "episode_reward_trend_value": -0.000471055912996437, "biggest_recent_change": 0.046034754840206915},
{"total_number_of_episodes": 32086, "number_of_timesteps": 3660309, "per_episode_reward": -130.61, "episode_reward_trend_value": 0.00023066435135490337, "biggest_recent_change": 0.044431496443280594},
{"total_number_of_episodes": 32096, "number_of_timesteps": 3661263, "per_episode_reward": -130.61, "episode_reward_trend_value": 0.00019547440398007943, "biggest_recent_change": 0.044431496443280594},
{"total_number_of_episodes": 32107, "number_of_timesteps": 3662452, "per_episode_reward": -130.6, "episode_reward_trend_value": 0.0005927519609568005, "biggest_recent_change": 0.044431496443280594},
{"total_number_of_episodes": 32119, "number_of_timesteps": 3663602, "per_episode_reward": -130.55, "episode_reward_trend_value": 0.0006136742812992048, "biggest_recent_change": 0.04631450527409697},
{"total_number_of_episodes": 32129, "number_of_timesteps": 3664893, "per_episode_reward": -130.6, "episode_reward_trend_value": 0.00010716633884031682, "biggest_recent_change": 0.04631450527409697},
{"total_number_of_episodes": 32140, "number_of_timesteps": 3665792, "per_episode_reward": -130.57, "episode_reward_trend_value": 0.0004555894511548154, "biggest_recent_change": 0.04631450527409697},
{"total_number_of_episodes": 32150, "number_of_timesteps": 3666637, "per_episode_reward": -130.53, "episode_reward_trend_value": 0.0007082135373596859, "biggest_recent_change": 0.04631450527409697},
{"total_number_of_episodes": 32160, "number_of_timesteps": 3667693, "per_episode_reward": -130.54, "episode_reward_trend_value": 0.0008185691471365115, "biggest_recent_change": 0.04631450527409697},
{"total_number_of_episodes": 32171, "number_of_timesteps": 3669172, "per_episode_reward": -130.57, "episode_reward_trend_value": 0.0006547282485153498, "biggest_recent_change": 0.04631450527409697},
{"total_number_of_episodes": 32182, "number_of_timesteps": 3670324, "per_episode_reward": -130.54, "episode_reward_trend_value": 0.0007110098271798254, "biggest_recent_change": 0.04631450527409697},
{"total_number_of_episodes": 32192, "number_of_timesteps": 3671107, "per_episode_reward": -130.51, "episode_reward_trend_value": 0.0010780311058305693, "biggest_recent_change": 0.04631450527409697},
{"total_number_of_episodes": 32202, "number_of_timesteps": 3671838, "per_episode_reward": -130.48, "episode_reward_trend_value": 0.0013672782293648804, "biggest_recent_change": 0.04631450527409697},
{"total_number_of_episodes": 32212, "number_of_timesteps": 3672967, "per_episode_reward": -130.47, "episode_reward_trend_value": 0.0009395880939908667, "biggest_recent_change": 0.04310634514260414},
{"total_number_of_episodes": 32222, "number_of_timesteps": 3674382, "per_episode_reward": -130.52, "episode_reward_trend_value": 0.000886604275119238, "biggest_recent_change": 0.04787488884105073},
{"total_number_of_episodes": 32233, "number_of_timesteps": 3675923, "per_episode_reward": -130.51, "episode_reward_trend_value": 0.0006243470976803185, "biggest_recent_change": 0.04787488884105073},
{"total_number_of_episodes": 32243, "number_of_timesteps": 3676708, "per_episode_reward": -130.48, "episode_reward_trend_value": 0.0004988166250200265, "biggest_recent_change": 0.04787488884105073},
{"total_number_of_episodes": 32253, "number_of_timesteps": 3677535, "per_episode_reward": -130.45, "episode_reward_trend_value": 0.000957541516982019, "biggest_recent_change": 0.04787488884105073},
{"total_number_of_episodes": 32263, "number_of_timesteps": 3678716, "per_episode_reward": -130.44, "episode_reward_trend_value": 0.0013601825741798418, "biggest_recent_change": 0.04787488884105073},
{"total_number_of_episodes": 32273, "number_of_timesteps": 3679750, "per_episode_reward": -130.41, "episode_reward_trend_value": 0.0015471184206265636, "biggest_recent_change": 0.04787488884105073},
{"total_number_of_episodes": 32283, "number_of_timesteps": 3680983, "per_episode_reward": -130.42, "episode_reward_trend_value": 0.0010199770007470002, "biggest_recent_change": 0.04787488884105073},
{"total_number_of_episodes": 32293, "number_of_timesteps": 3682455, "per_episode_reward": -130.45, "episode_reward_trend_value": 0.0002633189089313722, "biggest_recent_change": 0.04787488884105073},
{"total_number_of_episodes": 32303, "number_of_timesteps": 3683232, "per_episode_reward": -130.42, "episode_reward_trend_value": 0.0005152850650565218, "biggest_recent_change": 0.04787488884105073},
{"total_number_of_episodes": 32313, "number_of_timesteps": 3684123, "per_episode_reward": -130.38, "episode_reward_trend_value": 0.0015244085858016534, "biggest_recent_change": 0.04294622802601111},
{"total_number_of_episodes": 32323, "number_of_timesteps": 3685019, "per_episode_reward": -130.36, "episode_reward_trend_value": 0.001615010321941352, "biggest_recent_change": 0.04294622802601111},
{"total_number_of_episodes": 32333, "number_of_timesteps": 3685961, "per_episode_reward": -130.35, "episode_reward_trend_value": 0.001468852055312987, "biggest_recent_change": 0.04294622802601111},
{"total_number_of_episodes": 32343, "number_of_timesteps": 3687369, "per_episode_reward": -130.37, "episode_reward_trend_value": 0.0008988234338074916, "biggest_recent_change": 0.04294622802601111},
{"total_number_of_episodes": 32353, "number_of_timesteps": 3688727, "per_episode_reward": -130.39, "episode_reward_trend_value": 0.0006447995221148201, "biggest_recent_change": 0.04294622802601111},
{"total_number_of_episodes": 32363, "number_of_timesteps": 3689920, "per_episode_reward": -130.34, "episode_reward_trend_value": 0.0007244655948517852, "biggest_recent_change": 0.04617958375774833},
{"total_number_of_episodes": 32373, "number_of_timesteps": 3690892, "per_episode_reward": -130.34, "episode_reward_trend_value": 0.0008793591279211595, "biggest_recent_change": 0.04617958375774833},
{"total_number_of_episodes": 32383, "number_of_timesteps": 3692034, "per_episode_reward": -130.28, "episode_reward_trend_value": 0.0019721738273621742, "biggest_recent_change": 0.06768111571409463},
{"total_number_of_episodes": 32393, "number_of_timesteps": 3693708, "per_episode_reward": -130.31, "episode_reward_trend_value": 0.0012447248895111015, "biggest_recent_change": 0.06768111571409463},
{"total_number_of_episodes": 32404, "number_of_timesteps": 3694827, "per_episode_reward": -130.29, "episode_reward_trend_value": 0.001007992226512834, "biggest_recent_change": 0.06768111571409463},
{"total_number_of_episodes": 32414, "number_of_timesteps": 3695613, "per_episode_reward": -130.25, "episode_reward_trend_value": 0.0012318525291985024, "biggest_recent_change": 0.06768111571409463},
{"total_number_of_episodes": 32424, "number_of_timesteps": 3696401, "per_episode_reward": -130.22, "episode_reward_trend_value": 0.0014246108881160859, "biggest_recent_change": 0.06768111571409463},
{"total_number_of_episodes": 32435, "number_of_timesteps": 3697564, "per_episode_reward": -130.22, "episode_reward_trend_value": 0.0016612560020392822, "biggest_recent_change": 0.06768111571409463},
{"total_number_of_episodes": 32445, "number_of_timesteps": 3699060, "per_episode_reward": -130.24, "episode_reward_trend_value": 0.001659570032839497, "biggest_recent_change": 0.06768111571409463},
{"total_number_of_episodes": 32455, "number_of_timesteps": 3700232, "per_episode_reward": -130.21, "episode_reward_trend_value": 0.0014386051239970103, "biggest_recent_change": 0.06768111571409463},
{"total_number_of_episodes": 32465, "number_of_timesteps": 3701167, "per_episode_reward": -130.17, "episode_reward_trend_value": 0.0019014736933118885, "biggest_recent_change": 0.06768111571409463},
{"total_number_of_episodes": 32475, "number_of_timesteps": 3702101, "per_episode_reward": -130.17, "episode_reward_trend_value": 0.0011635390905313317, "biggest_recent_change": 0.0388899511600016},
{"total_number_of_episodes": 32485, "number_of_timesteps": 3703207, "per_episode_reward": -130.17, "episode_reward_trend_value": 0.0015124562750056865, "biggest_recent_change": 0.0388899511600016},
{"total_number_of_episodes": 32495, "number_of_timesteps": 3704344, "per_episode_reward": -130.16, "episode_reward_trend_value": 0.0014458855096048892, "biggest_recent_change": 0.0388899511600016},
{"total_number_of_episodes": 32505, "number_of_timesteps": 3705354, "per_episode_reward": -130.13, "episode_reward_trend_value": 0.0013518882428122147, "biggest_recent_change": 0.0388899511600016},
{"total_number_of_episodes": 32515, "number_of_timesteps": 3706221, "per_episode_reward": -130.0, "episode_reward_trend_value": 0.0024388274090259504, "biggest_recent_change": 0.1269230216682331},
{"total_number_of_episodes": 32525, "number_of_timesteps": 3707379, "per_episode_reward": -129.99, "episode_reward_trend_value": 0.002503520796223155, "biggest_recent_change": 0.1269230216682331},
{"total_number_of_episodes": 32535, "number_of_timesteps": 3708476, "per_episode_reward": -129.99, "episode_reward_trend_value": 0.002743018500093007, "biggest_recent_change": 0.1269230216682331},
{"total_number_of_episodes": 32545, "number_of_timesteps": 3709622, "per_episode_reward": -129.99, "episode_reward_trend_value": 0.0024820256643753027, "biggest_recent_change": 0.1269230216682331},
{"total_number_of_episodes": 32555, "number_of_timesteps": 3710859, "per_episode_reward": -129.96, "episode_reward_trend_value": 0.0023141469963462668, "biggest_recent_change": 0.1269230216682331},
{"total_number_of_episodes": 32565, "number_of_timesteps": 3711820, "per_episode_reward": -129.96, "episode_reward_trend_value": 0.002333572313700453, "biggest_recent_change": 0.1269230216682331},
{"total_number_of_episodes": 32575, "number_of_timesteps": 3713150, "per_episode_reward": -129.96, "episode_reward_trend_value": 0.0024107879626503364, "biggest_recent_change": 0.1269230216682331},
{"total_number_of_episodes": 32586, "number_of_timesteps": 3714548, "per_episode_reward": -129.97, "episode_reward_trend_value": 0.0021361286022296452, "biggest_recent_change": 0.1269230216682331},
{"total_number_of_episodes": 32598, "number_of_timesteps": 3715889, "per_episode_reward": -129.97, "episode_reward_trend_value": 0.0018089238958215975, "biggest_recent_change": 0.1269230216682331},
{"total_number_of_episodes": 32608, "number_of_timesteps": 3716929, "per_episode_reward": -129.96, "episode_reward_trend_value": 0.00047251933703509826, "biggest_recent_change": 0.02378087103738835},
{"total_number_of_episodes": 32618, "number_of_timesteps": 3718176, "per_episode_reward": -129.96, "episode_reward_trend_value": 0.0003997078920671508, "biggest_recent_change": 0.02378087103738835},
{"total_number_of_episodes": 32628, "number_of_timesteps": 3719394, "per_episode_reward": -129.96, "episode_reward_trend_value": 0.00037527679917369973, "biggest_recent_change": 0.02378087103738835},
{"total_number_of_episodes": 32640, "number_of_timesteps": 3720945, "per_episode_reward": -129.91, "episode_reward_trend_value": 0.000827326478555632, "biggest_recent_change": 0.04348785789170506},
{"total_number_of_episodes": 32650, "number_of_timesteps": 3722032, "per_episode_reward": -129.9, "episode_reward_trend_value": 0.0006629023437003272, "biggest_recent_change": 0.04348785789170506},
{"total_number_of_episodes": 32660, "number_of_timesteps": 3722980, "per_episode_reward": -129.9, "episode_reward_trend_value": 0.0006782803594398325, "biggest_recent_change": 0.04348785789170506},
{"total_number_of_episodes": 32670, "number_of_timesteps": 3724008, "per_episode_reward": -129.89, "episode_reward_trend_value": 0.0006981820606509043, "biggest_recent_change": 0.04348785789170506},
{"total_number_of_episodes": 32680, "number_of_timesteps": 3725388, "per_episode_reward": -129.94, "episode_reward_trend_value": 0.0003189211688954351, "biggest_recent_change": 0.04348785789170506},
{"total_number_of_episodes": 32690, "number_of_timesteps": 3726550, "per_episode_reward": -129.9, "episode_reward_trend_value": 0.000803713090396564, "biggest_recent_change": 0.04348785789170506},
{"total_number_of_episodes": 32700, "number_of_timesteps": 3727522, "per_episode_reward": -129.9, "episode_reward_trend_value": 0.0006892208809239896, "biggest_recent_change": 0.04348785789170506},
{"total_number_of_episodes": 32710, "number_of_timesteps": 3728597, "per_episode_reward": -129.93, "episode_reward_trend_value": 0.0003176256751477998, "biggest_recent_change": 0.04348785789170506},
{"total_number_of_episodes": 32720, "number_of_timesteps": 3730190, "per_episode_reward": -129.99, "episode_reward_trend_value": -0.0003543599456492075, "biggest_recent_change": 0.059318824050137664},
{"total_number_of_episodes": 32731, "number_of_timesteps": 3731463, "per_episode_reward": -129.97, "episode_reward_trend_value": -0.0006348910948275943, "biggest_recent_change": 0.059318824050137664},
{"total_number_of_episodes": 32741, "number_of_timesteps": 3732609, "per_episode_reward": -129.99, "episode_reward_trend_value": -0.0009230453867764431, "biggest_recent_change": 0.059318824050137664},
{"total_number_of_episodes": 32752, "number_of_timesteps": 3733793, "per_episode_reward": -129.98, "episode_reward_trend_value": -0.0008414849215392274, "biggest_recent_change": 0.059318824050137664},
{"total_number_of_episodes": 32762, "number_of_timesteps": 3734959, "per_episode_reward": -129.99, "episode_reward_trend_value": -0.0010604714316507903, "biggest_recent_change": 0.059318824050137664},
{"total_number_of_episodes": 32772, "number_of_timesteps": 3736334, "per_episode_reward": -129.98, "episode_reward_trend_value": -0.000529458379604206, "biggest_recent_change": 0.059318824050137664},
{"total_number_of_episodes": 32782, "number_of_timesteps": 3737667, "per_episode_reward": -129.97, "episode_reward_trend_value": -0.0007839875037673336, "biggest_recent_change": 0.059318824050137664},
{"total_number_of_episodes": 32792, "number_of_timesteps": 3738920, "per_episode_reward": -129.97, "episode_reward_trend_value": -0.0007707609369481993, "biggest_recent_change": 0.059318824050137664},
{"total_number_of_episodes": 32802, "number_of_timesteps": 3740086, "per_episode_reward": -130.0, "episode_reward_trend_value": -0.0007716322208630623, "biggest_recent_change": 0.059318824050137664},
{"total_number_of_episodes": 32812, "number_of_timesteps": 3741807, "per_episode_reward": -129.98, "episode_reward_trend_value": 4.936383750223033e-05, "biggest_recent_change": 0.028806643200567805},
{"total_number_of_episodes": 32822, "number_of_timesteps": 3743168, "per_episode_reward": -130.04, "episode_reward_trend_value": -0.0007680479073226504, "biggest_recent_change": 0.05532700256858902},
{"total_number_of_episodes": 32832, "number_of_timesteps": 3744051, "per_episode_reward": -129.98, "episode_reward_trend_value": 0.00012198490877134797, "biggest_recent_change": 0.06315176607347439},
{"total_number_of_episodes": 32844, "number_of_timesteps": 3745266, "per_episode_reward": -129.98, "episode_reward_trend_value": -5.392364157677952e-05, "biggest_recent_change": 0.06315176607347439},
{"total_number_of_episodes": 32854, "number_of_timesteps": 3746250, "per_episode_reward": -129.97, "episode_reward_trend_value": 0.0002061928219010017, "biggest_recent_change": 0.06315176607347439},
{"total_number_of_episodes": 32864, "number_of_timesteps": 3747401, "per_episode_reward": -129.98, "episode_reward_trend_value": 8.614745098232864e-05, "biggest_recent_change": 0.06315176607347439},
{"total_number_of_episodes": 32874, "number_of_timesteps": 3748150, "per_episode_reward": -129.94, "episode_reward_trend_value": 0.00028412492720425084, "biggest_recent_change": 0.06315176607347439},
{"total_number_of_episodes": 32884, "number_of_timesteps": 3749008, "per_episode_reward": -129.96, "episode_reward_trend_value": 0.00012788361563246376, "biggest_recent_change": 0.06315176607347439},
{"total_number_of_episodes": 32894, "number_of_timesteps": 3749849, "per_episode_reward": -129.92, "episode_reward_trend_value": 0.0008368469915470515, "biggest_recent_change": 0.06315176607347439},
{"total_number_of_episodes": 32905, "number_of_timesteps": 3750773, "per_episode_reward": -129.83, "episode_reward_trend_value": 0.0016862745376992432, "biggest_recent_change": 0.0910193003564359},
{"total_number_of_episodes": 32916, "number_of_timesteps": 3751930, "per_episode_reward": -129.81, "episode_reward_trend_value": 0.002541192269274006, "biggest_recent_change": 0.0910193003564359},
{"total_number_of_episodes": 32926, "number_of_timesteps": 3753557, "per_episode_reward": -129.8, "episode_reward_trend_value": 0.001977112360226998, "biggest_recent_change": 0.0910193003564359},
{"total_number_of_episodes": 32936, "number_of_timesteps": 3755174, "per_episode_reward": -129.83, "episode_reward_trend_value": 0.0016294921104954736, "biggest_recent_change": 0.0910193003564359},
{"total_number_of_episodes": 32946, "number_of_timesteps": 3756188, "per_episode_reward": -129.81, "episode_reward_trend_value": 0.0018186105988159322, "biggest_recent_change": 0.0910193003564359},
{"total_number_of_episodes": 32957, "number_of_timesteps": 3757403, "per_episode_reward": -129.79, "episode_reward_trend_value": 0.0020455492442494005, "biggest_recent_change": 0.0910193003564359},
{"total_number_of_episodes": 32967, "number_of_timesteps": 3758504, "per_episode_reward": -129.8, "episode_reward_trend_value": 0.0015845785136273586, "biggest_recent_change": 0.0910193003564359},
{"total_number_of_episodes": 32978, "number_of_timesteps": 3759590, "per_episode_reward": -129.8, "episode_reward_trend_value": 0.0017663497326708467, "biggest_recent_change": 0.0910193003564359},
{"total_number_of_episodes": 32989, "number_of_timesteps": 3760674, "per_episode_reward": -129.76, "episode_reward_trend_value": 0.0017716664593406348, "biggest_recent_change": 0.0910193003564359},
{"total_number_of_episodes": 33000, "number_of_timesteps": 3761917, "per_episode_reward": -129.76, "episode_reward_trend_value": 0.0008527378230995611, "biggest_recent_change": 0.03547856603202604},
{"total_number_of_episodes": 33011, "number_of_timesteps": 3762867, "per_episode_reward": -129.75, "episode_reward_trend_value": 0.0006848506217936448, "biggest_recent_change": 0.03547856603202604},
{"total_number_of_episodes": 33021, "number_of_timesteps": 3763941, "per_episode_reward": -129.75, "episode_reward_trend_value": 0.0005046323765438072, "biggest_recent_change": 0.03547856603202604},
{"total_number_of_episodes": 33031, "number_of_timesteps": 3765088, "per_episode_reward": -129.8, "episode_reward_trend_value": 0.000342915016256029, "biggest_recent_change": 0.04993241111944258},
{"total_number_of_episodes": 33041, "number_of_timesteps": 3766331, "per_episode_reward": -129.83, "episode_reward_trend_value": -0.00025771486165966607, "biggest_recent_change": 0.04993241111944258},
{"total_number_of_episodes": 33051, "number_of_timesteps": 3767341, "per_episode_reward": -129.81, "episode_reward_trend_value": -0.00019449980770976555, "biggest_recent_change": 0.04993241111944258},
{"total_number_of_episodes": 33061, "number_of_timesteps": 3768246, "per_episode_reward": -129.78, "episode_reward_trend_value": 0.00017012224240728655, "biggest_recent_change": 0.04993241111944258},
{"total_number_of_episodes": 33072, "number_of_timesteps": 3769775, "per_episode_reward": -129.83, "episode_reward_trend_value": -0.00033737634358475235, "biggest_recent_change": 0.04993241111944258},

{"total_number_of_episodes": 33082, "number_of_timesteps": 3770911, "per_episode_reward": -129.83, "episode_reward_trend_value": -0.0007505275610997033, "biggest_recent_change": 0.04993241111944258},
{"total_number_of_episodes": 33092, "number_of_timesteps": 3772306, "per_episode_reward": -129.84, "episode_reward_trend_value": -0.0009384292176002241, "biggest_recent_change": 0.04993241111944258},
{"total_number_of_episodes": 33102, "number_of_timesteps": 3773176, "per_episode_reward": -129.81, "episode_reward_trend_value": -0.0006481313238876081, "biggest_recent_change": 0.04993241111944258},
{"total_number_of_episodes": 33113, "number_of_timesteps": 3774338, "per_episode_reward": -129.76, "episode_reward_trend_value": -0.0001173140499351651, "biggest_recent_change": 0.04993241111944258},
{"total_number_of_episodes": 33123, "number_of_timesteps": 3775602, "per_episode_reward": -129.77, "episode_reward_trend_value": 0.00040765428418138884, "biggest_recent_change": 0.045844477528191874},
{"total_number_of_episodes": 33133, "number_of_timesteps": 3776676, "per_episode_reward": -129.77, "episode_reward_trend_value": 0.0006929047845012015, "biggest_recent_change": 0.045844477528191874},
{"total_number_of_episodes": 33143, "number_of_timesteps": 3777867, "per_episode_reward": -129.76, "episode_reward_trend_value": 0.000508779759297795, "biggest_recent_change": 0.045844477528191874},
{"total_number_of_episodes": 33154, "number_of_timesteps": 3779258, "per_episode_reward": -129.75, "episode_reward_trend_value": 0.000362563910770872, "biggest_recent_change": 0.045844477528191874},
{"total_number_of_episodes": 33164, "number_of_timesteps": 3780291, "per_episode_reward": -129.76, "episode_reward_trend_value": 0.0007586094596822098, "biggest_recent_change": 0.04393848684247814},
{"total_number_of_episodes": 33174, "number_of_timesteps": 3781315, "per_episode_reward": -129.77, "episode_reward_trend_value": 0.0006994549560264179, "biggest_recent_change": 0.04393848684247814},
{"total_number_of_episodes": 33184, "number_of_timesteps": 3782528, "per_episode_reward": -129.79, "episode_reward_trend_value": 0.0005603392509496214, "biggest_recent_change": 0.04393848684247814},
{"total_number_of_episodes": 33194, "number_of_timesteps": 3783253, "per_episode_reward": -129.77, "episode_reward_trend_value": 0.00044406823283035617, "biggest_recent_change": 0.04393848684247814},
{"total_number_of_episodes": 33204, "number_of_timesteps": 3784399, "per_episode_reward": -129.74, "episode_reward_trend_value": 0.00024418169545962576, "biggest_recent_change": 0.02594869847911241},
{"total_number_of_episodes": 33214, "number_of_timesteps": 3785484, "per_episode_reward": -129.78, "episode_reward_trend_value": -0.00010440667640586475, "biggest_recent_change": 0.034058214516846874},
{"total_number_of_episodes": 33224, "number_of_timesteps": 3786582, "per_episode_reward": -129.75, "episode_reward_trend_value": 0.00016394783508846762, "biggest_recent_change": 0.034058214516846874},
{"total_number_of_episodes": 33234, "number_of_timesteps": 3787853, "per_episode_reward": -129.8, "episode_reward_trend_value": -0.0003509017072139563, "biggest_recent_change": 0.0430106900552687},
{"total_number_of_episodes": 33244, "number_of_timesteps": 3788909, "per_episode_reward": -129.78, "episode_reward_trend_value": -0.00029424646956878556, "biggest_recent_change": 0.0430106900552687},
{"total_number_of_episodes": 33255, "number_of_timesteps": 3790740, "per_episode_reward": -129.69, "episode_reward_trend_value": 0.000743720027349405, "biggest_recent_change": 0.08321660659646568},
{"total_number_of_episodes": 33265, "number_of_timesteps": 3791587, "per_episode_reward": -129.65, "episode_reward_trend_value": 0.0012999466627146856, "biggest_recent_change": 0.08321660659646568},
{"total_number_of_episodes": 33275, "number_of_timesteps": 3793362, "per_episode_reward": -129.64, "episode_reward_trend_value": 0.001634758298108194, "biggest_recent_change": 0.08321660659646568},
{"total_number_of_episodes": 33286, "number_of_timesteps": 3794413, "per_episode_reward": -129.63, "episode_reward_trend_value": 0.001541561099104961, "biggest_recent_change": 0.08321660659646568},
{"total_number_of_episodes": 33296, "number_of_timesteps": 3795542, "per_episode_reward": -129.62, "episode_reward_trend_value": 0.001342372844071191, "biggest_recent_change": 0.08321660659646568},
{"total_number_of_episodes": 33306, "number_of_timesteps": 3796690, "per_episode_reward": -129.61, "episode_reward_trend_value": 0.0018513995926759384, "biggest_recent_change": 0.08321660659646568},
{"total_number_of_episodes": 33316, "number_of_timesteps": 3798641, "per_episode_reward": -129.59, "episode_reward_trend_value": 0.001815302833819664, "biggest_recent_change": 0.08321660659646568},
{"total_number_of_episodes": 33326, "number_of_timesteps": 3799528, "per_episode_reward": -129.58, "episode_reward_trend_value": 0.002363621484303419, "biggest_recent_change": 0.08321660659646568},
{"total_number_of_episodes": 33336, "number_of_timesteps": 3800495, "per_episode_reward": -129.58, "episode_reward_trend_value": 0.0021451316791901336, "biggest_recent_change": 0.08321660659646568},
{"total_number_of_episodes": 33347, "number_of_timesteps": 3801764, "per_episode_reward": -129.58, "episode_reward_trend_value": 0.0013055670408359927, "biggest_recent_change": 0.043031448309534426},
{"total_number_of_episodes": 33357, "number_of_timesteps": 3802663, "per_episode_reward": -129.58, "episode_reward_trend_value": 0.000830309742851101, "biggest_recent_change": 0.018413464357877274},
{"total_number_of_episodes": 33367, "number_of_timesteps": 3803828, "per_episode_reward": -129.59, "episode_reward_trend_value": 0.0005318928113988856, "biggest_recent_change": 0.018413464357877274},
{"total_number_of_episodes": 33377, "number_of_timesteps": 3805090, "per_episode_reward": -129.62, "episode_reward_trend_value": 0.0001232161660567499, "biggest_recent_change": 0.023000482032074387},
{"total_number_of_episodes": 33387, "number_of_timesteps": 3806240, "per_episode_reward": -129.58, "episode_reward_trend_value": 0.00047245055455044215, "biggest_recent_change": 0.0394528504905054},
{"total_number_of_episodes": 33397, "number_of_timesteps": 3807473, "per_episode_reward": -129.58, "episode_reward_trend_value": 0.0003254608069302852, "biggest_recent_change": 0.0394528504905054},
{"total_number_of_episodes": 33407, "number_of_timesteps": 3808638, "per_episode_reward": -129.59, "episode_reward_trend_value": -2.6996656179297435e-05, "biggest_recent_change": 0.0394528504905054},
{"total_number_of_episodes": 33418, "number_of_timesteps": 3810105, "per_episode_reward": -129.6, "episode_reward_trend_value": -0.00019132184493236712, "biggest_recent_change": 0.0394528504905054},
{"total_number_of_episodes": 33428, "number_of_timesteps": 3811465, "per_episode_reward": -129.62, "episode_reward_trend_value": -0.0003639822460816807, "biggest_recent_change": 0.0394528504905054},
{"total_number_of_episodes": 33438, "number_of_timesteps": 3812573, "per_episode_reward": -129.67, "episode_reward_trend_value": -0.0010292482849062405, "biggest_recent_change": 0.05221815434961741},
{"total_number_of_episodes": 33448, "number_of_timesteps": 3813674, "per_episode_reward": -129.67, "episode_reward_trend_value": -0.0009904257680043807, "biggest_recent_change": 0.05221815434961741},
{"total_number_of_episodes": 33458, "number_of_timesteps": 3814823, "per_episode_reward": -129.65, "episode_reward_trend_value": -0.0006156608783217936, "biggest_recent_change": 0.05221815434961741},
{"total_number_of_episodes": 33468, "number_of_timesteps": 3815765, "per_episode_reward": -129.62, "episode_reward_trend_value": -3.491564353813222e-05, "biggest_recent_change": 0.05221815434961741},
{"total_number_of_episodes": 33478, "number_of_timesteps": 3816605, "per_episode_reward": -129.58, "episode_reward_trend_value": -4.700924226186645e-05, "biggest_recent_change": 0.05221815434961741},
{"total_number_of_episodes": 33488, "number_of_timesteps": 3817825, "per_episode_reward": -129.57, "episode_reward_trend_value": 9.43632990448072e-05, "biggest_recent_change": 0.05221815434961741},
{"total_number_of_episodes": 33498, "number_of_timesteps": 3819104, "per_episode_reward": -129.59, "episode_reward_trend_value": 1.384745491211308e-05, "biggest_recent_change": 0.05221815434961741},
{"total_number_of_episodes": 33509, "number_of_timesteps": 3820343, "per_episode_reward": -129.62, "episode_reward_trend_value": -0.00019117850103593054, "biggest_recent_change": 0.05221815434961741},
{"total_number_of_episodes": 33519, "number_of_timesteps": 3821558, "per_episode_reward": -129.6, "episode_reward_trend_value": 0.00021363026300712639, "biggest_recent_change": 0.05221815434961741},
{"total_number_of_episodes": 33529, "number_of_timesteps": 3822609, "per_episode_reward": -129.64, "episode_reward_trend_value": 0.00033202895821078627, "biggest_recent_change": 0.04156227178128802},
{"total_number_of_episodes": 33539, "number_of_timesteps": 3823936, "per_episode_reward": -129.63, "episode_reward_trend_value": 0.0003678985231958778, "biggest_recent_change": 0.04156227178128802},
{"total_number_of_episodes": 33549, "number_of_timesteps": 3825057, "per_episode_reward": -129.64, "episode_reward_trend_value": 0.00014353062030004872, "biggest_recent_change": 0.04156227178128802},
{"total_number_of_episodes": 33559, "number_of_timesteps": 3826240, "per_episode_reward": -129.65, "episode_reward_trend_value": -0.0003583775031668463, "biggest_recent_change": 0.04156227178128802},
{"total_number_of_episodes": 33569, "number_of_timesteps": 3827407, "per_episode_reward": -129.65, "episode_reward_trend_value": -0.0007856109903880478, "biggest_recent_change": 0.04156227178128802},
{"total_number_of_episodes": 33579, "number_of_timesteps": 3828538, "per_episode_reward": -129.59, "episode_reward_trend_value": -0.00016520889774306448, "biggest_recent_change": 0.06708483262741538},
{"total_number_of_episodes": 33589, "number_of_timesteps": 3829712, "per_episode_reward": -129.64, "episode_reward_trend_value": -0.0005848646907531298, "biggest_recent_change": 0.06708483262741538},
{"total_number_of_episodes": 33599, "number_of_timesteps": 3830764, "per_episode_reward": -129.63, "episode_reward_trend_value": -0.0001434202946294742, "biggest_recent_change": 0.06708483262741538},
{"total_number_of_episodes": 33609, "number_of_timesteps": 3831663, "per_episode_reward": -129.58, "episode_reward_trend_value": 0.00017790515745730318, "biggest_recent_change": 0.06708483262741538},
{"total_number_of_episodes": 33619, "number_of_timesteps": 3833078, "per_episode_reward": -129.62, "episode_reward_trend_value": 0.0002135507089301806, "biggest_recent_change": 0.06708483262741538},
{"total_number_of_episodes": 33629, "number_of_timesteps": 3834189, "per_episode_reward": -129.62, "episode_reward_trend_value": 0.0001062900996856797, "biggest_recent_change": 0.06708483262741538},
{"total_number_of_episodes": 33639, "number_of_timesteps": 3835491, "per_episode_reward": -129.61, "episode_reward_trend_value": 0.00030659673042047564, "biggest_recent_change": 0.06708483262741538},
{"total_number_of_episodes": 33650, "number_of_timesteps": 3837326, "per_episode_reward": -129.6, "episode_reward_trend_value": 0.0005980126005277321, "biggest_recent_change": 0.06708483262741538},
{"total_number_of_episodes": 33660, "number_of_timesteps": 3838474, "per_episode_reward": -129.61, "episode_reward_trend_value": 0.0004566670902991948, "biggest_recent_change": 0.06708483262741538},
{"total_number_of_episodes": 33670, "number_of_timesteps": 3839364, "per_episode_reward": -129.58, "episode_reward_trend_value": 7.624969059476269e-05, "biggest_recent_change": 0.05832315466483351},
{"total_number_of_episodes": 33680, "number_of_timesteps": 3840496, "per_episode_reward": -129.6, "episode_reward_trend_value": 0.0005249171643305949, "biggest_recent_change": 0.049301414552644474},
{"total_number_of_episodes": 33690, "number_of_timesteps": 3841717, "per_episode_reward": -129.58, "episode_reward_trend_value": 0.0005757165940798991, "biggest_recent_change": 0.049301414552644474},
{"total_number_of_episodes": 33701, "number_of_timesteps": 3842938, "per_episode_reward": -129.6, "episode_reward_trend_value": -0.0002001013573602803, "biggest_recent_change": 0.03835417214872905},
{"total_number_of_episodes": 33711, "number_of_timesteps": 3844122, "per_episode_reward": -129.61, "episode_reward_trend_value": 0.00012888924868958737, "biggest_recent_change": 0.032847266654016494},
{"total_number_of_episodes": 33722, "number_of_timesteps": 3845357, "per_episode_reward": -129.61, "episode_reward_trend_value": 0.00011001305144210012, "biggest_recent_change": 0.032847266654016494},
{"total_number_of_episodes": 33732, "number_of_timesteps": 3846372, "per_episode_reward": -129.61, "episode_reward_trend_value": 1.203537151089525e-05, "biggest_recent_change": 0.032847266654016494},
{"total_number_of_episodes": 33742, "number_of_timesteps": 3847932, "per_episode_reward": -129.65, "episode_reward_trend_value": -0.0006136815806876761, "biggest_recent_change": 0.04599223940178376},
{"total_number_of_episodes": 33752, "number_of_timesteps": 3849108, "per_episode_reward": -129.66, "episode_reward_trend_value": -0.0005558210092904876, "biggest_recent_change": 0.04599223940178376},
{"total_number_of_episodes": 33762, "number_of_timesteps": 3850265, "per_episode_reward": -129.67, "episode_reward_trend_value": -0.0010148224657838354, "biggest_recent_change": 0.04599223940178376},
{"total_number_of_episodes": 33772, "number_of_timesteps": 3851367, "per_episode_reward": -129.67, "episode_reward_trend_value": -0.0008661531251798729, "biggest_recent_change": 0.04599223940178376},
{"total_number_of_episodes": 33782, "number_of_timesteps": 3852147, "per_episode_reward": -129.67, "episode_reward_trend_value": -0.0009845534592421421, "biggest_recent_change": 0.04599223940178376},
{"total_number_of_episodes": 33793, "number_of_timesteps": 3853412, "per_episode_reward": -129.67, "episode_reward_trend_value": -0.0007882479120584977, "biggest_recent_change": 0.04599223940178376},
{"total_number_of_episodes": 33803, "number_of_timesteps": 3854372, "per_episode_reward": -129.67, "episode_reward_trend_value": -0.0006387042482547006, "biggest_recent_change": 0.04599223940178376},
{"total_number_of_episodes": 33813, "number_of_timesteps": 3856082, "per_episode_reward": -129.69, "episode_reward_trend_value": -0.0008523619821583376, "biggest_recent_change": 0.04599223940178376},
{"total_number_of_episodes": 33823, "number_of_timesteps": 3857199, "per_episode_reward": -129.71, "episode_reward_trend_value": -0.0011270422850031992, "biggest_recent_change": 0.04599223940178376},
{"total_number_of_episodes": 33833, "number_of_timesteps": 3858050, "per_episode_reward": -129.66, "episode_reward_trend_value": -0.00010940968464865364, "biggest_recent_change": 0.04559469463012533},
{"total_number_of_episodes": 33843, "number_of_timesteps": 3859162, "per_episode_reward": -129.65, "episode_reward_trend_value": 0.00010751961134284708, "biggest_recent_change": 0.04559469463012533},
{"total_number_of_episodes": 33853, "number_of_timesteps": 3860237, "per_episode_reward": -129.67, "episode_reward_trend_value": 2.275611761572489e-05, "biggest_recent_change": 0.04559469463012533},
{"total_number_of_episodes": 33863, "number_of_timesteps": 3861220, "per_episode_reward": -129.65, "episode_reward_trend_value": 0.0002422870013440893, "biggest_recent_change": 0.04559469463012533},
{"total_number_of_episodes": 33874, "number_of_timesteps": 3862085, "per_episode_reward": -129.63, "episode_reward_trend_value": 0.00039509817827491943, "biggest_recent_change": 0.04559469463012533},
{"total_number_of_episodes": 33884, "number_of_timesteps": 3863178, "per_episode_reward": -129.59, "episode_reward_trend_value": 0.0009116117603168858, "biggest_recent_change": 0.04559469463012533},
{"total_number_of_episodes": 33894, "number_of_timesteps": 3864268, "per_episode_reward": -129.61, "episode_reward_trend_value": 0.0006589109991131813, "biggest_recent_change": 0.04559469463012533},
{"total_number_of_episodes": 33904, "number_of_timesteps": 3865551, "per_episode_reward": -129.58, "episode_reward_trend_value": 0.001173030373421587, "biggest_recent_change": 0.04559469463012533},
{"total_number_of_episodes": 33914, "number_of_timesteps": 3866398, "per_episode_reward": -129.59, "episode_reward_trend_value": 0.001287879418662088, "biggest_recent_change": 0.04559469463012533},
{"total_number_of_episodes": 33924, "number_of_timesteps": 3867378, "per_episode_reward": -129.59, "episode_reward_trend_value": 0.0007941094804850637, "biggest_recent_change": 0.0436315205533333},
{"total_number_of_episodes": 33934, "number_of_timesteps": 3868504, "per_episode_reward": -129.57, "episode_reward_trend_value": 0.0009528251058785346, "biggest_recent_change": 0.0436315205533333},
{"total_number_of_episodes": 33944, "number_of_timesteps": 3869507, "per_episode_reward": -129.58, "episode_reward_trend_value": 0.0009876365591957716, "biggest_recent_change": 0.0436315205533333},
{"total_number_of_episodes": 33954, "number_of_timesteps": 3870626, "per_episode_reward": -129.58, "episode_reward_trend_value": 0.0007665949996215381, "biggest_recent_change": 0.0436315205533333},
{"total_number_of_episodes": 33964, "number_of_timesteps": 3871708, "per_episode_reward": -129.59, "episode_reward_trend_value": 0.000473667505859036, "biggest_recent_change": 0.0436315205533333},
{"total_number_of_episodes": 33974, "number_of_timesteps": 3872719, "per_episode_reward": -129.61, "episode_reward_trend_value": -0.00024005070919675596, "biggest_recent_change": 0.026207811185287255},
{"total_number_of_episodes": 33985, "number_of_timesteps": 3874168, "per_episode_reward": -129.6, "episode_reward_trend_value": 7.305851254481391e-05, "biggest_recent_change": 0.026207811185287255},
{"total_number_of_episodes": 33995, "number_of_timesteps": 3875478, "per_episode_reward": -129.58, "episode_reward_trend_value": 2.53311358648034e-05, "biggest_recent_change": 0.026207811185287255},
{"total_number_of_episodes": 34006, "number_of_timesteps": 3876812, "per_episode_reward": -129.63, "episode_reward_trend_value": -0.0004026457627077207, "biggest_recent_change": 0.047997715765291105},
{"total_number_of_episodes": 34016, "number_of_timesteps": 3878237, "per_episode_reward": -129.67, "episode_reward_trend_value": -0.0008975494929842398, "biggest_recent_change": 0.047997715765291105},
{"total_number_of_episodes": 34027, "number_of_timesteps": 3879724, "per_episode_reward": -129.65, "episode_reward_trend_value": -0.0009155342297181809, "biggest_recent_change": 0.047997715765291105},
{"total_number_of_episodes": 34037, "number_of_timesteps": 3880930, "per_episode_reward": -129.68, "episode_reward_trend_value": -0.0011061441613662737, "biggest_recent_change": 0.047997715765291105},
{"total_number_of_episodes": 34047, "number_of_timesteps": 3881974, "per_episode_reward": -129.67, "episode_reward_trend_value": -0.0010095359786545387, "biggest_recent_change": 0.047997715765291105},
{"total_number_of_episodes": 34057, "number_of_timesteps": 3883077, "per_episode_reward": -129.73, "episode_reward_trend_value": -0.0015964050980626452, "biggest_recent_change": 0.058686389533448846},
{"total_number_of_episodes": 34068, "number_of_timesteps": 3884690, "per_episode_reward": -129.73, "episode_reward_trend_value": -0.0013088111855454245, "biggest_recent_change": 0.058686389533448846},
{"total_number_of_episodes": 34079, "number_of_timesteps": 3885913, "per_episode_reward": -129.72, "episode_reward_trend_value": -0.0013683001342116087, "biggest_recent_change": 0.058686389533448846},
{"total_number_of_episodes": 34089, "number_of_timesteps": 3886950, "per_episode_reward": -129.71, "episode_reward_trend_value": -0.0014261024379780766, "biggest_recent_change": 0.058686389533448846},
{"total_number_of_episodes": 34099, "number_of_timesteps": 3888008, "per_episode_reward": -129.66, "episode_reward_trend_value": -0.0003868214994895425, "biggest_recent_change": 0.058686389533448846},
{"total_number_of_episodes": 34109, "number_of_timesteps": 3889046, "per_episode_reward": -129.65, "episode_reward_trend_value": 0.00023364694796536393, "biggest_recent_change": 0.058686389533448846},
{"total_number_of_episodes": 34119, "number_of_timesteps": 3889988, "per_episode_reward": -129.64, "episode_reward_trend_value": 0.00013358769252154917, "biggest_recent_change": 0.058686389533448846},
{"total_number_of_episodes": 34129, "number_of_timesteps": 3891124, "per_episode_reward": -129.68, "episode_reward_trend_value": 2.1074099753251275e-05, "biggest_recent_change": 0.058686389533448846},
{"total_number_of_episodes": 34140, "number_of_timesteps": 3892184, "per_episode_reward": -129.64, "episode_reward_trend_value": 0.0004159833014638379, "biggest_recent_change": 0.058686389533448846},
{"total_number_of_episodes": 34150, "number_of_timesteps": 3893640, "per_episode_reward": -129.65, "episode_reward_trend_value": 0.0009145689956407447, "biggest_recent_change": 0.04553756869867698},

{"total_number_of_episodes": 34160, "number_of_timesteps": 3894611, "per_episode_reward": -129.65, "episode_reward_trend_value": 0.0008919121841813648, "biggest_recent_change": 0.04553756869867698},
{"total_number_of_episodes": 34170, "number_of_timesteps": 3895835, "per_episode_reward": -129.59, "episode_reward_trend_value": 0.0015352966051876947, "biggest_recent_change": 0.06270126609712179},
{"total_number_of_episodes": 34180, "number_of_timesteps": 3896922, "per_episode_reward": -129.62, "episode_reward_trend_value": 0.0010271178336116312, "biggest_recent_change": 0.06270126609712179},
{"total_number_of_episodes": 34191, "number_of_timesteps": 3898272, "per_episode_reward": -129.62, "episode_reward_trend_value": 0.0004970366656190587, "biggest_recent_change": 0.06270126609712179},
{"total_number_of_episodes": 34202, "number_of_timesteps": 3899637, "per_episode_reward": -129.67, "episode_reward_trend_value": -0.00020881232164842662, "biggest_recent_change": 0.06270126609712179},
{"total_number_of_episodes": 34212, "number_of_timesteps": 3900597, "per_episode_reward": -129.65, "episode_reward_trend_value": -0.00011662933324948375, "biggest_recent_change": 0.06270126609712179},
{"total_number_of_episodes": 34222, "number_of_timesteps": 3901860, "per_episode_reward": -129.65, "episode_reward_trend_value": 0.0003032455927066419, "biggest_recent_change": 0.06270126609712179},
{"total_number_of_episodes": 34232, "number_of_timesteps": 3902985, "per_episode_reward": -129.64, "episode_reward_trend_value": 1.1104786967229707e-05, "biggest_recent_change": 0.06270126609712179},
{"total_number_of_episodes": 34242, "number_of_timesteps": 3904042, "per_episode_reward": -129.73, "episode_reward_trend_value": -0.0008689788871729812, "biggest_recent_change": 0.09302120773014622},
{"total_number_of_episodes": 34253, "number_of_timesteps": 3905273, "per_episode_reward": -129.73, "episode_reward_trend_value": -0.0009368095541898609, "biggest_recent_change": 0.09302120773014622},
{"total_number_of_episodes": 34264, "number_of_timesteps": 3906650, "per_episode_reward": -129.74, "episode_reward_trend_value": -0.0016813788315289458, "biggest_recent_change": 0.09302120773014622},
{"total_number_of_episodes": 34274, "number_of_timesteps": 3907660, "per_episode_reward": -129.74, "episode_reward_trend_value": -0.0013063498610073844, "biggest_recent_change": 0.09302120773014622},
{"total_number_of_episodes": 34284, "number_of_timesteps": 3908766, "per_episode_reward": -129.7, "episode_reward_trend_value": -0.0009267086454548866, "biggest_recent_change": 0.09302120773014622},
{"total_number_of_episodes": 34295, "number_of_timesteps": 3910549, "per_episode_reward": -129.75, "episode_reward_trend_value": -0.0008868610625322995, "biggest_recent_change": 0.09302120773014622},
{"total_number_of_episodes": 34305, "number_of_timesteps": 3911506, "per_episode_reward": -129.75, "episode_reward_trend_value": -0.0011541778749965992, "biggest_recent_change": 0.09302120773014622},
{"total_number_of_episodes": 34315, "number_of_timesteps": 3912564, "per_episode_reward": -129.68, "episode_reward_trend_value": -0.000389547119262564, "biggest_recent_change": 0.09302120773014622},
{"total_number_of_episodes": 34325, "number_of_timesteps": 3913573, "per_episode_reward": -129.66, "episode_reward_trend_value": -0.00029169629633606244, "biggest_recent_change": 0.09302120773014622},
{"total_number_of_episodes": 34335, "number_of_timesteps": 3914538, "per_episode_reward": -129.59, "episode_reward_trend_value": 0.0015738911707056029, "biggest_recent_change": 0.07488166430360366},
{"total_number_of_episodes": 34345, "number_of_timesteps": 3915484, "per_episode_reward": -129.58, "episode_reward_trend_value": 0.00171020157236228, "biggest_recent_change": 0.07488166430360366},
{"total_number_of_episodes": 34356, "number_of_timesteps": 3916666, "per_episode_reward": -129.58, "episode_reward_trend_value": 0.0017457845116606702, "biggest_recent_change": 0.07488166430360366},
{"total_number_of_episodes": 34366, "number_of_timesteps": 3917541, "per_episode_reward": -129.55, "episode_reward_trend_value": 0.002066530344967532, "biggest_recent_change": 0.07488166430360366},
{"total_number_of_episodes": 34376, "number_of_timesteps": 3918618, "per_episode_reward": -129.56, "episode_reward_trend_value": 0.0015815535161269483, "biggest_recent_change": 0.07488166430360366},
{"total_number_of_episodes": 34386, "number_of_timesteps": 3919702, "per_episode_reward": -129.57, "episode_reward_trend_value": 0.0019720490033007664, "biggest_recent_change": 0.07488166430360366},
{"total_number_of_episodes": 34396, "number_of_timesteps": 3921289, "per_episode_reward": -129.6, "episode_reward_trend_value": 0.0016690757667302276, "biggest_recent_change": 0.07488166430360366},
{"total_number_of_episodes": 34406, "number_of_timesteps": 3922312, "per_episode_reward": -129.58, "episode_reward_trend_value": 0.0012129518655768835, "biggest_recent_change": 0.07488166430360366},
{"total_number_of_episodes": 34416, "number_of_timesteps": 3923544, "per_episode_reward": -129.56, "episode_reward_trend_value": 0.0011240027275619014, "biggest_recent_change": 0.07488166430360366},
{"total_number_of_episodes": 34426, "number_of_timesteps": 3924731, "per_episode_reward": -129.56, "episode_reward_trend_value": 0.00031550982039302907, "biggest_recent_change": 0.03005578557539934},
{"total_number_of_episodes": 34436, "number_of_timesteps": 3925889, "per_episode_reward": -129.54, "episode_reward_trend_value": 0.0003685746735628628, "biggest_recent_change": 0.03005578557539934},
{"total_number_of_episodes": 34446, "number_of_timesteps": 3926879, "per_episode_reward": -129.55, "episode_reward_trend_value": 0.0003140458810214063, "biggest_recent_change": 0.03005578557539934},
{"total_number_of_episodes": 34456, "number_of_timesteps": 3927946, "per_episode_reward": -129.55, "episode_reward_trend_value": -3.952809269568054e-05, "biggest_recent_change": 0.027445783567941362},
{"total_number_of_episodes": 34466, "number_of_timesteps": 3928942, "per_episode_reward": -129.53, "episode_reward_trend_value": 0.00036154759997278536, "biggest_recent_change": 0.027445783567941362},
{"total_number_of_episodes": 34476, "number_of_timesteps": 3929757, "per_episode_reward": -129.5, "episode_reward_trend_value": 0.0008198132728678174, "biggest_recent_change": 0.02890460275540363},
{"total_number_of_episodes": 34486, "number_of_timesteps": 3930784, "per_episode_reward": -129.49, "episode_reward_trend_value": 0.0012381960703467913, "biggest_recent_change": 0.02890460275540363},
{"total_number_of_episodes": 34496, "number_of_timesteps": 3931859, "per_episode_reward": -129.47, "episode_reward_trend_value": 0.0011359925927583467, "biggest_recent_change": 0.02890460275540363},
{"total_number_of_episodes": 34506, "number_of_timesteps": 3932781, "per_episode_reward": -129.45, "episode_reward_trend_value": 0.001212014511841946, "biggest_recent_change": 0.02890460275540363},
{"total_number_of_episodes": 34517, "number_of_timesteps": 3933923, "per_episode_reward": -129.45, "episode_reward_trend_value": 0.001228519645836299, "biggest_recent_change": 0.02890460275540363},
{"total_number_of_episodes": 34527, "number_of_timesteps": 3935339, "per_episode_reward": -129.48, "episode_reward_trend_value": 0.0007391577445781018, "biggest_recent_change": 0.02986233791685322},
{"total_number_of_episodes": 34537, "number_of_timesteps": 3936494, "per_episode_reward": -129.48, "episode_reward_trend_value": 0.0008307628051584161, "biggest_recent_change": 0.02986233791685322},
{"total_number_of_episodes": 34547, "number_of_timesteps": 3937467, "per_episode_reward": -129.48, "episode_reward_trend_value": 0.0008392662503429923, "biggest_recent_change": 0.02986233791685322},
{"total_number_of_episodes": 34557, "number_of_timesteps": 3938831, "per_episode_reward": -129.51, "episode_reward_trend_value": 0.00019034692382117807, "biggest_recent_change": 0.033955868663383626},
{"total_number_of_episodes": 34567, "number_of_timesteps": 3939987, "per_episode_reward": -129.52, "episode_reward_trend_value": -0.0001799365114193405, "biggest_recent_change": 0.033955868663383626},
{"total_number_of_episodes": 34578, "number_of_timesteps": 3941603, "per_episode_reward": -129.51, "episode_reward_trend_value": -0.00022319922650650722, "biggest_recent_change": 0.033955868663383626},
{"total_number_of_episodes": 34588, "number_of_timesteps": 3942620, "per_episode_reward": -129.48, "episode_reward_trend_value": -0.00010188056161047775, "biggest_recent_change": 0.033955868663383626},
{"total_number_of_episodes": 34598, "number_of_timesteps": 3944093, "per_episode_reward": -129.47, "episode_reward_trend_value": -0.00023056153055986465, "biggest_recent_change": 0.033955868663383626},
{"total_number_of_episodes": 34608, "number_of_timesteps": 3945046, "per_episode_reward": -129.47, "episode_reward_trend_value": -0.00026849402433918435, "biggest_recent_change": 0.033955868663383626},
{"total_number_of_episodes": 34619, "number_of_timesteps": 3946221, "per_episode_reward": -129.46, "episode_reward_trend_value": 0.00020445871175651416, "biggest_recent_change": 0.033955868663383626},
{"total_number_of_episodes": 34629, "number_of_timesteps": 3947347, "per_episode_reward": -129.44, "episode_reward_trend_value": 0.00034826844394804846, "biggest_recent_change": 0.033955868663383626},
{"total_number_of_episodes": 34639, "number_of_timesteps": 3948375, "per_episode_reward": -129.47, "episode_reward_trend_value": 0.0001192356298086376, "biggest_recent_change": 0.033955868663383626},
{"total_number_of_episodes": 34649, "number_of_timesteps": 3949681, "per_episode_reward": -129.46, "episode_reward_trend_value": 0.0005910018901276872, "biggest_recent_change": 0.027035061841246488},
{"total_number_of_episodes": 34659, "number_of_timesteps": 3950799, "per_episode_reward": -129.47, "episode_reward_trend_value": 0.0005513242843297424, "biggest_recent_change": 0.027035061841246488},
{"total_number_of_episodes": 34670, "number_of_timesteps": 3952148, "per_episode_reward": -129.46, "episode_reward_trend_value": 0.0005284251644408439, "biggest_recent_change": 0.027035061841246488},
{"total_number_of_episodes": 34680, "number_of_timesteps": 3953625, "per_episode_reward": -129.51, "episode_reward_trend_value": -0.00036041307003655573, "biggest_recent_change": 0.05296037926171948},
{"total_number_of_episodes": 34690, "number_of_timesteps": 3954536, "per_episode_reward": -129.52, "episode_reward_trend_value": -0.0004976928423815252, "biggest_recent_change": 0.05296037926171948},
{"total_number_of_episodes": 34700, "number_of_timesteps": 3955416, "per_episode_reward": -129.47, "episode_reward_trend_value": 4.7305735898817146e-05, "biggest_recent_change": 0.05296037926171948},
{"total_number_of_episodes": 34710, "number_of_timesteps": 3956791, "per_episode_reward": -129.49, "episode_reward_trend_value": -0.00031696971970202666, "biggest_recent_change": 0.05296037926171948},
{"total_number_of_episodes": 34720, "number_of_timesteps": 3958132, "per_episode_reward": -129.49, "episode_reward_trend_value": -0.00048586090723227294, "biggest_recent_change": 0.05296037926171948},
{"total_number_of_episodes": 34731, "number_of_timesteps": 3959177, "per_episode_reward": -129.46, "episode_reward_trend_value": 5.792582462618157e-05, "biggest_recent_change": 0.05296037926171948},
{"total_number_of_episodes": 34741, "number_of_timesteps": 3960355, "per_episode_reward": -129.49, "episode_reward_trend_value": -0.00030156425775658137, "biggest_recent_change": 0.05296037926171948},
{"total_number_of_episodes": 34751, "number_of_timesteps": 3961351, "per_episode_reward": -129.46, "episode_reward_trend_value": 6.182606385702153e-05, "biggest_recent_change": 0.05296037926171948},
{"total_number_of_episodes": 34761, "number_of_timesteps": 3962265, "per_episode_reward": -129.45, "episode_reward_trend_value": 0.00012388617972350049, "biggest_recent_change": 0.05296037926171948},
{"total_number_of_episodes": 34773, "number_of_timesteps": 3963716, "per_episode_reward": -129.46, "episode_reward_trend_value": 0.0005908222669685554, "biggest_recent_change": 0.04923871232298893},
{"total_number_of_episodes": 34783, "number_of_timesteps": 3964627, "per_episode_reward": -129.43, "episode_reward_trend_value": 0.0009894827087685422, "biggest_recent_change": 0.04923871232298893},
{"total_number_of_episodes": 34793, "number_of_timesteps": 3965568, "per_episode_reward": -129.36, "episode_reward_trend_value": 0.0011858198667302608, "biggest_recent_change": 0.0669090565395436},
{"total_number_of_episodes": 34803, "number_of_timesteps": 3966646, "per_episode_reward": -129.34, "episode_reward_trend_value": 0.0016924188811171033, "biggest_recent_change": 0.0669090565395436},
{"total_number_of_episodes": 34813, "number_of_timesteps": 3968080, "per_episode_reward": -129.38, "episode_reward_trend_value": 0.0012110213098420926, "biggest_recent_change": 0.0669090565395436},
{"total_number_of_episodes": 34823, "number_of_timesteps": 3969308, "per_episode_reward": -129.35, "episode_reward_trend_value": 0.0012238085512974648, "biggest_recent_change": 0.0669090565395436},
{"total_number_of_episodes": 34834, "number_of_timesteps": 3970297, "per_episode_reward": -129.35, "episode_reward_trend_value": 0.0015541155919338381, "biggest_recent_change": 0.0669090565395436},
{"total_number_of_episodes": 34844, "number_of_timesteps": 3971040, "per_episode_reward": -129.31, "episode_reward_trend_value": 0.0016413693360511337, "biggest_recent_change": 0.0669090565395436},
{"total_number_of_episodes": 34854, "number_of_timesteps": 3971955, "per_episode_reward": -129.27, "episode_reward_trend_value": 0.002048023628477659, "biggest_recent_change": 0.0669090565395436},
{"total_number_of_episodes": 34864, "number_of_timesteps": 3972857, "per_episode_reward": -129.21, "episode_reward_trend_value": 0.0027655206300282644, "biggest_recent_change": 0.0669090565395436},
{"total_number_of_episodes": 34875, "number_of_timesteps": 3974111, "per_episode_reward": -129.21, "episode_reward_trend_value": 0.0024240241208521715, "biggest_recent_change": 0.0669090565395436},
{"total_number_of_episodes": 34886, "number_of_timesteps": 3975196, "per_episode_reward": -129.16, "episode_reward_trend_value": 0.0022749817139192095, "biggest_recent_change": 0.053638598729889964},
{"total_number_of_episodes": 34896, "number_of_timesteps": 3976382, "per_episode_reward": -129.16, "episode_reward_trend_value": 0.001983895712573119, "biggest_recent_change": 0.053638598729889964},
{"total_number_of_episodes": 34906, "number_of_timesteps": 3977382, "per_episode_reward": -129.16, "episode_reward_trend_value": 0.0024749458510926717, "biggest_recent_change": 0.053638598729889964},
{"total_number_of_episodes": 34917, "number_of_timesteps": 3978686, "per_episode_reward": -129.15, "episode_reward_trend_value": 0.0022511907958687517, "biggest_recent_change": 0.053638598729889964},
{"total_number_of_episodes": 34927, "number_of_timesteps": 3979845, "per_episode_reward": -129.15, "episode_reward_trend_value": 0.0021837187329471893, "biggest_recent_change": 0.053638598729889964},
{"total_number_of_episodes": 34937, "number_of_timesteps": 3981197, "per_episode_reward": -129.18, "episode_reward_trend_value": 0.0014570148656806244, "biggest_recent_change": 0.053638598729889964},
{"total_number_of_episodes": 34948, "number_of_timesteps": 3982716, "per_episode_reward": -129.18, "episode_reward_trend_value": 0.0009643271063096235, "biggest_recent_change": 0.053638598729889964},
{"total_number_of_episodes": 34958, "number_of_timesteps": 3983682, "per_episode_reward": -129.17, "episode_reward_trend_value": 0.00043289604207106755, "biggest_recent_change": 0.05349523991557703},
{"total_number_of_episodes": 34970, "number_of_timesteps": 3985356, "per_episode_reward": -129.2, "episode_reward_trend_value": 0.0001385473189515096, "biggest_recent_change": 0.05349523991557703},
{"total_number_of_episodes": 34980, "number_of_timesteps": 3986341, "per_episode_reward": -129.18, "episode_reward_trend_value": -0.00028371044082859954, "biggest_recent_change": 0.03283727307626805},
{"total_number_of_episodes": 34990, "number_of_timesteps": 3987312, "per_episode_reward": -129.17, "episode_reward_trend_value": -0.00010984029297623642, "biggest_recent_change": 0.03283727307626805},
{"total_number_of_episodes": 35000, "number_of_timesteps": 3988305, "per_episode_reward": -129.15, "episode_reward_trend_value": 0.00011487073496773014, "biggest_recent_change": 0.03283727307626805},
{"total_number_of_episodes": 35010, "number_of_timesteps": 3989429, "per_episode_reward": -129.16, "episode_reward_trend_value": -0.00016596810582048723, "biggest_recent_change": 0.03283727307626805},
{"total_number_of_episodes": 35020, "number_of_timesteps": 3990474, "per_episode_reward": -129.15, "episode_reward_trend_value": -3.018295368456671e-05, "biggest_recent_change": 0.03283727307626805},
{"total_number_of_episodes": 35030, "number_of_timesteps": 3991399, "per_episode_reward": -129.14, "episode_reward_trend_value": 0.0004397297881726874, "biggest_recent_change": 0.024394883620459495},
{"total_number_of_episodes": 35040, "number_of_timesteps": 3993132, "per_episode_reward": -129.11, "episode_reward_trend_value": 0.0007802886809966165, "biggest_recent_change": 0.03274680181445433},
{"total_number_of_episodes": 35050, "number_of_timesteps": 3994042, "per_episode_reward": -129.07, "episode_reward_trend_value": 0.0011039480103944596, "biggest_recent_change": 0.034939142594225814},
{"total_number_of_episodes": 35060, "number_of_timesteps": 3994924, "per_episode_reward": -129.06, "episode_reward_trend_value": 0.001508797502926503, "biggest_recent_change": 0.034939142594225814},
{"total_number_of_episodes": 35070, "number_of_timesteps": 3995789, "per_episode_reward": -128.99, "episode_reward_trend_value": 0.0021725663509076613, "biggest_recent_change": 0.07523123785367147},
{"total_number_of_episodes": 35082, "number_of_timesteps": 3996933, "per_episode_reward": -129.0, "episode_reward_trend_value": 0.0019044813611720376, "biggest_recent_change": 0.07523123785367147},
{"total_number_of_episodes": 35092, "number_of_timesteps": 3997948, "per_episode_reward": -128.97, "episode_reward_trend_value": 0.0019620871656599093, "biggest_recent_change": 0.07523123785367147},
{"total_number_of_episodes": 35102, "number_of_timesteps": 3999093, "per_episode_reward": -129.02, "episode_reward_trend_value": 0.001570200465358261, "biggest_recent_change": 0.07523123785367147},
{"total_number_of_episodes": 35112, "number_of_timesteps": 4000279, "per_episode_reward": -129.08, "episode_reward_trend_value": 0.0008438672345199115, "biggest_recent_change": 0.07523123785367147},
{"total_number_of_episodes": 35122, "number_of_timesteps": 4001768, "per_episode_reward": -129.1, "episode_reward_trend_value": 0.0005108791997640892, "biggest_recent_change": 0.07523123785367147},
{"total_number_of_episodes": 35132, "number_of_timesteps": 4003097, "per_episode_reward": -129.11, "episode_reward_trend_value": -6.16522942237907e-05, "biggest_recent_change": 0.07523123785367147},
{"total_number_of_episodes": 35142, "number_of_timesteps": 4004188, "per_episode_reward": -129.11, "episode_reward_trend_value": -0.0003660467382174046, "biggest_recent_change": 0.07523123785367147},
{"total_number_of_episodes": 35153, "number_of_timesteps": 4005359, "per_episode_reward": -129.09, "episode_reward_trend_value": -0.00035464157098614475, "biggest_recent_change": 0.07523123785367147},
{"total_number_of_episodes": 35163, "number_of_timesteps": 4006429, "per_episode_reward": -129.13, "episode_reward_trend_value": -0.001547304188497378, "biggest_recent_change": 0.05334519173800345},
{"total_number_of_episodes": 35173, "number_of_timesteps": 4007503, "per_episode_reward": -129.12, "episode_reward_trend_value": -0.001423214709490455, "biggest_recent_change": 0.05334519173800345},
{"total_number_of_episodes": 35183, "number_of_timesteps": 4008821, "per_episode_reward": -129.13, "episode_reward_trend_value": -0.001794495049247126, "biggest_recent_change": 0.05334519173800345},
{"total_number_of_episodes": 35193, "number_of_timesteps": 4010222, "per_episode_reward": -129.16, "episode_reward_trend_value": -0.0015445465725434815, "biggest_recent_change": 0.05334519173800345},
{"total_number_of_episodes": 35205, "number_of_timesteps": 4011196, "per_episode_reward": -129.13, "episode_reward_trend_value": -0.0006181050639134532, "biggest_recent_change": 0.03210839772233953},
{"total_number_of_episodes": 35216, "number_of_timesteps": 4012095, "per_episode_reward": -129.07, "episode_reward_trend_value": 0.00027142013280341516, "biggest_recent_change": 0.05954321826737896},
{"total_number_of_episodes": 35226, "number_of_timesteps": 4013125, "per_episode_reward": -129.05, "episode_reward_trend_value": 0.0006971101899150906, "biggest_recent_change": 0.05954321826737896},
{"total_number_of_episodes": 35236, "number_of_timesteps": 4014556, "per_episode_reward": -129.05, "episode_reward_trend_value": 0.0005889868202962765, "biggest_recent_change": 0.05954321826737896},
{"total_number_of_episodes": 35246, "number_of_timesteps": 4016143, "per_episode_reward": -129.06, "episode_reward_trend_value": 0.00042954483856697657, "biggest_recent_change": 0.05954321826737896},
{"total_number_of_episodes": 35256, "number_of_timesteps": 4017559, "per_episode_reward": -129.08, "episode_reward_trend_value": 0.000559497525531722, "biggest_recent_change": 0.05954321826737896},
{"total_number_of_episodes": 35266, "number_of_timesteps": 4019213, "per_episode_reward": -129.13, "episode_reward_trend_value": -1.2113636395522715e-05, "biggest_recent_change": 0.05954321826737896},
{"total_number_of_episodes": 35276, "number_of_timesteps": 4020255, "per_episode_reward": -129.12, "episode_reward_trend_value": 9.170884518425738e-05, "biggest_recent_change": 0.05954321826737896},
{"total_number_of_episodes": 35287, "number_of_timesteps": 4021686, "per_episode_reward": -129.14, "episode_reward_trend_value": 0.000257531489554847, "biggest_recent_change": 0.05954321826737896},
{"total_number_of_episodes": 35297, "number_of_timesteps": 4022871, "per_episode_reward": -129.11, "episode_reward_trend_value": 0.0002796480954518504, "biggest_recent_change": 0.05954321826737896},
{"total_number_of_episodes": 35307, "number_of_timesteps": 4024112, "per_episode_reward": -129.07, "episode_reward_trend_value": 5.350742312341734e-05, "biggest_recent_change": 0.049441498730971034},
{"total_number_of_episodes": 35317, "number_of_timesteps": 4025377, "per_episode_reward": -129.11, "episode_reward_trend_value": -0.0006083801678101963, "biggest_recent_change": 0.049441498730971034},
{"total_number_of_episodes": 35327, "number_of_timesteps": 4026697, "per_episode_reward": -129.09, "episode_reward_trend_value": -0.00036606739778524873, "biggest_recent_change": 0.049441498730971034},
{"total_number_of_episodes": 35337, "number_of_timesteps": 4027780, "per_episode_reward": -129.1, "episode_reward_trend_value": -0.00044817921261836903, "biggest_recent_change": 0.049441498730971034},
{"total_number_of_episodes": 35347, "number_of_timesteps": 4028826, "per_episode_reward": -129.1, "episode_reward_trend_value": -0.00022159447675088964, "biggest_recent_change": 0.049441498730971034},
{"total_number_of_episodes": 35358, "number_of_timesteps": 4030388, "per_episode_reward": -129.12, "episode_reward_trend_value": 2.6658205182330776e-05, "biggest_recent_change": 0.040038810688429294},
{"total_number_of_episodes": 35368, "number_of_timesteps": 4031366, "per_episode_reward": -129.04, "episode_reward_trend_value": 0.0009231928511127307, "biggest_recent_change": 0.08286618568516246},
{"total_number_of_episodes": 35378, "number_of_timesteps": 4032269, "per_episode_reward": -129.02, "episode_reward_trend_value": 0.0013530958637905618, "biggest_recent_change": 0.08286618568516246},
{"total_number_of_episodes": 35388, "number_of_timesteps": 4033444, "per_episode_reward": -128.97, "episode_reward_trend_value": 0.0015056532845774326, "biggest_recent_change": 0.08286618568516246},
{"total_number_of_episodes": 35398, "number_of_timesteps": 4034549, "per_episode_reward": -129.03, "episode_reward_trend_value": 0.0004113963586080318, "biggest_recent_change": 0.08286618568516246},
{"total_number_of_episodes": 35408, "number_of_timesteps": 4036176, "per_episode_reward": -129.02, "episode_reward_trend_value": 0.0009786673604370182, "biggest_recent_change": 0.08286618568516246},
{"total_number_of_episodes": 35418, "number_of_timesteps": 4037234, "per_episode_reward": -128.94, "episode_reward_trend_value": 0.0016647149740795914, "biggest_recent_change": 0.08286618568516246},
{"total_number_of_episodes": 35429, "number_of_timesteps": 4038436, "per_episode_reward": -128.94, "episode_reward_trend_value": 0.0017504427641872173, "biggest_recent_change": 0.08286618568516246},
{"total_number_of_episodes": 35439, "number_of_timesteps": 4039951, "per_episode_reward": -128.94, "episode_reward_trend_value": 0.0016836708650875682, "biggest_recent_change": 0.08286618568516246},
{"total_number_of_episodes": 35449, "number_of_timesteps": 4041681, "per_episode_reward": -128.99, "episode_reward_trend_value": 0.0014888824209622145, "biggest_recent_change": 0.08286618568516246},
{"total_number_of_episodes": 35459, "number_of_timesteps": 4042748, "per_episode_reward": -129.03, "episode_reward_trend_value": 0.00014189722752114953, "biggest_recent_change": 0.08136497389918418},
{"total_number_of_episodes": 35469, "number_of_timesteps": 4043749, "per_episode_reward": -128.95, "episode_reward_trend_value": 0.0007547043810505885, "biggest_recent_change": 0.08136497389918418},
{"total_number_of_episodes": 35479, "number_of_timesteps": 4045070, "per_episode_reward": -128.99, "episode_reward_trend_value": -0.00017496999856329393, "biggest_recent_change": 0.08136497389918418},
{"total_number_of_episodes": 35489, "number_of_timesteps": 4046323, "per_episode_reward": -129.01, "episode_reward_trend_value": 0.00024409269569882023, "biggest_recent_change": 0.08136497389918418},
{"total_number_of_episodes": 35501, "number_of_timesteps": 4048369, "per_episode_reward": -129.04, "episode_reward_trend_value": -0.0002463455164202186, "biggest_recent_change": 0.08136497389918418},
{"total_number_of_episodes": 35511, "number_of_timesteps": 4049342, "per_episode_reward": -129.03, "episode_reward_trend_value": -0.0010682740879657457, "biggest_recent_change": 0.07905820452026546},
{"total_number_of_episodes": 35521, "number_of_timesteps": 4050379, "per_episode_reward": -128.99, "episode_reward_trend_value": -0.000565223680959232, "biggest_recent_change": 0.07905820452026546},
{"total_number_of_episodes": 35531, "number_of_timesteps": 4051531, "per_episode_reward": -128.95, "episode_reward_trend_value": -6.013336161711575e-05, "biggest_recent_change": 0.07905820452026546},
{"total_number_of_episodes": 35541, "number_of_timesteps": 4052772, "per_episode_reward": -128.93, "episode_reward_trend_value": 0.0006132496692395585, "biggest_recent_change": 0.07905820452026546},
{"total_number_of_episodes": 35551, "number_of_timesteps": 4054006, "per_episode_reward": -128.87, "episode_reward_trend_value": 0.0016930793481719775, "biggest_recent_change": 0.07905820452026546},
{"total_number_of_episodes": 35563, "number_of_timesteps": 4055219, "per_episode_reward": -128.88, "episode_reward_trend_value": 0.0007183366044507188, "biggest_recent_change": 0.058822189379384326},
{"total_number_of_episodes": 35573, "number_of_timesteps": 4056205, "per_episode_reward": -128.84, "episode_reward_trend_value": 0.001655506779853037, "biggest_recent_change": 0.058822189379384326},
{"total_number_of_episodes": 35583, "number_of_timesteps": 4057424, "per_episode_reward": -128.89, "episode_reward_trend_value": 0.0012746192228115028, "biggest_recent_change": 0.058822189379384326},
{"total_number_of_episodes": 35593, "number_of_timesteps": 4058628, "per_episode_reward": -128.93, "episode_reward_trend_value": 0.0012623766115293874, "biggest_recent_change": 0.058822189379384326},
{"total_number_of_episodes": 35603, "number_of_timesteps": 4059716, "per_episode_reward": -128.91, "episode_reward_trend_value": 0.0013205306234476033, "biggest_recent_change": 0.058822189379384326},
{"total_number_of_episodes": 35613, "number_of_timesteps": 4060390, "per_episode_reward": -128.9, "episode_reward_trend_value": 0.0009453010540021801, "biggest_recent_change": 0.058822189379384326},
{"total_number_of_episodes": 35623, "number_of_timesteps": 4061348, "per_episode_reward": -128.84, "episode_reward_trend_value": 0.001232064092679429, "biggest_recent_change": 0.06523730163533514},
{"total_number_of_episodes": 35633, "number_of_timesteps": 4062588, "per_episode_reward": -128.93, "episode_reward_trend_value": 1.0168282363072951e-05, "biggest_recent_change": 0.0939958674796344},
{"total_number_of_episodes": 35643, "number_of_timesteps": 4063833, "per_episode_reward": -128.85, "episode_reward_trend_value": 0.00023076892769514267, "biggest_recent_change": 0.0939958674796344},
{"total_number_of_episodes": 35655, "number_of_timesteps": 4064930, "per_episode_reward": -128.81, "episode_reward_trend_value": 0.0007904405498736524, "biggest_recent_change": 0.0939958674796344},
{"total_number_of_episodes": 35665, "number_of_timesteps": 4065877, "per_episode_reward": -128.79, "episode_reward_trend_value": 0.0005285609773917738, "biggest_recent_change": 0.0939958674796344},
{"total_number_of_episodes": 35675, "number_of_timesteps": 4067082, "per_episode_reward": -128.79, "episode_reward_trend_value": 0.0011472714566773826, "biggest_recent_change": 0.0939958674796344},
{"total_number_of_episodes": 35685, "number_of_timesteps": 4068516, "per_episode_reward": -128.8, "episode_reward_trend_value": 0.0013691633631424337, "biggest_recent_change": 0.0939958674796344},
{"total_number_of_episodes": 35695, "number_of_timesteps": 4069629, "per_episode_reward": -128.77, "episode_reward_trend_value": 0.001567860434895528, "biggest_recent_change": 0.0939958674796344},
{"total_number_of_episodes": 35706, "number_of_timesteps": 4070638, "per_episode_reward": -128.77, "episode_reward_trend_value": 0.0014770893606314277, "biggest_recent_change": 0.0939958674796344},
{"total_number_of_episodes": 35716, "number_of_timesteps": 4071611, "per_episode_reward": -128.77, "episode_reward_trend_value": 0.0007677109342416266, "biggest_recent_change": 0.0939958674796344},
{"total_number_of_episodes": 35726, "number_of_timesteps": 4072798, "per_episode_reward": -128.77, "episode_reward_trend_value": 0.0018508355830928421, "biggest_recent_change": 0.0786762474592706},
{"total_number_of_episodes": 35737, "number_of_timesteps": 4073796, "per_episode_reward": -128.76, "episode_reward_trend_value": 0.0010220330480857835, "biggest_recent_change": 0.04170180358141806},
{"total_number_of_episodes": 35747, "number_of_timesteps": 4074711, "per_episode_reward": -128.72, "episode_reward_trend_value": 0.0009771626894124411, "biggest_recent_change": 0.037663471300817264},

{"total_number_of_episodes": 35757, "number_of_timesteps": 4075937, "per_episode_reward": -128.76, "episode_reward_trend_value": 0.0003730646742992702, "biggest_recent_change": 0.037663471300817264},
{"total_number_of_episodes": 35767, "number_of_timesteps": 4077110, "per_episode_reward": -128.76, "episode_reward_trend_value": 0.00032737695237712057, "biggest_recent_change": 0.037663471300817264},
{"total_number_of_episodes": 35777, "number_of_timesteps": 4078284, "per_episode_reward": -128.76, "episode_reward_trend_value": 0.00046248029320313183, "biggest_recent_change": 0.037663471300817264},
{"total_number_of_episodes": 35787, "number_of_timesteps": 4079347, "per_episode_reward": -128.76, "episode_reward_trend_value": 0.00013010538469049809, "biggest_recent_change": 0.037663471300817264},
{"total_number_of_episodes": 35797, "number_of_timesteps": 4080666, "per_episode_reward": -128.78, "episode_reward_trend_value": -8.410440177297258e-05, "biggest_recent_change": 0.037663471300817264},
{"total_number_of_episodes": 35807, "number_of_timesteps": 4081962, "per_episode_reward": -128.76, "episode_reward_trend_value": 6.498012814751695e-05, "biggest_recent_change": 0.037663471300817264},
{"total_number_of_episodes": 35817, "number_of_timesteps": 4082857, "per_episode_reward": -128.74, "episode_reward_trend_value": 0.0002711955675825569, "biggest_recent_change": 0.037663471300817264},
{"total_number_of_episodes": 35828, "number_of_timesteps": 4083839, "per_episode_reward": -128.71, "episode_reward_trend_value": 0.000550041980042061, "biggest_recent_change": 0.037663471300817264},
{"total_number_of_episodes": 35839, "number_of_timesteps": 4084934, "per_episode_reward": -128.67, "episode_reward_trend_value": 0.0006477001824521267, "biggest_recent_change": 0.04645270951772318},
{"total_number_of_episodes": 35849, "number_of_timesteps": 4086108, "per_episode_reward": -128.68, "episode_reward_trend_value": 0.0008550213746878575, "biggest_recent_change": 0.04645270951772318},
{"total_number_of_episodes": 35859, "number_of_timesteps": 4087407, "per_episode_reward": -128.76, "episode_reward_trend_value": 2.022565727896916e-06, "biggest_recent_change": 0.081054647873259},
{"total_number_of_episodes": 35869, "number_of_timesteps": 4088683, "per_episode_reward": -128.76, "episode_reward_trend_value": 1.4110792473174014e-05, "biggest_recent_change": 0.081054647873259},
{"total_number_of_episodes": 35880, "number_of_timesteps": 4089826, "per_episode_reward": -128.78, "episode_reward_trend_value": -0.0002242716436522111, "biggest_recent_change": 0.081054647873259},
{"total_number_of_episodes": 35891, "number_of_timesteps": 4090886, "per_episode_reward": -128.7, "episode_reward_trend_value": 0.0008205529577723937, "biggest_recent_change": 0.081054647873259},
{"total_number_of_episodes": 35901, "number_of_timesteps": 4091870, "per_episode_reward": -128.64, "episode_reward_trend_value": 0.0013265109247969221, "biggest_recent_change": 0.081054647873259},
{"total_number_of_episodes": 35911, "number_of_timesteps": 4092926, "per_episode_reward": -128.67, "episode_reward_trend_value": 0.0008253365074848615, "biggest_recent_change": 0.081054647873259},
{"total_number_of_episodes": 35923, "number_of_timesteps": 4094266, "per_episode_reward": -128.67, "episode_reward_trend_value": 0.0004936158737257933, "biggest_recent_change": 0.081054647873259},
{"total_number_of_episodes": 35934, "number_of_timesteps": 4095082, "per_episode_reward": -128.62, "episode_reward_trend_value": 0.0004651582018460153, "biggest_recent_change": 0.081054647873259},
{"total_number_of_episodes": 35944, "number_of_timesteps": 4096156, "per_episode_reward": -128.63, "episode_reward_trend_value": 0.0005846652713917895, "biggest_recent_change": 0.081054647873259},
{"total_number_of_episodes": 35954, "number_of_timesteps": 4097611, "per_episode_reward": -128.63, "episode_reward_trend_value": 0.001415528882980905, "biggest_recent_change": 0.07713350722053747},
{"total_number_of_episodes": 35965, "number_of_timesteps": 4098862, "per_episode_reward": -128.66, "episode_reward_trend_value": 0.001138584154006455, "biggest_recent_change": 0.07713350722053747},
{"total_number_of_episodes": 35976, "number_of_timesteps": 4100271, "per_episode_reward": -128.69, "episode_reward_trend_value": 0.0009908235581298818, "biggest_recent_change": 0.07713350722053747},
{"total_number_of_episodes": 35986, "number_of_timesteps": 4101265, "per_episode_reward": -128.66, "episode_reward_trend_value": 0.00047549275278097665, "biggest_recent_change": 0.06034706798530465},
{"total_number_of_episodes": 35996, "number_of_timesteps": 4103216, "per_episode_reward": -128.65, "episode_reward_trend_value": -6.12724884954711e-05, "biggest_recent_change": 0.04389151904854316},
{"total_number_of_episodes": 36006, "number_of_timesteps": 4104208, "per_episode_reward": -128.63, "episode_reward_trend_value": 0.0004486082329063063, "biggest_recent_change": 0.04389151904854316},
{"total_number_of_episodes": 36017, "number_of_timesteps": 4105816, "per_episode_reward": -128.84, "episode_reward_trend_value": -0.0019090030392596366, "biggest_recent_change": 0.21285967510326032},
{"total_number_of_episodes": 36027, "number_of_timesteps": 4107005, "per_episode_reward": -128.87, "episode_reward_trend_value": -0.0027545266221702986, "biggest_recent_change": 0.21285967510326032},
{"total_number_of_episodes": 36038, "number_of_timesteps": 4108269, "per_episode_reward": -128.86, "episode_reward_trend_value": -0.002611707909864612, "biggest_recent_change": 0.21285967510326032},
{"total_number_of_episodes": 36048, "number_of_timesteps": 4109338, "per_episode_reward": -128.79, "episode_reward_trend_value": -0.0017890217484765319, "biggest_recent_change": 0.21285967510326032},
{"total_number_of_episodes": 36058, "number_of_timesteps": 4110473, "per_episode_reward": -128.87, "episode_reward_trend_value": -0.0022943313457782703, "biggest_recent_change": 0.21285967510326032},
{"total_number_of_episodes": 36069, "number_of_timesteps": 4111844, "per_episode_reward": -128.9, "episode_reward_trend_value": -0.0023083313528764566, "biggest_recent_change": 0.21285967510326032},
{"total_number_of_episodes": 36080, "number_of_timesteps": 4112677, "per_episode_reward": -128.82, "episode_reward_trend_value": -0.0017592399638456553, "biggest_recent_change": 0.21285967510326032},
{"total_number_of_episodes": 36090, "number_of_timesteps": 4113478, "per_episode_reward": -128.72, "episode_reward_trend_value": -0.0007695693560325228, "biggest_recent_change": 0.21285967510326032},
{"total_number_of_episodes": 36100, "number_of_timesteps": 4114477, "per_episode_reward": -128.69, "episode_reward_trend_value": -0.0007053509645241244, "biggest_recent_change": 0.21285967510326032},
{"total_number_of_episodes": 36110, "number_of_timesteps": 4115674, "per_episode_reward": -128.71, "episode_reward_trend_value": 0.001400350012339244, "biggest_recent_change": 0.10110855097360627},
{"total_number_of_episodes": 36120, "number_of_timesteps": 4116829, "per_episode_reward": -128.66, "episode_reward_trend_value": 0.0023738752487834818, "biggest_recent_change": 0.10110855097360627},
{"total_number_of_episodes": 36131, "number_of_timesteps": 4117732, "per_episode_reward": -128.65, "episode_reward_trend_value": 0.0023534166922388523, "biggest_recent_change": 0.10110855097360627},
{"total_number_of_episodes": 36141, "number_of_timesteps": 4118808, "per_episode_reward": -128.65, "episode_reward_trend_value": 0.0015724948590767934, "biggest_recent_change": 0.10110855097360627},
{"total_number_of_episodes": 36152, "number_of_timesteps": 4120128, "per_episode_reward": -128.63, "episode_reward_trend_value": 0.0026142974858373693, "biggest_recent_change": 0.10110855097360627},
{"total_number_of_episodes": 36162, "number_of_timesteps": 4120894, "per_episode_reward": -128.61, "episode_reward_trend_value": 0.0032156713936659447, "biggest_recent_change": 0.10110855097360627},
{"total_number_of_episodes": 36172, "number_of_timesteps": 4122085, "per_episode_reward": -128.61, "episode_reward_trend_value": 0.0023767946205452972, "biggest_recent_change": 0.10110855097360627},
{"total_number_of_episodes": 36182, "number_of_timesteps": 4123187, "per_episode_reward": -128.61, "episode_reward_trend_value": 0.0011778488406390705, "biggest_recent_change": 0.05541166786656504},
{"total_number_of_episodes": 36192, "number_of_timesteps": 4124435, "per_episode_reward": -128.62, "episode_reward_trend_value": 0.0007501379133780498, "biggest_recent_change": 0.05541166786656504},
{"total_number_of_episodes": 36202, "number_of_timesteps": 4125537, "per_episode_reward": -128.63, "episode_reward_trend_value": 0.0009059583201289142, "biggest_recent_change": 0.05541166786656504},
{"total_number_of_episodes": 36212, "number_of_timesteps": 4126469, "per_episode_reward": -128.63, "episode_reward_trend_value": 0.0003544536291877244, "biggest_recent_change": 0.022351165076941015},
{"total_number_of_episodes": 36222, "number_of_timesteps": 4127678, "per_episode_reward": -128.63, "episode_reward_trend_value": 0.00017042459327853976, "biggest_recent_change": 0.022351165076941015},
{"total_number_of_episodes": 36232, "number_of_timesteps": 4128676, "per_episode_reward": -128.64, "episode_reward_trend_value": 0.00018892665407703487, "biggest_recent_change": 0.022351165076941015},
{"total_number_of_episodes": 36242, "number_of_timesteps": 4129959, "per_episode_reward": -128.69, "episode_reward_trend_value": -0.0007133630770457305, "biggest_recent_change": 0.05885491072410787},
{"total_number_of_episodes": 36254, "number_of_timesteps": 4131136, "per_episode_reward": -128.68, "episode_reward_trend_value": -0.0007524752705945856, "biggest_recent_change": 0.05885491072410787},
{"total_number_of_episodes": 36264, "number_of_timesteps": 4132280, "per_episode_reward": -128.68, "episode_reward_trend_value": -0.0008537549541661823, "biggest_recent_change": 0.05885491072410787},
{"total_number_of_episodes": 36274, "number_of_timesteps": 4133402, "per_episode_reward": -128.67, "episode_reward_trend_value": -0.000653955563836285, "biggest_recent_change": 0.05885491072410787},
{"total_number_of_episodes": 36284, "number_of_timesteps": 4134734, "per_episode_reward": -128.65, "episode_reward_trend_value": -0.00026594066401817903, "biggest_recent_change": 0.05885491072410787},
{"total_number_of_episodes": 36294, "number_of_timesteps": 4135881, "per_episode_reward": -128.62, "episode_reward_trend_value": 0.00014690002361198316, "biggest_recent_change": 0.05885491072410787},
{"total_number_of_episodes": 36304, "number_of_timesteps": 4136943, "per_episode_reward": -128.65, "episode_reward_trend_value": -0.00021109338845740744, "biggest_recent_change": 0.05885491072410787},
{"total_number_of_episodes": 36314, "number_of_timesteps": 4138144, "per_episode_reward": -128.64, "episode_reward_trend_value": -3.7638431894038146e-05, "biggest_recent_change": 0.05885491072410787},
{"total_number_of_episodes": 36324, "number_of_timesteps": 4139109, "per_episode_reward": -128.59, "episode_reward_trend_value": 0.0005005917055074052, "biggest_recent_change": 0.05885491072410787},
{"total_number_of_episodes": 36335, "number_of_timesteps": 4140344, "per_episode_reward": -128.6, "episode_reward_trend_value": 0.001041323586287351, "biggest_recent_change": 0.047587764548097766},
{"total_number_of_episodes": 36345, "number_of_timesteps": 4141341, "per_episode_reward": -128.6, "episode_reward_trend_value": 0.000840159679413609, "biggest_recent_change": 0.047587764548097766},
{"total_number_of_episodes": 36355, "number_of_timesteps": 4142310, "per_episode_reward": -128.6, "episode_reward_trend_value": 0.0009271204800370469, "biggest_recent_change": 0.047587764548097766},
{"total_number_of_episodes": 36365, "number_of_timesteps": 4143306, "per_episode_reward": -128.58, "episode_reward_trend_value": 0.0010327108352852418, "biggest_recent_change": 0.047587764548097766},
{"total_number_of_episodes": 36375, "number_of_timesteps": 4144450, "per_episode_reward": -128.58, "episode_reward_trend_value": 0.0007898872001473163, "biggest_recent_change": 0.047587764548097766},
{"total_number_of_episodes": 36385, "number_of_timesteps": 4145720, "per_episode_reward": -128.59, "episode_reward_trend_value": 0.0003671270091795501, "biggest_recent_change": 0.047587764548097766},
{"total_number_of_episodes": 36395, "number_of_timesteps": 4146703, "per_episode_reward": -128.6, "episode_reward_trend_value": 0.0005277303746538565, "biggest_recent_change": 0.047587764548097766},
{"total_number_of_episodes": 36405, "number_of_timesteps": 4147945, "per_episode_reward": -128.65, "episode_reward_trend_value": -0.00017118211408191858, "biggest_recent_change": 0.05493498837086008},
{"total_number_of_episodes": 36416, "number_of_timesteps": 4149278, "per_episode_reward": -128.69, "episode_reward_trend_value": -0.0011242936088384189, "biggest_recent_change": 0.05493498837086008},
{"total_number_of_episodes": 36426, "number_of_timesteps": 4150228, "per_episode_reward": -128.64, "episode_reward_trend_value": -0.0004376841195036402, "biggest_recent_change": 0.05493498837086008},
{"total_number_of_episodes": 36436, "number_of_timesteps": 4151155, "per_episode_reward": -128.6, "episode_reward_trend_value": 8.509697624611414e-05, "biggest_recent_change": 0.05493498837086008},
{"total_number_of_episodes": 36446, "number_of_timesteps": 4152372, "per_episode_reward": -128.56, "episode_reward_trend_value": 0.0004846313544141544, "biggest_recent_change": 0.05493498837086008},
{"total_number_of_episodes": 36456, "number_of_timesteps": 4153158, "per_episode_reward": -128.52, "episode_reward_trend_value": 0.0006613749364520218, "biggest_recent_change": 0.05493498837086008},
{"total_number_of_episodes": 36466, "number_of_timesteps": 4154120, "per_episode_reward": -128.51, "episode_reward_trend_value": 0.0007103045001650166, "biggest_recent_change": 0.05493498837086008},
{"total_number_of_episodes": 36476, "number_of_timesteps": 4155619, "per_episode_reward": -128.51, "episode_reward_trend_value": 0.0008528263305126731, "biggest_recent_change": 0.05493498837086008},
{"total_number_of_episodes": 36486, "number_of_timesteps": 4156680, "per_episode_reward": -128.5, "episode_reward_trend_value": 0.0011033688882687582, "biggest_recent_change": 0.05493498837086008},
{"total_number_of_episodes": 36496, "number_of_timesteps": 4158065, "per_episode_reward": -128.51, "episode_reward_trend_value": 0.0016293852724512843, "biggest_recent_change": 0.051605812586217326},
{"total_number_of_episodes": 36506, "number_of_timesteps": 4159255, "per_episode_reward": -128.5, "episode_reward_trend_value": 0.002073453423767862, "biggest_recent_change": 0.051605812586217326},
{"total_number_of_episodes": 36516, "number_of_timesteps": 4160226, "per_episode_reward": -128.51, "episode_reward_trend_value": 0.0013959735346661419, "biggest_recent_change": 0.04413048598937053},
{"total_number_of_episodes": 36526, "number_of_timesteps": 4161308, "per_episode_reward": -128.51, "episode_reward_trend_value": 0.001001773912970331, "biggest_recent_change": 0.039342444740839255},
{"total_number_of_episodes": 36536, "number_of_timesteps": 4162351, "per_episode_reward": -128.59, "episode_reward_trend_value": -0.0003304152360123503, "biggest_recent_change": 0.08055457866760207},
{"total_number_of_episodes": 36546, "number_of_timesteps": 4163502, "per_episode_reward": -128.54, "episode_reward_trend_value": -0.000234208531784298, "biggest_recent_change": 0.08055457866760207},
{"total_number_of_episodes": 36556, "number_of_timesteps": 4164850, "per_episode_reward": -128.58, "episode_reward_trend_value": -0.0007546175568838482, "biggest_recent_change": 0.08055457866760207},
{"total_number_of_episodes": 36567, "number_of_timesteps": 4166179, "per_episode_reward": -128.61, "episode_reward_trend_value": -0.0010968937514822604, "biggest_recent_change": 0.08055457866760207},
{"total_number_of_episodes": 36577, "number_of_timesteps": 4167332, "per_episode_reward": -128.64, "episode_reward_trend_value": -0.0015501960161433063, "biggest_recent_change": 0.08055457866760207},
{"total_number_of_episodes": 36587, "number_of_timesteps": 4168340, "per_episode_reward": -128.6, "episode_reward_trend_value": -0.0010821493871642613, "biggest_recent_change": 0.08055457866760207},
{"total_number_of_episodes": 36597, "number_of_timesteps": 4169405, "per_episode_reward": -128.54, "episode_reward_trend_value": -0.0004172559151663159, "biggest_recent_change": 0.08055457866760207},
{"total_number_of_episodes": 36607, "number_of_timesteps": 4170621, "per_episode_reward": -128.51, "episode_reward_trend_value": 8.328312128879942e-05, "biggest_recent_change": 0.08055457866760207},
{"total_number_of_episodes": 36617, "number_of_timesteps": 4171732, "per_episode_reward": -128.48, "episode_reward_trend_value": 0.00022846589914485727, "biggest_recent_change": 0.08055457866760207},
{"total_number_of_episodes": 36628, "number_of_timesteps": 4173008, "per_episode_reward": -128.5, "episode_reward_trend_value": 0.0009588246319869617, "biggest_recent_change": 0.06161427611831982},
{"total_number_of_episodes": 36639, "number_of_timesteps": 4174789, "per_episode_reward": -128.5, "episode_reward_trend_value": 0.0004911576863008804, "biggest_recent_change": 0.06161427611831982},
{"total_number_of_episodes": 36650, "number_of_timesteps": 4176090, "per_episode_reward": -128.5, "episode_reward_trend_value": 0.0008425473432200507, "biggest_recent_change": 0.06161427611831982},
{"total_number_of_episodes": 36660, "number_of_timesteps": 4177250, "per_episode_reward": -128.47, "episode_reward_trend_value": 0.0015524258770382303, "biggest_recent_change": 0.06161427611831982},
{"total_number_of_episodes": 36670, "number_of_timesteps": 4178213, "per_episode_reward": -128.43, "episode_reward_trend_value": 0.002355273865326366, "biggest_recent_change": 0.06161427611831982},
{"total_number_of_episodes": 36681, "number_of_timesteps": 4179277, "per_episode_reward": -128.41, "episode_reward_trend_value": 0.0021056073404297293, "biggest_recent_change": 0.06161427611831982},
{"total_number_of_episodes": 36691, "number_of_timesteps": 4180499, "per_episode_reward": -128.44, "episode_reward_trend_value": 0.0010854048440971078, "biggest_recent_change": 0.0420190868127861},
{"total_number_of_episodes": 36701, "number_of_timesteps": 4181667, "per_episode_reward": -128.46, "episode_reward_trend_value": 0.0004651348342472754, "biggest_recent_change": 0.0420190868127861},
{"total_number_of_episodes": 36711, "number_of_timesteps": 4182536, "per_episode_reward": -128.43, "episode_reward_trend_value": 0.0005823467292591052, "biggest_recent_change": 0.0420190868127861},
{"total_number_of_episodes": 36721, "number_of_timesteps": 4183380, "per_episode_reward": -128.43, "episode_reward_trend_value": 0.0007418021542728563, "biggest_recent_change": 0.0420190868127861},
{"total_number_of_episodes": 36731, "number_of_timesteps": 4184181, "per_episode_reward": -128.41, "episode_reward_trend_value": 0.0009534678312585734, "biggest_recent_change": 0.0420190868127861},
{"total_number_of_episodes": 36742, "number_of_timesteps": 4185414, "per_episode_reward": -128.41, "episode_reward_trend_value": 0.0010676258262470304, "biggest_recent_change": 0.0420190868127861},
{"total_number_of_episodes": 36752, "number_of_timesteps": 4186505, "per_episode_reward": -128.38, "episode_reward_trend_value": 0.0009384904610688713, "biggest_recent_change": 0.0420190868127861},
{"total_number_of_episodes": 36762, "number_of_timesteps": 4187861, "per_episode_reward": -128.42, "episode_reward_trend_value": 0.00011160362051138389, "biggest_recent_change": 0.03240072883738776},
{"total_number_of_episodes": 36772, "number_of_timesteps": 4189489, "per_episode_reward": -128.42, "episode_reward_trend_value": -2.806548693222845e-05, "biggest_recent_change": 0.03240072883738776},
{"total_number_of_episodes": 36782, "number_of_timesteps": 4191071, "per_episode_reward": -128.41, "episode_reward_trend_value": 0.00039330947141201657, "biggest_recent_change": 0.03240072883738776},
{"total_number_of_episodes": 36792, "number_of_timesteps": 4192159, "per_episode_reward": -128.42, "episode_reward_trend_value": 0.0005323792055687844, "biggest_recent_change": 0.03240072883738776},
{"total_number_of_episodes": 36802, "number_of_timesteps": 4193229, "per_episode_reward": -128.41, "episode_reward_trend_value": 0.00027691032608553694, "biggest_recent_change": 0.03240072883738776},
{"total_number_of_episodes": 36812, "number_of_timesteps": 4194293, "per_episode_reward": -128.42, "episode_reward_trend_value": 0.00014945119861743529, "biggest_recent_change": 0.03240072883738776},
{"total_number_of_episodes": 36822, "number_of_timesteps": 4195456, "per_episode_reward": -128.46, "episode_reward_trend_value": -0.0005704879113301963, "biggest_recent_change": 0.04258060043031264},
{"total_number_of_episodes": 36832, "number_of_timesteps": 4196758, "per_episode_reward": -128.48, "episode_reward_trend_value": -0.0008233465396175335, "biggest_recent_change": 0.04258060043031264},
{"total_number_of_episodes": 36842, "number_of_timesteps": 4198009, "per_episode_reward": -128.49, "episode_reward_trend_value": -0.0011871831223844412, "biggest_recent_change": 0.04258060043031264},
{"total_number_of_episodes": 36852, "number_of_timesteps": 4199219, "per_episode_reward": -128.52, "episode_reward_trend_value": -0.001181525610108262, "biggest_recent_change": 0.04258060043031264},
{"total_number_of_episodes": 36862, "number_of_timesteps": 4200266, "per_episode_reward": -128.47, "episode_reward_trend_value": -0.0006030523718663971, "biggest_recent_change": 0.051553067344826786},
{"total_number_of_episodes": 36872, "number_of_timesteps": 4201354, "per_episode_reward": -128.48, "episode_reward_trend_value": -0.000779194618144806, "biggest_recent_change": 0.051553067344826786},
{"total_number_of_episodes": 36882, "number_of_timesteps": 4202726, "per_episode_reward": -128.44, "episode_reward_trend_value": -0.0003010925206742362, "biggest_recent_change": 0.051553067344826786},
{"total_number_of_episodes": 36892, "number_of_timesteps": 4203533, "per_episode_reward": -128.41, "episode_reward_trend_value": -1.0133371562106831e-05, "biggest_recent_change": 0.051553067344826786},
{"total_number_of_episodes": 36902, "number_of_timesteps": 4204473, "per_episode_reward": -128.42, "episode_reward_trend_value": 1.2116300780462552e-05, "biggest_recent_change": 0.051553067344826786},
{"total_number_of_episodes": 36912, "number_of_timesteps": 4205745, "per_episode_reward": -128.45, "episode_reward_trend_value": 0.00014862063332575165, "biggest_recent_change": 0.051553067344826786},
{"total_number_of_episodes": 36922, "number_of_timesteps": 4207103, "per_episode_reward": -128.45, "episode_reward_trend_value": 0.0003722914567052587, "biggest_recent_change": 0.051553067344826786},
{"total_number_of_episodes": 36933, "number_of_timesteps": 4208133, "per_episode_reward": -128.38, "episode_reward_trend_value": 0.001233418762731099, "biggest_recent_change": 0.06882965160997401},
{"total_number_of_episodes": 36943, "number_of_timesteps": 4209204, "per_episode_reward": -128.42, "episode_reward_trend_value": 0.0011024893438076333, "biggest_recent_change": 0.06882965160997401},
{"total_number_of_episodes": 36953, "number_of_timesteps": 4210298, "per_episode_reward": -128.49, "episode_reward_trend_value": -0.00015549858295129423, "biggest_recent_change": 0.06882965160997401},
{"total_number_of_episodes": 36963, "number_of_timesteps": 4211387, "per_episode_reward": -128.46, "episode_reward_trend_value": 0.00017999558004014993, "biggest_recent_change": 0.06882965160997401},
{"total_number_of_episodes": 36973, "number_of_timesteps": 4212471, "per_episode_reward": -128.46, "episode_reward_trend_value": -0.00022661713258034728, "biggest_recent_change": 0.06882965160997401},
{"total_number_of_episodes": 36983, "number_of_timesteps": 4213921, "per_episode_reward": -128.49, "episode_reward_trend_value": -0.0008507093211464836, "biggest_recent_change": 0.06882965160997401},
{"total_number_of_episodes": 36993, "number_of_timesteps": 4214994, "per_episode_reward": -128.52, "episode_reward_trend_value": -0.0011610840690609494, "biggest_recent_change": 0.06882965160997401},
{"total_number_of_episodes": 37003, "number_of_timesteps": 4216160, "per_episode_reward": -128.56, "episode_reward_trend_value": -0.0012188121319408336, "biggest_recent_change": 0.06882965160997401},
{"total_number_of_episodes": 37013, "number_of_timesteps": 4217331, "per_episode_reward": -128.56, "episode_reward_trend_value": -0.0011906288996540425, "biggest_recent_change": 0.06882965160997401},
{"total_number_of_episodes": 37023, "number_of_timesteps": 4218158, "per_episode_reward": -128.52, "episode_reward_trend_value": -0.001521348601780106, "biggest_recent_change": 0.06166584606347669},
{"total_number_of_episodes": 37033, "number_of_timesteps": 4219383, "per_episode_reward": -128.48, "episode_reward_trend_value": -0.0005905024975978297, "biggest_recent_change": 0.06166584606347669},
{"total_number_of_episodes": 37043, "number_of_timesteps": 4220529, "per_episode_reward": -128.47, "episode_reward_trend_value": 0.00018104297368021587, "biggest_recent_change": 0.04010094894076133},
{"total_number_of_episodes": 37053, "number_of_timesteps": 4221525, "per_episode_reward": -128.48, "episode_reward_trend_value": -0.00020363520058626567, "biggest_recent_change": 0.04010094894076133},
{"total_number_of_episodes": 37063, "number_of_timesteps": 4222594, "per_episode_reward": -128.61, "episode_reward_trend_value": -0.0016556630597569385, "biggest_recent_change": 0.13187535165320696},
{"total_number_of_episodes": 37073, "number_of_timesteps": 4223904, "per_episode_reward": -128.58, "episode_reward_trend_value": -0.0010871968838623994, "biggest_recent_change": 0.13187535165320696},
{"total_number_of_episodes": 37083, "number_of_timesteps": 4224803, "per_episode_reward": -128.55, "episode_reward_trend_value": -0.0002600371360655471, "biggest_recent_change": 0.13187535165320696},
{"total_number_of_episodes": 37093, "number_of_timesteps": 4225939, "per_episode_reward": -128.54, "episode_reward_trend_value": 0.00016438148763818895, "biggest_recent_change": 0.13187535165320696},
{"total_number_of_episodes": 37103, "number_of_timesteps": 4227162, "per_episode_reward": -128.58, "episode_reward_trend_value": -0.0002778299871127704, "biggest_recent_change": 0.13187535165320696},
{"total_number_of_episodes": 37114, "number_of_timesteps": 4228420, "per_episode_reward": -128.61, "episode_reward_trend_value": -0.0010010972001317164, "biggest_recent_change": 0.13187535165320696},
{"total_number_of_episodes": 37124, "number_of_timesteps": 4230207, "per_episode_reward": -128.61, "episode_reward_trend_value": -0.001474028235237294, "biggest_recent_change": 0.13187535165320696},
{"total_number_of_episodes": 37136, "number_of_timesteps": 4231630, "per_episode_reward": -128.62, "episode_reward_trend_value": -0.0016414464637863248, "biggest_recent_change": 0.13187535165320696},
{"total_number_of_episodes": 37147, "number_of_timesteps": 4232793, "per_episode_reward": -128.63, "episode_reward_trend_value": -0.0015982278052187365, "biggest_recent_change": 0.13187535165320696},
{"total_number_of_episodes": 37158, "number_of_timesteps": 4234113, "per_episode_reward": -128.65, "episode_reward_trend_value": -0.00038820063307727854, "biggest_recent_change": 0.03724211367890007},
{"total_number_of_episodes": 37168, "number_of_timesteps": 4235477, "per_episode_reward": -128.67, "episode_reward_trend_value": -0.001011358007711591, "biggest_recent_change": 0.03724211367890007},
{"total_number_of_episodes": 37178, "number_of_timesteps": 4236669, "per_episode_reward": -128.68, "episode_reward_trend_value": -0.00148031268109921, "biggest_recent_change": 0.03724211367890007},
{"total_number_of_episodes": 37188, "number_of_timesteps": 4237992, "per_episode_reward": -128.68, "episode_reward_trend_value": -0.0015582122092294211, "biggest_recent_change": 0.03724211367890007},
{"total_number_of_episodes": 37198, "number_of_timesteps": 4239054, "per_episode_reward": -128.71, "episode_reward_trend_value": -0.0014736010897678398, "biggest_recent_change": 0.029627112927357757},
{"total_number_of_episodes": 37208, "number_of_timesteps": 4240203, "per_episode_reward": -128.76, "episode_reward_trend_value": -0.0016976772116666754, "biggest_recent_change": 0.04619602172397208},
{"total_number_of_episodes": 37218, "number_of_timesteps": 4241335, "per_episode_reward": -128.76, "episode_reward_trend_value": -0.001670137609313353, "biggest_recent_change": 0.04619602172397208},
{"total_number_of_episodes": 37228, "number_of_timesteps": 4242635, "per_episode_reward": -128.76, "episode_reward_trend_value": -0.0015711694838365195, "biggest_recent_change": 0.04619602172397208},
{"total_number_of_episodes": 37238, "number_of_timesteps": 4243880, "per_episode_reward": -128.76, "episode_reward_trend_value": -0.0014750120814331544, "biggest_recent_change": 0.04619602172397208},
{"total_number_of_episodes": 37248, "number_of_timesteps": 4244730, "per_episode_reward": -128.75, "episode_reward_trend_value": -0.0010742483091806636, "biggest_recent_change": 0.04619602172397208},
{"total_number_of_episodes": 37259, "number_of_timesteps": 4245864, "per_episode_reward": -128.74, "episode_reward_trend_value": -0.0007207328685009568, "biggest_recent_change": 0.04619602172397208},
{"total_number_of_episodes": 37270, "number_of_timesteps": 4246903, "per_episode_reward": -128.68, "episode_reward_trend_value": -5.920502332483264e-05, "biggest_recent_change": 0.05390208002850727},
{"total_number_of_episodes": 37280, "number_of_timesteps": 4247869, "per_episode_reward": -128.65, "episode_reward_trend_value": 0.00041019623391618, "biggest_recent_change": 0.05390208002850727},
{"total_number_of_episodes": 37290, "number_of_timesteps": 4248960, "per_episode_reward": -128.64, "episode_reward_trend_value": 0.0008356308282931954, "biggest_recent_change": 0.05390208002850727},
{"total_number_of_episodes": 37301, "number_of_timesteps": 4250175, "per_episode_reward": -128.64, "episode_reward_trend_value": 0.0013213601506208762, "biggest_recent_change": 0.05390208002850727},
{"total_number_of_episodes": 37311, "number_of_timesteps": 4251959, "per_episode_reward": -128.64, "episode_reward_trend_value": 0.0013122869826768615, "biggest_recent_change": 0.05390208002850727},
{"total_number_of_episodes": 37322, "number_of_timesteps": 4253780, "per_episode_reward": -128.71, "episode_reward_trend_value": 0.0005542384301558438, "biggest_recent_change": 0.066611632651842},
{"total_number_of_episodes": 37332, "number_of_timesteps": 4255012, "per_episode_reward": -128.74, "episode_reward_trend_value": 0.00014569580718873317, "biggest_recent_change": 0.066611632651842},
{"total_number_of_episodes": 37343, "number_of_timesteps": 4256131, "per_episode_reward": -128.7, "episode_reward_trend_value": 0.00045787477030153744, "biggest_recent_change": 0.066611632651842},
{"total_number_of_episodes": 37353, "number_of_timesteps": 4257333, "per_episode_reward": -128.71, "episode_reward_trend_value": 0.0002987519466257835, "biggest_recent_change": 0.066611632651842},
{"total_number_of_episodes": 37363, "number_of_timesteps": 4258680, "per_episode_reward": -128.76, "episode_reward_trend_value": -0.0007983316922238574, "biggest_recent_change": 0.066611632651842},
{"total_number_of_episodes": 37373, "number_of_timesteps": 4260002, "per_episode_reward": -128.73, "episode_reward_trend_value": -0.0008985726347409203, "biggest_recent_change": 0.066611632651842},
{"total_number_of_episodes": 37383, "number_of_timesteps": 4261053, "per_episode_reward": -128.73, "episode_reward_trend_value": -0.0009672572775416357, "biggest_recent_change": 0.066611632651842},
{"total_number_of_episodes": 37393, "number_of_timesteps": 4262371, "per_episode_reward": -128.73, "episode_reward_trend_value": -0.0009907524402744154, "biggest_recent_change": 0.066611632651842},
{"total_number_of_episodes": 37403, "number_of_timesteps": 4263303, "per_episode_reward": -128.7, "episode_reward_trend_value": -0.0006451068177423419, "biggest_recent_change": 0.066611632651842},
{"total_number_of_episodes": 37413, "number_of_timesteps": 4264615, "per_episode_reward": -128.72, "episode_reward_trend_value": -0.00017962693708379145, "biggest_recent_change": 0.04483544746796042},
{"total_number_of_episodes": 37423, "number_of_timesteps": 4265725, "per_episode_reward": -128.73, "episode_reward_trend_value": 0.00016032308482812773, "biggest_recent_change": 0.04483544746796042},
{"total_number_of_episodes": 37433, "number_of_timesteps": 4267079, "per_episode_reward": -128.73, "episode_reward_trend_value": -0.0002947486640036029, "biggest_recent_change": 0.04483544746796042},
{"total_number_of_episodes": 37443, "number_of_timesteps": 4268549, "per_episode_reward": -128.8, "episode_reward_trend_value": -0.0009382899669573262, "biggest_recent_change": 0.06605172173155438},
{"total_number_of_episodes": 37453, "number_of_timesteps": 4269569, "per_episode_reward": -128.84, "episode_reward_trend_value": -0.0008920659356716796, "biggest_recent_change": 0.06605172173155438},
{"total_number_of_episodes": 37463, "number_of_timesteps": 4270639, "per_episode_reward": -128.86, "episode_reward_trend_value": -0.0014567657468695138, "biggest_recent_change": 0.06605172173155438},
{"total_number_of_episodes": 37473, "number_of_timesteps": 4272179, "per_episode_reward": -128.86, "episode_reward_trend_value": -0.001488724440934814, "biggest_recent_change": 0.06605172173155438},
{"total_number_of_episodes": 37483, "number_of_timesteps": 4273177, "per_episode_reward": -128.88, "episode_reward_trend_value": -0.001634165197215667, "biggest_recent_change": 0.06605172173155438},
{"total_number_of_episodes": 37494, "number_of_timesteps": 4274422, "per_episode_reward": -128.88, "episode_reward_trend_value": -0.001979710090645881, "biggest_recent_change": 0.06605172173155438},
{"total_number_of_episodes": 37504, "number_of_timesteps": 4275692, "per_episode_reward": -128.86, "episode_reward_trend_value": -0.001508772715812433, "biggest_recent_change": 0.06605172173155438},
{"total_number_of_episodes": 37514, "number_of_timesteps": 4276894, "per_episode_reward": -128.86, "episode_reward_trend_value": -0.0014208065615226436, "biggest_recent_change": 0.06605172173155438},
{"total_number_of_episodes": 37525, "number_of_timesteps": 4278179, "per_episode_reward": -128.86, "episode_reward_trend_value": -0.0013972285553472197, "biggest_recent_change": 0.06605172173155438},
{"total_number_of_episodes": 37535, "number_of_timesteps": 4279315, "per_episode_reward": -128.83, "episode_reward_trend_value": -0.0003366798075193047, "biggest_recent_change": 0.04067528465225223},
{"total_number_of_episodes": 37546, "number_of_timesteps": 4280683, "per_episode_reward": -128.83, "episode_reward_trend_value": 0.00012901757627648496, "biggest_recent_change": 0.029397665572957976},
{"total_number_of_episodes": 37556, "number_of_timesteps": 4281836, "per_episode_reward": -128.81, "episode_reward_trend_value": 0.0004936641110737759, "biggest_recent_change": 0.029397665572957976},
{"total_number_of_episodes": 37566, "number_of_timesteps": 4282739, "per_episode_reward": -128.81, "episode_reward_trend_value": 0.0004980629972000845, "biggest_recent_change": 0.029397665572957976},
{"total_number_of_episodes": 37576, "number_of_timesteps": 4284228, "per_episode_reward": -128.82, "episode_reward_trend_value": 0.0006256630627787116, "biggest_recent_change": 0.029397665572957976},
{"total_number_of_episodes": 37586, "number_of_timesteps": 4285222, "per_episode_reward": -128.83, "episode_reward_trend_value": 0.000514845829067983, "biggest_recent_change": 0.029397665572957976},
{"total_number_of_episodes": 37596, "number_of_timesteps": 4286328, "per_episode_reward": -128.87, "episode_reward_trend_value": -0.00014431040497634562, "biggest_recent_change": 0.04165814072155172},
{"total_number_of_episodes": 37606, "number_of_timesteps": 4287826, "per_episode_reward": -128.85, "episode_reward_trend_value": 5.678784575593454e-05, "biggest_recent_change": 0.04165814072155172},
{"total_number_of_episodes": 37616, "number_of_timesteps": 4288899, "per_episode_reward": -128.84, "episode_reward_trend_value": 0.00019676175647368333, "biggest_recent_change": 0.04165814072155172},
{"total_number_of_episodes": 37626, "number_of_timesteps": 4289979, "per_episode_reward": -128.84, "episode_reward_trend_value": -0.00010244181088536506, "biggest_recent_change": 0.04165814072155172},
{"total_number_of_episodes": 37637, "number_of_timesteps": 4291281, "per_episode_reward": -128.84, "episode_reward_trend_value": -0.0001705728803791039, "biggest_recent_change": 0.04165814072155172},
{"total_number_of_episodes": 37647, "number_of_timesteps": 4292279, "per_episode_reward": -128.84, "episode_reward_trend_value": -0.0002517306223820823, "biggest_recent_change": 0.04165814072155172},
{"total_number_of_episodes": 37657, "number_of_timesteps": 4293589, "per_episode_reward": -128.84, "episode_reward_trend_value": -0.0002546651928519673, "biggest_recent_change": 0.04165814072155172},
{"total_number_of_episodes": 37667, "number_of_timesteps": 4294599, "per_episode_reward": -128.83, "episode_reward_trend_value": -0.00011961500596334595, "biggest_recent_change": 0.04165814072155172},
{"total_number_of_episodes": 37677, "number_of_timesteps": 4295586, "per_episode_reward": -128.83, "episode_reward_trend_value": 2.18178677038673e-05, "biggest_recent_change": 0.04165814072155172},
{"total_number_of_episodes": 37688, "number_of_timesteps": 4296569, "per_episode_reward": -128.81, "episode_reward_trend_value": 0.000651378897576491, "biggest_recent_change": 0.019826742363960648},
{"total_number_of_episodes": 37698, "number_of_timesteps": 4297560, "per_episode_reward": -128.81, "episode_reward_trend_value": 0.00045063234666239775, "biggest_recent_change": 0.015002351966984406},
{"total_number_of_episodes": 37708, "number_of_timesteps": 4298867, "per_episode_reward": -128.82, "episode_reward_trend_value": 0.0001897641607257583, "biggest_recent_change": 0.015002351966984406},
{"total_number_of_episodes": 37718, "number_of_timesteps": 4300156, "per_episode_reward": -128.83, "episode_reward_trend_value": 3.0839152441015154e-05, "biggest_recent_change": 0.015002351966984406},
{"total_number_of_episodes": 37728, "number_of_timesteps": 4301577, "per_episode_reward": -128.84, "episode_reward_trend_value": 2.7382375659751942e-05, "biggest_recent_change": 0.015002351966984406},
{"total_number_of_episodes": 37738, "number_of_timesteps": 4302793, "per_episode_reward": -128.91, "episode_reward_trend_value": -0.000840534069151507, "biggest_recent_change": 0.0745010609229837},
{"total_number_of_episodes": 37748, "number_of_timesteps": 4304107, "per_episode_reward": -128.91, "episode_reward_trend_value": -0.000798967403669811, "biggest_recent_change": 0.0745010609229837},
{"total_number_of_episodes": 37758, "number_of_timesteps": 4305064, "per_episode_reward": -128.88, "episode_reward_trend_value": -0.0005014222812832258, "biggest_recent_change": 0.0745010609229837},
{"total_number_of_episodes": 37768, "number_of_timesteps": 4306129, "per_episode_reward": -128.9, "episode_reward_trend_value": -0.0008122468383747773, "biggest_recent_change": 0.0745010609229837},
{"total_number_of_episodes": 37778, "number_of_timesteps": 4307065, "per_episode_reward": -128.83, "episode_reward_trend_value": -0.0002035276663185136, "biggest_recent_change": 0.0745010609229837},
{"total_number_of_episodes": 37788, "number_of_timesteps": 4308095, "per_episode_reward": -128.87, "episode_reward_trend_value": -0.0005963930578370007, "biggest_recent_change": 0.0745010609229837},
{"total_number_of_episodes": 37798, "number_of_timesteps": 4309772, "per_episode_reward": -128.91, "episode_reward_trend_value": -0.0009538494643907016, "biggest_recent_change": 0.0745010609229837},
{"total_number_of_episodes": 37808, "number_of_timesteps": 4310793, "per_episode_reward": -128.86, "episode_reward_trend_value": -0.0003152011692024972, "biggest_recent_change": 0.0745010609229837},
{"total_number_of_episodes": 37818, "number_of_timesteps": 4311671, "per_episode_reward": -128.84, "episode_reward_trend_value": -3.5211300658172857e-05, "biggest_recent_change": 0.0745010609229837},
{"total_number_of_episodes": 37829, "number_of_timesteps": 4313117, "per_episode_reward": -128.86, "episode_reward_trend_value": 0.0005704264663348921, "biggest_recent_change": 0.06978707745204815},
{"total_number_of_episodes": 37840, "number_of_timesteps": 4314534, "per_episode_reward": -128.86, "episode_reward_trend_value": 0.0006032346936927348, "biggest_recent_change": 0.06978707745204815},
{"total_number_of_episodes": 37850, "number_of_timesteps": 4315643, "per_episode_reward": -128.84, "episode_reward_trend_value": 0.00038389303046560346, "biggest_recent_change": 0.06978707745204815},
{"total_number_of_episodes": 37860, "number_of_timesteps": 4316678, "per_episode_reward": -128.84, "episode_reward_trend_value": 0.0006533747575341901, "biggest_recent_change": 0.06978707745204815},
{"total_number_of_episodes": 37871, "number_of_timesteps": 4317770, "per_episode_reward": -128.81, "episode_reward_trend_value": 0.00022818247630501296, "biggest_recent_change": 0.04564444033195514},
{"total_number_of_episodes": 37881, "number_of_timesteps": 4319118, "per_episode_reward": -128.86, "episode_reward_trend_value": 7.414089404246877e-05, "biggest_recent_change": 0.047462074858600545},
{"total_number_of_episodes": 37892, "number_of_timesteps": 4320210, "per_episode_reward": -128.85, "episode_reward_trend_value": 0.0005848543180693216, "biggest_recent_change": 0.047462074858600545},
{"total_number_of_episodes": 37902, "number_of_timesteps": 4321033, "per_episode_reward": -128.8, "episode_reward_trend_value": 0.0007281196503154459, "biggest_recent_change": 0.05853832023410632},
{"total_number_of_episodes": 37912, "number_of_timesteps": 4322090, "per_episode_reward": -128.82, "episode_reward_trend_value": 0.00027365118893985457, "biggest_recent_change": 0.05853832023410632},
{"total_number_of_episodes": 37922, "number_of_timesteps": 4323510, "per_episode_reward": -128.82, "episode_reward_trend_value": 0.0005099687342351444, "biggest_recent_change": 0.05853832023410632},
{"total_number_of_episodes": 37933, "number_of_timesteps": 4324762, "per_episode_reward": -128.86, "episode_reward_trend_value": -1.1277223311228428e-05, "biggest_recent_change": 0.05853832023410632},
{"total_number_of_episodes": 37943, "number_of_timesteps": 4326337, "per_episode_reward": -128.88, "episode_reward_trend_value": -0.000397727939051467, "biggest_recent_change": 0.05853832023410632},
{"total_number_of_episodes": 37953, "number_of_timesteps": 4327287, "per_episode_reward": -128.85, "episode_reward_trend_value": -7.737784421490485e-05, "biggest_recent_change": 0.05853832023410632},
{"total_number_of_episodes": 37963, "number_of_timesteps": 4328197, "per_episode_reward": -128.84, "episode_reward_trend_value": -0.0002829358628582036, "biggest_recent_change": 0.05853832023410632},
{"total_number_of_episodes": 37973, "number_of_timesteps": 4329260, "per_episode_reward": -128.82, "episode_reward_trend_value": 0.000465874540948145, "biggest_recent_change": 0.05853832023410632},
{"total_number_of_episodes": 37983, "number_of_timesteps": 4330795, "per_episode_reward": -128.82, "episode_reward_trend_value": 0.00032870254026893994, "biggest_recent_change": 0.05853832023410632},
{"total_number_of_episodes": 37994, "number_of_timesteps": 4332064, "per_episode_reward": -128.84, "episode_reward_trend_value": -0.0005171420191576064, "biggest_recent_change": 0.040482507165904735},
{"total_number_of_episodes": 38004, "number_of_timesteps": 4333204, "per_episode_reward": -128.82, "episode_reward_trend_value": 2.1370131400367933e-06, "biggest_recent_change": 0.040482507165904735},
{"total_number_of_episodes": 38014, "number_of_timesteps": 4334479, "per_episode_reward": -128.84, "episode_reward_trend_value": -0.0003241996290326041, "biggest_recent_change": 0.040482507165904735},
{"total_number_of_episodes": 38025, "number_of_timesteps": 4335535, "per_episode_reward": -128.81, "episode_reward_trend_value": 0.0005219763201100452, "biggest_recent_change": 0.0356733282569337},
{"total_number_of_episodes": 38036, "number_of_timesteps": 4337187, "per_episode_reward": -128.89, "episode_reward_trend_value": -0.0001791310524371031, "biggest_recent_change": 0.08488800932516938},
{"total_number_of_episodes": 38046, "number_of_timesteps": 4337911, "per_episode_reward": -128.78, "episode_reward_trend_value": 0.0007624917492907773, "biggest_recent_change": 0.11182031408208104},
{"total_number_of_episodes": 38056, "number_of_timesteps": 4338768, "per_episode_reward": -128.74, "episode_reward_trend_value": 0.001066846078624116, "biggest_recent_change": 0.11182031408208104},
{"total_number_of_episodes": 38066, "number_of_timesteps": 4339750, "per_episode_reward": -128.74, "episode_reward_trend_value": 0.0008826293214279227, "biggest_recent_change": 0.11182031408208104},
{"total_number_of_episodes": 38076, "number_of_timesteps": 4340886, "per_episode_reward": -128.76, "episode_reward_trend_value": 0.0007001000062321812, "biggest_recent_change": 0.11182031408208104},
{"total_number_of_episodes": 38086, "number_of_timesteps": 4341994, "per_episode_reward": -128.74, "episode_reward_trend_value": 0.001173179907547074, "biggest_recent_change": 0.11182031408208104},
{"total_number_of_episodes": 38097, "number_of_timesteps": 4343006, "per_episode_reward": -128.71, "episode_reward_trend_value": 0.0012350872879270329, "biggest_recent_change": 0.11182031408208104},
{"total_number_of_episodes": 38108, "number_of_timesteps": 4343981, "per_episode_reward": -128.7, "episode_reward_trend_value": 0.0016099736419644412, "biggest_recent_change": 0.11182031408208104},
{"total_number_of_episodes": 38118, "number_of_timesteps": 4345041, "per_episode_reward": -128.69, "episode_reward_trend_value": 0.0013654614705340387, "biggest_recent_change": 0.11182031408208104},
{"total_number_of_episodes": 38128, "number_of_timesteps": 4346158, "per_episode_reward": -128.71, "episode_reward_trend_value": 0.0020674584125888232, "biggest_recent_change": 0.11182031408208104},
{"total_number_of_episodes": 38138, "number_of_timesteps": 4347256, "per_episode_reward": -128.73, "episode_reward_trend_value": 0.0005856077257754401, "biggest_recent_change": 0.04041144010352582},
{"total_number_of_episodes": 38148, "number_of_timesteps": 4348648, "per_episode_reward": -128.75, "episode_reward_trend_value": -5.7065314147861394e-05, "biggest_recent_change": 0.03139827751078883},
{"total_number_of_episodes": 38160, "number_of_timesteps": 4350310, "per_episode_reward": -128.84, "episode_reward_trend_value": -0.0011499843473135088, "biggest_recent_change": 0.09501135964859486},
{"total_number_of_episodes": 38171, "number_of_timesteps": 4351482, "per_episode_reward": -128.85, "episode_reward_trend_value": -0.0010013711647325685, "biggest_recent_change": 0.09501135964859486},
{"total_number_of_episodes": 38181, "number_of_timesteps": 4352434, "per_episode_reward": -128.84, "episode_reward_trend_value": -0.0011838866778605152, "biggest_recent_change": 0.09501135964859486},
{"total_number_of_episodes": 38191, "number_of_timesteps": 4353506, "per_episode_reward": -128.74, "episode_reward_trend_value": -0.0003563075795297108, "biggest_recent_change": 0.10588039636056124},
{"total_number_of_episodes": 38202, "number_of_timesteps": 4354718, "per_episode_reward": -128.8, "episode_reward_trend_value": -0.0011230161049749338, "biggest_recent_change": 0.10588039636056124},
{"total_number_of_episodes": 38212, "number_of_timesteps": 4355620, "per_episode_reward": -128.78, "episode_reward_trend_value": -0.001012024748695555, "biggest_recent_change": 0.10588039636056124},
{"total_number_of_episodes": 38222, "number_of_timesteps": 4356439, "per_episode_reward": -128.7, "episode_reward_trend_value": 4.047895071153107e-05, "biggest_recent_change": 0.10588039636056124},
{"total_number_of_episodes": 38232, "number_of_timesteps": 4357420, "per_episode_reward": -128.71, "episode_reward_trend_value": 0.00026702625845650296, "biggest_recent_change": 0.10588039636056124},
{"total_number_of_episodes": 38242, "number_of_timesteps": 4358769, "per_episode_reward": -128.74, "episode_reward_trend_value": 6.071102851687252e-05, "biggest_recent_change": 0.10588039636056124},
{"total_number_of_episodes": 38252, "number_of_timesteps": 4360116, "per_episode_reward": -128.79, "episode_reward_trend_value": 0.0005275952527079476, "biggest_recent_change": 0.10588039636056124},
{"total_number_of_episodes": 38262, "number_of_timesteps": 4361408, "per_episode_reward": -128.8, "episode_reward_trend_value": 0.0006276190687988976, "biggest_recent_change": 0.10588039636056124},
{"total_number_of_episodes": 38273, "number_of_timesteps": 4363100, "per_episode_reward": -128.83, "episode_reward_trend_value": 0.00013108653794960092, "biggest_recent_change": 0.10588039636056124},
{"total_number_of_episodes": 38283, "number_of_timesteps": 4364110, "per_episode_reward": -128.86, "episode_reward_trend_value": -0.0013371139121517218, "biggest_recent_change": 0.073017048406399},
{"total_number_of_episodes": 38293, "number_of_timesteps": 4365207, "per_episode_reward": -128.86, "episode_reward_trend_value": -0.0006587088033973664, "biggest_recent_change": 0.073017048406399},
{"total_number_of_episodes": 38303, "number_of_timesteps": 4366272, "per_episode_reward": -128.88, "episode_reward_trend_value": -0.0011458413406059108, "biggest_recent_change": 0.073017048406399},
{"total_number_of_episodes": 38314, "number_of_timesteps": 4367489, "per_episode_reward": -128.8, "episode_reward_trend_value": -0.0010418371238096647, "biggest_recent_change": 0.08237742791806113},
{"total_number_of_episodes": 38324, "number_of_timesteps": 4368685, "per_episode_reward": -128.8, "episode_reward_trend_value": -0.0010310472839718285, "biggest_recent_change": 0.08237742791806113},
{"total_number_of_episodes": 38334, "number_of_timesteps": 4369826, "per_episode_reward": -128.8, "episode_reward_trend_value": -0.0006662306656620685, "biggest_recent_change": 0.08237742791806113},
{"total_number_of_episodes": 38344, "number_of_timesteps": 4370938, "per_episode_reward": -128.75, "episode_reward_trend_value": 0.0004668299804721856, "biggest_recent_change": 0.08237742791806113},
{"total_number_of_episodes": 38354, "number_of_timesteps": 4372003, "per_episode_reward": -128.7, "episode_reward_trend_value": 0.001010451732009364, "biggest_recent_change": 0.08237742791806113},
{"total_number_of_episodes": 38364, "number_of_timesteps": 4373116, "per_episode_reward": -128.8, "episode_reward_trend_value": 0.00040713240164633494, "biggest_recent_change": 0.09042356268656704},
{"total_number_of_episodes": 38375, "number_of_timesteps": 4374517, "per_episode_reward": -128.81, "episode_reward_trend_value": 0.0005373266789670576, "biggest_recent_change": 0.09042356268656704},
{"total_number_of_episodes": 38386, "number_of_timesteps": 4375581, "per_episode_reward": -128.8, "episode_reward_trend_value": 0.0006731564788411661, "biggest_recent_change": 0.09042356268656704},
{"total_number_of_episodes": 38397, "number_of_timesteps": 4376876, "per_episode_reward": -128.84, "episode_reward_trend_value": 0.0005014183798926474, "biggest_recent_change": 0.09042356268656704},
{"total_number_of_episodes": 38407, "number_of_timesteps": 4378373, "per_episode_reward": -128.84, "episode_reward_trend_value": -0.00048711109551978396, "biggest_recent_change": 0.09042356268656704},
{"total_number_of_episodes": 38417, "number_of_timesteps": 4379133, "per_episode_reward": -128.81, "episode_reward_trend_value": -0.00017245686177602693, "biggest_recent_change": 0.09042356268656704},
{"total_number_of_episodes": 38427, "number_of_timesteps": 4379991, "per_episode_reward": -128.73, "episode_reward_trend_value": 0.0008301563427848023, "biggest_recent_change": 0.09042356268656704},
{"total_number_of_episodes": 38437, "number_of_timesteps": 4381226, "per_episode_reward": -128.81, "episode_reward_trend_value": -0.0006157149618009801, "biggest_recent_change": 0.09042356268656704},
{"total_number_of_episodes": 38447, "number_of_timesteps": 4383228, "per_episode_reward": -128.83, "episode_reward_trend_value": -0.0013639065564480764, "biggest_recent_change": 0.09042356268656704},
{"total_number_of_episodes": 38457, "number_of_timesteps": 4384615, "per_episode_reward": -128.86, "episode_reward_trend_value": -0.0007320661127434076, "biggest_recent_change": 0.08707117987421498},
{"total_number_of_episodes": 38468, "number_of_timesteps": 4385882, "per_episode_reward": -128.86, "episode_reward_trend_value": -0.0005726786175087126, "biggest_recent_change": 0.08707117987421498},
{"total_number_of_episodes": 38478, "number_of_timesteps": 4386995, "per_episode_reward": -128.88, "episode_reward_trend_value": -0.0009449984153690139, "biggest_recent_change": 0.08707117987421498},
{"total_number_of_episodes": 38488, "number_of_timesteps": 4388357, "per_episode_reward": -128.87, "episode_reward_trend_value": -0.00039825793369377356, "biggest_recent_change": 0.08707117987421498},
{"total_number_of_episodes": 38498, "number_of_timesteps": 4389338, "per_episode_reward": -128.84, "episode_reward_trend_value": 2.4407891118016778e-05, "biggest_recent_change": 0.08707117987421498},
{"total_number_of_episodes": 38509, "number_of_timesteps": 4390744, "per_episode_reward": -128.89, "episode_reward_trend_value": -0.000829742167406443, "biggest_recent_change": 0.08707117987421498},
{"total_number_of_episodes": 38519, "number_of_timesteps": 4392237, "per_episode_reward": -128.9, "episode_reward_trend_value": -0.0019332794588775768, "biggest_recent_change": 0.08114473873203565},
{"total_number_of_episodes": 38529, "number_of_timesteps": 4392945, "per_episode_reward": -128.87, "episode_reward_trend_value": -0.0007166642997772342, "biggest_recent_change": 0.04874052867893397},
{"total_number_of_episodes": 38539, "number_of_timesteps": 4393677, "per_episode_reward": -128.83, "episode_reward_trend_value": -4.408520987119067e-05, "biggest_recent_change": 0.04874052867893397},
{"total_number_of_episodes": 38549, "number_of_timesteps": 4394429, "per_episode_reward": -128.8, "episode_reward_trend_value": 0.0006897165524407001, "biggest_recent_change": 0.04874052867893397},
{"total_number_of_episodes": 38559, "number_of_timesteps": 4395359, "per_episode_reward": -128.7, "episode_reward_trend_value": 0.0018421620384919553, "biggest_recent_change": 0.10352480912604278},
{"total_number_of_episodes": 38569, "number_of_timesteps": 4396557, "per_episode_reward": -128.67, "episode_reward_trend_value": 0.0023333898604173935, "biggest_recent_change": 0.10352480912604278},
{"total_number_of_episodes": 38579, "number_of_timesteps": 4397737, "per_episode_reward": -128.72, "episode_reward_trend_value": 0.001650612498814515, "biggest_recent_change": 0.10352480912604278},
{"total_number_of_episodes": 38590, "number_of_timesteps": 4399553, "per_episode_reward": -128.78, "episode_reward_trend_value": 0.0006583933433568568, "biggest_recent_change": 0.10352480912604278},
{"total_number_of_episodes": 38600, "number_of_timesteps": 4400758, "per_episode_reward": -128.77, "episode_reward_trend_value": 0.0013671367180412139, "biggest_recent_change": 0.10352480912604278},
{"total_number_of_episodes": 38610, "number_of_timesteps": 4402145, "per_episode_reward": -128.8, "episode_reward_trend_value": 0.0010739776381269747, "biggest_recent_change": 0.10352480912604278},
{"total_number_of_episodes": 38620, "number_of_timesteps": 4403411, "per_episode_reward": -128.74, "episode_reward_trend_value": 0.0014315636199124051, "biggest_recent_change": 0.10352480912604278},
{"total_number_of_episodes": 38630, "number_of_timesteps": 4404563, "per_episode_reward": -128.82, "episode_reward_trend_value": 0.00012637180340328136, "biggest_recent_change": 0.10352480912604278},
{"total_number_of_episodes": 38641, "number_of_timesteps": 4405726, "per_episode_reward": -128.87, "episode_reward_trend_value": -0.0007561283351350312, "biggest_recent_change": 0.10352480912604278},
{"total_number_of_episodes": 38652, "number_of_timesteps": 4407084, "per_episode_reward": -128.85, "episode_reward_trend_value": -0.0017687719080457655, "biggest_recent_change": 0.07647206983622823},
{"total_number_of_episodes": 38662, "number_of_timesteps": 4408346, "per_episode_reward": -128.88, "episode_reward_trend_value": -0.00223260533145372, "biggest_recent_change": 0.07647206983622823},
{"total_number_of_episodes": 38672, "number_of_timesteps": 4409382, "per_episode_reward": -128.86, "episode_reward_trend_value": -0.0015233304076528182, "biggest_recent_change": 0.07647206983622823},
{"total_number_of_episodes": 38684, "number_of_timesteps": 4410508, "per_episode_reward": -128.85, "episode_reward_trend_value": -0.0007838558247215133, "biggest_recent_change": 0.07647206983622823},
{"total_number_of_episodes": 38694, "number_of_timesteps": 4411466, "per_episode_reward": -128.8, "episode_reward_trend_value": -0.00040771998932882526, "biggest_recent_change": 0.07647206983622823},
{"total_number_of_episodes": 38707, "number_of_timesteps": 4412760, "per_episode_reward": -128.77, "episode_reward_trend_value": 0.000329383105219626, "biggest_recent_change": 0.07647206983622823},
{"total_number_of_episodes": 38717, "number_of_timesteps": 4413924, "per_episode_reward": -128.75, "episode_reward_trend_value": -6.568429020035183e-05, "biggest_recent_change": 0.07647206983622823},
{"total_number_of_episodes": 38728, "number_of_timesteps": 4415218, "per_episode_reward": -128.76, "episode_reward_trend_value": 0.0006873678624581696, "biggest_recent_change": 0.04889860022800008},
{"total_number_of_episodes": 38738, "number_of_timesteps": 4416536, "per_episode_reward": -128.85, "episode_reward_trend_value": 0.00017131359704541813, "biggest_recent_change": 0.09338566050067243},
{"total_number_of_episodes": 38748, "number_of_timesteps": 4417792, "per_episode_reward": -128.87, "episode_reward_trend_value": -0.00015346343679330704, "biggest_recent_change": 0.09338566050067243},
{"total_number_of_episodes": 38758, "number_of_timesteps": 4418753, "per_episode_reward": -128.86, "episode_reward_trend_value": 0.00016835121035935823, "biggest_recent_change": 0.09338566050067243},
{"total_number_of_episodes": 38768, "number_of_timesteps": 4419940, "per_episode_reward": -128.84, "episode_reward_trend_value": 0.00024168748549426608, "biggest_recent_change": 0.09338566050067243},
{"total_number_of_episodes": 38778, "number_of_timesteps": 4421193, "per_episode_reward": -128.87, "episode_reward_trend_value": -0.0002353872919419094, "biggest_recent_change": 0.09338566050067243},
{"total_number_of_episodes": 38790, "number_of_timesteps": 4422587, "per_episode_reward": -128.87, "episode_reward_trend_value": -0.0007183551383841784, "biggest_recent_change": 0.09338566050067243},
{"total_number_of_episodes": 38801, "number_of_timesteps": 4423833, "per_episode_reward": -128.86, "episode_reward_trend_value": -0.0009232460818465269, "biggest_recent_change": 0.09338566050067243},
{"total_number_of_episodes": 38812, "number_of_timesteps": 4425524, "per_episode_reward": -128.87, "episode_reward_trend_value": -0.0013011043040936302, "biggest_recent_change": 0.09338566050067243},
{"total_number_of_episodes": 38823, "number_of_timesteps": 4426794, "per_episode_reward": -128.85, "episode_reward_trend_value": -0.001048822771223475, "biggest_recent_change": 0.09338566050067243},
{"total_number_of_episodes": 38834, "number_of_timesteps": 4428139, "per_episode_reward": -128.9, "episode_reward_trend_value": -0.0005411560950663998, "biggest_recent_change": 0.04769565964653566},
{"total_number_of_episodes": 38844, "number_of_timesteps": 4429325, "per_episode_reward": -128.89, "episode_reward_trend_value": -0.0002937959980591308, "biggest_recent_change": 0.04769565964653566},
{"total_number_of_episodes": 38855, "number_of_timesteps": 4430602, "per_episode_reward": -128.93, "episode_reward_trend_value": -0.0007202758719819889, "biggest_recent_change": 0.04769565964653566},
{"total_number_of_episodes": 38865, "number_of_timesteps": 4431840, "per_episode_reward": -128.93, "episode_reward_trend_value": -0.0010725323743107158, "biggest_recent_change": 0.04769565964653566},
{"total_number_of_episodes": 38875, "number_of_timesteps": 4433037, "per_episode_reward": -128.93, "episode_reward_trend_value": -0.000655599537868549, "biggest_recent_change": 0.04769565964653566},
{"total_number_of_episodes": 38888, "number_of_timesteps": 4434737, "per_episode_reward": -129.05, "episode_reward_trend_value": -0.0019979944019442855, "biggest_recent_change": 0.11538404371862043},
{"total_number_of_episodes": 38898, "number_of_timesteps": 4435637, "per_episode_reward": -129.02, "episode_reward_trend_value": -0.00183664836063018, "biggest_recent_change": 0.11538404371862043},
{"total_number_of_episodes": 38908, "number_of_timesteps": 4436475, "per_episode_reward": -128.98, "episode_reward_trend_value": -0.0013010781480918214, "biggest_recent_change": 0.11538404371862043},
{"total_number_of_episodes": 38920, "number_of_timesteps": 4437865, "per_episode_reward": -128.96, "episode_reward_trend_value": -0.0011673134587144632, "biggest_recent_change": 0.11538404371862043},
{"total_number_of_episodes": 38933, "number_of_timesteps": 4438901, "per_episode_reward": -128.91, "episode_reward_trend_value": -0.00015119739942122125, "biggest_recent_change": 0.11538404371862043},
{"total_number_of_episodes": 38943, "number_of_timesteps": 4439874, "per_episode_reward": -128.87, "episode_reward_trend_value": 0.0002518993499806912, "biggest_recent_change": 0.11538404371862043},
{"total_number_of_episodes": 38953, "number_of_timesteps": 4440892, "per_episode_reward": -128.91, "episode_reward_trend_value": 0.00012659264280267103, "biggest_recent_change": 0.11538404371862043},
{"total_number_of_episodes": 38963, "number_of_timesteps": 4441894, "per_episode_reward": -128.9, "episode_reward_trend_value": 0.00033668058970495924, "biggest_recent_change": 0.11538404371862043},
{"total_number_of_episodes": 38973, "number_of_timesteps": 4442864, "per_episode_reward": -128.9, "episode_reward_trend_value": 0.0003315413766721854, "biggest_recent_change": 0.11538404371862043},
{"total_number_of_episodes": 38984, "number_of_timesteps": 4444288, "per_episode_reward": -128.92, "episode_reward_trend_value": 0.001364002338573932, "biggest_recent_change": 0.043754785689856135},
{"total_number_of_episodes": 38994, "number_of_timesteps": 4446062, "per_episode_reward": -128.95, "episode_reward_trend_value": 0.0007577510399323096, "biggest_recent_change": 0.043754785689856135},
{"total_number_of_episodes": 39005, "number_of_timesteps": 4447395, "per_episode_reward": -128.99, "episode_reward_trend_value": -4.9140918560573884e-05, "biggest_recent_change": 0.043754785689856135},
{"total_number_of_episodes": 39015, "number_of_timesteps": 4448530, "per_episode_reward": -129.02, "episode_reward_trend_value": -0.0006727976858497995, "biggest_recent_change": 0.043754785689856135},
{"total_number_of_episodes": 39025, "number_of_timesteps": 4449297, "per_episode_reward": -129.01, "episode_reward_trend_value": -0.0010204430004923401, "biggest_recent_change": 0.041818994258903786},
{"total_number_of_episodes": 39035, "number_of_timesteps": 4450204, "per_episode_reward": -129.0, "episode_reward_trend_value": -0.0014601711078430272, "biggest_recent_change": 0.041818994258903786},
{"total_number_of_episodes": 39045, "number_of_timesteps": 4451133, "per_episode_reward": -128.96, "episode_reward_trend_value": -0.0004661762556846977, "biggest_recent_change": 0.04764054243534588},
{"total_number_of_episodes": 39055, "number_of_timesteps": 4452476, "per_episode_reward": -128.95, "episode_reward_trend_value": -0.0004689871945386257, "biggest_recent_change": 0.04764054243534588},
{"total_number_of_episodes": 39065, "number_of_timesteps": 4453378, "per_episode_reward": -128.88, "episode_reward_trend_value": 0.0002693866079188941, "biggest_recent_change": 0.069281026195398},
{"total_number_of_episodes": 39075, "number_of_timesteps": 4454343, "per_episode_reward": -128.9, "episode_reward_trend_value": 0.000313731472849415, "biggest_recent_change": 0.069281026195398},
{"total_number_of_episodes": 39085, "number_of_timesteps": 4455830, "per_episode_reward": -128.93, "episode_reward_trend_value": 0.0003265265476200183, "biggest_recent_change": 0.069281026195398},
{"total_number_of_episodes": 39095, "number_of_timesteps": 4457187, "per_episode_reward": -128.93, "episode_reward_trend_value": 0.0006798561434127098, "biggest_recent_change": 0.069281026195398},
{"total_number_of_episodes": 39105, "number_of_timesteps": 4458487, "per_episode_reward": -128.93, "episode_reward_trend_value": 0.0010324290357197519, "biggest_recent_change": 0.069281026195398},
{"total_number_of_episodes": 39115, "number_of_timesteps": 4459715, "per_episode_reward": -128.95, "episode_reward_trend_value": 0.0005908423379414292, "biggest_recent_change": 0.069281026195398},
{"total_number_of_episodes": 39125, "number_of_timesteps": 4460933, "per_episode_reward": -128.97, "episode_reward_trend_value": 0.0003925369457138888, "biggest_recent_change": 0.069281026195398},
{"total_number_of_episodes": 39136, "number_of_timesteps": 4462192, "per_episode_reward": -128.94, "episode_reward_trend_value": 0.0001975516029337617, "biggest_recent_change": 0.069281026195398},
{"total_number_of_episodes": 39146, "number_of_timesteps": 4463237, "per_episode_reward": -129.0, "episode_reward_trend_value": -0.0005555335853683927, "biggest_recent_change": 0.069281026195398},
{"total_number_of_episodes": 39156, "number_of_timesteps": 4464595, "per_episode_reward": -129.02, "episode_reward_trend_value": -0.0015504653466757014, "biggest_recent_change": 0.05827603508248558},
{"total_number_of_episodes": 39167, "number_of_timesteps": 4465836, "per_episode_reward": -128.98, "episode_reward_trend_value": -0.0009262895074490038, "biggest_recent_change": 0.05827603508248558},
{"total_number_of_episodes": 39177, "number_of_timesteps": 4466824, "per_episode_reward": -128.99, "episode_reward_trend_value": -0.0007206016280232714, "biggest_recent_change": 0.05827603508248558},
{"total_number_of_episodes": 39187, "number_of_timesteps": 4468296, "per_episode_reward": -128.95, "episode_reward_trend_value": -0.0002832936368482327, "biggest_recent_change": 0.05827603508248558},
{"total_number_of_episodes": 39197, "number_of_timesteps": 4469328, "per_episode_reward": -128.92, "episode_reward_trend_value": 0.00011297201006420387, "biggest_recent_change": 0.05827603508248558},
{"total_number_of_episodes": 39207, "number_of_timesteps": 4470606, "per_episode_reward": -128.96, "episode_reward_trend_value": -0.00011808440962587004, "biggest_recent_change": 0.05827603508248558},
{"total_number_of_episodes": 39217, "number_of_timesteps": 4471810, "per_episode_reward": -129.03, "episode_reward_trend_value": -0.0006663918287106046, "biggest_recent_change": 0.06507261198424885},
{"total_number_of_episodes": 39227, "number_of_timesteps": 4472791, "per_episode_reward": -129.02, "episode_reward_trend_value": -0.0009187222075528072, "biggest_recent_change": 0.06507261198424885},
{"total_number_of_episodes": 39238, "number_of_timesteps": 4473919, "per_episode_reward": -128.99, "episode_reward_trend_value": 9.564155509199029e-05, "biggest_recent_change": 0.06507261198424885},
{"total_number_of_episodes": 39248, "number_of_timesteps": 4474918, "per_episode_reward": -128.99, "episode_reward_trend_value": 0.0002445494205984586, "biggest_recent_change": 0.06507261198424885},
{"total_number_of_episodes": 39258, "number_of_timesteps": 4475794, "per_episode_reward": -128.92, "episode_reward_trend_value": 0.0006788654413043104, "biggest_recent_change": 0.07679274809021308},
{"total_number_of_episodes": 39268, "number_of_timesteps": 4476756, "per_episode_reward": -128.9, "episode_reward_trend_value": 0.0010180228689512837, "biggest_recent_change": 0.07679274809021308},
{"total_number_of_episodes": 39278, "number_of_timesteps": 4477898, "per_episode_reward": -128.91, "episode_reward_trend_value": 0.0005224210494020554, "biggest_recent_change": 0.07679274809021308},
{"total_number_of_episodes": 39288, "number_of_timesteps": 4478800, "per_episode_reward": -128.9, "episode_reward_trend_value": 0.00012450780617933156, "biggest_recent_change": 0.07679274809021308},
{"total_number_of_episodes": 39298, "number_of_timesteps": 4480353, "per_episode_reward": -128.89, "episode_reward_trend_value": 0.0008375064057806489, "biggest_recent_change": 0.07679274809021308},
{"total_number_of_episodes": 39308, "number_of_timesteps": 4481114, "per_episode_reward": -128.86, "episode_reward_trend_value": 0.0019040137681429314, "biggest_recent_change": 0.07679274809021308},
{"total_number_of_episodes": 39319, "number_of_timesteps": 4481916, "per_episode_reward": -128.81, "episode_reward_trend_value": 0.0023368624120024607, "biggest_recent_change": 0.07679274809021308},
{"total_number_of_episodes": 39329, "number_of_timesteps": 4482728, "per_episode_reward": -128.81, "episode_reward_trend_value": 0.0020279972204118877, "biggest_recent_change": 0.07679274809021308},
{"total_number_of_episodes": 39339, "number_of_timesteps": 4483638, "per_episode_reward": -128.78, "episode_reward_trend_value": 0.002418080395669146, "biggest_recent_change": 0.07679274809021308},
{"total_number_of_episodes": 39351, "number_of_timesteps": 4485515, "per_episode_reward": -128.8, "episode_reward_trend_value": 0.001255233196382556, "biggest_recent_change": 0.04633850543669382},
{"total_number_of_episodes": 39361, "number_of_timesteps": 4486402, "per_episode_reward": -128.8, "episode_reward_trend_value": 0.0011424465894931599, "biggest_recent_change": 0.04633850543669382},
{"total_number_of_episodes": 39371, "number_of_timesteps": 4487609, "per_episode_reward": -128.81, "episode_reward_trend_value": 0.0011032138759086744, "biggest_recent_change": 0.04633850543669382},
{"total_number_of_episodes": 39382, "number_of_timesteps": 4489098, "per_episode_reward": -128.81, "episode_reward_trend_value": 0.0010209304636039937, "biggest_recent_change": 0.04633850543669382},
{"total_number_of_episodes": 39392, "number_of_timesteps": 4489826, "per_episode_reward": -128.8, "episode_reward_trend_value": 0.0009691354472816252, "biggest_recent_change": 0.04633850543669382},
{"total_number_of_episodes": 39402, "number_of_timesteps": 4490689, "per_episode_reward": -128.71, "episode_reward_trend_value": 0.0015886357201537749, "biggest_recent_change": 0.08666807518685005},
{"total_number_of_episodes": 39412, "number_of_timesteps": 4491812, "per_episode_reward": -128.65, "episode_reward_trend_value": 0.0018012853628161136, "biggest_recent_change": 0.08666807518685005},
{"total_number_of_episodes": 39422, "number_of_timesteps": 4492965, "per_episode_reward": -128.64, "episode_reward_trend_value": 0.0018729240240595065, "biggest_recent_change": 0.08666807518685005},
{"total_number_of_episodes": 39432, "number_of_timesteps": 4494337, "per_episode_reward": -128.69, "episode_reward_trend_value": 0.0009966948541296637, "biggest_recent_change": 0.08666807518685005},
{"total_number_of_episodes": 39442, "number_of_timesteps": 4495028, "per_episode_reward": -128.64, "episode_reward_trend_value": 0.0018180654447901487, "biggest_recent_change": 0.08666807518685005},
{"total_number_of_episodes": 39452, "number_of_timesteps": 4495998, "per_episode_reward": -128.66, "episode_reward_trend_value": 0.0015282484289249017, "biggest_recent_change": 0.08666807518685005},
{"total_number_of_episodes": 39462, "number_of_timesteps": 4497143, "per_episode_reward": -128.65, "episode_reward_trend_value": 0.001753759766785063, "biggest_recent_change": 0.08666807518685005},
{"total_number_of_episodes": 39472, "number_of_timesteps": 4498092, "per_episode_reward": -128.62, "episode_reward_trend_value": 0.0020937830836291796, "biggest_recent_change": 0.08666807518685005},
{"total_number_of_episodes": 39482, "number_of_timesteps": 4499315, "per_episode_reward": -128.63, "episode_reward_trend_value": 0.001904964724789377, "biggest_recent_change": 0.08666807518685005},
{"total_number_of_episodes": 39492, "number_of_timesteps": 4500597, "per_episode_reward": -128.64, "episode_reward_trend_value": 0.0008134022035913328, "biggest_recent_change": 0.0654769732763043},
{"total_number_of_episodes": 39502, "number_of_timesteps": 4501657, "per_episode_reward": -128.61, "episode_reward_trend_value": 0.00037077412801743827, "biggest_recent_change": 0.05061426394721025},
{"total_number_of_episodes": 39512, "number_of_timesteps": 4503332, "per_episode_reward": -128.66, "episode_reward_trend_value": -0.00021774553532180916, "biggest_recent_change": 0.05061426394721025},
{"total_number_of_episodes": 39522, "number_of_timesteps": 4504855, "per_episode_reward": -128.65, "episode_reward_trend_value": 0.0003991322789286439, "biggest_recent_change": 0.04605985331386364},
{"total_number_of_episodes": 39532, "number_of_timesteps": 4505739, "per_episode_reward": -128.63, "episode_reward_trend_value": 0.00012929514557053306, "biggest_recent_change": 0.04130045387623227},
{"total_number_of_episodes": 39542, "number_of_timesteps": 4507088, "per_episode_reward": -128.68, "episode_reward_trend_value": -0.00021229243427159063, "biggest_recent_change": 0.04756344698000703},
{"total_number_of_episodes": 39552, "number_of_timesteps": 4508489, "per_episode_reward": -128.65, "episode_reward_trend_value": 3.6711963266119107e-06, "biggest_recent_change": 0.04756344698000703},
{"total_number_of_episodes": 39562, "number_of_timesteps": 4509782, "per_episode_reward": -128.66, "episode_reward_trend_value": -0.0003645719473777515, "biggest_recent_change": 0.04756344698000703},
{"total_number_of_episodes": 39573, "number_of_timesteps": 4510877, "per_episode_reward": -128.61, "episode_reward_trend_value": 0.0002599962035295297, "biggest_recent_change": 0.05065463058105024},
{"total_number_of_episodes": 39583, "number_of_timesteps": 4512120, "per_episode_reward": -128.67, "episode_reward_trend_value": -0.0003346967425276009, "biggest_recent_change": 0.06509491686611568},
{"total_number_of_episodes": 39593, "number_of_timesteps": 4513381, "per_episode_reward": -128.61, "episode_reward_trend_value": 3.321869123043244e-05, "biggest_recent_change": 0.06509491686611568},
{"total_number_of_episodes": 39603, "number_of_timesteps": 4514527, "per_episode_reward": -128.61, "episode_reward_trend_value": 0.0005625801937801119, "biggest_recent_change": 0.06509491686611568},
{"total_number_of_episodes": 39613, "number_of_timesteps": 4515655, "per_episode_reward": -128.64, "episode_reward_trend_value": 0.00012679416797835882, "biggest_recent_change": 0.06509491686611568},
{"total_number_of_episodes": 39623, "number_of_timesteps": 4516967, "per_episode_reward": -128.67, "episode_reward_trend_value": -0.0004832449321390363, "biggest_recent_change": 0.06509491686611568},
{"total_number_of_episodes": 39633, "number_of_timesteps": 4518079, "per_episode_reward": -128.61, "episode_reward_trend_value": 0.0007861431907634319, "biggest_recent_change": 0.0666814840812151},
{"total_number_of_episodes": 39643, "number_of_timesteps": 4518982, "per_episode_reward": -128.57, "episode_reward_trend_value": 0.0008122014364614769, "biggest_recent_change": 0.0666814840812151},
{"total_number_of_episodes": 39653, "number_of_timesteps": 4520082, "per_episode_reward": -128.6, "episode_reward_trend_value": 0.0005915668551270731, "biggest_recent_change": 0.0666814840812151},
{"total_number_of_episodes": 39663, "number_of_timesteps": 4521161, "per_episode_reward": -128.65, "episode_reward_trend_value": -0.00044609914840173636, "biggest_recent_change": 0.0666814840812151},
{"total_number_of_episodes": 39673, "number_of_timesteps": 4522322, "per_episode_reward": -128.67, "episode_reward_trend_value": 2.307577892837445e-05, "biggest_recent_change": 0.0666814840812151},
{"total_number_of_episodes": 39683, "number_of_timesteps": 4523694, "per_episode_reward": -128.68, "episode_reward_trend_value": -0.0007013974717918043, "biggest_recent_change": 0.0666814840812151},
{"total_number_of_episodes": 39693, "number_of_timesteps": 4524927, "per_episode_reward": -128.7, "episode_reward_trend_value": -0.001003692212355784, "biggest_recent_change": 0.0666814840812151},
{"total_number_of_episodes": 39703, "number_of_timesteps": 4526363, "per_episode_reward": -128.72, "episode_reward_trend_value": -0.0008949069175902954, "biggest_recent_change": 0.0666814840812151},
{"total_number_of_episodes": 39713, "number_of_timesteps": 4527474, "per_episode_reward": -128.72, "episode_reward_trend_value": -0.0004879785332421862, "biggest_recent_change": 0.0666814840812151},
{"total_number_of_episodes": 39723, "number_of_timesteps": 4528748, "per_episode_reward": -128.71, "episode_reward_trend_value": -0.0011877382307258384, "biggest_recent_change": 0.042735309736542604},
{"total_number_of_episodes": 39733, "number_of_timesteps": 4529986, "per_episode_reward": -128.68, "episode_reward_trend_value": -0.001188283648106234, "biggest_recent_change": 0.042735309736542604},
{"total_number_of_episodes": 39743, "number_of_timesteps": 4530749, "per_episode_reward": -128.64, "episode_reward_trend_value": -0.0004653821691950573, "biggest_recent_change": 0.042735309736542604},
{"total_number_of_episodes": 39754, "number_of_timesteps": 4531959, "per_episode_reward": -128.62, "episode_reward_trend_value": 0.00029248870249760884, "biggest_recent_change": 0.03675968074605862},
{"total_number_of_episodes": 39764, "number_of_timesteps": 4532942, "per_episode_reward": -128.65, "episode_reward_trend_value": 0.00025949214771464493, "biggest_recent_change": 0.03675968074605862},
{"total_number_of_episodes": 39775, "number_of_timesteps": 4534027, "per_episode_reward": -128.63, "episode_reward_trend_value": 0.0005328749122030432, "biggest_recent_change": 0.03675968074605862},
{"total_number_of_episodes": 39785, "number_of_timesteps": 4535038, "per_episode_reward": -128.61, "episode_reward_trend_value": 0.0009844111904581294, "biggest_recent_change": 0.03675968074605862},
{"total_number_of_episodes": 39795, "number_of_timesteps": 4535955, "per_episode_reward": -128.61, "episode_reward_trend_value": 0.001196453595037244, "biggest_recent_change": 0.03675968074605862},
{"total_number_of_episodes": 39805, "number_of_timesteps": 4536830, "per_episode_reward": -128.58, "episode_reward_trend_value": 0.0014883657977646989, "biggest_recent_change": 0.03675968074605862},
{"total_number_of_episodes": 39815, "number_of_timesteps": 4537737, "per_episode_reward": -128.58, "episode_reward_trend_value": 0.0014855002768042723, "biggest_recent_change": 0.03675968074605862},
{"total_number_of_episodes": 39825, "number_of_timesteps": 4539172, "per_episode_reward": -128.61, "episode_reward_trend_value": 0.0008481472185855587, "biggest_recent_change": 0.03675968074605862},
{"total_number_of_episodes": 39835, "number_of_timesteps": 4540409, "per_episode_reward": -128.6, "episode_reward_trend_value": 0.00044467558172950957, "biggest_recent_change": 0.029766645137868863},
{"total_number_of_episodes": 39845, "number_of_timesteps": 4541454, "per_episode_reward": -128.56, "episode_reward_trend_value": 0.0006142688794972805, "biggest_recent_change": 0.040736465514896736},
{"total_number_of_episodes": 39855, "number_of_timesteps": 4542671, "per_episode_reward": -128.58, "episode_reward_trend_value": 0.0007780265377407304, "biggest_recent_change": 0.040736465514896736},
{"total_number_of_episodes": 39865, "number_of_timesteps": 4543901, "per_episode_reward": -128.58, "episode_reward_trend_value": 0.0005366490906390532, "biggest_recent_change": 0.040736465514896736},
{"total_number_of_episodes": 39875, "number_of_timesteps": 4545515, "per_episode_reward": -128.61, "episode_reward_trend_value": -1.563090593745326e-05, "biggest_recent_change": 0.040736465514896736},
{"total_number_of_episodes": 39885, "number_of_timesteps": 4546454, "per_episode_reward": -128.58, "episode_reward_trend_value": 0.00039032427015052283, "biggest_recent_change": 0.040736465514896736},
{"total_number_of_episodes": 39895, "number_of_timesteps": 4547415, "per_episode_reward": -128.59, "episode_reward_trend_value": -0.0001028740450395718, "biggest_recent_change": 0.040736465514896736},
{"total_number_of_episodes": 39905, "number_of_timesteps": 4548593, "per_episode_reward": -128.6, "episode_reward_trend_value": -0.000246813371763071, "biggest_recent_change": 0.040736465514896736},
{"total_number_of_episodes": 39916, "number_of_timesteps": 4549891, "per_episode_reward": -128.63, "episode_reward_trend_value": -0.0003250921581458973, "biggest_recent_change": 0.040736465514896736},
{"total_number_of_episodes": 39926, "number_of_timesteps": 4551064, "per_episode_reward": -128.63, "episode_reward_trend_value": -0.00023076505279170256, "biggest_recent_change": 0.040736465514896736},
exited at update_barrier.wait(): 3, error = 
None
exited at update_barrier.wait(): 0, error = 
None
exited at all_updated_barrier.wait(): 4, error = 
None
exited at all_updated_barrier.wait(): 5, error = 
None
exited at update_barrier.wait(): 2, error = 
None

{"total_number_of_episodes": 39936, "number_of_timesteps": 4552458, "per_episode_reward": -128.64, "episode_reward_trend_value": -0.0008545711179177969, "biggest_recent_change": 0.032804588237496546},
{"total_number_of_episodes": 39946, "number_of_timesteps": 4553549, "per_episode_reward": -128.63, "episode_reward_trend_value": -0.0006227313991732646, "biggest_recent_change": 0.032804588237496546},
{"total_number_of_episodes": 39956, "number_of_timesteps": 4554666, "per_episode_reward": -128.64, "episode_reward_trend_value": -0.0006273297039895296, "biggest_recent_change": 0.032804588237496546},
{"total_number_of_episodes": 39966, "number_of_timesteps": 4555901, "per_episode_reward": -128.62, "episode_reward_trend_value": -7.93467568734564e-05, "biggest_recent_change": 0.032804588237496546},
{"total_number_of_episodes": 39977, "number_of_timesteps": 4557293, "per_episode_reward": -128.6, "episode_reward_trend_value": -0.000267001074706425, "biggest_recent_change": 0.032804588237496546},
{"total_number_of_episodes": 39987, "number_of_timesteps": 4558387, "per_episode_reward": -128.58, "episode_reward_trend_value": 0.00017281230423186065, "biggest_recent_change": 0.032804588237496546},
{"total_number_of_episodes": 39998, "number_of_timesteps": 4559552, "per_episode_reward": -128.58, "episode_reward_trend_value": 0.0002653214617367894, "biggest_recent_change": 0.032804588237496546},
exited at all_updated_barrier.wait(): 6, error = 
None
[done calling async_.run_async()]
final_eval: {'number_of_steps': 125000, 'number_of_episodes': None, 'mean': -317.2120362453365, 'median': -323.8528504062265, 'stdev': 136.3065907153466}
[starting train_a3c()]
[starting train_agent_async()]
[about to call async_.run_async()]
[starting run_func()]
[starting train_loop()]
Step 0 0 visits [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1 0 visits [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-11.111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2 1 visits [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-11.111, -5.461, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 3 2 visits [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-11.111, -5.461, -11.111, 0.0, 0.0, 0.0, 0.0]
Step 4 3 visits [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-11.111, -5.461, -11.111, -11.111, 0.0, 0.0, 0.0]
Step 5 4 visits [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 0 q_vals: [-11.111, -5.461, -11.111, -11.111, -8.264, 0.0, 0.0]
Step 6 5 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 0 q_vals: [-11.111, -5.461, -11.111, -11.111, -8.264, -9.583, 0.0]
Step 7 6 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 1 q_vals: [-11.111, -5.461, -11.111, -11.111, -8.264, -9.583, -11.111]
Step 8 1 visits [1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 3 q_vals: [-11.111, -8.286, -11.111, -11.111, -8.264, -9.583, -11.111]
Step 9 4 visits [1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0]  episode_count: 5 q_vals: [-11.111, -8.286, -11.111, -11.111, -6.165, -9.583, -11.111]
Step 10 4 visits [1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0]  episode_count: 7 q_vals: [-11.111, -8.286, -11.111, -11.111, -4.11, -9.583, -11.111]
Step 11 4 visits [1.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0]  episode_count: 7 q_vals: [-11.111, -8.286, -11.111, -11.111, -4.217, -9.583, -11.111]
Step 12 4 visits [1.0, 2.0, 1.0, 1.0, 5.0, 1.0, 1.0]  episode_count: 7 q_vals: [-11.111, -8.286, -11.111, -11.111, -5.596, -9.583, -11.111]
Step 13 4 visits [1.0, 2.0, 1.0, 1.0, 6.0, 1.0, 1.0]  episode_count: 7 q_vals: [-11.111, -8.286, -11.111, -11.111, -6.515, -9.583, -11.111]
Step 14 4 visits [1.0, 2.0, 1.0, 1.0, 7.0, 1.0, 1.0]  episode_count: 7 q_vals: [-11.111, -8.286, -11.111, -11.111, -5.585, -9.583, -11.111]
Step 15 4 visits [1.0, 2.0, 1.0, 1.0, 8.0, 1.0, 1.0]  episode_count: 8 q_vals: [-11.111, -8.286, -11.111, -11.111, -6.275, -9.583, -11.111]
Step 16 4 visits [1.0, 2.0, 1.0, 1.0, 9.0, 1.0, 1.0]  episode_count: 8 q_vals: [-11.111, -8.286, -11.111, -11.111, -6.77, -9.583, -11.111]
Step 17 4 visits [1.0, 2.0, 1.0, 1.0, 10.0, 1.0, 1.0]  episode_count: 8 q_vals: [-11.111, -8.286, -11.111, -11.111, -6.417, -9.583, -11.111]
Step 18 4 visits [1.0, 2.0, 1.0, 1.0, 11.0, 1.0, 1.0]  episode_count: 9 q_vals: [-11.111, -8.286, -11.111, -11.111, -6.519, -9.583, -11.111]
Step 19 4 visits [1.0, 2.0, 1.0, 1.0, 12.0, 1.0, 1.0]  episode_count: 11 q_vals: [-11.111, -8.286, -11.111, -11.111, -6.902, -9.583, -11.111]
Step 20 4 visits [1.0, 2.0, 1.0, 1.0, 13.0, 1.0, 1.0]  episode_count: 12 q_vals: [-11.111, -8.286, -11.111, -11.111, -7.225, -9.583, -11.111]
Step 21 4 visits [1.0, 2.0, 1.0, 1.0, 14.0, 1.0, 1.0]  episode_count: 14 q_vals: [-11.111, -8.286, -11.111, -11.111, -7.503, -9.583, -11.111]
Step 22 4 visits [1.0, 2.0, 1.0, 1.0, 15.0, 1.0, 1.0]  episode_count: 14 q_vals: [-11.111, -8.286, -11.111, -11.111, -7.744, -9.583, -11.111]
Step 23 1 visits [1.0, 3.0, 1.0, 1.0, 15.0, 1.0, 1.0]  episode_count: 14 q_vals: [-11.111, -9.228, -11.111, -11.111, -7.744, -9.583, -11.111]
Step 24 4 visits [1.0, 3.0, 1.0, 1.0, 16.0, 1.0, 1.0]  episode_count: 14 q_vals: [-11.111, -9.228, -11.111, -11.111, -7.796, -9.583, -11.111]
Step 25 4 visits [1.0, 3.0, 1.0, 1.0, 17.0, 1.0, 1.0]  episode_count: 14 q_vals: [-11.111, -9.228, -11.111, -11.111, -7.991, -9.583, -11.111]
Step 26 4 visits [1.0, 3.0, 1.0, 1.0, 18.0, 1.0, 1.0]  episode_count: 16 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.165, -9.583, -11.111]
Step 27 4 visits [1.0, 3.0, 1.0, 1.0, 19.0, 1.0, 1.0]  episode_count: 18 q_vals: [-11.111, -9.228, -11.111, -11.111, -7.735, -9.583, -11.111]
Step 28 4 visits [1.0, 3.0, 1.0, 1.0, 20.0, 1.0, 1.0]  episode_count: 19 q_vals: [-11.111, -9.228, -11.111, -11.111, -7.904, -9.583, -11.111]
Step 29 4 visits [1.0, 3.0, 1.0, 1.0, 21.0, 1.0, 1.0]  episode_count: 19 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.057, -9.583, -11.111]
Step 30 4 visits [1.0, 3.0, 1.0, 1.0, 22.0, 1.0, 1.0]  episode_count: 20 q_vals: [-11.111, -9.228, -11.111, -11.111, -7.69, -9.583, -11.111]
Step 31 4 visits [1.0, 3.0, 1.0, 1.0, 23.0, 1.0, 1.0]  episode_count: 20 q_vals: [-11.111, -9.228, -11.111, -11.111, -7.839, -9.583, -11.111]
Step 32 4 visits [1.0, 3.0, 1.0, 1.0, 24.0, 1.0, 1.0]  episode_count: 20 q_vals: [-11.111, -9.228, -11.111, -11.111, -7.975, -9.583, -11.111]
Step 33 4 visits [1.0, 3.0, 1.0, 1.0, 25.0, 1.0, 1.0]  episode_count: 20 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.101, -9.583, -11.111]
Step 34 5 visits [1.0, 3.0, 1.0, 1.0, 25.0, 2.0, 1.0]  episode_count: 20 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.101, -10.347, -11.111]
Step 35 4 visits [1.0, 3.0, 1.0, 1.0, 26.0, 2.0, 1.0]  episode_count: 22 q_vals: [-11.111, -9.228, -11.111, -11.111, -7.789, -10.347, -11.111]
Step 36 4 visits [1.0, 3.0, 1.0, 1.0, 27.0, 2.0, 1.0]  episode_count: 22 q_vals: [-11.111, -9.228, -11.111, -11.111, -7.912, -10.347, -11.111]
Step 37 4 visits [1.0, 3.0, 1.0, 1.0, 28.0, 2.0, 1.0]  episode_count: 24 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.027, -10.347, -11.111]
Step 38 4 visits [1.0, 3.0, 1.0, 1.0, 29.0, 2.0, 1.0]  episode_count: 24 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.133, -10.347, -11.111]
Step 39 4 visits [1.0, 3.0, 1.0, 1.0, 30.0, 2.0, 1.0]  episode_count: 25 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.232, -10.347, -11.111]
Step 40 4 visits [1.0, 3.0, 1.0, 1.0, 31.0, 2.0, 1.0]  episode_count: 25 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.325, -10.347, -11.111]
Step 41 4 visits [1.0, 3.0, 1.0, 1.0, 32.0, 2.0, 1.0]  episode_count: 25 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.237, -10.347, -11.111]
Step 42 4 visits [1.0, 3.0, 1.0, 1.0, 33.0, 2.0, 1.0]  episode_count: 26 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.324, -10.347, -11.111]
Step 43 4 visits [1.0, 3.0, 1.0, 1.0, 34.0, 2.0, 1.0]  episode_count: 27 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.079, -10.347, -11.111]
Step 44 4 visits [1.0, 3.0, 1.0, 1.0, 35.0, 2.0, 1.0]  episode_count: 27 q_vals: [-11.111, -9.228, -11.111, -11.111, -7.848, -10.347, -11.111]
Step 45 4 visits [1.0, 3.0, 1.0, 1.0, 36.0, 2.0, 1.0]  episode_count: 28 q_vals: [-11.111, -9.228, -11.111, -11.111, -7.939, -10.347, -11.111]
Step 46 4 visits [1.0, 3.0, 1.0, 1.0, 37.0, 2.0, 1.0]  episode_count: 30 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.024, -10.347, -11.111]
Step 47 4 visits [1.0, 3.0, 1.0, 1.0, 38.0, 2.0, 1.0]  episode_count: 30 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.106, -10.347, -11.111]
Step 48 4 visits [1.0, 3.0, 1.0, 1.0, 39.0, 2.0, 1.0]  episode_count: 30 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.183, -10.347, -11.111]
{"total_number_of_episodes": 31, "number_of_timesteps": 2933, "per_episode_reward": -162.36, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Step 49 4 visits [1.0, 3.0, 1.0, 1.0, 40.0, 2.0, 1.0]  episode_count: 31 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.256, -10.347, -11.111]
Step 50 4 visits [1.0, 3.0, 1.0, 1.0, 41.0, 2.0, 1.0]  episode_count: 31 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.055, -10.347, -11.111]
Step 51 4 visits [1.0, 3.0, 1.0, 1.0, 42.0, 2.0, 1.0]  episode_count: 32 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.127, -10.347, -11.111]
Step 52 4 visits [1.0, 3.0, 1.0, 1.0, 43.0, 2.0, 1.0]  episode_count: 33 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.197, -10.347, -11.111]
Step 53 4 visits [1.0, 3.0, 1.0, 1.0, 44.0, 2.0, 1.0]  episode_count: 33 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.01, -10.347, -11.111]
Step 54 4 visits [1.0, 3.0, 1.0, 1.0, 45.0, 2.0, 1.0]  episode_count: 34 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.079, -10.347, -11.111]
Step 55 4 visits [1.0, 3.0, 1.0, 1.0, 46.0, 2.0, 1.0]  episode_count: 36 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.145, -10.347, -11.111]
Step 56 4 visits [1.0, 3.0, 1.0, 1.0, 47.0, 2.0, 1.0]  episode_count: 36 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.208, -10.347, -11.111]
Step 57 4 visits [1.0, 3.0, 1.0, 1.0, 48.0, 2.0, 1.0]  episode_count: 38 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.269, -10.347, -11.111]
Step 58 4 visits [1.0, 3.0, 1.0, 1.0, 49.0, 2.0, 1.0]  episode_count: 38 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.327, -10.347, -11.111]
Step 59 4 visits [1.0, 3.0, 1.0, 1.0, 50.0, 2.0, 1.0]  episode_count: 38 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.16, -10.347, -11.111]
Step 60 4 visits [1.0, 3.0, 1.0, 1.0, 51.0, 2.0, 1.0]  episode_count: 39 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.218, -10.347, -11.111]
Step 61 4 visits [1.0, 3.0, 1.0, 1.0, 52.0, 2.0, 1.0]  episode_count: 39 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.274, -10.347, -11.111]
Step 62 4 visits [1.0, 3.0, 1.0, 1.0, 53.0, 2.0, 1.0]  episode_count: 40 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.327, -10.347, -11.111]
{"total_number_of_episodes": 41, "number_of_timesteps": 3882, "per_episode_reward": -187.2, "episode_reward_trend_value": -2.4838290877343896, "biggest_recent_change": NaN},
Step 63 4 visits [1.0, 3.0, 1.0, 1.0, 54.0, 2.0, 1.0]  episode_count: 41 q_vals: [-11.111, -9.228, -11.111, -11.111, -8.379, -10.347, -11.111]
Step 64 1 visits [1.0, 4.0, 1.0, 1.0, 54.0, 2.0, 1.0]  episode_count: 42 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.379, -10.347, -11.111]
Step 65 4 visits [1.0, 4.0, 1.0, 1.0, 55.0, 2.0, 1.0]  episode_count: 42 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.227, -10.347, -11.111]
Step 66 4 visits [1.0, 4.0, 1.0, 1.0, 56.0, 2.0, 1.0]  episode_count: 42 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.278, -10.347, -11.111]
Step 67 4 visits [1.0, 4.0, 1.0, 1.0, 57.0, 2.0, 1.0]  episode_count: 44 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.328, -10.347, -11.111]
Step 68 4 visits [1.0, 4.0, 1.0, 1.0, 58.0, 2.0, 1.0]  episode_count: 45 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.376, -10.347, -11.111]
Step 69 4 visits [1.0, 4.0, 1.0, 1.0, 59.0, 2.0, 1.0]  episode_count: 46 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.422, -10.347, -11.111]
Step 70 4 visits [1.0, 4.0, 1.0, 1.0, 60.0, 2.0, 1.0]  episode_count: 46 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.467, -10.347, -11.111]
Step 71 4 visits [1.0, 4.0, 1.0, 1.0, 61.0, 2.0, 1.0]  episode_count: 47 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.51, -10.347, -11.111]
Step 72 4 visits [1.0, 4.0, 1.0, 1.0, 62.0, 2.0, 1.0]  episode_count: 47 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.552, -10.347, -11.111]
Step 73 4 visits [1.0, 4.0, 1.0, 1.0, 63.0, 2.0, 1.0]  episode_count: 47 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.593, -10.347, -11.111]
Step 74 4 visits [1.0, 4.0, 1.0, 1.0, 64.0, 2.0, 1.0]  episode_count: 49 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.632, -10.347, -11.111]
Step 75 4 visits [1.0, 4.0, 1.0, 1.0, 65.0, 2.0, 1.0]  episode_count: 49 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.67, -10.347, -11.111]
{"total_number_of_episodes": 51, "number_of_timesteps": 4849, "per_episode_reward": -261.82, "episode_reward_trend_value": -4.97325414577702, "biggest_recent_change": NaN},
Step 76 4 visits [1.0, 4.0, 1.0, 1.0, 66.0, 2.0, 1.0]  episode_count: 51 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.707, -10.347, -11.111]
Step 77 4 visits [1.0, 4.0, 1.0, 1.0, 67.0, 2.0, 1.0]  episode_count: 52 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.743, -10.347, -11.111]
Step 78 4 visits [1.0, 4.0, 1.0, 1.0, 68.0, 2.0, 1.0]  episode_count: 53 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.778, -10.347, -11.111]
Step 79 4 visits [1.0, 4.0, 1.0, 1.0, 69.0, 2.0, 1.0]  episode_count: 53 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.812, -10.347, -11.111]
Step 80 4 visits [1.0, 4.0, 1.0, 1.0, 70.0, 2.0, 1.0]  episode_count: 53 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.686, -10.347, -11.111]
Step 81 4 visits [1.0, 4.0, 1.0, 1.0, 71.0, 2.0, 1.0]  episode_count: 53 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.72, -10.347, -11.111]
Step 82 4 visits [1.0, 4.0, 1.0, 1.0, 72.0, 2.0, 1.0]  episode_count: 53 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.599, -10.347, -11.111]
Step 83 4 visits [1.0, 4.0, 1.0, 1.0, 73.0, 2.0, 1.0]  episode_count: 55 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.481, -10.347, -11.111]
Step 84 4 visits [1.0, 4.0, 1.0, 1.0, 74.0, 2.0, 1.0]  episode_count: 56 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.517, -10.347, -11.111]
Step 85 4 visits [1.0, 4.0, 1.0, 1.0, 75.0, 2.0, 1.0]  episode_count: 56 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.551, -10.347, -11.111]
Step 86 4 visits [1.0, 4.0, 1.0, 1.0, 76.0, 2.0, 1.0]  episode_count: 57 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.585, -10.347, -11.111]
Step 87 4 visits [1.0, 4.0, 1.0, 1.0, 77.0, 2.0, 1.0]  episode_count: 58 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.618, -10.347, -11.111]
Step 88 4 visits [1.0, 4.0, 1.0, 1.0, 78.0, 2.0, 1.0]  episode_count: 60 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.65, -10.347, -11.111]
Step 89 4 visits [1.0, 4.0, 1.0, 1.0, 79.0, 2.0, 1.0]  episode_count: 60 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.54, -10.347, -11.111]
Step 90 4 visits [1.0, 4.0, 1.0, 1.0, 80.0, 2.0, 1.0]  episode_count: 60 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.434, -10.347, -11.111]
{"total_number_of_episodes": 62, "number_of_timesteps": 5864, "per_episode_reward": -329.56, "episode_reward_trend_value": -5.573347773382765, "biggest_recent_change": NaN},
Step 91 4 visits [1.0, 4.0, 1.0, 1.0, 81.0, 2.0, 1.0]  episode_count: 62 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.467, -10.347, -11.111]
Step 92 4 visits [1.0, 4.0, 1.0, 1.0, 82.0, 2.0, 1.0]  episode_count: 62 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.499, -10.347, -11.111]
Step 93 4 visits [1.0, 4.0, 1.0, 1.0, 83.0, 2.0, 1.0]  episode_count: 63 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.53, -10.347, -11.111]
Step 94 4 visits [1.0, 4.0, 1.0, 1.0, 84.0, 2.0, 1.0]  episode_count: 63 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.561, -10.347, -11.111]
Step 95 4 visits [1.0, 4.0, 1.0, 1.0, 85.0, 2.0, 1.0]  episode_count: 63 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.591, -10.347, -11.111]
Step 96 4 visits [1.0, 4.0, 1.0, 1.0, 86.0, 2.0, 1.0]  episode_count: 64 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.491, -10.347, -11.111]
Step 97 4 visits [1.0, 4.0, 1.0, 1.0, 87.0, 2.0, 1.0]  episode_count: 65 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.394, -10.347, -11.111]
Step 98 4 visits [1.0, 4.0, 1.0, 1.0, 88.0, 2.0, 1.0]  episode_count: 65 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.424, -10.347, -11.111]
Step 99 4 visits [1.0, 4.0, 1.0, 1.0, 89.0, 2.0, 1.0]  episode_count: 67 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.455, -10.347, -11.111]
Step 100 4 visits [1.0, 4.0, 1.0, 1.0, 90.0, 2.0, 1.0]  episode_count: 68 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.484, -10.347, -11.111]
Step 101 4 visits [1.0, 4.0, 1.0, 1.0, 91.0, 2.0, 1.0]  episode_count: 68 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.513, -10.347, -11.111]
Step 102 4 visits [1.0, 4.0, 1.0, 1.0, 92.0, 2.0, 1.0]  episode_count: 70 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.541, -10.347, -11.111]
Step 103 4 visits [1.0, 4.0, 1.0, 1.0, 93.0, 2.0, 1.0]  episode_count: 70 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.569, -10.347, -11.111]
Step 104 4 visits [1.0, 4.0, 1.0, 1.0, 94.0, 2.0, 1.0]  episode_count: 71 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.596, -10.347, -11.111]
{"total_number_of_episodes": 72, "number_of_timesteps": 6779, "per_episode_reward": -381.28, "episode_reward_trend_value": -5.473039783584698, "biggest_recent_change": NaN},
Step 105 4 visits [1.0, 4.0, 1.0, 1.0, 95.0, 2.0, 1.0]  episode_count: 72 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.622, -10.347, -11.111]
Step 106 4 visits [1.0, 4.0, 1.0, 1.0, 96.0, 2.0, 1.0]  episode_count: 72 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.648, -10.347, -11.111]
Step 107 4 visits [1.0, 4.0, 1.0, 1.0, 97.0, 2.0, 1.0]  episode_count: 72 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.674, -10.347, -11.111]
Step 108 4 visits [1.0, 4.0, 1.0, 1.0, 98.0, 2.0, 1.0]  episode_count: 73 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.699, -10.347, -11.111]
Step 109 4 visits [1.0, 4.0, 1.0, 1.0, 99.0, 2.0, 1.0]  episode_count: 73 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.723, -10.347, -11.111]
Step 110 4 visits [1.0, 4.0, 1.0, 1.0, 100.0, 2.0, 1.0]  episode_count: 74 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.747, -10.347, -11.111]
Step 111 4 visits [1.0, 4.0, 1.0, 1.0, 101.0, 2.0, 1.0]  episode_count: 77 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.77, -10.347, -11.111]
Step 112 4 visits [1.0, 4.0, 1.0, 1.0, 102.0, 2.0, 1.0]  episode_count: 77 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.793, -10.347, -11.111]
Step 113 4 visits [1.0, 4.0, 1.0, 1.0, 103.0, 2.0, 1.0]  episode_count: 79 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.816, -10.347, -11.111]
Step 114 4 visits [1.0, 4.0, 1.0, 1.0, 104.0, 2.0, 1.0]  episode_count: 79 q_vals: [-11.111, -9.699, -11.111, -11.111, -8.838, -10.347, -11.111]
Step 115 1 visits [1.0, 5.0, 1.0, 1.0, 104.0, 2.0, 1.0]  episode_count: 79 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.838, -10.347, -11.111]
Step 116 4 visits [1.0, 5.0, 1.0, 1.0, 105.0, 2.0, 1.0]  episode_count: 79 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.859, -10.347, -11.111]
Step 117 4 visits [1.0, 5.0, 1.0, 1.0, 106.0, 2.0, 1.0]  episode_count: 79 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.881, -10.347, -11.111]
Step 118 4 visits [1.0, 5.0, 1.0, 1.0, 107.0, 2.0, 1.0]  episode_count: 79 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.798, -10.347, -11.111]
Step 119 4 visits [1.0, 5.0, 1.0, 1.0, 108.0, 2.0, 1.0]  episode_count: 81 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.819, -10.347, -11.111]
{"total_number_of_episodes": 82, "number_of_timesteps": 7659, "per_episode_reward": -422.05, "episode_reward_trend_value": -5.193807714766214, "biggest_recent_change": NaN},
Step 120 4 visits [1.0, 5.0, 1.0, 1.0, 109.0, 2.0, 1.0]  episode_count: 82 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.84, -10.347, -11.111]
Step 121 4 visits [1.0, 5.0, 1.0, 1.0, 110.0, 2.0, 1.0]  episode_count: 84 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.861, -10.347, -11.111]
Step 122 4 visits [1.0, 5.0, 1.0, 1.0, 111.0, 2.0, 1.0]  episode_count: 84 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.838, -10.347, -11.111]
Step 123 4 visits [1.0, 5.0, 1.0, 1.0, 112.0, 2.0, 1.0]  episode_count: 86 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.858, -10.347, -11.111]
Step 124 4 visits [1.0, 5.0, 1.0, 1.0, 113.0, 2.0, 1.0]  episode_count: 86 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.878, -10.347, -11.111]
Step 125 4 visits [1.0, 5.0, 1.0, 1.0, 114.0, 2.0, 1.0]  episode_count: 86 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.8, -10.347, -11.111]
Step 126 4 visits [1.0, 5.0, 1.0, 1.0, 115.0, 2.0, 1.0]  episode_count: 86 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.821, -10.347, -11.111]
Step 127 4 visits [1.0, 5.0, 1.0, 1.0, 116.0, 2.0, 1.0]  episode_count: 86 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.84, -10.347, -11.111]
Step 128 4 visits [1.0, 5.0, 1.0, 1.0, 117.0, 2.0, 1.0]  episode_count: 86 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.86, -10.347, -11.111]
Step 129 4 visits [1.0, 5.0, 1.0, 1.0, 118.0, 2.0, 1.0]  episode_count: 87 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.879, -10.347, -11.111]
Step 130 4 visits [1.0, 5.0, 1.0, 1.0, 119.0, 2.0, 1.0]  episode_count: 89 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.804, -10.347, -11.111]
{"total_number_of_episodes": 92, "number_of_timesteps": 8605, "per_episode_reward": -465.39, "episode_reward_trend_value": -5.050621349603985, "biggest_recent_change": NaN},
Step 131 4 visits [1.0, 5.0, 1.0, 1.0, 120.0, 2.0, 1.0]  episode_count: 92 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.823, -10.347, -11.111]
Step 132 4 visits [1.0, 5.0, 1.0, 1.0, 121.0, 2.0, 1.0]  episode_count: 92 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.842, -10.347, -11.111]
Step 133 4 visits [1.0, 5.0, 1.0, 1.0, 122.0, 2.0, 1.0]  episode_count: 92 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.861, -10.347, -11.111]
Step 134 4 visits [1.0, 5.0, 1.0, 1.0, 123.0, 2.0, 1.0]  episode_count: 93 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.789, -10.347, -11.111]
Step 135 4 visits [1.0, 5.0, 1.0, 1.0, 124.0, 2.0, 1.0]  episode_count: 93 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.718, -10.347, -11.111]
Step 136 4 visits [1.0, 5.0, 1.0, 1.0, 125.0, 2.0, 1.0]  episode_count: 93 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.737, -10.347, -11.111]
Step 137 4 visits [1.0, 5.0, 1.0, 1.0, 126.0, 2.0, 1.0]  episode_count: 93 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.756, -10.347, -11.111]
Step 138 4 visits [1.0, 5.0, 1.0, 1.0, 127.0, 2.0, 1.0]  episode_count: 93 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.687, -10.347, -11.111]
Step 139 4 visits [1.0, 5.0, 1.0, 1.0, 128.0, 2.0, 1.0]  episode_count: 95 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.706, -10.347, -11.111]
Step 140 4 visits [1.0, 5.0, 1.0, 1.0, 129.0, 2.0, 1.0]  episode_count: 97 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.725, -10.347, -11.111]
Step 141 4 visits [1.0, 5.0, 1.0, 1.0, 130.0, 2.0, 1.0]  episode_count: 98 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.743, -10.347, -11.111]
Step 142 4 visits [1.0, 5.0, 1.0, 1.0, 131.0, 2.0, 1.0]  episode_count: 98 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.761, -10.347, -11.111]
Step 143 4 visits [1.0, 5.0, 1.0, 1.0, 132.0, 2.0, 1.0]  episode_count: 99 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.779, -10.347, -11.111]
Step 144 4 visits [1.0, 5.0, 1.0, 1.0, 133.0, 2.0, 1.0]  episode_count: 100 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.796, -10.347, -11.111]
Step 145 4 visits [1.0, 5.0, 1.0, 1.0, 134.0, 2.0, 1.0]  episode_count: 100 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.814, -10.347, -11.111]
Step 146 4 visits [1.0, 5.0, 1.0, 1.0, 135.0, 2.0, 1.0]  episode_count: 100 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.831, -10.347, -11.111]
Step 147 4 visits [1.0, 5.0, 1.0, 1.0, 136.0, 2.0, 1.0]  episode_count: 100 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.847, -10.347, -11.111]
Step 148 4 visits [1.0, 5.0, 1.0, 1.0, 137.0, 2.0, 1.0]  episode_count: 101 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.864, -10.347, -11.111]
{"total_number_of_episodes": 102, "number_of_timesteps": 9586, "per_episode_reward": -484.32, "episode_reward_trend_value": -4.599421327291147, "biggest_recent_change": NaN},
Step 149 4 visits [1.0, 5.0, 1.0, 1.0, 138.0, 2.0, 1.0]  episode_count: 102 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.88, -10.347, -11.111]
Step 150 4 visits [1.0, 5.0, 1.0, 1.0, 139.0, 2.0, 1.0]  episode_count: 102 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.896, -10.347, -11.111]
Step 151 4 visits [1.0, 5.0, 1.0, 1.0, 140.0, 2.0, 1.0]  episode_count: 102 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.833, -10.347, -11.111]
Step 152 4 visits [1.0, 5.0, 1.0, 1.0, 141.0, 2.0, 1.0]  episode_count: 104 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.849, -10.347, -11.111]
Step 153 4 visits [1.0, 5.0, 1.0, 1.0, 142.0, 2.0, 1.0]  episode_count: 105 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.787, -10.347, -11.111]
Step 154 4 visits [1.0, 5.0, 1.0, 1.0, 143.0, 2.0, 1.0]  episode_count: 105 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.803, -10.347, -11.111]
Step 155 4 visits [1.0, 5.0, 1.0, 1.0, 144.0, 2.0, 1.0]  episode_count: 106 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.819, -10.347, -11.111]
Step 156 4 visits [1.0, 5.0, 1.0, 1.0, 145.0, 2.0, 1.0]  episode_count: 107 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.835, -10.347, -11.111]
Step 157 4 visits [1.0, 5.0, 1.0, 1.0, 146.0, 2.0, 1.0]  episode_count: 107 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.85, -10.347, -11.111]
Step 158 4 visits [1.0, 5.0, 1.0, 1.0, 147.0, 2.0, 1.0]  episode_count: 108 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.79, -10.347, -11.111]
Step 159 4 visits [1.0, 5.0, 1.0, 1.0, 148.0, 2.0, 1.0]  episode_count: 108 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.806, -10.347, -11.111]
Step 160 4 visits [1.0, 5.0, 1.0, 1.0, 149.0, 2.0, 1.0]  episode_count: 108 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.821, -10.347, -11.111]
Step 161 4 visits [1.0, 5.0, 1.0, 1.0, 150.0, 2.0, 1.0]  episode_count: 108 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.837, -10.347, -11.111]
Step 162 4 visits [1.0, 5.0, 1.0, 1.0, 151.0, 2.0, 1.0]  episode_count: 109 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.852, -10.347, -11.111]
Step 163 4 visits [1.0, 5.0, 1.0, 1.0, 152.0, 2.0, 1.0]  episode_count: 110 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.866, -10.347, -11.111]
Step 164 4 visits [1.0, 5.0, 1.0, 1.0, 153.0, 2.0, 1.0]  episode_count: 111 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.881, -10.347, -11.111]
Step 165 4 visits [1.0, 5.0, 1.0, 1.0, 154.0, 2.0, 1.0]  episode_count: 111 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.896, -10.347, -11.111]
{"total_number_of_episodes": 112, "number_of_timesteps": 10705, "per_episode_reward": -519.78, "episode_reward_trend_value": -4.4677639797322195, "biggest_recent_change": NaN},
Step 166 4 visits [1.0, 5.0, 1.0, 1.0, 155.0, 2.0, 1.0]  episode_count: 112 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.91, -10.347, -11.111]
Step 167 4 visits [1.0, 5.0, 1.0, 1.0, 156.0, 2.0, 1.0]  episode_count: 112 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.924, -10.347, -11.111]
Step 168 4 visits [1.0, 5.0, 1.0, 1.0, 157.0, 2.0, 1.0]  episode_count: 112 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.938, -10.347, -11.111]
Step 169 5 visits [1.0, 5.0, 1.0, 1.0, 157.0, 3.0, 1.0]  episode_count: 114 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.938, -10.602, -11.111]
Step 170 4 visits [1.0, 5.0, 1.0, 1.0, 158.0, 3.0, 1.0]  episode_count: 114 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.952, -10.602, -11.111]
Step 171 4 visits [1.0, 5.0, 1.0, 1.0, 159.0, 3.0, 1.0]  episode_count: 115 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.965, -10.602, -11.111]
Step 172 4 visits [1.0, 5.0, 1.0, 1.0, 160.0, 3.0, 1.0]  episode_count: 115 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.979, -10.602, -11.111]
Step 173 4 visits [1.0, 5.0, 1.0, 1.0, 161.0, 3.0, 1.0]  episode_count: 116 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.992, -10.602, -11.111]
Step 174 4 visits [1.0, 5.0, 1.0, 1.0, 162.0, 3.0, 1.0]  episode_count: 116 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.936, -10.602, -11.111]
Step 175 4 visits [1.0, 5.0, 1.0, 1.0, 163.0, 3.0, 1.0]  episode_count: 116 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.882, -10.602, -11.111]
Step 176 4 visits [1.0, 5.0, 1.0, 1.0, 164.0, 3.0, 1.0]  episode_count: 117 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.895, -10.602, -11.111]
Step 177 4 visits [1.0, 5.0, 1.0, 1.0, 165.0, 3.0, 1.0]  episode_count: 119 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.909, -10.602, -11.111]
Step 178 4 visits [1.0, 5.0, 1.0, 1.0, 166.0, 3.0, 1.0]  episode_count: 120 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.922, -10.602, -11.111]
Step 179 4 visits [1.0, 5.0, 1.0, 1.0, 167.0, 3.0, 1.0]  episode_count: 121 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.935, -10.602, -11.111]
{"total_number_of_episodes": 122, "number_of_timesteps": 11840, "per_episode_reward": -552.03, "episode_reward_trend_value": -4.329643744380926, "biggest_recent_change": 74.6267920381965},
Step 180 4 visits [1.0, 5.0, 1.0, 1.0, 168.0, 3.0, 1.0]  episode_count: 122 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.948, -10.602, -11.111]
Step 181 4 visits [1.0, 5.0, 1.0, 1.0, 169.0, 3.0, 1.0]  episode_count: 122 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.961, -10.602, -11.111]
Step 182 4 visits [1.0, 5.0, 1.0, 1.0, 170.0, 3.0, 1.0]  episode_count: 123 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.973, -10.602, -11.111]
Step 183 4 visits [1.0, 5.0, 1.0, 1.0, 171.0, 3.0, 1.0]  episode_count: 124 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.986, -10.602, -11.111]
Step 184 4 visits [1.0, 5.0, 1.0, 1.0, 172.0, 3.0, 1.0]  episode_count: 124 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.998, -10.602, -11.111]
Step 185 4 visits [1.0, 5.0, 1.0, 1.0, 173.0, 3.0, 1.0]  episode_count: 124 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.01, -10.602, -11.111]
Step 186 0 visits [2.0, 5.0, 1.0, 1.0, 173.0, 3.0, 1.0]  episode_count: 125 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.01, -10.602, -11.111]
Step 187 2 visits [2.0, 5.0, 2.0, 1.0, 173.0, 3.0, 1.0]  episode_count: 125 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.01, -10.602, -11.111]
Step 188 3 visits [2.0, 5.0, 2.0, 2.0, 173.0, 3.0, 1.0]  episode_count: 126 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.01, -10.602, -11.111]
Step 189 6 visits [2.0, 5.0, 2.0, 2.0, 173.0, 3.0, 2.0]  episode_count: 126 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.01, -10.602, -11.111]
Step 190 4 visits [2.0, 5.0, 2.0, 2.0, 174.0, 3.0, 2.0]  episode_count: 126 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.959, -10.602, -11.111]
Step 191 4 visits [2.0, 5.0, 2.0, 2.0, 175.0, 3.0, 2.0]  episode_count: 126 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.971, -10.602, -11.111]
Step 192 4 visits [2.0, 5.0, 2.0, 2.0, 176.0, 3.0, 2.0]  episode_count: 126 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.983, -10.602, -11.111]
Step 193 4 visits [2.0, 5.0, 2.0, 2.0, 177.0, 3.0, 2.0]  episode_count: 127 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.932, -10.602, -11.111]
Step 194 4 visits [2.0, 5.0, 2.0, 2.0, 178.0, 3.0, 2.0]  episode_count: 128 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.945, -10.602, -11.111]
Step 195 4 visits [2.0, 5.0, 2.0, 2.0, 179.0, 3.0, 2.0]  episode_count: 128 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.957, -10.602, -11.111]
Step 196 4 visits [2.0, 5.0, 2.0, 2.0, 180.0, 3.0, 2.0]  episode_count: 130 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.969, -10.602, -11.111]
Step 197 4 visits [2.0, 5.0, 2.0, 2.0, 181.0, 3.0, 2.0]  episode_count: 131 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.981, -10.602, -11.111]
{"total_number_of_episodes": 133, "number_of_timesteps": 13133, "per_episode_reward": -562.44, "episode_reward_trend_value": -4.169434284352766, "biggest_recent_change": 74.6267920381965},
Step 198 4 visits [2.0, 5.0, 2.0, 2.0, 182.0, 3.0, 2.0]  episode_count: 133 q_vals: [-11.111, -9.981, -11.111, -11.111, -8.992, -10.602, -11.111]
Step 199 4 visits [2.0, 5.0, 2.0, 2.0, 183.0, 3.0, 2.0]  episode_count: 133 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.004, -10.602, -11.111]
Step 200 4 visits [2.0, 5.0, 2.0, 2.0, 184.0, 3.0, 2.0]  episode_count: 133 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.015, -10.602, -11.111]
Step 201 4 visits [2.0, 5.0, 2.0, 2.0, 185.0, 3.0, 2.0]  episode_count: 133 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.027, -10.602, -11.111]
Step 202 4 visits [2.0, 5.0, 2.0, 2.0, 186.0, 3.0, 2.0]  episode_count: 134 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.038, -10.602, -11.111]
Step 203 4 visits [2.0, 5.0, 2.0, 2.0, 187.0, 3.0, 2.0]  episode_count: 135 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.049, -10.602, -11.111]
Step 204 4 visits [2.0, 5.0, 2.0, 2.0, 188.0, 3.0, 2.0]  episode_count: 136 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.06, -10.602, -11.111]
Step 205 4 visits [2.0, 5.0, 2.0, 2.0, 189.0, 3.0, 2.0]  episode_count: 138 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.012, -10.602, -11.111]
Step 206 4 visits [2.0, 5.0, 2.0, 2.0, 190.0, 3.0, 2.0]  episode_count: 140 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.023, -10.602, -11.111]
Step 207 4 visits [2.0, 5.0, 2.0, 2.0, 191.0, 3.0, 2.0]  episode_count: 140 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.034, -10.602, -11.111]
Step 208 4 visits [2.0, 5.0, 2.0, 2.0, 192.0, 3.0, 2.0]  episode_count: 140 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.045, -10.602, -11.111]
Step 209 4 visits [2.0, 5.0, 2.0, 2.0, 193.0, 3.0, 2.0]  episode_count: 140 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.055, -10.602, -11.111]
Step 210 4 visits [2.0, 5.0, 2.0, 2.0, 194.0, 3.0, 2.0]  episode_count: 141 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.009, -10.602, -11.111]
Step 211 4 visits [2.0, 5.0, 2.0, 2.0, 195.0, 3.0, 2.0]  episode_count: 141 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.02, -10.602, -11.111]
Step 212 4 visits [2.0, 5.0, 2.0, 2.0, 196.0, 3.0, 2.0]  episode_count: 141 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.03, -10.602, -11.111]
{"total_number_of_episodes": 145, "number_of_timesteps": 14086, "per_episode_reward": -560.4, "episode_reward_trend_value": -3.3175294291843187, "biggest_recent_change": 67.73535028594256},
Step 213 4 visits [2.0, 5.0, 2.0, 2.0, 197.0, 3.0, 2.0]  episode_count: 145 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.041, -10.602, -11.111]
Step 214 4 visits [2.0, 5.0, 2.0, 2.0, 198.0, 3.0, 2.0]  episode_count: 146 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.051, -10.602, -11.111]
Step 215 4 visits [2.0, 5.0, 2.0, 2.0, 199.0, 3.0, 2.0]  episode_count: 146 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.062, -10.602, -11.111]
Step 216 4 visits [2.0, 5.0, 2.0, 2.0, 200.0, 3.0, 2.0]  episode_count: 147 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.072, -10.602, -11.111]
Step 217 4 visits [2.0, 5.0, 2.0, 2.0, 201.0, 3.0, 2.0]  episode_count: 148 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.082, -10.602, -11.111]
Step 218 4 visits [2.0, 5.0, 2.0, 2.0, 202.0, 3.0, 2.0]  episode_count: 148 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.092, -10.602, -11.111]
Step 219 4 visits [2.0, 5.0, 2.0, 2.0, 203.0, 3.0, 2.0]  episode_count: 148 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.102, -10.602, -11.111]
Step 220 4 visits [2.0, 5.0, 2.0, 2.0, 204.0, 3.0, 2.0]  episode_count: 150 q_vals: [-11.111, -9.981, -11.111, -11.111, -9.112, -10.602, -11.111]
Step 221 1 visits [2.0, 6.0, 2.0, 2.0, 204.0, 3.0, 2.0]  episode_count: 150 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.112, -10.602, -11.111]
Step 222 4 visits [2.0, 6.0, 2.0, 2.0, 205.0, 3.0, 2.0]  episode_count: 151 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.122, -10.602, -11.111]
Step 223 4 visits [2.0, 6.0, 2.0, 2.0, 206.0, 3.0, 2.0]  episode_count: 152 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.077, -10.602, -11.111]
Step 224 4 visits [2.0, 6.0, 2.0, 2.0, 207.0, 3.0, 2.0]  episode_count: 152 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.087, -10.602, -11.111]
Step 225 4 visits [2.0, 6.0, 2.0, 2.0, 208.0, 3.0, 2.0]  episode_count: 153 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.097, -10.602, -11.111]
Step 226 4 visits [2.0, 6.0, 2.0, 2.0, 209.0, 3.0, 2.0]  episode_count: 153 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.106, -10.602, -11.111]
Step 227 4 visits [2.0, 6.0, 2.0, 2.0, 210.0, 3.0, 2.0]  episode_count: 154 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.116, -10.602, -11.111]
Step 228 4 visits [2.0, 6.0, 2.0, 2.0, 211.0, 3.0, 2.0]  episode_count: 154 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.125, -10.602, -11.111]
{"total_number_of_episodes": 155, "number_of_timesteps": 14948, "per_episode_reward": -566.89, "episode_reward_trend_value": -2.6370323497539787, "biggest_recent_change": 51.72115814190494},
Step 229 4 visits [2.0, 6.0, 2.0, 2.0, 212.0, 3.0, 2.0]  episode_count: 155 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.135, -10.602, -11.111]
Step 230 4 visits [2.0, 6.0, 2.0, 2.0, 213.0, 3.0, 2.0]  episode_count: 156 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.144, -10.602, -11.111]
Step 231 4 visits [2.0, 6.0, 2.0, 2.0, 214.0, 3.0, 2.0]  episode_count: 158 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.153, -10.602, -11.111]
Step 232 4 visits [2.0, 6.0, 2.0, 2.0, 215.0, 3.0, 2.0]  episode_count: 158 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.111, -10.602, -11.111]
Step 233 4 visits [2.0, 6.0, 2.0, 2.0, 216.0, 3.0, 2.0]  episode_count: 159 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.069, -10.602, -11.111]
Step 234 4 visits [2.0, 6.0, 2.0, 2.0, 217.0, 3.0, 2.0]  episode_count: 159 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.078, -10.602, -11.111]
Step 235 4 visits [2.0, 6.0, 2.0, 2.0, 218.0, 3.0, 2.0]  episode_count: 161 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.036, -10.602, -11.111]
Step 236 4 visits [2.0, 6.0, 2.0, 2.0, 219.0, 3.0, 2.0]  episode_count: 162 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.046, -10.602, -11.111]
Step 237 4 visits [2.0, 6.0, 2.0, 2.0, 220.0, 3.0, 2.0]  episode_count: 162 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.005, -10.602, -11.111]
Step 238 4 visits [2.0, 6.0, 2.0, 2.0, 221.0, 3.0, 2.0]  episode_count: 163 q_vals: [-11.111, -10.169, -11.111, -11.111, -8.964, -10.602, -11.111]
Step 239 4 visits [2.0, 6.0, 2.0, 2.0, 222.0, 3.0, 2.0]  episode_count: 164 q_vals: [-11.111, -10.169, -11.111, -11.111, -8.974, -10.602, -11.111]
{"total_number_of_episodes": 165, "number_of_timesteps": 15849, "per_episode_reward": -574.78, "episode_reward_trend_value": -2.150008543153827, "biggest_recent_change": 43.346895237928436},
Step 240 4 visits [2.0, 6.0, 2.0, 2.0, 223.0, 3.0, 2.0]  episode_count: 165 q_vals: [-11.111, -10.169, -11.111, -11.111, -8.983, -10.602, -11.111]
Step 241 4 visits [2.0, 6.0, 2.0, 2.0, 224.0, 3.0, 2.0]  episode_count: 165 q_vals: [-11.111, -10.169, -11.111, -11.111, -8.993, -10.602, -11.111]
Step 242 4 visits [2.0, 6.0, 2.0, 2.0, 225.0, 3.0, 2.0]  episode_count: 166 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.002, -10.602, -11.111]
Step 243 4 visits [2.0, 6.0, 2.0, 2.0, 226.0, 3.0, 2.0]  episode_count: 167 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.011, -10.602, -11.111]
Step 244 4 visits [2.0, 6.0, 2.0, 2.0, 227.0, 3.0, 2.0]  episode_count: 167 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.021, -10.602, -11.111]
Step 245 4 visits [2.0, 6.0, 2.0, 2.0, 228.0, 3.0, 2.0]  episode_count: 168 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.03, -10.602, -11.111]
Step 246 4 visits [2.0, 6.0, 2.0, 2.0, 229.0, 3.0, 2.0]  episode_count: 168 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.039, -10.602, -11.111]
Step 247 4 visits [2.0, 6.0, 2.0, 2.0, 230.0, 3.0, 2.0]  episode_count: 169 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.048, -10.602, -11.111]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
Step 248 4 visits [2.0, 6.0, 2.0, 2.0, 231.0, 3.0, 2.0]  episode_count: 170 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.057, -10.602, -11.111]
Step 249 4 visits [2.0, 6.0, 2.0, 2.0, 232.0, 3.0, 2.0]  episode_count: 171 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.066, -10.602, -11.111]
Step 250 4 visits [2.0, 6.0, 2.0, 2.0, 233.0, 3.0, 2.0]  episode_count: 171 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.075, -10.602, -11.111]
Step 251 4 visits [2.0, 6.0, 2.0, 2.0, 234.0, 3.0, 2.0]  episode_count: 173 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.083, -10.602, -11.111]
Step 252 4 visits [2.0, 6.0, 2.0, 2.0, 235.0, 3.0, 2.0]  episode_count: 174 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.092, -10.602, -11.111]
Step 253 4 visits [2.0, 6.0, 2.0, 2.0, 236.0, 3.0, 2.0]  episode_count: 174 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.1, -10.602, -11.111]
Step 254 4 visits [2.0, 6.0, 2.0, 2.0, 237.0, 3.0, 2.0]  episode_count: 174 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.109, -10.602, -11.111]
Step 255 4 visits [2.0, 6.0, 2.0, 2.0, 238.0, 3.0, 2.0]  episode_count: 174 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.071, -10.602, -11.111]
Step 256 4 visits [2.0, 6.0, 2.0, 2.0, 239.0, 3.0, 2.0]  episode_count: 174 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.079, -10.602, -11.111]
{"total_number_of_episodes": 175, "number_of_timesteps": 16773, "per_episode_reward": -581.35, "episode_reward_trend_value": -1.770048111307473, "biggest_recent_change": 43.346895237928436},
Step 257 4 visits [2.0, 6.0, 2.0, 2.0, 240.0, 3.0, 2.0]  episode_count: 175 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.088, -10.602, -11.111]
Step 258 4 visits [2.0, 6.0, 2.0, 2.0, 241.0, 3.0, 2.0]  episode_count: 176 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.05, -10.602, -11.111]
Step 259 4 visits [2.0, 6.0, 2.0, 2.0, 242.0, 3.0, 2.0]  episode_count: 177 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.058, -10.602, -11.111]
Step 260 4 visits [2.0, 6.0, 2.0, 2.0, 243.0, 3.0, 2.0]  episode_count: 178 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.067, -10.602, -11.111]
Step 261 4 visits [2.0, 6.0, 2.0, 2.0, 244.0, 3.0, 2.0]  episode_count: 180 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.03, -10.602, -11.111]
Step 262 4 visits [2.0, 6.0, 2.0, 2.0, 245.0, 3.0, 2.0]  episode_count: 180 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.038, -10.602, -11.111]
Step 263 4 visits [2.0, 6.0, 2.0, 2.0, 246.0, 3.0, 2.0]  episode_count: 180 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.047, -10.602, -11.111]
Step 264 4 visits [2.0, 6.0, 2.0, 2.0, 247.0, 3.0, 2.0]  episode_count: 180 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.055, -10.602, -11.111]
Step 265 4 visits [2.0, 6.0, 2.0, 2.0, 248.0, 3.0, 2.0]  episode_count: 181 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.063, -10.602, -11.111]
Step 266 4 visits [2.0, 6.0, 2.0, 2.0, 249.0, 3.0, 2.0]  episode_count: 182 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.072, -10.602, -11.111]
Step 267 4 visits [2.0, 6.0, 2.0, 2.0, 250.0, 3.0, 2.0]  episode_count: 182 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.08, -10.602, -11.111]
Step 268 4 visits [2.0, 6.0, 2.0, 2.0, 251.0, 3.0, 2.0]  episode_count: 182 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.088, -10.602, -11.111]
Step 269 4 visits [2.0, 6.0, 2.0, 2.0, 252.0, 3.0, 2.0]  episode_count: 183 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.096, -10.602, -11.111]
{"total_number_of_episodes": 185, "number_of_timesteps": 17816, "per_episode_reward": -584.52, "episode_reward_trend_value": -1.323642135676483, "biggest_recent_change": 35.46162546819727},
Step 270 4 visits [2.0, 6.0, 2.0, 2.0, 253.0, 3.0, 2.0]  episode_count: 185 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.104, -10.602, -11.111]
Step 271 4 visits [2.0, 6.0, 2.0, 2.0, 254.0, 3.0, 2.0]  episode_count: 186 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.112, -10.602, -11.111]
Step 272 4 visits [2.0, 6.0, 2.0, 2.0, 255.0, 3.0, 2.0]  episode_count: 186 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.12, -10.602, -11.111]
Step 273 4 visits [2.0, 6.0, 2.0, 2.0, 256.0, 3.0, 2.0]  episode_count: 188 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.127, -10.602, -11.111]
Step 274 4 visits [2.0, 6.0, 2.0, 2.0, 257.0, 3.0, 2.0]  episode_count: 189 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.135, -10.602, -11.111]
Step 275 4 visits [2.0, 6.0, 2.0, 2.0, 258.0, 3.0, 2.0]  episode_count: 189 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.143, -10.602, -11.111]
Step 276 4 visits [2.0, 6.0, 2.0, 2.0, 259.0, 3.0, 2.0]  episode_count: 192 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.15, -10.602, -11.111]
Step 277 4 visits [2.0, 6.0, 2.0, 2.0, 260.0, 3.0, 2.0]  episode_count: 192 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.115, -10.602, -11.111]
Step 278 4 visits [2.0, 6.0, 2.0, 2.0, 261.0, 3.0, 2.0]  episode_count: 192 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.123, -10.602, -11.111]
Step 279 4 visits [2.0, 6.0, 2.0, 2.0, 262.0, 3.0, 2.0]  episode_count: 194 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.13, -10.602, -11.111]
{"total_number_of_episodes": 195, "number_of_timesteps": 18586, "per_episode_reward": -578.79, "episode_reward_trend_value": -1.0497056121692943, "biggest_recent_change": 35.46162546819727},
Step 280 4 visits [2.0, 6.0, 2.0, 2.0, 263.0, 3.0, 2.0]  episode_count: 195 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.138, -10.602, -11.111]
Step 281 4 visits [2.0, 6.0, 2.0, 2.0, 264.0, 3.0, 2.0]  episode_count: 195 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.103, -10.602, -11.111]
Step 282 4 visits [2.0, 6.0, 2.0, 2.0, 265.0, 3.0, 2.0]  episode_count: 195 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.111, -10.602, -11.111]
Step 283 4 visits [2.0, 6.0, 2.0, 2.0, 266.0, 3.0, 2.0]  episode_count: 196 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.118, -10.602, -11.111]
Step 284 4 visits [2.0, 6.0, 2.0, 2.0, 267.0, 3.0, 2.0]  episode_count: 196 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.126, -10.602, -11.111]
Step 285 4 visits [2.0, 6.0, 2.0, 2.0, 268.0, 3.0, 2.0]  episode_count: 197 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.133, -10.602, -11.111]
Step 286 4 visits [2.0, 6.0, 2.0, 2.0, 269.0, 3.0, 2.0]  episode_count: 199 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.141, -10.602, -11.111]
Step 287 4 visits [starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[2.0, 6.0, 2.0, 2.0, 270.0, 3.0, 2.0]  episode_count: 199 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.148, -10.602, -11.111]
Step 288 4 visits [2.0, 6.0, 2.0, 2.0, 271.0, 3.0, 2.0]  episode_count: 199 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.155, -10.602, -11.111]
Step 289 4 visits [2.0, 6.0, 2.0, 2.0, 272.0, 3.0, 2.0]  episode_count: 200 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.162, -10.602, -11.111]
Step 290 4 visits [2.0, 6.0, 2.0, 2.0, 273.0, 3.0, 2.0]  episode_count: 201 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.129, -10.602, -11.111]
Step 291 4 visits [2.0, 6.0, 2.0, 2.0, 274.0, 3.0, 2.0]  episode_count: 201 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.136, -10.602, -11.111]
Step 292 4 visits [2.0, 6.0, 2.0, 2.0, 275.0, 3.0, 2.0]  episode_count: 201 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.143, -10.602, -11.111]
Step 293 4 visits [2.0, 6.0, 2.0, 2.0, 276.0, 3.0, 2.0]  episode_count: 202 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.15, -10.602, -11.111]
Step 294 4 visits [2.0, 6.0, 2.0, 2.0, 277.0, 3.0, 2.0]  episode_count: 202 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.157, -10.602, -11.111]
Step 295 4 visits [2.0, 6.0, 2.0, 2.0, 278.0, 3.0, 2.0]  episode_count: 204 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.124, -10.602, -11.111]
{"total_number_of_episodes": 205, "number_of_timesteps": 19553, "per_episode_reward": -582.45, "episode_reward_trend_value": -0.6963854082844553, "biggest_recent_change": 32.246818615705706},
Step 296 4 visits [2.0, 6.0, 2.0, 2.0, 279.0, 3.0, 2.0]  episode_count: 205 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.132, -10.602, -11.111]
Step 297 4 visits [2.0, 6.0, 2.0, 2.0, 280.0, 3.0, 2.0]  episode_count: 205 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.139, -10.602, -11.111]
Step 298 4 visits [2.0, 6.0, 2.0, 2.0, 281.0, 3.0, 2.0]  episode_count: 207 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.146, -10.602, -11.111]
Step 299 4 visits [2.0, 6.0, 2.0, 2.0, 282.0, 3.0, 2.0]  episode_count: 207 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.153, -10.602, -11.111]
Step 300 4 visits [2.0, 6.0, 2.0, 2.0, 283.0, 3.0, 2.0]  episode_count: 207 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.12, -10.602, -11.111]
Step 301 4 visits [2.0, 6.0, 2.0, 2.0, 284.0, 3.0, 2.0]  episode_count: 207 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.127, -10.602, -11.111]
Step 302 4 visits [2.0, 6.0, 2.0, 2.0, 285.0, 3.0, 2.0]  episode_count: 208 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.134, -10.602, -11.111]
Step 303 4 visits [2.0, 6.0, 2.0, 2.0, 286.0, 3.0, 2.0]  episode_count: 209 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.141, -10.602, -11.111]
Step 304 4 visits [2.0, 6.0, 2.0, 2.0, 287.0, 3.0, 2.0]  episode_count: 210 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.148, -10.602, -11.111]
Step 305 4 visits [2.0, 6.0, 2.0, 2.0, 288.0, 3.0, 2.0]  episode_count: 211 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.116, -10.602, -11.111]
Step 306 4 visits [2.0, 6.0, 2.0, 2.0, 289.0, 3.0, 2.0]  episode_count: 212 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.123, -10.602, -11.111]
Step 307 4 visits [2.0, 6.0, 2.0, 2.0, 290.0, 3.0, 2.0]  episode_count: 212 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.092, -10.602, -11.111]
Step 308 4 visits [2.0, 6.0, 2.0, 2.0, 291.0, 3.0, 2.0]  episode_count: 214 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.099, -10.602, -11.111]
Step 309 4 visits [2.0, 6.0, 2.0, 2.0, 292.0, 3.0, 2.0]  episode_count: 214 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.067, -10.602, -11.111]
Step 310 4 visits [2.0, 6.0, 2.0, 2.0, 293.0, 3.0, 2.0]  episode_count: 214 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.074, -10.602, -11.111]
{"total_number_of_episodes": 215, "number_of_timesteps": 20544, "per_episode_reward": -583.25, "episode_reward_trend_value": -0.34697446300009716, "biggest_recent_change": 10.419439474809565},
Step 311 4 visits [2.0, 6.0, 2.0, 2.0, 294.0, 3.0, 2.0]  episode_count: 215 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.081, -10.602, -11.111]
Step 312 4 visits [2.0, 6.0, 2.0, 2.0, 295.0, 3.0, 2.0]  episode_count: 216 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.088, -10.602, -11.111]
Step 313 4 visits [2.0, 6.0, 2.0, 2.0, 296.0, 3.0, 2.0]  episode_count: 216 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.095, -10.602, -11.111]
Step 314 4 visits [2.0, 6.0, 2.0, 2.0, 297.0, 3.0, 2.0]  episode_count: 216 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.102, -10.602, -11.111]
Step 315 4 visits [2.0, 6.0, 2.0, 2.0, 298.0, 3.0, 2.0]  episode_count: 216 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.109, -10.602, -11.111]
Step 316 4 visits [2.0, 6.0, 2.0, 2.0, 299.0, 3.0, 2.0]  episode_count: 217 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.115, -10.602, -11.111]
Step 317 4 visits [2.0, 6.0, 2.0, 2.0, 300.0, 3.0, 2.0]  episode_count: 217 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.085, -10.602, -11.111]
Step 318 4 visits [2.0, 6.0, 2.0, 2.0, 301.0, 3.0, 2.0]  episode_count: 217 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.092, -10.602, -11.111]
Step 319 4 visits [2.0, 6.0, 2.0, 2.0, 302.0, 3.0, 2.0]  episode_count: 218 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.062, -10.602, -11.111]
Step 320 4 visits [2.0, 6.0, 2.0, 2.0, 303.0, 3.0, 2.0]  episode_count: 219 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.068, -10.602, -11.111]
Step 321 4 visits [2.0, 6.0, 2.0, 2.0, 304.0, 3.0, 2.0]  episode_count: 220 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.075, -10.602, -11.111]
Step 322 4 visits [2.0, 6.0, 2.0, 2.0, 305.0, 3.0, 2.0]  episode_count: 222 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.082, -10.602, -11.111]
Step 323 4 visits [2.0, 6.0, 2.0, 2.0, 306.0, 3.0, 2.0]  episode_count: 222 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.088, -10.602, -11.111]
Step 324 4 visits [2.0, 6.0, 2.0, 2.0, 307.0, 3.0, 2.0]  episode_count: 222 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.059, -10.602, -11.111]
Step 325 4 visits [2.0, 6.0, 2.0, 2.0, 308.0, 3.0, 2.0]  episode_count: 222 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.065, -10.602, -11.111]
Step 326 4 visits [2.0, 6.0, 2.0, 2.0, 309.0, 3.0, 2.0]  episode_count: 223 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.072, -10.602, -11.111]
Step 327 4 visits [2.0, 6.0, 2.0, 2.0, 310.0, 3.0, 2.0]  episode_count: 224 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.043, -10.602, -11.111]
{"total_number_of_episodes": 226, "number_of_timesteps": 21782, "per_episode_reward": -586.01, "episode_reward_trend_value": -0.261873894642555, "biggest_recent_change": 7.88901554789129},
Step 328 4 visits [2.0, 6.0, 2.0, 2.0, 311.0, 3.0, 2.0]  episode_count: 226 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.049, -10.602, -11.111]
Step 329 4 visits [2.0, 6.0, 2.0, 2.0, 312.0, 3.0, 2.0]  episode_count: 227 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.056, -10.602, -11.111]
Step 330 4 visits [2.0, 6.0, 2.0, 2.0, 313.0, 3.0, 2.0]  episode_count: 228 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.063, -10.602, -11.111]
Step 331 4 visits [2.0, 6.0, 2.0, 2.0, 314.0, 3.0, 2.0]  episode_count: 228 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.069, -10.602, -11.111]
Step 332 4 visits [2.0, 6.0, 2.0, 2.0, 315.0, 3.0, 2.0]  episode_count: 228 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.076, -10.602, -11.111]
Step 333 4 visits [2.0, 6.0, 2.0, 2.0, 316.0, 3.0, 2.0]  episode_count: 229 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.082, -10.602, -11.111]
Step 334 4 visits [2.0, 6.0, 2.0, 2.0, 317.0, 3.0, 2.0]  episode_count: 230 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.088, -10.602, -11.111]
Step 335 4 visits [2.0, 6.0, 2.0, 2.0, 318.0, 3.0, 2.0]  episode_count: 230 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.095, -10.602, -11.111]
Step 336 4 visits [2.0, 6.0, 2.0, 2.0, 319.0, 3.0, 2.0]  episode_count: 233 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.101, -10.602, -11.111]
Step 337 4 visits [2.0, 6.0, 2.0, 2.0, 320.0, 3.0, 2.0]  episode_count: 233 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.107, -10.602, -11.111]
Step 338 4 visits [2.0, 6.0, 2.0, 2.0, 321.0, 3.0, 2.0]  episode_count: 234 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.079, -10.602, -11.111]
Step 339 4 visits [2.0, 6.0, 2.0, 2.0, 322.0, 3.0, 2.0]  episode_count: 234 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.085, -10.602, -11.111]
Step 340 4 visits [2.0, 6.0, 2.0, 2.0, 323.0, 3.0, 2.0]  episode_count: 235 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.092, -10.602, -11.111]
Step 341 4 visits [2.0, 6.0, 2.0, 2.0, 324.0, 3.0, 2.0]  episode_count: 235 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.098, -10.602, -11.111]
{"total_number_of_episodes": 236, "number_of_timesteps": 22628, "per_episode_reward": -582.49, "episode_reward_trend_value": -0.24544518745259816, "biggest_recent_change": 7.88901554789129},
Step 342 4 visits [2.0, 6.0, 2.0, 2.0, 325.0, 3.0, 2.0]  episode_count: 236 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.104, -10.602, -11.111]
Step 343 4 visits [2.0, 6.0, 2.0, 2.0, 326.0, 3.0, 2.0]  episode_count: 236 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.11, -10.602, -11.111]
Step 344 4 visits [2.0, 6.0, 2.0, 2.0, 327.0, 3.0, 2.0]  episode_count: 239 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.116, -10.602, -11.111]
Step 345 4 visits [2.0, 6.0, 2.0, 2.0, 328.0, 3.0, 2.0]  episode_count: 239 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.089, -10.602, -11.111]
Step 346 4 visits [2.0, 6.0, 2.0, 2.0, 329.0, 3.0, 2.0]  episode_count: 239 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.095, -10.602, -11.111]
Step 347 4 visits [2.0, 6.0, 2.0, 2.0, 330.0, 3.0, 2.0]  episode_count: 240 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.101, -10.602, -11.111]
Step 348 4 visits [2.0, 6.0, 2.0, 2.0, 331.0, 3.0, 2.0]  episode_count: 240 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.107, -10.602, -11.111]
Step 349 4 visits [2.0, 6.0, 2.0, 2.0, 332.0, 3.0, 2.0]  episode_count: 240 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.113, -10.602, -11.111]
Step 350 4 visits [2.0, 6.0, 2.0, 2.0, 333.0, 3.0, 2.0]  episode_count: 240 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.119, -10.602, -11.111]
Step 351 4 visits [2.0, 6.0, 2.0, 2.0, 334.0, 3.0, 2.0]  episode_count: 241 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.125, -10.602, -11.111]
Step 352 4 visits [2.0, 6.0, 2.0, 2.0, 335.0, 3.0, 2.0]  episode_count: 245 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.131, -10.602, -11.111]
Step 353 4 visits [2.0, 6.0, 2.0, 2.0, 336.0, 3.0, 2.0]  episode_count: 245 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.137, -10.602, -11.111]
Step 354 4 visits [2.0, 6.0, 2.0, 2.0, 337.0, 3.0, 2.0]  episode_count: 245 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.143, -10.602, -11.111]
Step 355 4 visits [2.0, 6.0, 2.0, 2.0, 338.0, 3.0, 2.0]  episode_count: 245 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.148, -10.602, -11.111]
{"total_number_of_episodes": 246, "number_of_timesteps": 23593, "per_episode_reward": -586.17, "episode_reward_trend_value": -0.2142056742407615, "biggest_recent_change": 7.88901554789129},
Step 356 4 visits [2.0, 6.0, 2.0, 2.0, 339.0, 3.0, 2.0]  episode_count: 246 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.154, -10.602, -11.111]
Step 357 4 visits [2.0, 6.0, 2.0, 2.0, 340.0, 3.0, 2.0]  episode_count: 246 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.127, -10.602, -11.111]
Step 358 4 visits [2.0, 6.0, 2.0, 2.0, 341.0, 3.0, 2.0]  episode_count: 247 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.1, -10.602, -11.111]
Step 359 4 visits [2.0, 6.0, 2.0, 2.0, 342.0, 3.0, 2.0]  episode_count: 247 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.106, -10.602, -11.111]
Step 360 4 visits [2.0, 6.0, 2.0, 2.0, 343.0, 3.0, 2.0]  episode_count: 248 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.112, -10.602, -11.111]
Step 361 4 visits [2.0, 6.0, 2.0, 2.0, 344.0, 3.0, 2.0]  episode_count: 248 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.086, -10.602, -11.111]
Step 362 4 visits [2.0, 6.0, 2.0, 2.0, 345.0, 3.0, 2.0]  episode_count: 248 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.092, -10.602, -11.111]
Step 363 4 visits [2.0, 6.0, 2.0, 2.0, 346.0, 3.0, 2.0]  episode_count: 251 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.097, -10.602, -11.111]
Step 364 4 visits [2.0, 6.0, 2.0, 2.0, 347.0, 3.0, 2.0]  episode_count: 251 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.103, -10.602, -11.111]
Step 365 4 visits [2.0, 6.0, 2.0, 2.0, 348.0, 3.0, 2.0]  episode_count: 251 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.109, -10.602, -11.111]
Step 366 4 visits [2.0, 6.0, 2.0, 2.0, 349.0, 3.0, 2.0]  episode_count: 252 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.115, -10.602, -11.111]
Step 367 4 visits [2.0, 6.0, 2.0, 2.0, 350.0, 3.0, 2.0]  episode_count: 253 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.12, -10.602, -11.111]
Step 368 4 visits [2.0, 6.0, 2.0, 2.0, 351.0, 3.0, 2.0]  episode_count: 254 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.094, -10.602, -11.111]
Step 369 4 visits [2.0, 6.0, 2.0, 2.0, 352.0, 3.0, 2.0]  episode_count: 254 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.1, -10.602, -11.111]
Step 370 4 visits [2.0, 6.0, 2.0, 2.0, 353.0, 3.0, 2.0]  episode_count: 254 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.106, -10.602, -11.111]
Step 371 4 visits [2.0, 6.0, 2.0, 2.0, 354.0, 3.0, 2.0]  episode_count: 254 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.08, -10.602, -11.111]
Step 372 4 visits [2.0, 6.0, 2.0, 2.0, 355.0, 3.0, 2.0]  episode_count: 254 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.086, -10.602, -11.111]
Step 373 4 visits [2.0, 6.0, 2.0, 2.0, 356.0, 3.0, 2.0]  episode_count: 255 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.082, -10.602, -11.111]
{"total_number_of_episodes": 257, "number_of_timesteps": 24762, "per_episode_reward": -582.68, "episode_reward_trend_value": -0.08781551169263745, "biggest_recent_change": 6.572355528750904},
Step 374 4 visits [2.0, 6.0, 2.0, 2.0, 357.0, 3.0, 2.0]  episode_count: 257 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.088, -10.602, -11.111]
Step 375 4 visits [2.0, 6.0, 2.0, 2.0, 358.0, 3.0, 2.0]  episode_count: 258 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.094, -10.602, -11.111]
Step 376 4 visits [2.0, 6.0, 2.0, 2.0, 359.0, 3.0, 2.0]  episode_count: 259 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.068, -10.602, -11.111]
Step 377 4 visits [2.0, 6.0, 2.0, 2.0, 360.0, 3.0, 2.0]  episode_count: 259 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.074, -10.602, -11.111]
Step 378 4 visits [2.0, 6.0, 2.0, 2.0, 361.0, 3.0, 2.0]  episode_count: 259 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.08, -10.602, -11.111]
Step 379 4 visits [2.0, 6.0, 2.0, 2.0, 362.0, 3.0, 2.0]  episode_count: 260 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.085, -10.602, -11.111]
Step 380 4 visits [2.0, 6.0, 2.0, 2.0, 363.0, 3.0, 2.0]  episode_count: 260 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.06, -10.602, -11.111]
Step 381 4 visits [2.0, 6.0, 2.0, 2.0, 364.0, 3.0, 2.0]  episode_count: 260 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.066, -10.602, -11.111]
Step 382 4 visits [2.0, 6.0, 2.0, 2.0, 365.0, 3.0, 2.0]  episode_count: 261 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.071, -10.602, -11.111]
Step 383 4 visits [2.0, 6.0, 2.0, 2.0, 366.0, 3.0, 2.0]  episode_count: 263 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.077, -10.602, -11.111]
Step 384 4 visits [2.0, 6.0, 2.0, 2.0, 367.0, 3.0, 2.0]  episode_count: 263 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.082, -10.602, -11.111]
Step 385 4 visits [2.0, 6.0, 2.0, 2.0, 368.0, 3.0, 2.0]  episode_count: 265 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.058, -10.602, -11.111]
Step 386 4 visits [2.0, 6.0, 2.0, 2.0, 369.0, 3.0, 2.0]  episode_count: 265 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.063, -10.602, -11.111]
Step 387 4 visits [2.0, 6.0, 2.0, 2.0, 370.0, 3.0, 2.0]  episode_count: 266 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.069, -10.602, -11.111]
Step 388 4 visits [2.0, 6.0, 2.0, 2.0, 371.0, 3.0, 2.0]  episode_count: 266 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.074, -10.602, -11.111]
Step 389 4 visits [2.0, 6.0, 2.0, 2.0, 372.0, 3.0, 2.0]  episode_count: 266 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.08, -10.602, -11.111]
Step 390 4 visits [2.0, 6.0, 2.0, 2.0, 373.0, 3.0, 2.0]  episode_count: 266 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.085, -10.602, -11.111]
{"total_number_of_episodes": 267, "number_of_timesteps": 25772, "per_episode_reward": -582.96, "episode_reward_trend_value": -0.017886360617496343, "biggest_recent_change": 5.73207518150582},
Step 391 4 visits [2.0, 6.0, 2.0, 2.0, 374.0, 3.0, 2.0]  episode_count: 267 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.061, -10.602, -11.111]
Step 392 4 visits [2.0, 6.0, 2.0, 2.0, 375.0, 3.0, 2.0]  episode_count: 268 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.066, -10.602, -11.111]
Step 393 4 visits [2.0, 6.0, 2.0, 2.0, 376.0, 3.0, 2.0]  episode_count: 269 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.072, -10.602, -11.111]
Step 394 4 visits [2.0, 6.0, 2.0, 2.0, 377.0, 3.0, 2.0]  episode_count: 271 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.077, -10.602, -11.111]
Step 395 4 visits [2.0, 6.0, 2.0, 2.0, 378.0, 3.0, 2.0]  episode_count: 271 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.083, -10.602, -11.111]
Step 396 4 visits [2.0, 6.0, 2.0, 2.0, 379.0, 3.0, 2.0]  episode_count: 271 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.088, -10.602, -11.111]
Step 397 4 visits [2.0, 6.0, 2.0, 2.0, 380.0, 3.0, 2.0]  episode_count: 271 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.093, -10.602, -11.111]
Step 398 4 visits [2.0, 6.0, 2.0, 2.0, 381.0, 3.0, 2.0]  episode_count: 272 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.099, -10.602, -11.111]
Step 399 4 visits [2.0, 6.0, 2.0, 2.0, 382.0, 3.0, 2.0]  episode_count: 273 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.104, -10.602, -11.111]
Step 400 4 visits [2.0, 6.0, 2.0, 2.0, 383.0, 3.0, 2.0]  episode_count: 273 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.109, -10.602, -11.111]
Step 401 4 visits [2.0, 6.0, 2.0, 2.0, 384.0, 3.0, 2.0]  episode_count: 274 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.114, -10.602, -11.111]
Step 402 4 visits [2.0, 6.0, 2.0, 2.0, 385.0, 3.0, 2.0]  episode_count: 274 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.12, -10.602, -11.111]
Step 403 4 visits [2.0, 6.0, 2.0, 2.0, 386.0, 3.0, 2.0]  episode_count: 275 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.125, -10.602, -11.111]
Step 404 4 visits [2.0, 6.0, 2.0, 2.0, 387.0, 3.0, 2.0]  episode_count: 275 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.13, -10.602, -11.111]
Step 405 4 visits [2.0, 6.0, 2.0, 2.0, 388.0, 3.0, 2.0]  episode_count: 276 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.106, -10.602, -11.111]
Step 406 4 visits [2.0, 6.0, 2.0, 2.0, 389.0, 3.0, 2.0]  episode_count: 276 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.083, -10.602, -11.111]
{"total_number_of_episodes": 277, "number_of_timesteps": 26866, "per_episode_reward": -582.96, "episode_reward_trend_value": 0.017409755879590545, "biggest_recent_change": 5.73207518150582},
Step 407 4 visits [2.0, 6.0, 2.0, 2.0, 390.0, 3.0, 2.0]  episode_count: 277 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.088, -10.602, -11.111]
Step 408 4 visits [2.0, 6.0, 2.0, 2.0, 391.0, 3.0, 2.0]  episode_count: 278 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.093, -10.602, -11.111]
Step 409 4 visits [2.0, 6.0, 2.0, 2.0, 392.0, 3.0, 2.0]  episode_count: 278 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.098, -10.602, -11.111]
Step 410 4 visits [2.0, 6.0, 2.0, 2.0, 393.0, 3.0, 2.0]  episode_count: 278 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.104, -10.602, -11.111]
Step 411 4 visits [2.0, 6.0, 2.0, 2.0, 394.0, 3.0, 2.0]  episode_count: 280 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.109, -10.602, -11.111]
Step 412 4 visits [2.0, 6.0, 2.0, 2.0, 395.0, 3.0, 2.0]  episode_count: 282 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.114, -10.602, -11.111]
Step 413 4 visits [2.0, 6.0, 2.0, 2.0, 396.0, 3.0, 2.0]  episode_count: 282 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.091, -10.602, -11.111]
Step 414 4 visits [2.0, 6.0, 2.0, 2.0, 397.0, 3.0, 2.0]  episode_count: 283 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.096, -10.602, -11.111]
Step 415 4 visits [2.0, 6.0, 2.0, 2.0, 398.0, 3.0, 2.0]  episode_count: 283 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.101, -10.602, -11.111]
Step 416 4 visits [2.0, 6.0, 2.0, 2.0, 399.0, 3.0, 2.0]  episode_count: 283 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.078, -10.602, -11.111]
Step 417 4 visits [2.0, 6.0, 2.0, 2.0, 400.0, 3.0, 2.0]  episode_count: 283 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.083, -10.602, -11.111]
Step 418 4 visits [2.0, 6.0, 2.0, 2.0, 401.0, 3.0, 2.0]  episode_count: 283 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.088, -10.602, -11.111]
Step 419 4 visits [2.0, 6.0, 2.0, 2.0, 402.0, 3.0, 2.0]  episode_count: 284 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.093, -10.602, -11.111]
Step 420 4 visits [2.0, 6.0, 2.0, 2.0, 403.0, 3.0, 2.0]  episode_count: 284 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.098, -10.602, -11.111]
Step 421 4 visits [2.0, 6.0, 2.0, 2.0, 404.0, 3.0, 2.0]  episode_count: 285 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.103, -10.602, -11.111]
Step 422 4 visits [2.0, 6.0, 2.0, 2.0, 405.0, 3.0, 2.0]  episode_count: 285 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.108, -10.602, -11.111]
Step 423 4 visits [2.0, 6.0, 2.0, 2.0, 406.0, 3.0, 2.0]  episode_count: 285 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.113, -10.602, -11.111]
Step 424 4 visits [2.0, 6.0, 2.0, 2.0, 407.0, 3.0, 2.0]  episode_count: 285 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.118, -10.602, -11.111]
{"total_number_of_episodes": 287, "number_of_timesteps": 28015, "per_episode_reward": -580.71, "episode_reward_trend_value": -0.021302765333539104, "biggest_recent_change": 3.6790569481466946},
Step 425 4 visits [2.0, 6.0, 2.0, 2.0, 408.0, 3.0, 2.0]  episode_count: 287 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.123, -10.602, -11.111]
Step 426 4 visits [2.0, 6.0, 2.0, 2.0, 409.0, 3.0, 2.0]  episode_count: 288 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.128, -10.602, -11.111]
Step 427 4 visits [2.0, 6.0, 2.0, 2.0, 410.0, 3.0, 2.0]  episode_count: 288 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.133, -10.602, -11.111]
Step 428 4 visits [2.0, 6.0, 2.0, 2.0, 411.0, 3.0, 2.0]  episode_count: 289 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.137, -10.602, -11.111]
Step 429 4 visits [2.0, 6.0, 2.0, 2.0, 412.0, 3.0, 2.0]  episode_count: 289 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.142, -10.602, -11.111]
Step 430 4 visits [2.0, 6.0, 2.0, 2.0, 413.0, 3.0, 2.0]  episode_count: 290 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.147, -10.602, -11.111]
Step 431 4 visits [2.0, 6.0, 2.0, 2.0, 414.0, 3.0, 2.0]  episode_count: 290 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.152, -10.602, -11.111]
Step 432 4 visits [2.0, 6.0, 2.0, 2.0, 415.0, 3.0, 2.0]  episode_count: 290 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.156, -10.602, -11.111]
Step 433 4 visits [2.0, 6.0, 2.0, 2.0, 416.0, 3.0, 2.0]  episode_count: 290 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.161, -10.602, -11.111]
Step 434 4 visits [2.0, 6.0, 2.0, 2.0, 417.0, 3.0, 2.0]  episode_count: 292 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.166, -10.602, -11.111]
Step 435 4 visits [2.0, 6.0, 2.0, 2.0, 418.0, 3.0, 2.0]  episode_count: 294 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.17, -10.602, -11.111]
Step 436 4 visits [2.0, 6.0, 2.0, 2.0, 419.0, 3.0, 2.0]  episode_count: 294 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.175, -10.602, -11.111]
Step 437 4 visits [2.0, 6.0, 2.0, 2.0, 420.0, 3.0, 2.0]  episode_count: 295 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.18, -10.602, -11.111]
Step 438 4 visits [2.0, 6.0, 2.0, 2.0, 421.0, 3.0, 2.0]  episode_count: 295 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.158, -10.602, -11.111]
Step 439 4 visits [2.0, 6.0, 2.0, 2.0, 422.0, 3.0, 2.0]  episode_count: 296 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.163, -10.602, -11.111]
Step 440 4 visits [2.0, 6.0, 2.0, 2.0, 423.0, 3.0, 2.0]  episode_count: 296 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.141, -10.602, -11.111]
{"total_number_of_episodes": 297, "number_of_timesteps": 29228, "per_episode_reward": -580.99, "episode_reward_trend_value": 0.01627040606565389, "biggest_recent_change": 3.6790569481466946},
Step 441 4 visits [2.0, 6.0, 2.0, 2.0, 424.0, 3.0, 2.0]  episode_count: 297 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.146, -10.602, -11.111]
Step 442 4 visits [2.0, 6.0, 2.0, 2.0, 425.0, 3.0, 2.0]  episode_count: 298 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.15, -10.602, -11.111]
Step 443 4 visits [2.0, 6.0, 2.0, 2.0, 426.0, 3.0, 2.0]  episode_count: 298 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.155, -10.602, -11.111]
Step 444 4 visits [2.0, 6.0, 2.0, 2.0, 427.0, 3.0, 2.0]  episode_count: 300 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.159, -10.602, -11.111]
Step 445 4 visits [2.0, 6.0, 2.0, 2.0, 428.0, 3.0, 2.0]  episode_count: 300 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.164, -10.602, -11.111]
Step 446 4 visits [2.0, 6.0, 2.0, 2.0, 429.0, 3.0, 2.0]  episode_count: 301 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.168, -10.602, -11.111]
Step 447 4 visits [2.0, 6.0, 2.0, 2.0, 430.0, 3.0, 2.0]  episode_count: 301 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.173, -10.602, -11.111]
Step 448 4 visits [2.0, 6.0, 2.0, 2.0, 431.0, 3.0, 2.0]  episode_count: 301 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.177, -10.602, -11.111]
Step 449 4 visits [2.0, 6.0, 2.0, 2.0, 432.0, 3.0, 2.0]  episode_count: 301 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.182, -10.602, -11.111]
Step 450 4 visits [2.0, 6.0, 2.0, 2.0, 433.0, 3.0, 2.0]  episode_count: 302 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.186, -10.602, -11.111]
Step 451 4 visits [2.0, 6.0, 2.0, 2.0, 434.0, 3.0, 2.0]  episode_count: 304 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.191, -10.602, -11.111]
Step 452 4 visits [2.0, 6.0, 2.0, 2.0, 435.0, 3.0, 2.0]  episode_count: 304 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.17, -10.602, -11.111]
Step 453 4 visits [2.0, 6.0, 2.0, 2.0, 436.0, 3.0, 2.0]  episode_count: 304 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.174, -10.602, -11.111]
Step 454 4 visits [2.0, 6.0, 2.0, 2.0, 437.0, 3.0, 2.0]  episode_count: 305 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.153, -10.602, -11.111]
Step 455 4 visits [2.0, 6.0, 2.0, 2.0, 438.0, 3.0, 2.0]  episode_count: 306 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.158, -10.602, -11.111]
{"total_number_of_episodes": 307, "number_of_timesteps": 30308, "per_episode_reward": -580.98, "episode_reward_trend_value": 0.025225100037682247, "biggest_recent_change": 3.6790569481466946},
Step 456 4 visits [2.0, 6.0, 2.0, 2.0, 439.0, 3.0, 2.0]  episode_count: 307 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.162, -10.602, -11.111]
Step 457 4 visits [2.0, 6.0, 2.0, 2.0, 440.0, 3.0, 2.0]  episode_count: 308 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.167, -10.602, -11.111]
Step 458 4 visits [2.0, 6.0, 2.0, 2.0, 441.0, 3.0, 2.0]  episode_count: 308 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.171, -10.602, -11.111]
Step 459 4 visits [2.0, 6.0, 2.0, 2.0, 442.0, 3.0, 2.0]  episode_count: 308 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.175, -10.602, -11.111]
Step 460 4 visits [2.0, 6.0, 2.0, 2.0, 443.0, 3.0, 2.0]  episode_count: 308 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.18, -10.602, -11.111]
Step 461 4 visits [2.0, 6.0, 2.0, 2.0, 444.0, 3.0, 2.0]  episode_count: 308 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.184, -10.602, -11.111]
Step 462 4 visits [2.0, 6.0, 2.0, 2.0, 445.0, 3.0, 2.0]  episode_count: 309 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.188, -10.602, -11.111]
Step 463 4 visits [2.0, 6.0, 2.0, 2.0, 446.0, 3.0, 2.0]  episode_count: 309 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.193, -10.602, -11.111]
Step 464 4 visits [2.0, 6.0, 2.0, 2.0, 447.0, 3.0, 2.0]  episode_count: 309 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.197, -10.602, -11.111]
Step 465 4 visits [2.0, 6.0, 2.0, 2.0, 448.0, 3.0, 2.0]  episode_count: 310 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.176, -10.602, -11.111]
Step 466 4 visits [2.0, 6.0, 2.0, 2.0, 449.0, 3.0, 2.0]  episode_count: 310 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.181, -10.602, -11.111]
Step 467 4 visits [2.0, 6.0, 2.0, 2.0, 450.0, 3.0, 2.0]  episode_count: 310 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.185, -10.602, -11.111]
Step 468 4 visits [2.0, 6.0, 2.0, 2.0, 451.0, 3.0, 2.0]  episode_count: 311 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.189, -10.602, -11.111]
Step 469 4 visits [2.0, 6.0, 2.0, 2.0, 452.0, 3.0, 2.0]  episode_count: 312 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.194, -10.602, -11.111]
Step 470 4 visits [2.0, 6.0, 2.0, 2.0, 453.0, 3.0, 2.0]  episode_count: 313 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.198, -10.602, -11.111]
Step 471 4 visits [2.0, 6.0, 2.0, 2.0, 454.0, 3.0, 2.0]  episode_count: 313 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.202, -10.602, -11.111]
Step 472 4 visits [2.0, 6.0, 2.0, 2.0, 455.0, 3.0, 2.0]  episode_count: 313 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.206, -10.602, -11.111]
Step 473 4 visits [2.0, 6.0, 2.0, 2.0, 456.0, 3.0, 2.0]  episode_count: 313 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.21, -10.602, -11.111]
Step 474 4 visits [2.0, 6.0, 2.0, 2.0, 457.0, 3.0, 2.0]  episode_count: 314 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.215, -10.602, -11.111]
Step 475 4 visits [2.0, 6.0, 2.0, 2.0, 458.0, 3.0, 2.0]  episode_count: 314 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.219, -10.602, -11.111]
Step 476 4 visits [2.0, 6.0, 2.0, 2.0, 459.0, 3.0, 2.0]  episode_count: 315 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.223, -10.602, -11.111]
Step 477 4 visits [2.0, 6.0, 2.0, 2.0, 460.0, 3.0, 2.0]  episode_count: 316 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.227, -10.602, -11.111]
{"total_number_of_episodes": 318, "number_of_timesteps": 31679, "per_episode_reward": -581.15, "episode_reward_trend_value": 0.05407199815139292, "biggest_recent_change": 3.6790569481466946},
Step 478 4 visits [2.0, 6.0, 2.0, 2.0, 461.0, 3.0, 2.0]  episode_count: 318 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.231, -10.602, -11.111]
Step 479 4 visits [2.0, 6.0, 2.0, 2.0, 462.0, 3.0, 2.0]  episode_count: 318 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.235, -10.602, -11.111]
Step 480 4 visits [2.0, 6.0, 2.0, 2.0, 463.0, 3.0, 2.0]  episode_count: 318 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.239, -10.602, -11.111]
Step 481 4 visits [2.0, 6.0, 2.0, 2.0, 464.0, 3.0, 2.0]  episode_count: 318 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.243, -10.602, -11.111]
Step 482 4 visits [2.0, 6.0, 2.0, 2.0, 465.0, 3.0, 2.0]  episode_count: 320 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.247, -10.602, -11.111]
Step 483 4 visits [2.0, 6.0, 2.0, 2.0, 466.0, 3.0, 2.0]  episode_count: 321 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.251, -10.602, -11.111]
Step 484 4 visits [2.0, 6.0, 2.0, 2.0, 467.0, 3.0, 2.0]  episode_count: 321 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.255, -10.602, -11.111]
Step 485 4 visits [2.0, 6.0, 2.0, 2.0, 468.0, 3.0, 2.0]  episode_count: 321 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.259, -10.602, -11.111]
Step 486 4 visits [2.0, 6.0, 2.0, 2.0, 469.0, 3.0, 2.0]  episode_count: 321 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.263, -10.602, -11.111]
Step 487 4 visits [2.0, 6.0, 2.0, 2.0, 470.0, 3.0, 2.0]  episode_count: 325 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.267, -10.602, -11.111]
Step 488 4 visits [2.0, 6.0, 2.0, 2.0, 471.0, 3.0, 2.0]  episode_count: 325 q_vals: [-11.111, -10.169, -11.111, -11.111, -9.271, -10.602, -11.111]
Step 489 1 visits [2.0, 7.0, 2.0, 2.0, 471.0, 3.0, 2.0]  episode_count: 325 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.271, -10.602, -11.111]
Step 490 4 visits [2.0, 7.0, 2.0, 2.0, 472.0, 3.0, 2.0]  episode_count: 326 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.275, -10.602, -11.111]
Step 491 4 visits [2.0, 7.0, 2.0, 2.0, 473.0, 3.0, 2.0]  episode_count: 326 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.279, -10.602, -11.111]
Step 492 4 visits [2.0, 7.0, 2.0, 2.0, 474.0, 3.0, 2.0]  episode_count: 326 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.283, -10.602, -11.111]
Step 493 5 visits [2.0, 7.0, 2.0, 2.0, 474.0, 4.0, 2.0]  episode_count: 327 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.283, -10.729, -11.111]
Step 494 4 visits [2.0, 7.0, 2.0, 2.0, 475.0, 4.0, 2.0]  episode_count: 327 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.286, -10.729, -11.111]
{"total_number_of_episodes": 328, "number_of_timesteps": 32865, "per_episode_reward": -579.18, "episode_reward_trend_value": 0.03681607803542243, "biggest_recent_change": 3.6790569481466946},
Step 495 4 visits [2.0, 7.0, 2.0, 2.0, 476.0, 4.0, 2.0]  episode_count: 328 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.29, -10.729, -11.111]
Step 496 4 visits [2.0, 7.0, 2.0, 2.0, 477.0, 4.0, 2.0]  episode_count: 329 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.294, -10.729, -11.111]
Step 497 4 visits [2.0, 7.0, 2.0, 2.0, 478.0, 4.0, 2.0]  episode_count: 329 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.298, -10.729, -11.111]
Step 498 4 visits [2.0, 7.0, 2.0, 2.0, 479.0, 4.0, 2.0]  episode_count: 329 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.302, -10.729, -11.111]
Step 499 4 visits [2.0, 7.0, 2.0, 2.0, 480.0, 4.0, 2.0]  episode_count: 330 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.305, -10.729, -11.111]
Step 500 4 visits [2.0, 7.0, 2.0, 2.0, 481.0, 4.0, 2.0]  episode_count: 331 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.309, -10.729, -11.111]
Step 501 4 visits [2.0, 7.0, 2.0, 2.0, 482.0, 4.0, 2.0]  episode_count: 332 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.29, -10.729, -11.111]
Step 502 4 visits [2.0, 7.0, 2.0, 2.0, 483.0, 4.0, 2.0]  episode_count: 332 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.271, -10.729, -11.111]
Step 503 4 visits [2.0, 7.0, 2.0, 2.0, 484.0, 4.0, 2.0]  episode_count: 332 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.274, -10.729, -11.111]
Step 504 4 visits [2.0, 7.0, 2.0, 2.0, 485.0, 4.0, 2.0]  episode_count: 332 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.255, -10.729, -11.111]
Step 505 4 visits [2.0, 7.0, 2.0, 2.0, 486.0, 4.0, 2.0]  episode_count: 332 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 506 4 visits [2.0, 7.0, 2.0, 2.0, 487.0, 4.0, 2.0]  episode_count: 333 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.24, -10.729, -11.111]
Step 507 4 visits [2.0, 7.0, 2.0, 2.0, 488.0, 4.0, 2.0]  episode_count: 334 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.244, -10.729, -11.111]
Step 508 4 visits [2.0, 7.0, 2.0, 2.0, 489.0, 4.0, 2.0]  episode_count: 336 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.248, -10.729, -11.111]
Step 509 4 visits [2.0, 7.0, 2.0, 2.0, 490.0, 4.0, 2.0]  episode_count: 336 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.252, -10.729, -11.111]
Step 510 4 visits [2.0, 7.0, 2.0, 2.0, 491.0, 4.0, 2.0]  episode_count: 336 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.255, -10.729, -11.111]
Step 511 4 visits [2.0, 7.0, 2.0, 2.0, 492.0, 4.0, 2.0]  episode_count: 336 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 512 4 visits [2.0, 7.0, 2.0, 2.0, 493.0, 4.0, 2.0]  episode_count: 336 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.24, -10.729, -11.111]
{"total_number_of_episodes": 338, "number_of_timesteps": 34114, "per_episode_reward": -576.94, "episode_reward_trend_value": 0.10255470762798875, "biggest_recent_change": 3.4860990814398747},
Step 513 4 visits [2.0, 7.0, 2.0, 2.0, 494.0, 4.0, 2.0]  episode_count: 338 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.244, -10.729, -11.111]
Step 514 4 visits [2.0, 7.0, 2.0, 2.0, 495.0, 4.0, 2.0]  episode_count: 338 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.248, -10.729, -11.111]
Step 515 4 visits [2.0, 7.0, 2.0, 2.0, 496.0, 4.0, 2.0]  episode_count: 339 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.252, -10.729, -11.111]
Step 516 4 visits [2.0, 7.0, 2.0, 2.0, 497.0, 4.0, 2.0]  episode_count: 339 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.255, -10.729, -11.111]
Step 517 4 visits [2.0, 7.0, 2.0, 2.0, 498.0, 4.0, 2.0]  episode_count: 339 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 518 4 visits [2.0, 7.0, 2.0, 2.0, 499.0, 4.0, 2.0]  episode_count: 340 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.263, -10.729, -11.111]
Step 519 4 visits [2.0, 7.0, 2.0, 2.0, 500.0, 4.0, 2.0]  episode_count: 341 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.267, -10.729, -11.111]
Step 520 4 visits [2.0, 7.0, 2.0, 2.0, 501.0, 4.0, 2.0]  episode_count: 341 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.27, -10.729, -11.111]
Step 521 4 visits [2.0, 7.0, 2.0, 2.0, 502.0, 4.0, 2.0]  episode_count: 343 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.252, -10.729, -11.111]
Step 522 4 visits [2.0, 7.0, 2.0, 2.0, 503.0, 4.0, 2.0]  episode_count: 343 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.255, -10.729, -11.111]
Step 523 4 visits [2.0, 7.0, 2.0, 2.0, 504.0, 4.0, 2.0]  episode_count: 343 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 524 4 visits [2.0, 7.0, 2.0, 2.0, 505.0, 4.0, 2.0]  episode_count: 344 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.263, -10.729, -11.111]
q_vals: [-11.111, -10.304, -11.111, -11.111, -9.266, -10.729, -11.111]
Step 526 4 visits [2.0, 7.0, 2.0, 2.0, 507.0, 4.0, 2.0]  episode_count: 344 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.27, -10.729, -11.111]
Step 527 4 visits [2.0, 7.0, 2.0, 2.0, 508.0, 4.0, 2.0]  episode_count: 344 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.274, -10.729, -11.111]
Step 528 4 visits [2.0, 7.0, 2.0, 2.0, 509.0, 4.0, 2.0]  episode_count: 345 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.277, -10.729, -11.111]
Step 529 4 visits [2.0, 7.0, 2.0, 2.0, 510.0, 4.0, 2.0]  episode_count: 346 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.281, -10.729, -11.111]
Step 530 4 visits [2.0, 7.0, 2.0, 2.0, 511.0, 4.0, 2.0]  episode_count: 346 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.263, -10.729, -11.111]
Step 531 4 visits [2.0, 7.0, 2.0, 2.0, 512.0, 4.0, 2.0]  episode_count: 346 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.266, -10.729, -11.111]
Step 532 4 visits [2.0, 7.0, 2.0, 2.0, 513.0, 4.0, 2.0]  episode_count: 347 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.27, -10.729, -11.111]
{"total_number_of_episodes": 348, "number_of_timesteps": 35363, "per_episode_reward": -577.38, "episode_reward_trend_value": 0.058968024244907415, "biggest_recent_change": 2.2479482723241517},
Step 533 4 visits [2.0, 7.0, 2.0, 2.0, 514.0, 4.0, 2.0]  episode_count: 348 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.274, -10.729, -11.111]
Step 534 4 visits [2.0, 7.0, 2.0, 2.0, 515.0, 4.0, 2.0]  episode_count: 349 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.256, -10.729, -11.111]
Step 535 4 visits [2.0, 7.0, 2.0, 2.0, 516.0, 4.0, 2.0]  episode_count: 350 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 536 4 visits [2.0, 7.0, 2.0, 2.0, 517.0, 4.0, 2.0]  episode_count: 352 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.263, -10.729, -11.111]
Step 537 4 visits [2.0, 7.0, 2.0, 2.0, 518.0, 4.0, 2.0]  episode_count: 352 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.245, -10.729, -11.111]
Step 538 4 visits [2.0, 7.0, 2.0, 2.0, 519.0, 4.0, 2.0]  episode_count: 352 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.248, -10.729, -11.111]
Step 539 4 visits [2.0, 7.0, 2.0, 2.0, 520.0, 4.0, 2.0]  episode_count: 353 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.231, -10.729, -11.111]
Step 540 4 visits [2.0, 7.0, 2.0, 2.0, 521.0, 4.0, 2.0]  episode_count: 354 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.234, -10.729, -11.111]
Step 541 4 visits [2.0, 7.0, 2.0, 2.0, 522.0, 4.0, 2.0]  episode_count: 354 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.238, -10.729, -11.111]
Step 542 4 visits [2.0, 7.0, 2.0, 2.0, 523.0, 4.0, 2.0]  episode_count: 356 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.241, -10.729, -11.111]
Step 543 4 visits [2.0, 7.0, 2.0, 2.0, 524.0, 4.0, 2.0]  episode_count: 357 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.245, -10.729, -11.111]
Step 544 4 visits [2.0, 7.0, 2.0, 2.0, 525.0, 4.0, 2.0]  episode_count: 357 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.249, -10.729, -11.111]
{"total_number_of_episodes": 358, "number_of_timesteps": 36338, "per_episode_reward": -578.34, "episode_reward_trend_value": 0.05135042454473554, "biggest_recent_change": 2.2479482723241517},
Step 545 4 visits [2.0, 7.0, 2.0, 2.0, 526.0, 4.0, 2.0]  episode_count: 358 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.252, -10.729, -11.111]
Step 546 4 visits [2.0, 7.0, 2.0, 2.0, 527.0, 4.0, 2.0]  episode_count: 358 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.235, -10.729, -11.111]
Step 547 4 visits [2.0, 7.0, 2.0, 2.0, 528.0, 4.0, 2.0]  episode_count: 359 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.238, -10.729, -11.111]
Step 548 4 visits [2.0, 7.0, 2.0, 2.0, 529.0, 4.0, 2.0]  episode_count: 359 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.242, -10.729, -11.111]
Step 549 4 visits [2.0, 7.0, 2.0, 2.0, 530.0, 4.0, 2.0]  episode_count: 359 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.245, -10.729, -11.111]
Step 550 4 visits [2.0, 7.0, 2.0, 2.0, 531.0, 4.0, 2.0]  episode_count: 359 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.249, -10.729, -11.111]
Step 551 4 visits [2.0, 7.0, 2.0, 2.0, 532.0, 4.0, 2.0]  episode_count: 362 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.231, -10.729, -11.111]
Step 552 4 visits [2.0, 7.0, 2.0, 2.0, 533.0, 4.0, 2.0]  episode_count: 363 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.235, -10.729, -11.111]
Step 553 4 visits [2.0, 7.0, 2.0, 2.0, 534.0, 4.0, 2.0]  episode_count: 365 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.238, -10.729, -11.111]
Step 554 4 visits [2.0, 7.0, 2.0, 2.0, 535.0, 4.0, 2.0]  episode_count: 365 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.242, -10.729, -11.111]
Step 555 4 visits [2.0, 7.0, 2.0, 2.0, 536.0, 4.0, 2.0]  episode_count: 365 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.245, -10.729, -11.111]
Step 556 4 visits [2.0, 7.0, 2.0, 2.0, 537.0, 4.0, 2.0]  episode_count: 366 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.249, -10.729, -11.111]
Step 557 4 visits [2.0, 7.0, 2.0, 2.0, 538.0, 4.0, 2.0]  episode_count: 366 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.252, -10.729, -11.111]
Step 558 4 visits [2.0, 7.0, 2.0, 2.0, 539.0, 4.0, 2.0]  episode_count: 367 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.256, -10.729, -11.111]
{"total_number_of_episodes": 368, "number_of_timesteps": 37245, "per_episode_reward": -574.88, "episode_reward_trend_value": 0.08975854084209485, "biggest_recent_change": 3.463023520360821},
Step 559 4 visits [2.0, 7.0, 2.0, 2.0, 540.0, 4.0, 2.0]  episode_count: 368 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 560 4 visits [2.0, 7.0, 2.0, 2.0, 541.0, 4.0, 2.0]  episode_count: 370 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.263, -10.729, -11.111]
Step 561 4 visits [2.0, 7.0, 2.0, 2.0, 542.0, 4.0, 2.0]  episode_count: 371 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.266, -10.729, -11.111]
Step 562 4 visits [2.0, 7.0, 2.0, 2.0, 543.0, 4.0, 2.0]  episode_count: 371 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.249, -10.729, -11.111]
Step 563 4 visits [2.0, 7.0, 2.0, 2.0, 544.0, 4.0, 2.0]  episode_count: 372 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.252, -10.729, -11.111]
Step 564 4 visits [2.0, 7.0, 2.0, 2.0, 545.0, 4.0, 2.0]  episode_count: 372 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.256, -10.729, -11.111]
[2.0, 7.0, 2.0, 2.0, 546.0, 4.0, 2.0]  episode_count: 373 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 566 4 visits [2.0, 7.0, 2.0, 2.0, 547.0, 4.0, 2.0]  episode_count: 376 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.263, -10.729, -11.111]
Step 567 4 visits [2.0, 7.0, 2.0, 2.0, 548.0, 4.0, 2.0]  episode_count: 376 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.266, -10.729, -11.111]
Step 568 4 visits [2.0, 7.0, 2.0, 2.0, 549.0, 4.0, 2.0]  episode_count: 377 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.269, -10.729, -11.111]
{"total_number_of_episodes": 378, "number_of_timesteps": 38006, "per_episode_reward": -573.61, "episode_reward_trend_value": 0.07885852252443455, "biggest_recent_change": 3.463023520360821},
Step 569 4 visits [2.0, 7.0, 2.0, 2.0, 550.0, 4.0, 2.0]  episode_count: 378 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.273, -10.729, -11.111]
Step 570 4 visits [2.0, 7.0, 2.0, 2.0, 551.0, 4.0, 2.0]  episode_count: 379 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.276, -10.729, -11.111]
Step 571 4 visits [2.0, 7.0, 2.0, 2.0, 552.0, 4.0, 2.0]  episode_count: 379 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.279, -10.729, -11.111]
Step 572 4 visits [2.0, 7.0, 2.0, 2.0, 553.0, 4.0, 2.0]  episode_count: 380 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.283, -10.729, -11.111]
Step 573 4 visits [2.0, 7.0, 2.0, 2.0, 554.0, 4.0, 2.0]  episode_count: 382 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.286, -10.729, -11.111]
Step 574 4 visits [2.0, 7.0, 2.0, 2.0, 555.0, 4.0, 2.0]  episode_count: 383 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.289, -10.729, -11.111]
Step 575 4 visits [2.0, 7.0, 2.0, 2.0, 556.0, 4.0, 2.0]  episode_count: 384 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.272, -10.729, -11.111]
Step 576 4 visits [2.0, 7.0, 2.0, 2.0, 557.0, 4.0, 2.0]  episode_count: 385 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.276, -10.729, -11.111]
Step 577 4 visits [2.0, 7.0, 2.0, 2.0, 558.0, 4.0, 2.0]  episode_count: 385 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.279, -10.729, -11.111]
Step 578 4 visits [2.0, 7.0, 2.0, 2.0, 559.0, 4.0, 2.0]  episode_count: 385 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.282, -10.729, -11.111]
{"total_number_of_episodes": 389, "number_of_timesteps": 38755, "per_episode_reward": -569.86, "episode_reward_trend_value": 0.12367856393209042, "biggest_recent_change": 3.752582034054626},
Step 579 4 visits [2.0, 7.0, 2.0, 2.0, 560.0, 4.0, 2.0]  episode_count: 389 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.286, -10.729, -11.111]
Step 580 4 visits [2.0, 7.0, 2.0, 2.0, 561.0, 4.0, 2.0]  episode_count: 389 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.269, -10.729, -11.111]
Step 581 4 visits [2.0, 7.0, 2.0, 2.0, 562.0, 4.0, 2.0]  episode_count: 389 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.272, -10.729, -11.111]
Step 582 4 visits [2.0, 7.0, 2.0, 2.0, 563.0, 4.0, 2.0]  episode_count: 389 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.276, -10.729, -11.111]
Step 583 4 visits [2.0, 7.0, 2.0, 2.0, 564.0, 4.0, 2.0]  episode_count: 390 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.279, -10.729, -11.111]
Step 584 4 visits [2.0, 7.0, 2.0, 2.0, 565.0, 4.0, 2.0]  episode_count: 392 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.282, -10.729, -11.111]
Step 585 4 visits [2.0, 7.0, 2.0, 2.0, 566.0, 4.0, 2.0]  episode_count: 392 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.285, -10.729, -11.111]
Step 586 4 visits [2.0, 7.0, 2.0, 2.0, 567.0, 4.0, 2.0]  episode_count: 393 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.289, -10.729, -11.111]
Step 587 4 visits [2.0, 7.0, 2.0, 2.0, 568.0, 4.0, 2.0]  episode_count: 393 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.292, -10.729, -11.111]
Step 588 4 visits [2.0, 7.0, 2.0, 2.0, 569.0, 4.0, 2.0]  episode_count: 393 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.295, -10.729, -11.111]
Step 589 4 visits [2.0, 7.0, 2.0, 2.0, 570.0, 4.0, 2.0]  episode_count: 396 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.298, -10.729, -11.111]
Step 590 4 visits [2.0, 7.0, 2.0, 2.0, 571.0, 4.0, 2.0]  episode_count: 397 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.301, -10.729, -11.111]
Step 591 4 visits [2.0, 7.0, 2.0, 2.0, 572.0, 4.0, 2.0]  episode_count: 397 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.304, -10.729, -11.111]
Step 592 4 visits [2.0, 7.0, 2.0, 2.0, 573.0, 4.0, 2.0]  episode_count: 398 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.308, -10.729, -11.111]
{"total_number_of_episodes": 399, "number_of_timesteps": 39585, "per_episode_reward": -562.21, "episode_reward_trend_value": 0.20856796234722502, "biggest_recent_change": 7.646134774731195},
Step 593 4 visits [2.0, 7.0, 2.0, 2.0, 574.0, 4.0, 2.0]  episode_count: 399 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.311, -10.729, -11.111]
Step 594 4 visits [2.0, 7.0, 2.0, 2.0, 575.0, 4.0, 2.0]  episode_count: 399 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.314, -10.729, -11.111]
Step 595 4 visits [2.0, 7.0, 2.0, 2.0, 576.0, 4.0, 2.0]  episode_count: 400 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.317, -10.729, -11.111]
Step 596 4 visits [2.0, 7.0, 2.0, 2.0, 577.0, 4.0, 2.0]  episode_count: 400 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.32, -10.729, -11.111]
Step 597 4 visits [2.0, 7.0, 2.0, 2.0, 578.0, 4.0, 2.0]  episode_count: 401 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.323, -10.729, -11.111]
Step 598 4 visits [2.0, 7.0, 2.0, 2.0, 579.0, 4.0, 2.0]  episode_count: 402 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.326, -10.729, -11.111]
Step 599 4 visits [2.0, 7.0, 2.0, 2.0, 580.0, 4.0, 2.0]  episode_count: 402 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.329, -10.729, -11.111]
Step 600 4 visits [2.0, 7.0, 2.0, 2.0, 581.0, 4.0, 2.0]  episode_count: 402 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.332, -10.729, -11.111]
Step 601 4 visits [2.0, 7.0, 2.0, 2.0, 582.0, 4.0, 2.0]  episode_count: 403 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.336, -10.729, -11.111]
Step 602 4 visits [2.0, 7.0, 2.0, 2.0, 583.0, 4.0, 2.0]  episode_count: 405 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.339, -10.729, -11.111]
Step 603 4 visits [2.0, 7.0, 2.0, 2.0, 584.0, 4.0, 2.0]  episode_count: 406 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.342, -10.729, -11.111]
Step 604 4 visits [2.0, 7.0, 2.0, 2.0, 585.0, 4.0, 2.0]  episode_count: 406 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.345, -10.729, -11.111]
Step 605 4 visits [2.0, 7.0, 2.0, 2.0, 586.0, 4.0, 2.0]  episode_count: 407 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.348, -10.729, -11.111]
Step 606 4 visits [2.0, 7.0, 2.0, 2.0, 587.0, 4.0, 2.0]  episode_count: 408 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.332, -10.729, -11.111]
Step 607 4 visits [2.0, 7.0, 2.0, 2.0, 588.0, 4.0, 2.0]  episode_count: 408 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.335, -10.729, -11.111]
{"total_number_of_episodes": 409, "number_of_timesteps": 40526, "per_episode_reward": -557.64, "episode_reward_trend_value": 0.2611917719847687, "biggest_recent_change": 7.646134774731195},
Step 608 4 visits [2.0, 7.0, 2.0, 2.0, 589.0, 4.0, 2.0]  episode_count: 409 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.319, -10.729, -11.111]
Step 609 4 visits [2.0, 7.0, 2.0, 2.0, 590.0, 4.0, 2.0]  episode_count: 409 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.322, -10.729, -11.111]
Step 610 4 visits [2.0, 7.0, 2.0, 2.0, 591.0, 4.0, 2.0]  episode_count: 409 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.325, -10.729, -11.111]
Step 611 4 visits [2.0, 7.0, 2.0, 2.0, 592.0, 4.0, 2.0]  episode_count: 409 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.328, -10.729, -11.111]
Step 612 4 visits [2.0, 7.0, 2.0, 2.0, 593.0, 4.0, 2.0]  episode_count: 410 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.331, -10.729, -11.111]
Step 613 4 visits [2.0, 7.0, 2.0, 2.0, 594.0, 4.0, 2.0]  episode_count: 412 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.334, -10.729, -11.111]
Step 614 4 visits [2.0, 7.0, 2.0, 2.0, 595.0, 4.0, 2.0]  episode_count: 412 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.337, -10.729, -11.111]
Step 615 4 visits [2.0, 7.0, 2.0, 2.0, 596.0, 4.0, 2.0]  episode_count: 412 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.34, -10.729, -11.111]
Step 616 4 visits [2.0, 7.0, 2.0, 2.0, 597.0, 4.0, 2.0]  episode_count: 414 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.343, -10.729, -11.111]
Step 617 4 visits [2.0, 7.0, 2.0, 2.0, 598.0, 4.0, 2.0]  episode_count: 414 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.346, -10.729, -11.111]
Step 618 4 visits [2.0, 7.0, 2.0, 2.0, 599.0, 4.0, 2.0]  episode_count: 414 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.349, -10.729, -11.111]
Step 619 4 visits [2.0, 7.0, 2.0, 2.0, 600.0, 4.0, 2.0]  episode_count: 414 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.352, -10.729, -11.111]
Step 620 4 visits [2.0, 7.0, 2.0, 2.0, 601.0, 4.0, 2.0]  episode_count: 414 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.355, -10.729, -11.111]
Step 621 4 visits [2.0, 7.0, 2.0, 2.0, 602.0, 4.0, 2.0]  episode_count: 415 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.358, -10.729, -11.111]
Step 622 4 visits [2.0, 7.0, 2.0, 2.0, 603.0, 4.0, 2.0]  episode_count: 416 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.36, -10.729, -11.111]
Step 623 4 visits [2.0, 7.0, 2.0, 2.0, 604.0, 4.0, 2.0]  episode_count: 416 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.363, -10.729, -11.111]
Step 624 4 visits [2.0, 7.0, 2.0, 2.0, 605.0, 4.0, 2.0]  episode_count: 417 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.366, -10.729, -11.111]
Step 625 4 visits [2.0, 7.0, 2.0, 2.0, 606.0, 4.0, 2.0]  episode_count: 418 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.369, -10.729, -11.111]
Step 626 4 visits [2.0, 7.0, 2.0, 2.0, 607.0, 4.0, 2.0]  episode_count: 418 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.372, -10.729, -11.111]
{"total_number_of_episodes": 419, "number_of_timesteps": 41634, "per_episode_reward": -555.0, "episode_reward_trend_value": 0.26859965983139394, "biggest_recent_change": 7.646134774731195},
Step 627 4 visits [2.0, 7.0, 2.0, 2.0, 608.0, 4.0, 2.0]  episode_count: 419 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.375, -10.729, -11.111]
Step 628 4 visits [2.0, 7.0, 2.0, 2.0, 609.0, 4.0, 2.0]  episode_count: 419 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.378, -10.729, -11.111]
Step 629 4 visits [2.0, 7.0, 2.0, 2.0, 610.0, 4.0, 2.0]  episode_count: 420 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.362, -10.729, -11.111]
Step 630 4 visits [2.0, 7.0, 2.0, 2.0, 611.0, 4.0, 2.0]  episode_count: 420 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.365, -10.729, -11.111]
Step 631 4 visits [2.0, 7.0, 2.0, 2.0, 612.0, 4.0, 2.0]  episode_count: 420 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.368, -10.729, -11.111]
Step 632 4 visits [2.0, 7.0, 2.0, 2.0, 613.0, 4.0, 2.0]  episode_count: 421 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.371, -10.729, -11.111]
Step 633 4 visits [2.0, 7.0, 2.0, 2.0, 614.0, 4.0, 2.0]  episode_count: 422 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.356, -10.729, -11.111]
Step 634 4 visits [2.0, 7.0, 2.0, 2.0, 615.0, 4.0, 2.0]  episode_count: 422 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.359, -10.729, -11.111]
Step 635 4 visits [2.0, 7.0, 2.0, 2.0, 616.0, 4.0, 2.0]  episode_count: 422 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.361, -10.729, -11.111]
Step 636 4 visits [2.0, 7.0, 2.0, 2.0, 617.0, 4.0, 2.0]  episode_count: 423 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.364, -10.729, -11.111]
Step 637 4 visits [2.0, 7.0, 2.0, 2.0, 618.0, 4.0, 2.0]  episode_count: 423 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.349, -10.729, -11.111]
Step 638 4 visits [2.0, 7.0, 2.0, 2.0, 619.0, 4.0, 2.0]  episode_count: 425 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.352, -10.729, -11.111]
Step 639 4 visits [2.0, 7.0, 2.0, 2.0, 620.0, 4.0, 2.0]  episode_count: 425 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.355, -10.729, -11.111]
Step 640 4 visits [2.0, 7.0, 2.0, 2.0, 621.0, 4.0, 2.0]  episode_count: 425 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.358, -10.729, -11.111]
Step 641 4 visits [2.0, 7.0, 2.0, 2.0, 622.0, 4.0, 2.0]  episode_count: 425 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.36, -10.729, -11.111]
Step 642 4 visits [2.0, 7.0, 2.0, 2.0, 623.0, 4.0, 2.0]  episode_count: 425 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.363, -10.729, -11.111]
Step 643 4 visits [2.0, 7.0, 2.0, 2.0, 624.0, 4.0, 2.0]  episode_count: 425 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.366, -10.729, -11.111]
Step 644 4 visits [2.0, 7.0, 2.0, 2.0, 625.0, 4.0, 2.0]  episode_count: 425 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.351, -10.729, -11.111]
Step 645 4 visits [2.0, 7.0, 2.0, 2.0, 626.0, 4.0, 2.0]  episode_count: 425 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.354, -10.729, -11.111]
Step 646 4 visits [2.0, 7.0, 2.0, 2.0, 627.0, 4.0, 2.0]  episode_count: 426 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.357, -10.729, -11.111]
Step 647 4 visits [2.0, 7.0, 2.0, 2.0, 628.0, 4.0, 2.0]  episode_count: 426 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.359, -10.729, -11.111]
Step 648 4 visits [2.0, 7.0, 2.0, 2.0, 629.0, 4.0, 2.0]  episode_count: 428 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.362, -10.729, -11.111]
Step 649 4 visits [2.0, 7.0, 2.0, 2.0, 630.0, 4.0, 2.0]  episode_count: 428 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.347, -10.729, -11.111]
{"total_number_of_episodes": 429, "number_of_timesteps": 42995, "per_episode_reward": -552.98, "episode_reward_trend_value": 0.26623289921132404, "biggest_recent_change": 7.646134774731195},
Step 650 4 visits [2.0, 7.0, 2.0, 2.0, 631.0, 4.0, 2.0]  episode_count: 429 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.35, -10.729, -11.111]
Step 651 4 visits [2.0, 7.0, 2.0, 2.0, 632.0, 4.0, 2.0]  episode_count: 430 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.353, -10.729, -11.111]
Step 652 4 visits [2.0, 7.0, 2.0, 2.0, 633.0, 4.0, 2.0]  episode_count: 431 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.356, -10.729, -11.111]
Step 653 4 visits [2.0, 7.0, 2.0, 2.0, 634.0, 4.0, 2.0]  episode_count: 432 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.341, -10.729, -11.111]
Step 654 4 visits [2.0, 7.0, 2.0, 2.0, 635.0, 4.0, 2.0]  episode_count: 432 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.344, -10.729, -11.111]
Step 655 4 visits [2.0, 7.0, 2.0, 2.0, 636.0, 4.0, 2.0]  episode_count: 432 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.347, -10.729, -11.111]
Step 656 4 visits [2.0, 7.0, 2.0, 2.0, 637.0, 4.0, 2.0]  episode_count: 433 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.349, -10.729, -11.111]
Step 657 4 visits [2.0, 7.0, 2.0, 2.0, 638.0, 4.0, 2.0]  episode_count: 433 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.352, -10.729, -11.111]
Step 658 4 visits [2.0, 7.0, 2.0, 2.0, 639.0, 4.0, 2.0]  episode_count: 434 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.337, -10.729, -11.111]
Step 659 4 visits [2.0, 7.0, 2.0, 2.0, 640.0, 4.0, 2.0]  episode_count: 434 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.34, -10.729, -11.111]
Step 660 4 visits [2.0, 7.0, 2.0, 2.0, 641.0, 4.0, 2.0]  episode_count: 436 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.326, -10.729, -11.111]
Step 661 4 visits [2.0, 7.0, 2.0, 2.0, 642.0, 4.0, 2.0]  episode_count: 436 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.328, -10.729, -11.111]
Step 662 4 visits [2.0, 7.0, 2.0, 2.0, 643.0, 4.0, 2.0]  episode_count: 437 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.331, -10.729, -11.111]
Step 663 4 visits [2.0, 7.0, 2.0, 2.0, 644.0, 4.0, 2.0]  episode_count: 438 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.334, -10.729, -11.111]
{"total_number_of_episodes": 439, "number_of_timesteps": 44379, "per_episode_reward": -553.64, "episode_reward_trend_value": 0.26370482338392853, "biggest_recent_change": 7.646134774731195},
Step 664 4 visits [2.0, 7.0, 2.0, 2.0, 645.0, 4.0, 2.0]  episode_count: 439 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.319, -10.729, -11.111]
Step 665 4 visits [2.0, 7.0, 2.0, 2.0, 646.0, 4.0, 2.0]  episode_count: 439 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.322, -10.729, -11.111]
Step 666 4 visits [2.0, 7.0, 2.0, 2.0, 647.0, 4.0, 2.0]  episode_count: 440 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.325, -10.729, -11.111]
Step 667 4 visits [2.0, 7.0, 2.0, 2.0, 648.0, 4.0, 2.0]  episode_count: 441 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.328, -10.729, -11.111]
Step 668 4 visits [2.0, 7.0, 2.0, 2.0, 649.0, 4.0, 2.0]  episode_count: 441 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.33, -10.729, -11.111]
Step 669 4 visits [2.0, 7.0, 2.0, 2.0, 650.0, 4.0, 2.0]  episode_count: 441 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.333, -10.729, -11.111]
Step 670 4 visits [2.0, 7.0, 2.0, 2.0, 651.0, 4.0, 2.0]  episode_count: 441 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.336, -10.729, -11.111]
Step 671 4 visits [2.0, 7.0, 2.0, 2.0, 652.0, 4.0, 2.0]  episode_count: 442 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.339, -10.729, -11.111]
Step 672 4 visits [2.0, 7.0, 2.0, 2.0, 653.0, 4.0, 2.0]  episode_count: 443 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.324, -10.729, -11.111]
Step 673 4 visits [2.0, 7.0, 2.0, 2.0, 654.0, 4.0, 2.0]  episode_count: 443 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.31, -10.729, -11.111]
Step 674 4 visits [2.0, 7.0, 2.0, 2.0, 655.0, 4.0, 2.0]  episode_count: 444 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.296, -10.729, -11.111]
Step 675 4 visits [2.0, 7.0, 2.0, 2.0, 656.0, 4.0, 2.0]  episode_count: 444 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.299, -10.729, -11.111]
Step 676 4 visits [2.0, 7.0, 2.0, 2.0, 657.0, 4.0, 2.0]  episode_count: 447 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.301, -10.729, -11.111]
Step 677 4 visits [2.0, 7.0, 2.0, 2.0, 658.0, 4.0, 2.0]  episode_count: 447 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.304, -10.729, -11.111]
Step 678 4 visits [2.0, 7.0, 2.0, 2.0, 659.0, 4.0, 2.0]  episode_count: 447 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.29, -10.729, -11.111]
Step 679 4 visits [2.0, 7.0, 2.0, 2.0, 660.0, 4.0, 2.0]  episode_count: 448 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.293, -10.729, -11.111]
{"total_number_of_episodes": 450, "number_of_timesteps": 45506, "per_episode_reward": -550.39, "episode_reward_trend_value": 0.3105768541667556, "biggest_recent_change": 7.646134774731195},
Step 680 4 visits [2.0, 7.0, 2.0, 2.0, 661.0, 4.0, 2.0]  episode_count: 450 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.296, -10.729, -11.111]
Step 681 4 visits [2.0, 7.0, 2.0, 2.0, 662.0, 4.0, 2.0]  episode_count: 450 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.298, -10.729, -11.111]
Step 682 4 visits [2.0, 7.0, 2.0, 2.0, 663.0, 4.0, 2.0]  episode_count: 450 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.301, -10.729, -11.111]
Step 683 4 visits [2.0, 7.0, 2.0, 2.0, 664.0, 4.0, 2.0]  episode_count: 450 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.287, -10.729, -11.111]
Step 684 4 visits [2.0, 7.0, 2.0, 2.0, 665.0, 4.0, 2.0]  episode_count: 450 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.29, -10.729, -11.111]
Step 685 4 visits [2.0, 7.0, 2.0, 2.0, 666.0, 4.0, 2.0]  episode_count: 451 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.276, -10.729, -11.111]
Step 686 4 visits [2.0, 7.0, 2.0, 2.0, 667.0, 4.0, 2.0]  episode_count: 453 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.262, -10.729, -11.111]
Step 687 4 visits [2.0, 7.0, 2.0, 2.0, 668.0, 4.0, 2.0]  episode_count: 454 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.265, -10.729, -11.111]
Step 688 4 visits [2.0, 7.0, 2.0, 2.0, 669.0, 4.0, 2.0]  episode_count: 454 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.267, -10.729, -11.111]
Step 689 4 visits [2.0, 7.0, 2.0, 2.0, 670.0, 4.0, 2.0]  episode_count: 455 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.27, -10.729, -11.111]
Step 690 4 visits [2.0, 7.0, 2.0, 2.0, 671.0, 4.0, 2.0]  episode_count: 455 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.273, -10.729, -11.111]
Step 691 4 visits [2.0, 7.0, 2.0, 2.0, 672.0, 4.0, 2.0]  episode_count: 457 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.276, -10.729, -11.111]
Step 692 4 visits [2.0, 7.0, 2.0, 2.0, 673.0, 4.0, 2.0]  episode_count: 457 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.278, -10.729, -11.111]
Step 693 4 visits [2.0, 7.0, 2.0, 2.0, 674.0, 4.0, 2.0]  episode_count: 457 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.281, -10.729, -11.111]
Step 694 4 visits [2.0, 7.0, 2.0, 2.0, 675.0, 4.0, 2.0]  episode_count: 458 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.284, -10.729, -11.111]
Step 695 4 visits [2.0, 7.0, 2.0, 2.0, 676.0, 4.0, 2.0]  episode_count: 458 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.287, -10.729, -11.111]
Step 696 4 visits [2.0, 7.0, 2.0, 2.0, 677.0, 4.0, 2.0]  episode_count: 458 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.289, -10.729, -11.111]
Step 697 4 visits [2.0, 7.0, 2.0, 2.0, 678.0, 4.0, 2.0]  episode_count: 458 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.292, -10.729, -11.111]
Step 698 4 visits [2.0, 7.0, 2.0, 2.0, 679.0, 4.0, 2.0]  episode_count: 458 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.278, -10.729, -11.111]
{"total_number_of_episodes": 460, "number_of_timesteps": 46503, "per_episode_reward": -547.48, "episode_reward_trend_value": 0.30441272947906556, "biggest_recent_change": 7.646134774731195},
Step 699 4 visits [2.0, 7.0, 2.0, 2.0, 680.0, 4.0, 2.0]  episode_count: 460 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.281, -10.729, -11.111]
Step 700 4 visits [2.0, 7.0, 2.0, 2.0, 681.0, 4.0, 2.0]  episode_count: 463 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.284, -10.729, -11.111]
Step 701 4 visits [2.0, 7.0, 2.0, 2.0, 682.0, 4.0, 2.0]  episode_count: 463 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.286, -10.729, -11.111]
Step 702 4 visits [2.0, 7.0, 2.0, 2.0, 683.0, 4.0, 2.0]  episode_count: 464 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.273, -10.729, -11.111]
Step 703 4 visits [2.0, 7.0, 2.0, 2.0, 684.0, 4.0, 2.0]  episode_count: 464 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 704 4 visits [2.0, 7.0, 2.0, 2.0, 685.0, 4.0, 2.0]  episode_count: 464 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.262, -10.729, -11.111]
Step 705 4 visits [2.0, 7.0, 2.0, 2.0, 686.0, 4.0, 2.0]  episode_count: 464 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.265, -10.729, -11.111]
Step 706 4 visits [2.0, 7.0, 2.0, 2.0, 687.0, 4.0, 2.0]  episode_count: 464 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.267, -10.729, -11.111]
Step 707 4 visits [2.0, 7.0, 2.0, 2.0, 688.0, 4.0, 2.0]  episode_count: 464 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.27, -10.729, -11.111]
Step 708 4 visits [2.0, 7.0, 2.0, 2.0, 689.0, 4.0, 2.0]  episode_count: 467 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.256, -10.729, -11.111]
Step 709 4 visits [2.0, 7.0, 2.0, 2.0, 690.0, 4.0, 2.0]  episode_count: 469 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 710 4 visits [2.0, 7.0, 2.0, 2.0, 691.0, 4.0, 2.0]  episode_count: 469 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.246, -10.729, -11.111]
{"total_number_of_episodes": 470, "number_of_timesteps": 47539, "per_episode_reward": -548.75, "episode_reward_trend_value": 0.27627607592416376, "biggest_recent_change": 7.646134774731195},
Step 711 4 visits [2.0, 7.0, 2.0, 2.0, 692.0, 4.0, 2.0]  episode_count: 470 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.248, -10.729, -11.111]
Step 712 4 visits [2.0, 7.0, 2.0, 2.0, 693.0, 4.0, 2.0]  episode_count: 471 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.251, -10.729, -11.111]
Step 713 4 visits [2.0, 7.0, 2.0, 2.0, 694.0, 4.0, 2.0]  episode_count: 471 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.254, -10.729, -11.111]
Step 714 4 visits [2.0, 7.0, 2.0, 2.0, 695.0, 4.0, 2.0]  episode_count: 471 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.256, -10.729, -11.111]
Step 715 4 visits [2.0, 7.0, 2.0, 2.0, 696.0, 4.0, 2.0]  episode_count: 471 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.243, -10.729, -11.111]
Step 716 4 visits [2.0, 7.0, 2.0, 2.0, 697.0, 4.0, 2.0]  episode_count: 472 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.246, -10.729, -11.111]
Step 717 4 visits [2.0, 7.0, 2.0, 2.0, 698.0, 4.0, 2.0]  episode_count: 474 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.249, -10.729, -11.111]
Step 718 4 visits [2.0, 7.0, 2.0, 2.0, 699.0, 4.0, 2.0]  episode_count: 476 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.251, -10.729, -11.111]
Step 719 4 visits [2.0, 7.0, 2.0, 2.0, 700.0, 4.0, 2.0]  episode_count: 476 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.254, -10.729, -11.111]
Step 720 4 visits [2.0, 7.0, 2.0, 2.0, 701.0, 4.0, 2.0]  episode_count: 477 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.257, -10.729, -11.111]
Step 721 4 visits [2.0, 7.0, 2.0, 2.0, 702.0, 4.0, 2.0]  episode_count: 478 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 722 4 visits [2.0, 7.0, 2.0, 2.0, 703.0, 4.0, 2.0]  episode_count: 478 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.262, -10.729, -11.111]
Step 723 4 visits [2.0, 7.0, 2.0, 2.0, 704.0, 4.0, 2.0]  episode_count: 478 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.249, -10.729, -11.111]
Step 724 4 visits [2.0, 7.0, 2.0, 2.0, 705.0, 4.0, 2.0]  episode_count: 479 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.236, -10.729, -11.111]
{"total_number_of_episodes": 480, "number_of_timesteps": 48384, "per_episode_reward": -548.64, "episode_reward_trend_value": 0.23573469816202533, "biggest_recent_change": 7.646134774731195},
Step 725 4 visits [2.0, 7.0, 2.0, 2.0, 706.0, 4.0, 2.0]  episode_count: 480 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.238, -10.729, -11.111]
Step 726 4 visits [2.0, 7.0, 2.0, 2.0, 707.0, 4.0, 2.0]  episode_count: 480 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.241, -10.729, -11.111]
Step 727 4 visits [2.0, 7.0, 2.0, 2.0, 708.0, 4.0, 2.0]  episode_count: 480 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.228, -10.729, -11.111]
Step 728 4 visits [2.0, 7.0, 2.0, 2.0, 709.0, 4.0, 2.0]  episode_count: 481 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.23, -10.729, -11.111]
Step 729 4 visits [2.0, 7.0, 2.0, 2.0, 710.0, 4.0, 2.0]  episode_count: 482 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.233, -10.729, -11.111]
Step 730 4 visits [2.0, 7.0, 2.0, 2.0, 711.0, 4.0, 2.0]  episode_count: 483 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.22, -10.729, -11.111]
Step 731 4 visits [2.0, 7.0, 2.0, 2.0, 712.0, 4.0, 2.0]  episode_count: 483 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.223, -10.729, -11.111]
Step 732 4 visits [2.0, 7.0, 2.0, 2.0, 713.0, 4.0, 2.0]  episode_count: 486 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.225, -10.729, -11.111]
Step 733 4 visits [2.0, 7.0, 2.0, 2.0, 714.0, 4.0, 2.0]  episode_count: 487 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.212, -10.729, -11.111]
Step 734 4 visits [2.0, 7.0, 2.0, 2.0, 715.0, 4.0, 2.0]  episode_count: 487 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.215, -10.729, -11.111]
Step 735 4 visits [2.0, 7.0, 2.0, 2.0, 716.0, 4.0, 2.0]  episode_count: 487 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.218, -10.729, -11.111]
Step 736 4 visits [2.0, 7.0, 2.0, 2.0, 717.0, 4.0, 2.0]  episode_count: 487 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.205, -10.729, -11.111]
Step 737 4 visits [2.0, 7.0, 2.0, 2.0, 718.0, 4.0, 2.0]  episode_count: 488 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.208, -10.729, -11.111]
Step 738 4 visits [2.0, 7.0, 2.0, 2.0, 719.0, 4.0, 2.0]  episode_count: 488 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.21, -10.729, -11.111]
Step 739 4 visits [2.0, 7.0, 2.0, 2.0, 720.0, 4.0, 2.0]  episode_count: 488 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.213, -10.729, -11.111]
Step 740 4 visits [2.0, 7.0, 2.0, 2.0, 721.0, 4.0, 2.0]  episode_count: 488 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.215, -10.729, -11.111]
{"total_number_of_episodes": 491, "number_of_timesteps": 49434, "per_episode_reward": -546.87, "episode_reward_trend_value": 0.1704930422012075, "biggest_recent_change": 4.571975374982117},
Step 741 4 visits [2.0, 7.0, 2.0, 2.0, 722.0, 4.0, 2.0]  episode_count: 491 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.218, -10.729, -11.111]
Step 742 4 visits [2.0, 7.0, 2.0, 2.0, 723.0, 4.0, 2.0]  episode_count: 493 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.221, -10.729, -11.111]
Step 743 4 visits [2.0, 7.0, 2.0, 2.0, 724.0, 4.0, 2.0]  episode_count: 494 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.223, -10.729, -11.111]
Step 744 4 visits [2.0, 7.0, 2.0, 2.0, 725.0, 4.0, 2.0]  episode_count: 494 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.226, -10.729, -11.111]
Step 745 4 visits [2.0, 7.0, 2.0, 2.0, 726.0, 4.0, 2.0]  episode_count: 494 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.229, -10.729, -11.111]
Step 746 4 visits [2.0, 7.0, 2.0, 2.0, 727.0, 4.0, 2.0]  episode_count: 494 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.231, -10.729, -11.111]
Step 747 4 visits [2.0, 7.0, 2.0, 2.0, 728.0, 4.0, 2.0]  episode_count: 494 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.234, -10.729, -11.111]
Step 748 4 visits [2.0, 7.0, 2.0, 2.0, 729.0, 4.0, 2.0]  episode_count: 495 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.236, -10.729, -11.111]
Step 749 4 visits [2.0, 7.0, 2.0, 2.0, 730.0, 4.0, 2.0]  episode_count: 496 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.239, -10.729, -11.111]
Step 750 4 visits [2.0, 7.0, 2.0, 2.0, 731.0, 4.0, 2.0]  episode_count: 498 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.226, -10.729, -11.111]
Step 751 4 visits [2.0, 7.0, 2.0, 2.0, 732.0, 4.0, 2.0]  episode_count: 498 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.214, -10.729, -11.111]
Step 752 4 visits [2.0, 7.0, 2.0, 2.0, 733.0, 4.0, 2.0]  episode_count: 499 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.216, -10.729, -11.111]
{"total_number_of_episodes": 501, "number_of_timesteps": 50422, "per_episode_reward": -546.78, "episode_reward_trend_value": 0.1206493858888987, "biggest_recent_change": 3.2541668654507703},
Step 753 4 visits [2.0, 7.0, 2.0, 2.0, 734.0, 4.0, 2.0]  episode_count: 501 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.219, -10.729, -11.111]
Step 754 4 visits [2.0, 7.0, 2.0, 2.0, 735.0, 4.0, 2.0]  episode_count: 501 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.221, -10.729, -11.111]
Step 755 4 visits [2.0, 7.0, 2.0, 2.0, 736.0, 4.0, 2.0]  episode_count: 501 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.224, -10.729, -11.111]
Step 756 4 visits [2.0, 7.0, 2.0, 2.0, 737.0, 4.0, 2.0]  episode_count: 501 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.226, -10.729, -11.111]
Step 757 4 visits [2.0, 7.0, 2.0, 2.0, 738.0, 4.0, 2.0]  episode_count: 503 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.229, -10.729, -11.111]
Step 758 4 visits [2.0, 7.0, 2.0, 2.0, 739.0, 4.0, 2.0]  episode_count: 503 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.232, -10.729, -11.111]
Step 759 4 visits [2.0, 7.0, 2.0, 2.0, 740.0, 4.0, 2.0]  episode_count: 505 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.234, -10.729, -11.111]
Step 760 4 visits [2.0, 7.0, 2.0, 2.0, 741.0, 4.0, 2.0]  episode_count: 507 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.237, -10.729, -11.111]
Step 761 4 visits [2.0, 7.0, 2.0, 2.0, 742.0, 4.0, 2.0]  episode_count: 508 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.239, -10.729, -11.111]
Step 762 4 visits [2.0, 7.0, 2.0, 2.0, 743.0, 4.0, 2.0]  episode_count: 508 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.242, -10.729, -11.111]
Step 763 4 visits [2.0, 7.0, 2.0, 2.0, 744.0, 4.0, 2.0]  episode_count: 508 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.244, -10.729, -11.111]
Step 764 4 visits [2.0, 7.0, 2.0, 2.0, 745.0, 4.0, 2.0]  episode_count: 508 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.247, -10.729, -11.111]
Step 765 4 visits [2.0, 7.0, 2.0, 2.0, 746.0, 4.0, 2.0]  episode_count: 508 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.234, -10.729, -11.111]
{"total_number_of_episodes": 511, "number_of_timesteps": 51189, "per_episode_reward": -544.82, "episode_reward_trend_value": 0.11314181977132118, "biggest_recent_change": 3.2541668654507703},
Step 766 4 visits [2.0, 7.0, 2.0, 2.0, 747.0, 4.0, 2.0]  episode_count: 511 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.237, -10.729, -11.111]
Step 767 4 visits [2.0, 7.0, 2.0, 2.0, 748.0, 4.0, 2.0]  episode_count: 511 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.239, -10.729, -11.111]
Step 768 4 visits [2.0, 7.0, 2.0, 2.0, 749.0, 4.0, 2.0]  episode_count: 512 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.242, -10.729, -11.111]
Step 769 4 visits [2.0, 7.0, 2.0, 2.0, 750.0, 4.0, 2.0]  episode_count: 514 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.244, -10.729, -11.111]
Step 770 4 visits [2.0, 7.0, 2.0, 2.0, 751.0, 4.0, 2.0]  episode_count: 515 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.247, -10.729, -11.111]
Step 771 4 visits [2.0, 7.0, 2.0, 2.0, 752.0, 4.0, 2.0]  episode_count: 515 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.249, -10.729, -11.111]
Step 772 4 visits [2.0, 7.0, 2.0, 2.0, 753.0, 4.0, 2.0]  episode_count: 516 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.252, -10.729, -11.111]
Step 773 4 visits [2.0, 7.0, 2.0, 2.0, 754.0, 4.0, 2.0]  episode_count: 516 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.254, -10.729, -11.111]
Step 774 4 visits [2.0, 7.0, 2.0, 2.0, 755.0, 4.0, 2.0]  episode_count: 516 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.242, -10.729, -11.111]
Step 775 4 visits [2.0, 7.0, 2.0, 2.0, 756.0, 4.0, 2.0]  episode_count: 518 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.244, -10.729, -11.111]
Step 776 4 visits [2.0, 7.0, 2.0, 2.0, 757.0, 4.0, 2.0]  episode_count: 519 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.247, -10.729, -11.111]
Step 777 4 visits [2.0, 7.0, 2.0, 2.0, 758.0, 4.0, 2.0]  episode_count: 520 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.249, -10.729, -11.111]
Step 778 4 visits [2.0, 7.0, 2.0, 2.0, 759.0, 4.0, 2.0]  episode_count: 520 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.252, -10.729, -11.111]
{"total_number_of_episodes": 521, "number_of_timesteps": 52015, "per_episode_reward": -541.66, "episode_reward_trend_value": 0.12573445632279773, "biggest_recent_change": 3.2541668654507703},
Step 779 4 visits [2.0, 7.0, 2.0, 2.0, 760.0, 4.0, 2.0]  episode_count: 521 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.254, -10.729, -11.111]
Step 780 4 visits [2.0, 7.0, 2.0, 2.0, 761.0, 4.0, 2.0]  episode_count: 521 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.257, -10.729, -11.111]
Step 781 4 visits [2.0, 7.0, 2.0, 2.0, 762.0, 4.0, 2.0]  episode_count: 522 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 782 4 visits [2.0, 7.0, 2.0, 2.0, 763.0, 4.0, 2.0]  episode_count: 522 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.262, -10.729, -11.111]
Step 783 4 visits [2.0, 7.0, 2.0, 2.0, 764.0, 4.0, 2.0]  episode_count: 523 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.264, -10.729, -11.111]
Step 784 4 visits [2.0, 7.0, 2.0, 2.0, 765.0, 4.0, 2.0]  episode_count: 524 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.252, -10.729, -11.111]
Step 785 4 visits [2.0, 7.0, 2.0, 2.0, 766.0, 4.0, 2.0]  episode_count: 525 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.254, -10.729, -11.111]
Step 786 4 visits [2.0, 7.0, 2.0, 2.0, 767.0, 4.0, 2.0]  episode_count: 525 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.257, -10.729, -11.111]
Step 787 4 visits [2.0, 7.0, 2.0, 2.0, 768.0, 4.0, 2.0]  episode_count: 525 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.245, -10.729, -11.111]
Step 788 4 visits [2.0, 7.0, 2.0, 2.0, 769.0, 4.0, 2.0]  episode_count: 527 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.247, -10.729, -11.111]
Step 789 4 visits [2.0, 7.0, 2.0, 2.0, 770.0, 4.0, 2.0]  episode_count: 528 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.25, -10.729, -11.111]
Step 790 4 visits [2.0, 7.0, 2.0, 2.0, 771.0, 4.0, 2.0]  episode_count: 528 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.252, -10.729, -11.111]
Step 791 4 visits [2.0, 7.0, 2.0, 2.0, 772.0, 4.0, 2.0]  episode_count: 529 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.254, -10.729, -11.111]
Step 792 4 visits [2.0, 7.0, 2.0, 2.0, 773.0, 4.0, 2.0]  episode_count: 529 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.257, -10.729, -11.111]
Step 793 4 visits [2.0, 7.0, 2.0, 2.0, 774.0, 4.0, 2.0]  episode_count: 530 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
{"total_number_of_episodes": 531, "number_of_timesteps": 52993, "per_episode_reward": -535.31, "episode_reward_trend_value": 0.20366200363956627, "biggest_recent_change": 6.34925001100612},
Step 794 4 visits [2.0, 7.0, 2.0, 2.0, 775.0, 4.0, 2.0]  episode_count: 531 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.262, -10.729, -11.111]
Step 795 4 visits [2.0, 7.0, 2.0, 2.0, 776.0, 4.0, 2.0]  episode_count: 532 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.264, -10.729, -11.111]
Step 796 4 visits [2.0, 7.0, 2.0, 2.0, 777.0, 4.0, 2.0]  episode_count: 532 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.266, -10.729, -11.111]
Step 797 4 visits [2.0, 7.0, 2.0, 2.0, 778.0, 4.0, 2.0]  episode_count: 532 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.269, -10.729, -11.111]
Step 798 4 visits [2.0, 7.0, 2.0, 2.0, 779.0, 4.0, 2.0]  episode_count: 532 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.271, -10.729, -11.111]
Step 799 4 visits [2.0, 7.0, 2.0, 2.0, 780.0, 4.0, 2.0]  episode_count: 532 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.273, -10.729, -11.111]
Step 800 4 visits [2.0, 7.0, 2.0, 2.0, 781.0, 4.0, 2.0]  episode_count: 533 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.262, -10.729, -11.111]
Step 801 4 visits [2.0, 7.0, 2.0, 2.0, 782.0, 4.0, 2.0]  episode_count: 533 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.264, -10.729, -11.111]
Step 802 4 visits [2.0, 7.0, 2.0, 2.0, 783.0, 4.0, 2.0]  episode_count: 533 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.252, -10.729, -11.111]
Step 803 4 visits [2.0, 7.0, 2.0, 2.0, 784.0, 4.0, 2.0]  episode_count: 534 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.254, -10.729, -11.111]
Step 804 4 visits [2.0, 7.0, 2.0, 2.0, 785.0, 4.0, 2.0]  episode_count: 538 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.257, -10.729, -11.111]
Step 805 4 visits [2.0, 7.0, 2.0, 2.0, 786.0, 4.0, 2.0]  episode_count: 539 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.245, -10.729, -11.111]
Step 806 4 visits [2.0, 7.0, 2.0, 2.0, 787.0, 4.0, 2.0]  episode_count: 539 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.247, -10.729, -11.111]
Step 807 4 visits [2.0, 7.0, 2.0, 2.0, 788.0, 4.0, 2.0]  episode_count: 539 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.25, -10.729, -11.111]
Step 808 4 visits [2.0, 7.0, 2.0, 2.0, 789.0, 4.0, 2.0]  episode_count: 539 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.252, -10.729, -11.111]
Step 809 4 visits [2.0, 7.0, 2.0, 2.0, 790.0, 4.0, 2.0]  episode_count: 539 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.254, -10.729, -11.111]
Step 810 4 visits [2.0, 7.0, 2.0, 2.0, 791.0, 4.0, 2.0]  episode_count: 539 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.257, -10.729, -11.111]
Step 811 4 visits [2.0, 7.0, 2.0, 2.0, 792.0, 4.0, 2.0]  episode_count: 539 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 812 4 visits [2.0, 7.0, 2.0, 2.0, 793.0, 4.0, 2.0]  episode_count: 539 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.262, -10.729, -11.111]
Step 813 4 visits [2.0, 7.0, 2.0, 2.0, 794.0, 4.0, 2.0]  episode_count: 539 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.264, -10.729, -11.111]
{"total_number_of_episodes": 541, "number_of_timesteps": 54183, "per_episode_reward": -532.34, "episode_reward_trend_value": 0.20049230151175834, "biggest_recent_change": 6.34925001100612},
Step 814 4 visits [2.0, 7.0, 2.0, 2.0, 795.0, 4.0, 2.0]  episode_count: 541 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.266, -10.729, -11.111]
Step 815 4 visits [2.0, 7.0, 2.0, 2.0, 796.0, 4.0, 2.0]  episode_count: 541 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.268, -10.729, -11.111]
Step 816 4 visits [2.0, 7.0, 2.0, 2.0, 797.0, 4.0, 2.0]  episode_count: 543 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.271, -10.729, -11.111]
Step 817 4 visits [2.0, 7.0, 2.0, 2.0, 798.0, 4.0, 2.0]  episode_count: 545 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.273, -10.729, -11.111]
Step 818 4 visits [2.0, 7.0, 2.0, 2.0, 799.0, 4.0, 2.0]  episode_count: 545 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.275, -10.729, -11.111]
Step 819 4 visits [2.0, 7.0, 2.0, 2.0, 800.0, 4.0, 2.0]  episode_count: 545 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.278, -10.729, -11.111]
Step 820 4 visits [2.0, 7.0, 2.0, 2.0, 801.0, 4.0, 2.0]  episode_count: 545 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.28, -10.729, -11.111]
Step 821 4 visits [2.0, 7.0, 2.0, 2.0, 802.0, 4.0, 2.0]  episode_count: 546 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.282, -10.729, -11.111]
Step 822 4 visits [2.0, 7.0, 2.0, 2.0, 803.0, 4.0, 2.0]  episode_count: 546 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.285, -10.729, -11.111]
Step 823 4 visits [2.0, 7.0, 2.0, 2.0, 804.0, 4.0, 2.0]  episode_count: 546 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.287, -10.729, -11.111]
Step 824 4 visits [2.0, 7.0, 2.0, 2.0, 805.0, 4.0, 2.0]  episode_count: 547 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.275, -10.729, -11.111]
Step 825 4 visits [2.0, 7.0, 2.0, 2.0, 806.0, 4.0, 2.0]  episode_count: 547 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.278, -10.729, -11.111]
Step 826 4 visits [2.0, 7.0, 2.0, 2.0, 807.0, 4.0, 2.0]  episode_count: 548 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.28, -10.729, -11.111]
{"total_number_of_episodes": 551, "number_of_timesteps": 55362, "per_episode_reward": -532.02, "episode_reward_trend_value": 0.17177678908680288, "biggest_recent_change": 6.34925001100612},
Step 827 4 visits [2.0, 7.0, 2.0, 2.0, 808.0, 4.0, 2.0]  episode_count: 551 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.282, -10.729, -11.111]
Step 828 4 visits [2.0, 7.0, 2.0, 2.0, 809.0, 4.0, 2.0]  episode_count: 551 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.284, -10.729, -11.111]
Step 829 4 visits [2.0, 7.0, 2.0, 2.0, 810.0, 4.0, 2.0]  episode_count: 552 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.287, -10.729, -11.111]
Step 830 4 visits [2.0, 7.0, 2.0, 2.0, 811.0, 4.0, 2.0]  episode_count: 553 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.289, -10.729, -11.111]
Step 831 4 visits [2.0, 7.0, 2.0, 2.0, 812.0, 4.0, 2.0]  episode_count: 553 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.277, -10.729, -11.111]
Step 832 4 visits [2.0, 7.0, 2.0, 2.0, 813.0, 4.0, 2.0]  episode_count: 554 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.28, -10.729, -11.111]
Step 833 4 visits [2.0, 7.0, 2.0, 2.0, 814.0, 4.0, 2.0]  episode_count: 554 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.268, -10.729, -11.111]
Step 834 4 visits [2.0, 7.0, 2.0, 2.0, 815.0, 4.0, 2.0]  episode_count: 554 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.271, -10.729, -11.111]
Step 835 4 visits [2.0, 7.0, 2.0, 2.0, 816.0, 4.0, 2.0]  episode_count: 554 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.273, -10.729, -11.111]
Step 836 4 visits [2.0, 7.0, 2.0, 2.0, 817.0, 4.0, 2.0]  episode_count: 554 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.275, -10.729, -11.111]
Step 837 4 visits [2.0, 7.0, 2.0, 2.0, 818.0, 4.0, 2.0]  episode_count: 556 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.277, -10.729, -11.111]
Step 838 4 visits [2.0, 7.0, 2.0, 2.0, 819.0, 4.0, 2.0]  episode_count: 556 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.28, -10.729, -11.111]
Step 839 4 visits [2.0, 7.0, 2.0, 2.0, 820.0, 4.0, 2.0]  episode_count: 559 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.282, -10.729, -11.111]
Step 840 4 visits [2.0, 7.0, 2.0, 2.0, 821.0, 4.0, 2.0]  episode_count: 560 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.284, -10.729, -11.111]
{"total_number_of_episodes": 561, "number_of_timesteps": 56326, "per_episode_reward": -527.63, "episode_reward_trend_value": 0.23466274110068447, "biggest_recent_change": 6.34925001100612},
Step 841 4 visits [2.0, 7.0, 2.0, 2.0, 822.0, 4.0, 2.0]  episode_count: 561 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.286, -10.729, -11.111]
Step 842 4 visits [2.0, 7.0, 2.0, 2.0, 823.0, 4.0, 2.0]  episode_count: 561 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.288, -10.729, -11.111]
[-11.111, -10.304, -11.111, -11.111, -9.291, -10.729, -11.111]
Step 844 4 visits [2.0, 7.0, 2.0, 2.0, 825.0, 4.0, 2.0]  episode_count: 561 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.293, -10.729, -11.111]
Step 845 4 visits [2.0, 7.0, 2.0, 2.0, 826.0, 4.0, 2.0]  episode_count: 561 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.295, -10.729, -11.111]
Step 846 4 visits [2.0, 7.0, 2.0, 2.0, 827.0, 4.0, 2.0]  episode_count: 562 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.297, -10.729, -11.111]
Step 847 4 visits [2.0, 7.0, 2.0, 2.0, 828.0, 4.0, 2.0]  episode_count: 562 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.299, -10.729, -11.111]
Step 848 4 visits [2.0, 7.0, 2.0, 2.0, 829.0, 4.0, 2.0]  episode_count: 564 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.302, -10.729, -11.111]
Step 849 4 visits [2.0, 7.0, 2.0, 2.0, 830.0, 4.0, 2.0]  episode_count: 564 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.304, -10.729, -11.111]
Step 850 4 visits [2.0, 7.0, 2.0, 2.0, 831.0, 4.0, 2.0]  episode_count: 565 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.306, -10.729, -11.111]
Step 851 4 visits [2.0, 7.0, 2.0, 2.0, 832.0, 4.0, 2.0]  episode_count: 566 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.308, -10.729, -11.111]
Step 852 4 visits [2.0, 7.0, 2.0, 2.0, 833.0, 4.0, 2.0]  episode_count: 567 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.297, -10.729, -11.111]
Step 853 4 visits [2.0, 7.0, 2.0, 2.0, 834.0, 4.0, 2.0]  episode_count: 568 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.299, -10.729, -11.111]
Step 854 4 visits [2.0, 7.0, 2.0, 2.0, 835.0, 4.0, 2.0]  episode_count: 568 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.301, -10.729, -11.111]
Step 855 4 visits [2.0, 7.0, 2.0, 2.0, 836.0, 4.0, 2.0]  episode_count: 569 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.29, -10.729, -11.111]
Step 856 4 visits [2.0, 7.0, 2.0, 2.0, 837.0, 4.0, 2.0]  episode_count: 569 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.292, -10.729, -11.111]
Step 857 4 visits [2.0, 7.0, 2.0, 2.0, 838.0, 4.0, 2.0]  episode_count: 570 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.281, -10.729, -11.111]
{"total_number_of_episodes": 571, "number_of_timesteps": 57329, "per_episode_reward": -524.69, "episode_reward_trend_value": 0.266176197923288, "biggest_recent_change": 6.34925001100612},
Step 858 4 visits [2.0, 7.0, 2.0, 2.0, 839.0, 4.0, 2.0]  episode_count: 571 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.27, -10.729, -11.111]
Step 859 4 visits [2.0, 7.0, 2.0, 2.0, 840.0, 4.0, 2.0]  episode_count: 572 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.272, -10.729, -11.111]
Step 860 4 visits [2.0, 7.0, 2.0, 2.0, 841.0, 4.0, 2.0]  episode_count: 572 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.275, -10.729, -11.111]
Step 861 4 visits [2.0, 7.0, 2.0, 2.0, 842.0, 4.0, 2.0]  episode_count: 574 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.277, -10.729, -11.111]
Step 862 4 visits [2.0, 7.0, 2.0, 2.0, 843.0, 4.0, 2.0]  episode_count: 574 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.279, -10.729, -11.111]
Step 863 4 visits [2.0, 7.0, 2.0, 2.0, 844.0, 4.0, 2.0]  episode_count: 575 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.281, -10.729, -11.111]
Step 864 4 visits [2.0, 7.0, 2.0, 2.0, 845.0, 4.0, 2.0]  episode_count: 575 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.283, -10.729, -11.111]
Step 865 4 visits [2.0, 7.0, 2.0, 2.0, 846.0, 4.0, 2.0]  episode_count: 575 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.285, -10.729, -11.111]
Step 866 4 visits [2.0, 7.0, 2.0, 2.0, 847.0, 4.0, 2.0]  episode_count: 577 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.274, -10.729, -11.111]
Step 867 4 visits [2.0, 7.0, 2.0, 2.0, 848.0, 4.0, 2.0]  episode_count: 578 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.277, -10.729, -11.111]
Step 868 4 visits [2.0, 7.0, 2.0, 2.0, 849.0, 4.0, 2.0]  episode_count: 578 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.279, -10.729, -11.111]
Step 869 4 visits [2.0, 7.0, 2.0, 2.0, 850.0, 4.0, 2.0]  episode_count: 578 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.281, -10.729, -11.111]
Step 870 4 visits [2.0, 7.0, 2.0, 2.0, 851.0, 4.0, 2.0]  episode_count: 579 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.283, -10.729, -11.111]
{"total_number_of_episodes": 581, "number_of_timesteps": 58235, "per_episode_reward": -519.76, "episode_reward_trend_value": 0.3011686327397772, "biggest_recent_change": 6.34925001100612},
Step 871 4 visits [2.0, 7.0, 2.0, 2.0, 852.0, 4.0, 2.0]  episode_count: 581 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.285, -10.729, -11.111]
Step 872 4 visits [2.0, 7.0, 2.0, 2.0, 853.0, 4.0, 2.0]  episode_count: 581 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.287, -10.729, -11.111]
Step 873 4 visits [2.0, 7.0, 2.0, 2.0, 854.0, 4.0, 2.0]  episode_count: 582 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.29, -10.729, -11.111]
Step 874 4 visits [2.0, 7.0, 2.0, 2.0, 855.0, 4.0, 2.0]  episode_count: 582 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.292, -10.729, -11.111]
Step 875 4 visits [2.0, 7.0, 2.0, 2.0, 856.0, 4.0, 2.0]  episode_count: 582 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.294, -10.729, -11.111]
Step 876 4 visits [2.0, 7.0, 2.0, 2.0, 857.0, 4.0, 2.0]  episode_count: 584 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.296, -10.729, -11.111]
Step 877 4 visits [2.0, 7.0, 2.0, 2.0, 858.0, 4.0, 2.0]  episode_count: 584 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.298, -10.729, -11.111]
Step 878 4 visits [2.0, 7.0, 2.0, 2.0, 859.0, 4.0, 2.0]  episode_count: 585 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.287, -10.729, -11.111]
Step 879 4 visits [2.0, 7.0, 2.0, 2.0, 860.0, 4.0, 2.0]  episode_count: 587 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.289, -10.729, -11.111]
Step 880 4 visits [2.0, 7.0, 2.0, 2.0, 861.0, 4.0, 2.0]  episode_count: 587 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.279, -10.729, -11.111]
Step 881 4 visits [2.0, 7.0, 2.0, 2.0, 862.0, 4.0, 2.0]  episode_count: 588 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.281, -10.729, -11.111]
Step 882 4 visits [2.0, 7.0, 2.0, 2.0, 863.0, 4.0, 2.0]  episode_count: 588 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.283, -10.729, -11.111]
[-11.111, -10.304, -11.111, -11.111, -9.285, -10.729, -11.111]
Step 884 4 visits [2.0, 7.0, 2.0, 2.0, 865.0, 4.0, 2.0]  episode_count: 590 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.287, -10.729, -11.111]
Step 885 4 visits [2.0, 7.0, 2.0, 2.0, 866.0, 4.0, 2.0]  episode_count: 590 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.289, -10.729, -11.111]
Step 886 4 visits [2.0, 7.0, 2.0, 2.0, 867.0, 4.0, 2.0]  episode_count: 590 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.291, -10.729, -11.111]
{"total_number_of_episodes": 591, "number_of_timesteps": 59200, "per_episode_reward": -517.05, "episode_reward_trend_value": 0.3303597093518028, "biggest_recent_change": 6.34925001100612},
Step 887 4 visits [2.0, 7.0, 2.0, 2.0, 868.0, 4.0, 2.0]  episode_count: 591 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.281, -10.729, -11.111]
Step 888 4 visits [2.0, 7.0, 2.0, 2.0, 869.0, 4.0, 2.0]  episode_count: 593 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.283, -10.729, -11.111]
Step 889 4 visits [2.0, 7.0, 2.0, 2.0, 870.0, 4.0, 2.0]  episode_count: 594 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.272, -10.729, -11.111]
Step 890 4 visits [2.0, 7.0, 2.0, 2.0, 871.0, 4.0, 2.0]  episode_count: 594 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.274, -10.729, -11.111]
Step 891 4 visits [2.0, 7.0, 2.0, 2.0, 872.0, 4.0, 2.0]  episode_count: 594 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.263, -10.729, -11.111]
Step 892 4 visits [2.0, 7.0, 2.0, 2.0, 873.0, 4.0, 2.0]  episode_count: 595 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.266, -10.729, -11.111]
Step 893 4 visits [2.0, 7.0, 2.0, 2.0, 874.0, 4.0, 2.0]  episode_count: 595 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.268, -10.729, -11.111]
Step 894 4 visits [2.0, 7.0, 2.0, 2.0, 875.0, 4.0, 2.0]  episode_count: 595 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.27, -10.729, -11.111]
Step 895 4 visits [2.0, 7.0, 2.0, 2.0, 876.0, 4.0, 2.0]  episode_count: 595 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.272, -10.729, -11.111]
Step 896 4 visits [2.0, 7.0, 2.0, 2.0, 877.0, 4.0, 2.0]  episode_count: 597 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.274, -10.729, -11.111]
Step 897 4 visits [2.0, 7.0, 2.0, 2.0, 878.0, 4.0, 2.0]  episode_count: 597 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.263, -10.729, -11.111]
Step 898 4 visits [2.0, 7.0, 2.0, 2.0, 879.0, 4.0, 2.0]  episode_count: 597 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.266, -10.729, -11.111]
Step 899 4 visits [2.0, 7.0, 2.0, 2.0, 880.0, 4.0, 2.0]  episode_count: 597 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.255, -10.729, -11.111]
Step 900 4 visits [2.0, 7.0, 2.0, 2.0, 881.0, 4.0, 2.0]  episode_count: 598 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.257, -10.729, -11.111]
Step 901 4 visits [2.0, 7.0, 2.0, 2.0, 882.0, 4.0, 2.0]  episode_count: 598 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 902 4 visits [2.0, 7.0, 2.0, 2.0, 883.0, 4.0, 2.0]  episode_count: 600 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.249, -10.729, -11.111]
Step 903 4 visits [2.0, 7.0, 2.0, 2.0, 884.0, 4.0, 2.0]  episode_count: 600 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.251, -10.729, -11.111]
{"total_number_of_episodes": 601, "number_of_timesteps": 60321, "per_episode_reward": -515.09, "episode_reward_trend_value": 0.33033049806709747, "biggest_recent_change": 6.34925001100612},
Step 904 4 visits [2.0, 7.0, 2.0, 2.0, 885.0, 4.0, 2.0]  episode_count: 601 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.24, -10.729, -11.111]
Step 905 4 visits [2.0, 7.0, 2.0, 2.0, 886.0, 4.0, 2.0]  episode_count: 601 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.242, -10.729, -11.111]
Step 906 4 visits [2.0, 7.0, 2.0, 2.0, 887.0, 4.0, 2.0]  episode_count: 601 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.232, -10.729, -11.111]
Step 907 4 visits [2.0, 7.0, 2.0, 2.0, 888.0, 4.0, 2.0]  episode_count: 603 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.234, -10.729, -11.111]
Step 908 4 visits [2.0, 7.0, 2.0, 2.0, 889.0, 4.0, 2.0]  episode_count: 603 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.236, -10.729, -11.111]
Step 909 4 visits [2.0, 7.0, 2.0, 2.0, 890.0, 4.0, 2.0]  episode_count: 604 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.238, -10.729, -11.111]
Step 910 4 visits [2.0, 7.0, 2.0, 2.0, 891.0, 4.0, 2.0]  episode_count: 604 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.24, -10.729, -11.111]
Step 911 4 visits [2.0, 7.0, 2.0, 2.0, 892.0, 4.0, 2.0]  episode_count: 604 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.243, -10.729, -11.111]
Step 912 4 visits [2.0, 7.0, 2.0, 2.0, 893.0, 4.0, 2.0]  episode_count: 605 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.245, -10.729, -11.111]
Step 913 4 visits [2.0, 7.0, 2.0, 2.0, 894.0, 4.0, 2.0]  episode_count: 606 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.234, -10.729, -11.111]
Step 914 4 visits [2.0, 7.0, 2.0, 2.0, 895.0, 4.0, 2.0]  episode_count: 607 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.224, -10.729, -11.111]
Step 915 4 visits [2.0, 7.0, 2.0, 2.0, 896.0, 4.0, 2.0]  episode_count: 607 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.226, -10.729, -11.111]
Step 916 4 visits [2.0, 7.0, 2.0, 2.0, 897.0, 4.0, 2.0]  episode_count: 607 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.228, -10.729, -11.111]
Step 917 4 visits [2.0, 7.0, 2.0, 2.0, 898.0, 4.0, 2.0]  episode_count: 608 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.23, -10.729, -11.111]
Step 918 4 visits [2.0, 7.0, 2.0, 2.0, 899.0, 4.0, 2.0]  episode_count: 608 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.232, -10.729, -11.111]
{"total_number_of_episodes": 611, "number_of_timesteps": 61513, "per_episode_reward": -514.06, "episode_reward_trend_value": 0.30664203657646694, "biggest_recent_change": 6.34925001100612},
Step 919 4 visits [2.0, 7.0, 2.0, 2.0, 900.0, 4.0, 2.0]  episode_count: 611 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.234, -10.729, -11.111]
Step 920 4 visits [2.0, 7.0, 2.0, 2.0, 901.0, 4.0, 2.0]  episode_count: 611 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.237, -10.729, -11.111]
Step 921 4 visits [2.0, 7.0, 2.0, 2.0, 902.0, 4.0, 2.0]  episode_count: 612 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.226, -10.729, -11.111]
Step 922 4 visits [2.0, 7.0, 2.0, 2.0, 903.0, 4.0, 2.0]  episode_count: 612 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.216, -10.729, -11.111]
Step 923 4 visits [2.0, 7.0, 2.0, 2.0, 904.0, 4.0, 2.0]  episode_count: 613 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.218, -10.729, -11.111]
Step 924 4 visits [2.0, 7.0, 2.0, 2.0, 905.0, 4.0, 2.0]  episode_count: 614 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.22, -10.729, -11.111]
Step 925 4 visits [2.0, 7.0, 2.0, 2.0, 906.0, 4.0, 2.0]  episode_count: 614 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.222, -10.729, -11.111]
Step 926 4 visits [2.0, 7.0, 2.0, 2.0, 907.0, 4.0, 2.0]  episode_count: 615 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.224, -10.729, -11.111]
Step 927 4 visits [2.0, 7.0, 2.0, 2.0, 908.0, 4.0, 2.0]  episode_count: 615 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.214, -10.729, -11.111]
Step 928 4 visits [2.0, 7.0, 2.0, 2.0, 909.0, 4.0, 2.0]  episode_count: 617 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.216, -10.729, -11.111]
Step 929 4 visits [2.0, 7.0, 2.0, 2.0, 910.0, 4.0, 2.0]  episode_count: 617 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.218, -10.729, -11.111]
Step 930 4 visits [2.0, 7.0, 2.0, 2.0, 911.0, 4.0, 2.0]  episode_count: 617 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.221, -10.729, -11.111]
Step 931 4 visits [2.0, 7.0, 2.0, 2.0, 912.0, 4.0, 2.0]  episode_count: 617 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.223, -10.729, -11.111]
{"total_number_of_episodes": 621, "number_of_timesteps": 62436, "per_episode_reward": -507.72, "episode_reward_trend_value": 0.3065983820170604, "biggest_recent_change": 6.3453211006595325},
Step 932 4 visits [2.0, 7.0, 2.0, 2.0, 913.0, 4.0, 2.0]  episode_count: 621 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.225, -10.729, -11.111]
Step 933 4 visits [2.0, 7.0, 2.0, 2.0, 914.0, 4.0, 2.0]  episode_count: 621 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.227, -10.729, -11.111]
Step 934 4 visits [2.0, 7.0, 2.0, 2.0, 915.0, 4.0, 2.0]  episode_count: 621 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.217, -10.729, -11.111]
Step 935 4 visits [2.0, 7.0, 2.0, 2.0, 916.0, 4.0, 2.0]  episode_count: 621 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.219, -10.729, -11.111]
Step 936 4 visits [2.0, 7.0, 2.0, 2.0, 917.0, 4.0, 2.0]  episode_count: 621 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.221, -10.729, -11.111]
Step 937 4 visits [2.0, 7.0, 2.0, 2.0, 918.0, 4.0, 2.0]  episode_count: 622 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.223, -10.729, -11.111]
Step 938 4 visits [2.0, 7.0, 2.0, 2.0, 919.0, 4.0, 2.0]  episode_count: 622 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.225, -10.729, -11.111]
Step 939 4 visits [2.0, 7.0, 2.0, 2.0, 920.0, 4.0, 2.0]  episode_count: 623 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.227, -10.729, -11.111]
Step 940 4 visits [2.0, 7.0, 2.0, 2.0, 921.0, 4.0, 2.0]  episode_count: 623 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.229, -10.729, -11.111]
Step 941 4 visits [2.0, 7.0, 2.0, 2.0, 922.0, 4.0, 2.0]  episode_count: 624 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.231, -10.729, -11.111]
Step 942 4 visits [2.0, 7.0, 2.0, 2.0, 923.0, 4.0, 2.0]  episode_count: 625 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.233, -10.729, -11.111]
Step 943 4 visits [2.0, 7.0, 2.0, 2.0, 924.0, 4.0, 2.0]  episode_count: 625 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.235, -10.729, -11.111]
Step 944 4 visits [2.0, 7.0, 2.0, 2.0, 925.0, 4.0, 2.0]  episode_count: 626 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.236, -10.729, -11.111]
Step 945 4 visits [2.0, 7.0, 2.0, 2.0, 926.0, 4.0, 2.0]  episode_count: 627 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.238, -10.729, -11.111]
Step 946 4 visits [2.0, 7.0, 2.0, 2.0, 927.0, 4.0, 2.0]  episode_count: 627 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.24, -10.729, -11.111]
Step 947 4 visits [2.0, 7.0, 2.0, 2.0, 928.0, 4.0, 2.0]  episode_count: 628 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.242, -10.729, -11.111]
Step 948 4 visits [2.0, 7.0, 2.0, 2.0, 929.0, 4.0, 2.0]  episode_count: 628 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.244, -10.729, -11.111]
Step 949 4 visits [2.0, 7.0, 2.0, 2.0, 930.0, 4.0, 2.0]  episode_count: 629 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.246, -10.729, -11.111]
Step 950 4 visits [2.0, 7.0, 2.0, 2.0, 931.0, 4.0, 2.0]  episode_count: 629 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.248, -10.729, -11.111]
{"total_number_of_episodes": 631, "number_of_timesteps": 63558, "per_episode_reward": -504.91, "episode_reward_trend_value": 0.3047989573876154, "biggest_recent_change": 6.3453211006595325},
Step 951 4 visits [2.0, 7.0, 2.0, 2.0, 932.0, 4.0, 2.0]  episode_count: 631 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.25, -10.729, -11.111]
Step 952 4 visits [2.0, 7.0, 2.0, 2.0, 933.0, 4.0, 2.0]  episode_count: 631 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.252, -10.729, -11.111]
Step 953 4 visits [2.0, 7.0, 2.0, 2.0, 934.0, 4.0, 2.0]  episode_count: 632 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.254, -10.729, -11.111]
Step 954 4 visits [2.0, 7.0, 2.0, 2.0, 935.0, 4.0, 2.0]  episode_count: 632 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.256, -10.729, -11.111]
Step 955 4 visits [2.0, 7.0, 2.0, 2.0, 936.0, 4.0, 2.0]  episode_count: 632 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.258, -10.729, -11.111]
Step 956 4 visits [2.0, 7.0, 2.0, 2.0, 937.0, 4.0, 2.0]  episode_count: 632 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.248, -10.729, -11.111]
Step 957 4 visits [2.0, 7.0, 2.0, 2.0, 938.0, 4.0, 2.0]  episode_count: 633 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.25, -10.729, -11.111]
Step 958 4 visits [2.0, 7.0, 2.0, 2.0, 939.0, 4.0, 2.0]  episode_count: 634 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.252, -10.729, -11.111]
Step 959 4 visits [2.0, 7.0, 2.0, 2.0, 940.0, 4.0, 2.0]  episode_count: 634 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.254, -10.729, -11.111]
Step 960 4 visits [2.0, 7.0, 2.0, 2.0, 941.0, 4.0, 2.0]  episode_count: 635 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.256, -10.729, -11.111]
Step 961 4 visits [2.0, 7.0, 2.0, 2.0, 942.0, 4.0, 2.0]  episode_count: 636 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.253, -10.729, -11.111]
Step 962 4 visits [2.0, 7.0, 2.0, 2.0, 943.0, 4.0, 2.0]  episode_count: 637 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.255, -10.729, -11.111]
Step 963 4 visits [2.0, 7.0, 2.0, 2.0, 944.0, 4.0, 2.0]  episode_count: 637 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.257, -10.729, -11.111]
Step 964 4 visits [2.0, 7.0, 2.0, 2.0, 945.0, 4.0, 2.0]  episode_count: 637 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 965 4 visits [2.0, 7.0, 2.0, 2.0, 946.0, 4.0, 2.0]  episode_count: 638 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.261, -10.729, -11.111]
Step 966 4 visits [2.0, 7.0, 2.0, 2.0, 947.0, 4.0, 2.0]  episode_count: 638 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.263, -10.729, -11.111]
Step 967 4 visits [2.0, 7.0, 2.0, 2.0, 948.0, 4.0, 2.0]  episode_count: 639 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.265, -10.729, -11.111]
{"total_number_of_episodes": 641, "number_of_timesteps": 64679, "per_episode_reward": -502.37, "episode_reward_trend_value": 0.3294854432991826, "biggest_recent_change": 6.3453211006595325},
Step 968 4 visits [2.0, 7.0, 2.0, 2.0, 949.0, 4.0, 2.0]  episode_count: 641 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.255, -10.729, -11.111]
Step 969 4 visits [2.0, 7.0, 2.0, 2.0, 950.0, 4.0, 2.0]  episode_count: 643 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.257, -10.729, -11.111]
Step 970 4 visits [2.0, 7.0, 2.0, 2.0, 951.0, 4.0, 2.0]  episode_count: 643 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 971 4 visits [2.0, 7.0, 2.0, 2.0, 952.0, 4.0, 2.0]  episode_count: 643 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.249, -10.729, -11.111]
Step 972 4 visits [2.0, 7.0, 2.0, 2.0, 953.0, 4.0, 2.0]  episode_count: 643 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.251, -10.729, -11.111]
Step 973 4 visits [2.0, 7.0, 2.0, 2.0, 954.0, 4.0, 2.0]  episode_count: 643 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.253, -10.729, -11.111]
Step 974 4 visits [2.0, 7.0, 2.0, 2.0, 955.0, 4.0, 2.0]  episode_count: 644 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.255, -10.729, -11.111]
Step 975 4 visits [2.0, 7.0, 2.0, 2.0, 956.0, 4.0, 2.0]  episode_count: 644 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.246, -10.729, -11.111]
Step 976 4 visits [2.0, 7.0, 2.0, 2.0, 957.0, 4.0, 2.0]  episode_count: 644 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.248, -10.729, -11.111]
Step 977 4 visits [2.0, 7.0, 2.0, 2.0, 958.0, 4.0, 2.0]  episode_count: 644 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.249, -10.729, -11.111]
Step 978 4 visits [2.0, 7.0, 2.0, 2.0, 959.0, 4.0, 2.0]  episode_count: 647 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.251, -10.729, -11.111]
Step 979 4 visits [2.0, 7.0, 2.0, 2.0, 960.0, 4.0, 2.0]  episode_count: 649 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.253, -10.729, -11.111]
Step 980 4 visits [2.0, 7.0, 2.0, 2.0, 961.0, 4.0, 2.0]  episode_count: 649 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.255, -10.729, -11.111]
Step 981 4 visits [2.0, 7.0, 2.0, 2.0, 962.0, 4.0, 2.0]  episode_count: 649 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.257, -10.729, -11.111]
Step 982 4 visits [2.0, 7.0, 2.0, 2.0, 963.0, 4.0, 2.0]  episode_count: 649 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.259, -10.729, -11.111]
Step 983 4 visits [2.0, 7.0, 2.0, 2.0, 964.0, 4.0, 2.0]  episode_count: 649 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.261, -10.729, -11.111]
Step 984 4 visits [2.0, 7.0, 2.0, 2.0, 965.0, 4.0, 2.0]  episode_count: 650 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.263, -10.729, -11.111]
Step 985 4 visits [2.0, 7.0, 2.0, 2.0, 966.0, 4.0, 2.0]  episode_count: 650 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.265, -10.729, -11.111]
Step 986 4 visits [2.0, 7.0, 2.0, 2.0, 967.0, 4.0, 2.0]  episode_count: 650 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.267, -10.729, -11.111]
{"total_number_of_episodes": 651, "number_of_timesteps": 65834, "per_episode_reward": -499.41, "episode_reward_trend_value": 0.3135339290501678, "biggest_recent_change": 6.3453211006595325},
Step 987 4 visits [2.0, 7.0, 2.0, 2.0, 968.0, 4.0, 2.0]  episode_count: 651 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.269, -10.729, -11.111]
Step 988 4 visits [2.0, 7.0, 2.0, 2.0, 969.0, 4.0, 2.0]  episode_count: 652 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.271, -10.729, -11.111]
Step 989 4 visits [2.0, 7.0, 2.0, 2.0, 970.0, 4.0, 2.0]  episode_count: 653 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.273, -10.729, -11.111]
Step 990 4 visits [2.0, 7.0, 2.0, 2.0, 971.0, 4.0, 2.0]  episode_count: 653 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.274, -10.729, -11.111]
Step 991 4 visits [2.0, 7.0, 2.0, 2.0, 972.0, 4.0, 2.0]  episode_count: 654 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.276, -10.729, -11.111]
Step 992 4 visits [2.0, 7.0, 2.0, 2.0, 973.0, 4.0, 2.0]  episode_count: 654 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.267, -10.729, -11.111]
Step 993 4 visits [2.0, 7.0, 2.0, 2.0, 974.0, 4.0, 2.0]  episode_count: 654 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.269, -10.729, -11.111]
Step 994 4 visits [2.0, 7.0, 2.0, 2.0, 975.0, 4.0, 2.0]  episode_count: 655 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.271, -10.729, -11.111]
Step 995 4 visits [2.0, 7.0, 2.0, 2.0, 976.0, 4.0, 2.0]  episode_count: 656 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.272, -10.729, -11.111]
Step 996 4 visits [2.0, 7.0, 2.0, 2.0, 977.0, 4.0, 2.0]  episode_count: 657 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.274, -10.729, -11.111]
Step 997 4 visits [2.0, 7.0, 2.0, 2.0, 978.0, 4.0, 2.0]  episode_count: 658 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.276, -10.729, -11.111]
Step 998 4 visits [2.0, 7.0, 2.0, 2.0, 979.0, 4.0, 2.0]  episode_count: 658 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.267, -10.729, -11.111]
Step 999 4 visits [2.0, 7.0, 2.0, 2.0, 980.0, 4.0, 2.0]  episode_count: 659 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.269, -10.729, -11.111]
Step 1000 4 visits [2.0, 7.0, 2.0, 2.0, 981.0, 4.0, 2.0]  episode_count: 659 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.27, -10.729, -11.111]
{"total_number_of_episodes": 661, "number_of_timesteps": 66989, "per_episode_reward": -498.48, "episode_reward_trend_value": 0.29116543187252736, "biggest_recent_change": 6.3453211006595325},
Step 1001 4 visits [2.0, 7.0, 2.0, 2.0, 982.0, 4.0, 2.0]  episode_count: 661 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.272, -10.729, -11.111]
Step 1002 4 visits [2.0, 7.0, 2.0, 2.0, 983.0, 4.0, 2.0]  episode_count: 661 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.274, -10.729, -11.111]
Step 1003 4 visits [2.0, 7.0, 2.0, 2.0, 984.0, 4.0, 2.0]  episode_count: 661 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.265, -10.729, -11.111]
Step 1004 4 visits [2.0, 7.0, 2.0, 2.0, 985.0, 4.0, 2.0]  episode_count: 662 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.267, -10.729, -11.111]
Step 1005 4 visits [2.0, 7.0, 2.0, 2.0, 986.0, 4.0, 2.0]  episode_count: 662 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.269, -10.729, -11.111]
Step 1006 4 visits [2.0, 7.0, 2.0, 2.0, 987.0, 4.0, 2.0]  episode_count: 662 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.27, -10.729, -11.111]
Step 1007 4 visits [2.0, 7.0, 2.0, 2.0, 988.0, 4.0, 2.0]  episode_count: 662 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.272, -10.729, -11.111]
Step 1008 4 visits [2.0, 7.0, 2.0, 2.0, 989.0, 4.0, 2.0]  episode_count: 662 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.274, -10.729, -11.111]
Step 1009 4 visits [2.0, 7.0, 2.0, 2.0, 990.0, 4.0, 2.0]  episode_count: 664 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.276, -10.729, -11.111]
Step 1010 4 visits [2.0, 7.0, 2.0, 2.0, 991.0, 4.0, 2.0]  episode_count: 664 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.267, -10.729, -11.111]
Step 1011 4 visits [2.0, 7.0, 2.0, 2.0, 992.0, 4.0, 2.0]  episode_count: 665 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.268, -10.729, -11.111]
Step 1012 4 visits [2.0, 7.0, 2.0, 2.0, 993.0, 4.0, 2.0]  episode_count: 667 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.27, -10.729, -11.111]
Step 1013 4 visits [2.0, 7.0, 2.0, 2.0, 994.0, 4.0, 2.0]  episode_count: 667 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.272, -10.729, -11.111]
Step 1014 4 visits [2.0, 7.0, 2.0, 2.0, 995.0, 4.0, 2.0]  episode_count: 668 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.274, -10.729, -11.111]
Step 1015 4 visits [2.0, 7.0, 2.0, 2.0, 996.0, 4.0, 2.0]  episode_count: 668 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.276, -10.729, -11.111]
Step 1016 4 visits [2.0, 7.0, 2.0, 2.0, 997.0, 4.0, 2.0]  episode_count: 668 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.267, -10.729, -11.111]
Step 1017 4 visits [2.0, 7.0, 2.0, 2.0, 998.0, 4.0, 2.0]  episode_count: 670 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.268, -10.729, -11.111]
{"total_number_of_episodes": 671, "number_of_timesteps": 68120, "per_episode_reward": -498.14, "episode_reward_trend_value": 0.24019544021472825, "biggest_recent_change": 6.3453211006595325},
Step 1018 4 visits [2.0, 7.0, 2.0, 2.0, 999.0, 4.0, 2.0]  episode_count: 671 q_vals: [-11.111, -10.304, -11.111, -11.111, -9.27, -10.729, -11.111]
Step 1019 4 visits [0.0, 0.0, 0.0, 0.0, 1000.0, 0.0, 0.0]  episode_count: 671 q_vals: [0.0, 0.0, 0.0, 0.0, -inf, 0.0, 0.0]
Step 1020 0 visits [1.0, 0.0, 0.0, 0.0, 1000.0, 0.0, 0.0]  episode_count: 671 q_vals: [-12.8, 0.0, 0.0, 0.0, -inf, 0.0, 0.0]
Step 1021 1 visits [1.0, 1.0, 0.0, 0.0, 1000.0, 0.0, 0.0]  episode_count: 673 q_vals: [-12.8, -12.8, 0.0, 0.0, -inf, 0.0, 0.0]
Step 1022 2 visits [1.0, 1.0, 1.0, 0.0, 1000.0, 0.0, 0.0]  episode_count: 673 q_vals: [-12.8, -12.8, 0.0, 0.0, -inf, 0.0, 0.0]
Step 1023 3 visits [1.0, 1.0, 1.0, 1.0, 1000.0, 0.0, 0.0]  episode_count: 673 q_vals: [-12.8, -12.8, 0.0, -12.8, -inf, 0.0, 0.0]
Step 1024 5 visits [1.0, 1.0, 1.0, 1.0, 1000.0, 1.0, 0.0]  episode_count: 674 q_vals: [-12.8, -12.8, 0.0, -12.8, -inf, -12.8, 0.0]
Step 1025 6 visits [1.0, 1.0, 1.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 674 q_vals: [-12.8, -12.8, 0.0, -12.8, -inf, -12.8, -12.8]
Step 1026 2 visits [1.0, 1.0, 2.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 674 q_vals: [-12.8, -12.8, -6.4, -12.8, -inf, -12.8, -12.8]
Step 1027 2 visits [1.0, 1.0, 3.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 674 q_vals: [-12.8, -12.8, -8.533, -12.8, -inf, -12.8, -12.8]
Step 1028 2 visits [1.0, 1.0, 4.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 674 q_vals: [-12.8, -12.8, -9.6, -12.8, -inf, -12.8, -12.8]
Step 1029 2 visits [1.0, 1.0, 5.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 675 q_vals: [-12.8, -12.8, -10.24, -12.8, -inf, -12.8, -12.8]
Step 1030 2 visits [1.0, 1.0, 6.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 676 q_vals: [-12.8, -12.8, -10.667, -12.8, -inf, -12.8, -12.8]
Step 1031 2 visits [1.0, 1.0, 7.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 676 q_vals: [-12.8, -12.8, -10.971, -12.8, -inf, -12.8, -12.8]
Step 1032 2 visits [1.0, 1.0, 8.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 677 q_vals: [-12.8, -12.8, -11.2, -12.8, -inf, -12.8, -12.8]
Step 1033 2 visits [1.0, 1.0, 9.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 677 q_vals: [-12.8, -12.8, -11.378, -12.8, -inf, -12.8, -12.8]
Step 1034 2 visits [1.0, 1.0, 10.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 678 q_vals: [-12.8, -12.8, -11.52, -12.8, -inf, -12.8, -12.8]
Step 1035 2 visits [1.0, 1.0, 11.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 678 q_vals: [-12.8, -12.8, -10.473, -12.8, -inf, -12.8, -12.8]
Step 1036 2 visits [1.0, 1.0, 12.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 680 q_vals: [-12.8, -12.8, -10.667, -12.8, -inf, -12.8, -12.8]
Step 1037 2 visits [1.0, 1.0, 13.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 680 q_vals: [-12.8, -12.8, -10.831, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 681, "number_of_timesteps": 69424, "per_episode_reward": -419.88, "episode_reward_trend_value": 1.0796684670359387, "biggest_recent_change": 78.26581561586556},
Step 1038 2 visits [1.0, 1.0, 14.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 681 q_vals: [-12.8, -12.8, -10.057, -12.8, -inf, -12.8, -12.8]
Step 1039 2 visits [1.0, 1.0, 15.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 681 q_vals: [-12.8, -12.8, -10.24, -12.8, -inf, -12.8, -12.8]
Step 1040 2 visits [1.0, 1.0, 16.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 682 q_vals: [-12.8, -12.8, -10.4, -12.8, -inf, -12.8, -12.8]
Step 1041 2 visits [1.0, 1.0, 17.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 682 q_vals: [-12.8, -12.8, -9.788, -12.8, -inf, -12.8, -12.8]
Step 1042 2 visits [1.0, 1.0, 18.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 682 q_vals: [-12.8, -12.8, -9.244, -12.8, -inf, -12.8, -12.8]
Step 1043 2 visits [1.0, 1.0, 19.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 682 q_vals: [-12.8, -12.8, -9.432, -12.8, -inf, -12.8, -12.8]
Step 1044 2 visits [1.0, 1.0, 20.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 682 q_vals: [-12.8, -12.8, -9.6, -12.8, -inf, -12.8, -12.8]
Step 1045 2 visits [1.0, 1.0, 21.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 682 q_vals: [-12.8, -12.8, -9.752, -12.8, -inf, -12.8, -12.8]
Step 1046 2 visits [1.0, 1.0, 22.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 685 q_vals: [-12.8, -12.8, -9.891, -12.8, -inf, -12.8, -12.8]
Step 1047 2 visits [1.0, 1.0, 23.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 685 q_vals: [-12.8, -12.8, -9.461, -12.8, -inf, -12.8, -12.8]
Step 1048 2 visits [1.0, 1.0, 24.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 687 q_vals: [-12.8, -12.8, -9.6, -12.8, -inf, -12.8, -12.8]
Step 1049 2 visits [1.0, 1.0, 25.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 688 q_vals: [-12.8, -12.8, -9.728, -12.8, -inf, -12.8, -12.8]
Step 1050 2 visits [1.0, 1.0, 26.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 688 q_vals: [-12.8, -12.8, -9.846, -12.8, -inf, -12.8, -12.8]
Step 1051 2 visits [1.0, 1.0, 27.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 689 q_vals: [-12.8, -12.8, -9.956, -12.8, -inf, -12.8, -12.8]
Step 1052 2 visits [1.0, 1.0, 28.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 689 q_vals: [-12.8, -12.8, -9.6, -12.8, -inf, -12.8, -12.8]
Step 1053 2 visits [1.0, 1.0, 29.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 689 q_vals: [-12.8, -12.8, -9.269, -12.8, -inf, -12.8, -12.8]
Step 1054 2 visits [1.0, 1.0, 30.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 690 q_vals: [-12.8, -12.8, -9.387, -12.8, -inf, -12.8, -12.8]
Step 1055 2 visits [1.0, 1.0, 31.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 690 q_vals: [-12.8, -12.8, -9.084, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 691, "number_of_timesteps": 70522, "per_episode_reward": -418.21, "episode_reward_trend_value": 1.0764951391676676, "biggest_recent_change": 78.26581561586556},
Step 1056 2 visits [1.0, 1.0, 32.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 691 q_vals: [-12.8, -12.8, -9.2, -12.8, -inf, -12.8, -12.8]
Step 1057 2 visits [1.0, 1.0, 33.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 693 q_vals: [-12.8, -12.8, -8.921, -12.8, -inf, -12.8, -12.8]
Step 1058 2 visits [1.0, 1.0, 34.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 694 q_vals: [-12.8, -12.8, -9.035, -12.8, -inf, -12.8, -12.8]
Step 1059 2 visits [1.0, 1.0, 35.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 696 q_vals: [-12.8, -12.8, -9.143, -12.8, -inf, -12.8, -12.8]
Step 1060 2 visits [1.0, 1.0, 36.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 696 q_vals: [-12.8, -12.8, -9.244, -12.8, -inf, -12.8, -12.8]
Step 1061 2 visits [1.0, 1.0, 37.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 696 q_vals: [-12.8, -12.8, -8.995, -12.8, -inf, -12.8, -12.8]
Step 1062 2 visits [1.0, 1.0, 38.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 696 q_vals: [-12.8, -12.8, -9.095, -12.8, -inf, -12.8, -12.8]
Step 1063 2 visits [1.0, 1.0, 39.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 696 q_vals: [-12.8, -12.8, -8.862, -12.8, -inf, -12.8, -12.8]
Step 1064 2 visits [1.0, 1.0, 40.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 697 q_vals: [-12.8, -12.8, -8.96, -12.8, -inf, -12.8, -12.8]
Step 1065 2 visits [1.0, 1.0, 41.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 698 q_vals: [-12.8, -12.8, -9.054, -12.8, -inf, -12.8, -12.8]
Step 1066 2 visits [1.0, 1.0, 42.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 699 q_vals: [-12.8, -12.8, -8.838, -12.8, -inf, -12.8, -12.8]
Step 1067 2 visits [1.0, 1.0, 43.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 699 q_vals: [-12.8, -12.8, -8.633, -12.8, -inf, -12.8, -12.8]
Step 1068 2 visits [1.0, 1.0, 44.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 699 q_vals: [-12.8, -12.8, -8.727, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 701, "number_of_timesteps": 71485, "per_episode_reward": -415.54, "episode_reward_trend_value": 1.0947484282440094, "biggest_recent_change": 78.26581561586556},
Step 1069 2 visits [1.0, 1.0, 45.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 701 q_vals: [-12.8, -12.8, -8.818, -12.8, -inf, -12.8, -12.8]
Step 1070 2 visits [1.0, 1.0, 46.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 702 q_vals: [-12.8, -12.8, -8.904, -12.8, -inf, -12.8, -12.8]
Step 1071 2 visits [1.0, 1.0, 47.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 703 q_vals: [-12.8, -12.8, -8.715, -12.8, -inf, -12.8, -12.8]
Step 1072 2 visits [1.0, 1.0, 48.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 703 q_vals: [-12.8, -12.8, -8.533, -12.8, -inf, -12.8, -12.8]
Step 1073 2 visits [1.0, 1.0, 49.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 703 q_vals: [-12.8, -12.8, -8.62, -12.8, -inf, -12.8, -12.8]
Step 1074 2 visits [1.0, 1.0, 50.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 703 q_vals: [-12.8, -12.8, -8.448, -12.8, -inf, -12.8, -12.8]
Step 1075 2 visits [1.0, 1.0, 51.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 705 q_vals: [-12.8, -12.8, -8.533, -12.8, -inf, -12.8, -12.8]
Step 1076 2 visits [1.0, 1.0, 52.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 705 q_vals: [-12.8, -12.8, -8.615, -12.8, -inf, -12.8, -12.8]
Step 1077 2 visits [1.0, 1.0, 53.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 705 q_vals: [-12.8, -12.8, -8.694, -12.8, -inf, -12.8, -12.8]
Step 1078 2 visits [1.0, 1.0, 54.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 705 q_vals: [-12.8, -12.8, -8.77, -12.8, -inf, -12.8, -12.8]
Step 1079 2 visits [1.0, 1.0, 55.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 707 q_vals: [-12.8, -12.8, -8.844, -12.8, -inf, -12.8, -12.8]
Step 1080 2 visits [1.0, 1.0, 56.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 707 q_vals: [-12.8, -12.8, -8.914, -12.8, -inf, -12.8, -12.8]
Step 1081 2 visits [1.0, 1.0, 57.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 708 q_vals: [-12.8, -12.8, -8.982, -12.8, -inf, -12.8, -12.8]
Step 1082 2 visits [1.0, 1.0, 58.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 709 q_vals: [-12.8, -12.8, -8.828, -12.8, -inf, -12.8, -12.8]
Step 1083 2 visits [1.0, 1.0, 59.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 709 q_vals: [-12.8, -12.8, -8.895, -12.8, -inf, -12.8, -12.8]
Step 1084 2 visits [1.0, 1.0, 60.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 710 q_vals: [-12.8, -12.8, -8.747, -12.8, -inf, -12.8, -12.8]
Step 1085 2 visits [1.0, 1.0, 61.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 710 q_vals: [-12.8, -12.8, -8.603, -12.8, -inf, -12.8, -12.8]
Step 1086 2 visits [1.0, 1.0, 62.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 710 q_vals: [-12.8, -12.8, -8.671, -12.8, -inf, -12.8, -12.8]

Step 1087 2 visits [1.0, 1.0, 63.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 711 q_vals: [-12.8, -12.8, -8.533, -12.8, -inf, -12.8, -12.8]
Step 1088 2 visits [1.0, 1.0, 64.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 711 q_vals: [-12.8, -12.8, -8.6, -12.8, -inf, -12.8, -12.8]
Step 1089 2 visits [1.0, 1.0, 65.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 711 q_vals: [-12.8, -12.8, -8.468, -12.8, -inf, -12.8, -12.8]
Step 1090 2 visits [1.0, 1.0, 66.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 711 q_vals: [-12.8, -12.8, -8.533, -12.8, -inf, -12.8, -12.8]
Step 1091 2 visits [1.0, 1.0, 67.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 712 q_vals: [-12.8, -12.8, -8.597, -12.8, -inf, -12.8, -12.8]
Step 1092 2 visits [1.0, 1.0, 68.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 712 q_vals: [-12.8, -12.8, -8.659, -12.8, -inf, -12.8, -12.8]
Step 1093 2 visits [1.0, 1.0, 69.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 712 q_vals: [-12.8, -12.8, -8.533, -12.8, -inf, -12.8, -12.8]
Step 1094 2 visits [1.0, 1.0, 70.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 712 q_vals: [-12.8, -12.8, -8.594, -12.8, -inf, -12.8, -12.8]
Step 1095 2 visits [1.0, 1.0, 71.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 714 q_vals: [-12.8, -12.8, -8.473, -12.8, -inf, -12.8, -12.8]
Step 1096 2 visits [1.0, 1.0, 72.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 714 q_vals: [-12.8, -12.8, -8.533, -12.8, -inf, -12.8, -12.8]
Step 1097 2 visits [1.0, 1.0, 73.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 714 q_vals: [-12.8, -12.8, -8.592, -12.8, -inf, -12.8, -12.8]
Step 1098 2 visits [1.0, 1.0, 74.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 715 q_vals: [-12.8, -12.8, -8.649, -12.8, -inf, -12.8, -12.8]
Step 1099 2 visits [1.0, 1.0, 75.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 715 q_vals: [-12.8, -12.8, -8.533, -12.8, -inf, -12.8, -12.8]
Step 1100 2 visits [1.0, 1.0, 76.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 716 q_vals: [-12.8, -12.8, -8.421, -12.8, -inf, -12.8, -12.8]
Step 1101 2 visits [1.0, 1.0, 77.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 716 q_vals: [-12.8, -12.8, -8.478, -12.8, -inf, -12.8, -12.8]
Step 1102 2 visits [1.0, 1.0, 78.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 716 q_vals: [-12.8, -12.8, -8.533, -12.8, -inf, -12.8, -12.8]
Step 1103 2 visits [1.0, 1.0, 79.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 716 q_vals: [-12.8, -12.8, -8.587, -12.8, -inf, -12.8, -12.8]
Step 1104 2 visits [1.0, 1.0, 80.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 717 q_vals: [-12.8, -12.8, -8.48, -12.8, -inf, -12.8, -12.8]
Step 1105 2 visits [1.0, 1.0, 81.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 717 q_vals: [-12.8, -12.8, -8.533, -12.8, -inf, -12.8, -12.8]
Step 1106 2 visits [1.0, 1.0, 82.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 718 q_vals: [-12.8, -12.8, -8.429, -12.8, -inf, -12.8, -12.8]
Step 1107 2 visits [1.0, 1.0, 83.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 719 q_vals: [-12.8, -12.8, -8.482, -12.8, -inf, -12.8, -12.8]
Step 1108 2 visits [1.0, 1.0, 84.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 720 q_vals: [-12.8, -12.8, -8.533, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 723, "number_of_timesteps": 74376, "per_episode_reward": -413.47, "episode_reward_trend_value": 1.0160526949858784, "biggest_recent_change": 78.26581561586556},
Step 1109 2 visits [1.0, 1.0, 85.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 723 q_vals: [-12.8, -12.8, -8.584, -12.8, -inf, -12.8, -12.8]
Step 1110 2 visits [1.0, 1.0, 86.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 723 q_vals: [-12.8, -12.8, -8.633, -12.8, -inf, -12.8, -12.8]
Step 1111 2 visits [1.0, 1.0, 87.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 723 q_vals: [-12.8, -12.8, -8.533, -12.8, -inf, -12.8, -12.8]
Step 1112 2 visits [1.0, 1.0, 88.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 723 q_vals: [-12.8, -12.8, -8.582, -12.8, -inf, -12.8, -12.8]
Step 1113 2 visits [1.0, 1.0, 89.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 723 q_vals: [-12.8, -12.8, -8.629, -12.8, -inf, -12.8, -12.8]
Step 1114 2 visits [1.0, 1.0, 90.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 723 q_vals: [-12.8, -12.8, -8.533, -12.8, -inf, -12.8, -12.8]
Step 1115 2 visits [1.0, 1.0, 91.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 724 q_vals: [-12.8, -12.8, -8.58, -12.8, -inf, -12.8, -12.8]
Step 1116 2 visits [1.0, 1.0, 92.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 724 q_vals: [-12.8, -12.8, -8.626, -12.8, -inf, -12.8, -12.8]
Step 1117 2 visits [1.0, 1.0, 93.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 724 q_vals: [-12.8, -12.8, -8.671, -12.8, -inf, -12.8, -12.8]
Step 1118 2 visits [1.0, 1.0, 94.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 724 q_vals: [-12.8, -12.8, -8.691, -12.8, -inf, -12.8, -12.8]
Step 1119 2 visits [1.0, 1.0, 95.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 727 q_vals: [-12.8, -12.8, -8.734, -12.8, -inf, -12.8, -12.8]
Step 1120 2 visits [1.0, 1.0, 96.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 727 q_vals: [-12.8, -12.8, -8.643, -12.8, -inf, -12.8, -12.8]
Step 1121 2 visits [1.0, 1.0, 97.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 728 q_vals: [-12.8, -12.8, -8.554, -12.8, -inf, -12.8, -12.8]
Step 1122 2 visits [1.0, 1.0, 98.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 728 q_vals: [-12.8, -12.8, -8.597, -12.8, -inf, -12.8, -12.8]
Step 1123 2 visits [1.0, 1.0, 99.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 729 q_vals: [-12.8, -12.8, -8.51, -12.8, -inf, -12.8, -12.8]
Step 1124 2 visits [1.0, 1.0, 100.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 729 q_vals: [-12.8, -12.8, -8.553, -12.8, -inf, -12.8, -12.8]
Step 1125 2 visits [1.0, 1.0, 101.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 729 q_vals: [-12.8, -12.8, -8.468, -12.8, -inf, -12.8, -12.8]
Step 1126 2 visits [1.0, 1.0, 102.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 729 q_vals: [-12.8, -12.8, -8.439, -12.8, -inf, -12.8, -12.8]
Step 1127 2 visits [1.0, 1.0, 103.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 729 q_vals: [-12.8, -12.8, -8.481, -12.8, -inf, -12.8, -12.8]
Step 1128 2 visits [1.0, 1.0, 104.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 731 q_vals: [-12.8, -12.8, -8.523, -12.8, -inf, -12.8, -12.8]
Step 1129 2 visits [1.0, 1.0, 105.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 731 q_vals: [-12.8, -12.8, -8.564, -12.8, -inf, -12.8, -12.8]
Step 1130 2 visits [1.0, 1.0, 106.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 732 q_vals: [-12.8, -12.8, -8.603, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 733, "number_of_timesteps": 75607, "per_episode_reward": -411.17, "episode_reward_trend_value": 1.0133360840347545, "biggest_recent_change": 78.26581561586556},
Step 1131 2 visits [1.0, 1.0, 107.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 733 q_vals: [-12.8, -12.8, -8.643, -12.8, -inf, -12.8, -12.8]
Step 1132 2 visits [1.0, 1.0, 108.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 734 q_vals: [-12.8, -12.8, -8.563, -12.8, -inf, -12.8, -12.8]
Step 1133 2 visits [1.0, 1.0, 109.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 734 q_vals: [-12.8, -12.8, -8.602, -12.8, -inf, -12.8, -12.8]
Step 1134 2 visits [1.0, 1.0, 110.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 735 q_vals: [-12.8, -12.8, -8.64, -12.8, -inf, -12.8, -12.8]
Step 1135 2 visits [1.0, 1.0, 111.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 736 q_vals: [-12.8, -12.8, -8.677, -12.8, -inf, -12.8, -12.8]
Step 1136 2 visits [1.0, 1.0, 112.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 736 q_vals: [-12.8, -12.8, -8.6, -12.8, -inf, -12.8, -12.8]
Step 1137 2 visits [1.0, 1.0, 113.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 737 q_vals: [-12.8, -12.8, -8.637, -12.8, -inf, -12.8, -12.8]
Step 1138 2 visits [1.0, 1.0, 114.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 737 q_vals: [-12.8, -12.8, -8.673, -12.8, -inf, -12.8, -12.8]
Step 1139 2 visits [1.0, 1.0, 115.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 737 q_vals: [-12.8, -12.8, -8.709, -12.8, -inf, -12.8, -12.8]
Step 1140 2 visits [1.0, 1.0, 116.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 738 q_vals: [-12.8, -12.8, -8.634, -12.8, -inf, -12.8, -12.8]
Step 1141 2 visits [1.0, 1.0, 117.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 738 q_vals: [-12.8, -12.8, -8.56, -12.8, -inf, -12.8, -12.8]
Step 1142 2 visits [1.0, 1.0, 118.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 738 q_vals: [-12.8, -12.8, -8.596, -12.8, -inf, -12.8, -12.8]
Step 1143 2 visits [1.0, 1.0, 119.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 739 q_vals: [-12.8, -12.8, -8.632, -12.8, -inf, -12.8, -12.8]
Step 1144 2 visits [1.0, 1.0, 120.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 741 q_vals: [-12.8, -12.8, -8.666, -12.8, -inf, -12.8, -12.8]
Step 1145 2 visits [1.0, 1.0, 121.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 742 q_vals: [-12.8, -12.8, -8.595, -12.8, -inf, -12.8, -12.8]
Step 1146 2 visits [1.0, 1.0, 122.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 742 q_vals: [-12.8, -12.8, -8.524, -12.8, -inf, -12.8, -12.8]
Step 1147 2 visits [1.0, 1.0, 123.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 742 q_vals: [-12.8, -12.8, -8.559, -12.8, -inf, -12.8, -12.8]
Step 1148 2 visits [1.0, 1.0, 124.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 742 q_vals: [-12.8, -12.8, -8.49, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 743, "number_of_timesteps": 76750, "per_episode_reward": -407.14, "episode_reward_trend_value": 1.0251536534428465, "biggest_recent_change": 78.26581561586556},
Step 1149 2 visits [1.0, 1.0, 125.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 743 q_vals: [-12.8, -12.8, -8.525, -12.8, -inf, -12.8, -12.8]
Step 1150 2 visits [1.0, 1.0, 126.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 744 q_vals: [-12.8, -12.8, -8.558, -12.8, -inf, -12.8, -12.8]
Step 1151 2 visits [1.0, 1.0, 127.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 745 q_vals: [-12.8, -12.8, -8.491, -12.8, -inf, -12.8, -12.8]
Step 1152 2 visits [1.0, 1.0, 128.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 745 q_vals: [-12.8, -12.8, -8.525, -12.8, -inf, -12.8, -12.8]
Step 1153 2 visits [1.0, 1.0, 129.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 746 q_vals: [-12.8, -12.8, -8.547, -12.8, -inf, -12.8, -12.8]
Step 1154 2 visits [1.0, 1.0, 130.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 747 q_vals: [-12.8, -12.8, -8.579, -12.8, -inf, -12.8, -12.8]
Step 1155 2 visits [1.0, 1.0, 131.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 748 q_vals: [-12.8, -12.8, -8.612, -12.8, -inf, -12.8, -12.8]
Step 1156 2 visits [1.0, 1.0, 132.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 749 q_vals: [-12.8, -12.8, -8.643, -12.8, -inf, -12.8, -12.8]
Step 1157 2 visits [1.0, 1.0, 133.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 749 q_vals: [-12.8, -12.8, -8.664, -12.8, -inf, -12.8, -12.8]
Step 1158 2 visits [1.0, 1.0, 134.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 750 q_vals: [-12.8, -12.8, -8.695, -12.8, -inf, -12.8, -12.8]
Step 1159 2 visits [1.0, 1.0, 135.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 750 q_vals: [-12.8, -12.8, -8.63, -12.8, -inf, -12.8, -12.8]
Step 1160 2 visits [1.0, 1.0, 136.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 750 q_vals: [-12.8, -12.8, -8.567, -12.8, -inf, -12.8, -12.8]
Step 1161 2 visits [1.0, 1.0, 137.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 750 q_vals: [-12.8, -12.8, -8.598, -12.8, -inf, -12.8, -12.8]
Step 1162 2 visits [1.0, 1.0, 138.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 750 q_vals: [-12.8, -12.8, -8.535, -12.8, -inf, -12.8, -12.8]
Step 1163 2 visits [1.0, 1.0, 139.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 750 q_vals: [-12.8, -12.8, -8.566, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 753, "number_of_timesteps": 77902, "per_episode_reward": -404.09, "episode_reward_trend_value": 1.0488229738556634, "biggest_recent_change": 78.26581561586556},
Step 1164 2 visits [1.0, 1.0, 140.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 753 q_vals: [-12.8, -12.8, -8.596, -12.8, -inf, -12.8, -12.8]
Step 1165 2 visits [1.0, 1.0, 141.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 754 q_vals: [-12.8, -12.8, -8.535, -12.8, -inf, -12.8, -12.8]
Step 1166 2 visits [1.0, 1.0, 142.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 754 q_vals: [-12.8, -12.8, -8.565, -12.8, -inf, -12.8, -12.8]
Step 1167 2 visits [1.0, 1.0, 143.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 754 q_vals: [-12.8, -12.8, -8.595, -12.8, -inf, -12.8, -12.8]
Step 1168 2 visits [1.0, 1.0, 144.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 754 q_vals: [-12.8, -12.8, -8.624, -12.8, -inf, -12.8, -12.8]
Step 1169 2 visits [1.0, 1.0, 145.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 755 q_vals: [-12.8, -12.8, -8.653, -12.8, -inf, -12.8, -12.8]
Step 1170 2 visits [1.0, 1.0, 146.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 756 q_vals: [-12.8, -12.8, -8.681, -12.8, -inf, -12.8, -12.8]
Step 1171 2 visits [1.0, 1.0, 147.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 757 q_vals: [-12.8, -12.8, -8.709, -12.8, -inf, -12.8, -12.8]
 1172 2 visits [1.0, 1.0, 148.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 757 q_vals: [-12.8, -12.8, -8.737, -12.8, -inf, -12.8, -12.8]
Step 1173 2 visits [1.0, 1.0, 149.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 757 q_vals: [-12.8, -12.8, -8.678, -12.8, -inf, -12.8, -12.8]
Step 1174 2 visits [1.0, 1.0, 150.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 758 q_vals: [-12.8, -12.8, -8.706, -12.8, -inf, -12.8, -12.8]
Step 1175 2 visits [1.0, 1.0, 151.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 758 q_vals: [-12.8, -12.8, -8.648, -12.8, -inf, -12.8, -12.8]
Step 1176 2 visits [1.0, 1.0, 152.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 758 q_vals: [-12.8, -12.8, -8.676, -12.8, -inf, -12.8, -12.8]
Step 1177 2 visits [1.0, 1.0, 153.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 758 q_vals: [-12.8, -12.8, -8.619, -12.8, -inf, -12.8, -12.8]
Step 1178 2 visits [1.0, 1.0, 154.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 758 q_vals: [-12.8, -12.8, -8.646, -12.8, -inf, -12.8, -12.8]
Step 1179 2 visits [1.0, 1.0, 155.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 759 q_vals: [-12.8, -12.8, -8.673, -12.8, -inf, -12.8, -12.8]
Step 1180 2 visits [1.0, 1.0, 156.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 761 q_vals: [-12.8, -12.8, -8.699, -12.8, -inf, -12.8, -12.8]
Step 1181 2 visits [1.0, 1.0, 157.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 762 q_vals: [-12.8, -12.8, -8.725, -12.8, -inf, -12.8, -12.8]
Step 1182 2 visits [1.0, 1.0, 158.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 762 q_vals: [-12.8, -12.8, -8.737, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 763, "number_of_timesteps": 79175, "per_episode_reward": -402.85, "episode_reward_trend_value": 1.0588699429190078, "biggest_recent_change": 78.26581561586556},
Step 1183 2 visits [1.0, 1.0, 159.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 763 q_vals: [-12.8, -12.8, -8.763, -12.8, -inf, -12.8, -12.8]
Step 1184 2 visits [1.0, 1.0, 160.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 763 q_vals: [-12.8, -12.8, -8.788, -12.8, -inf, -12.8, -12.8]
Step 1185 2 visits [1.0, 1.0, 161.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 763 q_vals: [-12.8, -12.8, -8.813, -12.8, -inf, -12.8, -12.8]
Step 1186 2 visits [1.0, 1.0, 162.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 764 q_vals: [-12.8, -12.8, -8.759, -12.8, -inf, -12.8, -12.8]
Step 1187 2 visits [1.0, 1.0, 163.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 764 q_vals: [-12.8, -12.8, -8.784, -12.8, -inf, -12.8, -12.8]
Step 1188 2 visits [1.0, 1.0, 164.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 765 q_vals: [-12.8, -12.8, -8.808, -12.8, -inf, -12.8, -12.8]
Step 1189 2 visits [1.0, 1.0, 165.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 766 q_vals: [-12.8, -12.8, -8.832, -12.8, -inf, -12.8, -12.8]
Step 1190 2 visits [1.0, 1.0, 166.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 766 q_vals: [-12.8, -12.8, -8.856, -12.8, -inf, -12.8, -12.8]
Step 1191 2 visits [1.0, 1.0, 167.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 767 q_vals: [-12.8, -12.8, -8.803, -12.8, -inf, -12.8, -12.8]
Step 1192 2 visits [1.0, 1.0, 168.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 767 q_vals: [-12.8, -12.8, -8.751, -12.8, -inf, -12.8, -12.8]
Step 1193 2 visits [1.0, 1.0, 169.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 767 q_vals: [-12.8, -12.8, -8.775, -12.8, -inf, -12.8, -12.8]
Step 1194 2 visits [1.0, 1.0, 170.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 768 q_vals: [-12.8, -12.8, -8.723, -12.8, -inf, -12.8, -12.8]
Step 1195 2 visits [1.0, 1.0, 171.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 768 q_vals: [-12.8, -12.8, -8.672, -12.8, -inf, -12.8, -12.8]
Step 1196 2 visits [1.0, 1.0, 172.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 769 q_vals: [-12.8, -12.8, -8.622, -12.8, -inf, -12.8, -12.8]
Step 1197 2 visits [1.0, 1.0, 173.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 770 q_vals: [-12.8, -12.8, -8.646, -12.8, -inf, -12.8, -12.8]
Step 1198 2 visits [1.0, 1.0, 174.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 770 q_vals: [-12.8, -12.8, -8.67, -12.8, -inf, -12.8, -12.8]
Step 1199 2 visits [1.0, 1.0, 175.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 771 q_vals: [-12.8, -12.8, -8.693, -12.8, -inf, -12.8, -12.8]
Step 1200 2 visits [1.0, 1.0, 176.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 771 q_vals: [-12.8, -12.8, -8.644, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 774, "number_of_timesteps": 80532, "per_episode_reward": -403.18, "episode_reward_trend_value": 0.1854985015985095, "biggest_recent_change": 4.022328449359861},
Step 1201 2 visits [1.0, 1.0, 177.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 774 q_vals: [-12.8, -12.8, -8.667, -12.8, -inf, -12.8, -12.8]
Step 1202 2 visits [1.0, 1.0, 178.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 774 q_vals: [-12.8, -12.8, -8.691, -12.8, -inf, -12.8, -12.8]
Step 1203 2 visits [1.0, 1.0, 179.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 775 q_vals: [-12.8, -12.8, -8.642, -12.8, -inf, -12.8, -12.8]
Step 1204 2 visits [1.0, 1.0, 180.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 775 q_vals: [-12.8, -12.8, -8.665, -12.8, -inf, -12.8, -12.8]
Step 1205 2 visits [1.0, 1.0, 181.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 775 q_vals: [-12.8, -12.8, -8.617, -12.8, -inf, -12.8, -12.8]
Step 1206 2 visits [1.0, 1.0, 182.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 775 q_vals: [-12.8, -12.8, -8.64, -12.8, -inf, -12.8, -12.8]
Step 1207 2 visits [1.0, 1.0, 183.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 775 q_vals: [-12.8, -12.8, -8.663, -12.8, -inf, -12.8, -12.8]
Step 1208 2 visits [1.0, 1.0, 184.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 775 q_vals: [-12.8, -12.8, -8.685, -12.8, -inf, -12.8, -12.8]
Step 1209 2 visits [1.0, 1.0, 185.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 777 q_vals: [-12.8, -12.8, -8.638, -12.8, -inf, -12.8, -12.8]
Step 1210 2 visits [1.0, 1.0, 186.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 778 q_vals: [-12.8, -12.8, -8.661, -12.8, -inf, -12.8, -12.8]
Step 1211 2 visits [1.0, 1.0, 187.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 778 q_vals: [-12.8, -12.8, -8.683, -12.8, -inf, -12.8, -12.8]
Step 1212 2 visits [1.0, 1.0, 188.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 779 q_vals: [-12.8, -12.8, -8.705, -12.8, -inf, -12.8, -12.8]
Step 1213 2 visits [1.0, 1.0, 189.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 779 q_vals: [-12.8, -12.8, -8.727, -12.8, -inf, -12.8, -12.8]
Step 1214 2 visits [1.0, 1.0, 190.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 780 q_vals: [-12.8, -12.8, -8.681, -12.8, -inf, -12.8, -12.8]
Step 1215 2 visits [1.0, 1.0, 191.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 780 q_vals: [-12.8, -12.8, -8.635, -12.8, -inf, -12.8, -12.8]
Step 1216 2 visits [1.0, 1.0, 192.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 780 q_vals: [-12.8, -12.8, -8.657, -12.8, -inf, -12.8, -12.8]
Step 1217 2 visits [1.0, 1.0, 193.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 782 q_vals: [-12.8, -12.8, -8.678, -12.8, -inf, -12.8, -12.8]
Step 1218 2 visits [1.0, 1.0, 194.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 782 q_vals: [-12.8, -12.8, -8.7, -12.8, -inf, -12.8, -12.8]
Step 1219 2 visits [1.0, 1.0, 195.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 783 q_vals: [-12.8, -12.8, -8.721, -12.8, -inf, -12.8, -12.8]
Step 1220 2 visits [1.0, 1.0, 196.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 783 q_vals: [-12.8, -12.8, -8.676, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 786, "number_of_timesteps": 81851, "per_episode_reward": -399.4, "episode_reward_trend_value": 0.20896408288361829, "biggest_recent_change": 4.022328449359861},
Step 1221 2 visits [1.0, 1.0, 197.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 786 q_vals: [-12.8, -12.8, -8.697, -12.8, -inf, -12.8, -12.8]
Step 1222 2 visits [1.0, 1.0, 198.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 786 q_vals: [-12.8, -12.8, -8.653, -12.8, -inf, -12.8, -12.8]
Step 1223 2 visits [1.0, 1.0, 199.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 786 q_vals: [-12.8, -12.8, -8.674, -12.8, -inf, -12.8, -12.8]
Step 1224 2 visits [1.0, 1.0, 200.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 786 q_vals: [-12.8, -12.8, -8.695, -12.8, -inf, -12.8, -12.8]
Step 1225 2 visits [1.0, 1.0, 201.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 786 q_vals: [-12.8, -12.8, -8.715, -12.8, -inf, -12.8, -12.8]
Step 1226 2 visits [1.0, 1.0, 202.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 786 q_vals: [-12.8, -12.8, -8.735, -12.8, -inf, -12.8, -12.8]
Step 1227 2 visits [1.0, 1.0, 203.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 788 q_vals: [-12.8, -12.8, -8.755, -12.8, -inf, -12.8, -12.8]
Step 1228 2 visits [1.0, 1.0, 204.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 790 q_vals: [-12.8, -12.8, -8.775, -12.8, -inf, -12.8, -12.8]
Step 1229 2 visits [1.0, 1.0, 205.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 791 q_vals: [-12.8, -12.8, -8.795, -12.8, -inf, -12.8, -12.8]
Step 1230 2 visits [1.0, 1.0, 206.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 791 q_vals: [-12.8, -12.8, -8.814, -12.8, -inf, -12.8, -12.8]
Step 1231 2 visits [1.0, 1.0, 207.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 792 q_vals: [-12.8, -12.8, -8.833, -12.8, -inf, -12.8, -12.8]
Step 1232 2 visits [1.0, 1.0, 208.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 792 q_vals: [-12.8, -12.8, -8.791, -12.8, -inf, -12.8, -12.8]
Step 1233 2 visits [1.0, 1.0, 209.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 793 q_vals: [-12.8, -12.8, -8.749, -12.8, -inf, -12.8, -12.8]
Step 1234 2 visits [1.0, 1.0, 210.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 793 q_vals: [-12.8, -12.8, -8.707, -12.8, -inf, -12.8, -12.8]
Step 1235 2 visits [1.0, 1.0, 211.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 793 q_vals: [-12.8, -12.8, -8.666, -12.8, -inf, -12.8, -12.8]
Step 1236 2 visits [1.0, 1.0, 212.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 793 q_vals: [-12.8, -12.8, -8.625, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 797, "number_of_timesteps": 82931, "per_episode_reward": -399.42, "episode_reward_trend_value": 0.1790449691887545, "biggest_recent_change": 4.022328449359861},
Step 1237 2 visits [1.0, 1.0, 213.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 797 q_vals: [-12.8, -12.8, -8.645, -12.8, -inf, -12.8, -12.8]
Step 1238 2 visits [1.0, 1.0, 214.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 797 q_vals: [-12.8, -12.8, -8.604, -12.8, -inf, -12.8, -12.8]
Step 1239 2 visits [1.0, 1.0, 215.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 797 q_vals: [-12.8, -12.8, -8.624, -12.8, -inf, -12.8, -12.8]
Step 1240 2 visits [1.0, 1.0, 216.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 797 q_vals: [-12.8, -12.8, -8.643, -12.8, -inf, -12.8, -12.8]
Step 1241 2 visits [1.0, 1.0, 217.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 798 q_vals: [-12.8, -12.8, -8.662, -12.8, -inf, -12.8, -12.8]
Step 1242 2 visits [1.0, 1.0, 218.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 798 q_vals: [-12.8, -12.8, -8.681, -12.8, -inf, -12.8, -12.8]
Step 1243 2 visits [1.0, 1.0, 219.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 800 q_vals: [-12.8, -12.8, -8.7, -12.8, -inf, -12.8, -12.8]
Step 1244 2 visits [1.0, 1.0, 220.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 800 q_vals: [-12.8, -12.8, -8.661, -12.8, -inf, -12.8, -12.8]
Step 1245 2 visits [1.0, 1.0, 221.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 801 q_vals: [-12.8, -12.8, -8.679, -12.8, -inf, -12.8, -12.8]
Step 1246 2 visits [1.0, 1.0, 222.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 803 q_vals: [-12.8, -12.8, -8.64, -12.8, -inf, -12.8, -12.8]
Step 1247 2 visits [1.0, 1.0, 223.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 804 q_vals: [-12.8, -12.8, -8.601, -12.8, -inf, -12.8, -12.8]
Step 1248 2 visits [1.0, 1.0, 224.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 804 q_vals: [-12.8, -12.8, -8.62, -12.8, -inf, -12.8, -12.8]
Step 1249 2 visits [1.0, 1.0, 225.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 804 q_vals: [-12.8, -12.8, -8.639, -12.8, -inf, -12.8, -12.8]
Step 1250 2 visits [1.0, 1.0, 226.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 804 q_vals: [-12.8, -12.8, -8.657, -12.8, -inf, -12.8, -12.8]
Step 1251 2 visits [1.0, 1.0, 227.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 804 q_vals: [-12.8, -12.8, -8.675, -12.8, -inf, -12.8, -12.8]
Step 1252 2 visits [1.0, 1.0, 228.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 805 q_vals: [-12.8, -12.8, -8.637, -12.8, -inf, -12.8, -12.8]
Step 1253 2 visits [1.0, 1.0, 229.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 806 q_vals: [-12.8, -12.8, -8.6, -12.8, -inf, -12.8, -12.8]
Step 1254 2 visits [1.0, 1.0, 230.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 806 q_vals: [-12.8, -12.8, -8.618, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 809, "number_of_timesteps": 84109, "per_episode_reward": -400.44, "episode_reward_trend_value": 0.1545586614813538, "biggest_recent_change": 4.022328449359861},
Step 1255 2 visits [1.0, 1.0, 231.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 809 q_vals: [-12.8, -12.8, -8.636, -12.8, -inf, -12.8, -12.8]
Step 1256 2 visits [1.0, 1.0, 232.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 809 q_vals: [-12.8, -12.8, -8.654, -12.8, -inf, -12.8, -12.8]
Step 1257 2 visits [1.0, 1.0, 233.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 809 q_vals: [-12.8, -12.8, -8.672, -12.8, -inf, -12.8, -12.8]
Step 1258 2 visits [1.0, 1.0, 234.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 809 q_vals: [-12.8, -12.8, -8.689, -12.8, -inf, -12.8, -12.8]
Step 1259 2 visits [1.0, 1.0, 235.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 810 q_vals: [-12.8, -12.8, -8.707, -12.8, -inf, -12.8, -12.8]
Step 1260 2 visits [1.0, 1.0, 236.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 810 q_vals: [-12.8, -12.8, -8.724, -12.8, -inf, -12.8, -12.8]
Step 1261 2 visits [1.0, 1.0, 237.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 812 q_vals: [-12.8, -12.8, -8.741, -12.8, -inf, -12.8, -12.8]
Step 1262 2 visits [1.0, 1.0, 238.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 812 q_vals: [-12.8, -12.8, -8.758, -12.8, -inf, -12.8, -12.8]
Step 1263 2 visits [1.0, 1.0, 239.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 815 q_vals: [-12.8, -12.8, -8.722, -12.8, -inf, -12.8, -12.8]
Step 1264 2 visits [1.0, 1.0, 240.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 815 q_vals: [-12.8, -12.8, -8.739, -12.8, -inf, -12.8, -12.8]
Step 1265 2 visits [1.0, 1.0, 241.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 816 q_vals: [-12.8, -12.8, -8.756, -12.8, -inf, -12.8, -12.8]
Step 1266 2 visits [1.0, 1.0, 242.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 816 q_vals: [-12.8, -12.8, -8.772, -12.8, -inf, -12.8, -12.8]
Step 1267 2 visits [1.0, 1.0, 243.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 816 q_vals: [-12.8, -12.8, -8.789, -12.8, -inf, -12.8, -12.8]
Step 1268 2 visits [1.0, 1.0, 244.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 816 q_vals: [-12.8, -12.8, -8.805, -12.8, -inf, -12.8, -12.8]
Step 1269 2 visits [1.0, 1.0, 245.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 816 q_vals: [-12.8, -12.8, -8.822, -12.8, -inf, -12.8, -12.8]
Step 1270 2 visits [1.0, 1.0, 246.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 816 q_vals: [-12.8, -12.8, -8.838, -12.8, -inf, -12.8, -12.8]
Step 1271 2 visits [1.0, 1.0, 247.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 816 q_vals: [-12.8, -12.8, -8.854, -12.8, -inf, -12.8, -12.8]
Step 1272 2 visits [1.0, 1.0, 248.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 817 q_vals: [-12.8, -12.8, -8.87, -12.8, -inf, -12.8, -12.8]
Step 1273 2 visits [1.0, 1.0, 249.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 817 q_vals: [-12.8, -12.8, -8.886, -12.8, -inf, -12.8, -12.8]
Step 1274 2 visits [1.0, 1.0, 250.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 818 q_vals: [-12.8, -12.8, -8.901, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 819, "number_of_timesteps": 85097, "per_episode_reward": -399.93, "episode_reward_trend_value": 0.15040516805295914, "biggest_recent_change": 4.022328449359861},
Step 1275 2 visits [1.0, 1.0, 251.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 819 q_vals: [-12.8, -12.8, -8.866, -12.8, -inf, -12.8, -12.8]
Step 1276 2 visits [1.0, 1.0, 252.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 819 q_vals: [-12.8, -12.8, -8.881, -12.8, -inf, -12.8, -12.8]
Step 1277 2 visits [1.0, 1.0, 253.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 820 q_vals: [-12.8, -12.8, -8.897, -12.8, -inf, -12.8, -12.8]
Step 1278 2 visits [1.0, 1.0, 254.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 821 q_vals: [-12.8, -12.8, -8.912, -12.8, -inf, -12.8, -12.8]
Step 1279 2 visits [1.0, 1.0, 255.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 821 q_vals: [-12.8, -12.8, -8.928, -12.8, -inf, -12.8, -12.8]
Step 1280 2 visits [1.0, 1.0, 256.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 821 q_vals: [-12.8, -12.8, -8.893, -12.8, -inf, -12.8, -12.8]
Step 1281 2 visits [1.0, 1.0, 257.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 823 q_vals: [-12.8, -12.8, -8.908, -12.8, -inf, -12.8, -12.8]
Step 1282 2 visits [1.0, 1.0, 258.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 823 q_vals: [-12.8, -12.8, -8.923, -12.8, -inf, -12.8, -12.8]
Step 1283 2 visits [1.0, 1.0, 259.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 824 q_vals: [-12.8, -12.8, -8.938, -12.8, -inf, -12.8, -12.8]
Step 1284 2 visits [1.0, 1.0, 260.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 824 q_vals: [-12.8, -12.8, -8.953, -12.8, -inf, -12.8, -12.8]
Step 1285 2 visits [1.0, 1.0, 261.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 826 q_vals: [-12.8, -12.8, -8.967, -12.8, -inf, -12.8, -12.8]
Step 1286 2 visits [1.0, 1.0, 262.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 826 q_vals: [-12.8, -12.8, -8.982, -12.8, -inf, -12.8, -12.8]
Step 1287 2 visits [1.0, 1.0, 263.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 826 q_vals: [-12.8, -12.8, -8.997, -12.8, -inf, -12.8, -12.8]
Step 1288 2 visits [1.0, 1.0, 264.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 826 q_vals: [-12.8, -12.8, -9.011, -12.8, -inf, -12.8, -12.8]
Step 1289 2 visits [1.0, 1.0, 265.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 828 q_vals: [-12.8, -12.8, -9.025, -12.8, -inf, -12.8, -12.8]
Step 1290 2 visits [1.0, 1.0, 266.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 828 q_vals: [-12.8, -12.8, -8.991, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 829, "number_of_timesteps": 86402, "per_episode_reward": -398.24, "episode_reward_trend_value": 0.14364102088012234, "biggest_recent_change": 4.022328449359861},
Step 1291 2 visits [1.0, 1.0, 267.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 829 q_vals: [-12.8, -12.8, -9.006, -12.8, -inf, -12.8, -12.8]
Step 1292 2 visits [1.0, 1.0, 268.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 831 q_vals: [-12.8, -12.8, -9.02, -12.8, -inf, -12.8, -12.8]
Step 1293 2 visits [1.0, 1.0, 269.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 832 q_vals: [-12.8, -12.8, -8.986, -12.8, -inf, -12.8, -12.8]
Step 1294 2 visits [1.0, 1.0, 270.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 832 q_vals: [-12.8, -12.8, -9.0, -12.8, -inf, -12.8, -12.8]
Step 1295 2 visits [1.0, 1.0, 271.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 832 q_vals: [-12.8, -12.8, -8.967, -12.8, -inf, -12.8, -12.8]
Step 1296 2 visits [1.0, 1.0, 272.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 832 q_vals: [-12.8, -12.8, -8.934, -12.8, -inf, -12.8, -12.8]
Step 1297 2 visits [1.0, 1.0, 273.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 833 q_vals: [-12.8, -12.8, -8.948, -12.8, -inf, -12.8, -12.8]
Step 1298 2 visits [1.0, 1.0, 274.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 833 q_vals: [-12.8, -12.8, -8.962, -12.8, -inf, -12.8, -12.8]
Step 1299 2 visits [1.0, 1.0, 275.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 834 q_vals: [-12.8, -12.8, -8.976, -12.8, -inf, -12.8, -12.8]
Step 1300 2 visits [1.0, 1.0, 276.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 835 q_vals: [-12.8, -12.8, -8.944, -12.8, -inf, -12.8, -12.8]
Step 1301 2 visits [1.0, 1.0, 277.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 836 q_vals: [-12.8, -12.8, -8.958, -12.8, -inf, -12.8, -12.8]
Step 1302 2 visits [1.0, 1.0, 278.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 837 q_vals: [-12.8, -12.8, -8.972, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 839, "number_of_timesteps": 87403, "per_episode_reward": -397.65, "episode_reward_trend_value": 0.10553799028107531, "biggest_recent_change": 3.7848985111287448},
Step 1303 2 visits [1.0, 1.0, 279.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 839 q_vals: [-12.8, -12.8, -8.985, -12.8, -inf, -12.8, -12.8]
Step 1304 2 visits [1.0, 1.0, 280.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 839 q_vals: [-12.8, -12.8, -8.953, -12.8, -inf, -12.8, -12.8]
Step 1305 2 visits [1.0, 1.0, 281.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 840 q_vals: [-12.8, -12.8, -8.967, -12.8, -inf, -12.8, -12.8]
Step 1306 2 visits [1.0, 1.0, 282.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 840 q_vals: [-12.8, -12.8, -8.935, -12.8, -inf, -12.8, -12.8]
Step 1307 2 visits [1.0, 1.0, 283.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 840 q_vals: [-12.8, -12.8, -8.904, -12.8, -inf, -12.8, -12.8]
Step 1308 2 visits [1.0, 1.0, 284.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 841 q_vals: [-12.8, -12.8, -8.917, -12.8, -inf, -12.8, -12.8]
Step 1309 2 visits [1.0, 1.0, 285.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 841 q_vals: [-12.8, -12.8, -8.931, -12.8, -inf, -12.8, -12.8]
Step 1310 2 visits [1.0, 1.0, 286.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 841 q_vals: [-12.8, -12.8, -8.944, -12.8, -inf, -12.8, -12.8]
Step 1311 2 visits [1.0, 1.0, 287.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 841 q_vals: [-12.8, -12.8, -8.958, -12.8, -inf, -12.8, -12.8]
Step 1312 2 visits [1.0, 1.0, 288.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 842 q_vals: [-12.8, -12.8, -8.971, -12.8, -inf, -12.8, -12.8]
Step 1313 2 visits [1.0, 1.0, 289.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 843 q_vals: [-12.8, -12.8, -8.984, -12.8, -inf, -12.8, -12.8]
Step 1314 2 visits [1.0, 1.0, 290.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 844 q_vals: [-12.8, -12.8, -8.981, -12.8, -inf, -12.8, -12.8]
Step 1315 2 visits [1.0, 1.0, 291.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 845 q_vals: [-12.8, -12.8, -8.95, -12.8, -inf, -12.8, -12.8]
Step 1316 2 visits [1.0, 1.0, 292.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 846 q_vals: [-12.8, -12.8, -8.963, -12.8, -inf, -12.8, -12.8]
Step 1317 2 visits [1.0, 1.0, 293.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 847 q_vals: [-12.8, -12.8, -8.976, -12.8, -inf, -12.8, -12.8]
Step 1318 2 visits [1.0, 1.0, 294.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 847 q_vals: [-12.8, -12.8, -8.989, -12.8, -inf, -12.8, -12.8]
Step 1319 2 visits [1.0, 1.0, 295.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 847 q_vals: [-12.8, -12.8, -9.002, -12.8, -inf, -12.8, -12.8]
Step 1320 2 visits [1.0, 1.0, 296.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 848 q_vals: [-12.8, -12.8, -9.015, -12.8, -inf, -12.8, -12.8]
Step 1321 2 visits [1.0, 1.0, 297.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 848 q_vals: [-12.8, -12.8, -9.027, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 849, "number_of_timesteps": 88468, "per_episode_reward": -396.9, "episode_reward_trend_value": 0.07985061746394675, "biggest_recent_change": 3.7848985111287448},
Step 1322 2 visits [1.0, 1.0, 298.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 849 q_vals: [-12.8, -12.8, -9.04, -12.8, -inf, -12.8, -12.8]
Step 1323 2 visits [1.0, 1.0, 299.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 850 q_vals: [-12.8, -12.8, -9.053, -12.8, -inf, -12.8, -12.8]
Step 1324 2 visits [1.0, 1.0, 300.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 853 q_vals: [-12.8, -12.8, -9.065, -12.8, -inf, -12.8, -12.8]
Step 1325 2 visits [1.0, 1.0, 301.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 854 q_vals: [-12.8, -12.8, -9.078, -12.8, -inf, -12.8, -12.8]
Step 1326 2 visits [1.0, 1.0, 302.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 854 q_vals: [-12.8, -12.8, -9.09, -12.8, -inf, -12.8, -12.8]
Step 1327 2 visits [1.0, 1.0, 303.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 854 q_vals: [-12.8, -12.8, -9.06, -12.8, -inf, -12.8, -12.8]
Step 1328 2 visits [1.0, 1.0, 304.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 855 q_vals: [-12.8, -12.8, -9.072, -12.8, -inf, -12.8, -12.8]
Step 1329 2 visits [1.0, 1.0, 305.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 855 q_vals: [-12.8, -12.8, -9.084, -12.8, -inf, -12.8, -12.8]
Step 1330 2 visits [1.0, 1.0, 306.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 856 q_vals: [-12.8, -12.8, -9.055, -12.8, -inf, -12.8, -12.8]
Step 1331 2 visits [1.0, 1.0, 307.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 857 q_vals: [-12.8, -12.8, -9.067, -12.8, -inf, -12.8, -12.8]
Step 1332 2 visits [1.0, 1.0, 308.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 858 q_vals: [-12.8, -12.8, -9.079, -12.8, -inf, -12.8, -12.8]
Step 1333 2 visits [1.0, 1.0, 309.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 858 q_vals: [-12.8, -12.8, -9.091, -12.8, -inf, -12.8, -12.8]
Step 1334 2 visits [1.0, 1.0, 310.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 858 q_vals: [-12.8, -12.8, -9.062, -12.8, -inf, -12.8, -12.8]
Step 1335 2 visits [1.0, 1.0, 311.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 858 q_vals: [-12.8, -12.8, -9.074, -12.8, -inf, -12.8, -12.8]
Step 1336 2 visits [1.0, 1.0, 312.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 858 q_vals: [-12.8, -12.8, -9.086, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 859, "number_of_timesteps": 89336, "per_episode_reward": -395.43, "episode_reward_trend_value": 0.0823591579266766, "biggest_recent_change": 3.7848985111287448},
Step 1337 2 visits [1.0, 1.0, 313.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 859 q_vals: [-12.8, -12.8, -9.098, -12.8, -inf, -12.8, -12.8]
Step 1338 2 visits [1.0, 1.0, 314.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 859 q_vals: [-12.8, -12.8, -9.109, -12.8, -inf, -12.8, -12.8]
Step 1339 2 visits [1.0, 1.0, 315.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 859 q_vals: [-12.8, -12.8, -9.121, -12.8, -inf, -12.8, -12.8]
Step 1340 2 visits [1.0, 1.0, 316.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 861 q_vals: [-12.8, -12.8, -9.133, -12.8, -inf, -12.8, -12.8]
Step 1341 2 visits [1.0, 1.0, 317.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 862 q_vals: [-12.8, -12.8, -9.104, -12.8, -inf, -12.8, -12.8]
Step 1342 2 visits [1.0, 1.0, 318.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 863 q_vals: [-12.8, -12.8, -9.075, -12.8, -inf, -12.8, -12.8]
Step 1343 2 visits [1.0, 1.0, 319.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 864 q_vals: [-12.8, -12.8, -9.047, -12.8, -inf, -12.8, -12.8]
Step 1344 2 visits [1.0, 1.0, 320.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 864 q_vals: [-12.8, -12.8, -9.059, -12.8, -inf, -12.8, -12.8]
Step 1345 2 visits [1.0, 1.0, 321.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 866 q_vals: [-12.8, -12.8, -9.07, -12.8, -inf, -12.8, -12.8]
Step 1346 2 visits [1.0, 1.0, 322.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 866 q_vals: [-12.8, -12.8, -9.082, -12.8, -inf, -12.8, -12.8]
Step 1347 2 visits [1.0, 1.0, 323.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 866 q_vals: [-12.8, -12.8, -9.093, -12.8, -inf, -12.8, -12.8]
Step 1348 2 visits [1.0, 1.0, 324.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 866 q_vals: [-12.8, -12.8, -9.065, -12.8, -inf, -12.8, -12.8]
Step 1349 2 visits [1.0, 1.0, 325.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 866 q_vals: [-12.8, -12.8, -9.077, -12.8, -inf, -12.8, -12.8]
Step 1350 2 visits [1.0, 1.0, 326.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 868 q_vals: [-12.8, -12.8, -9.088, -12.8, -inf, -12.8, -12.8]
Step 1351 2 visits [1.0, 1.0, 327.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 868 q_vals: [-12.8, -12.8, -9.1, -12.8, -inf, -12.8, -12.8]
Step 1352 2 visits [1.0, 1.0, 328.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 868 q_vals: [-12.8, -12.8, -9.072, -12.8, -inf, -12.8, -12.8]
Step 1353 2 visits [1.0, 1.0, 329.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 868 q_vals: [-12.8, -12.8, -9.083, -12.8, -inf, -12.8, -12.8]
Step 1354 2 visits [1.0, 1.0, 330.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 868 q_vals: [-12.8, -12.8, -9.094, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 869, "number_of_timesteps": 90477, "per_episode_reward": -394.94, "episode_reward_trend_value": 0.09155727667373728, "biggest_recent_change": 3.7848985111287448},
Step 1355 2 visits [1.0, 1.0, 331.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 869 q_vals: [-12.8, -12.8, -9.106, -12.8, -inf, -12.8, -12.8]
Step 1356 2 visits [1.0, 1.0, 332.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 870 q_vals: [-12.8, -12.8, -9.117, -12.8, -inf, -12.8, -12.8]
Step 1357 2 visits [1.0, 1.0, 333.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 872 q_vals: [-12.8, -12.8, -9.089, -12.8, -inf, -12.8, -12.8]
Step 1358 2 visits [1.0, 1.0, 334.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 873 q_vals: [-12.8, -12.8, -9.1, -12.8, -inf, -12.8, -12.8]
Step 1359 2 visits [1.0, 1.0, 335.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 873 q_vals: [-12.8, -12.8, -9.073, -12.8, -inf, -12.8, -12.8]
Step 1360 2 visits [1.0, 1.0, 336.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 873 q_vals: [-12.8, -12.8, -9.046, -12.8, -inf, -12.8, -12.8]
Step 1361 2 visits [1.0, 1.0, 337.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 874 q_vals: [-12.8, -12.8, -9.057, -12.8, -inf, -12.8, -12.8]
Step 1362 2 visits [1.0, 1.0, 338.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 875 q_vals: [-12.8, -12.8, -9.069, -12.8, -inf, -12.8, -12.8]
Step 1363 2 visits [1.0, 1.0, 339.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 876 q_vals: [-12.8, -12.8, -9.08, -12.8, -inf, -12.8, -12.8]
Step 1364 2 visits [1.0, 1.0, 340.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 876 q_vals: [-12.8, -12.8, -9.053, -12.8, -inf, -12.8, -12.8]
Step 1365 2 visits [1.0, 1.0, 341.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 877 q_vals: [-12.8, -12.8, -9.064, -12.8, -inf, -12.8, -12.8]
Step 1366 2 visits [1.0, 1.0, 342.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 877 q_vals: [-12.8, -12.8, -9.075, -12.8, -inf, -12.8, -12.8]
Step 1367 2 visits [1.0, 1.0, 343.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 878 q_vals: [-12.8, -12.8, -9.086, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 879, "number_of_timesteps": 91608, "per_episode_reward": -395.68, "episode_reward_trend_value": 0.04133905962775468, "biggest_recent_change": 1.6923716811073177},
Step 1368 2 visits [1.0, 1.0, 344.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 879 q_vals: [-12.8, -12.8, -9.059, -12.8, -inf, -12.8, -12.8]
Step 1369 2 visits [1.0, 1.0, 345.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 880 q_vals: [-12.8, -12.8, -9.033, -12.8, -inf, -12.8, -12.8]
Step 1370 2 visits [1.0, 1.0, 346.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 882 q_vals: [-12.8, -12.8, -9.007, -12.8, -inf, -12.8, -12.8]
Step 1371 2 visits [1.0, 1.0, 347.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 882 q_vals: [-12.8, -12.8, -8.981, -12.8, -inf, -12.8, -12.8]
Step 1372 2 visits [1.0, 1.0, 348.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 882 q_vals: [-12.8, -12.8, -8.992, -12.8, -inf, -12.8, -12.8]
Step 1373 2 visits [1.0, 1.0, 349.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 884 q_vals: [-12.8, -12.8, -9.003, -12.8, -inf, -12.8, -12.8]
Step 1374 2 visits [1.0, 1.0, 350.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 884 q_vals: [-12.8, -12.8, -9.014, -12.8, -inf, -12.8, -12.8]
Step 1375 2 visits [1.0, 1.0, 351.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 884 q_vals: [-12.8, -12.8, -9.024, -12.8, -inf, -12.8, -12.8]
Step 1376 2 visits [1.0, 1.0, 352.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 885 q_vals: [-12.8, -12.8, -9.035, -12.8, -inf, -12.8, -12.8]
Step 1377 2 visits [1.0, 1.0, 353.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 888 q_vals: [-12.8, -12.8, -9.01, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 889, "number_of_timesteps": 92414, "per_episode_reward": -395.66, "episode_reward_trend_value": 0.04184060659797777, "biggest_recent_change": 1.6923716811073177},
Step 1378 2 visits [1.0, 1.0, 354.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 889 q_vals: [-12.8, -12.8, -9.02, -12.8, -inf, -12.8, -12.8]
Step 1379 2 visits [1.0, 1.0, 355.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 889 q_vals: [-12.8, -12.8, -9.031, -12.8, -inf, -12.8, -12.8]
Step 1380 2 visits [1.0, 1.0, 356.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 889 q_vals: [-12.8, -12.8, -9.041, -12.8, -inf, -12.8, -12.8]
[-12.8, -12.8, -9.052, -12.8, -inf, -12.8, -12.8]
Step 1382 2 visits [1.0, 1.0, 358.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 891 q_vals: [-12.8, -12.8, -9.027, -12.8, -inf, -12.8, -12.8]
Step 1383 2 visits [1.0, 1.0, 359.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 892 q_vals: [-12.8, -12.8, -9.037, -12.8, -inf, -12.8, -12.8]
Step 1384 2 visits [1.0, 1.0, 360.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 892 q_vals: [-12.8, -12.8, -9.048, -12.8, -inf, -12.8, -12.8]
Step 1385 2 visits [1.0, 1.0, 361.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 894 q_vals: [-12.8, -12.8, -9.023, -12.8, -inf, -12.8, -12.8]
Step 1386 2 visits [1.0, 1.0, 362.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 894 q_vals: [-12.8, -12.8, -9.033, -12.8, -inf, -12.8, -12.8]
Step 1387 2 visits [1.0, 1.0, 363.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 895 q_vals: [-12.8, -12.8, -9.043, -12.8, -inf, -12.8, -12.8]
Step 1388 2 visits [1.0, 1.0, 364.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 895 q_vals: [-12.8, -12.8, -9.054, -12.8, -inf, -12.8, -12.8]
Step 1389 2 visits [1.0, 1.0, 365.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 897 q_vals: [-12.8, -12.8, -9.064, -12.8, -inf, -12.8, -12.8]
Step 1390 2 visits [1.0, 1.0, 366.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 897 q_vals: [-12.8, -12.8, -9.039, -12.8, -inf, -12.8, -12.8]
Step 1391 2 visits [1.0, 1.0, 367.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 897 q_vals: [-12.8, -12.8, -9.015, -12.8, -inf, -12.8, -12.8]
Step 1392 2 visits [1.0, 1.0, 368.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 897 q_vals: [-12.8, -12.8, -9.025, -12.8, -inf, -12.8, -12.8]
Step 1393 2 visits [1.0, 1.0, 369.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 898 q_vals: [-12.8, -12.8, -9.0, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 899, "number_of_timesteps": 93220, "per_episode_reward": -395.36, "episode_reward_trend_value": 0.05640981529505464, "biggest_recent_change": 1.6923716811073177},
Step 1394 2 visits [1.0, 1.0, 370.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 899 q_vals: [-12.8, -12.8, -9.011, -12.8, -inf, -12.8, -12.8]
Step 1395 2 visits [1.0, 1.0, 371.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 900 q_vals: [-12.8, -12.8, -8.986, -12.8, -inf, -12.8, -12.8]
Step 1396 2 visits [1.0, 1.0, 372.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 901 q_vals: [-12.8, -12.8, -8.997, -12.8, -inf, -12.8, -12.8]
Step 1397 2 visits [1.0, 1.0, 373.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 902 q_vals: [-12.8, -12.8, -8.973, -12.8, -inf, -12.8, -12.8]
Step 1398 2 visits [1.0, 1.0, 374.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 903 q_vals: [-12.8, -12.8, -8.983, -12.8, -inf, -12.8, -12.8]
Step 1399 2 visits [1.0, 1.0, 375.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 903 q_vals: [-12.8, -12.8, -8.993, -12.8, -inf, -12.8, -12.8]
Step 1400 2 visits [1.0, 1.0, 376.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 903 q_vals: [-12.8, -12.8, -9.003, -12.8, -inf, -12.8, -12.8]
Step 1401 2 visits [1.0, 1.0, 377.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 905 q_vals: [-12.8, -12.8, -9.013, -12.8, -inf, -12.8, -12.8]
Step 1402 2 visits [1.0, 1.0, 378.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 907 q_vals: [-12.8, -12.8, -8.989, -12.8, -inf, -12.8, -12.8]
Step 1403 2 visits [1.0, 1.0, 379.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 907 q_vals: [-12.8, -12.8, -8.999, -12.8, -inf, -12.8, -12.8]
Step 1404 2 visits [1.0, 1.0, 380.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 907 q_vals: [-12.8, -12.8, -9.009, -12.8, -inf, -12.8, -12.8]
Step 1405 2 visits [1.0, 1.0, 381.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 907 q_vals: [-12.8, -12.8, -8.986, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 909, "number_of_timesteps": 94189, "per_episode_reward": -395.78, "episode_reward_trend_value": 0.04611334122013078, "biggest_recent_change": 1.6923716811073177},
Step 1406 2 visits [1.0, 1.0, 382.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 909 q_vals: [-12.8, -12.8, -8.962, -12.8, -inf, -12.8, -12.8]
Step 1407 2 visits [1.0, 1.0, 383.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 910 q_vals: [-12.8, -12.8, -8.939, -12.8, -inf, -12.8, -12.8]
Step 1408 2 visits [1.0, 1.0, 384.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 911 q_vals: [-12.8, -12.8, -8.949, -12.8, -inf, -12.8, -12.8]
Step 1409 2 visits [1.0, 1.0, 385.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 912 q_vals: [-12.8, -12.8, -8.959, -12.8, -inf, -12.8, -12.8]
Step 1410 2 visits [1.0, 1.0, 386.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 912 q_vals: [-12.8, -12.8, -8.969, -12.8, -inf, -12.8, -12.8]
Step 1411 2 visits [1.0, 1.0, 387.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 913 q_vals: [-12.8, -12.8, -8.979, -12.8, -inf, -12.8, -12.8]
Step 1412 2 visits [1.0, 1.0, 388.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 913 q_vals: [-12.8, -12.8, -8.956, -12.8, -inf, -12.8, -12.8]
Step 1413 2 visits [1.0, 1.0, 389.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 914 q_vals: [-12.8, -12.8, -8.933, -12.8, -inf, -12.8, -12.8]
Step 1414 2 visits [1.0, 1.0, 390.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 914 q_vals: [-12.8, -12.8, -8.942, -12.8, -inf, -12.8, -12.8]
Step 1415 2 visits [1.0, 1.0, 391.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 917 q_vals: [-12.8, -12.8, -8.952, -12.8, -inf, -12.8, -12.8]
Step 1416 2 visits [1.0, 1.0, 392.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 917 q_vals: [-12.8, -12.8, -8.93, -12.8, -inf, -12.8, -12.8]
Step 1417 2 visits [1.0, 1.0, 393.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 918 q_vals: [-12.8, -12.8, -8.939, -12.8, -inf, -12.8, -12.8]
Step 1418 2 visits [1.0, 1.0, 394.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 918 q_vals: [-12.8, -12.8, -8.949, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 919, "number_of_timesteps": 95031, "per_episode_reward": -395.22, "episode_reward_trend_value": 0.03353099904087394, "biggest_recent_change": 1.4664014798863718},
Step 1419 2 visits [1.0, 1.0, 395.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 919 q_vals: [-12.8, -12.8, -8.926, -12.8, -inf, -12.8, -12.8]
Step 1420 2 visits [1.0, 1.0, 396.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 919 q_vals: [-12.8, -12.8, -8.904, -12.8, -inf, -12.8, -12.8]
Step 1421 2 visits [1.0, 1.0, 397.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 919 q_vals: [-12.8, -12.8, -8.914, -12.8, -inf, -12.8, -12.8]
Step 1422 2 visits [1.0, 1.0, 398.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 921 q_vals: [-12.8, -12.8, -8.924, -12.8, -inf, -12.8, -12.8]
Step 1423 2 visits [1.0, 1.0, 399.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 922 q_vals: [-12.8, -12.8, -8.933, -12.8, -inf, -12.8, -12.8]
Step 1424 2 visits [1.0, 1.0, 400.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 922 q_vals: [-12.8, -12.8, -8.911, -12.8, -inf, -12.8, -12.8]
Step 1425 2 visits [1.0, 1.0, 401.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 922 q_vals: [-12.8, -12.8, -8.921, -12.8, -inf, -12.8, -12.8]
Step 1426 2 visits [1.0, 1.0, 402.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 922 q_vals: [-12.8, -12.8, -8.898, -12.8, -inf, -12.8, -12.8]
Step 1427 2 visits [1.0, 1.0, 403.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 922 q_vals: [-12.8, -12.8, -8.908, -12.8, -inf, -12.8, -12.8]
Step 1428 2 visits [1.0, 1.0, 404.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 922 q_vals: [-12.8, -12.8, -8.918, -12.8, -inf, -12.8, -12.8]
Step 1429 2 visits [1.0, 1.0, 405.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 923 q_vals: [-12.8, -12.8, -8.896, -12.8, -inf, -12.8, -12.8]
Step 1430 2 visits [1.0, 1.0, 406.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 924 q_vals: [-12.8, -12.8, -8.905, -12.8, -inf, -12.8, -12.8]
Step 1431 2 visits [1.0, 1.0, 407.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 924 q_vals: [-12.8, -12.8, -8.915, -12.8, -inf, -12.8, -12.8]
Step 1432 2 visits [1.0, 1.0, 408.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 924 q_vals: [-12.8, -12.8, -8.893, -12.8, -inf, -12.8, -12.8]
Step 1433 2 visits [1.0, 1.0, 409.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 927 q_vals: [-12.8, -12.8, -8.903, -12.8, -inf, -12.8, -12.8]
Step 1434 2 visits [1.0, 1.0, 410.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 928 q_vals: [-12.8, -12.8, -8.912, -12.8, -inf, -12.8, -12.8]
Step 1435 2 visits [1.0, 1.0, 411.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 928 q_vals: [-12.8, -12.8, -8.922, -12.8, -inf, -12.8, -12.8]
Step 1436 2 visits [1.0, 1.0, 412.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 928 q_vals: [-12.8, -12.8, -8.9, -12.8, -inf, -12.8, -12.8]
Step 1437 2 visits [1.0, 1.0, 413.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 928 q_vals: [-12.8, -12.8, -8.878, -12.8, -inf, -12.8, -12.8]
Step 1438 2 visits [1.0, 1.0, 414.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 928 q_vals: [-12.8, -12.8, -8.888, -12.8, -inf, -12.8, -12.8]
Step 1439 2 visits [1.0, 1.0, 415.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 928 q_vals: [-12.8, -12.8, -8.897, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 929, "number_of_timesteps": 96246, "per_episode_reward": -394.69, "episode_reward_trend_value": 0.032783865045930345, "biggest_recent_change": 1.4664014798863718},
Step 1440 2 visits [1.0, 1.0, 416.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 929 q_vals: [-12.8, -12.8, -8.907, -12.8, -inf, -12.8, -12.8]
Step 1441 2 visits [1.0, 1.0, 417.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 930 q_vals: [-12.8, -12.8, -8.885, -12.8, -inf, -12.8, -12.8]
Step 1442 2 visits [1.0, 1.0, 418.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 930 q_vals: [-12.8, -12.8, -8.895, -12.8, -inf, -12.8, -12.8]
Step 1443 2 visits [1.0, 1.0, 419.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 930 q_vals: [-12.8, -12.8, -8.873, -12.8, -inf, -12.8, -12.8]
Step 1444 2 visits [1.0, 1.0, 420.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 930 q_vals: [-12.8, -12.8, -8.883, -12.8, -inf, -12.8, -12.8]
Step 1445 2 visits [1.0, 1.0, 421.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 931 q_vals: [-12.8, -12.8, -8.862, -12.8, -inf, -12.8, -12.8]
Step 1446 2 visits [1.0, 1.0, 422.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 931 q_vals: [-12.8, -12.8, -8.841, -12.8, -inf, -12.8, -12.8]
Step 1447 2 visits [1.0, 1.0, 423.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 931 q_vals: [-12.8, -12.8, -8.85, -12.8, -inf, -12.8, -12.8]
Step 1448 2 visits [1.0, 1.0, 424.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 933 q_vals: [-12.8, -12.8, -8.859, -12.8, -inf, -12.8, -12.8]
Step 1449 2 visits [1.0, 1.0, 425.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 935 q_vals: [-12.8, -12.8, -8.869, -12.8, -inf, -12.8, -12.8]
Step 1450 2 visits [1.0, 1.0, 426.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 936 q_vals: [-12.8, -12.8, -8.878, -12.8, -inf, -12.8, -12.8]
Step 1451 2 visits [1.0, 1.0, 427.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 936 q_vals: [-12.8, -12.8, -8.887, -12.8, -inf, -12.8, -12.8]
Step 1452 2 visits [1.0, 1.0, 428.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 936 q_vals: [-12.8, -12.8, -8.866, -12.8, -inf, -12.8, -12.8]
Step 1453 2 visits [1.0, 1.0, 429.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 936 q_vals: [-12.8, -12.8, -8.875, -12.8, -inf, -12.8, -12.8]
Step 1454 2 visits [1.0, 1.0, 430.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 936 q_vals: [-12.8, -12.8, -8.885, -12.8, -inf, -12.8, -12.8]
Step 1455 2 visits [1.0, 1.0, 431.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 937 q_vals: [-12.8, -12.8, -8.894, -12.8, -inf, -12.8, -12.8]
Step 1456 2 visits [1.0, 1.0, 432.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 937 q_vals: [-12.8, -12.8, -8.903, -12.8, -inf, -12.8, -12.8]
Step 1457 2 visits [1.0, 1.0, 433.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 937 q_vals: [-12.8, -12.8, -8.912, -12.8, -inf, -12.8, -12.8]
Step 1458 2 visits [1.0, 1.0, 434.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 938 q_vals: [-12.8, -12.8, -8.921, -12.8, -inf, -12.8, -12.8]
Step 1459 2 visits [1.0, 1.0, 435.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 938 q_vals: [-12.8, -12.8, -8.93, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 940, "number_of_timesteps": 97688, "per_episode_reward": -394.04, "episode_reward_trend_value": 0.03181787753710397, "biggest_recent_change": 1.4664014798863718},
Step 1460 2 visits [1.0, 1.0, 436.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 940 q_vals: [-12.8, -12.8, -8.938, -12.8, -inf, -12.8, -12.8]
Step 1461 2 visits [1.0, 1.0, 437.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 940 q_vals: [-12.8, -12.8, -8.947, -12.8, -inf, -12.8, -12.8]
Step 1462 2 visits [1.0, 1.0, 438.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 940 q_vals: [-12.8, -12.8, -8.927, -12.8, -inf, -12.8, -12.8]
Step 1463 2 visits [1.0, 1.0, 439.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 940 q_vals: [-12.8, -12.8, -8.936, -12.8, -inf, -12.8, -12.8]
Step 1464 2 visits [1.0, 1.0, 440.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 941 q_vals: [-12.8, -12.8, -8.944, -12.8, -inf, -12.8, -12.8]
[1.0, 1.0, 441.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 942 q_vals: [-12.8, -12.8, -8.924, -12.8, -inf, -12.8, -12.8]
Step 1466 2 visits [1.0, 1.0, 442.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 942 q_vals: [-12.8, -12.8, -8.933, -12.8, -inf, -12.8, -12.8]
Step 1467 2 visits [1.0, 1.0, 443.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 942 q_vals: [-12.8, -12.8, -8.942, -12.8, -inf, -12.8, -12.8]
Step 1468 2 visits [1.0, 1.0, 444.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 944 q_vals: [-12.8, -12.8, -8.95, -12.8, -inf, -12.8, -12.8]
Step 1469 2 visits [1.0, 1.0, 445.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 944 q_vals: [-12.8, -12.8, -8.93, -12.8, -inf, -12.8, -12.8]
Step 1470 2 visits [1.0, 1.0, 446.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 946 q_vals: [-12.8, -12.8, -8.939, -12.8, -inf, -12.8, -12.8]
Step 1471 2 visits [1.0, 1.0, 447.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 948 q_vals: [-12.8, -12.8, -8.919, -12.8, -inf, -12.8, -12.8]
Step 1472 2 visits [1.0, 1.0, 448.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 948 q_vals: [-12.8, -12.8, -8.925, -12.8, -inf, -12.8, -12.8]
Step 1473 2 visits [1.0, 1.0, 449.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 948 q_vals: [-12.8, -12.8, -8.933, -12.8, -inf, -12.8, -12.8]
Step 1474 2 visits [1.0, 1.0, 450.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 948 q_vals: [-12.8, -12.8, -8.913, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 950, "number_of_timesteps": 98846, "per_episode_reward": -393.38, "episode_reward_trend_value": 0.022819727931056376, "biggest_recent_change": 0.7347410230096898},
Step 1475 2 visits [1.0, 1.0, 451.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 950 q_vals: [-12.8, -12.8, -8.922, -12.8, -inf, -12.8, -12.8]
Step 1476 2 visits [1.0, 1.0, 452.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 950 q_vals: [-12.8, -12.8, -8.902, -12.8, -inf, -12.8, -12.8]
Step 1477 2 visits [1.0, 1.0, 453.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 950 q_vals: [-12.8, -12.8, -8.911, -12.8, -inf, -12.8, -12.8]
Step 1478 2 visits [1.0, 1.0, 454.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 951 q_vals: [-12.8, -12.8, -8.891, -12.8, -inf, -12.8, -12.8]
Step 1479 2 visits [1.0, 1.0, 455.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 951 q_vals: [-12.8, -12.8, -8.9, -12.8, -inf, -12.8, -12.8]
Step 1480 2 visits [1.0, 1.0, 456.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 954 q_vals: [-12.8, -12.8, -8.908, -12.8, -inf, -12.8, -12.8]
Step 1481 2 visits [1.0, 1.0, 457.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 954 q_vals: [-12.8, -12.8, -8.917, -12.8, -inf, -12.8, -12.8]
Step 1482 2 visits [1.0, 1.0, 458.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 955 q_vals: [-12.8, -12.8, -8.925, -12.8, -inf, -12.8, -12.8]
Step 1483 2 visits [1.0, 1.0, 459.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 955 q_vals: [-12.8, -12.8, -8.906, -12.8, -inf, -12.8, -12.8]
Step 1484 2 visits [1.0, 1.0, 460.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 956 q_vals: [-12.8, -12.8, -8.914, -12.8, -inf, -12.8, -12.8]
Step 1485 2 visits [1.0, 1.0, 461.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 957 q_vals: [-12.8, -12.8, -8.895, -12.8, -inf, -12.8, -12.8]
Step 1486 2 visits [1.0, 1.0, 462.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 958 q_vals: [-12.8, -12.8, -8.904, -12.8, -inf, -12.8, -12.8]
Step 1487 2 visits [1.0, 1.0, 463.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 958 q_vals: [-12.8, -12.8, -8.912, -12.8, -inf, -12.8, -12.8]
Step 1488 2 visits [1.0, 1.0, 464.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 958 q_vals: [-12.8, -12.8, -8.92, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 960, "number_of_timesteps": 99713, "per_episode_reward": -392.06, "episode_reward_trend_value": 0.032057339168058106, "biggest_recent_change": 1.321601595586344},
Step 1489 2 visits [1.0, 1.0, 465.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 960 q_vals: [-12.8, -12.8, -8.929, -12.8, -inf, -12.8, -12.8]
Step 1490 2 visits [1.0, 1.0, 466.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 960 q_vals: [-12.8, -12.8, -8.937, -12.8, -inf, -12.8, -12.8]
Step 1491 2 visits [1.0, 1.0, 467.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 961 q_vals: [-12.8, -12.8, -8.918, -12.8, -inf, -12.8, -12.8]
Step 1492 2 visits [1.0, 1.0, 468.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 962 q_vals: [-12.8, -12.8, -8.926, -12.8, -inf, -12.8, -12.8]
Step 1493 2 visits [1.0, 1.0, 469.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 963 q_vals: [-12.8, -12.8, -8.934, -12.8, -inf, -12.8, -12.8]
Step 1494 2 visits [1.0, 1.0, 470.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 964 q_vals: [-12.8, -12.8, -8.943, -12.8, -inf, -12.8, -12.8]
Step 1495 2 visits [1.0, 1.0, 471.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 965 q_vals: [-12.8, -12.8, -8.924, -12.8, -inf, -12.8, -12.8]
Step 1496 2 visits [1.0, 1.0, 472.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 965 q_vals: [-12.8, -12.8, -8.932, -12.8, -inf, -12.8, -12.8]
Step 1497 2 visits [1.0, 1.0, 473.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 965 q_vals: [-12.8, -12.8, -8.94, -12.8, -inf, -12.8, -12.8]
Step 1498 2 visits [1.0, 1.0, 474.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 965 q_vals: [-12.8, -12.8, -8.948, -12.8, -inf, -12.8, -12.8]
Step 1499 2 visits [1.0, 1.0, 475.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 967 q_vals: [-12.8, -12.8, -8.929, -12.8, -inf, -12.8, -12.8]
Step 1500 2 visits [1.0, 1.0, 476.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 968 q_vals: [-12.8, -12.8, -8.937, -12.8, -inf, -12.8, -12.8]
Step 1501 2 visits [1.0, 1.0, 477.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 968 q_vals: [-12.8, -12.8, -8.946, -12.8, -inf, -12.8, -12.8]
Step 1502 2 visits [1.0, 1.0, 478.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 969 q_vals: [-12.8, -12.8, -8.954, -12.8, -inf, -12.8, -12.8]
Step 1503 2 visits [1.0, 1.0, 479.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 969 q_vals: [-12.8, -12.8, -8.962, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 971, "number_of_timesteps": 100740, "per_episode_reward": -389.51, "episode_reward_trend_value": 0.0685835665830963, "biggest_recent_change": 2.5526194443437475},
Step 1504 2 visits [1.0, 1.0, 480.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 971 q_vals: [-12.8, -12.8, -8.97, -12.8, -inf, -12.8, -12.8]
Step 1505 2 visits [1.0, 1.0, 481.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 971 q_vals: [-12.8, -12.8, -8.951, -12.8, -inf, -12.8, -12.8]
Step 1506 2 visits [1.0, 1.0, 482.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 972 q_vals: [-12.8, -12.8, -8.932, -12.8, -inf, -12.8, -12.8]
Step 1507 2 visits [1.0, 1.0, 483.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 972 q_vals: [-12.8, -12.8, -8.94, -12.8, -inf, -12.8, -12.8]
Step 1508 2 visits [1.0, 1.0, 484.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 972 q_vals: [-12.8, -12.8, -8.922, -12.8, -inf, -12.8, -12.8]
Step 1509 2 visits [1.0, 1.0, 485.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 973 q_vals: [-12.8, -12.8, -8.93, -12.8, -inf, -12.8, -12.8]
Step 1510 2 visits [1.0, 1.0, 486.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 973 q_vals: [-12.8, -12.8, -8.938, -12.8, -inf, -12.8, -12.8]
Step 1511 2 visits [1.0, 1.0, 487.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 973 q_vals: [-12.8, -12.8, -8.92, -12.8, -inf, -12.8, -12.8]
Step 1512 2 visits [1.0, 1.0, 488.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 975 q_vals: [-12.8, -12.8, -8.901, -12.8, -inf, -12.8, -12.8]
Step 1513 2 visits [1.0, 1.0, 489.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 976 q_vals: [-12.8, -12.8, -8.909, -12.8, -inf, -12.8, -12.8]
Step 1514 2 visits [1.0, 1.0, 490.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 976 q_vals: [-12.8, -12.8, -8.917, -12.8, -inf, -12.8, -12.8]
Step 1515 2 visits [1.0, 1.0, 491.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 977 q_vals: [-12.8, -12.8, -8.925, -12.8, -inf, -12.8, -12.8]
Step 1516 2 visits [1.0, 1.0, 492.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 979 q_vals: [-12.8, -12.8, -8.907, -12.8, -inf, -12.8, -12.8]
Step 1517 2 visits [1.0, 1.0, 493.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 979 q_vals: [-12.8, -12.8, -8.915, -12.8, -inf, -12.8, -12.8]
Step 1518 2 visits [1.0, 1.0, 494.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 979 q_vals: [-12.8, -12.8, -8.923, -12.8, -inf, -12.8, -12.8]
Step 1519 2 visits [1.0, 1.0, 495.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 980 q_vals: [-12.8, -12.8, -8.931, -12.8, -inf, -12.8, -12.8]
Step 1520 2 visits [1.0, 1.0, 496.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 980 q_vals: [-12.8, -12.8, -8.938, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 981, "number_of_timesteps": 101789, "per_episode_reward": -386.95, "episode_reward_trend_value": 0.09675517404138154, "biggest_recent_change": 2.5564466977529037},
Step 1521 2 visits [1.0, 1.0, 497.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 981 q_vals: [-12.8, -12.8, -8.946, -12.8, -inf, -12.8, -12.8]
Step 1522 2 visits [1.0, 1.0, 498.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 982 q_vals: [-12.8, -12.8, -8.954, -12.8, -inf, -12.8, -12.8]
Step 1523 2 visits [1.0, 1.0, 499.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 984 q_vals: [-12.8, -12.8, -8.962, -12.8, -inf, -12.8, -12.8]
Step 1524 2 visits [1.0, 1.0, 500.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 985 q_vals: [-12.8, -12.8, -8.944, -12.8, -inf, -12.8, -12.8]
Step 1525 2 visits [1.0, 1.0, 501.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 985 q_vals: [-12.8, -12.8, -8.926, -12.8, -inf, -12.8, -12.8]
Step 1526 2 visits [1.0, 1.0, 502.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 986 q_vals: [-12.8, -12.8, -8.934, -12.8, -inf, -12.8, -12.8]
Step 1527 2 visits [1.0, 1.0, 503.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 987 q_vals: [-12.8, -12.8, -8.941, -12.8, -inf, -12.8, -12.8]
Step 1528 2 visits [1.0, 1.0, 504.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 987 q_vals: [-12.8, -12.8, -8.924, -12.8, -inf, -12.8, -12.8]
Step 1529 2 visits [1.0, 1.0, 505.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 987 q_vals: [-12.8, -12.8, -8.931, -12.8, -inf, -12.8, -12.8]
Step 1530 2 visits [1.0, 1.0, 506.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 988 q_vals: [-12.8, -12.8, -8.939, -12.8, -inf, -12.8, -12.8]
Step 1531 2 visits [1.0, 1.0, 507.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 989 q_vals: [-12.8, -12.8, -8.946, -12.8, -inf, -12.8, -12.8]
Step 1532 2 visits [1.0, 1.0, 508.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 989 q_vals: [-12.8, -12.8, -8.954, -12.8, -inf, -12.8, -12.8]
Step 1533 2 visits [1.0, 1.0, 509.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 990 q_vals: [-12.8, -12.8, -8.936, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 991, "number_of_timesteps": 102668, "per_episode_reward": -384.39, "episode_reward_trend_value": 0.12198785453447587, "biggest_recent_change": 2.563868265485212},
Step 1534 2 visits [1.0, 1.0, 510.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 991 q_vals: [-12.8, -12.8, -8.919, -12.8, -inf, -12.8, -12.8]
Step 1535 2 visits [1.0, 1.0, 511.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 991 q_vals: [-12.8, -12.8, -8.927, -12.8, -inf, -12.8, -12.8]
Step 1536 2 visits [1.0, 1.0, 512.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 992 q_vals: [-12.8, -12.8, -8.934, -12.8, -inf, -12.8, -12.8]
Step 1537 2 visits [1.0, 1.0, 513.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 993 q_vals: [-12.8, -12.8, -8.917, -12.8, -inf, -12.8, -12.8]
Step 1538 2 visits [1.0, 1.0, 514.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 993 q_vals: [-12.8, -12.8, -8.924, -12.8, -inf, -12.8, -12.8]
Step 1539 2 visits [1.0, 1.0, 515.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 994 q_vals: [-12.8, -12.8, -8.932, -12.8, -inf, -12.8, -12.8]
Step 1540 2 visits [1.0, 1.0, 516.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 995 q_vals: [-12.8, -12.8, -8.939, -12.8, -inf, -12.8, -12.8]
Step 1541 2 visits [1.0, 1.0, 517.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 995 q_vals: [-12.8, -12.8, -8.922, -12.8, -inf, -12.8, -12.8]
Step 1542 2 visits [1.0, 1.0, 518.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 996 q_vals: [-12.8, -12.8, -8.929, -12.8, -inf, -12.8, -12.8]
Step 1543 2 visits [1.0, 1.0, 519.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 997 q_vals: [-12.8, -12.8, -8.937, -12.8, -inf, -12.8, -12.8]
Step 1544 2 visits [1.0, 1.0, 520.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 997 q_vals: [-12.8, -12.8, -8.92, -12.8, -inf, -12.8, -12.8]
Step 1545 2 visits [1.0, 1.0, 521.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 999 q_vals: [-12.8, -12.8, -8.903, -12.8, -inf, -12.8, -12.8]
Step 1546 2 visits [1.0, 1.0, 522.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 999 q_vals: [-12.8, -12.8, -8.886, -12.8, -inf, -12.8, -12.8]
Step 1547 2 visits [1.0, 1.0, 523.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 999 q_vals: [-12.8, -12.8, -8.869, -12.8, -inf, -12.8, -12.8]
Step 1548 2 visits [1.0, 1.0, 524.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1000 q_vals: [-12.8, -12.8, -8.876, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1002, "number_of_timesteps": 103767, "per_episode_reward": -383.12, "episode_reward_trend_value": 0.14068895876034287, "biggest_recent_change": 2.563868265485212},
Step 1549 2 visits [1.0, 1.0, 525.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1002 q_vals: [-12.8, -12.8, -8.884, -12.8, -inf, -12.8, -12.8]
Step 1550 2 visits [1.0, 1.0, 526.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1002 q_vals: [-12.8, -12.8, -8.867, -12.8, -inf, -12.8, -12.8]
Step 1551 2 visits [1.0, 1.0, 527.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1003 q_vals: [-12.8, -12.8, -8.874, -12.8, -inf, -12.8, -12.8]
Step 1552 2 visits [1.0, 1.0, 528.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1003 q_vals: [-12.8, -12.8, -8.857, -12.8, -inf, -12.8, -12.8]
Step 1553 2 visits [1.0, 1.0, 529.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1003 q_vals: [-12.8, -12.8, -8.841, -12.8, -inf, -12.8, -12.8]
Step 1554 2 visits [1.0, 1.0, 530.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1004 q_vals: [-12.8, -12.8, -8.848, -12.8, -inf, -12.8, -12.8]
Step 1555 2 visits [1.0, 1.0, 531.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1005 q_vals: [-12.8, -12.8, -8.855, -12.8, -inf, -12.8, -12.8]
Step 1556 2 visits [1.0, 1.0, 532.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1005 q_vals: [-12.8, -12.8, -8.839, -12.8, -inf, -12.8, -12.8]
Step 1557 2 visits [1.0, 1.0, 533.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1005 q_vals: [-12.8, -12.8, -8.822, -12.8, -inf, -12.8, -12.8]
Step 1558 2 visits [1.0, 1.0, 534.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1007 q_vals: [-12.8, -12.8, -8.83, -12.8, -inf, -12.8, -12.8]
Step 1559 2 visits [1.0, 1.0, 535.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1007 q_vals: [-12.8, -12.8, -8.837, -12.8, -inf, -12.8, -12.8]
Step 1560 2 visits [1.0, 1.0, 536.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1007 q_vals: [-12.8, -12.8, -8.844, -12.8, -inf, -12.8, -12.8]
Step 1561 2 visits [1.0, 1.0, 537.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1009 q_vals: [-12.8, -12.8, -8.828, -12.8, -inf, -12.8, -12.8]
Step 1562 2 visits [1.0, 1.0, 538.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1009 q_vals: [-12.8, -12.8, -8.835, -12.8, -inf, -12.8, -12.8]
Step 1563 2 visits [1.0, 1.0, 539.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1009 q_vals: [-12.8, -12.8, -8.843, -12.8, -inf, -12.8, -12.8]
Step 1564 2 visits [1.0, 1.0, 540.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1010 q_vals: [-12.8, -12.8, -8.85, -12.8, -inf, -12.8, -12.8]
Step 1565 2 visits [1.0, 1.0, 541.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1010 q_vals: [-12.8, -12.8, -8.834, -12.8, -inf, -12.8, -12.8]
Step 1566 2 visits [1.0, 1.0, 542.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1010 q_vals: [-12.8, -12.8, -8.841, -12.8, -inf, -12.8, -12.8]
Step 1567 2 visits [1.0, 1.0, 543.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1010 q_vals: [-12.8, -12.8, -8.848, -12.8, -inf, -12.8, -12.8]
Step 1568 2 visits [1.0, 1.0, 544.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1011 q_vals: [-12.8, -12.8, -8.832, -12.8, -inf, -12.8, -12.8]
Step 1569 2 visits [1.0, 1.0, 545.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1011 q_vals: [-12.8, -12.8, -8.816, -12.8, -inf, -12.8, -12.8]
Step 1570 2 visits [1.0, 1.0, 546.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1011 q_vals: [-12.8, -12.8, -8.823, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1012, "number_of_timesteps": 104747, "per_episode_reward": -378.21, "episode_reward_trend_value": 0.18904627874930496, "biggest_recent_change": 4.912119683980791},
Step 1571 2 visits [1.0, 1.0, 547.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1012 q_vals: [-12.8, -12.8, -8.83, -12.8, -inf, -12.8, -12.8]
Step 1572 2 visits [1.0, 1.0, 548.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1013 q_vals: [-12.8, -12.8, -8.838, -12.8, -inf, -12.8, -12.8]
Step 1573 2 visits [1.0, 1.0, 549.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1013 q_vals: [-12.8, -12.8, -8.845, -12.8, -inf, -12.8, -12.8]
Step 1574 2 visits [1.0, 1.0, 550.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1013 q_vals: [-12.8, -12.8, -8.829, -12.8, -inf, -12.8, -12.8]
Step 1575 2 visits [1.0, 1.0, 551.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1017 q_vals: [-12.8, -12.8, -8.836, -12.8, -inf, -12.8, -12.8]
Step 1576 2 visits [1.0, 1.0, 552.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1017 q_vals: [-12.8, -12.8, -8.82, -12.8, -inf, -12.8, -12.8]
Step 1577 2 visits [1.0, 1.0, 553.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1017 q_vals: [-12.8, -12.8, -8.827, -12.8, -inf, -12.8, -12.8]
Step 1578 2 visits [1.0, 1.0, 554.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1017 q_vals: [-12.8, -12.8, -8.834, -12.8, -inf, -12.8, -12.8]
Step 1579 2 visits [1.0, 1.0, 555.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1017 q_vals: [-12.8, -12.8, -8.818, -12.8, -inf, -12.8, -12.8]
Step 1580 2 visits [1.0, 1.0, 556.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1018 q_vals: [-12.8, -12.8, -8.803, -12.8, -inf, -12.8, -12.8]
Step 1581 2 visits [1.0, 1.0, 557.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1018 q_vals: [-12.8, -12.8, -8.81, -12.8, -inf, -12.8, -12.8]
Step 1582 2 visits [1.0, 1.0, 558.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1018 q_vals: [-12.8, -12.8, -8.794, -12.8, -inf, -12.8, -12.8]
Step 1583 2 visits [1.0, 1.0, 559.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1020 q_vals: [-12.8, -12.8, -8.801, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1022, "number_of_timesteps": 106145, "per_episode_reward": -375.2, "episode_reward_trend_value": 0.21658523577534275, "biggest_recent_change": 4.912119683980791},
Step 1584 2 visits [1.0, 1.0, 560.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1022 q_vals: [-12.8, -12.8, -8.785, -12.8, -inf, -12.8, -12.8]
Step 1585 2 visits [1.0, 1.0, 561.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1022 q_vals: [-12.8, -12.8, -8.77, -12.8, -inf, -12.8, -12.8]
Step 1586 2 visits [1.0, 1.0, 562.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1022 q_vals: [-12.8, -12.8, -8.777, -12.8, -inf, -12.8, -12.8]
Step 1587 2 visits [1.0, 1.0, 563.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1022 q_vals: [-12.8, -12.8, -8.784, -12.8, -inf, -12.8, -12.8]
Step 1588 2 visits [1.0, 1.0, 564.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1023 q_vals: [-12.8, -12.8, -8.791, -12.8, -inf, -12.8, -12.8]
Step 1589 2 visits [1.0, 1.0, 565.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1024 q_vals: [-12.8, -12.8, -8.798, -12.8, -inf, -12.8, -12.8]
Step 1590 2 visits [1.0, 1.0, 566.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1025 q_vals: [-12.8, -12.8, -8.783, -12.8, -inf, -12.8, -12.8]
Step 1591 2 visits [1.0, 1.0, 567.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1025 q_vals: [-12.8, -12.8, -8.79, -12.8, -inf, -12.8, -12.8]
Step 1592 2 visits [1.0, 1.0, 568.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1025 q_vals: [-12.8, -12.8, -8.797, -12.8, -inf, -12.8, -12.8]
Step 1593 2 visits [1.0, 1.0, 569.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1026 q_vals: [-12.8, -12.8, -8.781, -12.8, -inf, -12.8, -12.8]
Step 1594 2 visits [1.0, 1.0, 570.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1026 q_vals: [-12.8, -12.8, -8.766, -12.8, -inf, -12.8, -12.8]
Step 1595 2 visits [1.0, 1.0, 571.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1028 q_vals: [-12.8, -12.8, -8.773, -12.8, -inf, -12.8, -12.8]
Step 1596 2 visits [1.0, 1.0, 572.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1029 q_vals: [-12.8, -12.8, -8.78, -12.8, -inf, -12.8, -12.8]
Step 1597 2 visits [1.0, 1.0, 573.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1030 q_vals: [-12.8, -12.8, -8.787, -12.8, -inf, -12.8, -12.8]
Step 1598 2 visits [1.0, 1.0, 574.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1030 q_vals: [-12.8, -12.8, -8.772, -12.8, -inf, -12.8, -12.8]
Step 1599 2 visits [1.0, 1.0, 575.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1031 q_vals: [-12.8, -12.8, -8.779, -12.8, -inf, -12.8, -12.8]
Step 1600 2 visits [1.0, 1.0, 576.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1031 q_vals: [-12.8, -12.8, -8.764, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1032, "number_of_timesteps": 107199, "per_episode_reward": -376.04, "episode_reward_trend_value": 0.1999568163653704, "biggest_recent_change": 4.912119683980791},
Step 1601 2 visits [1.0, 1.0, 577.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1032 q_vals: [-12.8, -12.8, -8.771, -12.8, -inf, -12.8, -12.8]
Step 1602 2 visits [1.0, 1.0, 578.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1033 q_vals: [-12.8, -12.8, -8.778, -12.8, -inf, -12.8, -12.8]
Step 1603 2 visits [1.0, 1.0, 579.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1033 q_vals: [-12.8, -12.8, -8.762, -12.8, -inf, -12.8, -12.8]
Step 1604 2 visits [1.0, 1.0, 580.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1033 q_vals: [-12.8, -12.8, -8.769, -12.8, -inf, -12.8, -12.8]
Step 1605 2 visits [1.0, 1.0, 581.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1033 q_vals: [-12.8, -12.8, -8.776, -12.8, -inf, -12.8, -12.8]
Step 1606 2 visits [1.0, 1.0, 582.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1033 q_vals: [-12.8, -12.8, -8.761, -12.8, -inf, -12.8, -12.8]
Step 1607 2 visits [1.0, 1.0, 583.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1034 q_vals: [-12.8, -12.8, -8.768, -12.8, -inf, -12.8, -12.8]
Step 1608 2 visits [1.0, 1.0, 584.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1035 q_vals: [-12.8, -12.8, -8.753, -12.8, -inf, -12.8, -12.8]
Step 1609 2 visits [1.0, 1.0, 585.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1036 q_vals: [-12.8, -12.8, -8.76, -12.8, -inf, -12.8, -12.8]
Step 1610 2 visits [1.0, 1.0, 586.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1037 q_vals: [-12.8, -12.8, -8.767, -12.8, -inf, -12.8, -12.8]
Step 1611 2 visits [1.0, 1.0, 587.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1037 q_vals: [-12.8, -12.8, -8.752, -12.8, -inf, -12.8, -12.8]
Step 1612 2 visits [1.0, 1.0, 588.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1038 q_vals: [-12.8, -12.8, -8.737, -12.8, -inf, -12.8, -12.8]
Step 1613 2 visits [1.0, 1.0, 589.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1038 q_vals: [-12.8, -12.8, -8.722, -12.8, -inf, -12.8, -12.8]
Step 1614 2 visits [1.0, 1.0, 590.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1038 q_vals: [-12.8, -12.8, -8.729, -12.8, -inf, -12.8, -12.8]
Step 1615 2 visits [1.0, 1.0, 591.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1040 q_vals: [-12.8, -12.8, -8.736, -12.8, -inf, -12.8, -12.8]
Step 1616 2 visits [1.0, 1.0, 592.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1041 q_vals: [-12.8, -12.8, -8.721, -12.8, -inf, -12.8, -12.8]
Step 1617 2 visits [1.0, 1.0, 593.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1041 q_vals: [-12.8, -12.8, -8.707, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1042, "number_of_timesteps": 108360, "per_episode_reward": -375.86, "episode_reward_trend_value": 0.19468041626275673, "biggest_recent_change": 4.912119683980791},
Step 1618 2 visits [1.0, 1.0, 594.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1042 q_vals: [-12.8, -12.8, -8.692, -12.8, -inf, -12.8, -12.8]
Step 1619 2 visits [1.0, 1.0, 595.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1042 q_vals: [-12.8, -12.8, -8.677, -12.8, -inf, -12.8, -12.8]
Step 1620 2 visits [1.0, 1.0, 596.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1043 q_vals: [-12.8, -12.8, -8.684, -12.8, -inf, -12.8, -12.8]
Step 1621 2 visits [1.0, 1.0, 597.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1044 q_vals: [-12.8, -12.8, -8.67, -12.8, -inf, -12.8, -12.8]
Step 1622 2 visits [1.0, 1.0, 598.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1045 q_vals: [-12.8, -12.8, -8.677, -12.8, -inf, -12.8, -12.8]
Step 1623 2 visits [1.0, 1.0, 599.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1045 q_vals: [-12.8, -12.8, -8.684, -12.8, -inf, -12.8, -12.8]
Step 1624 2 visits [1.0, 1.0, 600.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1046 q_vals: [-12.8, -12.8, -8.669, -12.8, -inf, -12.8, -12.8]
Step 1625 2 visits [1.0, 1.0, 601.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1047 q_vals: [-12.8, -12.8, -8.676, -12.8, -inf, -12.8, -12.8]
Step 1626 2 visits [1.0, 1.0, 602.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1047 q_vals: [-12.8, -12.8, -8.683, -12.8, -inf, -12.8, -12.8]
Step 1627 2 visits [1.0, 1.0, 603.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1047 q_vals: [-12.8, -12.8, -8.69, -12.8, -inf, -12.8, -12.8]
Step 1628 2 visits [1.0, 1.0, 604.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1049 q_vals: [-12.8, -12.8, -8.675, -12.8, -inf, -12.8, -12.8]
Step 1629 2 visits [1.0, 1.0, 605.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1050 q_vals: [-12.8, -12.8, -8.682, -12.8, -inf, -12.8, -12.8]
Step 1630 2 visits [1.0, 1.0, 606.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1051 q_vals: [-12.8, -12.8, -8.689, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1052, "number_of_timesteps": 109322, "per_episode_reward": -367.96, "episode_reward_trend_value": 0.26774892928455196, "biggest_recent_change": 7.8977677675479185},
Step 1631 2 visits [1.0, 1.0, 607.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1052 q_vals: [-12.8, -12.8, -8.675, -12.8, -inf, -12.8, -12.8]
Step 1632 2 visits [1.0, 1.0, 608.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1053 q_vals: [-12.8, -12.8, -8.681, -12.8, -inf, -12.8, -12.8]
Step 1633 2 visits [1.0, 1.0, 609.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1053 q_vals: [-12.8, -12.8, -8.688, -12.8, -inf, -12.8, -12.8]
Step 1634 2 visits [1.0, 1.0, 610.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1053 q_vals: [-12.8, -12.8, -8.674, -12.8, -inf, -12.8, -12.8]
Step 1635 2 visits [1.0, 1.0, 611.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1054 q_vals: [-12.8, -12.8, -8.66, -12.8, -inf, -12.8, -12.8]
Step 1636 2 visits [1.0, 1.0, 612.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1055 q_vals: [-12.8, -12.8, -8.666, -12.8, -inf, -12.8, -12.8]
Step 1637 2 visits [1.0, 1.0, 613.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1055 q_vals: [-12.8, -12.8, -8.652, -12.8, -inf, -12.8, -12.8]
Step 1638 2 visits [1.0, 1.0, 614.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1055 q_vals: [-12.8, -12.8, -8.638, -12.8, -inf, -12.8, -12.8]
Step 1639 2 visits [1.0, 1.0, 615.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1055 q_vals: [-12.8, -12.8, -8.645, -12.8, -inf, -12.8, -12.8]
Step 1640 2 visits [1.0, 1.0, 616.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1057 q_vals: [-12.8, -12.8, -8.652, -12.8, -inf, -12.8, -12.8]
Step 1641 2 visits [1.0, 1.0, 617.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1059 q_vals: [-12.8, -12.8, -8.658, -12.8, -inf, -12.8, -12.8]
Step 1642 2 visits [1.0, 1.0, 618.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1059 q_vals: [-12.8, -12.8, -8.644, -12.8, -inf, -12.8, -12.8]
Step 1643 2 visits [1.0, 1.0, 619.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1059 q_vals: [-12.8, -12.8, -8.651, -12.8, -inf, -12.8, -12.8]
Step 1644 2 visits [1.0, 1.0, 620.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1059 q_vals: [-12.8, -12.8, -8.658, -12.8, -inf, -12.8, -12.8]
Step 1645 2 visits [1.0, 1.0, 621.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1059 q_vals: [-12.8, -12.8, -8.644, -12.8, -inf, -12.8, -12.8]
Step 1646 2 visits [1.0, 1.0, 622.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1059 q_vals: [-12.8, -12.8, -8.651, -12.8, -inf, -12.8, -12.8]
Step 1647 2 visits [1.0, 1.0, 623.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1059 q_vals: [-12.8, -12.8, -8.637, -12.8, -inf, -12.8, -12.8]
Step 1648 2 visits [1.0, 1.0, 624.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1061 q_vals: [-12.8, -12.8, -8.643, -12.8, -inf, -12.8, -12.8]
Step 1649 2 visits [1.0, 1.0, 625.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1061 q_vals: [-12.8, -12.8, -8.65, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1063, "number_of_timesteps": 110418, "per_episode_reward": -366.65, "episode_reward_trend_value": 0.2539955027294392, "biggest_recent_change": 7.8977677675479185},
Step 1650 2 visits [1.0, 1.0, 626.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1063 q_vals: [-12.8, -12.8, -8.657, -12.8, -inf, -12.8, -12.8]
Step 1651 2 visits [1.0, 1.0, 627.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1064 q_vals: [-12.8, -12.8, -8.643, -12.8, -inf, -12.8, -12.8]
Step 1652 2 visits [1.0, 1.0, 628.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1064 q_vals: [-12.8, -12.8, -8.649, -12.8, -inf, -12.8, -12.8]
Step 1653 2 visits [1.0, 1.0, 629.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1064 q_vals: [-12.8, -12.8, -8.656, -12.8, -inf, -12.8, -12.8]
Step 1654 2 visits [1.0, 1.0, 630.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1065 q_vals: [-12.8, -12.8, -8.663, -12.8, -inf, -12.8, -12.8]
Step 1655 2 visits [1.0, 1.0, 631.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1065 q_vals: [-12.8, -12.8, -8.669, -12.8, -inf, -12.8, -12.8]
Step 1656 2 visits [1.0, 1.0, 632.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1065 q_vals: [-12.8, -12.8, -8.676, -12.8, -inf, -12.8, -12.8]
Step 1657 2 visits [1.0, 1.0, 633.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1066 q_vals: [-12.8, -12.8, -8.662, -12.8, -inf, -12.8, -12.8]
Step 1658 2 visits [1.0, 1.0, 634.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1067 q_vals: [-12.8, -12.8, -8.669, -12.8, -inf, -12.8, -12.8]
Step 1659 2 visits [1.0, 1.0, 635.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1067 q_vals: [-12.8, -12.8, -8.675, -12.8, -inf, -12.8, -12.8]
Step 1660 2 visits [1.0, 1.0, 636.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1067 q_vals: [-12.8, -12.8, -8.661, -12.8, -inf, -12.8, -12.8]
Step 1661 2 visits [1.0, 1.0, 637.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1067 q_vals: [-12.8, -12.8, -8.668, -12.8, -inf, -12.8, -12.8]
Step 1662 2 visits [1.0, 1.0, 638.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1069 q_vals: [-12.8, -12.8, -8.674, -12.8, -inf, -12.8, -12.8]
Step 1663 2 visits [1.0, 1.0, 639.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1070 q_vals: [-12.8, -12.8, -8.681, -12.8, -inf, -12.8, -12.8]
Step 1664 2 visits [1.0, 1.0, 640.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1071 q_vals: [-12.8, -12.8, -8.687, -12.8, -inf, -12.8, -12.8]
Step 1665 2 visits [1.0, 1.0, 641.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1072 q_vals: [-12.8, -12.8, -8.694, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1073, "number_of_timesteps": 111680, "per_episode_reward": -365.43, "episode_reward_trend_value": 0.23909595749174234, "biggest_recent_change": 7.8977677675479185},
Step 1666 2 visits [1.0, 1.0, 642.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1073 q_vals: [-12.8, -12.8, -8.68, -12.8, -inf, -12.8, -12.8]
Step 1667 2 visits [1.0, 1.0, 643.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1073 q_vals: [-12.8, -12.8, -8.667, -12.8, -inf, -12.8, -12.8]
Step 1668 2 visits [1.0, 1.0, 644.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1073 q_vals: [-12.8, -12.8, -8.673, -12.8, -inf, -12.8, -12.8]
Step 1669 2 visits [1.0, 1.0, 645.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1074 q_vals: [-12.8, -12.8, -8.679, -12.8, -inf, -12.8, -12.8]
Step 1670 2 visits [1.0, 1.0, 646.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1074 q_vals: [-12.8, -12.8, -8.686, -12.8, -inf, -12.8, -12.8]
Step 1671 2 visits [1.0, 1.0, 647.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1074 q_vals: [-12.8, -12.8, -8.692, -12.8, -inf, -12.8, -12.8]
Step 1672 2 visits [1.0, 1.0, 648.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1075 q_vals: [-12.8, -12.8, -8.699, -12.8, -inf, -12.8, -12.8]
Step 1673 2 visits [1.0, 1.0, 649.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1076 q_vals: [-12.8, -12.8, -8.685, -12.8, -inf, -12.8, -12.8]
Step 1674 2 visits [1.0, 1.0, 650.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1077 q_vals: [-12.8, -12.8, -8.691, -12.8, -inf, -12.8, -12.8]
Step 1675 2 visits [1.0, 1.0, 651.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1077 q_vals: [-12.8, -12.8, -8.678, -12.8, -inf, -12.8, -12.8]
Step 1676 2 visits [1.0, 1.0, 652.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1078 q_vals: [-12.8, -12.8, -8.684, -12.8, -inf, -12.8, -12.8]
Step 1677 2 visits [1.0, 1.0, 653.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1079 q_vals: [-12.8, -12.8, -8.691, -12.8, -inf, -12.8, -12.8]
Step 1678 2 visits [1.0, 1.0, 654.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1080 q_vals: [-12.8, -12.8, -8.697, -12.8, -inf, -12.8, -12.8]
Step 1679 2 visits [1.0, 1.0, 655.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1081 q_vals: [-12.8, -12.8, -8.703, -12.8, -inf, -12.8, -12.8]
Step 1680 2 visits [1.0, 1.0, 656.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1081 q_vals: [-12.8, -12.8, -8.69, -12.8, -inf, -12.8, -12.8]
Step 1681 2 visits [1.0, 1.0, 657.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1082 q_vals: [-12.8, -12.8, -8.677, -12.8, -inf, -12.8, -12.8]
Step 1682 2 visits [1.0, 1.0, 658.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1082 q_vals: [-12.8, -12.8, -8.664, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1083, "number_of_timesteps": 112701, "per_episode_reward": -364.31, "episode_reward_trend_value": 0.22311296894241273, "biggest_recent_change": 7.8977677675479185},
Step 1683 2 visits [1.0, 1.0, 659.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1083 q_vals: [-12.8, -12.8, -8.67, -12.8, -inf, -12.8, -12.8]
Step 1684 2 visits [1.0, 1.0, 660.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1083 q_vals: [-12.8, -12.8, -8.657, -12.8, -inf, -12.8, -12.8]
Step 1685 2 visits [1.0, 1.0, 661.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1083 q_vals: [-12.8, -12.8, -8.644, -12.8, -inf, -12.8, -12.8]
Step 1686 2 visits [1.0, 1.0, 662.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1083 q_vals: [-12.8, -12.8, -8.65, -12.8, -inf, -12.8, -12.8]
Step 1687 2 visits [1.0, 1.0, 663.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1083 q_vals: [-12.8, -12.8, -8.656, -12.8, -inf, -12.8, -12.8]
Step 1688 2 visits [1.0, 1.0, 664.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1085 q_vals: [-12.8, -12.8, -8.662, -12.8, -inf, -12.8, -12.8]
Step 1689 2 visits [1.0, 1.0, 665.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1086 q_vals: [-12.8, -12.8, -8.669, -12.8, -inf, -12.8, -12.8]
Step 1690 2 visits [1.0, 1.0, 666.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1086 q_vals: [-12.8, -12.8, -8.675, -12.8, -inf, -12.8, -12.8]
Step 1691 2 visits [1.0, 1.0, 667.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1088 q_vals: [-12.8, -12.8, -8.668, -12.8, -inf, -12.8, -12.8]
Step 1692 2 visits [1.0, 1.0, 668.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1089 q_vals: [-12.8, -12.8, -8.655, -12.8, -inf, -12.8, -12.8]
Step 1693 2 visits [1.0, 1.0, 669.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1089 q_vals: [-12.8, -12.8, -8.662, -12.8, -inf, -12.8, -12.8]
Step 1694 2 visits [1.0, 1.0, 670.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1089 q_vals: [-12.8, -12.8, -8.668, -12.8, -inf, -12.8, -12.8]
Step 1695 2 visits [1.0, 1.0, 671.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1089 q_vals: [-12.8, -12.8, -8.674, -12.8, -inf, -12.8, -12.8]
Step 1696 2 visits [1.0, 1.0, 672.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1090 q_vals: [-12.8, -12.8, -8.68, -12.8, -inf, -12.8, -12.8]
Step 1697 2 visits [1.0, 1.0, 673.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1091 q_vals: [-12.8, -12.8, -8.686, -12.8, -inf, -12.8, -12.8]
Step 1698 2 visits [1.0, 1.0, 674.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1092 q_vals: [-12.8, -12.8, -8.692, -12.8, -inf, -12.8, -12.8]
Step 1699 2 visits [1.0, 1.0, 675.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1092 q_vals: [-12.8, -12.8, -8.698, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1096, "number_of_timesteps": 114071, "per_episode_reward": -362.99, "episode_reward_trend_value": 0.22360864905584837, "biggest_recent_change": 7.8977677675479185},
Step 1700 2 visits [1.0, 1.0, 676.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1096 q_vals: [-12.8, -12.8, -8.705, -12.8, -inf, -12.8, -12.8]
Step 1701 2 visits [1.0, 1.0, 677.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1096 q_vals: [-12.8, -12.8, -8.692, -12.8, -inf, -12.8, -12.8]
Step 1702 2 visits [1.0, 1.0, 678.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1096 q_vals: [-12.8, -12.8, -8.698, -12.8, -inf, -12.8, -12.8]
Step 1703 2 visits [1.0, 1.0, 679.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1096 q_vals: [-12.8, -12.8, -8.704, -12.8, -inf, -12.8, -12.8]
Step 1704 2 visits [1.0, 1.0, 680.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1096 q_vals: [-12.8, -12.8, -8.71, -12.8, -inf, -12.8, -12.8]
Step 1705 2 visits [1.0, 1.0, 681.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1096 q_vals: [-12.8, -12.8, -8.716, -12.8, -inf, -12.8, -12.8]
Step 1706 2 visits [1.0, 1.0, 682.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1096 q_vals: [-12.8, -12.8, -8.703, -12.8, -inf, -12.8, -12.8]
Step 1707 2 visits [1.0, 1.0, 683.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1099 q_vals: [-12.8, -12.8, -8.709, -12.8, -inf, -12.8, -12.8]
Step 1708 2 visits [1.0, 1.0, 684.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1099 q_vals: [-12.8, -12.8, -8.715, -12.8, -inf, -12.8, -12.8]
Step 1709 2 visits [1.0, 1.0, 685.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1101 q_vals: [-12.8, -12.8, -8.721, -12.8, -inf, -12.8, -12.8]
Step 1710 2 visits [1.0, 1.0, 686.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1101 q_vals: [-12.8, -12.8, -8.708, -12.8, -inf, -12.8, -12.8]
Step 1711 2 visits [1.0, 1.0, 687.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1102 q_vals: [-12.8, -12.8, -8.696, -12.8, -inf, -12.8, -12.8]
Step 1712 2 visits [1.0, 1.0, 688.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1102 q_vals: [-12.8, -12.8, -8.683, -12.8, -inf, -12.8, -12.8]
Step 1713 2 visits [1.0, 1.0, 689.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1103 q_vals: [-12.8, -12.8, -8.689, -12.8, -inf, -12.8, -12.8]
Step 1714 2 visits [1.0, 1.0, 690.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1103 q_vals: [-12.8, -12.8, -8.695, -12.8, -inf, -12.8, -12.8]
Step 1715 2 visits [1.0, 1.0, 691.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1103 q_vals: [-12.8, -12.8, -8.701, -12.8, -inf, -12.8, -12.8]
[-12.8, -12.8, -8.707, -12.8, -inf, -12.8, -12.8]
Step 1717 2 visits [1.0, 1.0, 693.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1105 q_vals: [-12.8, -12.8, -8.713, -12.8, -inf, -12.8, -12.8]
Step 1718 2 visits [1.0, 1.0, 694.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1105 q_vals: [-12.8, -12.8, -8.719, -12.8, -inf, -12.8, -12.8]
Step 1719 2 visits [1.0, 1.0, 695.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1105 q_vals: [-12.8, -12.8, -8.724, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1107, "number_of_timesteps": 115135, "per_episode_reward": -361.12, "episode_reward_trend_value": 0.18980111478932332, "biggest_recent_change": 7.8977677675479185},
Step 1720 2 visits [1.0, 1.0, 696.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1107 q_vals: [-12.8, -12.8, -8.73, -12.8, -inf, -12.8, -12.8]
Step 1721 2 visits [1.0, 1.0, 697.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1108 q_vals: [-12.8, -12.8, -8.718, -12.8, -inf, -12.8, -12.8]
Step 1722 2 visits [1.0, 1.0, 698.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1108 q_vals: [-12.8, -12.8, -8.724, -12.8, -inf, -12.8, -12.8]
Step 1723 2 visits [1.0, 1.0, 699.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1108 q_vals: [-12.8, -12.8, -8.729, -12.8, -inf, -12.8, -12.8]
Step 1724 2 visits [1.0, 1.0, 700.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1109 q_vals: [-12.8, -12.8, -8.717, -12.8, -inf, -12.8, -12.8]
Step 1725 2 visits [1.0, 1.0, 701.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1110 q_vals: [-12.8, -12.8, -8.723, -12.8, -inf, -12.8, -12.8]
Step 1726 2 visits [1.0, 1.0, 702.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1110 q_vals: [-12.8, -12.8, -8.71, -12.8, -inf, -12.8, -12.8]
Step 1727 2 visits [1.0, 1.0, 703.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1111 q_vals: [-12.8, -12.8, -8.716, -12.8, -inf, -12.8, -12.8]
Step 1728 2 visits [1.0, 1.0, 704.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1111 q_vals: [-12.8, -12.8, -8.722, -12.8, -inf, -12.8, -12.8]
Step 1729 2 visits [1.0, 1.0, 705.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1112 q_vals: [-12.8, -12.8, -8.71, -12.8, -inf, -12.8, -12.8]
Step 1730 2 visits [1.0, 1.0, 706.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1113 q_vals: [-12.8, -12.8, -8.715, -12.8, -inf, -12.8, -12.8]
Step 1731 2 visits [1.0, 1.0, 707.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1113 q_vals: [-12.8, -12.8, -8.721, -12.8, -inf, -12.8, -12.8]
Step 1732 2 visits [1.0, 1.0, 708.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1113 q_vals: [-12.8, -12.8, -8.727, -12.8, -inf, -12.8, -12.8]
Step 1733 2 visits [1.0, 1.0, 709.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1113 q_vals: [-12.8, -12.8, -8.715, -12.8, -inf, -12.8, -12.8]
Step 1734 2 visits [1.0, 1.0, 710.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1114 q_vals: [-12.8, -12.8, -8.72, -12.8, -inf, -12.8, -12.8]
Step 1735 2 visits [1.0, 1.0, 711.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1115 q_vals: [-12.8, -12.8, -8.726, -12.8, -inf, -12.8, -12.8]
Step 1736 2 visits [1.0, 1.0, 712.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1115 q_vals: [-12.8, -12.8, -8.732, -12.8, -inf, -12.8, -12.8]
Step 1737 2 visits [1.0, 1.0, 713.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1116 q_vals: [-12.8, -12.8, -8.738, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1117, "number_of_timesteps": 116368, "per_episode_reward": -359.87, "episode_reward_trend_value": 0.17036410819940467, "biggest_recent_change": 7.8977677675479185},
Step 1738 2 visits [1.0, 1.0, 714.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1117 q_vals: [-12.8, -12.8, -8.725, -12.8, -inf, -12.8, -12.8]
Step 1739 2 visits [1.0, 1.0, 715.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1117 q_vals: [-12.8, -12.8, -8.731, -12.8, -inf, -12.8, -12.8]
Step 1740 2 visits [1.0, 1.0, 716.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1118 q_vals: [-12.8, -12.8, -8.719, -12.8, -inf, -12.8, -12.8]
Step 1741 2 visits [1.0, 1.0, 717.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1118 q_vals: [-12.8, -12.8, -8.724, -12.8, -inf, -12.8, -12.8]
Step 1742 2 visits [1.0, 1.0, 718.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1120 q_vals: [-12.8, -12.8, -8.73, -12.8, -inf, -12.8, -12.8]
Step 1743 2 visits [1.0, 1.0, 719.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1120 q_vals: [-12.8, -12.8, -8.718, -12.8, -inf, -12.8, -12.8]
Step 1744 2 visits [1.0, 1.0, 720.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1121 q_vals: [-12.8, -12.8, -8.724, -12.8, -inf, -12.8, -12.8]
Step 1745 2 visits [1.0, 1.0, 721.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1121 q_vals: [-12.8, -12.8, -8.729, -12.8, -inf, -12.8, -12.8]
Step 1746 2 visits [1.0, 1.0, 722.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1122 q_vals: [-12.8, -12.8, -8.735, -12.8, -inf, -12.8, -12.8]
Step 1747 2 visits [1.0, 1.0, 723.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1123 q_vals: [-12.8, -12.8, -8.741, -12.8, -inf, -12.8, -12.8]
Step 1748 2 visits [1.0, 1.0, 724.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1123 q_vals: [-12.8, -12.8, -8.746, -12.8, -inf, -12.8, -12.8]
Step 1749 2 visits [1.0, 1.0, 725.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1123 q_vals: [-12.8, -12.8, -8.734, -12.8, -inf, -12.8, -12.8]
Step 1750 2 visits [1.0, 1.0, 726.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1124 q_vals: [-12.8, -12.8, -8.722, -12.8, -inf, -12.8, -12.8]
Step 1751 2 visits [1.0, 1.0, 727.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1124 q_vals: [-12.8, -12.8, -8.728, -12.8, -inf, -12.8, -12.8]
Step 1752 2 visits [1.0, 1.0, 728.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1124 q_vals: [-12.8, -12.8, -8.716, -12.8, -inf, -12.8, -12.8]
Step 1753 2 visits [1.0, 1.0, 729.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1124 q_vals: [-12.8, -12.8, -8.721, -12.8, -inf, -12.8, -12.8]
Step 1754 2 visits [1.0, 1.0, 730.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1126 q_vals: [-12.8, -12.8, -8.727, -12.8, -inf, -12.8, -12.8]
Step 1755 2 visits [1.0, 1.0, 731.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1126 q_vals: [-12.8, -12.8, -8.732, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1127, "number_of_timesteps": 117525, "per_episode_reward": -358.45, "episode_reward_trend_value": 0.19546916607423742, "biggest_recent_change": 7.8977677675479185},
Step 1756 2 visits [1.0, 1.0, 732.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1127 q_vals: [-12.8, -12.8, -8.721, -12.8, -inf, -12.8, -12.8]
visits [1.0, 1.0, 733.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1128 q_vals: [-12.8, -12.8, -8.726, -12.8, -inf, -12.8, -12.8]
Step 1758 2 visits [1.0, 1.0, 734.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1129 q_vals: [-12.8, -12.8, -8.732, -12.8, -inf, -12.8, -12.8]
Step 1759 2 visits [1.0, 1.0, 735.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1129 q_vals: [-12.8, -12.8, -8.737, -12.8, -inf, -12.8, -12.8]
Step 1760 2 visits [1.0, 1.0, 736.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1130 q_vals: [-12.8, -12.8, -8.743, -12.8, -inf, -12.8, -12.8]
Step 1761 2 visits [1.0, 1.0, 737.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1130 q_vals: [-12.8, -12.8, -8.748, -12.8, -inf, -12.8, -12.8]
Step 1762 2 visits [1.0, 1.0, 738.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1130 q_vals: [-12.8, -12.8, -8.754, -12.8, -inf, -12.8, -12.8]
Step 1763 2 visits [1.0, 1.0, 739.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1131 q_vals: [-12.8, -12.8, -8.759, -12.8, -inf, -12.8, -12.8]
Step 1764 2 visits [1.0, 1.0, 740.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1132 q_vals: [-12.8, -12.8, -8.764, -12.8, -inf, -12.8, -12.8]
Step 1765 2 visits [1.0, 1.0, 741.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1132 q_vals: [-12.8, -12.8, -8.77, -12.8, -inf, -12.8, -12.8]
Step 1766 2 visits [1.0, 1.0, 742.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1133 q_vals: [-12.8, -12.8, -8.758, -12.8, -inf, -12.8, -12.8]
Step 1767 2 visits [1.0, 1.0, 743.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1133 q_vals: [-12.8, -12.8, -8.746, -12.8, -inf, -12.8, -12.8]
Step 1768 2 visits [1.0, 1.0, 744.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1135 q_vals: [-12.8, -12.8, -8.752, -12.8, -inf, -12.8, -12.8]
Step 1769 2 visits [1.0, 1.0, 745.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1135 q_vals: [-12.8, -12.8, -8.757, -12.8, -inf, -12.8, -12.8]
Step 1770 2 visits [1.0, 1.0, 746.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1135 q_vals: [-12.8, -12.8, -8.763, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1137, "number_of_timesteps": 118650, "per_episode_reward": -357.4, "episode_reward_trend_value": 0.2051148060633965, "biggest_recent_change": 7.8977677675479185},
Step 1771 2 visits [1.0, 1.0, 747.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1137 q_vals: [-12.8, -12.8, -8.768, -12.8, -inf, -12.8, -12.8]
Step 1772 2 visits [1.0, 1.0, 748.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1138 q_vals: [-12.8, -12.8, -8.773, -12.8, -inf, -12.8, -12.8]
Step 1773 2 visits [1.0, 1.0, 749.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1138 q_vals: [-12.8, -12.8, -8.762, -12.8, -inf, -12.8, -12.8]
Step 1774 2 visits [1.0, 1.0, 750.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1138 q_vals: [-12.8, -12.8, -8.767, -12.8, -inf, -12.8, -12.8]
Step 1775 2 visits [1.0, 1.0, 751.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1138 q_vals: [-12.8, -12.8, -8.772, -12.8, -inf, -12.8, -12.8]
Step 1776 2 visits [1.0, 1.0, 752.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1140 q_vals: [-12.8, -12.8, -8.761, -12.8, -inf, -12.8, -12.8]
Step 1777 2 visits [1.0, 1.0, 753.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1140 q_vals: [-12.8, -12.8, -8.766, -12.8, -inf, -12.8, -12.8]
Step 1778 2 visits [1.0, 1.0, 754.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1140 q_vals: [-12.8, -12.8, -8.755, -12.8, -inf, -12.8, -12.8]
Step 1779 2 visits [1.0, 1.0, 755.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1142 q_vals: [-12.8, -12.8, -8.76, -12.8, -inf, -12.8, -12.8]
Step 1780 2 visits [1.0, 1.0, 756.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1144 q_vals: [-12.8, -12.8, -8.765, -12.8, -inf, -12.8, -12.8]
Step 1781 2 visits [1.0, 1.0, 757.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1144 q_vals: [-12.8, -12.8, -8.754, -12.8, -inf, -12.8, -12.8]
Step 1782 2 visits [1.0, 1.0, 758.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1144 q_vals: [-12.8, -12.8, -8.759, -12.8, -inf, -12.8, -12.8]
Step 1783 2 visits [1.0, 1.0, 759.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1144 q_vals: [-12.8, -12.8, -8.764, -12.8, -inf, -12.8, -12.8]
Step 1784 2 visits [1.0, 1.0, 760.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1145 q_vals: [-12.8, -12.8, -8.753, -12.8, -inf, -12.8, -12.8]
Step 1785 2 visits [1.0, 1.0, 761.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1145 q_vals: [-12.8, -12.8, -8.758, -12.8, -inf, -12.8, -12.8]
Step 1786 2 visits [1.0, 1.0, 762.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1146 q_vals: [-12.8, -12.8, -8.763, -12.8, -inf, -12.8, -12.8]
Step 1787 2 visits [1.0, 1.0, 763.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1146 q_vals: [-12.8, -12.8, -8.769, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1148, "number_of_timesteps": 119762, "per_episode_reward": -355.99, "episode_reward_trend_value": 0.13297495436204815, "biggest_recent_change": 1.8694415999935359},
Step 1788 2 visits [1.0, 1.0, 764.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1148 q_vals: [-12.8, -12.8, -8.757, -12.8, -inf, -12.8, -12.8]
Step 1789 2 visits [1.0, 1.0, 765.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1150 q_vals: [-12.8, -12.8, -8.763, -12.8, -inf, -12.8, -12.8]
Step 1790 2 visits [1.0, 1.0, 766.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1150 q_vals: [-12.8, -12.8, -8.768, -12.8, -inf, -12.8, -12.8]
Step 1791 2 visits [1.0, 1.0, 767.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1151 q_vals: [-12.8, -12.8, -8.773, -12.8, -inf, -12.8, -12.8]
Step 1792 2 visits [1.0, 1.0, 768.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1151 q_vals: [-12.8, -12.8, -8.778, -12.8, -inf, -12.8, -12.8]
Step 1793 2 visits [1.0, 1.0, 769.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1152 q_vals: [-12.8, -12.8, -8.784, -12.8, -inf, -12.8, -12.8]
Step 1794 2 visits [1.0, 1.0, 770.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1152 q_vals: [-12.8, -12.8, -8.772, -12.8, -inf, -12.8, -12.8]
Step 1795 2 visits [1.0, 1.0, 771.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1152 q_vals: [-12.8, -12.8, -8.777, -12.8, -inf, -12.8, -12.8]
Step 1796 2 visits [1.0, 1.0, 772.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1152 q_vals: [-12.8, -12.8, -8.783, -12.8, -inf, -12.8, -12.8]
Step 1797 2 visits [1.0, 1.0, 773.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1152 q_vals: [-12.8, -12.8, -8.788, -12.8, -inf, -12.8, -12.8]
Step 1798 2 visits [1.0, 1.0, 774.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1152 q_vals: [-12.8, -12.8, -8.793, -12.8, -inf, -12.8, -12.8]
Step 1799 2 visits [1.0, 1.0, 775.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1152 q_vals: [-12.8, -12.8, -8.798, -12.8, -inf, -12.8, -12.8]
Step 1800 2 visits [1.0, 1.0, 776.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1153 q_vals: [-12.8, -12.8, -8.803, -12.8, -inf, -12.8, -12.8]
Step 1801 2 visits [1.0, 1.0, 777.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1156 q_vals: [-12.8, -12.8, -8.807, -12.8, -inf, -12.8, -12.8]
Step 1802 2 visits [1.0, 1.0, 778.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1156 q_vals: [-12.8, -12.8, -8.812, -12.8, -inf, -12.8, -12.8]
Step 1803 2 visits [1.0, 1.0, 779.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1156 q_vals: [-12.8, -12.8, -8.817, -12.8, -inf, -12.8, -12.8]
Step 1804 2 visits [1.0, 1.0, 780.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1156 q_vals: [-12.8, -12.8, -8.822, -12.8, -inf, -12.8, -12.8]
Step 1805 2 visits [1.0, 1.0, 781.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1157 q_vals: [-12.8, -12.8, -8.827, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1158, "number_of_timesteps": 120950, "per_episode_reward": -355.69, "episode_reward_trend_value": 0.12170942308433344, "biggest_recent_change": 1.8694415999935359},
Step 1806 2 visits [1.0, 1.0, 782.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1158 q_vals: [-12.8, -12.8, -8.832, -12.8, -inf, -12.8, -12.8]
Step 1807 2 visits [1.0, 1.0, 783.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1158 q_vals: [-12.8, -12.8, -8.837, -12.8, -inf, -12.8, -12.8]
Step 1808 2 visits [1.0, 1.0, 784.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1158 q_vals: [-12.8, -12.8, -8.842, -12.8, -inf, -12.8, -12.8]
Step 1809 2 visits [1.0, 1.0, 785.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1158 q_vals: [-12.8, -12.8, -8.847, -12.8, -inf, -12.8, -12.8]
Step 1810 2 visits [1.0, 1.0, 786.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1159 q_vals: [-12.8, -12.8, -8.852, -12.8, -inf, -12.8, -12.8]
Step 1811 2 visits [1.0, 1.0, 787.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1160 q_vals: [-12.8, -12.8, -8.857, -12.8, -inf, -12.8, -12.8]
Step 1812 2 visits [1.0, 1.0, 788.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1161 q_vals: [-12.8, -12.8, -8.862, -12.8, -inf, -12.8, -12.8]
Step 1813 2 visits [1.0, 1.0, 789.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1163 q_vals: [-12.8, -12.8, -8.867, -12.8, -inf, -12.8, -12.8]
Step 1814 2 visits [1.0, 1.0, 790.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1163 q_vals: [-12.8, -12.8, -8.872, -12.8, -inf, -12.8, -12.8]
Step 1815 2 visits [1.0, 1.0, 791.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1163 q_vals: [-12.8, -12.8, -8.861, -12.8, -inf, -12.8, -12.8]
Step 1816 2 visits [1.0, 1.0, 792.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1163 q_vals: [-12.8, -12.8, -8.85, -12.8, -inf, -12.8, -12.8]
Step 1817 2 visits [1.0, 1.0, 793.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1164 q_vals: [-12.8, -12.8, -8.855, -12.8, -inf, -12.8, -12.8]
Step 1818 2 visits [1.0, 1.0, 794.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1165 q_vals: [-12.8, -12.8, -8.86, -12.8, -inf, -12.8, -12.8]
Step 1819 2 visits [1.0, 1.0, 795.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1166 q_vals: [-12.8, -12.8, -8.849, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1168, "number_of_timesteps": 121998, "per_episode_reward": -354.97, "episode_reward_trend_value": 0.11625203161586342, "biggest_recent_change": 1.8694415999935359},
Step 1820 2 visits [1.0, 1.0, 796.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1168 q_vals: [-12.8, -12.8, -8.854, -12.8, -inf, -12.8, -12.8]
Step 1821 2 visits [1.0, 1.0, 797.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1168 q_vals: [-12.8, -12.8, -8.859, -12.8, -inf, -12.8, -12.8]
Step 1822 2 visits [1.0, 1.0, 798.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1168 q_vals: [-12.8, -12.8, -8.848, -12.8, -inf, -12.8, -12.8]
Step 1823 2 visits [1.0, 1.0, 799.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1169 q_vals: [-12.8, -12.8, -8.853, -12.8, -inf, -12.8, -12.8]
Step 1824 2 visits [1.0, 1.0, 800.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1169 q_vals: [-12.8, -12.8, -8.842, -12.8, -inf, -12.8, -12.8]
Step 1825 2 visits [1.0, 1.0, 801.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1169 q_vals: [-12.8, -12.8, -8.846, -12.8, -inf, -12.8, -12.8]
Step 1826 2 visits [1.0, 1.0, 802.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1169 q_vals: [-12.8, -12.8, -8.835, -12.8, -inf, -12.8, -12.8]
Step 1827 2 visits [1.0, 1.0, 803.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1170 q_vals: [-12.8, -12.8, -8.84, -12.8, -inf, -12.8, -12.8]
Step 1828 2 visits [1.0, 1.0, 804.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1173 q_vals: [-12.8, -12.8, -8.845, -12.8, -inf, -12.8, -12.8]
Step 1829 2 visits [1.0, 1.0, 805.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1173 q_vals: [-12.8, -12.8, -8.85, -12.8, -inf, -12.8, -12.8]
Step 1830 2 visits [1.0, 1.0, 806.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1174 q_vals: [-12.8, -12.8, -8.839, -12.8, -inf, -12.8, -12.8]
Step 1831 2 visits [1.0, 1.0, 807.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1174 q_vals: [-12.8, -12.8, -8.828, -12.8, -inf, -12.8, -12.8]
Step 1832 2 visits [1.0, 1.0, 808.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1175 q_vals: [-12.8, -12.8, -8.833, -12.8, -inf, -12.8, -12.8]
Step 1833 2 visits [1.0, 1.0, 809.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1175 q_vals: [-12.8, -12.8, -8.838, -12.8, -inf, -12.8, -12.8]
Step 1834 2 visits [1.0, 1.0, 810.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1176 q_vals: [-12.8, -12.8, -8.827, -12.8, -inf, -12.8, -12.8]
Step 1835 2 visits [1.0, 1.0, 811.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1176 q_vals: [-12.8, -12.8, -8.832, -12.8, -inf, -12.8, -12.8]
Step 1836 2 visits [1.0, 1.0, 812.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1176 q_vals: [-12.8, -12.8, -8.821, -12.8, -inf, -12.8, -12.8]
Step 1837 2 visits [1.0, 1.0, 813.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1176 q_vals: [-12.8, -12.8, -8.826, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1178, "number_of_timesteps": 123031, "per_episode_reward": -354.43, "episode_reward_trend_value": 0.10976351295338291, "biggest_recent_change": 1.8694415999935359},
Step 1838 2 visits [1.0, 1.0, 814.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1178 q_vals: [-12.8, -12.8, -8.831, -12.8, -inf, -12.8, -12.8]
Step 1839 2 visits [1.0, 1.0, 815.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1178 q_vals: [-12.8, -12.8, -8.836, -12.8, -inf, -12.8, -12.8]
Step 1840 2 visits [1.0, 1.0, 816.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1179 q_vals: [-12.8, -12.8, -8.841, -12.8, -inf, -12.8, -12.8]
Step 1841 2 visits [1.0, 1.0, 817.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1180 q_vals: [-12.8, -12.8, -8.83, -12.8, -inf, -12.8, -12.8]
Step 1842 2 visits [1.0, 1.0, 818.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1181 q_vals: [-12.8, -12.8, -8.835, -12.8, -inf, -12.8, -12.8]
Step 1843 2 visits [1.0, 1.0, 819.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1181 q_vals: [-12.8, -12.8, -8.84, -12.8, -inf, -12.8, -12.8]
Step 1844 2 visits [1.0, 1.0, 820.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1181 q_vals: [-12.8, -12.8, -8.844, -12.8, -inf, -12.8, -12.8]
Step 1845 2 visits [1.0, 1.0, 821.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1181 q_vals: [-12.8, -12.8, -8.849, -12.8, -inf, -12.8, -12.8]
Step 1846 2 visits [1.0, 1.0, 822.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1182 q_vals: [-12.8, -12.8, -8.854, -12.8, -inf, -12.8, -12.8]
Step 1847 2 visits [1.0, 1.0, 823.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1184 q_vals: [-12.8, -12.8, -8.859, -12.8, -inf, -12.8, -12.8]
Step 1848 2 visits [1.0, 1.0, 824.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1184 q_vals: [-12.8, -12.8, -8.848, -12.8, -inf, -12.8, -12.8]
Step 1849 2 visits [1.0, 1.0, 825.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1184 q_vals: [-12.8, -12.8, -8.853, -12.8, -inf, -12.8, -12.8]
Step 1850 2 visits [1.0, 1.0, 826.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1186 q_vals: [-12.8, -12.8, -8.853, -12.8, -inf, -12.8, -12.8]
Step 1851 2 visits [1.0, 1.0, 827.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1186 q_vals: [-12.8, -12.8, -8.858, -12.8, -inf, -12.8, -12.8]
Step 1852 2 visits [1.0, 1.0, 828.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1186 q_vals: [-12.8, -12.8, -8.862, -12.8, -inf, -12.8, -12.8]
Step 1853 2 visits [1.0, 1.0, 829.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1186 q_vals: [-12.8, -12.8, -8.867, -12.8, -inf, -12.8, -12.8]
Step 1854 2 visits [1.0, 1.0, 830.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1186 q_vals: [-12.8, -12.8, -8.872, -12.8, -inf, -12.8, -12.8]
Step 1855 2 visits [1.0, 1.0, 831.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1186 q_vals: [-12.8, -12.8, -8.877, -12.8, -inf, -12.8, -12.8]
Step 1856 2 visits [1.0, 1.0, 832.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1186 q_vals: [-12.8, -12.8, -8.881, -12.8, -inf, -12.8, -12.8]
Step 1857 2 visits [1.0, 1.0, 833.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1187 q_vals: [-12.8, -12.8, -8.886, -12.8, -inf, -12.8, -12.8]
Step 1858 2 visits [1.0, 1.0, 834.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1187 q_vals: [-12.8, -12.8, -8.891, -12.8, -inf, -12.8, -12.8]
Step 1859 2 visits [1.0, 1.0, 835.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1187 q_vals: [-12.8, -12.8, -8.895, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1188, "number_of_timesteps": 124260, "per_episode_reward": -352.23, "episode_reward_trend_value": 0.11958922593340668, "biggest_recent_change": 2.195712316130596},
Step 1860 2 visits [1.0, 1.0, 836.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1188 q_vals: [-12.8, -12.8, -8.9, -12.8, -inf, -12.8, -12.8]
Step 1861 2 visits [1.0, 1.0, 837.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1190 q_vals: [-12.8, -12.8, -8.905, -12.8, -inf, -12.8, -12.8]
Step 1862 2 visits [1.0, 1.0, 838.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1191 q_vals: [-12.8, -12.8, -8.894, -12.8, -inf, -12.8, -12.8]
Step 1863 2 visits [1.0, 1.0, 839.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1191 q_vals: [-12.8, -12.8, -8.899, -12.8, -inf, -12.8, -12.8]
Step 1864 2 visits [1.0, 1.0, 840.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1191 q_vals: [-12.8, -12.8, -8.903, -12.8, -inf, -12.8, -12.8]
Step 1865 2 visits [1.0, 1.0, 841.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1191 q_vals: [-12.8, -12.8, -8.908, -12.8, -inf, -12.8, -12.8]
Step 1866 2 visits [1.0, 1.0, 842.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1191 q_vals: [-12.8, -12.8, -8.913, -12.8, -inf, -12.8, -12.8]
Step 1867 2 visits [1.0, 1.0, 843.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1191 q_vals: [-12.8, -12.8, -8.902, -12.8, -inf, -12.8, -12.8]
Step 1868 2 visits [1.0, 1.0, 844.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1192 q_vals: [-12.8, -12.8, -8.892, -12.8, -inf, -12.8, -12.8]
Step 1869 2 visits [1.0, 1.0, 845.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1194 q_vals: [-12.8, -12.8, -8.896, -12.8, -inf, -12.8, -12.8]
Step 1870 2 visits [1.0, 1.0, 846.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1196 q_vals: [-12.8, -12.8, -8.886, -12.8, -inf, -12.8, -12.8]
Step 1871 2 visits [1.0, 1.0, 847.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1197 q_vals: [-12.8, -12.8, -8.875, -12.8, -inf, -12.8, -12.8]
Step 1872 2 visits [1.0, 1.0, 848.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1197 q_vals: [-12.8, -12.8, -8.88, -12.8, -inf, -12.8, -12.8]
Step 1873 2 visits [1.0, 1.0, 849.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1197 q_vals: [-12.8, -12.8, -8.884, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1198, "number_of_timesteps": 125604, "per_episode_reward": -350.7, "episode_reward_trend_value": 0.1157978446431994, "biggest_recent_change": 2.195712316130596},
Step 1874 2 visits [1.0, 1.0, 850.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1198 q_vals: [-12.8, -12.8, -8.874, -12.8, -inf, -12.8, -12.8]
Step 1875 2 visits [1.0, 1.0, 851.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1199 q_vals: [-12.8, -12.8, -8.879, -12.8, -inf, -12.8, -12.8]
Step 1876 2 visits [1.0, 1.0, 852.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1200 q_vals: [-12.8, -12.8, -8.883, -12.8, -inf, -12.8, -12.8]
Step 1877 2 visits [1.0, 1.0, 853.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1201 q_vals: [-12.8, -12.8, -8.873, -12.8, -inf, -12.8, -12.8]
Step 1878 2 visits [1.0, 1.0, 854.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1201 q_vals: [-12.8, -12.8, -8.862, -12.8, -inf, -12.8, -12.8]
Step 1879 2 visits [1.0, 1.0, 855.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1203 q_vals: [-12.8, -12.8, -8.867, -12.8, -inf, -12.8, -12.8]
Step 1880 2 visits [1.0, 1.0, 856.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1204 q_vals: [-12.8, -12.8, -8.857, -12.8, -inf, -12.8, -12.8]
Step 1881 2 visits [1.0, 1.0, 857.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1204 q_vals: [-12.8, -12.8, -8.861, -12.8, -inf, -12.8, -12.8]
Step 1882 2 visits [1.0, 1.0, 858.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1204 q_vals: [-12.8, -12.8, -8.866, -12.8, -inf, -12.8, -12.8]
Step 1883 2 visits [1.0, 1.0, 859.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1205 q_vals: [-12.8, -12.8, -8.87, -12.8, -inf, -12.8, -12.8]
Step 1884 2 visits [1.0, 1.0, 860.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1205 q_vals: [-12.8, -12.8, -8.86, -12.8, -inf, -12.8, -12.8]
Step 1885 2 visits [1.0, 1.0, 861.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1207 q_vals: [-12.8, -12.8, -8.865, -12.8, -inf, -12.8, -12.8]
Step 1886 2 visits [1.0, 1.0, 862.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1207 q_vals: [-12.8, -12.8, -8.862, -12.8, -inf, -12.8, -12.8]
Step 1887 2 visits [1.0, 1.0, 863.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1207 q_vals: [-12.8, -12.8, -8.852, -12.8, -inf, -12.8, -12.8]
Step 1888 2 visits [1.0, 1.0, 864.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1207 q_vals: [-12.8, -12.8, -8.857, -12.8, -inf, -12.8, -12.8]
Step 1889 2 visits [1.0, 1.0, 865.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1207 q_vals: [-12.8, -12.8, -8.861, -12.8, -inf, -12.8, -12.8]
Step 1890 2 visits [1.0, 1.0, 866.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1207 q_vals: [-12.8, -12.8, -8.866, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1209, "number_of_timesteps": 126572, "per_episode_reward": -348.45, "episode_reward_trend_value": 0.12683205156407856, "biggest_recent_change": 2.2480677980305472},
Step 1891 2 visits [1.0, 1.0, 867.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1209 q_vals: [-12.8, -12.8, -8.87, -12.8, -inf, -12.8, -12.8]
Step 1892 2 visits [1.0, 1.0, 868.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1210 q_vals: [-12.8, -12.8, -8.875, -12.8, -inf, -12.8, -12.8]
Step 1893 2 visits [1.0, 1.0, 869.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1210 q_vals: [-12.8, -12.8, -8.879, -12.8, -inf, -12.8, -12.8]
Step 1894 2 visits [1.0, 1.0, 870.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1212 q_vals: [-12.8, -12.8, -8.884, -12.8, -inf, -12.8, -12.8]
Step 1895 2 visits [1.0, 1.0, 871.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1212 q_vals: [-12.8, -12.8, -8.888, -12.8, -inf, -12.8, -12.8]
Step 1896 2 visits [1.0, 1.0, 872.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1212 q_vals: [-12.8, -12.8, -8.878, -12.8, -inf, -12.8, -12.8]
Step 1897 2 visits [1.0, 1.0, 873.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1212 q_vals: [-12.8, -12.8, -8.868, -12.8, -inf, -12.8, -12.8]
Step 1898 2 visits [1.0, 1.0, 874.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1212 q_vals: [-12.8, -12.8, -8.872, -12.8, -inf, -12.8, -12.8]
Step 1899 2 visits [1.0, 1.0, 875.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1212 q_vals: [-12.8, -12.8, -8.877, -12.8, -inf, -12.8, -12.8]
Step 1900 2 visits [1.0, 1.0, 876.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1213 q_vals: [-12.8, -12.8, -8.881, -12.8, -inf, -12.8, -12.8]
Step 1901 2 visits [1.0, 1.0, 877.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1214 q_vals: [-12.8, -12.8, -8.886, -12.8, -inf, -12.8, -12.8]
Step 1902 2 visits [1.0, 1.0, 878.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1214 q_vals: [-12.8, -12.8, -8.89, -12.8, -inf, -12.8, -12.8]
Step 1903 2 visits [1.0, 1.0, 879.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1214 q_vals: [-12.8, -12.8, -8.88, -12.8, -inf, -12.8, -12.8]
Step 1904 2 visits [1.0, 1.0, 880.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1215 q_vals: [-12.8, -12.8, -8.87, -12.8, -inf, -12.8, -12.8]
Step 1905 2 visits [1.0, 1.0, 881.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1216 q_vals: [-12.8, -12.8, -8.866, -12.8, -inf, -12.8, -12.8]
Step 1906 2 visits [1.0, 1.0, 882.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1218 q_vals: [-12.8, -12.8, -8.87, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1220, "number_of_timesteps": 127955, "per_episode_reward": -345.59, "episode_reward_trend_value": 0.14284857542193094, "biggest_recent_change": 2.862725420370566},
Step 1907 2 visits [1.0, 1.0, 883.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1220 q_vals: [-12.8, -12.8, -8.86, -12.8, -inf, -12.8, -12.8]
Step 1908 2 visits [1.0, 1.0, 884.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1221 q_vals: [-12.8, -12.8, -8.864, -12.8, -inf, -12.8, -12.8]
Step 1909 2 visits [1.0, 1.0, 885.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1221 q_vals: [-12.8, -12.8, -8.854, -12.8, -inf, -12.8, -12.8]
Step 1910 2 visits [1.0, 1.0, 886.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1221 q_vals: [-12.8, -12.8, -8.844, -12.8, -inf, -12.8, -12.8]
Step 1911 2 visits [1.0, 1.0, 887.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1222 q_vals: [-12.8, -12.8, -8.849, -12.8, -inf, -12.8, -12.8]
Step 1912 2 visits [1.0, 1.0, 888.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1222 q_vals: [-12.8, -12.8, -8.851, -12.8, -inf, -12.8, -12.8]
Step 1913 2 visits [1.0, 1.0, 889.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1222 q_vals: [-12.8, -12.8, -8.855, -12.8, -inf, -12.8, -12.8]
Step 1914 2 visits [1.0, 1.0, 890.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1224 q_vals: [-12.8, -12.8, -8.845, -12.8, -inf, -12.8, -12.8]
Step 1915 2 visits [1.0, 1.0, 891.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1225 q_vals: [-12.8, -12.8, -8.85, -12.8, -inf, -12.8, -12.8]
Step 1916 2 visits [1.0, 1.0, 892.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1226 q_vals: [-12.8, -12.8, -8.854, -12.8, -inf, -12.8, -12.8]
Step 1917 2 visits [1.0, 1.0, 893.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1227 q_vals: [-12.8, -12.8, -8.844, -12.8, -inf, -12.8, -12.8]
Step 1918 2 visits [1.0, 1.0, 894.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1228 q_vals: [-12.8, -12.8, -8.834, -12.8, -inf, -12.8, -12.8]
Step 1919 2 visits [1.0, 1.0, 895.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1229 q_vals: [-12.8, -12.8, -8.839, -12.8, -inf, -12.8, -12.8]
Step 1920 2 visits [1.0, 1.0, 896.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1229 q_vals: [-12.8, -12.8, -8.843, -12.8, -inf, -12.8, -12.8]
Step 1921 2 visits [1.0, 1.0, 897.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1229 q_vals: [-12.8, -12.8, -8.848, -12.8, -inf, -12.8, -12.8]
Step 1922 2 visits [1.0, 1.0, 898.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1229 q_vals: [-12.8, -12.8, -8.852, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1230, "number_of_timesteps": 128780, "per_episode_reward": -342.34, "episode_reward_trend_value": 0.16734978176073065, "biggest_recent_change": 3.254908175623143},
Step 1923 2 visits [1.0, 1.0, 899.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1230 q_vals: [-12.8, -12.8, -8.856, -12.8, -inf, -12.8, -12.8]
Step 1924 2 visits [1.0, 1.0, 900.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1231 q_vals: [-12.8, -12.8, -8.847, -12.8, -inf, -12.8, -12.8]
Step 1925 2 visits [1.0, 1.0, 901.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1232 q_vals: [-12.8, -12.8, -8.847, -12.8, -inf, -12.8, -12.8]
Step 1926 2 visits [1.0, 1.0, 902.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1232 q_vals: [-12.8, -12.8, -8.851, -12.8, -inf, -12.8, -12.8]
Step 1927 2 visits [1.0, 1.0, 903.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1233 q_vals: [-12.8, -12.8, -8.856, -12.8, -inf, -12.8, -12.8]
Step 1928 2 visits [1.0, 1.0, 904.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1233 q_vals: [-12.8, -12.8, -8.86, -12.8, -inf, -12.8, -12.8]
Step 1929 2 visits [1.0, 1.0, 905.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1234 q_vals: [-12.8, -12.8, -8.85, -12.8, -inf, -12.8, -12.8]
Step 1930 2 visits [1.0, 1.0, 906.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1235 q_vals: [-12.8, -12.8, -8.841, -12.8, -inf, -12.8, -12.8]
Step 1931 2 visits [1.0, 1.0, 907.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1237 q_vals: [-12.8, -12.8, -8.845, -12.8, -inf, -12.8, -12.8]
Step 1932 2 visits [1.0, 1.0, 908.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1237 q_vals: [-12.8, -12.8, -8.835, -12.8, -inf, -12.8, -12.8]
Step 1933 2 visits [1.0, 1.0, 909.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1237 q_vals: [-12.8, -12.8, -8.834, -12.8, -inf, -12.8, -12.8]
Step 1934 2 visits [1.0, 1.0, 910.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1237 q_vals: [-12.8, -12.8, -8.837, -12.8, -inf, -12.8, -12.8]
Step 1935 2 visits [1.0, 1.0, 911.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1238 q_vals: [-12.8, -12.8, -8.841, -12.8, -inf, -12.8, -12.8]
Step 1936 2 visits [1.0, 1.0, 912.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1239 q_vals: [-12.8, -12.8, -8.845, -12.8, -inf, -12.8, -12.8]
Step 1937 2 visits [1.0, 1.0, 913.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1239 q_vals: [-12.8, -12.8, -8.85, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1241, "number_of_timesteps": 129878, "per_episode_reward": -340.22, "episode_reward_trend_value": 0.17525684336552938, "biggest_recent_change": 3.254908175623143},
Step 1938 2 visits [1.0, 1.0, 914.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1241 q_vals: [-12.8, -12.8, -8.854, -12.8, -inf, -12.8, -12.8]
Step 1939 2 visits [1.0, 1.0, 915.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1241 q_vals: [-12.8, -12.8, -8.858, -12.8, -inf, -12.8, -12.8]
Step 1940 2 visits [1.0, 1.0, 916.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1243 q_vals: [-12.8, -12.8, -8.862, -12.8, -inf, -12.8, -12.8]
Step 1941 2 visits [1.0, 1.0, 917.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1243 q_vals: [-12.8, -12.8, -8.866, -12.8, -inf, -12.8, -12.8]
Step 1942 2 visits [1.0, 1.0, 918.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1243 q_vals: [-12.8, -12.8, -8.87, -12.8, -inf, -12.8, -12.8]
Step 1943 2 visits [1.0, 1.0, 919.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1244 q_vals: [-12.8, -12.8, -8.875, -12.8, -inf, -12.8, -12.8]
Step 1944 2 visits [1.0, 1.0, 920.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1244 q_vals: [-12.8, -12.8, -8.865, -12.8, -inf, -12.8, -12.8]
Step 1945 2 visits [1.0, 1.0, 921.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1244 q_vals: [-12.8, -12.8, -8.869, -12.8, -inf, -12.8, -12.8]
Step 1946 2 visits [1.0, 1.0, 922.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1245 q_vals: [-12.8, -12.8, -8.874, -12.8, -inf, -12.8, -12.8]
Step 1947 2 visits [1.0, 1.0, 923.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1245 q_vals: [-12.8, -12.8, -8.864, -12.8, -inf, -12.8, -12.8]
Step 1948 2 visits [1.0, 1.0, 924.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1246 q_vals: [-12.8, -12.8, -8.854, -12.8, -inf, -12.8, -12.8]
Step 1949 2 visits [1.0, 1.0, 925.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1246 q_vals: [-12.8, -12.8, -8.845, -12.8, -inf, -12.8, -12.8]
Step 1950 2 visits [1.0, 1.0, 926.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1246 q_vals: [-12.8, -12.8, -8.849, -12.8, -inf, -12.8, -12.8]
Step 1951 2 visits [1.0, 1.0, 927.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1246 q_vals: [-12.8, -12.8, -8.853, -12.8, -inf, -12.8, -12.8]
Step 1952 2 visits [1.0, 1.0, 928.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1246 q_vals: [-12.8, -12.8, -8.844, -12.8, -inf, -12.8, -12.8]
Step 1953 2 visits [1.0, 1.0, 929.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1248 q_vals: [-12.8, -12.8, -8.848, -12.8, -inf, -12.8, -12.8]
Step 1954 2 visits [1.0, 1.0, 930.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1249 q_vals: [-12.8, -12.8, -8.839, -12.8, -inf, -12.8, -12.8]
Step 1955 2 visits [1.0, 1.0, 931.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1250 q_vals: [-12.8, -12.8, -8.843, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1251, "number_of_timesteps": 131119, "per_episode_reward": -338.27, "episode_reward_trend_value": 0.19363011093862117, "biggest_recent_change": 3.254908175623143},
Step 1956 2 visits [1.0, 1.0, 932.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1251 q_vals: [-12.8, -12.8, -8.847, -12.8, -inf, -12.8, -12.8]
Step 1957 2 visits [1.0, 1.0, 933.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1253 q_vals: [-12.8, -12.8, -8.851, -12.8, -inf, -12.8, -12.8]
Step 1958 2 visits [1.0, 1.0, 934.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1253 q_vals: [-12.8, -12.8, -8.842, -12.8, -inf, -12.8, -12.8]
Step 1959 2 visits [1.0, 1.0, 935.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1253 q_vals: [-12.8, -12.8, -8.846, -12.8, -inf, -12.8, -12.8]
Step 1960 2 visits [1.0, 1.0, 936.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1253 q_vals: [-12.8, -12.8, -8.837, -12.8, -inf, -12.8, -12.8]
Step 1961 2 visits [1.0, 1.0, 937.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1253 q_vals: [-12.8, -12.8, -8.841, -12.8, -inf, -12.8, -12.8]
Step 1962 2 visits [1.0, 1.0, 938.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1253 q_vals: [-12.8, -12.8, -8.845, -12.8, -inf, -12.8, -12.8]
Step 1963 2 visits [1.0, 1.0, 939.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1254 q_vals: [-12.8, -12.8, -8.849, -12.8, -inf, -12.8, -12.8]
Step 1964 2 visits [1.0, 1.0, 940.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1254 q_vals: [-12.8, -12.8, -8.853, -12.8, -inf, -12.8, -12.8]
Step 1965 2 visits [1.0, 1.0, 941.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1256 q_vals: [-12.8, -12.8, -8.844, -12.8, -inf, -12.8, -12.8]
Step 1966 2 visits [1.0, 1.0, 942.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1256 q_vals: [-12.8, -12.8, -8.835, -12.8, -inf, -12.8, -12.8]
1967 2 visits [1.0, 1.0, 943.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1258 q_vals: [-12.8, -12.8, -8.825, -12.8, -inf, -12.8, -12.8]
Step 1968 2 visits [1.0, 1.0, 944.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1258 q_vals: [-12.8, -12.8, -8.829, -12.8, -inf, -12.8, -12.8]
Step 1969 2 visits [1.0, 1.0, 945.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1258 q_vals: [-12.8, -12.8, -8.834, -12.8, -inf, -12.8, -12.8]
Step 1970 2 visits [1.0, 1.0, 946.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1258 q_vals: [-12.8, -12.8, -8.838, -12.8, -inf, -12.8, -12.8]
Step 1971 2 visits [1.0, 1.0, 947.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1258 q_vals: [-12.8, -12.8, -8.829, -12.8, -inf, -12.8, -12.8]
Step 1972 2 visits [1.0, 1.0, 948.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1259 q_vals: [-12.8, -12.8, -8.819, -12.8, -inf, -12.8, -12.8]
Step 1973 2 visits [1.0, 1.0, 949.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1259 q_vals: [-12.8, -12.8, -8.81, -12.8, -inf, -12.8, -12.8]
Step 1974 2 visits [1.0, 1.0, 950.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1260 q_vals: [-12.8, -12.8, -8.814, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1262, "number_of_timesteps": 132330, "per_episode_reward": -337.6, "episode_reward_trend_value": 0.19302115515070126, "biggest_recent_change": 3.254908175623143},
Step 1975 2 visits [1.0, 1.0, 951.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1262 q_vals: [-12.8, -12.8, -8.818, -12.8, -inf, -12.8, -12.8]
Step 1976 2 visits [1.0, 1.0, 952.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1265 q_vals: [-12.8, -12.8, -8.822, -12.8, -inf, -12.8, -12.8]
Step 1977 2 visits [1.0, 1.0, 953.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1265 q_vals: [-12.8, -12.8, -8.827, -12.8, -inf, -12.8, -12.8]
Step 1978 2 visits [1.0, 1.0, 954.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1265 q_vals: [-12.8, -12.8, -8.817, -12.8, -inf, -12.8, -12.8]
Step 1979 2 visits [1.0, 1.0, 955.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1265 q_vals: [-12.8, -12.8, -8.822, -12.8, -inf, -12.8, -12.8]
Step 1980 2 visits [1.0, 1.0, 956.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1265 q_vals: [-12.8, -12.8, -8.812, -12.8, -inf, -12.8, -12.8]
Step 1981 2 visits [1.0, 1.0, 957.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1266 q_vals: [-12.8, -12.8, -8.817, -12.8, -inf, -12.8, -12.8]
Step 1982 2 visits [1.0, 1.0, 958.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1266 q_vals: [-12.8, -12.8, -8.821, -12.8, -inf, -12.8, -12.8]
Step 1983 2 visits [1.0, 1.0, 959.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1269 q_vals: [-12.8, -12.8, -8.825, -12.8, -inf, -12.8, -12.8]
Step 1984 2 visits [1.0, 1.0, 960.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1270 q_vals: [-12.8, -12.8, -8.829, -12.8, -inf, -12.8, -12.8]
Step 1985 2 visits [1.0, 1.0, 961.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1271 q_vals: [-12.8, -12.8, -8.82, -12.8, -inf, -12.8, -12.8]
Step 1986 2 visits [1.0, 1.0, 962.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1271 q_vals: [-12.8, -12.8, -8.811, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1272, "number_of_timesteps": 133221, "per_episode_reward": -336.41, "episode_reward_trend_value": 0.20017049963804096, "biggest_recent_change": 3.254908175623143},
Step 1987 2 visits [1.0, 1.0, 963.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1272 q_vals: [-12.8, -12.8, -8.815, -12.8, -inf, -12.8, -12.8]
Step 1988 2 visits [1.0, 1.0, 964.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1272 q_vals: [-12.8, -12.8, -8.819, -12.8, -inf, -12.8, -12.8]
Step 1989 2 visits [1.0, 1.0, 965.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1272 q_vals: [-12.8, -12.8, -8.823, -12.8, -inf, -12.8, -12.8]
Step 1990 2 visits [1.0, 1.0, 966.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1273 q_vals: [-12.8, -12.8, -8.827, -12.8, -inf, -12.8, -12.8]
Step 1991 2 visits [1.0, 1.0, 967.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1273 q_vals: [-12.8, -12.8, -8.831, -12.8, -inf, -12.8, -12.8]
Step 1992 2 visits [1.0, 1.0, 968.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1273 q_vals: [-12.8, -12.8, -8.835, -12.8, -inf, -12.8, -12.8]
Step 1993 2 visits [1.0, 1.0, 969.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1274 q_vals: [-12.8, -12.8, -8.839, -12.8, -inf, -12.8, -12.8]
Step 1994 2 visits [1.0, 1.0, 970.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1274 q_vals: [-12.8, -12.8, -8.838, -12.8, -inf, -12.8, -12.8]
Step 1995 2 visits [1.0, 1.0, 971.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1276 q_vals: [-12.8, -12.8, -8.839, -12.8, -inf, -12.8, -12.8]
Step 1996 2 visits [1.0, 1.0, 972.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1277 q_vals: [-12.8, -12.8, -8.83, -12.8, -inf, -12.8, -12.8]
Step 1997 2 visits [1.0, 1.0, 973.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1277 q_vals: [-12.8, -12.8, -8.821, -12.8, -inf, -12.8, -12.8]
Step 1998 2 visits [1.0, 1.0, 974.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1277 q_vals: [-12.8, -12.8, -8.825, -12.8, -inf, -12.8, -12.8]
Step 1999 2 visits [1.0, 1.0, 975.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1277 q_vals: [-12.8, -12.8, -8.829, -12.8, -inf, -12.8, -12.8]
Step 2000 2 visits [1.0, 1.0, 976.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1277 q_vals: [-12.8, -12.8, -8.82, -12.8, -inf, -12.8, -12.8]
Step 2001 2 visits [1.0, 1.0, 977.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1279 q_vals: [-12.8, -12.8, -8.824, -12.8, -inf, -12.8, -12.8]
Step 2002 2 visits [1.0, 1.0, 978.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1280 q_vals: [-12.8, -12.8, -8.828, -12.8, -inf, -12.8, -12.8]
Step 2003 2 visits [1.0, 1.0, 979.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1280 q_vals: [-12.8, -12.8, -8.832, -12.8, -inf, -12.8, -12.8]
Step 2004 2 visits [1.0, 1.0, 980.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1280 q_vals: [-12.8, -12.8, -8.836, -12.8, -inf, -12.8, -12.8]
Step 2005 2 visits [1.0, 1.0, 981.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1280 q_vals: [-12.8, -12.8, -8.827, -12.8, -inf, -12.8, -12.8]
Step 2006 2 visits [1.0, 1.0, 982.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1280 q_vals: [-12.8, -12.8, -8.831, -12.8, -inf, -12.8, -12.8]
{"total_number_of_episodes": 1282, "number_of_timesteps": 134407, "per_episode_reward": -334.81, "episode_reward_trend_value": 0.1935679393812058, "biggest_recent_change": 3.254908175623143},
Step 2007 2 visits [1.0, 1.0, 983.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1282 q_vals: [-12.8, -12.8, -8.822, -12.8, -inf, -12.8, -12.8]
[-12.8, -12.8, -8.813, -12.8, -inf, -12.8, -12.8]
Step 2009 2 visits [1.0, 1.0, 985.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1282 q_vals: [-12.8, -12.8, -8.817, -12.8, -inf, -12.8, -12.8]
Step 2010 2 visits [1.0, 1.0, 986.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1282 q_vals: [-12.8, -12.8, -8.821, -12.8, -inf, -12.8, -12.8]
Step 2011 2 visits [1.0, 1.0, 987.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1282 q_vals: [-12.8, -12.8, -8.825, -12.8, -inf, -12.8, -12.8]
Step 2012 2 visits [1.0, 1.0, 988.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1283 q_vals: [-12.8, -12.8, -8.829, -12.8, -inf, -12.8, -12.8]
Step 2013 2 visits [1.0, 1.0, 989.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1283 q_vals: [-12.8, -12.8, -8.833, -12.8, -inf, -12.8, -12.8]
Step 2014 2 visits [1.0, 1.0, 990.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1285 q_vals: [-12.8, -12.8, -8.837, -12.8, -inf, -12.8, -12.8]
Step 2015 2 visits [1.0, 1.0, 991.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1286 q_vals: [-12.8, -12.8, -8.841, -12.8, -inf, -12.8, -12.8]
Step 2016 2 visits [1.0, 1.0, 992.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1287 q_vals: [-12.8, -12.8, -8.832, -12.8, -inf, -12.8, -12.8]
Step 2017 2 visits [1.0, 1.0, 993.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1287 q_vals: [-12.8, -12.8, -8.836, -12.8, -inf, -12.8, -12.8]
Step 2018 2 visits [1.0, 1.0, 994.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1287 q_vals: [-12.8, -12.8, -8.84, -12.8, -inf, -12.8, -12.8]
Step 2019 2 visits [1.0, 1.0, 995.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1287 q_vals: [-12.8, -12.8, -8.844, -12.8, -inf, -12.8, -12.8]
Step 2020 2 visits [1.0, 1.0, 996.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1289 q_vals: [-12.8, -12.8, -8.848, -12.8, -inf, -12.8, -12.8]
Step 2021 2 visits [1.0, 1.0, 997.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1289 q_vals: [-12.8, -12.8, -8.852, -12.8, -inf, -12.8, -12.8]
Step 2022 2 visits [1.0, 1.0, 998.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1290 q_vals: [-12.8, -12.8, -8.856, -12.8, -inf, -12.8, -12.8]
Step 2023 2 visits [1.0, 1.0, 999.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1290 q_vals: [-12.8, -12.8, -8.847, -12.8, -inf, -12.8, -12.8]
Step 2024 2 visits [0.0, 0.0, 1000.0, 0.0, 1000.0, 0.0, 0.0]  episode_count: 1290 q_vals: [0.0, 0.0, -inf, 0.0, -inf, 0.0, 0.0]
{"total_number_of_episodes": 1292, "number_of_timesteps": 135680, "per_episode_reward": -276.13, "episode_reward_trend_value": 0.8285412295731224, "biggest_recent_change": 58.675813401147366},
Step 2025 0 visits [1.0, 0.0, 1000.0, 0.0, 1000.0, 0.0, 0.0]  episode_count: 1292 q_vals: [0.0, 0.0, -inf, 0.0, -inf, 0.0, 0.0]
Step 2026 1 visits [1.0, 1.0, 1000.0, 0.0, 1000.0, 0.0, 0.0]  episode_count: 1292 q_vals: [0.0, 0.0, -inf, 0.0, -inf, 0.0, 0.0]
Step 2027 3 visits [1.0, 1.0, 1000.0, 1.0, 1000.0, 0.0, 0.0]  episode_count: 1292 q_vals: [0.0, 0.0, -inf, -15.0, -inf, 0.0, 0.0]
Step 2028 5 visits [1.0, 1.0, 1000.0, 1.0, 1000.0, 1.0, 0.0]  episode_count: 1292 q_vals: [0.0, 0.0, -inf, -15.0, -inf, -15.0, 0.0]
Step 2029 6 visits [1.0, 1.0, 1000.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1292 q_vals: [0.0, 0.0, -inf, -15.0, -inf, -15.0, 0.0]
Step 2030 0 visits [2.0, 1.0, 1000.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1292 q_vals: [0.0, 0.0, -inf, -15.0, -inf, -15.0, 0.0]
Step 2031 1 visits [2.0, 2.0, 1000.0, 1.0, 1000.0, 1.0, 1.0]  episode_count: 1293 q_vals: [0.0, -7.5, -inf, -15.0, -inf, -15.0, 0.0]
Step 2032 6 visits [2.0, 2.0, 1000.0, 1.0, 1000.0, 1.0, 2.0]  episode_count: 1294 q_vals: [0.0, -7.5, -inf, -15.0, -inf, -15.0, -7.5]
Step 2033 0 visits [3.0, 2.0, 1000.0, 1.0, 1000.0, 1.0, 2.0]  episode_count: 1295 q_vals: [0.0, -7.5, -inf, -15.0, -inf, -15.0, -7.5]
Step 2034 0 visits [4.0, 2.0, 1000.0, 1.0, 1000.0, 1.0, 2.0]  episode_count: 1295 q_vals: [-3.75, -7.5, -inf, -15.0, -inf, -15.0, -7.5]
Step 2035 0 visits [5.0, 2.0, 1000.0, 1.0, 1000.0, 1.0, 2.0]  episode_count: 1297 q_vals: [-6.0, -7.5, -inf, -15.0, -inf, -15.0, -7.5]
Step 2036 0 visits [6.0, 2.0, 1000.0, 1.0, 1000.0, 1.0, 2.0]  episode_count: 1297 q_vals: [-7.5, -7.5, -inf, -15.0, -inf, -15.0, -7.5]
Step 2037 1 visits [6.0, 3.0, 1000.0, 1.0, 1000.0, 1.0, 2.0]  episode_count: 1297 q_vals: [-7.5, -5.0, -inf, -15.0, -inf, -15.0, -7.5]
Step 2038 1 visits [6.0, 4.0, 1000.0, 1.0, 1000.0, 1.0, 2.0]  episode_count: 1298 q_vals: [-7.5, -3.75, -inf, -15.0, -inf, -15.0, -7.5]
Step 2039 1 visits [6.0, 5.0, 1000.0, 1.0, 1000.0, 1.0, 2.0]  episode_count: 1298 q_vals: [-7.5, -6.0, -inf, -15.0, -inf, -15.0, -7.5]
Step 2040 1 visits [6.0, 6.0, 1000.0, 1.0, 1000.0, 1.0, 2.0]  episode_count: 1298 q_vals: [-7.5, -7.5, -inf, -15.0, -inf, -15.0, -7.5]
Step 2041 6 visits [6.0, 6.0, 1000.0, 1.0, 1000.0, 1.0, 3.0]  episode_count: 1299 q_vals: [-7.5, -7.5, -inf, -15.0, -inf, -15.0, -10.0]
Step 2042 0 visits [7.0, 6.0, 1000.0, 1.0, 1000.0, 1.0, 3.0]  episode_count: 1300 q_vals: [-6.429, -7.5, -inf, -15.0, -inf, -15.0, -10.0]
Step 2043 0 visits [8.0, 6.0, 1000.0, 1.0, 1000.0, 1.0, 3.0]  episode_count: 1301 q_vals: [-7.5, -7.5, -inf, -15.0, -inf, -15.0, -10.0]
Step 2044 1 visits [8.0, 7.0, 1000.0, 1.0, 1000.0, 1.0, 3.0]  episode_count: 1301 q_vals: [-7.5, -8.571, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1302, "number_of_timesteps": 136968, "per_episode_reward": -274.49, "episode_reward_trend_value": 0.8218126953136258, "biggest_recent_change": 58.675813401147366},
Step 2045 0 visits [9.0, 7.0, 1000.0, 1.0, 1000.0, 1.0, 3.0]  episode_count: 1302 q_vals: [-8.333, -8.571, -inf, -15.0, -inf, -15.0, -10.0]
Step 2046 0 visits [10.0, 7.0, 1000.0, 1.0, 1000.0, 1.0, 3.0]  episode_count: 1302 q_vals: [-9.0, -8.571, -inf, -15.0, -inf, -15.0, -10.0]
Step 2047 1 visits [10.0, 8.0, 1000.0, 1.0, 1000.0, 1.0, 3.0]  episode_count: 1302 q_vals: [-9.0, -9.375, -inf, -15.0, -inf, -15.0, -10.0]
Step 2048 0 visits [11.0, 8.0, 1000.0, 1.0, 1000.0, 1.0, 3.0]  episode_count: 1302 q_vals: [-9.545, -9.375, -inf, -15.0, -inf, -15.0, -10.0]
Step 2049 1 visits [11.0, 9.0, 1000.0, 1.0, 1000.0, 1.0, 3.0]  episode_count: 1303 q_vals: [-9.545, -10.0, -inf, -15.0, -inf, -15.0, -10.0]
Step 2050 6 visits [11.0, 9.0, 1000.0, 1.0, 1000.0, 1.0, 4.0]  episode_count: 1303 q_vals: [-9.545, -10.0, -inf, -15.0, -inf, -15.0, -7.5]
Step 2051 6 visits [11.0, 9.0, 1000.0, 1.0, 1000.0, 1.0, 5.0]  episode_count: 1303 q_vals: [-9.545, -10.0, -inf, -15.0, -inf, -15.0, -9.0]
Step 2052 6 visits [11.0, 9.0, 1000.0, 1.0, 1000.0, 1.0, 6.0]  episode_count: 1303 q_vals: [-9.545, -10.0, -inf, -15.0, -inf, -15.0, -10.0]
Step 2053 0 visits [12.0, 9.0, 1000.0, 1.0, 1000.0, 1.0, 6.0]  episode_count: 1305 q_vals: [-8.75, -10.0, -inf, -15.0, -inf, -15.0, -10.0]
Step 2054 0 visits [13.0, 9.0, 1000.0, 1.0, 1000.0, 1.0, 6.0]  episode_count: 1305 q_vals: [-9.231, -10.0, -inf, -15.0, -inf, -15.0, -10.0]
Step 2055 0 visits [14.0, 9.0, 1000.0, 1.0, 1000.0, 1.0, 6.0]  episode_count: 1306 q_vals: [-9.643, -10.0, -inf, -15.0, -inf, -15.0, -10.0]
Step 2056 0 visits [15.0, 9.0, 1000.0, 1.0, 1000.0, 1.0, 6.0]  episode_count: 1306 q_vals: [-9.558, -10.0, -inf, -15.0, -inf, -15.0, -10.0]
Step 2057 0 visits [16.0, 9.0, 1000.0, 1.0, 1000.0, 1.0, 6.0]  episode_count: 1308 q_vals: [-9.898, -10.0, -inf, -15.0, -inf, -15.0, -10.0]
Step 2058 6 visits [16.0, 9.0, 1000.0, 1.0, 1000.0, 1.0, 7.0]  episode_count: 1308 q_vals: [-9.898, -10.0, -inf, -15.0, -inf, -15.0, -8.571]
Step 2059 6 visits [16.0, 9.0, 1000.0, 1.0, 1000.0, 1.0, 8.0]  episode_count: 1308 q_vals: [-9.898, -10.0, -inf, -15.0, -inf, -15.0, -9.375]
Step 2060 6 visits [16.0, 9.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1308 q_vals: [-9.898, -10.0, -inf, -15.0, -inf, -15.0, -10.0]
Step 2061 1 visits [16.0, 10.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1308 q_vals: [-9.898, -9.0, -inf, -15.0, -inf, -15.0, -10.0]
Step 2062 1 visits [16.0, 11.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1308 q_vals: [-9.898, -8.182, -inf, -15.0, -inf, -15.0, -10.0]
Step 2063 1 visits [16.0, 12.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1308 q_vals: [-9.898, -8.75, -inf, -15.0, -inf, -15.0, -10.0]
Step 2064 1 visits [16.0, 13.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1309 q_vals: [-9.898, -8.077, -inf, -15.0, -inf, -15.0, -10.0]
Step 2065 1 visits [16.0, 14.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1310 q_vals: [-9.898, -7.5, -inf, -15.0, -inf, -15.0, -10.0]
Step 2066 1 visits [16.0, 15.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1310 q_vals: [-9.898, -8.0, -inf, -15.0, -inf, -15.0, -10.0]
Step 2067 1 visits [16.0, 16.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1310 q_vals: [-9.898, -7.5, -inf, -15.0, -inf, -15.0, -10.0]
Step 2068 1 visits [16.0, 17.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1310 q_vals: [-9.898, -7.059, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1313, "number_of_timesteps": 138534, "per_episode_reward": -275.24, "episode_reward_trend_value": 0.7817295009688532, "biggest_recent_change": 58.675813401147366},
Step 2069 1 visits [16.0, 18.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1313 q_vals: [-9.898, -7.5, -inf, -15.0, -inf, -15.0, -10.0]
Step 2070 1 visits [16.0, 19.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1314 q_vals: [-9.898, -7.105, -inf, -15.0, -inf, -15.0, -10.0]
Step 2071 1 visits [16.0, 20.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1314 q_vals: [-9.898, -6.75, -inf, -15.0, -inf, -15.0, -10.0]
Step 2072 1 visits [16.0, 21.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1314 q_vals: [-9.898, -6.429, -inf, -15.0, -inf, -15.0, -10.0]
Step 2073 1 visits [16.0, 22.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1314 q_vals: [-9.898, -6.818, -inf, -15.0, -inf, -15.0, -10.0]
Step 2074 1 visits [16.0, 23.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1316 q_vals: [-9.898, -6.522, -inf, -15.0, -inf, -15.0, -10.0]
Step 2075 1 visits [16.0, 24.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1316 q_vals: [-9.898, -6.875, -inf, -15.0, -inf, -15.0, -10.0]
Step 2076 1 visits [16.0, 25.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1317 q_vals: [-9.898, -6.6, -inf, -15.0, -inf, -15.0, -10.0]
Step 2077 1 visits [16.0, 26.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1320 q_vals: [-9.898, -6.346, -inf, -15.0, -inf, -15.0, -10.0]
Step 2078 1 visits [16.0, 27.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1320 q_vals: [-9.898, -6.111, -inf, -15.0, -inf, -15.0, -10.0]
Step 2079 1 visits [16.0, 28.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1320 q_vals: [-9.898, -5.893, -inf, -15.0, -inf, -15.0, -10.0]
Step 2080 1 visits [16.0, 29.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1320 q_vals: [-9.898, -5.69, -inf, -15.0, -inf, -15.0, -10.0]
Step 2081 1 visits [16.0, 30.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1321 q_vals: [-9.898, -6.0, -inf, -15.0, -inf, -15.0, -10.0]
Step 2082 1 visits [16.0, 31.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1322 q_vals: [-9.898, -5.806, -inf, -15.0, -inf, -15.0, -10.0]
Step 2083 1 visits [16.0, 32.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1322 q_vals: [-9.898, -5.625, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1323, "number_of_timesteps": 139612, "per_episode_reward": -273.49, "episode_reward_trend_value": 0.7649621092394536, "biggest_recent_change": 58.675813401147366},
Step 2084 1 visits [16.0, 33.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1323 q_vals: [-9.898, -5.909, -inf, -15.0, -inf, -15.0, -10.0]
Step 2085 1 visits [16.0, 34.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1323 q_vals: [-9.898, -6.176, -inf, -15.0, -inf, -15.0, -10.0]
Step 2086 1 visits [16.0, 35.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1324 q_vals: [-9.898, -6.0, -inf, -15.0, -inf, -15.0, -10.0]
Step 2087 1 visits [16.0, 36.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1324 q_vals: [-9.898, -6.25, -inf, -15.0, -inf, -15.0, -10.0]
Step 2088 1 visits [16.0, 37.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1326 q_vals: [-9.898, -6.081, -inf, -15.0, -inf, -15.0, -10.0]
Step 2089 1 visits [16.0, 38.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1328 q_vals: [-9.898, -6.316, -inf, -15.0, -inf, -15.0, -10.0]
Step 2090 1 visits [16.0, 39.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1328 q_vals: [-9.898, -6.538, -inf, -15.0, -inf, -15.0, -10.0]
Step 2091 1 visits [16.0, 40.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1328 q_vals: [-9.898, -6.75, -inf, -15.0, -inf, -15.0, -10.0]
Step 2092 1 visits [16.0, 41.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1329 q_vals: [-9.898, -6.585, -inf, -15.0, -inf, -15.0, -10.0]
Step 2093 1 visits [16.0, 42.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1330 q_vals: [-9.898, -6.786, -inf, -15.0, -inf, -15.0, -10.0]
Step 2094 1 visits [16.0, 43.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1330 q_vals: [-9.898, -6.977, -inf, -15.0, -inf, -15.0, -10.0]
Step 2095 1 visits [16.0, 44.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1330 q_vals: [-9.898, -6.818, -inf, -15.0, -inf, -15.0, -10.0]
Step 2096 1 visits [16.0, 45.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1331 q_vals: [-9.898, -7.0, -inf, -15.0, -inf, -15.0, -10.0]
Step 2097 1 visits [16.0, 46.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1331 q_vals: [-9.898, -7.174, -inf, -15.0, -inf, -15.0, -10.0]
Step 2098 1 visits [16.0, 47.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1331 q_vals: [-9.898, -7.34, -inf, -15.0, -inf, -15.0, -10.0]
Step 2099 1 visits [16.0, 48.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1332 q_vals: [-9.898, -7.187, -inf, -15.0, -inf, -15.0, -10.0]
Step 2100 1 visits [16.0, 49.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1332 q_vals: [-9.898, -7.347, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1333, "number_of_timesteps": 140624, "per_episode_reward": -272.53, "episode_reward_trend_value": 0.7521384912260834, "biggest_recent_change": 58.675813401147366},
Step 2101 1 visits [16.0, 50.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1333 q_vals: [-9.898, -7.5, -inf, -15.0, -inf, -15.0, -10.0]
Step 2102 1 visits [16.0, 51.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1334 q_vals: [-9.898, -7.647, -inf, -15.0, -inf, -15.0, -10.0]
Step 2103 1 visits [16.0, 52.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1335 q_vals: [-9.898, -7.788, -inf, -15.0, -inf, -15.0, -10.0]
Step 2104 1 visits [16.0, 53.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1335 q_vals: [-9.898, -7.925, -inf, -15.0, -inf, -15.0, -10.0]
Step 2105 1 visits [16.0, 54.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1335 q_vals: [-9.898, -8.056, -inf, -15.0, -inf, -15.0, -10.0]
Step 2106 1 visits [16.0, 55.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1335 q_vals: [-9.898, -7.909, -inf, -15.0, -inf, -15.0, -10.0]
Step 2107 1 visits [16.0, 56.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1336 q_vals: [-9.898, -7.768, -inf, -15.0, -inf, -15.0, -10.0]
Step 2108 1 visits [16.0, 57.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1337 q_vals: [-9.898, -7.632, -inf, -15.0, -inf, -15.0, -10.0]
Step 2109 1 visits [16.0, 58.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1338 q_vals: [-9.898, -7.759, -inf, -15.0, -inf, -15.0, -10.0]
Step 2110 1 visits [16.0, 59.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1338 q_vals: [-9.898, -7.881, -inf, -15.0, -inf, -15.0, -10.0]
Step 2111 1 visits [16.0, 60.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1338 q_vals: [-9.898, -7.75, -inf, -15.0, -inf, -15.0, -10.0]
Step 2112 1 visits [16.0, 61.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1338 q_vals: [-9.898, -7.869, -inf, -15.0, -inf, -15.0, -10.0]
Step 2113 1 visits [16.0, 62.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1339 q_vals: [-9.898, -7.742, -inf, -15.0, -inf, -15.0, -10.0]
Step 2114 1 visits [16.0, 63.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1340 q_vals: [-9.898, -7.619, -inf, -15.0, -inf, -15.0, -10.0]
Step 2115 1 visits [16.0, 64.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1340 q_vals: [-9.898, -7.734, -inf, -15.0, -inf, -15.0, -10.0]
Step 2116 1 visits [16.0, 65.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1340 q_vals: [-9.898, -7.615, -inf, -15.0, -inf, -15.0, -10.0]
Step 2117 1 visits [16.0, 66.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1340 q_vals: [-9.898, -7.727, -inf, -15.0, -inf, -15.0, -10.0]
Step 2118 1 visits [16.0, 67.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1341 q_vals: [-9.898, -7.612, -inf, -15.0, -inf, -15.0, -10.0]
Step 2119 1 visits [16.0, 68.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1342 q_vals: [-9.898, -7.721, -inf, -15.0, -inf, -15.0, -10.0]
Step 2120 1 visits [16.0, 69.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1342 q_vals: [-9.898, -7.609, -inf, -15.0, -inf, -15.0, -10.0]
Step 2121 1 visits [16.0, 70.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1342 q_vals: [-9.898, -7.714, -inf, -15.0, -inf, -15.0, -10.0]
Step 2122 1 visits [16.0, 71.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1342 q_vals: [-9.898, -7.606, -inf, -15.0, -inf, -15.0, -10.0]
Step 2123 1 visits [16.0, 72.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1342 q_vals: [-9.898, -7.708, -inf, -15.0, -inf, -15.0, -10.0]
Step 2124 1 visits [16.0, 73.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1342 q_vals: [-9.898, -7.808, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1346, "number_of_timesteps": 142489, "per_episode_reward": -272.99, "episode_reward_trend_value": 0.7253061670807799, "biggest_recent_change": 58.675813401147366},
Step 2125 1 visits [16.0, 74.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1346 q_vals: [-9.898, -7.703, -inf, -15.0, -inf, -15.0, -10.0]
Step 2126 1 visits [16.0, 75.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1346 q_vals: [-9.898, -7.8, -inf, -15.0, -inf, -15.0, -10.0]
Step 2127 1 visits [16.0, 76.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1346 q_vals: [-9.898, -7.895, -inf, -15.0, -inf, -15.0, -10.0]
Step 2128 1 visits [16.0, 77.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1346 q_vals: [-9.898, -7.792, -inf, -15.0, -inf, -15.0, -10.0]
Step 2129 1 visits [16.0, 78.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1346 q_vals: [-9.898, -7.885, -inf, -15.0, -inf, -15.0, -10.0]
Step 2130 1 visits [16.0, 79.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1347 q_vals: [-9.898, -7.785, -inf, -15.0, -inf, -15.0, -10.0]
Step 2131 1 visits [16.0, 80.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1348 q_vals: [-9.898, -7.687, -inf, -15.0, -inf, -15.0, -10.0]
Step 2132 1 visits [16.0, 81.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1349 q_vals: [-9.898, -7.778, -inf, -15.0, -inf, -15.0, -10.0]
Step 2133 1 visits [16.0, 82.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1351 q_vals: [-9.898, -7.866, -inf, -15.0, -inf, -15.0, -10.0]
Step 2134 1 visits [16.0, 83.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1351 q_vals: [-9.898, -7.771, -inf, -15.0, -inf, -15.0, -10.0]
Step 2135 1 visits [16.0, 84.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1353 q_vals: [-9.898, -7.679, -inf, -15.0, -inf, -15.0, -10.0]
Step 2136 1 visits [16.0, 85.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1353 q_vals: [-9.898, -7.765, -inf, -15.0, -inf, -15.0, -10.0]
Step 2137 1 visits [16.0, 86.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1353 q_vals: [-9.898, -7.674, -inf, -15.0, -inf, -15.0, -10.0]
Step 2138 1 visits [16.0, 87.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1354 q_vals: [-9.898, -7.586, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1356, "number_of_timesteps": 143437, "per_episode_reward": -272.24, "episode_reward_trend_value": 0.7261683740971729, "biggest_recent_change": 58.675813401147366},
Step 2139 1 visits [16.0, 88.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1356 q_vals: [-9.898, -7.5, -inf, -15.0, -inf, -15.0, -10.0]
Step 2140 1 visits [16.0, 89.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1357 q_vals: [-9.898, -7.584, -inf, -15.0, -inf, -15.0, -10.0]
Step 2141 1 visits [16.0, 90.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1357 q_vals: [-9.898, -7.5, -inf, -15.0, -inf, -15.0, -10.0]
Step 2142 1 visits [16.0, 91.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1358 q_vals: [-9.898, -7.418, -inf, -15.0, -inf, -15.0, -10.0]
Step 2143 1 visits [16.0, 92.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1360 q_vals: [-9.898, -7.5, -inf, -15.0, -inf, -15.0, -10.0]
Step 2144 1 visits [16.0, 93.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1360 q_vals: [-9.898, -7.581, -inf, -15.0, -inf, -15.0, -10.0]
Step 2145 1 visits [16.0, 94.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1360 q_vals: [-9.898, -7.564, -inf, -15.0, -inf, -15.0, -10.0]
Step 2146 1 visits [16.0, 95.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1362 q_vals: [-9.898, -7.643, -inf, -15.0, -inf, -15.0, -10.0]
Step 2147 1 visits [16.0, 96.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1363 q_vals: [-9.898, -7.563, -inf, -15.0, -inf, -15.0, -10.0]
Step 2148 1 visits [16.0, 97.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1364 q_vals: [-9.898, -7.64, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1366, "number_of_timesteps": 144172, "per_episode_reward": -271.68, "episode_reward_trend_value": 0.7192363226051794, "biggest_recent_change": 58.675813401147366},
Step 2149 1 visits [16.0, 98.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1366 q_vals: [-9.898, -7.715, -inf, -15.0, -inf, -15.0, -10.0]
Step 2150 1 visits [16.0, 99.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1366 q_vals: [-9.898, -7.788, -inf, -15.0, -inf, -15.0, -10.0]
Step 2151 1 visits [16.0, 100.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1367 q_vals: [-9.898, -7.861, -inf, -15.0, -inf, -15.0, -10.0]
Step 2152 1 visits [16.0, 101.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1367 q_vals: [-9.898, -7.783, -inf, -15.0, -inf, -15.0, -10.0]
Step 2153 1 visits [16.0, 102.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1368 q_vals: [-9.898, -7.706, -inf, -15.0, -inf, -15.0, -10.0]
Step 2154 1 visits [16.0, 103.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1369 q_vals: [-9.898, -7.668, -inf, -15.0, -inf, -15.0, -10.0]
Step 2155 1 visits [16.0, 104.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1370 q_vals: [-9.898, -7.652, -inf, -15.0, -inf, -15.0, -10.0]
Step 2156 1 visits [16.0, 105.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1371 q_vals: [-9.898, -7.722, -inf, -15.0, -inf, -15.0, -10.0]
Step 2157 1 visits [16.0, 106.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1374 q_vals: [-9.898, -7.649, -inf, -15.0, -inf, -15.0, -10.0]
Step 2158 1 visits [16.0, 107.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1374 q_vals: [-9.898, -7.718, -inf, -15.0, -inf, -15.0, -10.0]
Step 2159 1 visits [16.0, 108.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1374 q_vals: [-9.898, -7.647, -inf, -15.0, -inf, -15.0, -10.0]
Step 2160 1 visits [16.0, 109.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1375 q_vals: [-9.898, -7.714, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1376, "number_of_timesteps": 144874, "per_episode_reward": -270.56, "episode_reward_trend_value": 0.713918315318043, "biggest_recent_change": 58.675813401147366},
Step 2161 1 visits [16.0, 110.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1376 q_vals: [-9.898, -7.78, -inf, -15.0, -inf, -15.0, -10.0]
Step 2162 1 visits [16.0, 111.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1376 q_vals: [-9.898, -7.845, -inf, -15.0, -inf, -15.0, -10.0]
Step 2163 1 visits [16.0, 112.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1378 q_vals: [-9.898, -7.909, -inf, -15.0, -inf, -15.0, -10.0]
Step 2164 1 visits [16.0, 113.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1380 q_vals: [-9.898, -7.972, -inf, -15.0, -inf, -15.0, -10.0]
Step 2165 1 visits [16.0, 114.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1381 q_vals: [-9.898, -8.034, -inf, -15.0, -inf, -15.0, -10.0]
Step 2166 1 visits [16.0, 115.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1382 q_vals: [-9.898, -8.094, -inf, -15.0, -inf, -15.0, -10.0]
Step 2167 1 visits [16.0, 116.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1382 q_vals: [-9.898, -8.025, -inf, -15.0, -inf, -15.0, -10.0]
Step 2168 1 visits [16.0, 117.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1382 q_vals: [-9.898, -8.084, -inf, -15.0, -inf, -15.0, -10.0]
Step 2169 1 visits [16.0, 118.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1383 q_vals: [-9.898, -8.143, -inf, -15.0, -inf, -15.0, -10.0]
Step 2170 1 visits [16.0, 119.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1383 q_vals: [-9.898, -8.074, -inf, -15.0, -inf, -15.0, -10.0]
Step 2171 1 visits [16.0, 120.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1384 q_vals: [-9.898, -8.007, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1387, "number_of_timesteps": 145657, "per_episode_reward": -268.14, "episode_reward_trend_value": 0.08880560623081238, "biggest_recent_change": 2.4156695832966193},
Step 2172 1 visits [16.0, 121.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1387 q_vals: [-9.898, -7.941, -inf, -15.0, -inf, -15.0, -10.0]
Step 2173 1 visits [16.0, 122.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1388 q_vals: [-9.898, -7.876, -inf, -15.0, -inf, -15.0, -10.0]
Step 2174 1 visits [16.0, 123.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1389 q_vals: [-9.898, -7.812, -inf, -15.0, -inf, -15.0, -10.0]
Step 2175 1 visits [16.0, 124.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1389 q_vals: [-9.898, -7.749, -inf, -15.0, -inf, -15.0, -10.0]
Step 2176 1 visits [16.0, 125.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1390 q_vals: [-9.898, -7.807, -inf, -15.0, -inf, -15.0, -10.0]
Step 2177 1 visits [16.0, 126.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1390 q_vals: [-9.898, -7.745, -inf, -15.0, -inf, -15.0, -10.0]
Step 2178 1 visits [16.0, 127.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1391 q_vals: [-9.898, -7.802, -inf, -15.0, -inf, -15.0, -10.0]
Step 2179 1 visits [16.0, 128.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1392 q_vals: [-9.898, -7.858, -inf, -15.0, -inf, -15.0, -10.0]
Step 2180 1 visits [16.0, 129.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1394 q_vals: [-9.898, -7.797, -inf, -15.0, -inf, -15.0, -10.0]
Step 2181 1 visits [16.0, 130.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1395 q_vals: [-9.898, -7.853, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1397, "number_of_timesteps": 146384, "per_episode_reward": -265.91, "episode_reward_trend_value": 0.0953905784436971, "biggest_recent_change": 2.4156695832966193},
Step 2182 1 visits [16.0, 131.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1397 q_vals: [-9.898, -7.793, -inf, -15.0, -inf, -15.0, -10.0]
Step 2183 1 visits [16.0, 132.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1397 q_vals: [-9.898, -7.734, -inf, -15.0, -inf, -15.0, -10.0]
Step 2184 1 visits [16.0, 133.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1397 q_vals: [-9.898, -7.676, -inf, -15.0, -inf, -15.0, -10.0]
Step 2185 1 visits [16.0, 134.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1397 q_vals: [-9.898, -7.73, -inf, -15.0, -inf, -15.0, -10.0]
Step 2186 1 visits [16.0, 135.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1399 q_vals: [-9.898, -7.784, -inf, -15.0, -inf, -15.0, -10.0]
Step 2187 1 visits [16.0, 136.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1399 q_vals: [-9.898, -7.837, -inf, -15.0, -inf, -15.0, -10.0]
Step 2188 1 visits [16.0, 137.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1401 q_vals: [-9.898, -7.78, -inf, -15.0, -inf, -15.0, -10.0]
Step 2189 1 visits [16.0, 138.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1403 q_vals: [-9.898, -7.832, -inf, -15.0, -inf, -15.0, -10.0]
Step 2190 1 visits [16.0, 139.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1404 q_vals: [-9.898, -7.884, -inf, -15.0, -inf, -15.0, -10.0]
Step 2191 1 visits [16.0, 140.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1404 q_vals: [-9.898, -7.827, -inf, -15.0, -inf, -15.0, -10.0]
Step 2192 1 visits [16.0, 141.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1404 q_vals: [-9.898, -7.878, -inf, -15.0, -inf, -15.0, -10.0]
Step 2193 1 visits [16.0, 142.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1404 q_vals: [-9.898, -7.823, -inf, -15.0, -inf, -15.0, -10.0]
Step 2194 1 visits [16.0, 143.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1405 q_vals: [-9.898, -7.768, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1407, "number_of_timesteps": 147136, "per_episode_reward": -265.28, "episode_reward_trend_value": 0.1106029233483361, "biggest_recent_change": 2.4156695832966193},
Step 2195 1 visits [16.0, 144.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1407 q_vals: [-9.898, -7.818, -inf, -15.0, -inf, -15.0, -10.0]
Step 2196 1 visits [16.0, 145.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1408 q_vals: [-9.898, -7.868, -inf, -15.0, -inf, -15.0, -10.0]
Step 2197 1 visits [16.0, 146.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1410 q_vals: [-9.898, -7.814, -inf, -15.0, -inf, -15.0, -10.0]
Step 2198 1 visits [16.0, 147.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1411 q_vals: [-9.898, -7.863, -inf, -15.0, -inf, -15.0, -10.0]
Step 2199 1 visits [16.0, 148.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1411 q_vals: [-9.898, -7.905, -inf, -15.0, -inf, -15.0, -10.0]
Step 2200 1 visits [16.0, 149.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1412 q_vals: [-9.898, -7.852, -inf, -15.0, -inf, -15.0, -10.0]
Step 2201 1 visits [16.0, 150.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1412 q_vals: [-9.898, -7.799, -inf, -15.0, -inf, -15.0, -10.0]
Step 2202 1 visits [16.0, 151.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1413 q_vals: [-9.898, -7.814, -inf, -15.0, -inf, -15.0, -10.0]
Step 2203 1 visits [16.0, 152.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1413 q_vals: [-9.898, -7.861, -inf, -15.0, -inf, -15.0, -10.0]
Step 2204 1 visits [16.0, 153.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1414 q_vals: [-9.898, -7.81, -inf, -15.0, -inf, -15.0, -10.0]
Step 2205 1 visits [16.0, 154.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1416 q_vals: [-9.898, -7.759, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1417, "number_of_timesteps": 147880, "per_episode_reward": -264.22, "episode_reward_trend_value": 0.1030287411609316, "biggest_recent_change": 2.4156695832966193},
Step 2206 1 visits [16.0, 155.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1417 q_vals: [-9.898, -7.806, -inf, -15.0, -inf, -15.0, -10.0]
Step 2207 1 visits [16.0, 156.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1418 q_vals: [-9.898, -7.852, -inf, -15.0, -inf, -15.0, -10.0]
Step 2208 1 visits [16.0, 157.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1419 q_vals: [-9.898, -7.897, -inf, -15.0, -inf, -15.0, -10.0]
Step 2209 1 visits [16.0, 158.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1420 q_vals: [-9.898, -7.847, -inf, -15.0, -inf, -15.0, -10.0]
Step 2210 1 visits [16.0, 159.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1421 q_vals: [-9.898, -7.892, -inf, -15.0, -inf, -15.0, -10.0]
Step 2211 1 visits [16.0, 160.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1422 q_vals: [-9.898, -7.937, -inf, -15.0, -inf, -15.0, -10.0]
Step 2212 1 visits [16.0, 161.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1423 q_vals: [-9.898, -7.981, -inf, -15.0, -inf, -15.0, -10.0]
Step 2213 1 visits [16.0, 162.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1424 q_vals: [-9.898, -7.931, -inf, -15.0, -inf, -15.0, -10.0]
Step 2214 1 visits [16.0, 163.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1424 q_vals: [-9.898, -7.975, -inf, -15.0, -inf, -15.0, -10.0]
Step 2215 1 visits [16.0, 164.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1425 q_vals: [-9.898, -8.018, -inf, -15.0, -inf, -15.0, -10.0]
Step 2216 1 visits [16.0, 165.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1426 q_vals: [-9.898, -7.969, -inf, -15.0, -inf, -15.0, -10.0]
Step 2217 1 visits [16.0, 166.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1426 q_vals: [-9.898, -7.921, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1429, "number_of_timesteps": 148700, "per_episode_reward": -262.28, "episode_reward_trend_value": 0.11380838791957457, "biggest_recent_change": 2.4156695832966193},
Step 2218 1 visits [16.0, 167.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1429 q_vals: [-9.898, -7.874, -inf, -15.0, -inf, -15.0, -10.0]
Step 2219 1 visits [16.0, 168.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1429 q_vals: [-9.898, -7.827, -inf, -15.0, -inf, -15.0, -10.0]
Step 2220 1 visits [16.0, 169.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1430 q_vals: [-9.898, -7.78, -inf, -15.0, -inf, -15.0, -10.0]
Step 2221 1 visits [16.0, 170.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1431 q_vals: [-9.898, -7.823, -inf, -15.0, -inf, -15.0, -10.0]
Step 2222 1 visits [16.0, 171.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1432 q_vals: [-9.898, -7.777, -inf, -15.0, -inf, -15.0, -10.0]
Step 2223 1 visits [16.0, 172.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1432 q_vals: [-9.898, -7.732, -inf, -15.0, -inf, -15.0, -10.0]
Step 2224 1 visits [16.0, 173.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1436 q_vals: [-9.898, -7.774, -inf, -15.0, -inf, -15.0, -10.0]
Step 2225 1 visits [16.0, 174.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1436 q_vals: [-9.898, -7.816, -inf, -15.0, -inf, -15.0, -10.0]
Step 2226 1 visits [16.0, 175.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1436 q_vals: [-9.898, -7.782, -inf, -15.0, -inf, -15.0, -10.0]
Step 2227 1 visits [16.0, 176.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1436 q_vals: [-9.898, -7.738, -inf, -15.0, -inf, -15.0, -10.0]
Step 2228 1 visits [16.0, 177.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1436 q_vals: [-9.898, -7.779, -inf, -15.0, -inf, -15.0, -10.0]
Step 2229 1 visits [16.0, 178.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1437 q_vals: [-9.898, -7.735, -inf, -15.0, -inf, -15.0, -10.0]
Step 2230 1 visits [16.0, 179.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1438 q_vals: [-9.898, -7.776, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1439, "number_of_timesteps": 149409, "per_episode_reward": -260.78, "episode_reward_trend_value": 0.1355997275420287, "biggest_recent_change": 2.4156695832966193},
Step 2231 1 visits [16.0, 180.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1439 q_vals: [-9.898, -7.802, -inf, -15.0, -inf, -15.0, -10.0]
Step 2232 1 visits [16.0, 181.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1441 q_vals: [-9.898, -7.758, -inf, -15.0, -inf, -15.0, -10.0]
Step 2233 1 visits [16.0, 182.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1443 q_vals: [-9.898, -7.798, -inf, -15.0, -inf, -15.0, -10.0]
Step 2234 1 visits [16.0, 183.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1443 q_vals: [-9.898, -7.838, -inf, -15.0, -inf, -15.0, -10.0]
Step 2235 1 visits [16.0, 184.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1443 q_vals: [-9.898, -7.795, -inf, -15.0, -inf, -15.0, -10.0]
Step 2236 1 visits [16.0, 185.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1443 q_vals: [-9.898, -7.753, -inf, -15.0, -inf, -15.0, -10.0]
Step 2237 1 visits [16.0, 186.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1445 q_vals: [-9.898, -7.792, -inf, -15.0, -inf, -15.0, -10.0]
Step 2238 1 visits [16.0, 187.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1445 q_vals: [-9.898, -7.75, -inf, -15.0, -inf, -15.0, -10.0]
Step 2239 1 visits [16.0, 188.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1446 q_vals: [-9.898, -7.789, -inf, -15.0, -inf, -15.0, -10.0]
Step 2240 1 visits [16.0, 189.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1448 q_vals: [-9.898, -7.827, -inf, -15.0, -inf, -15.0, -10.0]
Step 2241 1 visits [16.0, 190.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1448 q_vals: [-9.898, -7.865, -inf, -15.0, -inf, -15.0, -10.0]
Step 2242 1 visits [16.0, 191.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1448 q_vals: [-9.898, -7.823, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1449, "number_of_timesteps": 150207, "per_episode_reward": -259.54, "episode_reward_trend_value": 0.141064728479064, "biggest_recent_change": 2.4156695832966193},
Step 2243 1 visits [16.0, 192.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1449 q_vals: [-9.898, -7.861, -inf, -15.0, -inf, -15.0, -10.0]
Step 2244 1 visits [16.0, 193.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1450 q_vals: [-9.898, -7.898, -inf, -15.0, -inf, -15.0, -10.0]
Step 2245 1 visits [16.0, 194.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1450 q_vals: [-9.898, -7.934, -inf, -15.0, -inf, -15.0, -10.0]
Step 2246 1 visits [16.0, 195.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1451 q_vals: [-9.898, -7.971, -inf, -15.0, -inf, -15.0, -10.0]
Step 2247 1 visits [16.0, 196.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1451 q_vals: [-9.898, -8.007, -inf, -15.0, -inf, -15.0, -10.0]
Step 2248 1 visits [16.0, 197.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1451 q_vals: [-9.898, -8.042, -inf, -15.0, -inf, -15.0, -10.0]
Step 2249 1 visits [16.0, 198.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1451 q_vals: [-9.898, -8.001, -inf, -15.0, -inf, -15.0, -10.0]
Step 2250 1 visits [16.0, 199.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1452 q_vals: [-9.898, -7.961, -inf, -15.0, -inf, -15.0, -10.0]
Step 2251 1 visits [16.0, 200.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1452 q_vals: [-9.898, -7.921, -inf, -15.0, -inf, -15.0, -10.0]
Step 2252 1 visits [16.0, 201.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1454 q_vals: [-9.898, -7.957, -inf, -15.0, -inf, -15.0, -10.0]
Step 2253 1 visits [16.0, 202.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1454 q_vals: [-9.898, -7.991, -inf, -15.0, -inf, -15.0, -10.0]
Step 2254 1 visits [16.0, 203.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1455 q_vals: [-9.898, -8.026, -inf, -15.0, -inf, -15.0, -10.0]
Step 2255 1 visits [16.0, 204.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1456 q_vals: [-9.898, -7.987, -inf, -15.0, -inf, -15.0, -10.0]
[-9.898, -8.021, -inf, -15.0, -inf, -15.0, -10.0]
Step 2257 1 visits [16.0, 206.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1458 q_vals: [-9.898, -7.982, -inf, -15.0, -inf, -15.0, -10.0]
Step 2258 1 visits [16.0, 207.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1458 q_vals: [-9.898, -8.016, -inf, -15.0, -inf, -15.0, -10.0]
Step 2259 1 visits [16.0, 208.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1458 q_vals: [-9.898, -7.977, -inf, -15.0, -inf, -15.0, -10.0]
Step 2260 1 visits [16.0, 209.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1458 q_vals: [-9.898, -8.011, -inf, -15.0, -inf, -15.0, -10.0]
Step 2261 1 visits [16.0, 210.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1458 q_vals: [-9.898, -8.044, -inf, -15.0, -inf, -15.0, -10.0]
Step 2262 1 visits [16.0, 211.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1458 q_vals: [-9.898, -8.006, -inf, -15.0, -inf, -15.0, -10.0]
Step 2263 1 visits [16.0, 212.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1458 q_vals: [-9.898, -8.039, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1459, "number_of_timesteps": 151350, "per_episode_reward": -258.48, "episode_reward_trend_value": 0.1466201892228292, "biggest_recent_change": 2.4156695832966193},
Step 2264 1 visits [16.0, 213.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1459 q_vals: [-9.898, -8.001, -inf, -15.0, -inf, -15.0, -10.0]
Step 2265 1 visits [16.0, 214.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1461 q_vals: [-9.898, -8.034, -inf, -15.0, -inf, -15.0, -10.0]
Step 2266 1 visits [16.0, 215.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1463 q_vals: [-9.898, -7.997, -inf, -15.0, -inf, -15.0, -10.0]
Step 2267 1 visits [16.0, 216.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1463 q_vals: [-9.898, -7.96, -inf, -15.0, -inf, -15.0, -10.0]
Step 2268 1 visits [16.0, 217.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1464 q_vals: [-9.898, -7.992, -inf, -15.0, -inf, -15.0, -10.0]
Step 2269 1 visits [16.0, 218.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1465 q_vals: [-9.898, -8.024, -inf, -15.0, -inf, -15.0, -10.0]
Step 2270 1 visits [16.0, 219.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1465 q_vals: [-9.898, -8.056, -inf, -15.0, -inf, -15.0, -10.0]
Step 2271 1 visits [16.0, 220.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1465 q_vals: [-9.898, -8.019, -inf, -15.0, -inf, -15.0, -10.0]
Step 2272 1 visits [16.0, 221.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1465 q_vals: [-9.898, -7.983, -inf, -15.0, -inf, -15.0, -10.0]
Step 2273 1 visits [16.0, 222.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1465 q_vals: [-9.898, -7.947, -inf, -15.0, -inf, -15.0, -10.0]
Step 2274 1 visits [16.0, 223.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1467 q_vals: [-9.898, -7.979, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1469, "number_of_timesteps": 152437, "per_episode_reward": -257.72, "episode_reward_trend_value": 0.14263131313045646, "biggest_recent_change": 2.4156695832966193},
Step 2275 1 visits [16.0, 224.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1469 q_vals: [-9.898, -8.01, -inf, -15.0, -inf, -15.0, -10.0]
Step 2276 1 visits [16.0, 225.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1469 q_vals: [-9.898, -8.041, -inf, -15.0, -inf, -15.0, -10.0]
Step 2277 1 visits [16.0, 226.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1469 q_vals: [-9.898, -8.006, -inf, -15.0, -inf, -15.0, -10.0]
Step 2278 1 visits [16.0, 227.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1470 q_vals: [-9.898, -8.036, -inf, -15.0, -inf, -15.0, -10.0]
Step 2279 1 visits [16.0, 228.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1471 q_vals: [-9.898, -8.067, -inf, -15.0, -inf, -15.0, -10.0]
Step 2280 1 visits [16.0, 229.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1472 q_vals: [-9.898, -8.032, -inf, -15.0, -inf, -15.0, -10.0]
Step 2281 1 visits [16.0, 230.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1472 q_vals: [-9.898, -8.062, -inf, -15.0, -inf, -15.0, -10.0]
Step 2282 1 visits [16.0, 231.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1472 q_vals: [-9.898, -8.027, -inf, -15.0, -inf, -15.0, -10.0]
Step 2283 1 visits [16.0, 232.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1472 q_vals: [-9.898, -7.993, -inf, -15.0, -inf, -15.0, -10.0]
Step 2284 1 visits [16.0, 233.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1473 q_vals: [-9.898, -8.023, -inf, -15.0, -inf, -15.0, -10.0]
Step 2285 1 visits [16.0, 234.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1473 q_vals: [-9.898, -7.988, -inf, -15.0, -inf, -15.0, -10.0]
Step 2286 1 visits [16.0, 235.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1474 q_vals: [-9.898, -7.954, -inf, -15.0, -inf, -15.0, -10.0]
Step 2287 1 visits [16.0, 236.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1476 q_vals: [-9.898, -7.984, -inf, -15.0, -inf, -15.0, -10.0]
Step 2288 1 visits [16.0, 237.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1476 q_vals: [-9.898, -8.014, -inf, -15.0, -inf, -15.0, -10.0]
Step 2289 1 visits [16.0, 238.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1477 q_vals: [-9.898, -8.043, -inf, -15.0, -inf, -15.0, -10.0]
Step 2290 1 visits [16.0, 239.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1477 q_vals: [-9.898, -8.01, -inf, -15.0, -inf, -15.0, -10.0]
Step 2291 1 visits [16.0, 240.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1477 q_vals: [-9.898, -8.039, -inf, -15.0, -inf, -15.0, -10.0]
Step 2292 1 visits [16.0, 241.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1477 q_vals: [-9.898, -8.068, -inf, -15.0, -inf, -15.0, -10.0]
Step 2293 1 visits [16.0, 242.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1478 q_vals: [-9.898, -8.096, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1479, "number_of_timesteps": 153476, "per_episode_reward": -257.67, "episode_reward_trend_value": 0.11635162599695958, "biggest_recent_change": 2.2351472138354893},
Step 2294 1 visits [16.0, 243.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1479 q_vals: [-9.898, -8.063, -inf, -15.0, -inf, -15.0, -10.0]
Step 2295 1 visits [16.0, 244.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1481 q_vals: [-9.898, -8.091, -inf, -15.0, -inf, -15.0, -10.0]
Step 2296 1 visits [16.0, 245.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1481 q_vals: [-9.898, -8.12, -inf, -15.0, -inf, -15.0, -10.0]
[-9.898, -8.147, -inf, -15.0, -inf, -15.0, -10.0]
Step 2298 1 visits [16.0, 247.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1481 q_vals: [-9.898, -8.175, -inf, -15.0, -inf, -15.0, -10.0]
Step 2299 1 visits [16.0, 248.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1481 q_vals: [-9.898, -8.203, -inf, -15.0, -inf, -15.0, -10.0]
Step 2300 1 visits [16.0, 249.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1482 q_vals: [-9.898, -8.23, -inf, -15.0, -inf, -15.0, -10.0]
Step 2301 1 visits [16.0, 250.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1483 q_vals: [-9.898, -8.197, -inf, -15.0, -inf, -15.0, -10.0]
Step 2302 1 visits [16.0, 251.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1483 q_vals: [-9.898, -8.224, -inf, -15.0, -inf, -15.0, -10.0]
Step 2303 1 visits [16.0, 252.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1484 q_vals: [-9.898, -8.251, -inf, -15.0, -inf, -15.0, -10.0]
Step 2304 1 visits [16.0, 253.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1484 q_vals: [-9.898, -8.278, -inf, -15.0, -inf, -15.0, -10.0]
Step 2305 1 visits [16.0, 254.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1486 q_vals: [-9.898, -8.304, -inf, -15.0, -inf, -15.0, -10.0]
Step 2306 1 visits [16.0, 255.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1486 q_vals: [-9.898, -8.331, -inf, -15.0, -inf, -15.0, -10.0]
Step 2307 1 visits [16.0, 256.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1486 q_vals: [-9.898, -8.357, -inf, -15.0, -inf, -15.0, -10.0]
Step 2308 1 visits [16.0, 257.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1486 q_vals: [-9.898, -8.382, -inf, -15.0, -inf, -15.0, -10.0]
Step 2309 1 visits [16.0, 258.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1486 q_vals: [-9.898, -8.35, -inf, -15.0, -inf, -15.0, -10.0]
Step 2310 1 visits [16.0, 259.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1487 q_vals: [-9.898, -8.376, -inf, -15.0, -inf, -15.0, -10.0]
Step 2311 1 visits [16.0, 260.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1487 q_vals: [-9.898, -8.343, -inf, -15.0, -inf, -15.0, -10.0]
Step 2312 1 visits [16.0, 261.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1488 q_vals: [-9.898, -8.369, -inf, -15.0, -inf, -15.0, -10.0]
Step 2313 1 visits [16.0, 262.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1488 q_vals: [-9.898, -8.394, -inf, -15.0, -inf, -15.0, -10.0]
Step 2314 1 visits [16.0, 263.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1488 q_vals: [-9.898, -8.362, -inf, -15.0, -inf, -15.0, -10.0]
Step 2315 1 visits [16.0, 264.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1488 q_vals: [-9.898, -8.387, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1489, "number_of_timesteps": 154480, "per_episode_reward": -256.45, "episode_reward_trend_value": 0.10506774254871201, "biggest_recent_change": 1.9328592459330025},
Step 2316 1 visits [16.0, 265.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1489 q_vals: [-9.898, -8.412, -inf, -15.0, -inf, -15.0, -10.0]
Step 2317 1 visits [16.0, 266.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1489 q_vals: [-9.898, -8.381, -inf, -15.0, -inf, -15.0, -10.0]
Step 2318 1 visits [16.0, 267.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1489 q_vals: [-9.898, -8.406, -inf, -15.0, -inf, -15.0, -10.0]
Step 2319 1 visits [16.0, 268.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1489 q_vals: [-9.898, -8.43, -inf, -15.0, -inf, -15.0, -10.0]
Step 2320 1 visits [16.0, 269.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1489 q_vals: [-9.898, -8.455, -inf, -15.0, -inf, -15.0, -10.0]
Step 2321 1 visits [16.0, 270.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1490 q_vals: [-9.898, -8.479, -inf, -15.0, -inf, -15.0, -10.0]
Step 2322 1 visits [16.0, 271.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1492 q_vals: [-9.898, -8.448, -inf, -15.0, -inf, -15.0, -10.0]
Step 2323 1 visits [16.0, 272.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1492 q_vals: [-9.898, -8.472, -inf, -15.0, -inf, -15.0, -10.0]
Step 2324 1 visits [16.0, 273.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1492 q_vals: [-9.898, -8.496, -inf, -15.0, -inf, -15.0, -10.0]
Step 2325 1 visits [16.0, 274.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1493 q_vals: [-9.898, -8.519, -inf, -15.0, -inf, -15.0, -10.0]
Step 2326 1 visits [16.0, 275.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1493 q_vals: [-9.898, -8.543, -inf, -15.0, -inf, -15.0, -10.0]
Step 2327 1 visits [16.0, 276.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1493 q_vals: [-9.898, -8.566, -inf, -15.0, -inf, -15.0, -10.0]
Step 2328 1 visits [16.0, 277.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1493 q_vals: [-9.898, -8.589, -inf, -15.0, -inf, -15.0, -10.0]
Step 2329 1 visits [16.0, 278.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1493 q_vals: [-9.898, -8.559, -inf, -15.0, -inf, -15.0, -10.0]
Step 2330 1 visits [16.0, 279.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1494 q_vals: [-9.898, -8.528, -inf, -15.0, -inf, -15.0, -10.0]
Step 2331 1 visits [16.0, 280.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1495 q_vals: [-9.898, -8.497, -inf, -15.0, -inf, -15.0, -10.0]
Step 2332 1 visits [16.0, 281.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1495 q_vals: [-9.898, -8.521, -inf, -15.0, -inf, -15.0, -10.0]
Step 2333 1 visits [16.0, 282.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1498 q_vals: [-9.898, -8.49, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1499, "number_of_timesteps": 156378, "per_episode_reward": -255.96, "episode_reward_trend_value": 0.10354880003345954, "biggest_recent_change": 1.9328592459330025},
Step 2334 1 visits [16.0, 283.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1499 q_vals: [-9.898, -8.513, -inf, -15.0, -inf, -15.0, -10.0]
Step 2335 1 visits [16.0, 284.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1499 q_vals: [-9.898, -8.536, -inf, -15.0, -inf, -15.0, -10.0]
Step 2336 1 visits [16.0, 285.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1500 q_vals: [-9.898, -8.559, -inf, -15.0, -inf, -15.0, -10.0]
Step 2337 1 visits [16.0, 286.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1500 q_vals: [-9.898, -8.581, -inf, -15.0, -inf, -15.0, -10.0]
Step 2338 1 visits [16.0, 287.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1501 q_vals: [-9.898, -8.604, -inf, -15.0, -inf, -15.0, -10.0]
Step 2339 1 visits [16.0, 288.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1503 q_vals: [-9.898, -8.574, -inf, -15.0, -inf, -15.0, -10.0]
[16.0, 289.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1503 q_vals: [-9.898, -8.544, -inf, -15.0, -inf, -15.0, -10.0]
Step 2341 1 visits [16.0, 290.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1505 q_vals: [-9.898, -8.566, -inf, -15.0, -inf, -15.0, -10.0]
Step 2342 1 visits [16.0, 291.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1505 q_vals: [-9.898, -8.589, -inf, -15.0, -inf, -15.0, -10.0]
Step 2343 1 visits [16.0, 292.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1505 q_vals: [-9.898, -8.559, -inf, -15.0, -inf, -15.0, -10.0]
Step 2344 1 visits [16.0, 293.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1506 q_vals: [-9.898, -8.53, -inf, -15.0, -inf, -15.0, -10.0]
Step 2345 1 visits [16.0, 294.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1508 q_vals: [-9.898, -8.552, -inf, -15.0, -inf, -15.0, -10.0]
Step 2346 1 visits [16.0, 295.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1508 q_vals: [-9.898, -8.574, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1511, "number_of_timesteps": 157387, "per_episode_reward": -254.72, "episode_reward_trend_value": 0.10550632797423261, "biggest_recent_change": 1.9328592459330025},
Step 2347 1 visits [16.0, 296.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1511 q_vals: [-9.898, -8.596, -inf, -15.0, -inf, -15.0, -10.0]
Step 2348 1 visits [16.0, 297.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1511 q_vals: [-9.898, -8.617, -inf, -15.0, -inf, -15.0, -10.0]
Step 2349 1 visits [16.0, 298.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1512 q_vals: [-9.898, -8.637, -inf, -15.0, -inf, -15.0, -10.0]
Step 2350 1 visits [16.0, 299.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1513 q_vals: [-9.898, -8.608, -inf, -15.0, -inf, -15.0, -10.0]
Step 2351 1 visits [16.0, 300.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1513 q_vals: [-9.898, -8.629, -inf, -15.0, -inf, -15.0, -10.0]
Step 2352 1 visits [16.0, 301.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1514 q_vals: [-9.898, -8.65, -inf, -15.0, -inf, -15.0, -10.0]
Step 2353 1 visits [16.0, 302.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1514 q_vals: [-9.898, -8.671, -inf, -15.0, -inf, -15.0, -10.0]
Step 2354 1 visits [16.0, 303.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1516 q_vals: [-9.898, -8.692, -inf, -15.0, -inf, -15.0, -10.0]
Step 2355 1 visits [16.0, 304.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1516 q_vals: [-9.898, -8.713, -inf, -15.0, -inf, -15.0, -10.0]
Step 2356 1 visits [16.0, 305.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1518 q_vals: [-9.898, -8.684, -inf, -15.0, -inf, -15.0, -10.0]
Step 2357 1 visits [16.0, 306.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1519 q_vals: [-9.898, -8.705, -inf, -15.0, -inf, -15.0, -10.0]
Step 2358 1 visits [16.0, 307.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1519 q_vals: [-9.898, -8.725, -inf, -15.0, -inf, -15.0, -10.0]
Step 2359 1 visits [16.0, 308.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1520 q_vals: [-9.898, -8.746, -inf, -15.0, -inf, -15.0, -10.0]
Step 2360 1 visits [16.0, 309.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1520 q_vals: [-9.898, -8.717, -inf, -15.0, -inf, -15.0, -10.0]
Step 2361 1 visits [16.0, 310.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1520 q_vals: [-9.898, -8.689, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1521, "number_of_timesteps": 158134, "per_episode_reward": -253.23, "episode_reward_trend_value": 0.10057109859024789, "biggest_recent_change": 1.5008187139110873},
Step 2362 1 visits [16.0, 311.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1521 q_vals: [-9.898, -8.661, -inf, -15.0, -inf, -15.0, -10.0]
Step 2363 1 visits [16.0, 312.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1522 q_vals: [-9.898, -8.634, -inf, -15.0, -inf, -15.0, -10.0]
Step 2364 1 visits [16.0, 313.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1522 q_vals: [-9.898, -8.606, -inf, -15.0, -inf, -15.0, -10.0]
Step 2365 1 visits [16.0, 314.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1522 q_vals: [-9.898, -8.626, -inf, -15.0, -inf, -15.0, -10.0]
Step 2366 1 visits [16.0, 315.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1525 q_vals: [-9.898, -8.647, -inf, -15.0, -inf, -15.0, -10.0]
Step 2367 1 visits [16.0, 316.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1525 q_vals: [-9.898, -8.667, -inf, -15.0, -inf, -15.0, -10.0]
Step 2368 1 visits [16.0, 317.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1525 q_vals: [-9.898, -8.639, -inf, -15.0, -inf, -15.0, -10.0]
Step 2369 1 visits [16.0, 318.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1526 q_vals: [-9.898, -8.659, -inf, -15.0, -inf, -15.0, -10.0]
Step 2370 1 visits [16.0, 319.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1526 q_vals: [-9.898, -8.679, -inf, -15.0, -inf, -15.0, -10.0]
Step 2371 1 visits [16.0, 320.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1526 q_vals: [-9.898, -8.652, -inf, -15.0, -inf, -15.0, -10.0]
Step 2372 1 visits [16.0, 321.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1527 q_vals: [-9.898, -8.672, -inf, -15.0, -inf, -15.0, -10.0]
Step 2373 1 visits [16.0, 322.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1527 q_vals: [-9.898, -8.692, -inf, -15.0, -inf, -15.0, -10.0]
Step 2374 1 visits [16.0, 323.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1528 q_vals: [-9.898, -8.665, -inf, -15.0, -inf, -15.0, -10.0]
Step 2375 1 visits [16.0, 324.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1528 q_vals: [-9.898, -8.684, -inf, -15.0, -inf, -15.0, -10.0]
Step 2376 1 visits [16.0, 325.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1530 q_vals: [-9.898, -8.704, -inf, -15.0, -inf, -15.0, -10.0]
Step 2377 1 visits [16.0, 326.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1530 q_vals: [-9.898, -8.723, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1531, "number_of_timesteps": 159260, "per_episode_reward": -250.86, "episode_reward_trend_value": 0.11030937917902262, "biggest_recent_change": 2.377263966900813},
Step 2378 1 visits [16.0, 327.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1531 q_vals: [-9.898, -8.733, -inf, -15.0, -inf, -15.0, -10.0]
Step 2379 1 visits [16.0, 328.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1531 q_vals: [-9.898, -8.752, -inf, -15.0, -inf, -15.0, -10.0]
Step 2380 1 visits [16.0, 329.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1532 q_vals: [-9.898, -8.771, -inf, -15.0, -inf, -15.0, -10.0]
Step 2381 1 visits [16.0, 330.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1532 q_vals: [-9.898, -8.744, -inf, -15.0, -inf, -15.0, -10.0]
Step 2382 1 visits [16.0, 331.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1533 q_vals: [-9.898, -8.718, -inf, -15.0, -inf, -15.0, -10.0]
Step 2383 1 visits [16.0, 332.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1533 q_vals: [-9.898, -8.737, -inf, -15.0, -inf, -15.0, -10.0]
Step 2384 1 visits [16.0, 333.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1533 q_vals: [-9.898, -8.756, -inf, -15.0, -inf, -15.0, -10.0]
Step 2385 1 visits [16.0, 334.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1534 q_vals: [-9.898, -8.729, -inf, -15.0, -inf, -15.0, -10.0]
Step 2386 1 visits [16.0, 335.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1534 q_vals: [-9.898, -8.748, -inf, -15.0, -inf, -15.0, -10.0]
Step 2387 1 visits [16.0, 336.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1536 q_vals: [-9.898, -8.767, -inf, -15.0, -inf, -15.0, -10.0]
Step 2388 1 visits [16.0, 337.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1536 q_vals: [-9.898, -8.785, -inf, -15.0, -inf, -15.0, -10.0]
Step 2389 1 visits [16.0, 338.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1537 q_vals: [-9.898, -8.759, -inf, -15.0, -inf, -15.0, -10.0]
Step 2390 1 visits [16.0, 339.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1539 q_vals: [-9.898, -8.778, -inf, -15.0, -inf, -15.0, -10.0]
Step 2391 1 visits [16.0, 340.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1540 q_vals: [-9.898, -8.752, -inf, -15.0, -inf, -15.0, -10.0]
Step 2392 1 visits [16.0, 341.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1540 q_vals: [-9.898, -8.77, -inf, -15.0, -inf, -15.0, -10.0]
Step 2393 1 visits [16.0, 342.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1540 q_vals: [-9.898, -8.744, -inf, -15.0, -inf, -15.0, -10.0]
Step 2394 1 visits [16.0, 343.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1540 q_vals: [-9.898, -8.719, -inf, -15.0, -inf, -15.0, -10.0]
Step 2395 1 visits [16.0, 344.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1540 q_vals: [-9.898, -8.694, -inf, -15.0, -inf, -15.0, -10.0]
Step 2396 1 visits [16.0, 345.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1540 q_vals: [-9.898, -8.712, -inf, -15.0, -inf, -15.0, -10.0]
Step 2397 1 visits [16.0, 346.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1540 q_vals: [-9.898, -8.73, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1541, "number_of_timesteps": 160424, "per_episode_reward": -250.75, "episode_reward_trend_value": 0.09767343102083019, "biggest_recent_change": 2.377263966900813},
Step 2398 1 visits [16.0, 347.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1541 q_vals: [-9.898, -8.748, -inf, -15.0, -inf, -15.0, -10.0]
Step 2399 1 visits [16.0, 348.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1543 q_vals: [-9.898, -8.766, -inf, -15.0, -inf, -15.0, -10.0]
Step 2400 1 visits [16.0, 349.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1544 q_vals: [-9.898, -8.741, -inf, -15.0, -inf, -15.0, -10.0]
Step 2401 1 visits [16.0, 350.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1544 q_vals: [-9.898, -8.759, -inf, -15.0, -inf, -15.0, -10.0]
Step 2402 1 visits [16.0, 351.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1544 q_vals: [-9.898, -8.734, -inf, -15.0, -inf, -15.0, -10.0]
Step 2403 1 visits [16.0, 352.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1544 q_vals: [-9.898, -8.752, -inf, -15.0, -inf, -15.0, -10.0]
Step 2404 1 visits [16.0, 353.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1544 q_vals: [-9.898, -8.727, -inf, -15.0, -inf, -15.0, -10.0]
Step 2405 1 visits [16.0, 354.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1545 q_vals: [-9.898, -8.745, -inf, -15.0, -inf, -15.0, -10.0]
Step 2406 1 visits [16.0, 355.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1545 q_vals: [-9.898, -8.72, -inf, -15.0, -inf, -15.0, -10.0]
Step 2407 1 visits [16.0, 356.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1545 q_vals: [-9.898, -8.695, -inf, -15.0, -inf, -15.0, -10.0]
Step 2408 1 visits [16.0, 357.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1547 q_vals: [-9.898, -8.671, -inf, -15.0, -inf, -15.0, -10.0]
Step 2409 1 visits [16.0, 358.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1549 q_vals: [-9.898, -8.689, -inf, -15.0, -inf, -15.0, -10.0]
Step 2410 1 visits [16.0, 359.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1549 q_vals: [-9.898, -8.665, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1551, "number_of_timesteps": 161663, "per_episode_reward": -250.12, "episode_reward_trend_value": 0.09294200765477065, "biggest_recent_change": 2.377263966900813},
Step 2411 1 visits [16.0, 360.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1551 q_vals: [-9.898, -8.682, -inf, -15.0, -inf, -15.0, -10.0]
Step 2412 1 visits [16.0, 361.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1551 q_vals: [-9.898, -8.7, -inf, -15.0, -inf, -15.0, -10.0]
Step 2413 1 visits [16.0, 362.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1551 q_vals: [-9.898, -8.717, -inf, -15.0, -inf, -15.0, -10.0]
Step 2414 1 visits [16.0, 363.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1551 q_vals: [-9.898, -8.734, -inf, -15.0, -inf, -15.0, -10.0]
Step 2415 1 visits [16.0, 364.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1552 q_vals: [-9.898, -8.752, -inf, -15.0, -inf, -15.0, -10.0]
Step 2416 1 visits [16.0, 365.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1552 q_vals: [-9.898, -8.728, -inf, -15.0, -inf, -15.0, -10.0]
Step 2417 1 visits [16.0, 366.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1554 q_vals: [-9.898, -8.745, -inf, -15.0, -inf, -15.0, -10.0]
Step 2418 1 visits [16.0, 367.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1555 q_vals: [-9.898, -8.762, -inf, -15.0, -inf, -15.0, -10.0]
Step 2419 1 visits [16.0, 368.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1557 q_vals: [-9.898, -8.779, -inf, -15.0, -inf, -15.0, -10.0]
Step 2420 1 visits [16.0, 369.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1557 q_vals: [-9.898, -8.796, -inf, -15.0, -inf, -15.0, -10.0]
Step 2421 1 visits [16.0, 370.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1557 q_vals: [-9.898, -8.812, -inf, -15.0, -inf, -15.0, -10.0]
Step 2422 1 visits [16.0, 371.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1558 q_vals: [-9.898, -8.829, -inf, -15.0, -inf, -15.0, -10.0]
Step 2423 1 visits [16.0, 372.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1558 q_vals: [-9.898, -8.846, -inf, -15.0, -inf, -15.0, -10.0]
Step 2424 1 visits [16.0, 373.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1560 q_vals: [-9.898, -8.822, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1561, "number_of_timesteps": 162506, "per_episode_reward": -248.52, "episode_reward_trend_value": 0.10222501144198222, "biggest_recent_change": 2.377263966900813},
Step 2425 1 visits [16.0, 374.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1561 q_vals: [-9.898, -8.838, -inf, -15.0, -inf, -15.0, -10.0]
Step 2426 1 visits [16.0, 375.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1562 q_vals: [-9.898, -8.815, -inf, -15.0, -inf, -15.0, -10.0]
Step 2427 1 visits [16.0, 376.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1563 q_vals: [-9.898, -8.791, -inf, -15.0, -inf, -15.0, -10.0]
Step 2428 1 visits [16.0, 377.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1563 q_vals: [-9.898, -8.768, -inf, -15.0, -inf, -15.0, -10.0]
Step 2429 1 visits [16.0, 378.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1564 q_vals: [-9.898, -8.785, -inf, -15.0, -inf, -15.0, -10.0]
Step 2430 1 visits [16.0, 379.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1564 q_vals: [-9.898, -8.801, -inf, -15.0, -inf, -15.0, -10.0]
Step 2431 1 visits [16.0, 380.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1564 q_vals: [-9.898, -8.778, -inf, -15.0, -inf, -15.0, -10.0]
Step 2432 1 visits [16.0, 381.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1564 q_vals: [-9.898, -8.794, -inf, -15.0, -inf, -15.0, -10.0]
Step 2433 1 visits [16.0, 382.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1566 q_vals: [-9.898, -8.81, -inf, -15.0, -inf, -15.0, -10.0]
Step 2434 1 visits [16.0, 383.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1566 q_vals: [-9.898, -8.827, -inf, -15.0, -inf, -15.0, -10.0]
Step 2435 1 visits [16.0, 384.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1569 q_vals: [-9.898, -8.804, -inf, -15.0, -inf, -15.0, -10.0]
Step 2436 1 visits [16.0, 385.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1569 q_vals: [-9.898, -8.781, -inf, -15.0, -inf, -15.0, -10.0]
Step 2437 1 visits [16.0, 386.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1570 q_vals: [-9.898, -8.758, -inf, -15.0, -inf, -15.0, -10.0]
Step 2438 1 visits [16.0, 387.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1570 q_vals: [-9.898, -8.735, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1571, "number_of_timesteps": 163378, "per_episode_reward": -246.82, "episode_reward_trend_value": 0.12059242984869564, "biggest_recent_change": 2.377263966900813},
Step 2439 1 visits [16.0, 388.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1571 q_vals: [-9.898, -8.752, -inf, -15.0, -inf, -15.0, -10.0]
Step 2440 1 visits [16.0, 389.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1572 q_vals: [-9.898, -8.768, -inf, -15.0, -inf, -15.0, -10.0]
Step 2441 1 visits [16.0, 390.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1573 q_vals: [-9.898, -8.745, -inf, -15.0, -inf, -15.0, -10.0]
Step 2442 1 visits [16.0, 391.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1574 q_vals: [-9.898, -8.761, -inf, -15.0, -inf, -15.0, -10.0]
Step 2443 1 visits [16.0, 392.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1574 q_vals: [-9.898, -8.739, -inf, -15.0, -inf, -15.0, -10.0]
Step 2444 1 visits [16.0, 393.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1574 q_vals: [-9.898, -8.755, -inf, -15.0, -inf, -15.0, -10.0]
Step 2445 1 visits [16.0, 394.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1574 q_vals: [-9.898, -8.732, -inf, -15.0, -inf, -15.0, -10.0]
Step 2446 1 visits [16.0, 395.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1574 q_vals: [-9.898, -8.748, -inf, -15.0, -inf, -15.0, -10.0]
Step 2447 1 visits [16.0, 396.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1576 q_vals: [-9.898, -8.726, -inf, -15.0, -inf, -15.0, -10.0]
Step 2448 1 visits [16.0, 397.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1577 q_vals: [-9.898, -8.704, -inf, -15.0, -inf, -15.0, -10.0]
Step 2449 1 visits [16.0, 398.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1577 q_vals: [-9.898, -8.72, -inf, -15.0, -inf, -15.0, -10.0]
Step 2450 1 visits [16.0, 399.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1578 q_vals: [-9.898, -8.736, -inf, -15.0, -inf, -15.0, -10.0]
Step 2451 1 visits [16.0, 400.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1580 q_vals: [-9.898, -8.751, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1581, "number_of_timesteps": 164350, "per_episode_reward": -244.96, "episode_reward_trend_value": 0.12761639898165528, "biggest_recent_change": 2.377263966900813},
Step 2452 1 visits [16.0, 401.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1581 q_vals: [-9.898, -8.73, -inf, -15.0, -inf, -15.0, -10.0]
Step 2453 1 visits [16.0, 402.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1581 q_vals: [-9.898, -8.745, -inf, -15.0, -inf, -15.0, -10.0]
Step 2454 1 visits [16.0, 403.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1581 q_vals: [-9.898, -8.761, -inf, -15.0, -inf, -15.0, -10.0]
Step 2455 1 visits [16.0, 404.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1581 q_vals: [-9.898, -8.776, -inf, -15.0, -inf, -15.0, -10.0]
Step 2456 1 visits [16.0, 405.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1582 q_vals: [-9.898, -8.792, -inf, -15.0, -inf, -15.0, -10.0]
Step 2457 1 visits [16.0, 406.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1582 q_vals: [-9.898, -8.807, -inf, -15.0, -inf, -15.0, -10.0]
Step 2458 1 visits [16.0, 407.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1582 q_vals: [-9.898, -8.822, -inf, -15.0, -inf, -15.0, -10.0]
Step 2459 1 visits [16.0, 408.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1582 q_vals: [-9.898, -8.8, -inf, -15.0, -inf, -15.0, -10.0]
Step 2460 1 visits [16.0, 409.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1585 q_vals: [-9.898, -8.779, -inf, -15.0, -inf, -15.0, -10.0]
Step 2461 1 visits [16.0, 410.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1587 q_vals: [-9.898, -8.758, -inf, -15.0, -inf, -15.0, -10.0]
Step 2462 1 visits [16.0, 411.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1587 q_vals: [-9.898, -8.773, -inf, -15.0, -inf, -15.0, -10.0]
Step 2463 1 visits [16.0, 412.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1587 q_vals: [-9.898, -8.788, -inf, -15.0, -inf, -15.0, -10.0]
Step 2464 1 visits [16.0, 413.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1587 q_vals: [-9.898, -8.767, -inf, -15.0, -inf, -15.0, -10.0]
Step 2465 1 visits [16.0, 414.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1587 q_vals: [-9.898, -8.782, -inf, -15.0, -inf, -15.0, -10.0]
Step 2466 1 visits [16.0, 415.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1588 q_vals: [-9.898, -8.797, -inf, -15.0, -inf, -15.0, -10.0]
Step 2467 1 visits [16.0, 416.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1589 q_vals: [-9.898, -8.775, -inf, -15.0, -inf, -15.0, -10.0]
Step 2468 1 visits [16.0, 417.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1589 q_vals: [-9.898, -8.79, -inf, -15.0, -inf, -15.0, -10.0]
Step 2469 1 visits [16.0, 418.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1590 q_vals: [-9.898, -8.805, -inf, -15.0, -inf, -15.0, -10.0]
Step 2470 1 visits [16.0, 419.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1590 q_vals: [-9.898, -8.82, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1591, "number_of_timesteps": 165363, "per_episode_reward": -244.9, "episode_reward_trend_value": 0.12296685860202546, "biggest_recent_change": 2.377263966900813},
Step 2471 1 visits [16.0, 420.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1591 q_vals: [-9.898, -8.799, -inf, -15.0, -inf, -15.0, -10.0]
Step 2472 1 visits [16.0, 421.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1591 q_vals: [-9.898, -8.778, -inf, -15.0, -inf, -15.0, -10.0]
Step 2473 1 visits [16.0, 422.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1591 q_vals: [-9.898, -8.793, -inf, -15.0, -inf, -15.0, -10.0]
Step 2474 1 visits [16.0, 423.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1592 q_vals: [-9.898, -8.808, -inf, -15.0, -inf, -15.0, -10.0]
Step 2475 1 visits [16.0, 424.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1593 q_vals: [-9.898, -8.822, -inf, -15.0, -inf, -15.0, -10.0]
Step 2476 1 visits [16.0, 425.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1593 q_vals: [-9.898, -8.837, -inf, -15.0, -inf, -15.0, -10.0]
Step 2477 1 visits [16.0, 426.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1593 q_vals: [-9.898, -8.851, -inf, -15.0, -inf, -15.0, -10.0]
Step 2478 1 visits [16.0, 427.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1593 q_vals: [-9.898, -8.866, -inf, -15.0, -inf, -15.0, -10.0]
Step 2479 1 visits [16.0, 428.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1594 q_vals: [-9.898, -8.845, -inf, -15.0, -inf, -15.0, -10.0]
Step 2480 1 visits [16.0, 429.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1594 q_vals: [-9.898, -8.859, -inf, -15.0, -inf, -15.0, -10.0]
Step 2481 1 visits [16.0, 430.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1595 q_vals: [-9.898, -8.873, -inf, -15.0, -inf, -15.0, -10.0]
Step 2482 1 visits [16.0, 431.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1596 q_vals: [-9.898, -8.853, -inf, -15.0, -inf, -15.0, -10.0]
Step 2483 1 visits [16.0, 432.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1597 q_vals: [-9.898, -8.832, -inf, -15.0, -inf, -15.0, -10.0]
Step 2484 1 visits [16.0, 433.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1597 q_vals: [-9.898, -8.812, -inf, -15.0, -inf, -15.0, -10.0]
Step 2485 1 visits [16.0, 434.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1598 q_vals: [-9.898, -8.826, -inf, -15.0, -inf, -15.0, -10.0]
Step 2486 1 visits [16.0, 435.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1598 q_vals: [-9.898, -8.84, -inf, -15.0, -inf, -15.0, -10.0]
Step 2487 1 visits [16.0, 436.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1598 q_vals: [-9.898, -8.82, -inf, -15.0, -inf, -15.0, -10.0]
Step 2488 1 visits [16.0, 437.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1598 q_vals: [-9.898, -8.834, -inf, -15.0, -inf, -15.0, -10.0]
Step 2489 1 visits [16.0, 438.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1598 q_vals: [-9.898, -8.814, -inf, -15.0, -inf, -15.0, -10.0]
Step 2490 1 visits [16.0, 439.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1599 q_vals: [-9.898, -8.828, -inf, -15.0, -inf, -15.0, -10.0]
Step 2491 1 visits [16.0, 440.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1599 q_vals: [-9.898, -8.808, -inf, -15.0, -inf, -15.0, -10.0]
Step 2492 1 visits [16.0, 441.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1599 q_vals: [-9.898, -8.788, -inf, -15.0, -inf, -15.0, -10.0]
Step 2493 1 visits [16.0, 442.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1600 q_vals: [-9.898, -8.773, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1601, "number_of_timesteps": 166754, "per_episode_reward": -245.41, "episode_reward_trend_value": 0.10348518316393784, "biggest_recent_change": 2.377263966900813},
Step 2494 1 visits [16.0, 443.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1601 q_vals: [-9.898, -8.753, -inf, -15.0, -inf, -15.0, -10.0]
Step 2495 1 visits [16.0, 444.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1601 q_vals: [-9.898, -8.767, -inf, -15.0, -inf, -15.0, -10.0]
Step 2496 1 visits [16.0, 445.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1601 q_vals: [-9.898, -8.747, -inf, -15.0, -inf, -15.0, -10.0]
Step 2497 1 visits [16.0, 446.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1603 q_vals: [-9.898, -8.728, -inf, -15.0, -inf, -15.0, -10.0]
Step 2498 1 visits [16.0, 447.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1604 q_vals: [-9.898, -8.742, -inf, -15.0, -inf, -15.0, -10.0]
Step 2499 1 visits [16.0, 448.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1605 q_vals: [-9.898, -8.756, -inf, -15.0, -inf, -15.0, -10.0]
Step 2500 1 visits [16.0, 449.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1605 q_vals: [-9.898, -8.77, -inf, -15.0, -inf, -15.0, -10.0]
Step 2501 1 visits [16.0, 450.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1606 q_vals: [-9.898, -8.78, -inf, -15.0, -inf, -15.0, -10.0]
Step 2502 1 visits [16.0, 451.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1607 q_vals: [-9.898, -8.761, -inf, -15.0, -inf, -15.0, -10.0]
Step 2503 1 visits [16.0, 452.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1608 q_vals: [-9.898, -8.774, -inf, -15.0, -inf, -15.0, -10.0]
Step 2504 1 visits [16.0, 453.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1609 q_vals: [-9.898, -8.755, -inf, -15.0, -inf, -15.0, -10.0]
Step 2505 1 visits [16.0, 454.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1609 q_vals: [-9.898, -8.736, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1611, "number_of_timesteps": 167943, "per_episode_reward": -243.43, "episode_reward_trend_value": 0.10887805513071543, "biggest_recent_change": 2.377263966900813},
Step 2506 1 visits [16.0, 455.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1611 q_vals: [-9.898, -8.75, -inf, -15.0, -inf, -15.0, -10.0]
Step 2507 1 visits [16.0, 456.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1611 q_vals: [-9.898, -8.73, -inf, -15.0, -inf, -15.0, -10.0]
Step 2508 1 visits [16.0, 457.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1611 q_vals: [-9.898, -8.744, -inf, -15.0, -inf, -15.0, -10.0]
Step 2509 1 visits [16.0, 458.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1612 q_vals: [-9.898, -8.725, -inf, -15.0, -inf, -15.0, -10.0]
Step 2510 1 visits [16.0, 459.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1612 q_vals: [-9.898, -8.735, -inf, -15.0, -inf, -15.0, -10.0]
Step 2511 1 visits [16.0, 460.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1613 q_vals: [-9.898, -8.742, -inf, -15.0, -inf, -15.0, -10.0]
Step 2512 1 visits [16.0, 461.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1613 q_vals: [-9.898, -8.756, -inf, -15.0, -inf, -15.0, -10.0]
Step 2513 1 visits [16.0, 462.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1613 q_vals: [-9.898, -8.769, -inf, -15.0, -inf, -15.0, -10.0]
Step 2514 1 visits [16.0, 463.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1613 q_vals: [-9.898, -8.75, -inf, -15.0, -inf, -15.0, -10.0]
Step 2515 1 visits [16.0, 464.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1615 q_vals: [-9.898, -8.731, -inf, -15.0, -inf, -15.0, -10.0]
Step 2516 1 visits [16.0, 465.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1615 q_vals: [-9.898, -8.745, -inf, -15.0, -inf, -15.0, -10.0]
Step 2517 1 visits [16.0, 466.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1615 q_vals: [-9.898, -8.758, -inf, -15.0, -inf, -15.0, -10.0]
Step 2518 1 visits [16.0, 467.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1615 q_vals: [-9.898, -8.772, -inf, -15.0, -inf, -15.0, -10.0]
Step 2519 1 visits [16.0, 468.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1616 q_vals: [-9.898, -8.753, -inf, -15.0, -inf, -15.0, -10.0]
Step 2520 1 visits [16.0, 469.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1617 q_vals: [-9.898, -8.766, -inf, -15.0, -inf, -15.0, -10.0]
Step 2521 1 visits [16.0, 470.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1617 q_vals: [-9.898, -8.78, -inf, -15.0, -inf, -15.0, -10.0]
Step 2522 1 visits [16.0, 471.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1617 q_vals: [-9.898, -8.761, -inf, -15.0, -inf, -15.0, -10.0]
Step 2523 1 visits [16.0, 472.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1617 q_vals: [-9.898, -8.774, -inf, -15.0, -inf, -15.0, -10.0]
Step 2524 1 visits [16.0, 473.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1618 q_vals: [-9.898, -8.756, -inf, -15.0, -inf, -15.0, -10.0]
Step 2525 1 visits [16.0, 474.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1618 q_vals: [-9.898, -8.769, -inf, -15.0, -inf, -15.0, -10.0]
Step 2526 1 visits [16.0, 475.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1619 q_vals: [-9.898, -8.75, -inf, -15.0, -inf, -15.0, -10.0]
Step 2527 1 visits [16.0, 476.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1620 q_vals: [-9.898, -8.732, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1622, "number_of_timesteps": 169398, "per_episode_reward": -242.69, "episode_reward_trend_value": 0.09075483714687684, "biggest_recent_change": 1.974047078384359},
Step 2528 1 visits [16.0, 477.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1622 q_vals: [-9.898, -8.745, -inf, -15.0, -inf, -15.0, -10.0]
Step 2529 1 visits [16.0, 478.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1622 q_vals: [-9.898, -8.758, -inf, -15.0, -inf, -15.0, -10.0]
Step 2530 1 visits [16.0, 479.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1623 q_vals: [-9.898, -8.74, -inf, -15.0, -inf, -15.0, -10.0]
Step 2531 1 visits [16.0, 480.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1623 q_vals: [-9.898, -8.753, -inf, -15.0, -inf, -15.0, -10.0]
Step 2532 1 visits [16.0, 481.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1623 q_vals: [-9.898, -8.735, -inf, -15.0, -inf, -15.0, -10.0]
Step 2533 1 visits [16.0, 482.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1623 q_vals: [-9.898, -8.748, -inf, -15.0, -inf, -15.0, -10.0]
Step 2534 1 visits [16.0, 483.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1623 q_vals: [-9.898, -8.73, -inf, -15.0, -inf, -15.0, -10.0]
Step 2535 1 visits [16.0, 484.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1624 q_vals: [-9.898, -8.743, -inf, -15.0, -inf, -15.0, -10.0]
Step 2536 1 visits [16.0, 485.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1625 q_vals: [-9.898, -8.725, -inf, -15.0, -inf, -15.0, -10.0]
Step 2537 1 visits [16.0, 486.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1626 q_vals: [-9.898, -8.737, -inf, -15.0, -inf, -15.0, -10.0]
Step 2538 1 visits [16.0, 487.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1626 q_vals: [-9.898, -8.719, -inf, -15.0, -inf, -15.0, -10.0]
Step 2539 1 visits [16.0, 488.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1626 q_vals: [-9.898, -8.732, -inf, -15.0, -inf, -15.0, -10.0]
Step 2540 1 visits [16.0, 489.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1628 q_vals: [-9.898, -8.745, -inf, -15.0, -inf, -15.0, -10.0]
Step 2541 1 visits [16.0, 490.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1628 q_vals: [-9.898, -8.727, -inf, -15.0, -inf, -15.0, -10.0]
Step 2542 1 visits [16.0, 491.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1629 q_vals: [-9.898, -8.74, -inf, -15.0, -inf, -15.0, -10.0]
Step 2543 1 visits [16.0, 492.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1629 q_vals: [-9.898, -8.753, -inf, -15.0, -inf, -15.0, -10.0]
Step 2544 1 visits [16.0, 493.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1631 q_vals: [-9.898, -8.765, -inf, -15.0, -inf, -15.0, -10.0]
Step 2545 1 visits [16.0, 494.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1631 q_vals: [-9.898, -8.778, -inf, -15.0, -inf, -15.0, -10.0]
Step 2546 1 visits [16.0, 495.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1631 q_vals: [-9.898, -8.76, -inf, -15.0, -inf, -15.0, -10.0]
[-9.898, -8.743, -inf, -15.0, -inf, -15.0, -10.0]
Step 2548 1 visits [16.0, 497.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1631 q_vals: [-9.898, -8.725, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1632, "number_of_timesteps": 170606, "per_episode_reward": -242.03, "episode_reward_trend_value": 0.09689690996861013, "biggest_recent_change": 1.974047078384359},
Step 2549 1 visits [16.0, 498.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1632 q_vals: [-9.898, -8.738, -inf, -15.0, -inf, -15.0, -10.0]
Step 2550 1 visits [16.0, 499.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1634 q_vals: [-9.898, -8.72, -inf, -15.0, -inf, -15.0, -10.0]
Step 2551 1 visits [16.0, 500.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1634 q_vals: [-9.898, -8.703, -inf, -15.0, -inf, -15.0, -10.0]
Step 2552 1 visits [16.0, 501.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1634 q_vals: [-9.898, -8.685, -inf, -15.0, -inf, -15.0, -10.0]
Step 2553 1 visits [16.0, 502.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1635 q_vals: [-9.898, -8.698, -inf, -15.0, -inf, -15.0, -10.0]
Step 2554 1 visits [16.0, 503.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1635 q_vals: [-9.898, -8.711, -inf, -15.0, -inf, -15.0, -10.0]
Step 2555 1 visits [16.0, 504.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1637 q_vals: [-9.898, -8.723, -inf, -15.0, -inf, -15.0, -10.0]
Step 2556 1 visits [16.0, 505.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1637 q_vals: [-9.898, -8.735, -inf, -15.0, -inf, -15.0, -10.0]
Step 2557 1 visits [16.0, 506.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1637 q_vals: [-9.898, -8.718, -inf, -15.0, -inf, -15.0, -10.0]
Step 2558 1 visits [16.0, 507.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1638 q_vals: [-9.898, -8.731, -inf, -15.0, -inf, -15.0, -10.0]
Step 2559 1 visits [16.0, 508.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1639 q_vals: [-9.898, -8.743, -inf, -15.0, -inf, -15.0, -10.0]
Step 2560 1 visits [16.0, 509.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1639 q_vals: [-9.898, -8.726, -inf, -15.0, -inf, -15.0, -10.0]
Step 2561 1 visits [16.0, 510.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1639 q_vals: [-9.898, -8.709, -inf, -15.0, -inf, -15.0, -10.0]
Step 2562 1 visits [16.0, 511.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1640 q_vals: [-9.898, -8.721, -inf, -15.0, -inf, -15.0, -10.0]
Step 2563 1 visits [16.0, 512.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1640 q_vals: [-9.898, -8.733, -inf, -15.0, -inf, -15.0, -10.0]
Step 2564 1 visits [16.0, 513.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1640 q_vals: [-9.898, -8.745, -inf, -15.0, -inf, -15.0, -10.0]
Step 2565 1 visits [16.0, 514.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1640 q_vals: [-9.898, -8.728, -inf, -15.0, -inf, -15.0, -10.0]
Step 2566 1 visits [16.0, 515.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1641 q_vals: [-9.898, -8.711, -inf, -15.0, -inf, -15.0, -10.0]
Step 2567 1 visits [16.0, 516.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1641 q_vals: [-9.898, -8.695, -inf, -15.0, -inf, -15.0, -10.0]
Step 2568 1 visits [16.0, 517.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1641 q_vals: [-9.898, -8.707, -inf, -15.0, -inf, -15.0, -10.0]
Step 2569 1 visits [16.0, 518.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1641 q_vals: [-9.898, -8.69, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1642, "number_of_timesteps": 171751, "per_episode_reward": -242.01, "episode_reward_trend_value": 0.09010611806248474, "biggest_recent_change": 1.974047078384359},
Step 2570 1 visits [16.0, 519.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1642 q_vals: [-9.898, -8.702, -inf, -15.0, -inf, -15.0, -10.0]
Step 2571 1 visits [16.0, 520.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1643 q_vals: [-9.898, -8.714, -inf, -15.0, -inf, -15.0, -10.0]
Step 2572 1 visits [16.0, 521.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1644 q_vals: [-9.898, -8.726, -inf, -15.0, -inf, -15.0, -10.0]
Step 2573 1 visits [16.0, 522.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1644 q_vals: [-9.898, -8.738, -inf, -15.0, -inf, -15.0, -10.0]
Step 2574 1 visits [16.0, 523.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1646 q_vals: [-9.898, -8.75, -inf, -15.0, -inf, -15.0, -10.0]
Step 2575 1 visits [16.0, 524.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1647 q_vals: [-9.898, -8.762, -inf, -15.0, -inf, -15.0, -10.0]
Step 2576 1 visits [16.0, 525.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1648 q_vals: [-9.898, -8.746, -inf, -15.0, -inf, -15.0, -10.0]
Step 2577 1 visits [16.0, 526.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1648 q_vals: [-9.898, -8.757, -inf, -15.0, -inf, -15.0, -10.0]
Step 2578 1 visits [16.0, 527.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1649 q_vals: [-9.898, -8.769, -inf, -15.0, -inf, -15.0, -10.0]
Step 2579 1 visits [16.0, 528.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1649 q_vals: [-9.898, -8.753, -inf, -15.0, -inf, -15.0, -10.0]
Step 2580 1 visits [16.0, 529.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1651 q_vals: [-9.898, -8.736, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1652, "number_of_timesteps": 172969, "per_episode_reward": -240.64, "episode_reward_trend_value": 0.08756385332080564, "biggest_recent_change": 1.974047078384359},
Step 2581 1 visits [16.0, 530.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1652 q_vals: [-9.898, -8.748, -inf, -15.0, -inf, -15.0, -10.0]
Step 2582 1 visits [16.0, 531.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1652 q_vals: [-9.898, -8.731, -inf, -15.0, -inf, -15.0, -10.0]
Step 2583 1 visits [16.0, 532.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1652 q_vals: [-9.898, -8.715, -inf, -15.0, -inf, -15.0, -10.0]
Step 2584 1 visits [16.0, 533.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1652 q_vals: [-9.898, -8.699, -inf, -15.0, -inf, -15.0, -10.0]
Step 2585 1 visits [16.0, 534.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1654 q_vals: [-9.898, -8.71, -inf, -15.0, -inf, -15.0, -10.0]
Step 2586 1 visits [16.0, 535.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1654 q_vals: [-9.898, -8.694, -inf, -15.0, -inf, -15.0, -10.0]
Step 2587 1 visits [16.0, 536.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1654 q_vals: [-9.898, -8.678, -inf, -15.0, -inf, -15.0, -10.0]
[-9.898, -8.662, -inf, -15.0, -inf, -15.0, -10.0]
Step 2589 1 visits [16.0, 538.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1656 q_vals: [-9.898, -8.674, -inf, -15.0, -inf, -15.0, -10.0]
Step 2590 1 visits [16.0, 539.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1657 q_vals: [-9.898, -8.657, -inf, -15.0, -inf, -15.0, -10.0]
Step 2591 1 visits [16.0, 540.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1658 q_vals: [-9.898, -8.641, -inf, -15.0, -inf, -15.0, -10.0]
Step 2592 1 visits [16.0, 541.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1658 q_vals: [-9.898, -8.625, -inf, -15.0, -inf, -15.0, -10.0]
Step 2593 1 visits [16.0, 542.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1659 q_vals: [-9.898, -8.637, -inf, -15.0, -inf, -15.0, -10.0]
Step 2594 1 visits [16.0, 543.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1659 q_vals: [-9.898, -8.649, -inf, -15.0, -inf, -15.0, -10.0]
Step 2595 1 visits [16.0, 544.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1660 q_vals: [-9.898, -8.661, -inf, -15.0, -inf, -15.0, -10.0]
Step 2596 1 visits [16.0, 545.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1660 q_vals: [-9.898, -8.645, -inf, -15.0, -inf, -15.0, -10.0]
Step 2597 1 visits [16.0, 546.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1660 q_vals: [-9.898, -8.656, -inf, -15.0, -inf, -15.0, -10.0]
Step 2598 1 visits [16.0, 547.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1660 q_vals: [-9.898, -8.668, -inf, -15.0, -inf, -15.0, -10.0]
Step 2599 1 visits [16.0, 548.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1661 q_vals: [-9.898, -8.664, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1662, "number_of_timesteps": 173991, "per_episode_reward": -239.8, "episode_reward_trend_value": 0.07793661991963871, "biggest_recent_change": 1.974047078384359},
Step 2600 1 visits [16.0, 549.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1662 q_vals: [-9.898, -8.676, -inf, -15.0, -inf, -15.0, -10.0]
Step 2601 1 visits [16.0, 550.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1663 q_vals: [-9.898, -8.66, -inf, -15.0, -inf, -15.0, -10.0]
Step 2602 1 visits [16.0, 551.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1663 q_vals: [-9.898, -8.644, -inf, -15.0, -inf, -15.0, -10.0]
Step 2603 1 visits [16.0, 552.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1663 q_vals: [-9.898, -8.656, -inf, -15.0, -inf, -15.0, -10.0]
Step 2604 1 visits [16.0, 553.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1663 q_vals: [-9.898, -8.667, -inf, -15.0, -inf, -15.0, -10.0]
Step 2605 1 visits [16.0, 554.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1664 q_vals: [-9.898, -8.678, -inf, -15.0, -inf, -15.0, -10.0]
Step 2606 1 visits [16.0, 555.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1665 q_vals: [-9.898, -8.663, -inf, -15.0, -inf, -15.0, -10.0]
Step 2607 1 visits [16.0, 556.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1665 q_vals: [-9.898, -8.647, -inf, -15.0, -inf, -15.0, -10.0]
Step 2608 1 visits [16.0, 557.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1665 q_vals: [-9.898, -8.659, -inf, -15.0, -inf, -15.0, -10.0]
Step 2609 1 visits [16.0, 558.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1666 q_vals: [-9.898, -8.67, -inf, -15.0, -inf, -15.0, -10.0]
Step 2610 1 visits [16.0, 559.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1666 q_vals: [-9.898, -8.681, -inf, -15.0, -inf, -15.0, -10.0]
Step 2611 1 visits [16.0, 560.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1666 q_vals: [-9.898, -8.693, -inf, -15.0, -inf, -15.0, -10.0]
Step 2612 1 visits [16.0, 561.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1666 q_vals: [-9.898, -8.704, -inf, -15.0, -inf, -15.0, -10.0]
Step 2613 1 visits [16.0, 562.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1667 q_vals: [-9.898, -8.688, -inf, -15.0, -inf, -15.0, -10.0]
Step 2614 1 visits [16.0, 563.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1667 q_vals: [-9.898, -8.673, -inf, -15.0, -inf, -15.0, -10.0]
Step 2615 1 visits [16.0, 564.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1668 q_vals: [-9.898, -8.658, -inf, -15.0, -inf, -15.0, -10.0]
Step 2616 1 visits [16.0, 565.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1670 q_vals: [-9.898, -8.669, -inf, -15.0, -inf, -15.0, -10.0]
Step 2617 1 visits [16.0, 566.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1670 q_vals: [-9.898, -8.68, -inf, -15.0, -inf, -15.0, -10.0]
Step 2618 1 visits [16.0, 567.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1670 q_vals: [-9.898, -8.691, -inf, -15.0, -inf, -15.0, -10.0]
Step 2619 1 visits [16.0, 568.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1671 q_vals: [-9.898, -8.676, -inf, -15.0, -inf, -15.0, -10.0]
Step 2620 1 visits [16.0, 569.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1671 q_vals: [-9.898, -8.661, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1672, "number_of_timesteps": 175535, "per_episode_reward": -238.75, "episode_reward_trend_value": 0.06902977688924068, "biggest_recent_change": 1.974047078384359},
Step 2621 1 visits [16.0, 570.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1672 q_vals: [-9.898, -8.672, -inf, -15.0, -inf, -15.0, -10.0]
Step 2622 1 visits [16.0, 571.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1673 q_vals: [-9.898, -8.656, -inf, -15.0, -inf, -15.0, -10.0]
Step 2623 1 visits [16.0, 572.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1675 q_vals: [-9.898, -8.668, -inf, -15.0, -inf, -15.0, -10.0]
Step 2624 1 visits [16.0, 573.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1675 q_vals: [-9.898, -8.679, -inf, -15.0, -inf, -15.0, -10.0]
Step 2625 1 visits [16.0, 574.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1676 q_vals: [-9.898, -8.69, -inf, -15.0, -inf, -15.0, -10.0]
Step 2626 1 visits [16.0, 575.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1677 q_vals: [-9.898, -8.675, -inf, -15.0, -inf, -15.0, -10.0]
Step 2627 1 visits [16.0, 576.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1678 q_vals: [-9.898, -8.686, -inf, -15.0, -inf, -15.0, -10.0]
Step 2628 1 visits [16.0, 577.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1678 q_vals: [-9.898, -8.67, -inf, -15.0, -inf, -15.0, -10.0]
Step 2629 1 visits [16.0, 578.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1678 q_vals: [-9.898, -8.655, -inf, -15.0, -inf, -15.0, -10.0]
Step 2630 1 visits [16.0, 579.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1679 q_vals: [-9.898, -8.641, -inf, -15.0, -inf, -15.0, -10.0]
Step 2631 1 visits [16.0, 580.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1681 q_vals: [-9.898, -8.626, -inf, -15.0, -inf, -15.0, -10.0]
Step 2632 1 visits [16.0, 581.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1681 q_vals: [-9.898, -8.637, -inf, -15.0, -inf, -15.0, -10.0]
Step 2633 1 visits [16.0, 582.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1681 q_vals: [-9.898, -8.622, -inf, -15.0, -inf, -15.0, -10.0]
Step 2634 1 visits [16.0, 583.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1681 q_vals: [-9.898, -8.633, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1682, "number_of_timesteps": 176419, "per_episode_reward": -237.81, "episode_reward_trend_value": 0.07873235587440205, "biggest_recent_change": 1.974047078384359},
Step 2635 1 visits [16.0, 584.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1682 q_vals: [-9.898, -8.644, -inf, -15.0, -inf, -15.0, -10.0]
Step 2636 1 visits [16.0, 585.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1683 q_vals: [-9.898, -8.629, -inf, -15.0, -inf, -15.0, -10.0]
Step 2637 1 visits [16.0, 586.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1683 q_vals: [-9.898, -8.634, -inf, -15.0, -inf, -15.0, -10.0]
Step 2638 1 visits [16.0, 587.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1684 q_vals: [-9.898, -8.645, -inf, -15.0, -inf, -15.0, -10.0]
Step 2639 1 visits [16.0, 588.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1684 q_vals: [-9.898, -8.63, -inf, -15.0, -inf, -15.0, -10.0]
Step 2640 1 visits [16.0, 589.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1684 q_vals: [-9.898, -8.641, -inf, -15.0, -inf, -15.0, -10.0]
Step 2641 1 visits [16.0, 590.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1684 q_vals: [-9.898, -8.652, -inf, -15.0, -inf, -15.0, -10.0]
Step 2642 1 visits [16.0, 591.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1686 q_vals: [-9.898, -8.637, -inf, -15.0, -inf, -15.0, -10.0]
Step 2643 1 visits [16.0, 592.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1686 q_vals: [-9.898, -8.648, -inf, -15.0, -inf, -15.0, -10.0]
Step 2644 1 visits [16.0, 593.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1686 q_vals: [-9.898, -8.659, -inf, -15.0, -inf, -15.0, -10.0]
Step 2645 1 visits [16.0, 594.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1686 q_vals: [-9.898, -8.669, -inf, -15.0, -inf, -15.0, -10.0]
Step 2646 1 visits [16.0, 595.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1686 q_vals: [-9.898, -8.68, -inf, -15.0, -inf, -15.0, -10.0]
Step 2647 1 visits [16.0, 596.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1686 q_vals: [-9.898, -8.691, -inf, -15.0, -inf, -15.0, -10.0]
Step 2648 1 visits [16.0, 597.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1687 q_vals: [-9.898, -8.676, -inf, -15.0, -inf, -15.0, -10.0]
Step 2649 1 visits [16.0, 598.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1687 q_vals: [-9.898, -8.661, -inf, -15.0, -inf, -15.0, -10.0]
Step 2650 1 visits [16.0, 599.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1687 q_vals: [-9.898, -8.647, -inf, -15.0, -inf, -15.0, -10.0]
Step 2651 1 visits [16.0, 600.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1687 q_vals: [-9.898, -8.658, -inf, -15.0, -inf, -15.0, -10.0]
Step 2652 1 visits [16.0, 601.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1688 q_vals: [-9.898, -8.668, -inf, -15.0, -inf, -15.0, -10.0]
Step 2653 1 visits [16.0, 602.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1689 q_vals: [-9.898, -8.679, -inf, -15.0, -inf, -15.0, -10.0]
Step 2654 1 visits [16.0, 603.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1689 q_vals: [-9.898, -8.689, -inf, -15.0, -inf, -15.0, -10.0]
Step 2655 1 visits [16.0, 604.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1689 q_vals: [-9.898, -8.675, -inf, -15.0, -inf, -15.0, -10.0]
Step 2656 1 visits [16.0, 605.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1691 q_vals: [-9.898, -8.66, -inf, -15.0, -inf, -15.0, -10.0]
Step 2657 1 visits [16.0, 606.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1691 q_vals: [-9.898, -8.646, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1692, "number_of_timesteps": 177707, "per_episode_reward": -237.39, "episode_reward_trend_value": 0.08914433145065428, "biggest_recent_change": 1.974047078384359},
Step 2658 1 visits [16.0, 607.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1692 q_vals: [-9.898, -8.657, -inf, -15.0, -inf, -15.0, -10.0]
Step 2659 1 visits [16.0, 608.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1693 q_vals: [-9.898, -8.642, -inf, -15.0, -inf, -15.0, -10.0]
Step 2660 1 visits [16.0, 609.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1693 q_vals: [-9.898, -8.628, -inf, -15.0, -inf, -15.0, -10.0]
Step 2661 1 visits [16.0, 610.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1695 q_vals: [-9.898, -8.614, -inf, -15.0, -inf, -15.0, -10.0]
Step 2662 1 visits [16.0, 611.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1696 q_vals: [-9.898, -8.624, -inf, -15.0, -inf, -15.0, -10.0]
Step 2663 1 visits [16.0, 612.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1696 q_vals: [-9.898, -8.635, -inf, -15.0, -inf, -15.0, -10.0]
Step 2664 1 visits [16.0, 613.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1696 q_vals: [-9.898, -8.645, -inf, -15.0, -inf, -15.0, -10.0]
Step 2665 1 visits [16.0, 614.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1696 q_vals: [-9.898, -8.656, -inf, -15.0, -inf, -15.0, -10.0]
Step 2666 1 visits [16.0, 615.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1696 q_vals: [-9.898, -8.642, -inf, -15.0, -inf, -15.0, -10.0]
Step 2667 1 visits [16.0, 616.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1697 q_vals: [-9.898, -8.652, -inf, -15.0, -inf, -15.0, -10.0]
Step 2668 1 visits [16.0, 617.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1698 q_vals: [-9.898, -8.638, -inf, -15.0, -inf, -15.0, -10.0]
Step 2669 1 visits [16.0, 618.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1698 q_vals: [-9.898, -8.648, -inf, -15.0, -inf, -15.0, -10.0]
Step 2670 1 visits [16.0, 619.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1698 q_vals: [-9.898, -8.658, -inf, -15.0, -inf, -15.0, -10.0]
Step 2671 1 visits [16.0, 620.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1698 q_vals: [-9.898, -8.669, -inf, -15.0, -inf, -15.0, -10.0]
Step 2672 1 visits [16.0, 621.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1700 q_vals: [-9.898, -8.655, -inf, -15.0, -inf, -15.0, -10.0]
Step 2673 1 visits [16.0, 622.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1700 q_vals: [-9.898, -8.641, -inf, -15.0, -inf, -15.0, -10.0]
Step 2674 1 visits [16.0, 623.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1701 q_vals: [-9.898, -8.627, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1702, "number_of_timesteps": 179198, "per_episode_reward": -236.91, "episode_reward_trend_value": 0.07250249525729972, "biggest_recent_change": 1.370528902957517},
Step 2675 1 visits [16.0, 624.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1702 q_vals: [-9.898, -8.637, -inf, -15.0, -inf, -15.0, -10.0]
Step 2676 1 visits [16.0, 625.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1702 q_vals: [-9.898, -8.647, -inf, -15.0, -inf, -15.0, -10.0]
Step 2677 1 visits [16.0, 626.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1704 q_vals: [-9.898, -8.657, -inf, -15.0, -inf, -15.0, -10.0]
Step 2678 1 visits [16.0, 627.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1704 q_vals: [-9.898, -8.644, -inf, -15.0, -inf, -15.0, -10.0]
Step 2679 1 visits [16.0, 628.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1705 q_vals: [-9.898, -8.647, -inf, -15.0, -inf, -15.0, -10.0]
Step 2680 1 visits [16.0, 629.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1705 q_vals: [-9.898, -8.657, -inf, -15.0, -inf, -15.0, -10.0]
Step 2681 1 visits [16.0, 630.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1705 q_vals: [-9.898, -8.667, -inf, -15.0, -inf, -15.0, -10.0]
Step 2682 1 visits [16.0, 631.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1705 q_vals: [-9.898, -8.653, -inf, -15.0, -inf, -15.0, -10.0]
Step 2683 1 visits [16.0, 632.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1705 q_vals: [-9.898, -8.663, -inf, -15.0, -inf, -15.0, -10.0]
Step 2684 1 visits [16.0, 633.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1707 q_vals: [-9.898, -8.649, -inf, -15.0, -inf, -15.0, -10.0]
Step 2685 1 visits [16.0, 634.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1709 q_vals: [-9.898, -8.659, -inf, -15.0, -inf, -15.0, -10.0]
Step 2686 1 visits [16.0, 635.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1711 q_vals: [-9.898, -8.669, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1712, "number_of_timesteps": 180224, "per_episode_reward": -236.18, "episode_reward_trend_value": 0.07227614370548596, "biggest_recent_change": 1.370528902957517},
Step 2687 1 visits [16.0, 636.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1712 q_vals: [-9.898, -8.674, -inf, -15.0, -inf, -15.0, -10.0]
Step 2688 1 visits [16.0, 637.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1712 q_vals: [-9.898, -8.684, -inf, -15.0, -inf, -15.0, -10.0]
Step 2689 1 visits [16.0, 638.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1712 q_vals: [-9.898, -8.694, -inf, -15.0, -inf, -15.0, -10.0]
Step 2690 1 visits [16.0, 639.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1712 q_vals: [-9.898, -8.681, -inf, -15.0, -inf, -15.0, -10.0]
Step 2691 1 visits [16.0, 640.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1712 q_vals: [-9.898, -8.667, -inf, -15.0, -inf, -15.0, -10.0]
Step 2692 1 visits [16.0, 641.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1712 q_vals: [-9.898, -8.677, -inf, -15.0, -inf, -15.0, -10.0]
Step 2693 1 visits [16.0, 642.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1712 q_vals: [-9.898, -8.687, -inf, -15.0, -inf, -15.0, -10.0]
Step 2694 1 visits [16.0, 643.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1713 q_vals: [-9.898, -8.673, -inf, -15.0, -inf, -15.0, -10.0]
Step 2695 1 visits [16.0, 644.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1714 q_vals: [-9.898, -8.683, -inf, -15.0, -inf, -15.0, -10.0]
Step 2696 1 visits [16.0, 645.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1718 q_vals: [-9.898, -8.67, -inf, -15.0, -inf, -15.0, -10.0]
Step 2697 1 visits [16.0, 646.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1718 q_vals: [-9.898, -8.679, -inf, -15.0, -inf, -15.0, -10.0]
Step 2698 1 visits [16.0, 647.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1719 q_vals: [-9.898, -8.689, -inf, -15.0, -inf, -15.0, -10.0]
Step 2699 1 visits [16.0, 648.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1719 q_vals: [-9.898, -8.676, -inf, -15.0, -inf, -15.0, -10.0]
Step 2700 1 visits [16.0, 649.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1719 q_vals: [-9.898, -8.662, -inf, -15.0, -inf, -15.0, -10.0]
Step 2701 1 visits [16.0, 650.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1719 q_vals: [-9.898, -8.672, -inf, -15.0, -inf, -15.0, -10.0]
Step 2702 1 visits [16.0, 651.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1719 q_vals: [-9.898, -8.659, -inf, -15.0, -inf, -15.0, -10.0]
Step 2703 1 visits [16.0, 652.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1719 q_vals: [-9.898, -8.645, -inf, -15.0, -inf, -15.0, -10.0]
Step 2704 1 visits [16.0, 653.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1719 q_vals: [-9.898, -8.632, -inf, -15.0, -inf, -15.0, -10.0]
Step 2705 1 visits [16.0, 654.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1720 q_vals: [-9.898, -8.642, -inf, -15.0, -inf, -15.0, -10.0]
Step 2706 1 visits [16.0, 655.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1720 q_vals: [-9.898, -8.652, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1723, "number_of_timesteps": 181317, "per_episode_reward": -235.43, "episode_reward_trend_value": 0.07334369057014858, "biggest_recent_change": 1.370528902957517},
Step 2707 1 visits [16.0, 656.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1723 q_vals: [-9.898, -8.661, -inf, -15.0, -inf, -15.0, -10.0]
Step 2708 1 visits [16.0, 657.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1723 q_vals: [-9.898, -8.648, -inf, -15.0, -inf, -15.0, -10.0]
Step 2709 1 visits [16.0, 658.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1723 q_vals: [-9.898, -8.635, -inf, -15.0, -inf, -15.0, -10.0]
Step 2710 1 visits [16.0, 659.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1724 q_vals: [-9.898, -8.645, -inf, -15.0, -inf, -15.0, -10.0]
Step 2711 1 visits [16.0, 660.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1726 q_vals: [-9.898, -8.632, -inf, -15.0, -inf, -15.0, -10.0]
Step 2712 1 visits [16.0, 661.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1726 q_vals: [-9.898, -8.641, -inf, -15.0, -inf, -15.0, -10.0]
Step 2713 1 visits [16.0, 662.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1726 q_vals: [-9.898, -8.651, -inf, -15.0, -inf, -15.0, -10.0]
Step 2714 1 visits [16.0, 663.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1726 q_vals: [-9.898, -8.638, -inf, -15.0, -inf, -15.0, -10.0]
Step 2715 1 visits [16.0, 664.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1726 q_vals: [-9.898, -8.647, -inf, -15.0, -inf, -15.0, -10.0]
Step 2716 1 visits [16.0, 665.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1727 q_vals: [-9.898, -8.657, -inf, -15.0, -inf, -15.0, -10.0]
Step 2717 1 visits [16.0, 666.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1727 q_vals: [-9.898, -8.644, -inf, -15.0, -inf, -15.0, -10.0]
Step 2718 1 visits [16.0, 667.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1727 q_vals: [-9.898, -8.653, -inf, -15.0, -inf, -15.0, -10.0]
Step 2719 1 visits [16.0, 668.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1728 q_vals: [-9.898, -8.663, -inf, -15.0, -inf, -15.0, -10.0]
Step 2720 1 visits [16.0, 669.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1729 q_vals: [-9.898, -8.65, -inf, -15.0, -inf, -15.0, -10.0]
Step 2721 1 visits [16.0, 670.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1730 q_vals: [-9.898, -8.637, -inf, -15.0, -inf, -15.0, -10.0]
Step 2722 1 visits [16.0, 671.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1731 q_vals: [-9.898, -8.647, -inf, -15.0, -inf, -15.0, -10.0]
Step 2723 1 visits [16.0, 672.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1732 q_vals: [-9.898, -8.634, -inf, -15.0, -inf, -15.0, -10.0]
Step 2724 1 visits [16.0, 673.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1732 q_vals: [-9.898, -8.643, -inf, -15.0, -inf, -15.0, -10.0]
Step 2725 1 visits [16.0, 674.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1732 q_vals: [-9.898, -8.653, -inf, -15.0, -inf, -15.0, -10.0]
Step 2726 1 visits [16.0, 675.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1732 q_vals: [-9.898, -8.662, -inf, -15.0, -inf, -15.0, -10.0]
Step 2727 1 visits [16.0, 676.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1732 q_vals: [-9.898, -8.671, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1733, "number_of_timesteps": 182556, "per_episode_reward": -235.41, "episode_reward_trend_value": 0.07333393261907557, "biggest_recent_change": 1.370528902957517},
Step 2728 1 visits [16.0, 677.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1733 q_vals: [-9.898, -8.659, -inf, -15.0, -inf, -15.0, -10.0]
Step 2729 1 visits [16.0, 678.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1734 q_vals: [-9.898, -8.668, -inf, -15.0, -inf, -15.0, -10.0]
Step 2730 1 visits [16.0, 679.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1734 q_vals: [-9.898, -8.655, -inf, -15.0, -inf, -15.0, -10.0]
Step 2731 1 visits [16.0, 680.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1736 q_vals: [-9.898, -8.664, -inf, -15.0, -inf, -15.0, -10.0]
Step 2732 1 visits [16.0, 681.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1736 q_vals: [-9.898, -8.674, -inf, -15.0, -inf, -15.0, -10.0]
Step 2733 1 visits [16.0, 682.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1736 q_vals: [-9.898, -8.661, -inf, -15.0, -inf, -15.0, -10.0]
Step 2734 1 visits [16.0, 683.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1736 q_vals: [-9.898, -8.67, -inf, -15.0, -inf, -15.0, -10.0]
Step 2735 1 visits [16.0, 684.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1736 q_vals: [-9.898, -8.658, -inf, -15.0, -inf, -15.0, -10.0]
Step 2736 1 visits [16.0, 685.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1737 q_vals: [-9.898, -8.645, -inf, -15.0, -inf, -15.0, -10.0]
Step 2737 1 visits [16.0, 686.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1738 q_vals: [-9.898, -8.654, -inf, -15.0, -inf, -15.0, -10.0]
Step 2738 1 visits [16.0, 687.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1738 q_vals: [-9.898, -8.642, -inf, -15.0, -inf, -15.0, -10.0]
Step 2739 1 visits [16.0, 688.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1738 q_vals: [-9.898, -8.651, -inf, -15.0, -inf, -15.0, -10.0]
Step 2740 1 visits [16.0, 689.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1740 q_vals: [-9.898, -8.638, -inf, -15.0, -inf, -15.0, -10.0]
Step 2741 1 visits [16.0, 690.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1740 q_vals: [-9.898, -8.648, -inf, -15.0, -inf, -15.0, -10.0]
Step 2742 1 visits [16.0, 691.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1740 q_vals: [-9.898, -8.657, -inf, -15.0, -inf, -15.0, -10.0]
Step 2743 1 visits [16.0, 692.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1740 q_vals: [-9.898, -8.644, -inf, -15.0, -inf, -15.0, -10.0]
Step 2744 1 visits [16.0, 693.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1740 q_vals: [-9.898, -8.632, -inf, -15.0, -inf, -15.0, -10.0]
Step 2745 1 visits [16.0, 694.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1741 q_vals: [-9.898, -8.641, -inf, -15.0, -inf, -15.0, -10.0]
Step 2746 1 visits [16.0, 695.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1741 q_vals: [-9.898, -8.65, -inf, -15.0, -inf, -15.0, -10.0]
Step 2747 1 visits [16.0, 696.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1742 q_vals: [-9.898, -8.659, -inf, -15.0, -inf, -15.0, -10.0]
Step 2748 1 visits [16.0, 697.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1742 q_vals: [-9.898, -8.668, -inf, -15.0, -inf, -15.0, -10.0]
Step 2749 1 visits [16.0, 698.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1742 q_vals: [-9.898, -8.677, -inf, -15.0, -inf, -15.0, -10.0]
Step 2750 1 visits [16.0, 699.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1742 q_vals: [-9.898, -8.686, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1743, "number_of_timesteps": 183727, "per_episode_reward": -236.27, "episode_reward_trend_value": 0.04850421472779405, "biggest_recent_change": 1.0501390527237504},
Step 2751 1 visits [16.0, 700.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1743 q_vals: [-9.898, -8.696, -inf, -15.0, -inf, -15.0, -10.0]
Step 2752 1 visits [16.0, 701.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1743 q_vals: [-9.898, -8.704, -inf, -15.0, -inf, -15.0, -10.0]
Step 2753 1 visits [16.0, 702.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1743 q_vals: [-9.898, -8.713, -inf, -15.0, -inf, -15.0, -10.0]
[16.0, 703.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1745 q_vals: [-9.898, -8.722, -inf, -15.0, -inf, -15.0, -10.0]
Step 2755 1 visits [16.0, 704.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1746 q_vals: [-9.898, -8.731, -inf, -15.0, -inf, -15.0, -10.0]
Step 2756 1 visits [16.0, 705.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1746 q_vals: [-9.898, -8.719, -inf, -15.0, -inf, -15.0, -10.0]
Step 2757 1 visits [16.0, 706.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1746 q_vals: [-9.898, -8.728, -inf, -15.0, -inf, -15.0, -10.0]
Step 2758 1 visits [16.0, 707.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1746 q_vals: [-9.898, -8.737, -inf, -15.0, -inf, -15.0, -10.0]
Step 2759 1 visits [16.0, 708.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1747 q_vals: [-9.898, -8.746, -inf, -15.0, -inf, -15.0, -10.0]
Step 2760 1 visits [16.0, 709.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1747 q_vals: [-9.898, -8.733, -inf, -15.0, -inf, -15.0, -10.0]
Step 2761 1 visits [16.0, 710.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1747 q_vals: [-9.898, -8.742, -inf, -15.0, -inf, -15.0, -10.0]
Step 2762 1 visits [16.0, 711.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1749 q_vals: [-9.898, -8.751, -inf, -15.0, -inf, -15.0, -10.0]
Step 2763 1 visits [16.0, 712.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1749 q_vals: [-9.898, -8.739, -inf, -15.0, -inf, -15.0, -10.0]
Step 2764 1 visits [16.0, 713.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1749 q_vals: [-9.898, -8.726, -inf, -15.0, -inf, -15.0, -10.0]
Step 2765 1 visits [16.0, 714.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1750 q_vals: [-9.898, -8.714, -inf, -15.0, -inf, -15.0, -10.0]
Step 2766 1 visits [16.0, 715.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1750 q_vals: [-9.898, -8.723, -inf, -15.0, -inf, -15.0, -10.0]
Step 2767 1 visits [16.0, 716.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1750 q_vals: [-9.898, -8.732, -inf, -15.0, -inf, -15.0, -10.0]
Step 2768 1 visits [16.0, 717.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1751 q_vals: [-9.898, -8.74, -inf, -15.0, -inf, -15.0, -10.0]
Step 2769 1 visits [16.0, 718.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1751 q_vals: [-9.898, -8.749, -inf, -15.0, -inf, -15.0, -10.0]
Step 2770 1 visits [16.0, 719.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1751 q_vals: [-9.898, -8.758, -inf, -15.0, -inf, -15.0, -10.0]
Step 2771 1 visits [16.0, 720.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1752 q_vals: [-9.898, -8.746, -inf, -15.0, -inf, -15.0, -10.0]
Step 2772 1 visits [16.0, 721.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1752 q_vals: [-9.898, -8.735, -inf, -15.0, -inf, -15.0, -10.0]
Step 2773 1 visits [16.0, 722.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1752 q_vals: [-9.898, -8.744, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1753, "number_of_timesteps": 185611, "per_episode_reward": -237.48, "episode_reward_trend_value": 0.025815301089964278, "biggest_recent_change": 1.2048878356235946},
Step 2774 1 visits [16.0, 723.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1753 q_vals: [-9.898, -8.752, -inf, -15.0, -inf, -15.0, -10.0]
Step 2775 1 visits [16.0, 724.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1754 q_vals: [-9.898, -8.74, -inf, -15.0, -inf, -15.0, -10.0]
Step 2776 1 visits [16.0, 725.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1756 q_vals: [-9.898, -8.728, -inf, -15.0, -inf, -15.0, -10.0]
Step 2777 1 visits [16.0, 726.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1756 q_vals: [-9.898, -8.737, -inf, -15.0, -inf, -15.0, -10.0]
Step 2778 1 visits [16.0, 727.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1757 q_vals: [-9.898, -8.725, -inf, -15.0, -inf, -15.0, -10.0]
Step 2779 1 visits [16.0, 728.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1757 q_vals: [-9.898, -8.733, -inf, -15.0, -inf, -15.0, -10.0]
Step 2780 1 visits [16.0, 729.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1758 q_vals: [-9.898, -8.742, -inf, -15.0, -inf, -15.0, -10.0]
Step 2781 1 visits [16.0, 730.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1758 q_vals: [-9.898, -8.73, -inf, -15.0, -inf, -15.0, -10.0]
Step 2782 1 visits [16.0, 731.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1759 q_vals: [-9.898, -8.739, -inf, -15.0, -inf, -15.0, -10.0]
Step 2783 1 visits [16.0, 732.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1762 q_vals: [-9.898, -8.747, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1763, "number_of_timesteps": 186766, "per_episode_reward": -236.34, "episode_reward_trend_value": 0.026744864752790438, "biggest_recent_change": 1.2048878356235946},
Step 2784 1 visits [16.0, 733.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1763 q_vals: [-9.898, -8.756, -inf, -15.0, -inf, -15.0, -10.0]
Step 2785 1 visits [16.0, 734.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1763 q_vals: [-9.898, -8.764, -inf, -15.0, -inf, -15.0, -10.0]
Step 2786 1 visits [16.0, 735.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1764 q_vals: [-9.898, -8.752, -inf, -15.0, -inf, -15.0, -10.0]
Step 2787 1 visits [16.0, 736.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1765 q_vals: [-9.898, -8.761, -inf, -15.0, -inf, -15.0, -10.0]
Step 2788 1 visits [16.0, 737.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1765 q_vals: [-9.898, -8.749, -inf, -15.0, -inf, -15.0, -10.0]
Step 2789 1 visits [16.0, 738.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1765 q_vals: [-9.898, -8.737, -inf, -15.0, -inf, -15.0, -10.0]
Step 2790 1 visits [16.0, 739.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1765 q_vals: [-9.898, -8.745, -inf, -15.0, -inf, -15.0, -10.0]
Step 2791 1 visits [16.0, 740.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1768 q_vals: [-9.898, -8.734, -inf, -15.0, -inf, -15.0, -10.0]
Step 2792 1 visits [16.0, 741.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1769 q_vals: [-9.898, -8.742, -inf, -15.0, -inf, -15.0, -10.0]
Step 2793 1 visits [16.0, 742.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1771 q_vals: [-9.898, -8.751, -inf, -15.0, -inf, -15.0, -10.0]
Step 2794 1 visits [16.0, 743.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1771 q_vals: [-9.898, -8.759, -inf, -15.0, -inf, -15.0, -10.0]
Step 2795 1 visits [16.0, 744.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1771 q_vals: [-9.898, -8.747, -inf, -15.0, -inf, -15.0, -10.0]
Step 2796 1 visits [16.0, 745.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1772 q_vals: [-9.898, -8.756, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1773, "number_of_timesteps": 187525, "per_episode_reward": -235.33, "episode_reward_trend_value": 0.027544603440410105, "biggest_recent_change": 1.2048878356235946},
Step 2797 1 visits [16.0, 746.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1773 q_vals: [-9.898, -8.744, -inf, -15.0, -inf, -15.0, -10.0]
Step 2798 1 visits [16.0, 747.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1775 q_vals: [-9.898, -8.752, -inf, -15.0, -inf, -15.0, -10.0]
Step 2799 1 visits [16.0, 748.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1776 q_vals: [-9.898, -8.761, -inf, -15.0, -inf, -15.0, -10.0]
Step 2800 1 visits [16.0, 749.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1776 q_vals: [-9.898, -8.769, -inf, -15.0, -inf, -15.0, -10.0]
Step 2801 1 visits [16.0, 750.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1777 q_vals: [-9.898, -8.777, -inf, -15.0, -inf, -15.0, -10.0]
Step 2802 1 visits [16.0, 751.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1778 q_vals: [-9.898, -8.766, -inf, -15.0, -inf, -15.0, -10.0]
Step 2803 1 visits [16.0, 752.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1778 q_vals: [-9.898, -8.754, -inf, -15.0, -inf, -15.0, -10.0]
Step 2804 1 visits [16.0, 753.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1779 q_vals: [-9.898, -8.742, -inf, -15.0, -inf, -15.0, -10.0]
Step 2805 1 visits [16.0, 754.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1779 q_vals: [-9.898, -8.731, -inf, -15.0, -inf, -15.0, -10.0]
Step 2806 1 visits [16.0, 755.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1780 q_vals: [-9.898, -8.739, -inf, -15.0, -inf, -15.0, -10.0]
Step 2807 1 visits [16.0, 756.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1780 q_vals: [-9.898, -8.747, -inf, -15.0, -inf, -15.0, -10.0]
Step 2808 1 visits [16.0, 757.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1781 q_vals: [-9.898, -8.756, -inf, -15.0, -inf, -15.0, -10.0]
Step 2809 1 visits [16.0, 758.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1782 q_vals: [-9.898, -8.744, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1784, "number_of_timesteps": 188413, "per_episode_reward": -234.25, "episode_reward_trend_value": 0.03483076764885469, "biggest_recent_change": 1.2048878356235946},
Step 2810 1 visits [16.0, 759.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1784 q_vals: [-9.898, -8.752, -inf, -15.0, -inf, -15.0, -10.0]
Step 2811 1 visits [16.0, 760.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1784 q_vals: [-9.898, -8.76, -inf, -15.0, -inf, -15.0, -10.0]
Step 2812 1 visits [16.0, 761.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1785 q_vals: [-9.898, -8.749, -inf, -15.0, -inf, -15.0, -10.0]
Step 2813 1 visits [16.0, 762.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1786 q_vals: [-9.898, -8.757, -inf, -15.0, -inf, -15.0, -10.0]
Step 2814 1 visits [16.0, 763.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1786 q_vals: [-9.898, -8.765, -inf, -15.0, -inf, -15.0, -10.0]
Step 2815 1 visits [16.0, 764.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1786 q_vals: [-9.898, -8.754, -inf, -15.0, -inf, -15.0, -10.0]
Step 2816 1 visits [16.0, 765.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1787 q_vals: [-9.898, -8.742, -inf, -15.0, -inf, -15.0, -10.0]
Step 2817 1 visits [16.0, 766.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1787 q_vals: [-9.898, -8.731, -inf, -15.0, -inf, -15.0, -10.0]
Step 2818 1 visits [16.0, 767.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1788 q_vals: [-9.898, -8.739, -inf, -15.0, -inf, -15.0, -10.0]
Step 2819 1 visits [16.0, 768.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1788 q_vals: [-9.898, -8.747, -inf, -15.0, -inf, -15.0, -10.0]
Step 2820 1 visits [16.0, 769.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1789 q_vals: [-9.898, -8.736, -inf, -15.0, -inf, -15.0, -10.0]
Step 2821 1 visits [16.0, 770.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1790 q_vals: [-9.898, -8.725, -inf, -15.0, -inf, -15.0, -10.0]
Step 2822 1 visits [16.0, 771.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1790 q_vals: [-9.898, -8.733, -inf, -15.0, -inf, -15.0, -10.0]
Step 2823 1 visits [16.0, 772.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1791 q_vals: [-9.898, -8.741, -inf, -15.0, -inf, -15.0, -10.0]
Step 2824 1 visits [16.0, 773.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1791 q_vals: [-9.898, -8.749, -inf, -15.0, -inf, -15.0, -10.0]
Step 2825 1 visits [16.0, 774.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1791 q_vals: [-9.898, -8.738, -inf, -15.0, -inf, -15.0, -10.0]
Step 2826 1 visits [16.0, 775.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1791 q_vals: [-9.898, -8.726, -inf, -15.0, -inf, -15.0, -10.0]
Step 2827 1 visits [16.0, 776.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1792 q_vals: [-9.898, -8.734, -inf, -15.0, -inf, -15.0, -10.0]
Step 2828 1 visits [16.0, 777.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1792 q_vals: [-9.898, -8.742, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1794, "number_of_timesteps": 189544, "per_episode_reward": -233.24, "episode_reward_trend_value": 0.04077989264431083, "biggest_recent_change": 1.2048878356235946},
Step 2829 1 visits [16.0, 778.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1794 q_vals: [-9.898, -8.731, -inf, -15.0, -inf, -15.0, -10.0]
Step 2830 1 visits [16.0, 779.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1796 q_vals: [-9.898, -8.72, -inf, -15.0, -inf, -15.0, -10.0]
Step 2831 1 visits [16.0, 780.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1797 q_vals: [-9.898, -8.728, -inf, -15.0, -inf, -15.0, -10.0]
Step 2832 1 visits [16.0, 781.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1797 q_vals: [-9.898, -8.717, -inf, -15.0, -inf, -15.0, -10.0]
Step 2833 1 visits [16.0, 782.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1798 q_vals: [-9.898, -8.706, -inf, -15.0, -inf, -15.0, -10.0]
Step 2834 1 visits [16.0, 783.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1798 q_vals: [-9.898, -8.714, -inf, -15.0, -inf, -15.0, -10.0]
Step 2835 1 visits [16.0, 784.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1798 q_vals: [-9.898, -8.703, -inf, -15.0, -inf, -15.0, -10.0]
[-9.898, -8.711, -inf, -15.0, -inf, -15.0, -10.0]
Step 2837 1 visits [16.0, 786.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1798 q_vals: [-9.898, -8.719, -inf, -15.0, -inf, -15.0, -10.0]
Step 2838 1 visits [16.0, 787.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1798 q_vals: [-9.898, -8.727, -inf, -15.0, -inf, -15.0, -10.0]
Step 2839 1 visits [16.0, 788.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1799 q_vals: [-9.898, -8.735, -inf, -15.0, -inf, -15.0, -10.0]
Step 2840 1 visits [16.0, 789.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1801 q_vals: [-9.898, -8.743, -inf, -15.0, -inf, -15.0, -10.0]
Step 2841 1 visits [16.0, 790.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1803 q_vals: [-9.898, -8.732, -inf, -15.0, -inf, -15.0, -10.0]
Step 2842 1 visits [16.0, 791.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1803 q_vals: [-9.898, -8.739, -inf, -15.0, -inf, -15.0, -10.0]
Step 2843 1 visits [16.0, 792.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1803 q_vals: [-9.898, -8.728, -inf, -15.0, -inf, -15.0, -10.0]
Step 2844 1 visits [16.0, 793.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1803 q_vals: [-9.898, -8.736, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1804, "number_of_timesteps": 190607, "per_episode_reward": -231.55, "episode_reward_trend_value": 0.05144960181619006, "biggest_recent_change": 1.6860765341612307},
Step 2845 1 visits [16.0, 794.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1804 q_vals: [-9.898, -8.744, -inf, -15.0, -inf, -15.0, -10.0]
Step 2846 1 visits [16.0, 795.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1804 q_vals: [-9.898, -8.752, -inf, -15.0, -inf, -15.0, -10.0]
Step 2847 1 visits [16.0, 796.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1804 q_vals: [-9.898, -8.741, -inf, -15.0, -inf, -15.0, -10.0]
Step 2848 1 visits [16.0, 797.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1805 q_vals: [-9.898, -8.749, -inf, -15.0, -inf, -15.0, -10.0]
Step 2849 1 visits [16.0, 798.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1805 q_vals: [-9.898, -8.757, -inf, -15.0, -inf, -15.0, -10.0]
Step 2850 1 visits [16.0, 799.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1807 q_vals: [-9.898, -8.746, -inf, -15.0, -inf, -15.0, -10.0]
Step 2851 1 visits [16.0, 800.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1808 q_vals: [-9.898, -8.754, -inf, -15.0, -inf, -15.0, -10.0]
Step 2852 1 visits [16.0, 801.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1808 q_vals: [-9.898, -8.761, -inf, -15.0, -inf, -15.0, -10.0]
Step 2853 1 visits [16.0, 802.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1808 q_vals: [-9.898, -8.769, -inf, -15.0, -inf, -15.0, -10.0]
Step 2854 1 visits [16.0, 803.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1808 q_vals: [-9.898, -8.758, -inf, -15.0, -inf, -15.0, -10.0]
Step 2855 1 visits [16.0, 804.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1808 q_vals: [-9.898, -8.766, -inf, -15.0, -inf, -15.0, -10.0]
Step 2856 1 visits [16.0, 805.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1809 q_vals: [-9.898, -8.774, -inf, -15.0, -inf, -15.0, -10.0]
Step 2857 1 visits [16.0, 806.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1809 q_vals: [-9.898, -8.782, -inf, -15.0, -inf, -15.0, -10.0]
Step 2858 1 visits [16.0, 807.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1809 q_vals: [-9.898, -8.789, -inf, -15.0, -inf, -15.0, -10.0]
Step 2859 1 visits [16.0, 808.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1810 q_vals: [-9.898, -8.797, -inf, -15.0, -inf, -15.0, -10.0]
Step 2860 1 visits [16.0, 809.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1811 q_vals: [-9.898, -8.805, -inf, -15.0, -inf, -15.0, -10.0]
Step 2861 1 visits [16.0, 810.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1811 q_vals: [-9.898, -8.812, -inf, -15.0, -inf, -15.0, -10.0]
Step 2862 1 visits [16.0, 811.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1812 q_vals: [-9.898, -8.82, -inf, -15.0, -inf, -15.0, -10.0]
Step 2863 1 visits [16.0, 812.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1813 q_vals: [-9.898, -8.827, -inf, -15.0, -inf, -15.0, -10.0]
Step 2864 1 visits [16.0, 813.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1813 q_vals: [-9.898, -8.835, -inf, -15.0, -inf, -15.0, -10.0]
Step 2865 1 visits [16.0, 814.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1813 q_vals: [-9.898, -8.824, -inf, -15.0, -inf, -15.0, -10.0]
Step 2866 1 visits [16.0, 815.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1813 q_vals: [-9.898, -8.822, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1814, "number_of_timesteps": 191889, "per_episode_reward": -231.67, "episode_reward_trend_value": 0.04178891390310184, "biggest_recent_change": 1.6860765341612307},
Step 2867 1 visits [16.0, 816.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1814 q_vals: [-9.898, -8.811, -inf, -15.0, -inf, -15.0, -10.0]
Step 2868 1 visits [16.0, 817.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1816 q_vals: [-9.898, -8.819, -inf, -15.0, -inf, -15.0, -10.0]
Step 2869 1 visits [16.0, 818.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1816 q_vals: [-9.898, -8.826, -inf, -15.0, -inf, -15.0, -10.0]
Step 2870 1 visits [16.0, 819.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1817 q_vals: [-9.898, -8.834, -inf, -15.0, -inf, -15.0, -10.0]
Step 2871 1 visits [16.0, 820.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1817 q_vals: [-9.898, -8.823, -inf, -15.0, -inf, -15.0, -10.0]
Step 2872 1 visits [16.0, 821.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1818 q_vals: [-9.898, -8.831, -inf, -15.0, -inf, -15.0, -10.0]
Step 2873 1 visits [16.0, 822.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1818 q_vals: [-9.898, -8.838, -inf, -15.0, -inf, -15.0, -10.0]
Step 2874 1 visits [16.0, 823.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1819 q_vals: [-9.898, -8.846, -inf, -15.0, -inf, -15.0, -10.0]
Step 2875 1 visits [16.0, 824.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1820 q_vals: [-9.898, -8.853, -inf, -15.0, -inf, -15.0, -10.0]
[-9.898, -8.842, -inf, -15.0, -inf, -15.0, -10.0]
Step 2877 1 visits [16.0, 826.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1821 q_vals: [-9.898, -8.832, -inf, -15.0, -inf, -15.0, -10.0]
Step 2878 1 visits [16.0, 827.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1821 q_vals: [-9.898, -8.821, -inf, -15.0, -inf, -15.0, -10.0]
Step 2879 1 visits [16.0, 828.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1821 q_vals: [-9.898, -8.81, -inf, -15.0, -inf, -15.0, -10.0]
Step 2880 1 visits [16.0, 829.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1821 q_vals: [-9.898, -8.8, -inf, -15.0, -inf, -15.0, -10.0]
Step 2881 1 visits [16.0, 830.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1821 q_vals: [-9.898, -8.807, -inf, -15.0, -inf, -15.0, -10.0]
Step 2882 1 visits [16.0, 831.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1822 q_vals: [-9.898, -8.815, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1824, "number_of_timesteps": 193168, "per_episode_reward": -232.56, "episode_reward_trend_value": 0.03164246844747633, "biggest_recent_change": 1.6860765341612307},
Step 2883 1 visits [16.0, 832.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1824 q_vals: [-9.898, -8.822, -inf, -15.0, -inf, -15.0, -10.0]
Step 2884 1 visits [16.0, 833.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1824 q_vals: [-9.898, -8.829, -inf, -15.0, -inf, -15.0, -10.0]
Step 2885 1 visits [16.0, 834.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1825 q_vals: [-9.898, -8.819, -inf, -15.0, -inf, -15.0, -10.0]
Step 2886 1 visits [16.0, 835.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1827 q_vals: [-9.898, -8.808, -inf, -15.0, -inf, -15.0, -10.0]
Step 2887 1 visits [16.0, 836.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1827 q_vals: [-9.898, -8.798, -inf, -15.0, -inf, -15.0, -10.0]
Step 2888 1 visits [16.0, 837.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1827 q_vals: [-9.898, -8.787, -inf, -15.0, -inf, -15.0, -10.0]
Step 2889 1 visits [16.0, 838.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1828 q_vals: [-9.898, -8.777, -inf, -15.0, -inf, -15.0, -10.0]
Step 2890 1 visits [16.0, 839.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1829 q_vals: [-9.898, -8.779, -inf, -15.0, -inf, -15.0, -10.0]
Step 2891 1 visits [16.0, 840.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1830 q_vals: [-9.898, -8.768, -inf, -15.0, -inf, -15.0, -10.0]
Step 2892 1 visits [16.0, 841.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1831 q_vals: [-9.898, -8.758, -inf, -15.0, -inf, -15.0, -10.0]
Step 2893 1 visits [16.0, 842.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1831 q_vals: [-9.898, -8.747, -inf, -15.0, -inf, -15.0, -10.0]
Step 2894 1 visits [16.0, 843.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1833 q_vals: [-9.898, -8.755, -inf, -15.0, -inf, -15.0, -10.0]
Step 2895 1 visits [16.0, 844.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1833 q_vals: [-9.898, -8.762, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1834, "number_of_timesteps": 194189, "per_episode_reward": -232.06, "episode_reward_trend_value": 0.0468726692275251, "biggest_recent_change": 1.6860765341612307},
Step 2896 1 visits [16.0, 845.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1834 q_vals: [-9.898, -8.752, -inf, -15.0, -inf, -15.0, -10.0]
Step 2897 1 visits [16.0, 846.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1835 q_vals: [-9.898, -8.759, -inf, -15.0, -inf, -15.0, -10.0]
Step 2898 1 visits [16.0, 847.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1835 q_vals: [-9.898, -8.767, -inf, -15.0, -inf, -15.0, -10.0]
Step 2899 1 visits [16.0, 848.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1835 q_vals: [-9.898, -8.774, -inf, -15.0, -inf, -15.0, -10.0]
Step 2900 1 visits [16.0, 849.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1836 q_vals: [-9.898, -8.781, -inf, -15.0, -inf, -15.0, -10.0]
Step 2901 1 visits [16.0, 850.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1836 q_vals: [-9.898, -8.789, -inf, -15.0, -inf, -15.0, -10.0]
Step 2902 1 visits [16.0, 851.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1836 q_vals: [-9.898, -8.778, -inf, -15.0, -inf, -15.0, -10.0]
Step 2903 1 visits [16.0, 852.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1838 q_vals: [-9.898, -8.771, -inf, -15.0, -inf, -15.0, -10.0]
Step 2904 1 visits [16.0, 853.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1840 q_vals: [-9.898, -8.778, -inf, -15.0, -inf, -15.0, -10.0]
Step 2905 1 visits [16.0, 854.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1840 q_vals: [-9.898, -8.768, -inf, -15.0, -inf, -15.0, -10.0]
Step 2906 1 visits [16.0, 855.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1842 q_vals: [-9.898, -8.758, -inf, -15.0, -inf, -15.0, -10.0]
Step 2907 1 visits [16.0, 856.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1842 q_vals: [-9.898, -8.765, -inf, -15.0, -inf, -15.0, -10.0]
Step 2908 1 visits [16.0, 857.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1842 q_vals: [-9.898, -8.772, -inf, -15.0, -inf, -15.0, -10.0]
Step 2909 1 visits [16.0, 858.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1842 q_vals: [-9.898, -8.779, -inf, -15.0, -inf, -15.0, -10.0]
Step 2910 1 visits [16.0, 859.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1842 q_vals: [-9.898, -8.787, -inf, -15.0, -inf, -15.0, -10.0]
Step 2911 1 visits [16.0, 860.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1842 q_vals: [-9.898, -8.794, -inf, -15.0, -inf, -15.0, -10.0]
Step 2912 1 visits [16.0, 861.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1842 q_vals: [-9.898, -8.784, -inf, -15.0, -inf, -15.0, -10.0]
Step 2913 1 visits [16.0, 862.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1842 q_vals: [-9.898, -8.773, -inf, -15.0, -inf, -15.0, -10.0]
Step 2914 1 visits [16.0, 863.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1843 q_vals: [-9.898, -8.763, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1844, "number_of_timesteps": 195208, "per_episode_reward": -231.22, "episode_reward_trend_value": 0.06953516926895449, "biggest_recent_change": 1.6860765341612307},
Step 2915 1 visits [16.0, 864.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1844 q_vals: [-9.898, -8.771, -inf, -15.0, -inf, -15.0, -10.0]
Step 2916 1 visits [16.0, 865.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1845 q_vals: [-9.898, -8.778, -inf, -15.0, -inf, -15.0, -10.0]
Step 2917 1 visits [16.0, 866.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1848 q_vals: [-9.898, -8.785, -inf, -15.0, -inf, -15.0, -10.0]
Step 2918 1 visits [16.0, 867.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1848 q_vals: [-9.898, -8.775, -inf, -15.0, -inf, -15.0, -10.0]
Step 2919 1 visits [16.0, 868.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1849 q_vals: [-9.898, -8.765, -inf, -15.0, -inf, -15.0, -10.0]
Step 2920 1 visits [16.0, 869.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1849 q_vals: [-9.898, -8.772, -inf, -15.0, -inf, -15.0, -10.0]
Step 2921 1 visits [16.0, 870.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1849 q_vals: [-9.898, -8.779, -inf, -15.0, -inf, -15.0, -10.0]
Step 2922 1 visits [16.0, 871.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1849 q_vals: [-9.898, -8.769, -inf, -15.0, -inf, -15.0, -10.0]
Step 2923 1 visits [16.0, 872.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1849 q_vals: [-9.898, -8.759, -inf, -15.0, -inf, -15.0, -10.0]
Step 2924 1 visits [16.0, 873.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1849 q_vals: [-9.898, -8.766, -inf, -15.0, -inf, -15.0, -10.0]
Step 2925 1 visits [16.0, 874.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1850 q_vals: [-9.898, -8.773, -inf, -15.0, -inf, -15.0, -10.0]
Step 2926 1 visits [16.0, 875.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1851 q_vals: [-9.898, -8.78, -inf, -15.0, -inf, -15.0, -10.0]
Step 2927 1 visits [16.0, 876.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1852 q_vals: [-9.898, -8.787, -inf, -15.0, -inf, -15.0, -10.0]
Step 2928 1 visits [16.0, 877.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1853 q_vals: [-9.898, -8.794, -inf, -15.0, -inf, -15.0, -10.0]
Step 2929 1 visits [16.0, 878.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1853 q_vals: [-9.898, -8.802, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1854, "number_of_timesteps": 196324, "per_episode_reward": -231.52, "episode_reward_trend_value": 0.053571148946374735, "biggest_recent_change": 1.6860765341612307},
Step 2930 1 visits [16.0, 879.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1854 q_vals: [-9.898, -8.792, -inf, -15.0, -inf, -15.0, -10.0]
Step 2931 1 visits [16.0, 880.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1854 q_vals: [-9.898, -8.799, -inf, -15.0, -inf, -15.0, -10.0]
Step 2932 1 visits [16.0, 881.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1855 q_vals: [-9.898, -8.789, -inf, -15.0, -inf, -15.0, -10.0]
Step 2933 1 visits [16.0, 882.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1855 q_vals: [-9.898, -8.779, -inf, -15.0, -inf, -15.0, -10.0]
Step 2934 1 visits [16.0, 883.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1857 q_vals: [-9.898, -8.786, -inf, -15.0, -inf, -15.0, -10.0]
Step 2935 1 visits [16.0, 884.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1858 q_vals: [-9.898, -8.793, -inf, -15.0, -inf, -15.0, -10.0]
Step 2936 1 visits [16.0, 885.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1858 q_vals: [-9.898, -8.8, -inf, -15.0, -inf, -15.0, -10.0]
Step 2937 1 visits [16.0, 886.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1858 q_vals: [-9.898, -8.807, -inf, -15.0, -inf, -15.0, -10.0]
Step 2938 1 visits [16.0, 887.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1860 q_vals: [-9.898, -8.814, -inf, -15.0, -inf, -15.0, -10.0]
Step 2939 1 visits [16.0, 888.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1860 q_vals: [-9.898, -8.821, -inf, -15.0, -inf, -15.0, -10.0]
Step 2940 1 visits [16.0, 889.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1861 q_vals: [-9.898, -8.828, -inf, -15.0, -inf, -15.0, -10.0]
Step 2941 1 visits [16.0, 890.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1861 q_vals: [-9.898, -8.835, -inf, -15.0, -inf, -15.0, -10.0]
Step 2942 1 visits [16.0, 891.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1861 q_vals: [-9.898, -8.841, -inf, -15.0, -inf, -15.0, -10.0]
Step 2943 1 visits [16.0, 892.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1862 q_vals: [-9.898, -8.832, -inf, -15.0, -inf, -15.0, -10.0]
Step 2944 1 visits [16.0, 893.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1862 q_vals: [-9.898, -8.838, -inf, -15.0, -inf, -15.0, -10.0]
Step 2945 1 visits [16.0, 894.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1862 q_vals: [-9.898, -8.845, -inf, -15.0, -inf, -15.0, -10.0]
Step 2946 1 visits [16.0, 895.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1863 q_vals: [-9.898, -8.835, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1864, "number_of_timesteps": 197452, "per_episode_reward": -230.82, "episode_reward_trend_value": 0.05012252851692173, "biggest_recent_change": 1.6860765341612307},
Step 2947 1 visits [16.0, 896.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1864 q_vals: [-9.898, -8.842, -inf, -15.0, -inf, -15.0, -10.0]
Step 2948 1 visits [16.0, 897.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1865 q_vals: [-9.898, -8.832, -inf, -15.0, -inf, -15.0, -10.0]
Step 2949 1 visits [16.0, 898.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1865 q_vals: [-9.898, -8.839, -inf, -15.0, -inf, -15.0, -10.0]
Step 2950 1 visits [16.0, 899.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1866 q_vals: [-9.898, -8.846, -inf, -15.0, -inf, -15.0, -10.0]
Step 2951 1 visits [16.0, 900.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1867 q_vals: [-9.898, -8.853, -inf, -15.0, -inf, -15.0, -10.0]
Step 2952 1 visits [16.0, 901.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1868 q_vals: [-9.898, -8.86, -inf, -15.0, -inf, -15.0, -10.0]
Step 2953 1 visits [16.0, 902.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1868 q_vals: [-9.898, -8.867, -inf, -15.0, -inf, -15.0, -10.0]
Step 2954 1 visits [16.0, 903.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1868 q_vals: [-9.898, -8.873, -inf, -15.0, -inf, -15.0, -10.0]
Step 2955 1 visits [16.0, 904.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1868 q_vals: [-9.898, -8.864, -inf, -15.0, -inf, -15.0, -10.0]
Step 2956 1 visits [16.0, 905.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1869 q_vals: [-9.898, -8.87, -inf, -15.0, -inf, -15.0, -10.0]
Step 2957 1 visits [16.0, 906.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1870 q_vals: [-9.898, -8.877, -inf, -15.0, -inf, -15.0, -10.0]
Step 2958 1 visits [16.0, 907.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1871 q_vals: [-9.898, -8.884, -inf, -15.0, -inf, -15.0, -10.0]
Step 2959 1 visits [16.0, 908.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1871 q_vals: [-9.898, -8.891, -inf, -15.0, -inf, -15.0, -10.0]
Step 2960 1 visits [16.0, 909.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1872 q_vals: [-9.898, -8.897, -inf, -15.0, -inf, -15.0, -10.0]
Step 2961 1 visits [16.0, 910.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1872 q_vals: [-9.898, -8.888, -inf, -15.0, -inf, -15.0, -10.0]
Step 2962 1 visits [16.0, 911.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1873 q_vals: [-9.898, -8.894, -inf, -15.0, -inf, -15.0, -10.0]
Step 2963 1 visits [16.0, 912.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1873 q_vals: [-9.898, -8.885, -inf, -15.0, -inf, -15.0, -10.0]
Step 2964 1 visits [16.0, 913.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1873 q_vals: [-9.898, -8.891, -inf, -15.0, -inf, -15.0, -10.0]
Step 2965 1 visits [16.0, 914.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1873 q_vals: [-9.898, -8.898, -inf, -15.0, -inf, -15.0, -10.0]
Step 2966 1 visits [16.0, 915.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1873 q_vals: [-9.898, -8.905, -inf, -15.0, -inf, -15.0, -10.0]
Step 2967 1 visits [16.0, 916.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1873 q_vals: [-9.898, -8.895, -inf, -15.0, -inf, -15.0, -10.0]
Step 2968 1 visits [16.0, 917.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1873 q_vals: [-9.898, -8.902, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1875, "number_of_timesteps": 198744, "per_episode_reward": -230.98, "episode_reward_trend_value": 0.036366643054876455, "biggest_recent_change": 1.6860765341612307},
Step 2969 1 visits [16.0, 918.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1875 q_vals: [-9.898, -8.892, -inf, -15.0, -inf, -15.0, -10.0]
Step 2970 1 visits [16.0, 919.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1876 q_vals: [-9.898, -8.882, -inf, -15.0, -inf, -15.0, -10.0]
Step 2971 1 visits [16.0, 920.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1876 q_vals: [-9.898, -8.889, -inf, -15.0, -inf, -15.0, -10.0]
Step 2972 1 visits [16.0, 921.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1878 q_vals: [-9.898, -8.895, -inf, -15.0, -inf, -15.0, -10.0]
Step 2973 1 visits [16.0, 922.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1878 q_vals: [-9.898, -8.886, -inf, -15.0, -inf, -15.0, -10.0]
Step 2974 1 visits [16.0, 923.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1878 q_vals: [-9.898, -8.876, -inf, -15.0, -inf, -15.0, -10.0]
Step 2975 1 visits [16.0, 924.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1878 q_vals: [-9.898, -8.867, -inf, -15.0, -inf, -15.0, -10.0]
Step 2976 1 visits [16.0, 925.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1879 q_vals: [-9.898, -8.873, -inf, -15.0, -inf, -15.0, -10.0]
Step 2977 1 visits [16.0, 926.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1879 q_vals: [-9.898, -8.88, -inf, -15.0, -inf, -15.0, -10.0]
Step 2978 1 visits [16.0, 927.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1880 q_vals: [-9.898, -8.87, -inf, -15.0, -inf, -15.0, -10.0]
Step 2979 1 visits [16.0, 928.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1880 q_vals: [-9.898, -8.861, -inf, -15.0, -inf, -15.0, -10.0]
Step 2980 1 visits [16.0, 929.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1882 q_vals: [-9.898, -8.851, -inf, -15.0, -inf, -15.0, -10.0]
Step 2981 1 visits [16.0, 930.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1882 q_vals: [-9.898, -8.858, -inf, -15.0, -inf, -15.0, -10.0]
Step 2982 1 visits [16.0, 931.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1883 q_vals: [-9.898, -8.864, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1885, "number_of_timesteps": 200113, "per_episode_reward": -229.87, "episode_reward_trend_value": 0.037420740945686745, "biggest_recent_change": 1.6860765341612307},
Step 2983 1 visits [16.0, 932.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1885 q_vals: [-9.898, -8.871, -inf, -15.0, -inf, -15.0, -10.0]
Step 2984 1 visits [16.0, 933.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1885 q_vals: [-9.898, -8.878, -inf, -15.0, -inf, -15.0, -10.0]
Step 2985 1 visits [16.0, 934.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1885 q_vals: [-9.898, -8.868, -inf, -15.0, -inf, -15.0, -10.0]
Step 2986 1 visits [16.0, 935.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1885 q_vals: [-9.898, -8.875, -inf, -15.0, -inf, -15.0, -10.0]
Step 2987 1 visits [16.0, 936.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1885 q_vals: [-9.898, -8.881, -inf, -15.0, -inf, -15.0, -10.0]
Step 2988 1 visits [16.0, 937.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1886 q_vals: [-9.898, -8.872, -inf, -15.0, -inf, -15.0, -10.0]
Step 2989 1 visits [16.0, 938.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1886 q_vals: [-9.898, -8.878, -inf, -15.0, -inf, -15.0, -10.0]
Step 2990 1 visits [16.0, 939.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1886 q_vals: [-9.898, -8.869, -inf, -15.0, -inf, -15.0, -10.0]
Step 2991 1 visits [16.0, 940.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1887 q_vals: [-9.898, -8.859, -inf, -15.0, -inf, -15.0, -10.0]
Step 2992 1 visits [16.0, 941.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1887 q_vals: [-9.898, -8.866, -inf, -15.0, -inf, -15.0, -10.0]
Step 2993 1 visits [16.0, 942.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1889 q_vals: [-9.898, -8.856, -inf, -15.0, -inf, -15.0, -10.0]
Step 2994 1 visits [16.0, 943.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1889 q_vals: [-9.898, -8.863, -inf, -15.0, -inf, -15.0, -10.0]
Step 2995 1 visits [16.0, 944.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1889 q_vals: [-9.898, -8.854, -inf, -15.0, -inf, -15.0, -10.0]
Step 2996 1 visits [16.0, 945.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1889 q_vals: [-9.898, -8.86, -inf, -15.0, -inf, -15.0, -10.0]
Step 2997 1 visits [16.0, 946.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1889 q_vals: [-9.898, -8.851, -inf, -15.0, -inf, -15.0, -10.0]
Step 2998 1 visits [16.0, 947.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1889 q_vals: [-9.898, -8.857, -inf, -15.0, -inf, -15.0, -10.0]
Step 2999 1 visits [16.0, 948.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1889 q_vals: [-9.898, -8.864, -inf, -15.0, -inf, -15.0, -10.0]
Step 3000 1 visits [16.0, 949.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1889 q_vals: [-9.898, -8.87, -inf, -15.0, -inf, -15.0, -10.0]
Step 3001 1 visits [16.0, 950.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1890 q_vals: [-9.898, -8.877, -inf, -15.0, -inf, -15.0, -10.0]
Step 3002 1 visits [16.0, 951.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1892 q_vals: [-9.898, -8.883, -inf, -15.0, -inf, -15.0, -10.0]
Step 3003 1 visits [16.0, 952.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1893 q_vals: [-9.898, -8.874, -inf, -15.0, -inf, -15.0, -10.0]
Step 3004 1 visits [16.0, 953.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1893 q_vals: [-9.898, -8.864, -inf, -15.0, -inf, -15.0, -10.0]
Step 3005 1 visits [16.0, 954.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1893 q_vals: [-9.898, -8.871, -inf, -15.0, -inf, -15.0, -10.0]
Step 3006 1 visits [16.0, 955.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1894 q_vals: [-9.898, -8.877, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1896, "number_of_timesteps": 201644, "per_episode_reward": -229.27, "episode_reward_trend_value": 0.025391820339682014, "biggest_recent_change": 1.1065718807464293},
Step 3007 1 visits [16.0, 956.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1896 q_vals: [-9.898, -8.884, -inf, -15.0, -inf, -15.0, -10.0]
Step 3008 1 visits [16.0, 957.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1896 q_vals: [-9.898, -8.874, -inf, -15.0, -inf, -15.0, -10.0]
Step 3009 1 visits [16.0, 958.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1897 q_vals: [-9.898, -8.865, -inf, -15.0, -inf, -15.0, -10.0]
Step 3010 1 visits [16.0, 959.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1898 q_vals: [-9.898, -8.871, -inf, -15.0, -inf, -15.0, -10.0]
Step 3011 1 visits [16.0, 960.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1898 q_vals: [-9.898, -8.862, -inf, -15.0, -inf, -15.0, -10.0]
Step 3012 1 visits [16.0, 961.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1899 q_vals: [-9.898, -8.869, -inf, -15.0, -inf, -15.0, -10.0]
Step 3013 1 visits [16.0, 962.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1901 q_vals: [-9.898, -8.875, -inf, -15.0, -inf, -15.0, -10.0]
Step 3014 1 visits [16.0, 963.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1902 q_vals: [-9.898, -8.866, -inf, -15.0, -inf, -15.0, -10.0]
Step 3015 1 visits [16.0, 964.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1904 q_vals: [-9.898, -8.864, -inf, -15.0, -inf, -15.0, -10.0]
Step 3016 1 visits [16.0, 965.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1904 q_vals: [-9.898, -8.854, -inf, -15.0, -inf, -15.0, -10.0]
Step 3017 1 visits [16.0, 966.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1904 q_vals: [-9.898, -8.861, -inf, -15.0, -inf, -15.0, -10.0]
Step 3018 1 visits [16.0, 967.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1904 q_vals: [-9.898, -8.867, -inf, -15.0, -inf, -15.0, -10.0]
Step 3019 1 visits [16.0, 968.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1904 q_vals: [-9.898, -8.873, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1906, "number_of_timesteps": 202453, "per_episode_reward": -228.5, "episode_reward_trend_value": 0.03525291512872539, "biggest_recent_change": 1.1065718807464293},
Step 3020 1 visits [16.0, 969.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1906 q_vals: [-9.898, -8.875, -inf, -15.0, -inf, -15.0, -10.0]
Step 3021 1 visits [16.0, 970.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1909 q_vals: [-9.898, -8.866, -inf, -15.0, -inf, -15.0, -10.0]
Step 3022 1 visits [16.0, 971.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1910 q_vals: [-9.898, -8.872, -inf, -15.0, -inf, -15.0, -10.0]
Step 3023 1 visits [16.0, 972.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1910 q_vals: [-9.898, -8.863, -inf, -15.0, -inf, -15.0, -10.0]
Step 3024 1 visits [16.0, 973.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1911 q_vals: [-9.898, -8.854, -inf, -15.0, -inf, -15.0, -10.0]
Step 3025 1 visits [16.0, 974.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1911 q_vals: [-9.898, -8.845, -inf, -15.0, -inf, -15.0, -10.0]
Step 3026 1 visits [16.0, 975.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1911 q_vals: [-9.898, -8.851, -inf, -15.0, -inf, -15.0, -10.0]
Step 3027 1 visits [16.0, 976.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1911 q_vals: [-9.898, -8.842, -inf, -15.0, -inf, -15.0, -10.0]
Step 3028 1 visits [16.0, 977.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1911 q_vals: [-9.898, -8.848, -inf, -15.0, -inf, -15.0, -10.0]
Step 3029 1 visits [16.0, 978.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1911 q_vals: [-9.898, -8.855, -inf, -15.0, -inf, -15.0, -10.0]
Step 3030 1 visits [16.0, 979.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1914 q_vals: [-9.898, -8.846, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1916, "number_of_timesteps": 203329, "per_episode_reward": -228.01, "episode_reward_trend_value": 0.05058157486485678, "biggest_recent_change": 1.1065718807464293},
Step 3031 1 visits [16.0, 980.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1916 q_vals: [-9.898, -8.852, -inf, -15.0, -inf, -15.0, -10.0]
Step 3032 1 visits [16.0, 981.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1916 q_vals: [-9.898, -8.857, -inf, -15.0, -inf, -15.0, -10.0]
Step 3033 1 visits [16.0, 982.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1917 q_vals: [-9.898, -8.863, -inf, -15.0, -inf, -15.0, -10.0]
Step 3034 1 visits [16.0, 983.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1917 q_vals: [-9.898, -8.869, -inf, -15.0, -inf, -15.0, -10.0]
Step 3035 1 visits [16.0, 984.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1917 q_vals: [-9.898, -8.876, -inf, -15.0, -inf, -15.0, -10.0]
Step 3036 1 visits [16.0, 985.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1917 q_vals: [-9.898, -8.867, -inf, -15.0, -inf, -15.0, -10.0]
Step 3037 1 visits [16.0, 986.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1917 q_vals: [-9.898, -8.873, -inf, -15.0, -inf, -15.0, -10.0]
Step 3038 1 visits [16.0, 987.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1918 q_vals: [-9.898, -8.879, -inf, -15.0, -inf, -15.0, -10.0]
Step 3039 1 visits [16.0, 988.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1918 q_vals: [-9.898, -8.885, -inf, -15.0, -inf, -15.0, -10.0]
[-9.898, -8.891, -inf, -15.0, -inf, -15.0, -10.0]
Step 3041 1 visits [16.0, 990.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1920 q_vals: [-9.898, -8.882, -inf, -15.0, -inf, -15.0, -10.0]
Step 3042 1 visits [16.0, 991.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1920 q_vals: [-9.898, -8.873, -inf, -15.0, -inf, -15.0, -10.0]
Step 3043 1 visits [16.0, 992.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1921 q_vals: [-9.898, -8.864, -inf, -15.0, -inf, -15.0, -10.0]
Step 3044 1 visits [16.0, 993.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1921 q_vals: [-9.898, -8.855, -inf, -15.0, -inf, -15.0, -10.0]
Step 3045 1 visits [16.0, 994.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1921 q_vals: [-9.898, -8.862, -inf, -15.0, -inf, -15.0, -10.0]
Step 3046 1 visits [16.0, 995.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1922 q_vals: [-9.898, -8.868, -inf, -15.0, -inf, -15.0, -10.0]
Step 3047 1 visits [16.0, 996.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1922 q_vals: [-9.898, -8.859, -inf, -15.0, -inf, -15.0, -10.0]
Step 3048 1 visits [16.0, 997.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1922 q_vals: [-9.898, -8.85, -inf, -15.0, -inf, -15.0, -10.0]
Step 3049 1 visits [16.0, 998.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1922 q_vals: [-9.898, -8.841, -inf, -15.0, -inf, -15.0, -10.0]
Step 3050 1 visits [16.0, 999.0, 1000.0, 1.0, 1000.0, 1.0, 9.0]  episode_count: 1924 q_vals: [-9.898, -8.847, -inf, -15.0, -inf, -15.0, -10.0]
{"total_number_of_episodes": 1926, "number_of_timesteps": 204508, "per_episode_reward": -227.39, "episode_reward_trend_value": 0.051809269277322614, "biggest_recent_change": 1.1065718807464293},
Step 3051 1 visits [0.0, 1000.0, 1000.0, 0.0, 1000.0, 0.0, 0.0]  episode_count: 1926 q_vals: [0.0, -inf, -inf, 0.0, -inf, 0.0, 0.0]
{"total_number_of_episodes": 1936, "number_of_timesteps": 205750, "per_episode_reward": -182.52, "episode_reward_trend_value": 0.5410949251554813, "biggest_recent_change": 44.87044619713933},
{"total_number_of_episodes": 1946, "number_of_timesteps": 206861, "per_episode_reward": -181.91, "episode_reward_trend_value": 0.5512505610841696, "biggest_recent_change": 44.87044619713933},
{"total_number_of_episodes": 1957, "number_of_timesteps": 208240, "per_episode_reward": -181.44, "episode_reward_trend_value": 0.5486527929776571, "biggest_recent_change": 44.87044619713933},
{"total_number_of_episodes": 1967, "number_of_timesteps": 209397, "per_episode_reward": -181.45, "episode_reward_trend_value": 0.5502905064760989, "biggest_recent_change": 44.87044619713933},
{"total_number_of_episodes": 1977, "number_of_timesteps": 210442, "per_episode_reward": -181.22, "episode_reward_trend_value": 0.5405549112783764, "biggest_recent_change": 44.87044619713933},
{"total_number_of_episodes": 1987, "number_of_timesteps": 211770, "per_episode_reward": -181.18, "episode_reward_trend_value": 0.5343202595106138, "biggest_recent_change": 44.87044619713933},
{"total_number_of_episodes": 1998, "number_of_timesteps": 212749, "per_episode_reward": -180.8, "episode_reward_trend_value": 0.5299870019099024, "biggest_recent_change": 44.87044619713933},
{"total_number_of_episodes": 2008, "number_of_timesteps": 213794, "per_episode_reward": -180.37, "episode_reward_trend_value": 0.5293330366003757, "biggest_recent_change": 44.87044619713933},
{"total_number_of_episodes": 2018, "number_of_timesteps": 214830, "per_episode_reward": -179.81, "episode_reward_trend_value": 0.5286557898474077, "biggest_recent_change": 44.87044619713933},
{"total_number_of_episodes": 2028, "number_of_timesteps": 215933, "per_episode_reward": -179.38, "episode_reward_trend_value": 0.03496453415779462, "biggest_recent_change": 0.6110451869278677},
{"total_number_of_episodes": 2038, "number_of_timesteps": 217136, "per_episode_reward": -180.15, "episode_reward_trend_value": 0.019533640711320764, "biggest_recent_change": 0.7777352232547798},
{"total_number_of_episodes": 2048, "number_of_timesteps": 218468, "per_episode_reward": -179.71, "episode_reward_trend_value": 0.019260000420668964, "biggest_recent_change": 0.7777352232547798},
{"total_number_of_episodes": 2059, "number_of_timesteps": 219614, "per_episode_reward": -179.32, "episode_reward_trend_value": 0.023669716528075292, "biggest_recent_change": 0.7777352232547798},
{"total_number_of_episodes": 2069, "number_of_timesteps": 220631, "per_episode_reward": -179.33, "episode_reward_trend_value": 0.021039560918989272, "biggest_recent_change": 0.7777352232547798},
{"total_number_of_episodes": 2080, "number_of_timesteps": 221809, "per_episode_reward": -178.93, "episode_reward_trend_value": 0.024992291256042323, "biggest_recent_change": 0.7777352232547798},
{"total_number_of_episodes": 2090, "number_of_timesteps": 222974, "per_episode_reward": -178.81, "episode_reward_trend_value": 0.02213011521071735, "biggest_recent_change": 0.7777352232547798},
{"total_number_of_episodes": 2100, "number_of_timesteps": 224258, "per_episode_reward": -178.65, "episode_reward_trend_value": 0.01911122554068988, "biggest_recent_change": 0.7777352232547798},
{"total_number_of_episodes": 2110, "number_of_timesteps": 225516, "per_episode_reward": -178.26, "episode_reward_trend_value": 0.017224515572520874, "biggest_recent_change": 0.7777352232547798},
{"total_number_of_episodes": 2120, "number_of_timesteps": 226757, "per_episode_reward": -177.97, "episode_reward_trend_value": 0.01558140852632606, "biggest_recent_change": 0.7777352232547798},
{"total_number_of_episodes": 2130, "number_of_timesteps": 228056, "per_episode_reward": -178.0, "episode_reward_trend_value": 0.023928783458609992, "biggest_recent_change": 0.4455915063738871},
{"total_number_of_episodes": 2140, "number_of_timesteps": 228859, "per_episode_reward": -177.87, "episode_reward_trend_value": 0.020449669770651883, "biggest_recent_change": 0.3981007508569405},
{"total_number_of_episodes": 2151, "number_of_timesteps": 230568, "per_episode_reward": -177.72, "episode_reward_trend_value": 0.017769554859799225, "biggest_recent_change": 0.3981007508569405},
{"total_number_of_episodes": 2161, "number_of_timesteps": 231601, "per_episode_reward": -178.11, "episode_reward_trend_value": 0.01348266545886045, "biggest_recent_change": 0.3981007508569405},
{"total_number_of_episodes": 2171, "number_of_timesteps": 233011, "per_episode_reward": -178.02, "episode_reward_trend_value": 0.01015967073954174, "biggest_recent_change": 0.392165737950819},
{"total_number_of_episodes": 2182, "number_of_timesteps": 234172, "per_episode_reward": -177.75, "episode_reward_trend_value": 0.011801662640582815, "biggest_recent_change": 0.392165737950819},
{"total_number_of_episodes": 2192, "number_of_timesteps": 235103, "per_episode_reward": -177.45, "episode_reward_trend_value": 0.013329248213343525, "biggest_recent_change": 0.392165737950819},
{"total_number_of_episodes": 2202, "number_of_timesteps": 236166, "per_episode_reward": -177.85, "episode_reward_trend_value": 0.0045681422203327, "biggest_recent_change": 0.40219078420480514},
{"total_number_of_episodes": 2212, "number_of_timesteps": 237318, "per_episode_reward": -177.64, "episode_reward_trend_value": 0.0036455999557978833, "biggest_recent_change": 0.40219078420480514},
{"total_number_of_episodes": 2222, "number_of_timesteps": 238411, "per_episode_reward": -178.3, "episode_reward_trend_value": -0.0033452203525203886, "biggest_recent_change": 0.6556453070978705},
{"total_number_of_episodes": 2232, "number_of_timesteps": 239621, "per_episode_reward": -178.49, "episode_reward_trend_value": -0.0069231415213143535, "biggest_recent_change": 0.6556453070978705},
{"total_number_of_episodes": 2242, "number_of_timesteps": 240597, "per_episode_reward": -178.57, "episode_reward_trend_value": -0.009478036894668345, "biggest_recent_change": 0.6556453070978705},

{"total_number_of_episodes": 2252, "number_of_timesteps": 241346, "per_episode_reward": -177.9, "episode_reward_trend_value": 0.002375390010419033, "biggest_recent_change": 0.6746426835070451},
{"total_number_of_episodes": 2262, "number_of_timesteps": 242248, "per_episode_reward": -178.0, "episode_reward_trend_value": 0.000203456643381767, "biggest_recent_change": 0.6746426835070451},
{"total_number_of_episodes": 2272, "number_of_timesteps": 243460, "per_episode_reward": -178.42, "episode_reward_trend_value": -0.00743987357708641, "biggest_recent_change": 0.6746426835070451},
{"total_number_of_episodes": 2282, "number_of_timesteps": 244392, "per_episode_reward": -178.6, "episode_reward_trend_value": -0.012819407302589209, "biggest_recent_change": 0.6746426835070451},
{"total_number_of_episodes": 2293, "number_of_timesteps": 245514, "per_episode_reward": -179.57, "episode_reward_trend_value": -0.019086408122703662, "biggest_recent_change": 0.9662208580151059},
{"total_number_of_episodes": 2303, "number_of_timesteps": 246555, "per_episode_reward": -180.3, "episode_reward_trend_value": -0.02951633186096798, "biggest_recent_change": 0.9662208580151059},
{"total_number_of_episodes": 2313, "number_of_timesteps": 247475, "per_episode_reward": -180.62, "episode_reward_trend_value": -0.025731454756307746, "biggest_recent_change": 0.9662208580151059},
{"total_number_of_episodes": 2323, "number_of_timesteps": 248498, "per_episode_reward": -181.05, "episode_reward_trend_value": -0.02841373980764388, "biggest_recent_change": 0.9662208580151059},
{"total_number_of_episodes": 2334, "number_of_timesteps": 249702, "per_episode_reward": -181.43, "episode_reward_trend_value": -0.03174874454725764, "biggest_recent_change": 0.9662208580151059},
{"total_number_of_episodes": 2345, "number_of_timesteps": 250876, "per_episode_reward": -181.54, "episode_reward_trend_value": -0.04045985984798064, "biggest_recent_change": 0.9662208580151059},
{"total_number_of_episodes": 2356, "number_of_timesteps": 252170, "per_episode_reward": -183.45, "episode_reward_trend_value": -0.06055760235102746, "biggest_recent_change": 1.9052396021893117},
{"total_number_of_episodes": 2366, "number_of_timesteps": 253394, "per_episode_reward": -182.76, "episode_reward_trend_value": -0.04828130451835635, "biggest_recent_change": 1.9052396021893117},
{"total_number_of_episodes": 2376, "number_of_timesteps": 254582, "per_episode_reward": -182.81, "episode_reward_trend_value": -0.0466899513151257, "biggest_recent_change": 1.9052396021893117},
{"total_number_of_episodes": 2386, "number_of_timesteps": 255619, "per_episode_reward": -182.79, "episode_reward_trend_value": -0.035765582448209446, "biggest_recent_change": 1.9052396021893117},
{"total_number_of_episodes": 2396, "number_of_timesteps": 256932, "per_episode_reward": -182.91, "episode_reward_trend_value": -0.02896423439087875, "biggest_recent_change": 1.9052396021893117},
{"total_number_of_episodes": 2406, "number_of_timesteps": 258082, "per_episode_reward": -183.01, "episode_reward_trend_value": -0.02659413987029306, "biggest_recent_change": 1.9052396021893117},
{"total_number_of_episodes": 2416, "number_of_timesteps": 259429, "per_episode_reward": -182.63, "episode_reward_trend_value": -0.01761233840299749, "biggest_recent_change": 1.9052396021893117},
{"total_number_of_episodes": 2427, "number_of_timesteps": 260566, "per_episode_reward": -181.67, "episode_reward_trend_value": -0.0026214958722394813, "biggest_recent_change": 1.9052396021893117},
{"total_number_of_episodes": 2438, "number_of_timesteps": 262000, "per_episode_reward": -181.2, "episode_reward_trend_value": 0.0037673270671847252, "biggest_recent_change": 1.9052396021893117},
{"total_number_of_episodes": 2449, "number_of_timesteps": 263458, "per_episode_reward": -180.88, "episode_reward_trend_value": 0.02852848351358009, "biggest_recent_change": 0.9639392775418116},
{"total_number_of_episodes": 2460, "number_of_timesteps": 264711, "per_episode_reward": -181.27, "episode_reward_trend_value": 0.016572794578835707, "biggest_recent_change": 0.9639392775418116},
{"total_number_of_episodes": 2470, "number_of_timesteps": 265737, "per_episode_reward": -181.65, "episode_reward_trend_value": 0.012886448289335009, "biggest_recent_change": 0.9639392775418116},
{"total_number_of_episodes": 2480, "number_of_timesteps": 266857, "per_episode_reward": -181.13, "episode_reward_trend_value": 0.018439144020840736, "biggest_recent_change": 0.9639392775418116},
{"total_number_of_episodes": 2490, "number_of_timesteps": 267816, "per_episode_reward": -180.83, "episode_reward_trend_value": 0.02314166096974791, "biggest_recent_change": 0.9639392775418116},
{"total_number_of_episodes": 2500, "number_of_timesteps": 268872, "per_episode_reward": -180.04, "episode_reward_trend_value": 0.033016529453367915, "biggest_recent_change": 0.9639392775418116},
{"total_number_of_episodes": 2510, "number_of_timesteps": 269880, "per_episode_reward": -179.58, "episode_reward_trend_value": 0.03388899922380485, "biggest_recent_change": 0.9639392775418116},
{"total_number_of_episodes": 2520, "number_of_timesteps": 270907, "per_episode_reward": -179.18, "episode_reward_trend_value": 0.027630985412025983, "biggest_recent_change": 0.7870403027000634},
{"total_number_of_episodes": 2530, "number_of_timesteps": 272022, "per_episode_reward": -178.23, "episode_reward_trend_value": 0.03299176157092316, "biggest_recent_change": 0.9481062252908998},
{"total_number_of_episodes": 2540, "number_of_timesteps": 273365, "per_episode_reward": -177.79, "episode_reward_trend_value": 0.034271882222759585, "biggest_recent_change": 0.9481062252908998},
{"total_number_of_episodes": 2550, "number_of_timesteps": 274673, "per_episode_reward": -177.6, "episode_reward_trend_value": 0.04076908718311706, "biggest_recent_change": 0.9481062252908998},
{"total_number_of_episodes": 2560, "number_of_timesteps": 276015, "per_episode_reward": -178.01, "episode_reward_trend_value": 0.040372150008383616, "biggest_recent_change": 0.9481062252908998},
{"total_number_of_episodes": 2571, "number_of_timesteps": 277157, "per_episode_reward": -177.47, "episode_reward_trend_value": 0.04064315133343699, "biggest_recent_change": 0.9481062252908998},
{"total_number_of_episodes": 2582, "number_of_timesteps": 278447, "per_episode_reward": -177.3, "episode_reward_trend_value": 0.03913926620596726, "biggest_recent_change": 0.9481062252908998},
{"total_number_of_episodes": 2592, "number_of_timesteps": 279386, "per_episode_reward": -176.74, "episode_reward_trend_value": 0.036640774808875815, "biggest_recent_change": 0.9481062252908998},
{"total_number_of_episodes": 2602, "number_of_timesteps": 280548, "per_episode_reward": -176.79, "episode_reward_trend_value": 0.031030762661834882, "biggest_recent_change": 0.9481062252908998},
{"total_number_of_episodes": 2612, "number_of_timesteps": 281692, "per_episode_reward": -175.86, "episode_reward_trend_value": 0.036857842504737295, "biggest_recent_change": 0.9481062252908998},
{"total_number_of_episodes": 2622, "number_of_timesteps": 282728, "per_episode_reward": -175.42, "episode_reward_trend_value": 0.031205852097416043, "biggest_recent_change": 0.9251552203429299},
{"total_number_of_episodes": 2632, "number_of_timesteps": 283701, "per_episode_reward": -175.19, "episode_reward_trend_value": 0.02890163912082768, "biggest_recent_change": 0.9251552203429299},
{"total_number_of_episodes": 2642, "number_of_timesteps": 284927, "per_episode_reward": -175.31, "episode_reward_trend_value": 0.025448978235634613, "biggest_recent_change": 0.9251552203429299},
{"total_number_of_episodes": 2652, "number_of_timesteps": 286072, "per_episode_reward": -175.31, "episode_reward_trend_value": 0.030026798872327416, "biggest_recent_change": 0.9251552203429299},
{"total_number_of_episodes": 2662, "number_of_timesteps": 287372, "per_episode_reward": -175.03, "episode_reward_trend_value": 0.027150320114242593, "biggest_recent_change": 0.9251552203429299},
{"total_number_of_episodes": 2672, "number_of_timesteps": 288281, "per_episode_reward": -174.65, "episode_reward_trend_value": 0.02951324347935756, "biggest_recent_change": 0.9251552203429299},
{"total_number_of_episodes": 2682, "number_of_timesteps": 289117, "per_episode_reward": -174.2, "episode_reward_trend_value": 0.028202962499225097, "biggest_recent_change": 0.9251552203429299},
{"total_number_of_episodes": 2692, "number_of_timesteps": 289897, "per_episode_reward": -173.81, "episode_reward_trend_value": 0.03304981503946906, "biggest_recent_change": 0.9251552203429299},
{"total_number_of_episodes": 2703, "number_of_timesteps": 291161, "per_episode_reward": -173.59, "episode_reward_trend_value": 0.025224506539189267, "biggest_recent_change": 0.44425078874991186},
{"total_number_of_episodes": 2713, "number_of_timesteps": 292583, "per_episode_reward": -173.61, "episode_reward_trend_value": 0.02016837644289511, "biggest_recent_change": 0.44425078874991186},
{"total_number_of_episodes": 2723, "number_of_timesteps": 294226, "per_episode_reward": -173.59, "episode_reward_trend_value": 0.017818579783241896, "biggest_recent_change": 0.44425078874991186},
{"total_number_of_episodes": 2734, "number_of_timesteps": 295154, "per_episode_reward": -173.03, "episode_reward_trend_value": 0.025376328685304216, "biggest_recent_change": 0.5639838373400323},
{"total_number_of_episodes": 2744, "number_of_timesteps": 296178, "per_episode_reward": -172.06, "episode_reward_trend_value": 0.03611996098146019, "biggest_recent_change": 0.966926906654038},
{"total_number_of_episodes": 2754, "number_of_timesteps": 297697, "per_episode_reward": -172.09, "episode_reward_trend_value": 0.03263810168808479, "biggest_recent_change": 0.966926906654038},
{"total_number_of_episodes": 2764, "number_of_timesteps": 298789, "per_episode_reward": -172.07, "episode_reward_trend_value": 0.02860515696583516, "biggest_recent_change": 0.966926906654038},
{"total_number_of_episodes": 2774, "number_of_timesteps": 299967, "per_episode_reward": -171.75, "episode_reward_trend_value": 0.027210367143021268, "biggest_recent_change": 0.966926906654038},
{"total_number_of_episodes": 2785, "number_of_timesteps": 301256, "per_episode_reward": -171.11, "episode_reward_trend_value": 0.03005689473955076, "biggest_recent_change": 0.966926906654038},
{"total_number_of_episodes": 2795, "number_of_timesteps": 302777, "per_episode_reward": -171.35, "episode_reward_trend_value": 0.02493434609283472, "biggest_recent_change": 0.966926906654038},
{"total_number_of_episodes": 2805, "number_of_timesteps": 304265, "per_episode_reward": -171.19, "episode_reward_trend_value": 0.026831603170825565, "biggest_recent_change": 0.966926906654038},
{"total_number_of_episodes": 2815, "number_of_timesteps": 305893, "per_episode_reward": -171.17, "episode_reward_trend_value": 0.026881761850869323, "biggest_recent_change": 0.966926906654038},
{"total_number_of_episodes": 2825, "number_of_timesteps": 306930, "per_episode_reward": -170.8, "episode_reward_trend_value": 0.02470199171258495, "biggest_recent_change": 0.966926906654038},
{"total_number_of_episodes": 2836, "number_of_timesteps": 308323, "per_episode_reward": -171.04, "episode_reward_trend_value": 0.011345223503079182, "biggest_recent_change": 0.6434402451178016},
{"total_number_of_episodes": 2846, "number_of_timesteps": 309515, "per_episode_reward": -170.64, "episode_reward_trend_value": 0.016119744500898984, "biggest_recent_change": 0.6434402451178016},
{"total_number_of_episodes": 2857, "number_of_timesteps": 310767, "per_episode_reward": -170.51, "episode_reward_trend_value": 0.017352814056141596, "biggest_recent_change": 0.6434402451178016},
{"total_number_of_episodes": 2867, "number_of_timesteps": 311811, "per_episode_reward": -168.69, "episode_reward_trend_value": 0.03407450225408897, "biggest_recent_change": 1.8236716425119255},
{"total_number_of_episodes": 2877, "number_of_timesteps": 312622, "per_episode_reward": -168.35, "episode_reward_trend_value": 0.030682198736510853, "biggest_recent_change": 1.8236716425119255},
{"total_number_of_episodes": 2887, "number_of_timesteps": 313832, "per_episode_reward": -168.55, "episode_reward_trend_value": 0.031074429758286393, "biggest_recent_change": 1.8236716425119255},
{"total_number_of_episodes": 2897, "number_of_timesteps": 315333, "per_episode_reward": -169.22, "episode_reward_trend_value": 0.021906951763617462, "biggest_recent_change": 1.8236716425119255},
{"total_number_of_episodes": 2907, "number_of_timesteps": 316880, "per_episode_reward": -168.93, "episode_reward_trend_value": 0.02484272302200168, "biggest_recent_change": 1.8236716425119255},
{"total_number_of_episodes": 2917, "number_of_timesteps": 317958, "per_episode_reward": -168.5, "episode_reward_trend_value": 0.02561097610468342, "biggest_recent_change": 1.8236716425119255},
{"total_number_of_episodes": 2927, "number_of_timesteps": 318733, "per_episode_reward": -168.38, "episode_reward_trend_value": 0.029550833534452182, "biggest_recent_change": 1.8236716425119255},
{"total_number_of_episodes": 2937, "number_of_timesteps": 319608, "per_episode_reward": -167.94, "episode_reward_trend_value": 0.029992222005962, "biggest_recent_change": 1.8236716425119255},
{"total_number_of_episodes": 2948, "number_of_timesteps": 320835, "per_episode_reward": -168.18, "episode_reward_trend_value": 0.02588343396540217, "biggest_recent_change": 1.8236716425119255},
{"total_number_of_episodes": 2958, "number_of_timesteps": 321917, "per_episode_reward": -167.86, "episode_reward_trend_value": 0.009222263179866432, "biggest_recent_change": 0.6699445025355146},
{"total_number_of_episodes": 2968, "number_of_timesteps": 322899, "per_episode_reward": -167.47, "episode_reward_trend_value": 0.009762153547705705, "biggest_recent_change": 0.6699445025355146},
{"total_number_of_episodes": 2978, "number_of_timesteps": 323913, "per_episode_reward": -167.37, "episode_reward_trend_value": 0.013190542907068448, "biggest_recent_change": 0.6699445025355146},
{"total_number_of_episodes": 2989, "number_of_timesteps": 325271, "per_episode_reward": -167.11, "episode_reward_trend_value": 0.023523950223768804, "biggest_recent_change": 0.43828650270592107},
{"total_number_of_episodes": 2999, "number_of_timesteps": 326153, "per_episode_reward": -165.55, "episode_reward_trend_value": 0.03762464056004641, "biggest_recent_change": 1.5574102941133106},
{"total_number_of_episodes": 3009, "number_of_timesteps": 326999, "per_episode_reward": -165.63, "episode_reward_trend_value": 0.03190655059889498, "biggest_recent_change": 1.5574102941133106},
{"total_number_of_episodes": 3019, "number_of_timesteps": 328228, "per_episode_reward": -165.12, "episode_reward_trend_value": 0.03616281976747157, "biggest_recent_change": 1.5574102941133106},
{"total_number_of_episodes": 3029, "number_of_timesteps": 329516, "per_episode_reward": -164.41, "episode_reward_trend_value": 0.03923328294461455, "biggest_recent_change": 1.5574102941133106},
{"total_number_of_episodes": 3039, "number_of_timesteps": 330576, "per_episode_reward": -164.71, "episode_reward_trend_value": 0.03859525094346957, "biggest_recent_change": 1.5574102941133106},
{"total_number_of_episodes": 3049, "number_of_timesteps": 331590, "per_episode_reward": -164.59, "episode_reward_trend_value": 0.03628581581375556, "biggest_recent_change": 1.5574102941133106},
{"total_number_of_episodes": 3059, "number_of_timesteps": 332506, "per_episode_reward": -163.8, "episode_reward_trend_value": 0.0407220395203748, "biggest_recent_change": 1.5574102941133106},
{"total_number_of_episodes": 3069, "number_of_timesteps": 333874, "per_episode_reward": -164.82, "episode_reward_trend_value": 0.02831179126705447, "biggest_recent_change": 1.5574102941133106},
{"total_number_of_episodes": 3079, "number_of_timesteps": 335338, "per_episode_reward": -164.85, "episode_reward_trend_value": 0.02505384132681867, "biggest_recent_change": 1.5574102941133106},
{"total_number_of_episodes": 3090, "number_of_timesteps": 336507, "per_episode_reward": -164.66, "episode_reward_trend_value": 0.009875258261454672, "biggest_recent_change": 1.0132184313830805},
{"total_number_of_episodes": 3100, "number_of_timesteps": 337514, "per_episode_reward": -164.04, "episode_reward_trend_value": 0.017634185420223502, "biggest_recent_change": 1.0132184313830805},
{"total_number_of_episodes": 3110, "number_of_timesteps": 338524, "per_episode_reward": -163.92, "episode_reward_trend_value": 0.013386270442705317, "biggest_recent_change": 1.0132184313830805},
{"total_number_of_episodes": 3120, "number_of_timesteps": 339604, "per_episode_reward": -163.25, "episode_reward_trend_value": 0.01292709052254079, "biggest_recent_change": 1.0132184313830805},
{"total_number_of_episodes": 3131, "number_of_timesteps": 340639, "per_episode_reward": -163.06, "episode_reward_trend_value": 0.018336369454217384, "biggest_recent_change": 1.0132184313830805},
{"total_number_of_episodes": 3141, "number_of_timesteps": 341794, "per_episode_reward": -162.9, "episode_reward_trend_value": 0.01875841479416983, "biggest_recent_change": 1.0132184313830805},
{"total_number_of_episodes": 3152, "number_of_timesteps": 343126, "per_episode_reward": -162.8, "episode_reward_trend_value": 0.01114966909839173, "biggest_recent_change": 1.0132184313830805},
{"total_number_of_episodes": 3162, "number_of_timesteps": 344371, "per_episode_reward": -162.76, "episode_reward_trend_value": 0.022856833688297544, "biggest_recent_change": 0.673301995833981},
{"total_number_of_episodes": 3173, "number_of_timesteps": 345818, "per_episode_reward": -162.73, "episode_reward_trend_value": 0.023561765116026045, "biggest_recent_change": 0.673301995833981},
{"total_number_of_episodes": 3183, "number_of_timesteps": 346712, "per_episode_reward": -162.52, "episode_reward_trend_value": 0.023752536082253074, "biggest_recent_change": 0.673301995833981},
{"total_number_of_episodes": 3193, "number_of_timesteps": 347577, "per_episode_reward": -162.06, "episode_reward_trend_value": 0.021991415462271548, "biggest_recent_change": 0.673301995833981},
{"total_number_of_episodes": 3203, "number_of_timesteps": 348757, "per_episode_reward": -162.2, "episode_reward_trend_value": 0.019120679335883198, "biggest_recent_change": 0.673301995833981},
{"total_number_of_episodes": 3214, "number_of_timesteps": 350379, "per_episode_reward": -162.04, "episode_reward_trend_value": 0.013346010125522095, "biggest_recent_change": 0.4621217943230249},
{"total_number_of_episodes": 3224, "number_of_timesteps": 351762, "per_episode_reward": -162.05, "episode_reward_trend_value": 0.011229105493511169, "biggest_recent_change": 0.4621217943230249},
{"total_number_of_episodes": 3234, "number_of_timesteps": 353363, "per_episode_reward": -162.17, "episode_reward_trend_value": 0.008168425369619727, "biggest_recent_change": 0.4621217943230249},
{"total_number_of_episodes": 3244, "number_of_timesteps": 354476, "per_episode_reward": -162.18, "episode_reward_trend_value": 0.006909862653447856, "biggest_recent_change": 0.4621217943230249},
{"total_number_of_episodes": 3254, "number_of_timesteps": 355673, "per_episode_reward": -162.3, "episode_reward_trend_value": 0.005074544608752439, "biggest_recent_change": 0.4621217943230249},
{"total_number_of_episodes": 3265, "number_of_timesteps": 357209, "per_episode_reward": -162.21, "episode_reward_trend_value": 0.005740085818637731, "biggest_recent_change": 0.4621217943230249},
{"total_number_of_episodes": 3275, "number_of_timesteps": 358390, "per_episode_reward": -162.01, "episode_reward_trend_value": 0.00565331963133057, "biggest_recent_change": 0.4621217943230249},
{"total_number_of_episodes": 3285, "number_of_timesteps": 359394, "per_episode_reward": -161.73, "episode_reward_trend_value": 0.003689884315200073, "biggest_recent_change": 0.2854126158712802},
{"total_number_of_episodes": 3295, "number_of_timesteps": 360430, "per_episode_reward": -161.7, "episode_reward_trend_value": 0.005522889241992681, "biggest_recent_change": 0.2854126158712802},
{"total_number_of_episodes": 3305, "number_of_timesteps": 362103, "per_episode_reward": -161.8, "episode_reward_trend_value": 0.00267324589968641, "biggest_recent_change": 0.2854126158712802},
{"total_number_of_episodes": 3315, "number_of_timesteps": 363543, "per_episode_reward": -161.81, "episode_reward_trend_value": 0.0026373730910535186, "biggest_recent_change": 0.2854126158712802},
{"total_number_of_episodes": 3325, "number_of_timesteps": 364616, "per_episode_reward": -161.78, "episode_reward_trend_value": 0.004323304922177032, "biggest_recent_change": 0.2854126158712802},
{"total_number_of_episodes": 3336, "number_of_timesteps": 366119, "per_episode_reward": -161.49, "episode_reward_trend_value": 0.007670466408763508, "biggest_recent_change": 0.2891699719543226},
{"total_number_of_episodes": 3347, "number_of_timesteps": 367219, "per_episode_reward": -161.03, "episode_reward_trend_value": 0.014199268891227097, "biggest_recent_change": 0.46283998110757807},
{"total_number_of_episodes": 3357, "number_of_timesteps": 368973, "per_episode_reward": -160.99, "episode_reward_trend_value": 0.013622790160890316, "biggest_recent_change": 0.46283998110757807},
{"total_number_of_episodes": 3367, "number_of_timesteps": 370039, "per_episode_reward": -160.84, "episode_reward_trend_value": 0.01305511607637426, "biggest_recent_change": 0.46283998110757807},
{"total_number_of_episodes": 3378, "number_of_timesteps": 371720, "per_episode_reward": -159.87, "episode_reward_trend_value": 0.020689880127567208, "biggest_recent_change": 0.9725413804786456},
{"total_number_of_episodes": 3388, "number_of_timesteps": 372583, "per_episode_reward": -159.35, "episode_reward_trend_value": 0.026165682302792627, "biggest_recent_change": 0.9725413804786456},
{"total_number_of_episodes": 3399, "number_of_timesteps": 373529, "per_episode_reward": -158.72, "episode_reward_trend_value": 0.0343099064805459, "biggest_recent_change": 0.9725413804786456},
{"total_number_of_episodes": 3409, "number_of_timesteps": 374486, "per_episode_reward": -158.81, "episode_reward_trend_value": 0.03336237750834307, "biggest_recent_change": 0.9725413804786456},
{"total_number_of_episodes": 3419, "number_of_timesteps": 375805, "per_episode_reward": -158.65, "episode_reward_trend_value": 0.034734047710638705, "biggest_recent_change": 0.9725413804786456},
{"total_number_of_episodes": 3429, "number_of_timesteps": 377156, "per_episode_reward": -158.51, "episode_reward_trend_value": 0.03314397424383849, "biggest_recent_change": 0.9725413804786456},
{"total_number_of_episodes": 3439, "number_of_timesteps": 378281, "per_episode_reward": -158.57, "episode_reward_trend_value": 0.027246533548881124, "biggest_recent_change": 0.9725413804786456},
{"total_number_of_episodes": 3449, "number_of_timesteps": 379479, "per_episode_reward": -158.62, "episode_reward_trend_value": 0.026324258781026955, "biggest_recent_change": 0.9725413804786456},
{"total_number_of_episodes": 3459, "number_of_timesteps": 380721, "per_episode_reward": -158.76, "episode_reward_trend_value": 0.023142502359837003, "biggest_recent_change": 0.9725413804786456},
{"total_number_of_episodes": 3469, "number_of_timesteps": 381794, "per_episode_reward": -158.54, "episode_reward_trend_value": 0.014768857971558682, "biggest_recent_change": 0.6300940420917129},
{"total_number_of_episodes": 3479, "number_of_timesteps": 382706, "per_episode_reward": -158.57, "episode_reward_trend_value": 0.008654220383649797, "biggest_recent_change": 0.6300940420917129},
{"total_number_of_episodes": 3489, "number_of_timesteps": 384190, "per_episode_reward": -158.6, "episode_reward_trend_value": 0.001271043986597912, "biggest_recent_change": 0.21891338553359674},
{"total_number_of_episodes": 3499, "number_of_timesteps": 385679, "per_episode_reward": -158.52, "episode_reward_trend_value": 0.0031779751173268605, "biggest_recent_change": 0.21891338553359674},
{"total_number_of_episodes": 3509, "number_of_timesteps": 387039, "per_episode_reward": -158.57, "episode_reward_trend_value": 0.0009303931484270025, "biggest_recent_change": 0.21891338553359674},
{"total_number_of_episodes": 3520, "number_of_timesteps": 388045, "per_episode_reward": -158.31, "episode_reward_trend_value": 0.002177534369335869, "biggest_recent_change": 0.2583060698241013},
{"total_number_of_episodes": 3530, "number_of_timesteps": 389191, "per_episode_reward": -158.3, "episode_reward_trend_value": 0.0030105974796798465, "biggest_recent_change": 0.2583060698241013},
{"total_number_of_episodes": 3541, "number_of_timesteps": 390629, "per_episode_reward": -158.45, "episode_reward_trend_value": 0.0018997883020944073, "biggest_recent_change": 0.2583060698241013},
{"total_number_of_episodes": 3551, "number_of_timesteps": 391857, "per_episode_reward": -159.1, "episode_reward_trend_value": -0.003772999303373581, "biggest_recent_change": 0.647301381672321},
{"total_number_of_episodes": 3561, "number_of_timesteps": 392850, "per_episode_reward": -158.49, "episode_reward_trend_value": 0.0005494252662843893, "biggest_recent_change": 0.647301381672321},
{"total_number_of_episodes": 3571, "number_of_timesteps": 393778, "per_episode_reward": -158.38, "episode_reward_trend_value": 0.002056938030555797, "biggest_recent_change": 0.647301381672321},
{"total_number_of_episodes": 3581, "number_of_timesteps": 395304, "per_episode_reward": -158.59, "episode_reward_trend_value": 0.00013535060591133669, "biggest_recent_change": 0.647301381672321},
{"total_number_of_episodes": 3591, "number_of_timesteps": 396647, "per_episode_reward": -158.56, "episode_reward_trend_value": -0.00041532038161354496, "biggest_recent_change": 0.647301381672321},
{"total_number_of_episodes": 3601, "number_of_timesteps": 397883, "per_episode_reward": -158.26, "episode_reward_trend_value": 0.0033782273522837787, "biggest_recent_change": 0.647301381672321},
{"total_number_of_episodes": 3611, "number_of_timesteps": 399178, "per_episode_reward": -158.2, "episode_reward_trend_value": 0.0011811043701543313, "biggest_recent_change": 0.647301381672321},
{"total_number_of_episodes": 3621, "number_of_timesteps": 400474, "per_episode_reward": -158.11, "episode_reward_trend_value": 0.002092803326348442, "biggest_recent_change": 0.647301381672321},
{"total_number_of_episodes": 3631, "number_of_timesteps": 401456, "per_episode_reward": -158.01, "episode_reward_trend_value": 0.0048248980171226525, "biggest_recent_change": 0.647301381672321},
{"total_number_of_episodes": 3642, "number_of_timesteps": 402357, "per_episode_reward": -157.53, "episode_reward_trend_value": 0.017426367922106716, "biggest_recent_change": 0.6079315968028141},
{"total_number_of_episodes": 3653, "number_of_timesteps": 403417, "per_episode_reward": -156.98, "episode_reward_trend_value": 0.016735444960515464, "biggest_recent_change": 0.5457485302596012},
{"total_number_of_episodes": 3663, "number_of_timesteps": 404832, "per_episode_reward": -157.11, "episode_reward_trend_value": 0.01415225092678093, "biggest_recent_change": 0.5457485302596012},
{"total_number_of_episodes": 3674, "number_of_timesteps": 405773, "per_episode_reward": -156.83, "episode_reward_trend_value": 0.01950491185564481, "biggest_recent_change": 0.5457485302596012},
{"total_number_of_episodes": 3684, "number_of_timesteps": 406568, "per_episode_reward": -156.71, "episode_reward_trend_value": 0.020504663034389144, "biggest_recent_change": 0.5457485302596012},
{"total_number_of_episodes": 3694, "number_of_timesteps": 407798, "per_episode_reward": -156.64, "episode_reward_trend_value": 0.018013695248623347, "biggest_recent_change": 0.5457485302596012},
{"total_number_of_episodes": 3704, "number_of_timesteps": 409073, "per_episode_reward": -156.7, "episode_reward_trend_value": 0.016661540111981153, "biggest_recent_change": 0.5457485302596012},
{"total_number_of_episodes": 3714, "number_of_timesteps": 410035, "per_episode_reward": -156.56, "episode_reward_trend_value": 0.017296372410667813, "biggest_recent_change": 0.5457485302596012},
{"total_number_of_episodes": 3724, "number_of_timesteps": 411557, "per_episode_reward": -156.89, "episode_reward_trend_value": 0.012456678489212437, "biggest_recent_change": 0.5457485302596012},
{"total_number_of_episodes": 3734, "number_of_timesteps": 413081, "per_episode_reward": -156.67, "episode_reward_trend_value": 0.009473527244650073, "biggest_recent_change": 0.5457485302596012},
{"total_number_of_episodes": 3744, "number_of_timesteps": 414079, "per_episode_reward": -156.44, "episode_reward_trend_value": 0.006037785897432792, "biggest_recent_change": 0.3343553728496431},
{"total_number_of_episodes": 3754, "number_of_timesteps": 415245, "per_episode_reward": -156.7, "episode_reward_trend_value": 0.00449907218957656, "biggest_recent_change": 0.3343553728496431},

{"total_number_of_episodes": 3764, "number_of_timesteps": 416387, "per_episode_reward": -156.32, "episode_reward_trend_value": 0.005764661895384885, "biggest_recent_change": 0.3883078552595407},
{"total_number_of_episodes": 3775, "number_of_timesteps": 417503, "per_episode_reward": -156.38, "episode_reward_trend_value": 0.0037226030738183786, "biggest_recent_change": 0.3883078552595407},
{"total_number_of_episodes": 3785, "number_of_timesteps": 419028, "per_episode_reward": -157.02, "episode_reward_trend_value": -0.004145152836904092, "biggest_recent_change": 0.6391240512415095},
{"total_number_of_episodes": 3795, "number_of_timesteps": 420234, "per_episode_reward": -157.05, "episode_reward_trend_value": -0.003833923346101958, "biggest_recent_change": 0.6391240512415095},
{"total_number_of_episodes": 3805, "number_of_timesteps": 421478, "per_episode_reward": -157.18, "episode_reward_trend_value": -0.006891131624591177, "biggest_recent_change": 0.6391240512415095},
{"total_number_of_episodes": 3815, "number_of_timesteps": 422516, "per_episode_reward": -156.95, "episode_reward_trend_value": -0.0006311374892902677, "biggest_recent_change": 0.6391240512415095},
{"total_number_of_episodes": 3825, "number_of_timesteps": 423674, "per_episode_reward": -157.04, "episode_reward_trend_value": -0.004010065090185182, "biggest_recent_change": 0.6391240512415095},
{"total_number_of_episodes": 3837, "number_of_timesteps": 424897, "per_episode_reward": -157.02, "episode_reward_trend_value": -0.006464186967573306, "biggest_recent_change": 0.6391240512415095},
{"total_number_of_episodes": 3847, "number_of_timesteps": 425576, "per_episode_reward": -156.8, "episode_reward_trend_value": -0.0010331798843196793, "biggest_recent_change": 0.6391240512415095},
{"total_number_of_episodes": 3858, "number_of_timesteps": 426545, "per_episode_reward": -156.61, "episode_reward_trend_value": -0.0033221380853288135, "biggest_recent_change": 0.6391240512415095},
{"total_number_of_episodes": 3868, "number_of_timesteps": 427491, "per_episode_reward": -156.55, "episode_reward_trend_value": -0.0019248549171483847, "biggest_recent_change": 0.6391240512415095},
{"total_number_of_episodes": 3878, "number_of_timesteps": 428653, "per_episode_reward": -156.61, "episode_reward_trend_value": 0.004504435261538712, "biggest_recent_change": 0.22904409932743874},
{"total_number_of_episodes": 3888, "number_of_timesteps": 429966, "per_episode_reward": -156.46, "episode_reward_trend_value": 0.006578978972425237, "biggest_recent_change": 0.22904409932743874},
{"total_number_of_episodes": 3898, "number_of_timesteps": 431211, "per_episode_reward": -156.41, "episode_reward_trend_value": 0.008495080523614244, "biggest_recent_change": 0.22904409932743874},
{"total_number_of_episodes": 3909, "number_of_timesteps": 432356, "per_episode_reward": -156.41, "episode_reward_trend_value": 0.006023758286651552, "biggest_recent_change": 0.22276090810191818},
{"total_number_of_episodes": 3919, "number_of_timesteps": 433441, "per_episode_reward": -156.23, "episode_reward_trend_value": 0.008997051377089822, "biggest_recent_change": 0.22276090810191818},
{"total_number_of_episodes": 3929, "number_of_timesteps": 434485, "per_episode_reward": -156.18, "episode_reward_trend_value": 0.009379042169373658, "biggest_recent_change": 0.22276090810191818},
{"total_number_of_episodes": 3939, "number_of_timesteps": 435738, "per_episode_reward": -156.2, "episode_reward_trend_value": 0.006617024956370995, "biggest_recent_change": 0.18230161716871862},
{"total_number_of_episodes": 3950, "number_of_timesteps": 437195, "per_episode_reward": -156.39, "episode_reward_trend_value": 0.0024452818896779464, "biggest_recent_change": 0.1931552588336558},
{"total_number_of_episodes": 3960, "number_of_timesteps": 438149, "per_episode_reward": -156.19, "episode_reward_trend_value": 0.004034346201233853, "biggest_recent_change": 0.20692485873544797},
{"total_number_of_episodes": 3970, "number_of_timesteps": 439322, "per_episode_reward": -156.36, "episode_reward_trend_value": 0.0027505921621067526, "biggest_recent_change": 0.20692485873544797},
{"total_number_of_episodes": 3980, "number_of_timesteps": 440372, "per_episode_reward": -156.03, "episode_reward_trend_value": 0.00473646333873003, "biggest_recent_change": 0.3323190331827277},
{"total_number_of_episodes": 3990, "number_of_timesteps": 441173, "per_episode_reward": -155.58, "episode_reward_trend_value": 0.00929787117800313, "biggest_recent_change": 0.45406091150920247},
{"total_number_of_episodes": 4000, "number_of_timesteps": 442170, "per_episode_reward": -155.4, "episode_reward_trend_value": 0.011157681106455344, "biggest_recent_change": 0.45406091150920247},
{"total_number_of_episodes": 4013, "number_of_timesteps": 443741, "per_episode_reward": -155.46, "episode_reward_trend_value": 0.008464298565470409, "biggest_recent_change": 0.45406091150920247},
{"total_number_of_episodes": 4023, "number_of_timesteps": 444688, "per_episode_reward": -155.37, "episode_reward_trend_value": 0.008995950252315765, "biggest_recent_change": 0.45406091150920247},
{"total_number_of_episodes": 4033, "number_of_timesteps": 445728, "per_episode_reward": -155.37, "episode_reward_trend_value": 0.009272801979884724, "biggest_recent_change": 0.45406091150920247},
{"total_number_of_episodes": 4043, "number_of_timesteps": 446605, "per_episode_reward": -154.86, "episode_reward_trend_value": 0.017084464658519018, "biggest_recent_change": 0.5098943822434308},
{"total_number_of_episodes": 4054, "number_of_timesteps": 447642, "per_episode_reward": -154.8, "episode_reward_trend_value": 0.015450991750802246, "biggest_recent_change": 0.5098943822434308},
{"total_number_of_episodes": 4064, "number_of_timesteps": 448749, "per_episode_reward": -154.69, "episode_reward_trend_value": 0.018572478247303868, "biggest_recent_change": 0.5098943822434308},
{"total_number_of_episodes": 4074, "number_of_timesteps": 449844, "per_episode_reward": -154.69, "episode_reward_trend_value": 0.014945834149596887, "biggest_recent_change": 0.5098943822434308},
{"total_number_of_episodes": 4084, "number_of_timesteps": 451061, "per_episode_reward": -154.51, "episode_reward_trend_value": 0.011877690916816796, "biggest_recent_change": 0.5098943822434308},
{"total_number_of_episodes": 4094, "number_of_timesteps": 452215, "per_episode_reward": -154.37, "episode_reward_trend_value": 0.011512525792236755, "biggest_recent_change": 0.5098943822434308},
{"total_number_of_episodes": 4104, "number_of_timesteps": 453116, "per_episode_reward": -154.04, "episode_reward_trend_value": 0.01584281545509422, "biggest_recent_change": 0.5098943822434308},
{"total_number_of_episodes": 4114, "number_of_timesteps": 454101, "per_episode_reward": -153.72, "episode_reward_trend_value": 0.01826703681596579, "biggest_recent_change": 0.5098943822434308},
{"total_number_of_episodes": 4125, "number_of_timesteps": 455025, "per_episode_reward": -153.38, "episode_reward_trend_value": 0.022101581405056928, "biggest_recent_change": 0.5098943822434308},
{"total_number_of_episodes": 4135, "number_of_timesteps": 455987, "per_episode_reward": -153.08, "episode_reward_trend_value": 0.019753230282198806, "biggest_recent_change": 0.3442050274310873},
{"total_number_of_episodes": 4146, "number_of_timesteps": 458105, "per_episode_reward": -153.22, "episode_reward_trend_value": 0.017519604996017315, "biggest_recent_change": 0.3442050274310873},
{"total_number_of_episodes": 4157, "number_of_timesteps": 459348, "per_episode_reward": -152.83, "episode_reward_trend_value": 0.020663579591523117, "biggest_recent_change": 0.3878656995995584},
{"total_number_of_episodes": 4167, "number_of_timesteps": 460327, "per_episode_reward": -152.27, "episode_reward_trend_value": 0.026807360269919894, "biggest_recent_change": 0.5588613254448092},
{"total_number_of_episodes": 4177, "number_of_timesteps": 461532, "per_episode_reward": -151.83, "episode_reward_trend_value": 0.029709979184571644, "biggest_recent_change": 0.5588613254448092},
{"total_number_of_episodes": 4187, "number_of_timesteps": 462540, "per_episode_reward": -152.01, "episode_reward_trend_value": 0.02614528391763334, "biggest_recent_change": 0.5588613254448092},
{"total_number_of_episodes": 4197, "number_of_timesteps": 463366, "per_episode_reward": -151.78, "episode_reward_trend_value": 0.02506638688014833, "biggest_recent_change": 0.5588613254448092},
{"total_number_of_episodes": 4209, "number_of_timesteps": 464758, "per_episode_reward": -151.99, "episode_reward_trend_value": 0.019271256652371626, "biggest_recent_change": 0.5588613254448092},
{"total_number_of_episodes": 4219, "number_of_timesteps": 466072, "per_episode_reward": -151.82, "episode_reward_trend_value": 0.01732144823705697, "biggest_recent_change": 0.5588613254448092},
{"total_number_of_episodes": 4229, "number_of_timesteps": 467150, "per_episode_reward": -151.89, "episode_reward_trend_value": 0.013242487706796802, "biggest_recent_change": 0.5588613254448092},
{"total_number_of_episodes": 4239, "number_of_timesteps": 468570, "per_episode_reward": -151.93, "episode_reward_trend_value": 0.014285912715627408, "biggest_recent_change": 0.5588613254448092},
{"total_number_of_episodes": 4249, "number_of_timesteps": 469650, "per_episode_reward": -151.64, "episode_reward_trend_value": 0.013226113137061665, "biggest_recent_change": 0.5588613254448092},
{"total_number_of_episodes": 4259, "number_of_timesteps": 470492, "per_episode_reward": -151.58, "episode_reward_trend_value": 0.007738006887510728, "biggest_recent_change": 0.4391637228776517},
{"total_number_of_episodes": 4270, "number_of_timesteps": 471702, "per_episode_reward": -151.77, "episode_reward_trend_value": 0.0007043082079289004, "biggest_recent_change": 0.29248373752864154},
{"total_number_of_episodes": 4281, "number_of_timesteps": 473154, "per_episode_reward": -152.12, "episode_reward_trend_value": -0.0011811450568968793, "biggest_recent_change": 0.3493702375094756},
{"total_number_of_episodes": 4291, "number_of_timesteps": 474403, "per_episode_reward": -152.23, "episode_reward_trend_value": -0.004950421847053753, "biggest_recent_change": 0.3493702375094756},
{"total_number_of_episodes": 4301, "number_of_timesteps": 475359, "per_episode_reward": -152.02, "episode_reward_trend_value": -0.0003415316790778888, "biggest_recent_change": 0.3493702375094756},
{"total_number_of_episodes": 4311, "number_of_timesteps": 476357, "per_episode_reward": -151.64, "episode_reward_trend_value": 0.001984953504419688, "biggest_recent_change": 0.3781059365675503},
{"total_number_of_episodes": 4321, "number_of_timesteps": 477517, "per_episode_reward": -151.2, "episode_reward_trend_value": 0.007647557638512442, "biggest_recent_change": 0.44107070553113203},
{"total_number_of_episodes": 4331, "number_of_timesteps": 478471, "per_episode_reward": -151.22, "episode_reward_trend_value": 0.007900013212949692, "biggest_recent_change": 0.44107070553113203},
{"total_number_of_episodes": 4341, "number_of_timesteps": 479592, "per_episode_reward": -151.25, "episode_reward_trend_value": 0.00433331573354931, "biggest_recent_change": 0.44107070553113203},
{"total_number_of_episodes": 4351, "number_of_timesteps": 480757, "per_episode_reward": -151.16, "episode_reward_trend_value": 0.004664148373068934, "biggest_recent_change": 0.44107070553113203},
{"total_number_of_episodes": 4361, "number_of_timesteps": 481876, "per_episode_reward": -150.89, "episode_reward_trend_value": 0.009828803263239176, "biggest_recent_change": 0.44107070553113203},
{"total_number_of_episodes": 4371, "number_of_timesteps": 483062, "per_episode_reward": -150.46, "episode_reward_trend_value": 0.01848726986577055, "biggest_recent_change": 0.44107070553113203},
{"total_number_of_episodes": 4381, "number_of_timesteps": 484217, "per_episode_reward": -150.25, "episode_reward_trend_value": 0.022000109590885903, "biggest_recent_change": 0.44107070553113203},
{"total_number_of_episodes": 4391, "number_of_timesteps": 485008, "per_episode_reward": -149.9, "episode_reward_trend_value": 0.023540296625072364, "biggest_recent_change": 0.44107070553113203},
{"total_number_of_episodes": 4401, "number_of_timesteps": 486028, "per_episode_reward": -149.95, "episode_reward_trend_value": 0.018757947728520387, "biggest_recent_change": 0.44107070553113203},
{"total_number_of_episodes": 4412, "number_of_timesteps": 487373, "per_episode_reward": -149.71, "episode_reward_trend_value": 0.01649274203923533, "biggest_recent_change": 0.429891756718348},
{"total_number_of_episodes": 4422, "number_of_timesteps": 488539, "per_episode_reward": -149.69, "episode_reward_trend_value": 0.01701418096908564, "biggest_recent_change": 0.429891756718348},
{"total_number_of_episodes": 4432, "number_of_timesteps": 489773, "per_episode_reward": -149.6, "episode_reward_trend_value": 0.01833705929678994, "biggest_recent_change": 0.429891756718348},
{"total_number_of_episodes": 4443, "number_of_timesteps": 491050, "per_episode_reward": -149.29, "episode_reward_trend_value": 0.020776517558691567, "biggest_recent_change": 0.429891756718348},
{"total_number_of_episodes": 4453, "number_of_timesteps": 491893, "per_episode_reward": -149.1, "episode_reward_trend_value": 0.01982685850929834, "biggest_recent_change": 0.429891756718348},
{"total_number_of_episodes": 4463, "number_of_timesteps": 492957, "per_episode_reward": -149.06, "episode_reward_trend_value": 0.015555335043479898, "biggest_recent_change": 0.3479238133398894},
{"total_number_of_episodes": 4473, "number_of_timesteps": 494069, "per_episode_reward": -149.13, "episode_reward_trend_value": 0.012411654172181683, "biggest_recent_change": 0.3479238133398894},
{"total_number_of_episodes": 4483, "number_of_timesteps": 495299, "per_episode_reward": -149.11, "episode_reward_trend_value": 0.00873796043041466, "biggest_recent_change": 0.31425794411313746},
{"total_number_of_episodes": 4493, "number_of_timesteps": 496671, "per_episode_reward": -149.05, "episode_reward_trend_value": 0.010047359353219083, "biggest_recent_change": 0.31425794411313746},
{"total_number_of_episodes": 4503, "number_of_timesteps": 497858, "per_episode_reward": -149.01, "episode_reward_trend_value": 0.007824028649821773, "biggest_recent_change": 0.31425794411313746},
{"total_number_of_episodes": 4513, "number_of_timesteps": 499122, "per_episode_reward": -149.07, "episode_reward_trend_value": 0.006924446200919003, "biggest_recent_change": 0.31425794411313746},
{"total_number_of_episodes": 4526, "number_of_timesteps": 500504, "per_episode_reward": -149.15, "episode_reward_trend_value": 0.004963011357251743, "biggest_recent_change": 0.31425794411313746},
{"total_number_of_episodes": 4536, "number_of_timesteps": 501699, "per_episode_reward": -149.02, "episode_reward_trend_value": 0.0029739944291476503, "biggest_recent_change": 0.18548046738521862},
{"total_number_of_episodes": 4546, "number_of_timesteps": 502977, "per_episode_reward": -149.09, "episode_reward_trend_value": 0.00013848444272134152, "biggest_recent_change": 0.13524642058376912},
{"total_number_of_episodes": 4556, "number_of_timesteps": 504436, "per_episode_reward": -149.54, "episode_reward_trend_value": -0.005374305491519573, "biggest_recent_change": 0.45069644928699404},
{"total_number_of_episodes": 4566, "number_of_timesteps": 505612, "per_episode_reward": -149.82, "episode_reward_trend_value": -0.00764286375583241, "biggest_recent_change": 0.45069644928699404},
{"total_number_of_episodes": 4576, "number_of_timesteps": 506993, "per_episode_reward": -150.06, "episode_reward_trend_value": -0.010560615589691718, "biggest_recent_change": 0.45069644928699404},
{"total_number_of_episodes": 4587, "number_of_timesteps": 508415, "per_episode_reward": -149.9, "episode_reward_trend_value": -0.009446473538167766, "biggest_recent_change": 0.45069644928699404},
{"total_number_of_episodes": 4597, "number_of_timesteps": 509119, "per_episode_reward": -149.69, "episode_reward_trend_value": -0.007601348661475526, "biggest_recent_change": 0.45069644928699404},
{"total_number_of_episodes": 4608, "number_of_timesteps": 509885, "per_episode_reward": -149.32, "episode_reward_trend_value": -0.0028141881491102875, "biggest_recent_change": 0.45069644928699404},
{"total_number_of_episodes": 4618, "number_of_timesteps": 510793, "per_episode_reward": -149.16, "episode_reward_trend_value": -0.00011080679062666201, "biggest_recent_change": 0.45069644928699404},
{"total_number_of_episodes": 4628, "number_of_timesteps": 512072, "per_episode_reward": -149.24, "episode_reward_trend_value": -0.00246951038779015, "biggest_recent_change": 0.45069644928699404},
{"total_number_of_episodes": 4640, "number_of_timesteps": 513991, "per_episode_reward": -149.36, "episode_reward_trend_value": -0.0030523652833706035, "biggest_recent_change": 0.45069644928699404},
{"total_number_of_episodes": 4650, "number_of_timesteps": 514956, "per_episode_reward": -149.07, "episode_reward_trend_value": 0.005274613591761737, "biggest_recent_change": 0.3723268031768612},
{"total_number_of_episodes": 4661, "number_of_timesteps": 516210, "per_episode_reward": -149.2, "episode_reward_trend_value": 0.006915981837881999, "biggest_recent_change": 0.3723268031768612},
{"total_number_of_episodes": 4671, "number_of_timesteps": 517223, "per_episode_reward": -149.12, "episode_reward_trend_value": 0.010508028845450528, "biggest_recent_change": 0.3723268031768612},
{"total_number_of_episodes": 4681, "number_of_timesteps": 518345, "per_episode_reward": -149.33, "episode_reward_trend_value": 0.0062723043384825886, "biggest_recent_change": 0.3723268031768612},
{"total_number_of_episodes": 4691, "number_of_timesteps": 519693, "per_episode_reward": -149.99, "episode_reward_trend_value": -0.0032397267505707024, "biggest_recent_change": 0.6529191289227754},
{"total_number_of_episodes": 4701, "number_of_timesteps": 520695, "per_episode_reward": -149.87, "episode_reward_trend_value": -0.0061323490046387655, "biggest_recent_change": 0.6529191289227754},
{"total_number_of_episodes": 4711, "number_of_timesteps": 521930, "per_episode_reward": -149.76, "episode_reward_trend_value": -0.006602914469370565, "biggest_recent_change": 0.6529191289227754},
{"total_number_of_episodes": 4721, "number_of_timesteps": 523116, "per_episode_reward": -149.97, "episode_reward_trend_value": -0.008042612936504333, "biggest_recent_change": 0.6529191289227754},
{"total_number_of_episodes": 4731, "number_of_timesteps": 524083, "per_episode_reward": -149.92, "episode_reward_trend_value": -0.006158138242771353, "biggest_recent_change": 0.6529191289227754},
{"total_number_of_episodes": 4741, "number_of_timesteps": 525569, "per_episode_reward": -149.72, "episode_reward_trend_value": -0.007288348875511335, "biggest_recent_change": 0.6529191289227754},
{"total_number_of_episodes": 4751, "number_of_timesteps": 526297, "per_episode_reward": -149.62, "episode_reward_trend_value": -0.004679806348585834, "biggest_recent_change": 0.6529191289227754},
{"total_number_of_episodes": 4764, "number_of_timesteps": 527459, "per_episode_reward": -149.45, "episode_reward_trend_value": -0.003735693889983812, "biggest_recent_change": 0.6529191289227754},
{"total_number_of_episodes": 4774, "number_of_timesteps": 528692, "per_episode_reward": -149.4, "episode_reward_trend_value": -0.0007399043545029194, "biggest_recent_change": 0.6529191289227754},
{"total_number_of_episodes": 4784, "number_of_timesteps": 529794, "per_episode_reward": -149.26, "episode_reward_trend_value": 0.008090487217234316, "biggest_recent_change": 0.2066097652029839},
{"total_number_of_episodes": 4794, "number_of_timesteps": 530590, "per_episode_reward": -149.2, "episode_reward_trend_value": 0.007534827287899286, "biggest_recent_change": 0.2066097652029839},
{"total_number_of_episodes": 4804, "number_of_timesteps": 531801, "per_episode_reward": -149.13, "episode_reward_trend_value": 0.006946128379977129, "biggest_recent_change": 0.2066097652029839},
{"total_number_of_episodes": 4814, "number_of_timesteps": 533065, "per_episode_reward": -148.99, "episode_reward_trend_value": 0.010801734549725791, "biggest_recent_change": 0.1970126925283182},
{"total_number_of_episodes": 4824, "number_of_timesteps": 534366, "per_episode_reward": -148.93, "episode_reward_trend_value": 0.011001564681162297, "biggest_recent_change": 0.1970126925283182},
{"total_number_of_episodes": 4834, "number_of_timesteps": 535467, "per_episode_reward": -148.91, "episode_reward_trend_value": 0.008968875278357775, "biggest_recent_change": 0.16294806348886937},
{"total_number_of_episodes": 4844, "number_of_timesteps": 536747, "per_episode_reward": -148.93, "episode_reward_trend_value": 0.007666536942274307, "biggest_recent_change": 0.16294806348886937},
{"total_number_of_episodes": 4854, "number_of_timesteps": 538388, "per_episode_reward": -148.71, "episode_reward_trend_value": 0.008266950515950259, "biggest_recent_change": 0.21698528511970494},
{"total_number_of_episodes": 4864, "number_of_timesteps": 539692, "per_episode_reward": -148.58, "episode_reward_trend_value": 0.009128748021891259, "biggest_recent_change": 0.21698528511970494},
{"total_number_of_episodes": 4874, "number_of_timesteps": 540641, "per_episode_reward": -148.27, "episode_reward_trend_value": 0.010944294907317777, "biggest_recent_change": 0.3052153322219624},
{"total_number_of_episodes": 4885, "number_of_timesteps": 542019, "per_episode_reward": -148.17, "episode_reward_trend_value": 0.011420109420041374, "biggest_recent_change": 0.3052153322219624},
{"total_number_of_episodes": 4895, "number_of_timesteps": 543482, "per_episode_reward": -148.16, "episode_reward_trend_value": 0.0108355754150005, "biggest_recent_change": 0.3052153322219624},
{"total_number_of_episodes": 4905, "number_of_timesteps": 544611, "per_episode_reward": -148.08, "episode_reward_trend_value": 0.0101905576900129, "biggest_recent_change": 0.3052153322219624},
{"total_number_of_episodes": 4916, "number_of_timesteps": 545775, "per_episode_reward": -148.01, "episode_reward_trend_value": 0.01024577033496712, "biggest_recent_change": 0.3052153322219624},
{"total_number_of_episodes": 4926, "number_of_timesteps": 546795, "per_episode_reward": -147.73, "episode_reward_trend_value": 0.013173863361326551, "biggest_recent_change": 0.3052153322219624},
{"total_number_of_episodes": 4937, "number_of_timesteps": 547980, "per_episode_reward": -147.77, "episode_reward_trend_value": 0.012830298659138683, "biggest_recent_change": 0.3052153322219624},
{"total_number_of_episodes": 4948, "number_of_timesteps": 549594, "per_episode_reward": -147.72, "episode_reward_trend_value": 0.011028194646802564, "biggest_recent_change": 0.3052153322219624},
{"total_number_of_episodes": 4958, "number_of_timesteps": 550705, "per_episode_reward": -147.66, "episode_reward_trend_value": 0.01018956869385224, "biggest_recent_change": 0.3052153322219624},
{"total_number_of_episodes": 4968, "number_of_timesteps": 551767, "per_episode_reward": -147.54, "episode_reward_trend_value": 0.008197962371132423, "biggest_recent_change": 0.2775990186482602},
{"total_number_of_episodes": 4978, "number_of_timesteps": 552950, "per_episode_reward": -147.77, "episode_reward_trend_value": 0.0043993410832980666, "biggest_recent_change": 0.2775990186482602},
{"total_number_of_episodes": 4988, "number_of_timesteps": 554205, "per_episode_reward": -147.81, "episode_reward_trend_value": 0.003893217377932956, "biggest_recent_change": 0.2775990186482602},
{"total_number_of_episodes": 4998, "number_of_timesteps": 555555, "per_episode_reward": -147.96, "episode_reward_trend_value": 0.0012651749800141943, "biggest_recent_change": 0.2775990186482602},
{"total_number_of_episodes": 5008, "number_of_timesteps": 556614, "per_episode_reward": -147.88, "episode_reward_trend_value": 0.001392599485291157, "biggest_recent_change": 0.2775990186482602},
{"total_number_of_episodes": 5018, "number_of_timesteps": 557934, "per_episode_reward": -147.86, "episode_reward_trend_value": -0.0014776896759709896, "biggest_recent_change": 0.23707120308938556},
{"total_number_of_episodes": 5028, "number_of_timesteps": 559131, "per_episode_reward": -147.81, "episode_reward_trend_value": -0.0004018893537448776, "biggest_recent_change": 0.23707120308938556},
{"total_number_of_episodes": 5039, "number_of_timesteps": 560473, "per_episode_reward": -147.81, "episode_reward_trend_value": -0.0009748984208265988, "biggest_recent_change": 0.23707120308938556},
{"total_number_of_episodes": 5049, "number_of_timesteps": 561607, "per_episode_reward": -147.87, "episode_reward_trend_value": -0.0023456667680572234, "biggest_recent_change": 0.23707120308938556},
{"total_number_of_episodes": 5059, "number_of_timesteps": 563084, "per_episode_reward": -147.93, "episode_reward_trend_value": -0.004428963314263177, "biggest_recent_change": 0.23707120308938556},
{"total_number_of_episodes": 5070, "number_of_timesteps": 564372, "per_episode_reward": -147.92, "episode_reward_trend_value": -0.0015934182323822672, "biggest_recent_change": 0.15418062098717655},
{"total_number_of_episodes": 5080, "number_of_timesteps": 565228, "per_episode_reward": -147.5, "episode_reward_trend_value": 0.0033765904168982764, "biggest_recent_change": 0.4111229911693215},
{"total_number_of_episodes": 5090, "number_of_timesteps": 566219, "per_episode_reward": -147.34, "episode_reward_trend_value": 0.006862967715451242, "biggest_recent_change": 0.4111229911693215},
{"total_number_of_episodes": 5100, "number_of_timesteps": 567361, "per_episode_reward": -147.53, "episode_reward_trend_value": 0.003931008639014837, "biggest_recent_change": 0.4111229911693215},
{"total_number_of_episodes": 5111, "number_of_timesteps": 568589, "per_episode_reward": -147.34, "episode_reward_trend_value": 0.005816439268785542, "biggest_recent_change": 0.4111229911693215},
{"total_number_of_episodes": 5122, "number_of_timesteps": 569609, "per_episode_reward": -146.93, "episode_reward_trend_value": 0.009785774937187991, "biggest_recent_change": 0.4111229911693215},
{"total_number_of_episodes": 5133, "number_of_timesteps": 570883, "per_episode_reward": -146.89, "episode_reward_trend_value": 0.01021406369573678, "biggest_recent_change": 0.4111229911693215},
{"total_number_of_episodes": 5143, "number_of_timesteps": 572580, "per_episode_reward": -147.03, "episode_reward_trend_value": 0.00932360570652438, "biggest_recent_change": 0.4111229911693215},
{"total_number_of_episodes": 5153, "number_of_timesteps": 573573, "per_episode_reward": -146.83, "episode_reward_trend_value": 0.012317553490196234, "biggest_recent_change": 0.4111229911693215},
{"total_number_of_episodes": 5163, "number_of_timesteps": 574629, "per_episode_reward": -146.78, "episode_reward_trend_value": 0.012664649396232144, "biggest_recent_change": 0.4111229911693215},
{"total_number_of_episodes": 5174, "number_of_timesteps": 575856, "per_episode_reward": -146.72, "episode_reward_trend_value": 0.008685451829265074, "biggest_recent_change": 0.4103031766469485},
{"total_number_of_episodes": 5184, "number_of_timesteps": 577105, "per_episode_reward": -146.74, "episode_reward_trend_value": 0.006705058818381342, "biggest_recent_change": 0.4103031766469485},
{"total_number_of_episodes": 5194, "number_of_timesteps": 578438, "per_episode_reward": -146.92, "episode_reward_trend_value": 0.006696900232490243, "biggest_recent_change": 0.4103031766469485},
{"total_number_of_episodes": 5204, "number_of_timesteps": 579506, "per_episode_reward": -146.92, "episode_reward_trend_value": 0.00467038223459642, "biggest_recent_change": 0.4103031766469485},
{"total_number_of_episodes": 5215, "number_of_timesteps": 580756, "per_episode_reward": -146.92, "episode_reward_trend_value": 9.731800949579236e-05, "biggest_recent_change": 0.20792937454910998},
{"total_number_of_episodes": 5227, "number_of_timesteps": 582429, "per_episode_reward": -146.92, "episode_reward_trend_value": -0.000417129315196184, "biggest_recent_change": 0.20792937454910998},
{"total_number_of_episodes": 5238, "number_of_timesteps": 583548, "per_episode_reward": -146.9, "episode_reward_trend_value": 0.0014237479902097525, "biggest_recent_change": 0.20792937454910998},
{"total_number_of_episodes": 5248, "number_of_timesteps": 584617, "per_episode_reward": -146.74, "episode_reward_trend_value": 0.0009127172710157715, "biggest_recent_change": 0.18275818381880526},
{"total_number_of_episodes": 5259, "number_of_timesteps": 585849, "per_episode_reward": -146.69, "episode_reward_trend_value": 0.0009776815222977576, "biggest_recent_change": 0.18275818381880526},
{"total_number_of_episodes": 5270, "number_of_timesteps": 587027, "per_episode_reward": -146.69, "episode_reward_trend_value": 0.00034319678304812996, "biggest_recent_change": 0.18275818381880526},
{"total_number_of_episodes": 5281, "number_of_timesteps": 587915, "per_episode_reward": -146.38, "episode_reward_trend_value": 0.004001515556000376, "biggest_recent_change": 0.31060665446875646},
{"total_number_of_episodes": 5291, "number_of_timesteps": 588868, "per_episode_reward": -146.27, "episode_reward_trend_value": 0.007314402966380208, "biggest_recent_change": 0.31060665446875646},
{"total_number_of_episodes": 5301, "number_of_timesteps": 589786, "per_episode_reward": -146.33, "episode_reward_trend_value": 0.0065617177706817145, "biggest_recent_change": 0.31060665446875646},
{"total_number_of_episodes": 5312, "number_of_timesteps": 590770, "per_episode_reward": -146.2, "episode_reward_trend_value": 0.007995439945133537, "biggest_recent_change": 0.31060665446875646},
{"total_number_of_episodes": 5322, "number_of_timesteps": 592956, "per_episode_reward": -146.23, "episode_reward_trend_value": 0.007723366444361722, "biggest_recent_change": 0.31060665446875646},
{"total_number_of_episodes": 5332, "number_of_timesteps": 593855, "per_episode_reward": -146.26, "episode_reward_trend_value": 0.007159878620742195, "biggest_recent_change": 0.31060665446875646},
{"total_number_of_episodes": 5342, "number_of_timesteps": 594592, "per_episode_reward": -145.48, "episode_reward_trend_value": 0.014077988609131531, "biggest_recent_change": 0.7845665087766918},
{"total_number_of_episodes": 5353, "number_of_timesteps": 595601, "per_episode_reward": -145.29, "episode_reward_trend_value": 0.015517939411588421, "biggest_recent_change": 0.7845665087766918},
{"total_number_of_episodes": 5363, "number_of_timesteps": 596791, "per_episode_reward": -145.28, "episode_reward_trend_value": 0.015643707849241333, "biggest_recent_change": 0.7845665087766918},
{"total_number_of_episodes": 5373, "number_of_timesteps": 597616, "per_episode_reward": -145.19, "episode_reward_trend_value": 0.013274019708178899, "biggest_recent_change": 0.7845665087766918},
{"total_number_of_episodes": 5383, "number_of_timesteps": 598592, "per_episode_reward": -145.08, "episode_reward_trend_value": 0.0131829006097705, "biggest_recent_change": 0.7845665087766918},
{"total_number_of_episodes": 5393, "number_of_timesteps": 599620, "per_episode_reward": -145.04, "episode_reward_trend_value": 0.01425968289223426, "biggest_recent_change": 0.7845665087766918},
{"total_number_of_episodes": 5403, "number_of_timesteps": 600622, "per_episode_reward": -144.95, "episode_reward_trend_value": 0.013915401295503216, "biggest_recent_change": 0.7845665087766918},
{"total_number_of_episodes": 5413, "number_of_timesteps": 601878, "per_episode_reward": -145.05, "episode_reward_trend_value": 0.01312032498044068, "biggest_recent_change": 0.7845665087766918},
{"total_number_of_episodes": 5423, "number_of_timesteps": 603053, "per_episode_reward": -145.01, "episode_reward_trend_value": 0.013889253831756479, "biggest_recent_change": 0.7845665087766918},
{"total_number_of_episodes": 5433, "number_of_timesteps": 604132, "per_episode_reward": -145.15, "episode_reward_trend_value": 0.0036423647308232096, "biggest_recent_change": 0.18480884065962755},
{"total_number_of_episodes": 5443, "number_of_timesteps": 605348, "per_episode_reward": -145.1, "episode_reward_trend_value": 0.0021456902640349224, "biggest_recent_change": 0.13765351030730244},
{"total_number_of_episodes": 5455, "number_of_timesteps": 606702, "per_episode_reward": -145.1, "episode_reward_trend_value": 0.0020079153717170407, "biggest_recent_change": 0.13765351030730244},
{"total_number_of_episodes": 5465, "number_of_timesteps": 607711, "per_episode_reward": -145.02, "episode_reward_trend_value": 0.0018693088051249004, "biggest_recent_change": 0.13765351030730244},
{"total_number_of_episodes": 5475, "number_of_timesteps": 608968, "per_episode_reward": -145.09, "episode_reward_trend_value": -0.0001531249800134699, "biggest_recent_change": 0.13765351030730244},
{"total_number_of_episodes": 5485, "number_of_timesteps": 610202, "per_episode_reward": -145.18, "episode_reward_trend_value": -0.001530100926173519, "biggest_recent_change": 0.13765351030730244},
{"total_number_of_episodes": 5495, "number_of_timesteps": 611501, "per_episode_reward": -145.07, "episode_reward_trend_value": -0.001353503178965967, "biggest_recent_change": 0.13765351030730244},
{"total_number_of_episodes": 5505, "number_of_timesteps": 612420, "per_episode_reward": -144.9, "episode_reward_trend_value": 0.0016332366373145786, "biggest_recent_change": 0.1682339370593695},
{"total_number_of_episodes": 5515, "number_of_timesteps": 613592, "per_episode_reward": -144.81, "episode_reward_trend_value": 0.002270413482722549, "biggest_recent_change": 0.1682339370593695},
{"total_number_of_episodes": 5525, "number_of_timesteps": 614770, "per_episode_reward": -144.86, "episode_reward_trend_value": 0.0032496754178408887, "biggest_recent_change": 0.1682339370593695},
{"total_number_of_episodes": 5536, "number_of_timesteps": 616097, "per_episode_reward": -144.95, "episode_reward_trend_value": 0.0016166108378207074, "biggest_recent_change": 0.1682339370593695},
{"total_number_of_episodes": 5547, "number_of_timesteps": 617360, "per_episode_reward": -144.89, "episode_reward_trend_value": 0.002318352622783474, "biggest_recent_change": 0.1682339370593695},
{"total_number_of_episodes": 5557, "number_of_timesteps": 618467, "per_episode_reward": -145.0, "episode_reward_trend_value": 0.00020167423424387229, "biggest_recent_change": 0.1682339370593695},
{"total_number_of_episodes": 5567, "number_of_timesteps": 619819, "per_episode_reward": -144.99, "episode_reward_trend_value": 0.0011080209736124718, "biggest_recent_change": 0.1682339370593695},
{"total_number_of_episodes": 5578, "number_of_timesteps": 620620, "per_episode_reward": -144.88, "episode_reward_trend_value": 0.00334303711726294, "biggest_recent_change": 0.1682339370593695},
{"total_number_of_episodes": 5589, "number_of_timesteps": 621533, "per_episode_reward": -144.78, "episode_reward_trend_value": 0.0032437572487111765, "biggest_recent_change": 0.1682339370593695},
{"total_number_of_episodes": 5599, "number_of_timesteps": 622276, "per_episode_reward": -144.49, "episode_reward_trend_value": 0.004595469397100121, "biggest_recent_change": 0.2898880304143745},
{"total_number_of_episodes": 5609, "number_of_timesteps": 623159, "per_episode_reward": -144.11, "episode_reward_trend_value": 0.007737002343125393, "biggest_recent_change": 0.3770466768310712},
{"total_number_of_episodes": 5620, "number_of_timesteps": 624342, "per_episode_reward": -144.0, "episode_reward_trend_value": 0.00951895938096325, "biggest_recent_change": 0.3770466768310712},
{"total_number_of_episodes": 5630, "number_of_timesteps": 625282, "per_episode_reward": -144.04, "episode_reward_trend_value": 0.010115828777217138, "biggest_recent_change": 0.3770466768310712},
{"total_number_of_episodes": 5640, "number_of_timesteps": 626288, "per_episode_reward": -143.99, "episode_reward_trend_value": 0.010000538392362854, "biggest_recent_change": 0.3770466768310712},
{"total_number_of_episodes": 5650, "number_of_timesteps": 627470, "per_episode_reward": -144.15, "episode_reward_trend_value": 0.009404175893282879, "biggest_recent_change": 0.3770466768310712},
{"total_number_of_episodes": 5660, "number_of_timesteps": 628524, "per_episode_reward": -144.31, "episode_reward_trend_value": 0.00756269338066444, "biggest_recent_change": 0.3770466768310712},
{"total_number_of_episodes": 5671, "number_of_timesteps": 629873, "per_episode_reward": -144.12, "episode_reward_trend_value": 0.008458947706450065, "biggest_recent_change": 0.3770466768310712},
{"total_number_of_episodes": 5682, "number_of_timesteps": 631064, "per_episode_reward": -143.9, "episode_reward_trend_value": 0.009738950015791186, "biggest_recent_change": 0.3770466768310712},
{"total_number_of_episodes": 5692, "number_of_timesteps": 632168, "per_episode_reward": -143.99, "episode_reward_trend_value": 0.005483673131371979, "biggest_recent_change": 0.3770466768310712},
{"total_number_of_episodes": 5702, "number_of_timesteps": 633281, "per_episode_reward": -143.99, "episode_reward_trend_value": 0.0013008926457767226, "biggest_recent_change": 0.218935865302484},
{"total_number_of_episodes": 5712, "number_of_timesteps": 634403, "per_episode_reward": -143.92, "episode_reward_trend_value": 0.0009228490462416201, "biggest_recent_change": 0.218935865302484},
{"total_number_of_episodes": 5722, "number_of_timesteps": 635562, "per_episode_reward": -143.94, "episode_reward_trend_value": 0.0011531912995249311, "biggest_recent_change": 0.218935865302484},
{"total_number_of_episodes": 5732, "number_of_timesteps": 636826, "per_episode_reward": -144.09, "episode_reward_trend_value": -0.0010445305210058423, "biggest_recent_change": 0.218935865302484},
{"total_number_of_episodes": 5743, "number_of_timesteps": 638473, "per_episode_reward": -144.04, "episode_reward_trend_value": 0.001228351689108346, "biggest_recent_change": 0.218935865302484},
{"total_number_of_episodes": 5753, "number_of_timesteps": 639446, "per_episode_reward": -143.88, "episode_reward_trend_value": 0.00478088487739525, "biggest_recent_change": 0.218935865302484},
{"total_number_of_episodes": 5763, "number_of_timesteps": 640659, "per_episode_reward": -143.82, "episode_reward_trend_value": 0.0032856999159933927, "biggest_recent_change": 0.218935865302484},
{"total_number_of_episodes": 5773, "number_of_timesteps": 641802, "per_episode_reward": -143.8, "episode_reward_trend_value": 0.0011205080603812374, "biggest_recent_change": 0.16074769094950625},
{"total_number_of_episodes": 5784, "number_of_timesteps": 643097, "per_episode_reward": -143.84, "episode_reward_trend_value": 0.0016879095986534292, "biggest_recent_change": 0.16074769094950625},
{"total_number_of_episodes": 5796, "number_of_timesteps": 644450, "per_episode_reward": -143.82, "episode_reward_trend_value": 0.0019437253051162568, "biggest_recent_change": 0.16074769094950625},
{"total_number_of_episodes": 5806, "number_of_timesteps": 645320, "per_episode_reward": -143.84, "episode_reward_trend_value": 0.0008936768045682837, "biggest_recent_change": 0.16074769094950625},
{"total_number_of_episodes": 5817, "number_of_timesteps": 646307, "per_episode_reward": -143.77, "episode_reward_trend_value": 0.0018879830744418138, "biggest_recent_change": 0.16074769094950625},
{"total_number_of_episodes": 5827, "number_of_timesteps": 647341, "per_episode_reward": -143.6, "episode_reward_trend_value": 0.005373621393656612, "biggest_recent_change": 0.1635041135812969},
{"total_number_of_episodes": 5837, "number_of_timesteps": 648581, "per_episode_reward": -143.56, "episode_reward_trend_value": 0.005406705081734723, "biggest_recent_change": 0.1635041135812969},
{"total_number_of_episodes": 5847, "number_of_timesteps": 649863, "per_episode_reward": -143.61, "episode_reward_trend_value": 0.002979978471825322, "biggest_recent_change": 0.1635041135812969},
{"total_number_of_episodes": 5858, "number_of_timesteps": 651091, "per_episode_reward": -143.59, "episode_reward_trend_value": 0.002603875294214062, "biggest_recent_change": 0.1635041135812969},
{"total_number_of_episodes": 5868, "number_of_timesteps": 652105, "per_episode_reward": -143.49, "episode_reward_trend_value": 0.003401055896580058, "biggest_recent_change": 0.1635041135812969},
{"total_number_of_episodes": 5879, "number_of_timesteps": 653162, "per_episode_reward": -143.32, "episode_reward_trend_value": 0.005780268427861302, "biggest_recent_change": 0.1721083770764551},
{"total_number_of_episodes": 5889, "number_of_timesteps": 653885, "per_episode_reward": -143.17, "episode_reward_trend_value": 0.0071594016937117045, "biggest_recent_change": 0.1721083770764551},
{"total_number_of_episodes": 5899, "number_of_timesteps": 655212, "per_episode_reward": -143.38, "episode_reward_trend_value": 0.005080445706553544, "biggest_recent_change": 0.20477813059295613},
{"total_number_of_episodes": 5909, "number_of_timesteps": 656466, "per_episode_reward": -143.46, "episode_reward_trend_value": 0.0034713820391289118, "biggest_recent_change": 0.20477813059295613},
{"total_number_of_episodes": 5919, "number_of_timesteps": 657352, "per_episode_reward": -143.39, "episode_reward_trend_value": 0.0023784792437882944, "biggest_recent_change": 0.20477813059295613},
{"total_number_of_episodes": 5929, "number_of_timesteps": 658445, "per_episode_reward": -143.24, "episode_reward_trend_value": 0.0035081782310824234, "biggest_recent_change": 0.20477813059295613},
{"total_number_of_episodes": 5939, "number_of_timesteps": 659706, "per_episode_reward": -143.37, "episode_reward_trend_value": 0.002726103213427362, "biggest_recent_change": 0.20477813059295613},
{"total_number_of_episodes": 5949, "number_of_timesteps": 661251, "per_episode_reward": -143.52, "episode_reward_trend_value": 0.0007963267077248778, "biggest_recent_change": 0.20477813059295613},
{"total_number_of_episodes": 5961, "number_of_timesteps": 662631, "per_episode_reward": -143.39, "episode_reward_trend_value": 0.001148667082646979, "biggest_recent_change": 0.20477813059295613},
{"total_number_of_episodes": 5971, "number_of_timesteps": 663491, "per_episode_reward": -143.24, "episode_reward_trend_value": 0.0008704252638996954, "biggest_recent_change": 0.20477813059295613},
{"total_number_of_episodes": 5982, "number_of_timesteps": 664647, "per_episode_reward": -143.08, "episode_reward_trend_value": 0.0010784394051695598, "biggest_recent_change": 0.20477813059295613},
{"total_number_of_episodes": 5992, "number_of_timesteps": 666033, "per_episode_reward": -142.93, "episode_reward_trend_value": 0.005029331551780084, "biggest_recent_change": 0.16646311334997677},
{"total_number_of_episodes": 6002, "number_of_timesteps": 666859, "per_episode_reward": -142.73, "episode_reward_trend_value": 0.008116306587299012, "biggest_recent_change": 0.20008096232231765},
{"total_number_of_episodes": 6012, "number_of_timesteps": 668069, "per_episode_reward": -142.91, "episode_reward_trend_value": 0.005335807772375271, "biggest_recent_change": 0.20008096232231765},
{"total_number_of_episodes": 6022, "number_of_timesteps": 669542, "per_episode_reward": -142.94, "episode_reward_trend_value": 0.003346462227283256, "biggest_recent_change": 0.20008096232231765},
{"total_number_of_episodes": 6032, "number_of_timesteps": 670776, "per_episode_reward": -143.02, "episode_reward_trend_value": 0.0038865833444150315, "biggest_recent_change": 0.20008096232231765},
{"total_number_of_episodes": 6042, "number_of_timesteps": 672251, "per_episode_reward": -143.12, "episode_reward_trend_value": 0.004405195677070614, "biggest_recent_change": 0.20008096232231765},

{"total_number_of_episodes": 6054, "number_of_timesteps": 673328, "per_episode_reward": -143.0, "episode_reward_trend_value": 0.00432847485882001, "biggest_recent_change": 0.20008096232231765},
{"total_number_of_episodes": 6064, "number_of_timesteps": 674262, "per_episode_reward": -142.88, "episode_reward_trend_value": 0.004023337922472731, "biggest_recent_change": 0.20008096232231765},
{"total_number_of_episodes": 6075, "number_of_timesteps": 675632, "per_episode_reward": -142.83, "episode_reward_trend_value": 0.002757005502485299, "biggest_recent_change": 0.20008096232231765},
{"total_number_of_episodes": 6085, "number_of_timesteps": 676899, "per_episode_reward": -142.97, "episode_reward_trend_value": -0.0005154043641432003, "biggest_recent_change": 0.20008096232231765},
{"total_number_of_episodes": 6095, "number_of_timesteps": 677861, "per_episode_reward": -142.99, "episode_reward_trend_value": -0.0028907928142384914, "biggest_recent_change": 0.18510203134249537},
{"total_number_of_episodes": 6105, "number_of_timesteps": 678798, "per_episode_reward": -142.87, "episode_reward_trend_value": 0.0004274872189079638, "biggest_recent_change": 0.14371472539457386},
{"total_number_of_episodes": 6115, "number_of_timesteps": 679916, "per_episode_reward": -142.78, "episode_reward_trend_value": 0.0017337729316718904, "biggest_recent_change": 0.14371472539457386},
{"total_number_of_episodes": 6126, "number_of_timesteps": 680903, "per_episode_reward": -142.54, "episode_reward_trend_value": 0.005303898349219101, "biggest_recent_change": 0.24187773258981338},
{"total_number_of_episodes": 6136, "number_of_timesteps": 681890, "per_episode_reward": -142.63, "episode_reward_trend_value": 0.005475323128226882, "biggest_recent_change": 0.24187773258981338},
{"total_number_of_episodes": 6146, "number_of_timesteps": 682720, "per_episode_reward": -142.58, "episode_reward_trend_value": 0.004684492487252908, "biggest_recent_change": 0.24187773258981338},
{"total_number_of_episodes": 6156, "number_of_timesteps": 683629, "per_episode_reward": -142.37, "episode_reward_trend_value": 0.00568741999500983, "biggest_recent_change": 0.24187773258981338},
{"total_number_of_episodes": 6166, "number_of_timesteps": 684762, "per_episode_reward": -142.21, "episode_reward_trend_value": 0.0068633956330851715, "biggest_recent_change": 0.24187773258981338},
{"total_number_of_episodes": 6176, "number_of_timesteps": 686189, "per_episode_reward": -142.57, "episode_reward_trend_value": 0.004456871015699132, "biggest_recent_change": 0.36030194095931734},
{"total_number_of_episodes": 6186, "number_of_timesteps": 687581, "per_episode_reward": -142.67, "episode_reward_trend_value": 0.0035383898697865053, "biggest_recent_change": 0.36030194095931734},
{"total_number_of_episodes": 6196, "number_of_timesteps": 688923, "per_episode_reward": -142.65, "episode_reward_trend_value": 0.002431995965934814, "biggest_recent_change": 0.36030194095931734},
{"total_number_of_episodes": 6206, "number_of_timesteps": 690495, "per_episode_reward": -142.65, "episode_reward_trend_value": 0.0015197969856046711, "biggest_recent_change": 0.36030194095931734},
{"total_number_of_episodes": 6216, "number_of_timesteps": 691820, "per_episode_reward": -142.42, "episode_reward_trend_value": 0.0013270068825439315, "biggest_recent_change": 0.36030194095931734},
{"total_number_of_episodes": 6226, "number_of_timesteps": 692778, "per_episode_reward": -142.37, "episode_reward_trend_value": 0.002841713059954524, "biggest_recent_change": 0.36030194095931734},
{"total_number_of_episodes": 6236, "number_of_timesteps": 694072, "per_episode_reward": -142.4, "episode_reward_trend_value": 0.0019554544737322506, "biggest_recent_change": 0.36030194095931734},
{"total_number_of_episodes": 6246, "number_of_timesteps": 695386, "per_episode_reward": -142.43, "episode_reward_trend_value": -0.0007058702406099983, "biggest_recent_change": 0.36030194095931734},
{"total_number_of_episodes": 6257, "number_of_timesteps": 696404, "per_episode_reward": -142.3, "episode_reward_trend_value": -0.0009591242506003381, "biggest_recent_change": 0.36030194095931734},
{"total_number_of_episodes": 6267, "number_of_timesteps": 697309, "per_episode_reward": -142.25, "episode_reward_trend_value": 0.0035659589285978025, "biggest_recent_change": 0.2245266233143468},
{"total_number_of_episodes": 6277, "number_of_timesteps": 698298, "per_episode_reward": -142.17, "episode_reward_trend_value": 0.005505879335984471, "biggest_recent_change": 0.2245266233143468},
{"total_number_of_episodes": 6287, "number_of_timesteps": 699511, "per_episode_reward": -142.22, "episode_reward_trend_value": 0.004865014071931897, "biggest_recent_change": 0.2245266233143468},
{"total_number_of_episodes": 6297, "number_of_timesteps": 700463, "per_episode_reward": -142.16, "episode_reward_trend_value": 0.005430012308364793, "biggest_recent_change": 0.2245266233143468},
{"total_number_of_episodes": 6307, "number_of_timesteps": 701499, "per_episode_reward": -142.06, "episode_reward_trend_value": 0.004056349768543378, "biggest_recent_change": 0.13553814207875803},
{"total_number_of_episodes": 6317, "number_of_timesteps": 702657, "per_episode_reward": -142.19, "episode_reward_trend_value": 0.0020197492640351, "biggest_recent_change": 0.13553814207875803},
{"total_number_of_episodes": 6327, "number_of_timesteps": 703674, "per_episode_reward": -142.16, "episode_reward_trend_value": 0.0027095328311118137, "biggest_recent_change": 0.13553814207875803},
{"total_number_of_episodes": 6337, "number_of_timesteps": 705056, "per_episode_reward": -141.95, "episode_reward_trend_value": 0.0053696558964165635, "biggest_recent_change": 0.20975961640269247},
{"total_number_of_episodes": 6348, "number_of_timesteps": 706433, "per_episode_reward": -141.97, "episode_reward_trend_value": 0.0036186814929992455, "biggest_recent_change": 0.20975961640269247},
{"total_number_of_episodes": 6359, "number_of_timesteps": 707538, "per_episode_reward": -141.97, "episode_reward_trend_value": 0.0030801709963213853, "biggest_recent_change": 0.20975961640269247},
{"total_number_of_episodes": 6369, "number_of_timesteps": 708714, "per_episode_reward": -141.98, "episode_reward_trend_value": 0.0020955426761935943, "biggest_recent_change": 0.20975961640269247},
{"total_number_of_episodes": 6379, "number_of_timesteps": 709808, "per_episode_reward": -142.43, "episode_reward_trend_value": -0.0024373324948723193, "biggest_recent_change": 0.4516689188666305},
{"total_number_of_episodes": 6389, "number_of_timesteps": 711329, "per_episode_reward": -142.5, "episode_reward_trend_value": -0.0038467241608060474, "biggest_recent_change": 0.4516689188666305},
{"total_number_of_episodes": 6399, "number_of_timesteps": 712521, "per_episode_reward": -142.49, "episode_reward_trend_value": -0.004846394002505703, "biggest_recent_change": 0.4516689188666305},
{"total_number_of_episodes": 6409, "number_of_timesteps": 713251, "per_episode_reward": -142.37, "episode_reward_trend_value": -0.002042468703164483, "biggest_recent_change": 0.4516689188666305},
{"total_number_of_episodes": 6419, "number_of_timesteps": 714164, "per_episode_reward": -142.32, "episode_reward_trend_value": -0.001818898114730574, "biggest_recent_change": 0.4516689188666305},
{"total_number_of_episodes": 6429, "number_of_timesteps": 715335, "per_episode_reward": -142.35, "episode_reward_trend_value": -0.004443172086489098, "biggest_recent_change": 0.4516689188666305},
{"total_number_of_episodes": 6439, "number_of_timesteps": 716484, "per_episode_reward": -142.39, "episode_reward_trend_value": -0.004649103729906617, "biggest_recent_change": 0.4516689188666305},
{"total_number_of_episodes": 6451, "number_of_timesteps": 718086, "per_episode_reward": -142.43, "episode_reward_trend_value": -0.005060274468914372, "biggest_recent_change": 0.4516689188666305},
{"total_number_of_episodes": 6461, "number_of_timesteps": 719366, "per_episode_reward": -142.45, "episode_reward_trend_value": -0.005163210553112663, "biggest_recent_change": 0.4516689188666305},
{"total_number_of_episodes": 6472, "number_of_timesteps": 721126, "per_episode_reward": -142.51, "episode_reward_trend_value": -0.000830507569761115, "biggest_recent_change": 0.1190206854345206},
{"total_number_of_episodes": 6482, "number_of_timesteps": 722608, "per_episode_reward": -142.45, "episode_reward_trend_value": 0.0005926021698349536, "biggest_recent_change": 0.1190206854345206},
{"total_number_of_episodes": 6492, "number_of_timesteps": 724113, "per_episode_reward": -142.47, "episode_reward_trend_value": 0.00020623820843184147, "biggest_recent_change": 0.1190206854345206},
{"total_number_of_episodes": 6502, "number_of_timesteps": 725469, "per_episode_reward": -142.44, "episode_reward_trend_value": -0.0007832585857480959, "biggest_recent_change": 0.061725650364991225},
{"total_number_of_episodes": 6512, "number_of_timesteps": 726637, "per_episode_reward": -142.4, "episode_reward_trend_value": -0.0008384822565230051, "biggest_recent_change": 0.061725650364991225},
{"total_number_of_episodes": 6522, "number_of_timesteps": 727467, "per_episode_reward": -142.3, "episode_reward_trend_value": 0.0005192781720043942, "biggest_recent_change": 0.09577339751189129},
{"total_number_of_episodes": 6532, "number_of_timesteps": 728200, "per_episode_reward": -142.22, "episode_reward_trend_value": 0.0018932332836524464, "biggest_recent_change": 0.09577339751189129},
{"total_number_of_episodes": 6544, "number_of_timesteps": 729447, "per_episode_reward": -142.18, "episode_reward_trend_value": 0.002744935694898408, "biggest_recent_change": 0.09577339751189129},
{"total_number_of_episodes": 6554, "number_of_timesteps": 730578, "per_episode_reward": -142.11, "episode_reward_trend_value": 0.0037539439553967214, "biggest_recent_change": 0.09577339751189129},
{"total_number_of_episodes": 6564, "number_of_timesteps": 731675, "per_episode_reward": -141.95, "episode_reward_trend_value": 0.00626762911775308, "biggest_recent_change": 0.1645060142470811},
{"total_number_of_episodes": 6574, "number_of_timesteps": 732938, "per_episode_reward": -142.03, "episode_reward_trend_value": 0.0047276179298304695, "biggest_recent_change": 0.1645060142470811},
{"total_number_of_episodes": 6584, "number_of_timesteps": 733667, "per_episode_reward": -141.76, "episode_reward_trend_value": 0.00797796929720265, "biggest_recent_change": 0.26868557551466665},
{"total_number_of_episodes": 6595, "number_of_timesteps": 734659, "per_episode_reward": -141.75, "episode_reward_trend_value": 0.007729286758922803, "biggest_recent_change": 0.26868557551466665},
{"total_number_of_episodes": 6606, "number_of_timesteps": 735997, "per_episode_reward": -141.63, "episode_reward_trend_value": 0.008486259117351994, "biggest_recent_change": 0.26868557551466665},
{"total_number_of_episodes": 6616, "number_of_timesteps": 737105, "per_episode_reward": -141.61, "episode_reward_trend_value": 0.007674892048480172, "biggest_recent_change": 0.26868557551466665},
{"total_number_of_episodes": 6626, "number_of_timesteps": 738793, "per_episode_reward": -141.77, "episode_reward_trend_value": 0.004961937732417078, "biggest_recent_change": 0.26868557551466665},
{"total_number_of_episodes": 6636, "number_of_timesteps": 739990, "per_episode_reward": -141.53, "episode_reward_trend_value": 0.007181038053342882, "biggest_recent_change": 0.26868557551466665},
{"total_number_of_episodes": 6646, "number_of_timesteps": 740777, "per_episode_reward": -140.97, "episode_reward_trend_value": 0.012688615217324973, "biggest_recent_change": 0.5668374271602943},
{"total_number_of_episodes": 6656, "number_of_timesteps": 741693, "per_episode_reward": -140.85, "episode_reward_trend_value": 0.012132529444521525, "biggest_recent_change": 0.5668374271602943},
{"total_number_of_episodes": 6666, "number_of_timesteps": 742811, "per_episode_reward": -140.73, "episode_reward_trend_value": 0.014356358922062403, "biggest_recent_change": 0.5668374271602943},
{"total_number_of_episodes": 6676, "number_of_timesteps": 744005, "per_episode_reward": -140.75, "episode_reward_trend_value": 0.011144941993062377, "biggest_recent_change": 0.5668374271602943},
{"total_number_of_episodes": 6686, "number_of_timesteps": 745074, "per_episode_reward": -140.67, "episode_reward_trend_value": 0.011940806008936357, "biggest_recent_change": 0.5668374271602943},
{"total_number_of_episodes": 6696, "number_of_timesteps": 746055, "per_episode_reward": -140.55, "episode_reward_trend_value": 0.012073463817075789, "biggest_recent_change": 0.5668374271602943},
{"total_number_of_episodes": 6706, "number_of_timesteps": 747083, "per_episode_reward": -140.46, "episode_reward_trend_value": 0.012823988835633158, "biggest_recent_change": 0.5668374271602943},
{"total_number_of_episodes": 6716, "number_of_timesteps": 747956, "per_episode_reward": -140.28, "episode_reward_trend_value": 0.016561906715710013, "biggest_recent_change": 0.5668374271602943},
{"total_number_of_episodes": 6726, "number_of_timesteps": 749692, "per_episode_reward": -140.0, "episode_reward_trend_value": 0.017083227804907765, "biggest_recent_change": 0.5668374271602943},
{"total_number_of_episodes": 6736, "number_of_timesteps": 750436, "per_episode_reward": -139.61, "episode_reward_trend_value": 0.015130575916150394, "biggest_recent_change": 0.3910987571721307},
{"total_number_of_episodes": 6746, "number_of_timesteps": 751384, "per_episode_reward": -139.35, "episode_reward_trend_value": 0.01670440224556905, "biggest_recent_change": 0.3910987571721307},
{"total_number_of_episodes": 6756, "number_of_timesteps": 752492, "per_episode_reward": -139.34, "episode_reward_trend_value": 0.015515429850351994, "biggest_recent_change": 0.3910987571721307},
{"total_number_of_episodes": 6767, "number_of_timesteps": 754073, "per_episode_reward": -139.66, "episode_reward_trend_value": 0.012193844709603734, "biggest_recent_change": 0.3910987571721307},
{"total_number_of_episodes": 6777, "number_of_timesteps": 755400, "per_episode_reward": -139.81, "episode_reward_trend_value": 0.0095579441505363, "biggest_recent_change": 0.3910987571721307},
{"total_number_of_episodes": 6787, "number_of_timesteps": 756844, "per_episode_reward": -140.06, "episode_reward_trend_value": 0.005416141997520501, "biggest_recent_change": 0.3910987571721307},
{"total_number_of_episodes": 6797, "number_of_timesteps": 757940, "per_episode_reward": -140.04, "episode_reward_trend_value": 0.00466473509463583, "biggest_recent_change": 0.3910987571721307},
{"total_number_of_episodes": 6808, "number_of_timesteps": 759684, "per_episode_reward": -140.06, "episode_reward_trend_value": 0.0025105205596029617, "biggest_recent_change": 0.3910987571721307},
{"total_number_of_episodes": 6818, "number_of_timesteps": 760806, "per_episode_reward": -140.12, "episode_reward_trend_value": -0.0013162335437164707, "biggest_recent_change": 0.3910987571721307},
{"total_number_of_episodes": 6828, "number_of_timesteps": 761807, "per_episode_reward": -139.88, "episode_reward_trend_value": -0.003042579188671526, "biggest_recent_change": 0.3192846107626792},
{"total_number_of_episodes": 6838, "number_of_timesteps": 762786, "per_episode_reward": -139.96, "episode_reward_trend_value": -0.006764827845533875, "biggest_recent_change": 0.3192846107626792},
{"total_number_of_episodes": 6848, "number_of_timesteps": 763900, "per_episode_reward": -139.99, "episode_reward_trend_value": -0.0072939204335505615, "biggest_recent_change": 0.3192846107626792},
{"total_number_of_episodes": 6859, "number_of_timesteps": 764930, "per_episode_reward": -139.72, "episode_reward_trend_value": -0.0006798580827971061, "biggest_recent_change": 0.27598100080513177},
{"total_number_of_episodes": 6870, "number_of_timesteps": 766112, "per_episode_reward": -139.51, "episode_reward_trend_value": 0.0033646023956082323, "biggest_recent_change": 0.27598100080513177},
{"total_number_of_episodes": 6880, "number_of_timesteps": 767000, "per_episode_reward": -139.67, "episode_reward_trend_value": 0.004333977687739813, "biggest_recent_change": 0.27598100080513177},
{"total_number_of_episodes": 6890, "number_of_timesteps": 768300, "per_episode_reward": -139.88, "episode_reward_trend_value": 0.0017641231526874259, "biggest_recent_change": 0.27598100080513177},
{"total_number_of_episodes": 6900, "number_of_timesteps": 769613, "per_episode_reward": -139.73, "episode_reward_trend_value": 0.003588362302585008, "biggest_recent_change": 0.27598100080513177},
{"total_number_of_episodes": 6910, "number_of_timesteps": 770466, "per_episode_reward": -139.56, "episode_reward_trend_value": 0.006144406352349089, "biggest_recent_change": 0.27598100080513177},
{"total_number_of_episodes": 6920, "number_of_timesteps": 771549, "per_episode_reward": -139.77, "episode_reward_trend_value": 0.0012183824575591493, "biggest_recent_change": 0.27598100080513177},
{"total_number_of_episodes": 6930, "number_of_timesteps": 772815, "per_episode_reward": -139.88, "episode_reward_trend_value": 0.0008890797547170197, "biggest_recent_change": 0.27598100080513177},
{"total_number_of_episodes": 6941, "number_of_timesteps": 774251, "per_episode_reward": -139.67, "episode_reward_trend_value": 0.00355360455535371, "biggest_recent_change": 0.27598100080513177},
{"total_number_of_episodes": 6951, "number_of_timesteps": 775234, "per_episode_reward": -139.79, "episode_reward_trend_value": -0.0008098470544483562, "biggest_recent_change": 0.20861591643074462},
{"total_number_of_episodes": 6961, "number_of_timesteps": 776348, "per_episode_reward": -139.6, "episode_reward_trend_value": -0.0009655189538139867, "biggest_recent_change": 0.20861591643074462},
{"total_number_of_episodes": 6971, "number_of_timesteps": 777189, "per_episode_reward": -139.44, "episode_reward_trend_value": 0.0025292435616184623, "biggest_recent_change": 0.20861591643074462},
{"total_number_of_episodes": 6982, "number_of_timesteps": 778274, "per_episode_reward": -139.22, "episode_reward_trend_value": 0.007368614311683548, "biggest_recent_change": 0.22692745107511314},
{"total_number_of_episodes": 6992, "number_of_timesteps": 780040, "per_episode_reward": -139.28, "episode_reward_trend_value": 0.005016759112122474, "biggest_recent_change": 0.22692745107511314},
{"total_number_of_episodes": 7002, "number_of_timesteps": 780898, "per_episode_reward": -139.14, "episode_reward_trend_value": 0.00472787061742363, "biggest_recent_change": 0.22692745107511314},
{"total_number_of_episodes": 7012, "number_of_timesteps": 781895, "per_episode_reward": -139.14, "episode_reward_trend_value": 0.007018517900005526, "biggest_recent_change": 0.22692745107511314},
{"total_number_of_episodes": 7022, "number_of_timesteps": 783347, "per_episode_reward": -139.35, "episode_reward_trend_value": 0.005913497312189975, "biggest_recent_change": 0.22692745107511314},
{"total_number_of_episodes": 7032, "number_of_timesteps": 784393, "per_episode_reward": -139.33, "episode_reward_trend_value": 0.0037854390672713914, "biggest_recent_change": 0.22692745107511314},
{"total_number_of_episodes": 7042, "number_of_timesteps": 785711, "per_episode_reward": -139.61, "episode_reward_trend_value": 0.001974380783727901, "biggest_recent_change": 0.2797248895959683},
{"total_number_of_episodes": 7052, "number_of_timesteps": 787031, "per_episode_reward": -139.46, "episode_reward_trend_value": 0.0015217337109094033, "biggest_recent_change": 0.2797248895959683},
{"total_number_of_episodes": 7063, "number_of_timesteps": 787933, "per_episode_reward": -139.16, "episode_reward_trend_value": 0.0031780365360592417, "biggest_recent_change": 0.3050585039533189},
{"total_number_of_episodes": 7073, "number_of_timesteps": 788838, "per_episode_reward": -139.14, "episode_reward_trend_value": 0.0007995114697984541, "biggest_recent_change": 0.3050585039533189},
{"total_number_of_episodes": 7083, "number_of_timesteps": 789921, "per_episode_reward": -139.25, "episode_reward_trend_value": 0.0003578133387024865, "biggest_recent_change": 0.3050585039533189},
{"total_number_of_episodes": 7093, "number_of_timesteps": 790983, "per_episode_reward": -139.37, "episode_reward_trend_value": -0.0026275406017302, "biggest_recent_change": 0.3050585039533189},
{"total_number_of_episodes": 7103, "number_of_timesteps": 792427, "per_episode_reward": -139.53, "episode_reward_trend_value": -0.004353955877411093, "biggest_recent_change": 0.3050585039533189},
{"total_number_of_episodes": 7113, "number_of_timesteps": 793791, "per_episode_reward": -139.35, "episode_reward_trend_value": -3.8934599897149585e-05, "biggest_recent_change": 0.3050585039533189},
{"total_number_of_episodes": 7123, "number_of_timesteps": 794712, "per_episode_reward": -139.3, "episode_reward_trend_value": 0.0003715701912334958, "biggest_recent_change": 0.3050585039533189},
{"total_number_of_episodes": 7133, "number_of_timesteps": 795681, "per_episode_reward": -139.16, "episode_reward_trend_value": 0.005074656153921195, "biggest_recent_change": 0.3050585039533189},
{"total_number_of_episodes": 7143, "number_of_timesteps": 796890, "per_episode_reward": -139.01, "episode_reward_trend_value": 0.0050439053079717015, "biggest_recent_change": 0.3050585039533189},
{"total_number_of_episodes": 7153, "number_of_timesteps": 798093, "per_episode_reward": -139.04, "episode_reward_trend_value": 0.0012404149514907204, "biggest_recent_change": 0.18036310404190203},
{"total_number_of_episodes": 7163, "number_of_timesteps": 799235, "per_episode_reward": -139.21, "episode_reward_trend_value": -0.0007208348206341321, "biggest_recent_change": 0.18036310404190203},
{"total_number_of_episodes": 7173, "number_of_timesteps": 800639, "per_episode_reward": -139.06, "episode_reward_trend_value": 0.0021066033062289253, "biggest_recent_change": 0.18036310404190203},
{"total_number_of_episodes": 7185, "number_of_timesteps": 802058, "per_episode_reward": -139.17, "episode_reward_trend_value": 0.002221503848397472, "biggest_recent_change": 0.18036310404190203},
{"total_number_of_episodes": 7195, "number_of_timesteps": 803003, "per_episode_reward": -139.08, "episode_reward_trend_value": 0.004956830533934446, "biggest_recent_change": 0.18036310404190203},
{"total_number_of_episodes": 7205, "number_of_timesteps": 804728, "per_episode_reward": -139.1, "episode_reward_trend_value": 0.0027544491991941793, "biggest_recent_change": 0.16365228437959445},
{"total_number_of_episodes": 7215, "number_of_timesteps": 805834, "per_episode_reward": -139.16, "episode_reward_trend_value": 0.001547007270143139, "biggest_recent_change": 0.16365228437959445},
{"total_number_of_episodes": 7225, "number_of_timesteps": 806986, "per_episode_reward": -139.34, "episode_reward_trend_value": -0.0020821192465964107, "biggest_recent_change": 0.18306853946063484},
{"total_number_of_episodes": 7238, "number_of_timesteps": 808698, "per_episode_reward": -139.31, "episode_reward_trend_value": -0.003397215244058316, "biggest_recent_change": 0.18306853946063484},
{"total_number_of_episodes": 7249, "number_of_timesteps": 810079, "per_episode_reward": -139.45, "episode_reward_trend_value": -0.004552292303526428, "biggest_recent_change": 0.18306853946063484},
{"total_number_of_episodes": 7259, "number_of_timesteps": 811013, "per_episode_reward": -139.6, "episode_reward_trend_value": -0.004309987640095238, "biggest_recent_change": 0.18306853946063484},
{"total_number_of_episodes": 7269, "number_of_timesteps": 812038, "per_episode_reward": -139.51, "episode_reward_trend_value": -0.004978025981830254, "biggest_recent_change": 0.18306853946063484},
{"total_number_of_episodes": 7279, "number_of_timesteps": 813760, "per_episode_reward": -139.68, "episode_reward_trend_value": -0.005588839234034834, "biggest_recent_change": 0.18306853946063484},
{"total_number_of_episodes": 7291, "number_of_timesteps": 815326, "per_episode_reward": -139.4, "episode_reward_trend_value": -0.0034945092323722645, "biggest_recent_change": 0.27783548106413036},
{"total_number_of_episodes": 7301, "number_of_timesteps": 816501, "per_episode_reward": -139.53, "episode_reward_trend_value": -0.004777267473662682, "biggest_recent_change": 0.27783548106413036},
{"total_number_of_episodes": 7311, "number_of_timesteps": 817622, "per_episode_reward": -139.44, "episode_reward_trend_value": -0.003065762356521557, "biggest_recent_change": 0.27783548106413036},
{"total_number_of_episodes": 7321, "number_of_timesteps": 818699, "per_episode_reward": -139.43, "episode_reward_trend_value": -0.000986176131262242, "biggest_recent_change": 0.27783548106413036},
{"total_number_of_episodes": 7331, "number_of_timesteps": 819806, "per_episode_reward": -139.51, "episode_reward_trend_value": -0.002142763088971833, "biggest_recent_change": 0.27783548106413036},
{"total_number_of_episodes": 7341, "number_of_timesteps": 820853, "per_episode_reward": -139.37, "episode_reward_trend_value": 0.000949006686645109, "biggest_recent_change": 0.27783548106413036},
{"total_number_of_episodes": 7351, "number_of_timesteps": 821996, "per_episode_reward": -139.4, "episode_reward_trend_value": 0.0021909071066747604, "biggest_recent_change": 0.27783548106413036},
{"total_number_of_episodes": 7361, "number_of_timesteps": 823037, "per_episode_reward": -139.56, "episode_reward_trend_value": -0.0006331194974971292, "biggest_recent_change": 0.27783548106413036},
{"total_number_of_episodes": 7371, "number_of_timesteps": 824488, "per_episode_reward": -139.69, "episode_reward_trend_value": -0.00019266520832054033, "biggest_recent_change": 0.27783548106413036},
{"total_number_of_episodes": 7381, "number_of_timesteps": 825767, "per_episode_reward": -139.55, "episode_reward_trend_value": -0.001700251126160879, "biggest_recent_change": 0.16561471946207007},
{"total_number_of_episodes": 7391, "number_of_timesteps": 826999, "per_episode_reward": -139.53, "episode_reward_trend_value": 4.452166847859947e-05, "biggest_recent_change": 0.16561471946207007},
{"total_number_of_episodes": 7402, "number_of_timesteps": 828406, "per_episode_reward": -139.24, "episode_reward_trend_value": 0.0022085441141345857, "biggest_recent_change": 0.29068039118533306},
{"total_number_of_episodes": 7412, "number_of_timesteps": 829634, "per_episode_reward": -139.37, "episode_reward_trend_value": 0.0006894894020607327, "biggest_recent_change": 0.29068039118533306},
{"total_number_of_episodes": 7422, "number_of_timesteps": 831066, "per_episode_reward": -139.52, "episode_reward_trend_value": -0.00017405764216612676, "biggest_recent_change": 0.29068039118533306},
{"total_number_of_episodes": 7432, "number_of_timesteps": 832841, "per_episode_reward": -139.77, "episode_reward_trend_value": -0.00446716460719535, "biggest_recent_change": 0.29068039118533306},
{"total_number_of_episodes": 7442, "number_of_timesteps": 834245, "per_episode_reward": -139.62, "episode_reward_trend_value": -0.002507243916231674, "biggest_recent_change": 0.29068039118533306},
{"total_number_of_episodes": 7452, "number_of_timesteps": 835482, "per_episode_reward": -139.42, "episode_reward_trend_value": 0.00161276438913439, "biggest_recent_change": 0.29068039118533306},
{"total_number_of_episodes": 7462, "number_of_timesteps": 836734, "per_episode_reward": -139.4, "episode_reward_trend_value": 0.0032936776756880845, "biggest_recent_change": 0.29068039118533306},
{"total_number_of_episodes": 7472, "number_of_timesteps": 837707, "per_episode_reward": -139.15, "episode_reward_trend_value": 0.004500602590095405, "biggest_recent_change": 0.29068039118533306},
{"total_number_of_episodes": 7482, "number_of_timesteps": 839124, "per_episode_reward": -139.28, "episode_reward_trend_value": 0.002757339046936459, "biggest_recent_change": 0.29068039118533306},
{"total_number_of_episodes": 7492, "number_of_timesteps": 840199, "per_episode_reward": -139.21, "episode_reward_trend_value": 0.0002758527999393184, "biggest_recent_change": 0.2507759907551588},
{"total_number_of_episodes": 7502, "number_of_timesteps": 841701, "per_episode_reward": -139.32, "episode_reward_trend_value": 0.0006093969760330411, "biggest_recent_change": 0.2507759907551588},
{"total_number_of_episodes": 7512, "number_of_timesteps": 842830, "per_episode_reward": -139.2, "episode_reward_trend_value": 0.0035813302659931877, "biggest_recent_change": 0.2507759907551588},
{"total_number_of_episodes": 7523, "number_of_timesteps": 844286, "per_episode_reward": -139.17, "episode_reward_trend_value": 0.006726647872868814, "biggest_recent_change": 0.2507759907551588},
{"total_number_of_episodes": 7534, "number_of_timesteps": 845578, "per_episode_reward": -139.12, "episode_reward_trend_value": 0.005620797400279306, "biggest_recent_change": 0.2507759907551588},
{"total_number_of_episodes": 7544, "number_of_timesteps": 846749, "per_episode_reward": -139.03, "episode_reward_trend_value": 0.004293579601503615, "biggest_recent_change": 0.2507759907551588},
{"total_number_of_episodes": 7554, "number_of_timesteps": 848526, "per_episode_reward": -139.01, "episode_reward_trend_value": 0.0043329303737632725, "biggest_recent_change": 0.2507759907551588},
{"total_number_of_episodes": 7564, "number_of_timesteps": 849566, "per_episode_reward": -138.88, "episode_reward_trend_value": 0.0029753603586960427, "biggest_recent_change": 0.1331636251676116},
{"total_number_of_episodes": 7574, "number_of_timesteps": 850622, "per_episode_reward": -138.97, "episode_reward_trend_value": 0.003469853031018033, "biggest_recent_change": 0.12859468939910812},
{"total_number_of_episodes": 7584, "number_of_timesteps": 852015, "per_episode_reward": -138.77, "episode_reward_trend_value": 0.004949685992425796, "biggest_recent_change": 0.20053159548228905},
{"total_number_of_episodes": 7594, "number_of_timesteps": 853335, "per_episode_reward": -138.89, "episode_reward_trend_value": 0.004706091155239278, "biggest_recent_change": 0.20053159548228905},
{"total_number_of_episodes": 7604, "number_of_timesteps": 854377, "per_episode_reward": -138.75, "episode_reward_trend_value": 0.004953185414301073, "biggest_recent_change": 0.20053159548228905},
{"total_number_of_episodes": 7614, "number_of_timesteps": 855507, "per_episode_reward": -139.02, "episode_reward_trend_value": 0.001663834265509144, "biggest_recent_change": 0.262295929301672},
{"total_number_of_episodes": 7624, "number_of_timesteps": 856579, "per_episode_reward": -138.73, "episode_reward_trend_value": 0.004325780157299479, "biggest_recent_change": 0.2863676230466865},
{"total_number_of_episodes": 7634, "number_of_timesteps": 857649, "per_episode_reward": -138.74, "episode_reward_trend_value": 0.0032965764688684535, "biggest_recent_change": 0.2863676230466865},
{"total_number_of_episodes": 7644, "number_of_timesteps": 858607, "per_episode_reward": -138.8, "episode_reward_trend_value": 0.0023582335611927697, "biggest_recent_change": 0.2863676230466865},
{"total_number_of_episodes": 7654, "number_of_timesteps": 859945, "per_episode_reward": -139.01, "episode_reward_trend_value": -0.0014224551780065062, "biggest_recent_change": 0.2863676230466865},
{"total_number_of_episodes": 7664, "number_of_timesteps": 861331, "per_episode_reward": -138.86, "episode_reward_trend_value": 0.001201532147580843, "biggest_recent_change": 0.2863676230466865},
{"total_number_of_episodes": 7675, "number_of_timesteps": 862457, "per_episode_reward": -138.67, "episode_reward_trend_value": 0.001069512085276061, "biggest_recent_change": 0.2863676230466865},
{"total_number_of_episodes": 7686, "number_of_timesteps": 863527, "per_episode_reward": -138.82, "episode_reward_trend_value": 0.0007446659272640469, "biggest_recent_change": 0.2863676230466865},
{"total_number_of_episodes": 7696, "number_of_timesteps": 864910, "per_episode_reward": -138.99, "episode_reward_trend_value": -0.002647100313488219, "biggest_recent_change": 0.2863676230466865},
{"total_number_of_episodes": 7706, "number_of_timesteps": 866481, "per_episode_reward": -139.02, "episode_reward_trend_value": -3.94439640495471e-05, "biggest_recent_change": 0.2863676230466865},
{"total_number_of_episodes": 7716, "number_of_timesteps": 867259, "per_episode_reward": -138.89, "episode_reward_trend_value": -0.0017585546257177184, "biggest_recent_change": 0.2116672971288267},
{"total_number_of_episodes": 7726, "number_of_timesteps": 868352, "per_episode_reward": -138.57, "episode_reward_trend_value": 0.0018732180280671348, "biggest_recent_change": 0.319967633012908},
{"total_number_of_episodes": 7736, "number_of_timesteps": 869583, "per_episode_reward": -138.54, "episode_reward_trend_value": 0.0028395676634381238, "biggest_recent_change": 0.319967633012908},
{"total_number_of_episodes": 7746, "number_of_timesteps": 870811, "per_episode_reward": -138.46, "episode_reward_trend_value": 0.006049345425252442, "biggest_recent_change": 0.319967633012908},
{"total_number_of_episodes": 7757, "number_of_timesteps": 872044, "per_episode_reward": -138.45, "episode_reward_trend_value": 0.004505692352987959, "biggest_recent_change": 0.319967633012908},
{"total_number_of_episodes": 7767, "number_of_timesteps": 873175, "per_episode_reward": -138.46, "episode_reward_trend_value": 0.0023443383840616307, "biggest_recent_change": 0.319967633012908},
{"total_number_of_episodes": 7777, "number_of_timesteps": 874174, "per_episode_reward": -138.44, "episode_reward_trend_value": 0.0042422492648032375, "biggest_recent_change": 0.319967633012908},
{"total_number_of_episodes": 7789, "number_of_timesteps": 876066, "per_episode_reward": -138.33, "episode_reward_trend_value": 0.007335184721736078, "biggest_recent_change": 0.319967633012908},
{"total_number_of_episodes": 7799, "number_of_timesteps": 876891, "per_episode_reward": -138.23, "episode_reward_trend_value": 0.00877369549434819, "biggest_recent_change": 0.319967633012908},
{"total_number_of_episodes": 7809, "number_of_timesteps": 877698, "per_episode_reward": -137.63, "episode_reward_trend_value": 0.014032053817358146, "biggest_recent_change": 0.604899912567447},
{"total_number_of_episodes": 7820, "number_of_timesteps": 879117, "per_episode_reward": -137.66, "episode_reward_trend_value": 0.010110139308938908, "biggest_recent_change": 0.604899912567447},
{"total_number_of_episodes": 7830, "number_of_timesteps": 880216, "per_episode_reward": -137.55, "episode_reward_trend_value": 0.010979478892337448, "biggest_recent_change": 0.604899912567447},
{"total_number_of_episodes": 7840, "number_of_timesteps": 881332, "per_episode_reward": -137.54, "episode_reward_trend_value": 0.010248328612924398, "biggest_recent_change": 0.604899912567447},
{"total_number_of_episodes": 7851, "number_of_timesteps": 882533, "per_episode_reward": -137.55, "episode_reward_trend_value": 0.010013352621309776, "biggest_recent_change": 0.604899912567447},
{"total_number_of_episodes": 7861, "number_of_timesteps": 883572, "per_episode_reward": -137.48, "episode_reward_trend_value": 0.010885966896818092, "biggest_recent_change": 0.604899912567447},
{"total_number_of_episodes": 7871, "number_of_timesteps": 884816, "per_episode_reward": -137.58, "episode_reward_trend_value": 0.009537347519022887, "biggest_recent_change": 0.604899912567447},
{"total_number_of_episodes": 7881, "number_of_timesteps": 886039, "per_episode_reward": -137.8, "episode_reward_trend_value": 0.005887841763300293, "biggest_recent_change": 0.604899912567447},
{"total_number_of_episodes": 7891, "number_of_timesteps": 887246, "per_episode_reward": -137.89, "episode_reward_trend_value": 0.003757730472183754, "biggest_recent_change": 0.604899912567447},
{"total_number_of_episodes": 7902, "number_of_timesteps": 888637, "per_episode_reward": -137.88, "episode_reward_trend_value": -0.002811274243967432, "biggest_recent_change": 0.21734209304247543},
{"total_number_of_episodes": 7912, "number_of_timesteps": 889431, "per_episode_reward": -137.61, "episode_reward_trend_value": 0.0005594113512598951, "biggest_recent_change": 0.270357030825636},
{"total_number_of_episodes": 7922, "number_of_timesteps": 890419, "per_episode_reward": -137.67, "episode_reward_trend_value": -0.0013321992999762086, "biggest_recent_change": 0.270357030825636},
{"total_number_of_episodes": 7933, "number_of_timesteps": 891702, "per_episode_reward": -137.58, "episode_reward_trend_value": -0.0004208402074046565, "biggest_recent_change": 0.270357030825636},
{"total_number_of_episodes": 7943, "number_of_timesteps": 892886, "per_episode_reward": -137.73, "episode_reward_trend_value": -0.0019280983421850807, "biggest_recent_change": 0.270357030825636},
{"total_number_of_episodes": 7953, "number_of_timesteps": 894272, "per_episode_reward": -137.86, "episode_reward_trend_value": -0.004245104920992856, "biggest_recent_change": 0.270357030825636},
{"total_number_of_episodes": 7963, "number_of_timesteps": 895544, "per_episode_reward": -137.81, "episode_reward_trend_value": -0.002498914904830624, "biggest_recent_change": 0.270357030825636},
{"total_number_of_episodes": 7973, "number_of_timesteps": 896687, "per_episode_reward": -137.78, "episode_reward_trend_value": 0.0001906977617712376, "biggest_recent_change": 0.270357030825636},
{"total_number_of_episodes": 7983, "number_of_timesteps": 898020, "per_episode_reward": -137.98, "episode_reward_trend_value": -0.0010223918939655304, "biggest_recent_change": 0.270357030825636},
{"total_number_of_episodes": 7994, "number_of_timesteps": 899389, "per_episode_reward": -138.0, "episode_reward_trend_value": -0.0013497111872867308, "biggest_recent_change": 0.270357030825636},
{"total_number_of_episodes": 8004, "number_of_timesteps": 900312, "per_episode_reward": -137.91, "episode_reward_trend_value": -0.0033042469171154685, "biggest_recent_change": 0.19902897353389903},
{"total_number_of_episodes": 8015, "number_of_timesteps": 901350, "per_episode_reward": -137.66, "episode_reward_trend_value": 0.00015508137780260414, "biggest_recent_change": 0.24741791724392215},
{"total_number_of_episodes": 8025, "number_of_timesteps": 902433, "per_episode_reward": -137.78, "episode_reward_trend_value": -0.0022202619699372562, "biggest_recent_change": 0.24741791724392215},
{"total_number_of_episodes": 8035, "number_of_timesteps": 903669, "per_episode_reward": -137.85, "episode_reward_trend_value": -0.0013372156297540036, "biggest_recent_change": 0.24741791724392215},
{"total_number_of_episodes": 8046, "number_of_timesteps": 905005, "per_episode_reward": -137.94, "episode_reward_trend_value": -0.0008259215174439937, "biggest_recent_change": 0.24741791724392215},
{"total_number_of_episodes": 8057, "number_of_timesteps": 906196, "per_episode_reward": -137.91, "episode_reward_trend_value": -0.0011590479998981587, "biggest_recent_change": 0.24741791724392215},
{"total_number_of_episodes": 8068, "number_of_timesteps": 907626, "per_episode_reward": -137.93, "episode_reward_trend_value": -0.0016515886580738953, "biggest_recent_change": 0.24741791724392215},
{"total_number_of_episodes": 8078, "number_of_timesteps": 908682, "per_episode_reward": -137.64, "episode_reward_trend_value": 0.0037671122626420583, "biggest_recent_change": 0.2886541093305368},
{"total_number_of_episodes": 8088, "number_of_timesteps": 909769, "per_episode_reward": -137.72, "episode_reward_trend_value": 0.0031532892786316326, "biggest_recent_change": 0.2886541093305368},
{"total_number_of_episodes": 8098, "number_of_timesteps": 910769, "per_episode_reward": -137.78, "episode_reward_trend_value": 0.001343408370258064, "biggest_recent_change": 0.2886541093305368},
{"total_number_of_episodes": 8109, "number_of_timesteps": 912099, "per_episode_reward": -137.73, "episode_reward_trend_value": -0.0007626242723947345, "biggest_recent_change": 0.2886541093305368},
{"total_number_of_episodes": 8119, "number_of_timesteps": 912990, "per_episode_reward": -137.44, "episode_reward_trend_value": 0.0037219918887147845, "biggest_recent_change": 0.2886541093305368},
{"total_number_of_episodes": 8129, "number_of_timesteps": 913929, "per_episode_reward": -137.3, "episode_reward_trend_value": 0.006035787996192235, "biggest_recent_change": 0.2886541093305368},
{"total_number_of_episodes": 8139, "number_of_timesteps": 915376, "per_episode_reward": -137.38, "episode_reward_trend_value": 0.0061453589552017875, "biggest_recent_change": 0.2886541093305368},
{"total_number_of_episodes": 8150, "number_of_timesteps": 916708, "per_episode_reward": -137.36, "episode_reward_trend_value": 0.006199127326136514, "biggest_recent_change": 0.2886541093305368},
{"total_number_of_episodes": 8162, "number_of_timesteps": 917867, "per_episode_reward": -137.28, "episode_reward_trend_value": 0.007281791116709416, "biggest_recent_change": 0.2886541093305368},
{"total_number_of_episodes": 8173, "number_of_timesteps": 919105, "per_episode_reward": -137.4, "episode_reward_trend_value": 0.0027021753601878295, "biggest_recent_change": 0.2832660478219964},
{"total_number_of_episodes": 8183, "number_of_timesteps": 920339, "per_episode_reward": -137.33, "episode_reward_trend_value": 0.004251154484213595, "biggest_recent_change": 0.2832660478219964},

{"total_number_of_episodes": 8193, "number_of_timesteps": 921351, "per_episode_reward": -137.31, "episode_reward_trend_value": 0.005230230370282937, "biggest_recent_change": 0.2832660478219964},
{"total_number_of_episodes": 8206, "number_of_timesteps": 923294, "per_episode_reward": -137.22, "episode_reward_trend_value": 0.0056463163076797525, "biggest_recent_change": 0.2832660478219964},
{"total_number_of_episodes": 8216, "number_of_timesteps": 924595, "per_episode_reward": -137.26, "episode_reward_trend_value": 0.0019991471348321157, "biggest_recent_change": 0.1394855470543348},
{"total_number_of_episodes": 8228, "number_of_timesteps": 925909, "per_episode_reward": -137.46, "episode_reward_trend_value": -0.001713662378532553, "biggest_recent_change": 0.1946673091484854},
{"total_number_of_episodes": 8238, "number_of_timesteps": 927033, "per_episode_reward": -137.59, "episode_reward_trend_value": -0.002329203832972995, "biggest_recent_change": 0.1946673091484854},
{"total_number_of_episodes": 8248, "number_of_timesteps": 928254, "per_episode_reward": -137.54, "episode_reward_trend_value": -0.0020543550074295226, "biggest_recent_change": 0.1946673091484854},
{"total_number_of_episodes": 8258, "number_of_timesteps": 929872, "per_episode_reward": -137.65, "episode_reward_trend_value": -0.004097362973023008, "biggest_recent_change": 0.1946673091484854},
{"total_number_of_episodes": 8268, "number_of_timesteps": 931513, "per_episode_reward": -137.79, "episode_reward_trend_value": -0.004261669164048953, "biggest_recent_change": 0.1946673091484854},
{"total_number_of_episodes": 8278, "number_of_timesteps": 932839, "per_episode_reward": -137.56, "episode_reward_trend_value": -0.002486722844892913, "biggest_recent_change": 0.22813997304035638},
{"total_number_of_episodes": 8288, "number_of_timesteps": 933761, "per_episode_reward": -137.52, "episode_reward_trend_value": -0.0023195054874311912, "biggest_recent_change": 0.22813997304035638},
{"total_number_of_episodes": 8298, "number_of_timesteps": 934956, "per_episode_reward": -137.62, "episode_reward_trend_value": -0.004506573297975239, "biggest_recent_change": 0.22813997304035638},
{"total_number_of_episodes": 8308, "number_of_timesteps": 935956, "per_episode_reward": -137.51, "episode_reward_trend_value": -0.0027090968006016664, "biggest_recent_change": 0.22813997304035638},
{"total_number_of_episodes": 8318, "number_of_timesteps": 936913, "per_episode_reward": -137.59, "episode_reward_trend_value": -0.0014313884686581939, "biggest_recent_change": 0.22813997304035638},
{"total_number_of_episodes": 8328, "number_of_timesteps": 938365, "per_episode_reward": -137.94, "episode_reward_trend_value": -0.003906650488320591, "biggest_recent_change": 0.3581618308759573},
{"total_number_of_episodes": 8338, "number_of_timesteps": 939540, "per_episode_reward": -137.89, "episode_reward_trend_value": -0.0038696395605743164, "biggest_recent_change": 0.3581618308759573},
{"total_number_of_episodes": 8348, "number_of_timesteps": 940377, "per_episode_reward": -137.65, "episode_reward_trend_value": -8.917180135831081e-05, "biggest_recent_change": 0.3581618308759573},
{"total_number_of_episodes": 8358, "number_of_timesteps": 941357, "per_episode_reward": -137.74, "episode_reward_trend_value": 0.0005172332618630864, "biggest_recent_change": 0.3581618308759573},
{"total_number_of_episodes": 8368, "number_of_timesteps": 942502, "per_episode_reward": -137.7, "episode_reward_trend_value": -0.0015344838863673735, "biggest_recent_change": 0.3581618308759573},
{"total_number_of_episodes": 8378, "number_of_timesteps": 943647, "per_episode_reward": -137.93, "episode_reward_trend_value": -0.004577007485026267, "biggest_recent_change": 0.3581618308759573},
{"total_number_of_episodes": 8388, "number_of_timesteps": 944976, "per_episode_reward": -137.88, "episode_reward_trend_value": -0.0028459512180783503, "biggest_recent_change": 0.3581618308759573},
{"total_number_of_episodes": 8398, "number_of_timesteps": 945990, "per_episode_reward": -137.76, "episode_reward_trend_value": -0.0027731244893737365, "biggest_recent_change": 0.3581618308759573},
{"total_number_of_episodes": 8410, "number_of_timesteps": 947557, "per_episode_reward": -137.48, "episode_reward_trend_value": 0.0011457388322898825, "biggest_recent_change": 0.3581618308759573},
{"total_number_of_episodes": 8421, "number_of_timesteps": 948534, "per_episode_reward": -137.43, "episode_reward_trend_value": 0.005676438038746786, "biggest_recent_change": 0.2730241396761528},
{"total_number_of_episodes": 8431, "number_of_timesteps": 949842, "per_episode_reward": -137.49, "episode_reward_trend_value": 0.0044874891017353015, "biggest_recent_change": 0.2730241396761528},
{"total_number_of_episodes": 8442, "number_of_timesteps": 951765, "per_episode_reward": -137.64, "episode_reward_trend_value": 0.00019894193685748482, "biggest_recent_change": 0.2730241396761528},
{"total_number_of_episodes": 8452, "number_of_timesteps": 952714, "per_episode_reward": -137.57, "episode_reward_trend_value": 0.0019040197460302327, "biggest_recent_change": 0.2730241396761528},
{"total_number_of_episodes": 8462, "number_of_timesteps": 953821, "per_episode_reward": -137.78, "episode_reward_trend_value": -0.000972709899879318, "biggest_recent_change": 0.2730241396761528},
{"total_number_of_episodes": 8472, "number_of_timesteps": 955417, "per_episode_reward": -137.81, "episode_reward_trend_value": 0.0014088768762829003, "biggest_recent_change": 0.2730241396761528},
{"total_number_of_episodes": 8483, "number_of_timesteps": 956638, "per_episode_reward": -137.71, "episode_reward_trend_value": 0.0018673357533231182, "biggest_recent_change": 0.2730241396761528},
{"total_number_of_episodes": 8493, "number_of_timesteps": 957514, "per_episode_reward": -137.57, "episode_reward_trend_value": 0.0020640779160099026, "biggest_recent_change": 0.2730241396761528},
{"total_number_of_episodes": 8503, "number_of_timesteps": 958546, "per_episode_reward": -137.72, "episode_reward_trend_value": -0.002661840023117179, "biggest_recent_change": 0.21542023843224456},
{"total_number_of_episodes": 8513, "number_of_timesteps": 959664, "per_episode_reward": -137.64, "episode_reward_trend_value": -0.0023402944502107755, "biggest_recent_change": 0.21542023843224456},
{"total_number_of_episodes": 8523, "number_of_timesteps": 960796, "per_episode_reward": -137.65, "episode_reward_trend_value": -0.0017989713124251239, "biggest_recent_change": 0.21542023843224456},
{"total_number_of_episodes": 8533, "number_of_timesteps": 961965, "per_episode_reward": -137.71, "episode_reward_trend_value": -0.0008205785511535169, "biggest_recent_change": 0.21542023843224456},
{"total_number_of_episodes": 8543, "number_of_timesteps": 963128, "per_episode_reward": -137.68, "episode_reward_trend_value": -0.00126780041745336, "biggest_recent_change": 0.21542023843224456},
{"total_number_of_episodes": 8553, "number_of_timesteps": 964538, "per_episode_reward": -137.88, "episode_reward_trend_value": -0.001051742426765322, "biggest_recent_change": 0.19597501927032113},
{"total_number_of_episodes": 8563, "number_of_timesteps": 966020, "per_episode_reward": -137.72, "episode_reward_trend_value": 0.001000861491355762, "biggest_recent_change": 0.19597501927032113},
{"total_number_of_episodes": 8575, "number_of_timesteps": 967108, "per_episode_reward": -137.59, "episode_reward_trend_value": 0.001330526166998109, "biggest_recent_change": 0.19597501927032113},
{"total_number_of_episodes": 8587, "number_of_timesteps": 968632, "per_episode_reward": -137.97, "episode_reward_trend_value": -0.004491059909229497, "biggest_recent_change": 0.3828878396059281},
{"total_number_of_episodes": 8597, "number_of_timesteps": 969905, "per_episode_reward": -137.89, "episode_reward_trend_value": -0.0018175997869687107, "biggest_recent_change": 0.3828878396059281},
{"total_number_of_episodes": 8607, "number_of_timesteps": 971085, "per_episode_reward": -137.98, "episode_reward_trend_value": -0.003724069478707924, "biggest_recent_change": 0.3828878396059281},
{"total_number_of_episodes": 8617, "number_of_timesteps": 972269, "per_episode_reward": -138.08, "episode_reward_trend_value": -0.004770759536002503, "biggest_recent_change": 0.3828878396059281},
{"total_number_of_episodes": 8627, "number_of_timesteps": 973574, "per_episode_reward": -137.97, "episode_reward_trend_value": -0.0029057934206526345, "biggest_recent_change": 0.3828878396059281},
{"total_number_of_episodes": 8637, "number_of_timesteps": 974912, "per_episode_reward": -138.09, "episode_reward_trend_value": -0.0044916551816761, "biggest_recent_change": 0.3828878396059281},
{"total_number_of_episodes": 8647, "number_of_timesteps": 976276, "per_episode_reward": -138.09, "episode_reward_trend_value": -0.0023746931105291776, "biggest_recent_change": 0.3828878396059281},
{"total_number_of_episodes": 8657, "number_of_timesteps": 977322, "per_episode_reward": -138.06, "episode_reward_trend_value": -0.0037882931223562205, "biggest_recent_change": 0.3828878396059281},
{"total_number_of_episodes": 8668, "number_of_timesteps": 978455, "per_episode_reward": -138.08, "episode_reward_trend_value": -0.005428560615431542, "biggest_recent_change": 0.3828878396059281},
{"total_number_of_episodes": 8679, "number_of_timesteps": 979554, "per_episode_reward": -138.04, "episode_reward_trend_value": -0.0007349637403595782, "biggest_recent_change": 0.11324293389236573},
{"total_number_of_episodes": 8689, "number_of_timesteps": 980566, "per_episode_reward": -137.92, "episode_reward_trend_value": -0.000349878920857173, "biggest_recent_change": 0.12296056991340265},
{"total_number_of_episodes": 8699, "number_of_timesteps": 981766, "per_episode_reward": -138.19, "episode_reward_trend_value": -0.002297269974842051, "biggest_recent_change": 0.26830726784842795},
{"total_number_of_episodes": 8711, "number_of_timesteps": 983055, "per_episode_reward": -137.96, "episode_reward_trend_value": 0.0013276939166634823, "biggest_recent_change": 0.26830726784842795},
{"total_number_of_episodes": 8721, "number_of_timesteps": 984220, "per_episode_reward": -137.8, "episode_reward_trend_value": 0.001936459791751746, "biggest_recent_change": 0.26830726784842795},
{"total_number_of_episodes": 8731, "number_of_timesteps": 985428, "per_episode_reward": -137.81, "episode_reward_trend_value": 0.003061960649944871, "biggest_recent_change": 0.26830726784842795},
{"total_number_of_episodes": 8742, "number_of_timesteps": 986509, "per_episode_reward": -137.63, "episode_reward_trend_value": 0.005105025740319825, "biggest_recent_change": 0.26830726784842795},
{"total_number_of_episodes": 8752, "number_of_timesteps": 987509, "per_episode_reward": -137.59, "episode_reward_trend_value": 0.005249841683774371, "biggest_recent_change": 0.26830726784842795},
{"total_number_of_episodes": 8762, "number_of_timesteps": 988479, "per_episode_reward": -137.54, "episode_reward_trend_value": 0.005965571384329375, "biggest_recent_change": 0.26830726784842795},
{"total_number_of_episodes": 8772, "number_of_timesteps": 989706, "per_episode_reward": -137.48, "episode_reward_trend_value": 0.006208231422702207, "biggest_recent_change": 0.26830726784842795},
{"total_number_of_episodes": 8782, "number_of_timesteps": 990890, "per_episode_reward": -137.48, "episode_reward_trend_value": 0.0048758854384333165, "biggest_recent_change": 0.26830726784842795},
{"total_number_of_episodes": 8792, "number_of_timesteps": 992042, "per_episode_reward": -137.43, "episode_reward_trend_value": 0.008374928387020633, "biggest_recent_change": 0.22951539063438986},
{"total_number_of_episodes": 8802, "number_of_timesteps": 993140, "per_episode_reward": -137.54, "episode_reward_trend_value": 0.004662298389394929, "biggest_recent_change": 0.1784274252666478},
{"total_number_of_episodes": 8812, "number_of_timesteps": 994444, "per_episode_reward": -137.47, "episode_reward_trend_value": 0.0036777145118706916, "biggest_recent_change": 0.1784274252666478},
{"total_number_of_episodes": 8822, "number_of_timesteps": 995634, "per_episode_reward": -137.57, "episode_reward_trend_value": 0.00262585424868765, "biggest_recent_change": 0.1784274252666478},
{"total_number_of_episodes": 8832, "number_of_timesteps": 996676, "per_episode_reward": -137.53, "episode_reward_trend_value": 0.0011100427819674982, "biggest_recent_change": 0.10661528034145817},
{"total_number_of_episodes": 8842, "number_of_timesteps": 997760, "per_episode_reward": -137.6, "episode_reward_trend_value": -0.00011509872954604817, "biggest_recent_change": 0.10661528034145817},
{"total_number_of_episodes": 8852, "number_of_timesteps": 998899, "per_episode_reward": -137.7, "episode_reward_trend_value": -0.0017261037744374461, "biggest_recent_change": 0.10661528034145817},
{"total_number_of_episodes": 8862, "number_of_timesteps": 1000635, "per_episode_reward": -137.67, "episode_reward_trend_value": -0.0020585980420005654, "biggest_recent_change": 0.10661528034145817},
{"total_number_of_episodes": 8872, "number_of_timesteps": 1001750, "per_episode_reward": -137.68, "episode_reward_trend_value": -0.002177932150719799, "biggest_recent_change": 0.10661528034145817},
{"total_number_of_episodes": 8882, "number_of_timesteps": 1003217, "per_episode_reward": -137.68, "episode_reward_trend_value": -0.002705130787860968, "biggest_recent_change": 0.10661528034145817},
{"total_number_of_episodes": 8892, "number_of_timesteps": 1004626, "per_episode_reward": -137.74, "episode_reward_trend_value": -0.0022090970907858794, "biggest_recent_change": 0.10661528034145817},
{"total_number_of_episodes": 8902, "number_of_timesteps": 1005666, "per_episode_reward": -137.77, "episode_reward_trend_value": -0.0034178677889409904, "biggest_recent_change": 0.10661528034145817},
{"total_number_of_episodes": 8912, "number_of_timesteps": 1006544, "per_episode_reward": -137.7, "episode_reward_trend_value": -0.001378898948193018, "biggest_recent_change": 0.10298606077839167},
{"total_number_of_episodes": 8922, "number_of_timesteps": 1007539, "per_episode_reward": -137.75, "episode_reward_trend_value": -0.0024502674744948335, "biggest_recent_change": 0.10298606077839167},
{"total_number_of_episodes": 8932, "number_of_timesteps": 1008792, "per_episode_reward": -137.74, "episode_reward_trend_value": -0.0016003413424944784, "biggest_recent_change": 0.10298606077839167},
{"total_number_of_episodes": 8942, "number_of_timesteps": 1009840, "per_episode_reward": -137.73, "episode_reward_trend_value": -0.0003943952314446935, "biggest_recent_change": 0.07689191532585937},
{"total_number_of_episodes": 8953, "number_of_timesteps": 1011168, "per_episode_reward": -137.66, "episode_reward_trend_value": 0.0001048330790275208, "biggest_recent_change": 0.07689191532585937},
{"total_number_of_episodes": 8963, "number_of_timesteps": 1012120, "per_episode_reward": -137.67, "episode_reward_trend_value": 5.207313828445118e-05, "biggest_recent_change": 0.07689191532585937},
{"total_number_of_episodes": 8973, "number_of_timesteps": 1013022, "per_episode_reward": -137.63, "episode_reward_trend_value": 0.0005285265460347293, "biggest_recent_change": 0.07689191532585937},
{"total_number_of_episodes": 8983, "number_of_timesteps": 1013968, "per_episode_reward": -137.59, "episode_reward_trend_value": 0.0016344112820986666, "biggest_recent_change": 0.07689191532585937},
{"total_number_of_episodes": 8993, "number_of_timesteps": 1015137, "per_episode_reward": -137.5, "episode_reward_trend_value": 0.003026519079098951, "biggest_recent_change": 0.08681528302722086},
{"total_number_of_episodes": 9003, "number_of_timesteps": 1016184, "per_episode_reward": -137.46, "episode_reward_trend_value": 0.0026385104557217825, "biggest_recent_change": 0.08681528302722086},
{"total_number_of_episodes": 9013, "number_of_timesteps": 1017372, "per_episode_reward": -137.45, "episode_reward_trend_value": 0.003360518123448565, "biggest_recent_change": 0.08681528302722086},
{"total_number_of_episodes": 9023, "number_of_timesteps": 1018706, "per_episode_reward": -137.48, "episode_reward_trend_value": 0.002928063915277966, "biggest_recent_change": 0.08681528302722086},
{"total_number_of_episodes": 9033, "number_of_timesteps": 1019682, "per_episode_reward": -137.47, "episode_reward_trend_value": 0.0029053920211089867, "biggest_recent_change": 0.08681528302722086},
{"total_number_of_episodes": 9043, "number_of_timesteps": 1020741, "per_episode_reward": -137.56, "episode_reward_trend_value": 0.0010996104877007283, "biggest_recent_change": 0.08681528302722086},
{"total_number_of_episodes": 9053, "number_of_timesteps": 1022328, "per_episode_reward": -137.47, "episode_reward_trend_value": 0.0022336805453581593, "biggest_recent_change": 0.08962727206676391},
{"total_number_of_episodes": 9063, "number_of_timesteps": 1023054, "per_episode_reward": -137.38, "episode_reward_trend_value": 0.002707512524034428, "biggest_recent_change": 0.08962727206676391},
{"total_number_of_episodes": 9073, "number_of_timesteps": 1023771, "per_episode_reward": -137.28, "episode_reward_trend_value": 0.0034123755973028995, "biggest_recent_change": 0.10298902642475127},
{"total_number_of_episodes": 9083, "number_of_timesteps": 1024449, "per_episode_reward": -137.12, "episode_reward_trend_value": 0.004283206451041287, "biggest_recent_change": 0.16519005986367574},
{"total_number_of_episodes": 9093, "number_of_timesteps": 1025121, "per_episode_reward": -136.93, "episode_reward_trend_value": 0.00585860329738384, "biggest_recent_change": 0.183756855392744},
{"total_number_of_episodes": 9103, "number_of_timesteps": 1025877, "per_episode_reward": -136.8, "episode_reward_trend_value": 0.0072287149540478084, "biggest_recent_change": 0.183756855392744},
{"total_number_of_episodes": 9114, "number_of_timesteps": 1026675, "per_episode_reward": -136.74, "episode_reward_trend_value": 0.008174575488451158, "biggest_recent_change": 0.183756855392744},
{"total_number_of_episodes": 9124, "number_of_timesteps": 1027393, "per_episode_reward": -136.63, "episode_reward_trend_value": 0.00934108541659542, "biggest_recent_change": 0.183756855392744},
{"total_number_of_episodes": 9135, "number_of_timesteps": 1028262, "per_episode_reward": -136.56, "episode_reward_trend_value": 0.011096072025481855, "biggest_recent_change": 0.183756855392744},
{"total_number_of_episodes": 9145, "number_of_timesteps": 1029135, "per_episode_reward": -136.51, "episode_reward_trend_value": 0.010616106989483063, "biggest_recent_change": 0.183756855392744},
{"total_number_of_episodes": 9155, "number_of_timesteps": 1030273, "per_episode_reward": -136.56, "episode_reward_trend_value": 0.009149568515916763, "biggest_recent_change": 0.183756855392744},
{"total_number_of_episodes": 9165, "number_of_timesteps": 1031497, "per_episode_reward": -136.58, "episode_reward_trend_value": 0.00784501334912717, "biggest_recent_change": 0.183756855392744},
{"total_number_of_episodes": 9176, "number_of_timesteps": 1033371, "per_episode_reward": -136.61, "episode_reward_trend_value": 0.005590043303275946, "biggest_recent_change": 0.183756855392744},
{"total_number_of_episodes": 9186, "number_of_timesteps": 1034706, "per_episode_reward": -136.64, "episode_reward_trend_value": 0.003250055024435975, "biggest_recent_change": 0.13387196508983834},
{"total_number_of_episodes": 9196, "number_of_timesteps": 1035840, "per_episode_reward": -136.59, "episode_reward_trend_value": 0.002368446580441565, "biggest_recent_change": 0.10849451227386453},
{"total_number_of_episodes": 9207, "number_of_timesteps": 1036956, "per_episode_reward": -136.62, "episode_reward_trend_value": 0.0012935743178571911, "biggest_recent_change": 0.10849451227386453},
{"total_number_of_episodes": 9217, "number_of_timesteps": 1038317, "per_episode_reward": -136.58, "episode_reward_trend_value": 0.0005453961306901394, "biggest_recent_change": 0.07180980325895803},
{"total_number_of_episodes": 9227, "number_of_timesteps": 1039692, "per_episode_reward": -136.53, "episode_reward_trend_value": 0.00030321399707765475, "biggest_recent_change": 0.05452720513034137},
{"total_number_of_episodes": 9237, "number_of_timesteps": 1041078, "per_episode_reward": -136.54, "episode_reward_trend_value": -0.0002318650490571549, "biggest_recent_change": 0.05452720513034137},
{"total_number_of_episodes": 9247, "number_of_timesteps": 1042106, "per_episode_reward": -136.47, "episode_reward_trend_value": 0.0009926953744796821, "biggest_recent_change": 0.06290638045746277},
{"total_number_of_episodes": 9257, "number_of_timesteps": 1043241, "per_episode_reward": -136.44, "episode_reward_trend_value": 0.0014993739057966118, "biggest_recent_change": 0.06290638045746277},
{"total_number_of_episodes": 9267, "number_of_timesteps": 1044328, "per_episode_reward": -136.47, "episode_reward_trend_value": 0.0015671894264342099, "biggest_recent_change": 0.06290638045746277},
{"total_number_of_episodes": 9278, "number_of_timesteps": 1045357, "per_episode_reward": -136.38, "episode_reward_trend_value": 0.0028416436582653485, "biggest_recent_change": 0.08785879116194906},
{"total_number_of_episodes": 9288, "number_of_timesteps": 1046422, "per_episode_reward": -136.37, "episode_reward_trend_value": 0.0023499255108633734, "biggest_recent_change": 0.08785879116194906},
{"total_number_of_episodes": 9298, "number_of_timesteps": 1047477, "per_episode_reward": -136.27, "episode_reward_trend_value": 0.003991062180924447, "biggest_recent_change": 0.10918637963555966},
{"total_number_of_episodes": 9308, "number_of_timesteps": 1048349, "per_episode_reward": -136.16, "episode_reward_trend_value": 0.0047137238203220026, "biggest_recent_change": 0.10918637963555966},
{"total_number_of_episodes": 9318, "number_of_timesteps": 1049314, "per_episode_reward": -136.21, "episode_reward_trend_value": 0.00359488228255, "biggest_recent_change": 0.10918637963555966},
{"total_number_of_episodes": 9328, "number_of_timesteps": 1050319, "per_episode_reward": -136.22, "episode_reward_trend_value": 0.0034663811977392496, "biggest_recent_change": 0.10918637963555966},
{"total_number_of_episodes": 9338, "number_of_timesteps": 1051425, "per_episode_reward": -136.31, "episode_reward_trend_value": 0.001840138733654031, "biggest_recent_change": 0.10918637963555966},
{"total_number_of_episodes": 9348, "number_of_timesteps": 1052872, "per_episode_reward": -136.25, "episode_reward_trend_value": 0.0021000800752353317, "biggest_recent_change": 0.10918637963555966},
{"total_number_of_episodes": 9358, "number_of_timesteps": 1053991, "per_episode_reward": -136.33, "episode_reward_trend_value": 0.001535530171331819, "biggest_recent_change": 0.10918637963555966},
{"total_number_of_episodes": 9368, "number_of_timesteps": 1055075, "per_episode_reward": -136.09, "episode_reward_trend_value": 0.003255143456302613, "biggest_recent_change": 0.2426239868093205},
{"total_number_of_episodes": 9378, "number_of_timesteps": 1055931, "per_episode_reward": -136.01, "episode_reward_trend_value": 0.004092427953038521, "biggest_recent_change": 0.2426239868093205},
{"total_number_of_episodes": 9388, "number_of_timesteps": 1057083, "per_episode_reward": -135.99, "episode_reward_trend_value": 0.0030954817057145573, "biggest_recent_change": 0.2426239868093205},
{"total_number_of_episodes": 9398, "number_of_timesteps": 1058080, "per_episode_reward": -135.97, "episode_reward_trend_value": 0.00212471816368836, "biggest_recent_change": 0.2426239868093205},
{"total_number_of_episodes": 9408, "number_of_timesteps": 1059082, "per_episode_reward": -136.02, "episode_reward_trend_value": 0.0020734216522530205, "biggest_recent_change": 0.2426239868093205},
{"total_number_of_episodes": 9418, "number_of_timesteps": 1060196, "per_episode_reward": -136.03, "episode_reward_trend_value": 0.0021272511102122535, "biggest_recent_change": 0.2426239868093205},
{"total_number_of_episodes": 9428, "number_of_timesteps": 1061868, "per_episode_reward": -136.02, "episode_reward_trend_value": 0.003172635792448217, "biggest_recent_change": 0.2426239868093205},
{"total_number_of_episodes": 9438, "number_of_timesteps": 1063252, "per_episode_reward": -135.97, "episode_reward_trend_value": 0.0031828812878855056, "biggest_recent_change": 0.2426239868093205},
{"total_number_of_episodes": 9448, "number_of_timesteps": 1064382, "per_episode_reward": -135.91, "episode_reward_trend_value": 0.004749035784250408, "biggest_recent_change": 0.2426239868093205},
{"total_number_of_episodes": 9458, "number_of_timesteps": 1065431, "per_episode_reward": -135.95, "episode_reward_trend_value": 0.0016125330227721533, "biggest_recent_change": 0.08562817657039545},
{"total_number_of_episodes": 9469, "number_of_timesteps": 1066836, "per_episode_reward": -135.94, "episode_reward_trend_value": 0.000769064706119909, "biggest_recent_change": 0.05849056591597446},
{"total_number_of_episodes": 9479, "number_of_timesteps": 1067897, "per_episode_reward": -135.85, "episode_reward_trend_value": 0.0014853497983842267, "biggest_recent_change": 0.08392687568019142},
{"total_number_of_episodes": 9489, "number_of_timesteps": 1068930, "per_episode_reward": -135.81, "episode_reward_trend_value": 0.0017563602191902165, "biggest_recent_change": 0.08392687568019142},
{"total_number_of_episodes": 9500, "number_of_timesteps": 1070486, "per_episode_reward": -135.92, "episode_reward_trend_value": 0.0010934978869367265, "biggest_recent_change": 0.11495662309764043},
{"total_number_of_episodes": 9512, "number_of_timesteps": 1072043, "per_episode_reward": -135.94, "episode_reward_trend_value": 0.0009868456003804087, "biggest_recent_change": 0.11495662309764043},
{"total_number_of_episodes": 9522, "number_of_timesteps": 1073271, "per_episode_reward": -135.92, "episode_reward_trend_value": 0.0011595316635786427, "biggest_recent_change": 0.11495662309764043},
{"total_number_of_episodes": 9532, "number_of_timesteps": 1074474, "per_episode_reward": -135.92, "episode_reward_trend_value": 0.0005264316379165418, "biggest_recent_change": 0.11495662309764043},
{"total_number_of_episodes": 9542, "number_of_timesteps": 1075807, "per_episode_reward": -135.93, "episode_reward_trend_value": -0.00025765024920663867, "biggest_recent_change": 0.11495662309764043},
{"total_number_of_episodes": 9552, "number_of_timesteps": 1077105, "per_episode_reward": -135.96, "episode_reward_trend_value": -9.882567459966492e-05, "biggest_recent_change": 0.11495662309764043},
{"total_number_of_episodes": 9562, "number_of_timesteps": 1078291, "per_episode_reward": -135.89, "episode_reward_trend_value": 0.000549202397937481, "biggest_recent_change": 0.11495662309764043},
{"total_number_of_episodes": 9573, "number_of_timesteps": 1079589, "per_episode_reward": -135.99, "episode_reward_trend_value": -0.0014844119157901205, "biggest_recent_change": 0.11495662309764043},
{"total_number_of_episodes": 9583, "number_of_timesteps": 1080865, "per_episode_reward": -136.0, "episode_reward_trend_value": -0.0021638895356034028, "biggest_recent_change": 0.11495662309764043},
{"total_number_of_episodes": 9593, "number_of_timesteps": 1082211, "per_episode_reward": -136.15, "episode_reward_trend_value": -0.002465367409839953, "biggest_recent_change": 0.14208963177892997},
{"total_number_of_episodes": 9604, "number_of_timesteps": 1083593, "per_episode_reward": -136.16, "episode_reward_trend_value": -0.002451636239032319, "biggest_recent_change": 0.14208963177892997},
{"total_number_of_episodes": 9614, "number_of_timesteps": 1084595, "per_episode_reward": -136.08, "episode_reward_trend_value": -0.001791112923402554, "biggest_recent_change": 0.14208963177892997},
{"total_number_of_episodes": 9624, "number_of_timesteps": 1085540, "per_episode_reward": -135.96, "episode_reward_trend_value": -0.0004149644700270806, "biggest_recent_change": 0.14208963177892997},
{"total_number_of_episodes": 9635, "number_of_timesteps": 1086903, "per_episode_reward": -135.92, "episode_reward_trend_value": 8.036316483968323e-05, "biggest_recent_change": 0.14208963177892997},
{"total_number_of_episodes": 9645, "number_of_timesteps": 1087978, "per_episode_reward": -135.92, "episode_reward_trend_value": 0.00036493982526811426, "biggest_recent_change": 0.14208963177892997},
{"total_number_of_episodes": 9655, "number_of_timesteps": 1089015, "per_episode_reward": -135.89, "episode_reward_trend_value": -3.573085400224348e-05, "biggest_recent_change": 0.14208963177892997},
{"total_number_of_episodes": 9665, "number_of_timesteps": 1089952, "per_episode_reward": -135.79, "episode_reward_trend_value": 0.0021435163390937833, "biggest_recent_change": 0.14208963177892997},
{"total_number_of_episodes": 9675, "number_of_timesteps": 1091250, "per_episode_reward": -135.78, "episode_reward_trend_value": 0.0025163148174789916, "biggest_recent_change": 0.14208963177892997},
{"total_number_of_episodes": 9685, "number_of_timesteps": 1092326, "per_episode_reward": -135.78, "episode_reward_trend_value": 0.004064890281418343, "biggest_recent_change": 0.12237130305808819},
{"total_number_of_episodes": 9695, "number_of_timesteps": 1093491, "per_episode_reward": -135.82, "episode_reward_trend_value": 0.003862597732190428, "biggest_recent_change": 0.12237130305808819},
{"total_number_of_episodes": 9705, "number_of_timesteps": 1094804, "per_episode_reward": -135.88, "episode_reward_trend_value": 0.0021684802226183643, "biggest_recent_change": 0.12237130305808819},
{"total_number_of_episodes": 9715, "number_of_timesteps": 1096179, "per_episode_reward": -135.88, "episode_reward_trend_value": 0.0008473869237087051, "biggest_recent_change": 0.09703383482334971},
{"total_number_of_episodes": 9725, "number_of_timesteps": 1097299, "per_episode_reward": -135.88, "episode_reward_trend_value": 0.00047858178708679586, "biggest_recent_change": 0.09703383482334971},
{"total_number_of_episodes": 9736, "number_of_timesteps": 1099201, "per_episode_reward": -135.98, "episode_reward_trend_value": -0.0006746200012088365, "biggest_recent_change": 0.10354331151714291},
{"total_number_of_episodes": 9746, "number_of_timesteps": 1100541, "per_episode_reward": -136.04, "episode_reward_trend_value": -0.0016486072460395462, "biggest_recent_change": 0.10354331151714291},
{"total_number_of_episodes": 9756, "number_of_timesteps": 1101581, "per_episode_reward": -135.88, "episode_reward_trend_value": -0.0009215725826824913, "biggest_recent_change": 0.16246695452548465},
{"total_number_of_episodes": 9767, "number_of_timesteps": 1102433, "per_episode_reward": -135.84, "episode_reward_trend_value": -0.0006528389663837213, "biggest_recent_change": 0.16246695452548465},
{"total_number_of_episodes": 9777, "number_of_timesteps": 1103353, "per_episode_reward": -135.8, "episode_reward_trend_value": -0.00020678150944743518, "biggest_recent_change": 0.16246695452548465},
{"total_number_of_episodes": 9787, "number_of_timesteps": 1104636, "per_episode_reward": -135.78, "episode_reward_trend_value": 0.0004186751646200391, "biggest_recent_change": 0.16246695452548465},
{"total_number_of_episodes": 9797, "number_of_timesteps": 1105514, "per_episode_reward": -135.65, "episode_reward_trend_value": 0.0025847044662492004, "biggest_recent_change": 0.16246695452548465},
{"total_number_of_episodes": 9807, "number_of_timesteps": 1107063, "per_episode_reward": -135.74, "episode_reward_trend_value": 0.001515162356855626, "biggest_recent_change": 0.16246695452548465},
{"total_number_of_episodes": 9817, "number_of_timesteps": 1108004, "per_episode_reward": -135.74, "episode_reward_trend_value": 0.0015259034434462946, "biggest_recent_change": 0.16246695452548465},
{"total_number_of_episodes": 9827, "number_of_timesteps": 1109114, "per_episode_reward": -135.68, "episode_reward_trend_value": 0.0033605106897769904, "biggest_recent_change": 0.16246695452548465},
{"total_number_of_episodes": 9837, "number_of_timesteps": 1110424, "per_episode_reward": -135.74, "episode_reward_trend_value": 0.0032889383948334705, "biggest_recent_change": 0.16246695452548465},
{"total_number_of_episodes": 9847, "number_of_timesteps": 1111797, "per_episode_reward": -135.81, "episode_reward_trend_value": 0.000707464949335051, "biggest_recent_change": 0.12809008547068856},
{"total_number_of_episodes": 9857, "number_of_timesteps": 1112990, "per_episode_reward": -135.82, "episode_reward_trend_value": 0.0002342798910739753, "biggest_recent_change": 0.12809008547068856},
{"total_number_of_episodes": 9867, "number_of_timesteps": 1114006, "per_episode_reward": -135.76, "episode_reward_trend_value": 0.00043022055799263445, "biggest_recent_change": 0.12809008547068856},
{"total_number_of_episodes": 9877, "number_of_timesteps": 1115166, "per_episode_reward": -135.82, "episode_reward_trend_value": -0.0005048888499377174, "biggest_recent_change": 0.12809008547068856},
{"total_number_of_episodes": 9887, "number_of_timesteps": 1116530, "per_episode_reward": -135.86, "episode_reward_trend_value": -0.0023420846591692326, "biggest_recent_change": 0.09278588368920282},
{"total_number_of_episodes": 9898, "number_of_timesteps": 1117651, "per_episode_reward": -135.86, "episode_reward_trend_value": -0.0013568223470498551, "biggest_recent_change": 0.06986565556937308},
{"total_number_of_episodes": 9909, "number_of_timesteps": 1118668, "per_episode_reward": -135.83, "episode_reward_trend_value": -0.0009367066551334346, "biggest_recent_change": 0.06986565556937308},
{"total_number_of_episodes": 9920, "number_of_timesteps": 1120694, "per_episode_reward": -135.85, "episode_reward_trend_value": -0.0018805039782607638, "biggest_recent_change": 0.06986565556937308},
{"total_number_of_episodes": 9930, "number_of_timesteps": 1121969, "per_episode_reward": -135.89, "episode_reward_trend_value": -0.001585970969470433, "biggest_recent_change": 0.06986565556937308},
{"total_number_of_episodes": 9940, "number_of_timesteps": 1122976, "per_episode_reward": -135.87, "episode_reward_trend_value": -0.000656857921410392, "biggest_recent_change": 0.06288511763744964},
{"total_number_of_episodes": 9950, "number_of_timesteps": 1124123, "per_episode_reward": -135.82, "episode_reward_trend_value": -2.3329377609747503e-05, "biggest_recent_change": 0.06288511763744964},
{"total_number_of_episodes": 9960, "number_of_timesteps": 1125168, "per_episode_reward": -135.83, "episode_reward_trend_value": -0.0007730306377441012, "biggest_recent_change": 0.06288511763744964},
{"total_number_of_episodes": 9970, "number_of_timesteps": 1126212, "per_episode_reward": -135.81, "episode_reward_trend_value": 0.00013669550866508314, "biggest_recent_change": 0.05423605850171498},
{"total_number_of_episodes": 9980, "number_of_timesteps": 1127390, "per_episode_reward": -135.82, "episode_reward_trend_value": 0.0004318749365741799, "biggest_recent_change": 0.05423605850171498},
{"total_number_of_episodes": 9991, "number_of_timesteps": 1128341, "per_episode_reward": -135.79, "episode_reward_trend_value": 0.0007963023975476189, "biggest_recent_change": 0.05423605850171498},
{"total_number_of_episodes": 10001, "number_of_timesteps": 1129449, "per_episode_reward": -135.8, "episode_reward_trend_value": 0.00030547272446786644, "biggest_recent_change": 0.05423605850171498},
{"total_number_of_episodes": 10013, "number_of_timesteps": 1130974, "per_episode_reward": -135.83, "episode_reward_trend_value": 0.00017831403832941657, "biggest_recent_change": 0.05423605850171498},
{"total_number_of_episodes": 10023, "number_of_timesteps": 1132040, "per_episode_reward": -135.83, "episode_reward_trend_value": 0.0005655849761353693, "biggest_recent_change": 0.05423605850171498},
{"total_number_of_episodes": 10033, "number_of_timesteps": 1133117, "per_episode_reward": -135.84, "episode_reward_trend_value": 0.00038689420067612447, "biggest_recent_change": 0.05423605850171498},
{"total_number_of_episodes": 10043, "number_of_timesteps": 1134411, "per_episode_reward": -135.99, "episode_reward_trend_value": -0.0019181122661633607, "biggest_recent_change": 0.15321452351383869},
{"total_number_of_episodes": 10054, "number_of_timesteps": 1135374, "per_episode_reward": -135.85, "episode_reward_trend_value": -0.00025503082438610317, "biggest_recent_change": 0.15321452351383869},
{"total_number_of_episodes": 10064, "number_of_timesteps": 1136553, "per_episode_reward": -135.84, "episode_reward_trend_value": -0.0003482041419879857, "biggest_recent_change": 0.15321452351383869},
{"total_number_of_episodes": 10074, "number_of_timesteps": 1137707, "per_episode_reward": -135.8, "episode_reward_trend_value": 0.00020918405177812677, "biggest_recent_change": 0.15321452351383869},
{"total_number_of_episodes": 10084, "number_of_timesteps": 1138764, "per_episode_reward": -135.87, "episode_reward_trend_value": -0.0008327560943481811, "biggest_recent_change": 0.15321452351383869},
{"total_number_of_episodes": 10094, "number_of_timesteps": 1140147, "per_episode_reward": -135.88, "episode_reward_trend_value": -0.0008981467835386385, "biggest_recent_change": 0.15321452351383869},

{"total_number_of_episodes": 10104, "number_of_timesteps": 1140945, "per_episode_reward": -135.82, "episode_reward_trend_value": 0.00014171892592824203, "biggest_recent_change": 0.15321452351383869},
{"total_number_of_episodes": 10115, "number_of_timesteps": 1141799, "per_episode_reward": -135.71, "episode_reward_trend_value": 0.0013943853738560897, "biggest_recent_change": 0.15321452351383869},
{"total_number_of_episodes": 10125, "number_of_timesteps": 1142678, "per_episode_reward": -135.63, "episode_reward_trend_value": 0.002266308741011534, "biggest_recent_change": 0.15321452351383869},
{"total_number_of_episodes": 10135, "number_of_timesteps": 1143978, "per_episode_reward": -135.71, "episode_reward_trend_value": 0.003090748204219393, "biggest_recent_change": 0.13726620747041807},
{"total_number_of_episodes": 10145, "number_of_timesteps": 1145460, "per_episode_reward": -135.74, "episode_reward_trend_value": 0.001203612706241112, "biggest_recent_change": 0.11198017039319552},
{"total_number_of_episodes": 10155, "number_of_timesteps": 1146761, "per_episode_reward": -135.75, "episode_reward_trend_value": 0.0009788949830809516, "biggest_recent_change": 0.11198017039319552},
{"total_number_of_episodes": 10165, "number_of_timesteps": 1148051, "per_episode_reward": -135.76, "episode_reward_trend_value": 0.00046500734321897297, "biggest_recent_change": 0.11198017039319552},
{"total_number_of_episodes": 10175, "number_of_timesteps": 1149589, "per_episode_reward": -135.73, "episode_reward_trend_value": 0.0014984209290743265, "biggest_recent_change": 0.11198017039319552},
{"total_number_of_episodes": 10185, "number_of_timesteps": 1150483, "per_episode_reward": -135.69, "episode_reward_trend_value": 0.002086363100654391, "biggest_recent_change": 0.11198017039319552},
{"total_number_of_episodes": 10195, "number_of_timesteps": 1151552, "per_episode_reward": -135.68, "episode_reward_trend_value": 0.0016084803843666705, "biggest_recent_change": 0.11198017039319552},
{"total_number_of_episodes": 10205, "number_of_timesteps": 1152613, "per_episode_reward": -135.59, "episode_reward_trend_value": 0.0013261944575055573, "biggest_recent_change": 0.08657443697569533},
{"total_number_of_episodes": 10215, "number_of_timesteps": 1153927, "per_episode_reward": -135.76, "episode_reward_trend_value": -0.0014135844576173896, "biggest_recent_change": 0.1704346503523766},
{"total_number_of_episodes": 10225, "number_of_timesteps": 1155269, "per_episode_reward": -135.8, "episode_reward_trend_value": -0.0009487896603625737, "biggest_recent_change": 0.1704346503523766},
{"total_number_of_episodes": 10235, "number_of_timesteps": 1156182, "per_episode_reward": -135.76, "episode_reward_trend_value": -0.00020167128277535085, "biggest_recent_change": 0.1704346503523766},
{"total_number_of_episodes": 10245, "number_of_timesteps": 1156981, "per_episode_reward": -135.7, "episode_reward_trend_value": 0.0005764883453556042, "biggest_recent_change": 0.1704346503523766},
{"total_number_of_episodes": 10255, "number_of_timesteps": 1158198, "per_episode_reward": -135.78, "episode_reward_trend_value": -0.0001876690550381631, "biggest_recent_change": 0.1704346503523766},
{"total_number_of_episodes": 10265, "number_of_timesteps": 1159675, "per_episode_reward": -135.76, "episode_reward_trend_value": -0.0003508158089946139, "biggest_recent_change": 0.1704346503523766},
{"total_number_of_episodes": 10276, "number_of_timesteps": 1160967, "per_episode_reward": -135.81, "episode_reward_trend_value": -0.0013452776199222348, "biggest_recent_change": 0.1704346503523766},
{"total_number_of_episodes": 10286, "number_of_timesteps": 1162484, "per_episode_reward": -135.8, "episode_reward_trend_value": -0.0013607959859964721, "biggest_recent_change": 0.1704346503523766},
{"total_number_of_episodes": 10296, "number_of_timesteps": 1163713, "per_episode_reward": -135.82, "episode_reward_trend_value": -0.00253205117099987, "biggest_recent_change": 0.1704346503523766},
{"total_number_of_episodes": 10306, "number_of_timesteps": 1164785, "per_episode_reward": -135.8, "episode_reward_trend_value": -0.0004272060622301726, "biggest_recent_change": 0.07555050503239613},
{"total_number_of_episodes": 10316, "number_of_timesteps": 1166075, "per_episode_reward": -135.88, "episode_reward_trend_value": -0.0009198090644288313, "biggest_recent_change": 0.08151771027007726},
{"total_number_of_episodes": 10326, "number_of_timesteps": 1167470, "per_episode_reward": -135.86, "episode_reward_trend_value": -0.0011312789330812875, "biggest_recent_change": 0.08151771027007726},
{"total_number_of_episodes": 10336, "number_of_timesteps": 1168425, "per_episode_reward": -135.81, "episode_reward_trend_value": -0.0011616630734298243, "biggest_recent_change": 0.08151771027007726},
{"total_number_of_episodes": 10346, "number_of_timesteps": 1169850, "per_episode_reward": -135.81, "episode_reward_trend_value": -0.0003959703959146231, "biggest_recent_change": 0.08151771027007726},
{"total_number_of_episodes": 10356, "number_of_timesteps": 1171164, "per_episode_reward": -135.84, "episode_reward_trend_value": -0.0008449246110176191, "biggest_recent_change": 0.08151771027007726},
{"total_number_of_episodes": 10366, "number_of_timesteps": 1172532, "per_episode_reward": -135.84, "episode_reward_trend_value": -0.00027620847349586107, "biggest_recent_change": 0.08151771027007726},
{"total_number_of_episodes": 10376, "number_of_timesteps": 1173767, "per_episode_reward": -135.82, "episode_reward_trend_value": -0.000220468396928671, "biggest_recent_change": 0.08151771027007726},
{"total_number_of_episodes": 10386, "number_of_timesteps": 1174906, "per_episode_reward": -135.74, "episode_reward_trend_value": 0.0008285331614460902, "biggest_recent_change": 0.08151771027007726},
{"total_number_of_episodes": 10396, "number_of_timesteps": 1175972, "per_episode_reward": -135.69, "episode_reward_trend_value": 0.0012636914372273446, "biggest_recent_change": 0.08151771027007726},
{"total_number_of_episodes": 10406, "number_of_timesteps": 1176997, "per_episode_reward": -135.64, "episode_reward_trend_value": 0.0026297196433328436, "biggest_recent_change": 0.07557161057911799},
{"total_number_of_episodes": 10416, "number_of_timesteps": 1178038, "per_episode_reward": -135.63, "episode_reward_trend_value": 0.0025897845479612948, "biggest_recent_change": 0.07557161057911799},
{"total_number_of_episodes": 10426, "number_of_timesteps": 1179190, "per_episode_reward": -135.6, "episode_reward_trend_value": 0.0022866510931947915, "biggest_recent_change": 0.07557161057911799},
{"total_number_of_episodes": 10436, "number_of_timesteps": 1180309, "per_episode_reward": -135.62, "episode_reward_trend_value": 0.0021373867267856085, "biggest_recent_change": 0.07557161057911799},
{"total_number_of_episodes": 10446, "number_of_timesteps": 1181888, "per_episode_reward": -135.71, "episode_reward_trend_value": 0.001496694316953848, "biggest_recent_change": 0.0848325986354439},
{"total_number_of_episodes": 10456, "number_of_timesteps": 1182896, "per_episode_reward": -135.66, "episode_reward_trend_value": 0.0019491940946102834, "biggest_recent_change": 0.0848325986354439},
{"total_number_of_episodes": 10466, "number_of_timesteps": 1184165, "per_episode_reward": -135.67, "episode_reward_trend_value": 0.0016585267374305585, "biggest_recent_change": 0.0848325986354439},
{"total_number_of_episodes": 10476, "number_of_timesteps": 1185103, "per_episode_reward": -135.6, "episode_reward_trend_value": 0.0016191500804252554, "biggest_recent_change": 0.0848325986354439},
{"total_number_of_episodes": 10486, "number_of_timesteps": 1185922, "per_episode_reward": -135.6, "episode_reward_trend_value": 0.0009897898905829076, "biggest_recent_change": 0.0848325986354439},
{"total_number_of_episodes": 10498, "number_of_timesteps": 1187008, "per_episode_reward": -135.41, "episode_reward_trend_value": 0.0025801127027878894, "biggest_recent_change": 0.184553881377866},
{"total_number_of_episodes": 10508, "number_of_timesteps": 1188304, "per_episode_reward": -135.57, "episode_reward_trend_value": 0.0006494690989727461, "biggest_recent_change": 0.184553881377866},
{"total_number_of_episodes": 10518, "number_of_timesteps": 1189527, "per_episode_reward": -135.69, "episode_reward_trend_value": -0.0010062488778004308, "biggest_recent_change": 0.184553881377866},
{"total_number_of_episodes": 10528, "number_of_timesteps": 1190807, "per_episode_reward": -135.66, "episode_reward_trend_value": -0.00040064898678685446, "biggest_recent_change": 0.184553881377866},
{"total_number_of_episodes": 10538, "number_of_timesteps": 1192383, "per_episode_reward": -135.72, "episode_reward_trend_value": -0.00013524749926906073, "biggest_recent_change": 0.184553881377866},
{"total_number_of_episodes": 10548, "number_of_timesteps": 1193336, "per_episode_reward": -135.62, "episode_reward_trend_value": 0.0004334767642240599, "biggest_recent_change": 0.184553881377866},
{"total_number_of_episodes": 10558, "number_of_timesteps": 1194381, "per_episode_reward": -135.71, "episode_reward_trend_value": -0.0004184099244197468, "biggest_recent_change": 0.184553881377866},
{"total_number_of_episodes": 10568, "number_of_timesteps": 1195652, "per_episode_reward": -135.77, "episode_reward_trend_value": -0.0018617036008906653, "biggest_recent_change": 0.184553881377866},
{"total_number_of_episodes": 10578, "number_of_timesteps": 1196948, "per_episode_reward": -135.75, "episode_reward_trend_value": -0.0017037327005946662, "biggest_recent_change": 0.184553881377866},
{"total_number_of_episodes": 10588, "number_of_timesteps": 1197890, "per_episode_reward": -135.69, "episode_reward_trend_value": -0.0031050483802867275, "biggest_recent_change": 0.16171970447030048},
{"total_number_of_episodes": 10598, "number_of_timesteps": 1199023, "per_episode_reward": -135.67, "episode_reward_trend_value": -0.001028583593908176, "biggest_recent_change": 0.1186167930673605},
{"total_number_of_episodes": 10608, "number_of_timesteps": 1200091, "per_episode_reward": -135.74, "episode_reward_trend_value": -0.0005039823879997129, "biggest_recent_change": 0.09453534691738241},
{"total_number_of_episodes": 10618, "number_of_timesteps": 1201043, "per_episode_reward": -135.66, "episode_reward_trend_value": -6.364406378591209e-05, "biggest_recent_change": 0.09453534691738241},
{"total_number_of_episodes": 10628, "number_of_timesteps": 1201801, "per_episode_reward": -135.55, "episode_reward_trend_value": 0.0018508313451848027, "biggest_recent_change": 0.11135632204852186},
{"total_number_of_episodes": 10638, "number_of_timesteps": 1202729, "per_episode_reward": -135.47, "episode_reward_trend_value": 0.001694721021488969, "biggest_recent_change": 0.11135632204852186},
{"total_number_of_episodes": 10649, "number_of_timesteps": 1204067, "per_episode_reward": -135.51, "episode_reward_trend_value": 0.002246533274827635, "biggest_recent_change": 0.11135632204852186},
{"total_number_of_episodes": 10659, "number_of_timesteps": 1205322, "per_episode_reward": -135.44, "episode_reward_trend_value": 0.0035709514038002347, "biggest_recent_change": 0.11135632204852186},
{"total_number_of_episodes": 10669, "number_of_timesteps": 1206429, "per_episode_reward": -135.46, "episode_reward_trend_value": 0.003264032411699228, "biggest_recent_change": 0.11135632204852186},
{"total_number_of_episodes": 10679, "number_of_timesteps": 1207582, "per_episode_reward": -135.45, "episode_reward_trend_value": 0.0026739916241297125, "biggest_recent_change": 0.11135632204852186},
{"total_number_of_episodes": 10689, "number_of_timesteps": 1208646, "per_episode_reward": -135.41, "episode_reward_trend_value": 0.0028904811868497087, "biggest_recent_change": 0.11135632204852186},
{"total_number_of_episodes": 10700, "number_of_timesteps": 1209835, "per_episode_reward": -135.4, "episode_reward_trend_value": 0.003795783274663083, "biggest_recent_change": 0.11135632204852186},
{"total_number_of_episodes": 10710, "number_of_timesteps": 1211079, "per_episode_reward": -135.37, "episode_reward_trend_value": 0.0032753462869581857, "biggest_recent_change": 0.11135632204852186},
{"total_number_of_episodes": 10720, "number_of_timesteps": 1212308, "per_episode_reward": -135.41, "episode_reward_trend_value": 0.0015642400706203335, "biggest_recent_change": 0.08048541778475737},
{"total_number_of_episodes": 10730, "number_of_timesteps": 1213587, "per_episode_reward": -135.37, "episode_reward_trend_value": 0.0011688642333126608, "biggest_recent_change": 0.061328912173792105},
{"total_number_of_episodes": 10740, "number_of_timesteps": 1214857, "per_episode_reward": -135.39, "episode_reward_trend_value": 0.0013038883237265332, "biggest_recent_change": 0.061328912173792105},
{"total_number_of_episodes": 10750, "number_of_timesteps": 1215660, "per_episode_reward": -135.31, "episode_reward_trend_value": 0.0014401604412338682, "biggest_recent_change": 0.07359340274945225},
{"total_number_of_episodes": 10760, "number_of_timesteps": 1216636, "per_episode_reward": -135.28, "episode_reward_trend_value": 0.0019530101103113237, "biggest_recent_change": 0.07359340274945225},
{"total_number_of_episodes": 10771, "number_of_timesteps": 1218007, "per_episode_reward": -135.36, "episode_reward_trend_value": 0.0010059176480278135, "biggest_recent_change": 0.07990652228119188},
{"total_number_of_episodes": 10781, "number_of_timesteps": 1219065, "per_episode_reward": -135.34, "episode_reward_trend_value": 0.0006792030567642844, "biggest_recent_change": 0.07990652228119188},
{"total_number_of_episodes": 10791, "number_of_timesteps": 1219993, "per_episode_reward": -135.2, "episode_reward_trend_value": 0.00222319844571075, "biggest_recent_change": 0.14903408837278675},
{"total_number_of_episodes": 10801, "number_of_timesteps": 1220877, "per_episode_reward": -135.17, "episode_reward_trend_value": 0.0022484341862180042, "biggest_recent_change": 0.14903408837278675},
{"total_number_of_episodes": 10811, "number_of_timesteps": 1222529, "per_episode_reward": -135.02, "episode_reward_trend_value": 0.004359028203676808, "biggest_recent_change": 0.14903408837278675},
{"total_number_of_episodes": 10821, "number_of_timesteps": 1223902, "per_episode_reward": -134.98, "episode_reward_trend_value": 0.00423599329873083, "biggest_recent_change": 0.14903408837278675},
{"total_number_of_episodes": 10832, "number_of_timesteps": 1225168, "per_episode_reward": -134.98, "episode_reward_trend_value": 0.004546128091306261, "biggest_recent_change": 0.14903408837278675},
{"total_number_of_episodes": 10842, "number_of_timesteps": 1226262, "per_episode_reward": -135.01, "episode_reward_trend_value": 0.00332608173897313, "biggest_recent_change": 0.14903408837278675},
{"total_number_of_episodes": 10852, "number_of_timesteps": 1227497, "per_episode_reward": -135.05, "episode_reward_trend_value": 0.002557835604503427, "biggest_recent_change": 0.14903408837278675},
{"total_number_of_episodes": 10863, "number_of_timesteps": 1228929, "per_episode_reward": -135.09, "episode_reward_trend_value": 0.0030319566260194127, "biggest_recent_change": 0.14903408837278675},
{"total_number_of_episodes": 10874, "number_of_timesteps": 1230423, "per_episode_reward": -135.11, "episode_reward_trend_value": 0.002581170805487116, "biggest_recent_change": 0.14903408837278675},
{"total_number_of_episodes": 10885, "number_of_timesteps": 1231553, "per_episode_reward": -135.05, "episode_reward_trend_value": 0.0016171609386358594, "biggest_recent_change": 0.14731022414940753},
{"total_number_of_episodes": 10896, "number_of_timesteps": 1232791, "per_episode_reward": -135.14, "episode_reward_trend_value": 0.00026609387378029065, "biggest_recent_change": 0.14731022414940753},
{"total_number_of_episodes": 10906, "number_of_timesteps": 1233783, "per_episode_reward": -135.09, "episode_reward_trend_value": -0.0008454691415945743, "biggest_recent_change": 0.0921016657471796},
{"total_number_of_episodes": 10916, "number_of_timesteps": 1235274, "per_episode_reward": -135.13, "episode_reward_trend_value": -0.0016142294537224364, "biggest_recent_change": 0.0921016657471796},
{"total_number_of_episodes": 10926, "number_of_timesteps": 1236083, "per_episode_reward": -134.82, "episode_reward_trend_value": 0.0017310138209571352, "biggest_recent_change": 0.30735315601575053},
{"total_number_of_episodes": 10936, "number_of_timesteps": 1237401, "per_episode_reward": -134.82, "episode_reward_trend_value": 0.0021455834659361824, "biggest_recent_change": 0.30735315601575053},
{"total_number_of_episodes": 10947, "number_of_timesteps": 1238603, "per_episode_reward": -134.73, "episode_reward_trend_value": 0.0035981240625927863, "biggest_recent_change": 0.30735315601575053},
{"total_number_of_episodes": 10957, "number_of_timesteps": 1239516, "per_episode_reward": -134.64, "episode_reward_trend_value": 0.0049583221733791386, "biggest_recent_change": 0.30735315601575053},
{"total_number_of_episodes": 10968, "number_of_timesteps": 1240562, "per_episode_reward": -134.54, "episode_reward_trend_value": 0.0063697357564055646, "biggest_recent_change": 0.30735315601575053},
{"total_number_of_episodes": 10978, "number_of_timesteps": 1241733, "per_episode_reward": -134.6, "episode_reward_trend_value": 0.00496836264925283, "biggest_recent_change": 0.30735315601575053},
{"total_number_of_episodes": 10988, "number_of_timesteps": 1242612, "per_episode_reward": -134.47, "episode_reward_trend_value": 0.0074970280095003426, "biggest_recent_change": 0.30735315601575053},
{"total_number_of_episodes": 10998, "number_of_timesteps": 1244041, "per_episode_reward": -134.5, "episode_reward_trend_value": 0.0065707492011878475, "biggest_recent_change": 0.30735315601575053},
{"total_number_of_episodes": 11009, "number_of_timesteps": 1245514, "per_episode_reward": -134.51, "episode_reward_trend_value": 0.00684624303183499, "biggest_recent_change": 0.30735315601575053},
{"total_number_of_episodes": 11019, "number_of_timesteps": 1246531, "per_episode_reward": -134.7, "episode_reward_trend_value": 0.0013804871170075709, "biggest_recent_change": 0.1845648763187171},
{"total_number_of_episodes": 11029, "number_of_timesteps": 1248373, "per_episode_reward": -134.71, "episode_reward_trend_value": 0.0012386858315822894, "biggest_recent_change": 0.1845648763187171},
{"total_number_of_episodes": 11039, "number_of_timesteps": 1249376, "per_episode_reward": -134.63, "episode_reward_trend_value": 0.0010510912009354771, "biggest_recent_change": 0.1845648763187171},
{"total_number_of_episodes": 11049, "number_of_timesteps": 1250322, "per_episode_reward": -134.51, "episode_reward_trend_value": 0.0014845669811863773, "biggest_recent_change": 0.1845648763187171},
{"total_number_of_episodes": 11059, "number_of_timesteps": 1251340, "per_episode_reward": -134.54, "episode_reward_trend_value": -2.4930645988913764e-06, "biggest_recent_change": 0.1845648763187171},
{"total_number_of_episodes": 11069, "number_of_timesteps": 1252424, "per_episode_reward": -134.65, "episode_reward_trend_value": -0.0005338862352573415, "biggest_recent_change": 0.1845648763187171},
{"total_number_of_episodes": 11079, "number_of_timesteps": 1253558, "per_episode_reward": -134.62, "episode_reward_trend_value": -0.0016536138011711426, "biggest_recent_change": 0.1845648763187171},
{"total_number_of_episodes": 11089, "number_of_timesteps": 1254897, "per_episode_reward": -134.7, "episode_reward_trend_value": -0.0022337816757432923, "biggest_recent_change": 0.1845648763187171},
{"total_number_of_episodes": 11100, "number_of_timesteps": 1256450, "per_episode_reward": -134.67, "episode_reward_trend_value": -0.0017153147639949868, "biggest_recent_change": 0.1845648763187171},
{"total_number_of_episodes": 11110, "number_of_timesteps": 1257606, "per_episode_reward": -134.66, "episode_reward_trend_value": 0.0004657434117926111, "biggest_recent_change": 0.12419501984859949},
{"total_number_of_episodes": 11122, "number_of_timesteps": 1259026, "per_episode_reward": -134.57, "episode_reward_trend_value": 0.0015343541963283593, "biggest_recent_change": 0.12419501984859949},
{"total_number_of_episodes": 11132, "number_of_timesteps": 1260251, "per_episode_reward": -134.64, "episode_reward_trend_value": -0.00012703411126090537, "biggest_recent_change": 0.12419501984859949},
{"total_number_of_episodes": 11143, "number_of_timesteps": 1261513, "per_episode_reward": -134.64, "episode_reward_trend_value": -0.0015259469177345232, "biggest_recent_change": 0.11167576464683293},
{"total_number_of_episodes": 11153, "number_of_timesteps": 1262455, "per_episode_reward": -134.53, "episode_reward_trend_value": 9.231335472148001e-05, "biggest_recent_change": 0.11350639275968888},
{"total_number_of_episodes": 11163, "number_of_timesteps": 1263405, "per_episode_reward": -134.43, "episode_reward_trend_value": 0.0024205106564409106, "biggest_recent_change": 0.11350639275968888},
{"total_number_of_episodes": 11173, "number_of_timesteps": 1264306, "per_episode_reward": -134.34, "episode_reward_trend_value": 0.0030813809909817436, "biggest_recent_change": 0.11350639275968888},
{"total_number_of_episodes": 11184, "number_of_timesteps": 1265642, "per_episode_reward": -134.73, "episode_reward_trend_value": -0.0002755459780442177, "biggest_recent_change": 0.39043407590628476},
{"total_number_of_episodes": 11194, "number_of_timesteps": 1267205, "per_episode_reward": -134.76, "episode_reward_trend_value": -0.0010065080234135672, "biggest_recent_change": 0.39043407590628476},
{"total_number_of_episodes": 11204, "number_of_timesteps": 1268287, "per_episode_reward": -134.82, "episode_reward_trend_value": -0.0018574262766192205, "biggest_recent_change": 0.39043407590628476},
{"total_number_of_episodes": 11215, "number_of_timesteps": 1269278, "per_episode_reward": -134.74, "episode_reward_trend_value": -0.0019036222732646973, "biggest_recent_change": 0.39043407590628476},
{"total_number_of_episodes": 11226, "number_of_timesteps": 1270501, "per_episode_reward": -134.75, "episode_reward_trend_value": -0.0011965765572717322, "biggest_recent_change": 0.39043407590628476},
{"total_number_of_episodes": 11238, "number_of_timesteps": 1271879, "per_episode_reward": -134.83, "episode_reward_trend_value": -0.00204741561197592, "biggest_recent_change": 0.39043407590628476},
{"total_number_of_episodes": 11249, "number_of_timesteps": 1273750, "per_episode_reward": -134.85, "episode_reward_trend_value": -0.003594033494138355, "biggest_recent_change": 0.39043407590628476},
{"total_number_of_episodes": 11259, "number_of_timesteps": 1274820, "per_episode_reward": -134.93, "episode_reward_trend_value": -0.005576181224595365, "biggest_recent_change": 0.39043407590628476},
{"total_number_of_episodes": 11269, "number_of_timesteps": 1276104, "per_episode_reward": -134.87, "episode_reward_trend_value": -0.005924649017029537, "biggest_recent_change": 0.39043407590628476},
{"total_number_of_episodes": 11279, "number_of_timesteps": 1277330, "per_episode_reward": -134.95, "episode_reward_trend_value": -0.0024413329704167886, "biggest_recent_change": 0.08053130323321511},
{"total_number_of_episodes": 11291, "number_of_timesteps": 1278802, "per_episode_reward": -135.03, "episode_reward_trend_value": -0.003007855305145313, "biggest_recent_change": 0.08067710450279719},
{"total_number_of_episodes": 11302, "number_of_timesteps": 1280185, "per_episode_reward": -135.03, "episode_reward_trend_value": -0.002273958815319727, "biggest_recent_change": 0.08067710450279719},
{"total_number_of_episodes": 11312, "number_of_timesteps": 1281498, "per_episode_reward": -135.03, "episode_reward_trend_value": -0.0031668000854245468, "biggest_recent_change": 0.08067710450279719},
{"total_number_of_episodes": 11323, "number_of_timesteps": 1283017, "per_episode_reward": -134.85, "episode_reward_trend_value": -0.0010549811164742727, "biggest_recent_change": 0.18315023792638385},
{"total_number_of_episodes": 11334, "number_of_timesteps": 1283979, "per_episode_reward": -134.81, "episode_reward_trend_value": 0.00018548858168306498, "biggest_recent_change": 0.18315023792638385},
{"total_number_of_episodes": 11345, "number_of_timesteps": 1285041, "per_episode_reward": -134.71, "episode_reward_trend_value": 0.0015844674858742438, "biggest_recent_change": 0.18315023792638385},
{"total_number_of_episodes": 11355, "number_of_timesteps": 1286557, "per_episode_reward": -134.71, "episode_reward_trend_value": 0.002492202267919197, "biggest_recent_change": 0.18315023792638385},
{"total_number_of_episodes": 11365, "number_of_timesteps": 1287494, "per_episode_reward": -134.67, "episode_reward_trend_value": 0.002210528938797059, "biggest_recent_change": 0.18315023792638385},
{"total_number_of_episodes": 11375, "number_of_timesteps": 1288486, "per_episode_reward": -134.68, "episode_reward_trend_value": 0.0029412275146780886, "biggest_recent_change": 0.18315023792638385},
{"total_number_of_episodes": 11385, "number_of_timesteps": 1289811, "per_episode_reward": -134.7, "episode_reward_trend_value": 0.003679394506928525, "biggest_recent_change": 0.18315023792638385},
{"total_number_of_episodes": 11395, "number_of_timesteps": 1290861, "per_episode_reward": -134.72, "episode_reward_trend_value": 0.003418346810800838, "biggest_recent_change": 0.18315023792638385},
{"total_number_of_episodes": 11406, "number_of_timesteps": 1291940, "per_episode_reward": -134.66, "episode_reward_trend_value": 0.00411762047357974, "biggest_recent_change": 0.18315023792638385},
{"total_number_of_episodes": 11416, "number_of_timesteps": 1292877, "per_episode_reward": -134.66, "episode_reward_trend_value": 0.002082617829953253, "biggest_recent_change": 0.1002188847422758},
{"total_number_of_episodes": 11426, "number_of_timesteps": 1293849, "per_episode_reward": -134.59, "episode_reward_trend_value": 0.0024410606450639234, "biggest_recent_change": 0.1002188847422758},
{"total_number_of_episodes": 11436, "number_of_timesteps": 1294940, "per_episode_reward": -134.61, "episode_reward_trend_value": 0.0011590278255230006, "biggest_recent_change": 0.06561947853671768},
{"total_number_of_episodes": 11446, "number_of_timesteps": 1296048, "per_episode_reward": -134.66, "episode_reward_trend_value": 0.0005521868040245989, "biggest_recent_change": 0.06561947853671768},
{"total_number_of_episodes": 11456, "number_of_timesteps": 1296938, "per_episode_reward": -134.59, "episode_reward_trend_value": 0.0009382026758626378, "biggest_recent_change": 0.07220979337688505},
{"total_number_of_episodes": 11467, "number_of_timesteps": 1298333, "per_episode_reward": -134.63, "episode_reward_trend_value": 0.0005865261989217491, "biggest_recent_change": 0.07220979337688505},
{"total_number_of_episodes": 11477, "number_of_timesteps": 1299452, "per_episode_reward": -134.61, "episode_reward_trend_value": 0.0010121379851322368, "biggest_recent_change": 0.07220979337688505},
{"total_number_of_episodes": 11487, "number_of_timesteps": 1300694, "per_episode_reward": -134.62, "episode_reward_trend_value": 0.0011549236044980185, "biggest_recent_change": 0.07220979337688505},
{"total_number_of_episodes": 11497, "number_of_timesteps": 1302183, "per_episode_reward": -134.61, "episode_reward_trend_value": 0.0005353595859692935, "biggest_recent_change": 0.07220979337688505},
{"total_number_of_episodes": 11508, "number_of_timesteps": 1303312, "per_episode_reward": -134.4, "episode_reward_trend_value": 0.002901067710975427, "biggest_recent_change": 0.21291373125055202},
{"total_number_of_episodes": 11518, "number_of_timesteps": 1304604, "per_episode_reward": -134.55, "episode_reward_trend_value": 0.0005175426147303597, "biggest_recent_change": 0.21291373125055202},
{"total_number_of_episodes": 11528, "number_of_timesteps": 1305994, "per_episode_reward": -134.57, "episode_reward_trend_value": 0.0004012286003709657, "biggest_recent_change": 0.21291373125055202},
{"total_number_of_episodes": 11538, "number_of_timesteps": 1306889, "per_episode_reward": -134.42, "episode_reward_trend_value": 0.002639208242611188, "biggest_recent_change": 0.21291373125055202},
{"total_number_of_episodes": 11548, "number_of_timesteps": 1307942, "per_episode_reward": -134.4, "episode_reward_trend_value": 0.002056647937141381, "biggest_recent_change": 0.21291373125055202},
{"total_number_of_episodes": 11558, "number_of_timesteps": 1308783, "per_episode_reward": -134.34, "episode_reward_trend_value": 0.003190817870874222, "biggest_recent_change": 0.21291373125055202},
{"total_number_of_episodes": 11569, "number_of_timesteps": 1310030, "per_episode_reward": -134.28, "episode_reward_trend_value": 0.0036041908098758944, "biggest_recent_change": 0.21291373125055202},
{"total_number_of_episodes": 11580, "number_of_timesteps": 1311236, "per_episode_reward": -134.37, "episode_reward_trend_value": 0.002772023515190527, "biggest_recent_change": 0.21291373125055202},
{"total_number_of_episodes": 11590, "number_of_timesteps": 1312496, "per_episode_reward": -134.37, "episode_reward_trend_value": 0.002699476377991219, "biggest_recent_change": 0.21291373125055202},
{"total_number_of_episodes": 11600, "number_of_timesteps": 1313708, "per_episode_reward": -134.36, "episode_reward_trend_value": 0.00037680531003192957, "biggest_recent_change": 0.14889778012533839},
{"total_number_of_episodes": 11611, "number_of_timesteps": 1315059, "per_episode_reward": -134.41, "episode_reward_trend_value": 0.0015547747655059792, "biggest_recent_change": 0.14796730301759453},
{"total_number_of_episodes": 11621, "number_of_timesteps": 1316273, "per_episode_reward": -134.36, "episode_reward_trend_value": 0.002325910786675915, "biggest_recent_change": 0.14796730301759453},
{"total_number_of_episodes": 11631, "number_of_timesteps": 1317587, "per_episode_reward": -134.41, "episode_reward_trend_value": 0.00019917354869581537, "biggest_recent_change": 0.0843402426322939},
{"total_number_of_episodes": 11641, "number_of_timesteps": 1318624, "per_episode_reward": -134.37, "episode_reward_trend_value": 0.00039277622459823965, "biggest_recent_change": 0.0843402426322939},
{"total_number_of_episodes": 11651, "number_of_timesteps": 1319838, "per_episode_reward": -134.34, "episode_reward_trend_value": 5.673800987943246e-05, "biggest_recent_change": 0.0843402426322939},
{"total_number_of_episodes": 11661, "number_of_timesteps": 1321177, "per_episode_reward": -134.41, "episode_reward_trend_value": -0.0014338514345458484, "biggest_recent_change": 0.0843402426322939},
{"total_number_of_episodes": 11672, "number_of_timesteps": 1322381, "per_episode_reward": -134.45, "episode_reward_trend_value": -0.000864998645534835, "biggest_recent_change": 0.07288649992943874},
{"total_number_of_episodes": 11683, "number_of_timesteps": 1323810, "per_episode_reward": -134.55, "episode_reward_trend_value": -0.0019950800706077924, "biggest_recent_change": 0.10106270262198791},
{"total_number_of_episodes": 11693, "number_of_timesteps": 1325068, "per_episode_reward": -134.46, "episode_reward_trend_value": -0.001102665777533376, "biggest_recent_change": 0.10106270262198791},
{"total_number_of_episodes": 11703, "number_of_timesteps": 1326150, "per_episode_reward": -134.52, "episode_reward_trend_value": -0.0013133022533629124, "biggest_recent_change": 0.10106270262198791},
{"total_number_of_episodes": 11713, "number_of_timesteps": 1327158, "per_episode_reward": -134.66, "episode_reward_trend_value": -0.003277482968850778, "biggest_recent_change": 0.1330063527973664},
{"total_number_of_episodes": 11725, "number_of_timesteps": 1328665, "per_episode_reward": -134.69, "episode_reward_trend_value": -0.0031170651283373573, "biggest_recent_change": 0.1330063527973664},
{"total_number_of_episodes": 11735, "number_of_timesteps": 1329753, "per_episode_reward": -134.67, "episode_reward_trend_value": -0.0033651204885324485, "biggest_recent_change": 0.1330063527973664},
{"total_number_of_episodes": 11745, "number_of_timesteps": 1330854, "per_episode_reward": -134.67, "episode_reward_trend_value": -0.0036771618746077673, "biggest_recent_change": 0.1330063527973664},
{"total_number_of_episodes": 11755, "number_of_timesteps": 1332286, "per_episode_reward": -134.66, "episode_reward_trend_value": -0.0027945036379643778, "biggest_recent_change": 0.1330063527973664},
{"total_number_of_episodes": 11765, "number_of_timesteps": 1333603, "per_episode_reward": -134.67, "episode_reward_trend_value": -0.0024904766615375393, "biggest_recent_change": 0.1330063527973664},
{"total_number_of_episodes": 11775, "number_of_timesteps": 1334696, "per_episode_reward": -134.69, "episode_reward_trend_value": -0.0016384111008499584, "biggest_recent_change": 0.1330063527973664},
{"total_number_of_episodes": 11785, "number_of_timesteps": 1336135, "per_episode_reward": -134.69, "episode_reward_trend_value": -0.0025148319325126066, "biggest_recent_change": 0.1330063527973664},
{"total_number_of_episodes": 11795, "number_of_timesteps": 1337717, "per_episode_reward": -134.69, "episode_reward_trend_value": -0.0018083958535681985, "biggest_recent_change": 0.1330063527973664},
{"total_number_of_episodes": 11805, "number_of_timesteps": 1338729, "per_episode_reward": -134.67, "episode_reward_trend_value": -0.000192259554475211, "biggest_recent_change": 0.029001442754406526},
{"total_number_of_episodes": 11815, "number_of_timesteps": 1339895, "per_episode_reward": -134.75, "episode_reward_trend_value": -0.000672094382639759, "biggest_recent_change": 0.07218657728921585},
{"total_number_of_episodes": 11825, "number_of_timesteps": 1341063, "per_episode_reward": -134.8, "episode_reward_trend_value": -0.0014022282718157285, "biggest_recent_change": 0.07218657728921585},
{"total_number_of_episodes": 11835, "number_of_timesteps": 1342250, "per_episode_reward": -134.79, "episode_reward_trend_value": -0.0013179842224802642, "biggest_recent_change": 0.07218657728921585},
{"total_number_of_episodes": 11845, "number_of_timesteps": 1343034, "per_episode_reward": -134.7, "episode_reward_trend_value": -0.0004203680892405575, "biggest_recent_change": 0.0873381933600399},
{"total_number_of_episodes": 11855, "number_of_timesteps": 1343960, "per_episode_reward": -134.52, "episode_reward_trend_value": 0.001711852955417233, "biggest_recent_change": 0.18611883027631393},
{"total_number_of_episodes": 11865, "number_of_timesteps": 1344969, "per_episode_reward": -134.39, "episode_reward_trend_value": 0.003341430225574666, "biggest_recent_change": 0.18611883027631393},
{"total_number_of_episodes": 11875, "number_of_timesteps": 1346190, "per_episode_reward": -134.48, "episode_reward_trend_value": 0.002272130177359107, "biggest_recent_change": 0.18611883027631393},
{"total_number_of_episodes": 11885, "number_of_timesteps": 1347533, "per_episode_reward": -134.55, "episode_reward_trend_value": 0.0015281815530256734, "biggest_recent_change": 0.18611883027631393},
{"total_number_of_episodes": 11895, "number_of_timesteps": 1348700, "per_episode_reward": -134.59, "episode_reward_trend_value": 0.0008952790860939153, "biggest_recent_change": 0.18611883027631393},
{"total_number_of_episodes": 11906, "number_of_timesteps": 1349709, "per_episode_reward": -134.58, "episode_reward_trend_value": 0.0018244717539981064, "biggest_recent_change": 0.18611883027631393},
{"total_number_of_episodes": 11917, "number_of_timesteps": 1350705, "per_episode_reward": -134.49, "episode_reward_trend_value": 0.003464584537000645, "biggest_recent_change": 0.18611883027631393},
{"total_number_of_episodes": 11927, "number_of_timesteps": 1351681, "per_episode_reward": -134.38, "episode_reward_trend_value": 0.004526437747014395, "biggest_recent_change": 0.18611883027631393},
{"total_number_of_episodes": 11937, "number_of_timesteps": 1353200, "per_episode_reward": -134.5, "episode_reward_trend_value": 0.002244468812031957, "biggest_recent_change": 0.18611883027631393},
{"total_number_of_episodes": 11947, "number_of_timesteps": 1354441, "per_episode_reward": -134.53, "episode_reward_trend_value": -0.0002108256805232461, "biggest_recent_change": 0.12228515215406333},
{"total_number_of_episodes": 11957, "number_of_timesteps": 1355400, "per_episode_reward": -134.49, "episode_reward_trend_value": -0.0010720816249147446, "biggest_recent_change": 0.11803901078837953},
{"total_number_of_episodes": 11967, "number_of_timesteps": 1356673, "per_episode_reward": -134.49, "episode_reward_trend_value": -4.225193819296338e-05, "biggest_recent_change": 0.11803901078837953},
{"total_number_of_episodes": 11977, "number_of_timesteps": 1357807, "per_episode_reward": -134.35, "episode_reward_trend_value": 0.0022432243472511318, "biggest_recent_change": 0.14047892464762413},
{"total_number_of_episodes": 11987, "number_of_timesteps": 1358633, "per_episode_reward": -134.17, "episode_reward_trend_value": 0.004657531395135569, "biggest_recent_change": 0.17277232640674356},
{"total_number_of_episodes": 11997, "number_of_timesteps": 1359835, "per_episode_reward": -134.26, "episode_reward_trend_value": 0.003585077263008429, "biggest_recent_change": 0.17277232640674356},
{"total_number_of_episodes": 12007, "number_of_timesteps": 1360988, "per_episode_reward": -134.46, "episode_reward_trend_value": 0.0002856994595924157, "biggest_recent_change": 0.20016727756478758},
{"total_number_of_episodes": 12017, "number_of_timesteps": 1362158, "per_episode_reward": -134.45, "episode_reward_trend_value": -0.0007994398827934092, "biggest_recent_change": 0.20016727756478758},
{"total_number_of_episodes": 12027, "number_of_timesteps": 1363256, "per_episode_reward": -134.42, "episode_reward_trend_value": 0.0009271692252910826, "biggest_recent_change": 0.20016727756478758},
{"total_number_of_episodes": 12037, "number_of_timesteps": 1364298, "per_episode_reward": -134.26, "episode_reward_trend_value": 0.0030618871442075917, "biggest_recent_change": 0.20016727756478758},
{"total_number_of_episodes": 12047, "number_of_timesteps": 1365237, "per_episode_reward": -134.1, "episode_reward_trend_value": 0.004322150998814954, "biggest_recent_change": 0.20016727756478758},
{"total_number_of_episodes": 12057, "number_of_timesteps": 1366730, "per_episode_reward": -134.2, "episode_reward_trend_value": 0.003210838067530454, "biggest_recent_change": 0.20016727756478758},
{"total_number_of_episodes": 12067, "number_of_timesteps": 1367677, "per_episode_reward": -134.18, "episode_reward_trend_value": 0.0018210086710272182, "biggest_recent_change": 0.20016727756478758},
{"total_number_of_episodes": 12077, "number_of_timesteps": 1368455, "per_episode_reward": -134.08, "episode_reward_trend_value": 0.0010915849288500744, "biggest_recent_change": 0.20016727756478758},
{"total_number_of_episodes": 12087, "number_of_timesteps": 1369371, "per_episode_reward": -134.04, "episode_reward_trend_value": 0.002410106058848606, "biggest_recent_change": 0.20016727756478758},
{"total_number_of_episodes": 12098, "number_of_timesteps": 1370731, "per_episode_reward": -134.01, "episode_reward_trend_value": 0.004991897902801333, "biggest_recent_change": 0.15819586407349107},
{"total_number_of_episodes": 12108, "number_of_timesteps": 1371882, "per_episode_reward": -134.03, "episode_reward_trend_value": 0.0047236503407238695, "biggest_recent_change": 0.15819586407349107},
{"total_number_of_episodes": 12118, "number_of_timesteps": 1373123, "per_episode_reward": -134.06, "episode_reward_trend_value": 0.0039060115558220963, "biggest_recent_change": 0.15819586407349107},
{"total_number_of_episodes": 12128, "number_of_timesteps": 1374605, "per_episode_reward": -134.03, "episode_reward_trend_value": 0.002524704740096379, "biggest_recent_change": 0.15819586407349107},
{"total_number_of_episodes": 12138, "number_of_timesteps": 1375483, "per_episode_reward": -134.04, "episode_reward_trend_value": 0.0006586018806931154, "biggest_recent_change": 0.10712418961080061},
{"total_number_of_episodes": 12148, "number_of_timesteps": 1376568, "per_episode_reward": -134.03, "episode_reward_trend_value": 0.001829167241618595, "biggest_recent_change": 0.10712418961080061},

{"total_number_of_episodes": 12158, "number_of_timesteps": 1377818, "per_episode_reward": -134.02, "episode_reward_trend_value": 0.0018305857466556416, "biggest_recent_change": 0.10712418961080061},
{"total_number_of_episodes": 12169, "number_of_timesteps": 1378971, "per_episode_reward": -134.02, "episode_reward_trend_value": 0.0005824920461062927, "biggest_recent_change": 0.036231681701934804},
{"total_number_of_episodes": 12179, "number_of_timesteps": 1380014, "per_episode_reward": -134.02, "episode_reward_trend_value": 0.0002319182058010306, "biggest_recent_change": 0.036231681701934804},
{"total_number_of_episodes": 12189, "number_of_timesteps": 1381057, "per_episode_reward": -134.04, "episode_reward_trend_value": -0.00032529776520896623, "biggest_recent_change": 0.036231681701934804},
{"total_number_of_episodes": 12199, "number_of_timesteps": 1382286, "per_episode_reward": -134.07, "episode_reward_trend_value": -0.00042851795463718647, "biggest_recent_change": 0.036231681701934804},
{"total_number_of_episodes": 12210, "number_of_timesteps": 1383759, "per_episode_reward": -134.09, "episode_reward_trend_value": -0.0002466974363408604, "biggest_recent_change": 0.0329493252335169},
{"total_number_of_episodes": 12220, "number_of_timesteps": 1385081, "per_episode_reward": -134.16, "episode_reward_trend_value": -0.001378464350601247, "biggest_recent_change": 0.0689096970499179},
{"total_number_of_episodes": 12230, "number_of_timesteps": 1386378, "per_episode_reward": -134.07, "episode_reward_trend_value": -0.00032884772929201567, "biggest_recent_change": 0.08471210264502815},
{"total_number_of_episodes": 12241, "number_of_timesteps": 1387403, "per_episode_reward": -134.05, "episode_reward_trend_value": -0.00012521270453476064, "biggest_recent_change": 0.08471210264502815},
{"total_number_of_episodes": 12251, "number_of_timesteps": 1388731, "per_episode_reward": -134.02, "episode_reward_trend_value": -8.921936913313604e-06, "biggest_recent_change": 0.08471210264502815},
{"total_number_of_episodes": 12262, "number_of_timesteps": 1390091, "per_episode_reward": -134.11, "episode_reward_trend_value": -0.0009176027563641911, "biggest_recent_change": 0.08698551718921976},
{"total_number_of_episodes": 12272, "number_of_timesteps": 1391295, "per_episode_reward": -134.24, "episode_reward_trend_value": -0.002385178574372225, "biggest_recent_change": 0.13004667661761005},
{"total_number_of_episodes": 12282, "number_of_timesteps": 1392416, "per_episode_reward": -134.13, "episode_reward_trend_value": -0.0009515329312171793, "biggest_recent_change": 0.13004667661761005},
{"total_number_of_episodes": 12292, "number_of_timesteps": 1393351, "per_episode_reward": -134.02, "episode_reward_trend_value": 0.0005355071504109471, "biggest_recent_change": 0.13004667661761005},
{"total_number_of_episodes": 12302, "number_of_timesteps": 1394628, "per_episode_reward": -134.04, "episode_reward_trend_value": 0.0005546649884732031, "biggest_recent_change": 0.13004667661761005},
{"total_number_of_episodes": 12312, "number_of_timesteps": 1395767, "per_episode_reward": -134.09, "episode_reward_trend_value": 0.0006844703623064181, "biggest_recent_change": 0.13004667661761005},
{"total_number_of_episodes": 12322, "number_of_timesteps": 1397332, "per_episode_reward": -134.15, "episode_reward_trend_value": -0.0008378330543763468, "biggest_recent_change": 0.13004667661761005},
{"total_number_of_episodes": 12332, "number_of_timesteps": 1398445, "per_episode_reward": -134.26, "episode_reward_trend_value": -0.0023542538344701017, "biggest_recent_change": 0.13004667661761005},
{"total_number_of_episodes": 12342, "number_of_timesteps": 1399555, "per_episode_reward": -134.19, "episode_reward_trend_value": -0.0019285324645942916, "biggest_recent_change": 0.13004667661761005},
{"total_number_of_episodes": 12352, "number_of_timesteps": 1400895, "per_episode_reward": -134.26, "episode_reward_trend_value": -0.0017229042742542334, "biggest_recent_change": 0.13004667661761005},
{"total_number_of_episodes": 12362, "number_of_timesteps": 1402222, "per_episode_reward": -134.52, "episode_reward_trend_value": -0.003167824807878282, "biggest_recent_change": 0.26008952464377444},
{"total_number_of_episodes": 12376, "number_of_timesteps": 1403364, "per_episode_reward": -134.34, "episode_reward_trend_value": -0.0023942461892283344, "biggest_recent_change": 0.26008952464377444},
{"total_number_of_episodes": 12386, "number_of_timesteps": 1404244, "per_episode_reward": -134.21, "episode_reward_trend_value": -0.0020900047420964385, "biggest_recent_change": 0.26008952464377444},
{"total_number_of_episodes": 12397, "number_of_timesteps": 1405352, "per_episode_reward": -134.24, "episode_reward_trend_value": -0.00226532725574897, "biggest_recent_change": 0.26008952464377444},
{"total_number_of_episodes": 12407, "number_of_timesteps": 1406643, "per_episode_reward": -134.24, "episode_reward_trend_value": -0.0015758165889053545, "biggest_recent_change": 0.26008952464377444},
{"total_number_of_episodes": 12417, "number_of_timesteps": 1407581, "per_episode_reward": -134.23, "episode_reward_trend_value": -0.0009512951296149671, "biggest_recent_change": 0.26008952464377444},
{"total_number_of_episodes": 12427, "number_of_timesteps": 1408478, "per_episode_reward": -134.17, "episode_reward_trend_value": 0.0009298074845598117, "biggest_recent_change": 0.26008952464377444},
{"total_number_of_episodes": 12437, "number_of_timesteps": 1409583, "per_episode_reward": -134.22, "episode_reward_trend_value": -0.0003058912848476641, "biggest_recent_change": 0.26008952464377444},
{"total_number_of_episodes": 12447, "number_of_timesteps": 1410822, "per_episode_reward": -134.28, "episode_reward_trend_value": -0.00019792467075616414, "biggest_recent_change": 0.26008952464377444},
{"total_number_of_episodes": 12457, "number_of_timesteps": 1412072, "per_episode_reward": -134.24, "episode_reward_trend_value": 0.0031031818863498173, "biggest_recent_change": 0.18069473456250762},
{"total_number_of_episodes": 12467, "number_of_timesteps": 1413316, "per_episode_reward": -134.23, "episode_reward_trend_value": 0.0012510984726039473, "biggest_recent_change": 0.1341939396375551},
{"total_number_of_episodes": 12477, "number_of_timesteps": 1414472, "per_episode_reward": -134.16, "episode_reward_trend_value": 0.0005509460663625356, "biggest_recent_change": 0.07118022307582805},
{"total_number_of_episodes": 12487, "number_of_timesteps": 1416090, "per_episode_reward": -134.43, "episode_reward_trend_value": -0.0020772454224874714, "biggest_recent_change": 0.2704598898548909},
{"total_number_of_episodes": 12497, "number_of_timesteps": 1417317, "per_episode_reward": -134.46, "episode_reward_trend_value": -0.0024639526544247147, "biggest_recent_change": 0.2704598898548909},
{"total_number_of_episodes": 12507, "number_of_timesteps": 1418284, "per_episode_reward": -134.45, "episode_reward_trend_value": -0.002457769381874186, "biggest_recent_change": 0.2704598898548909},
{"total_number_of_episodes": 12517, "number_of_timesteps": 1419216, "per_episode_reward": -134.4, "episode_reward_trend_value": -0.002495502530062292, "biggest_recent_change": 0.2704598898548909},
{"total_number_of_episodes": 12527, "number_of_timesteps": 1420168, "per_episode_reward": -134.38, "episode_reward_trend_value": -0.0018261049683057234, "biggest_recent_change": 0.2704598898548909},
{"total_number_of_episodes": 12537, "number_of_timesteps": 1421086, "per_episode_reward": -134.38, "episode_reward_trend_value": -0.001082038334512466, "biggest_recent_change": 0.2704598898548909},
{"total_number_of_episodes": 12549, "number_of_timesteps": 1422113, "per_episode_reward": -134.25, "episode_reward_trend_value": -7.377322289004143e-05, "biggest_recent_change": 0.2704598898548909},
{"total_number_of_episodes": 12560, "number_of_timesteps": 1423278, "per_episode_reward": -134.32, "episode_reward_trend_value": -0.0010242804698609436, "biggest_recent_change": 0.2704598898548909},
{"total_number_of_episodes": 12570, "number_of_timesteps": 1424715, "per_episode_reward": -134.43, "episode_reward_trend_value": -0.0030074859585858525, "biggest_recent_change": 0.2704598898548909},
{"total_number_of_episodes": 12582, "number_of_timesteps": 1426234, "per_episode_reward": -134.42, "episode_reward_trend_value": 3.540435022052356e-05, "biggest_recent_change": 0.1277539255417821},
{"total_number_of_episodes": 12592, "number_of_timesteps": 1427943, "per_episode_reward": -134.43, "episode_reward_trend_value": 0.0002870812487830992, "biggest_recent_change": 0.1277539255417821},
{"total_number_of_episodes": 12603, "number_of_timesteps": 1428895, "per_episode_reward": -134.36, "episode_reward_trend_value": 0.0009793085278813705, "biggest_recent_change": 0.1277539255417821},
{"total_number_of_episodes": 12613, "number_of_timesteps": 1429834, "per_episode_reward": -134.35, "episode_reward_trend_value": 0.0005532090251187406, "biggest_recent_change": 0.1277539255417821},
{"total_number_of_episodes": 12623, "number_of_timesteps": 1430803, "per_episode_reward": -134.33, "episode_reward_trend_value": 0.0006342574737228941, "biggest_recent_change": 0.1277539255417821},
{"total_number_of_episodes": 12633, "number_of_timesteps": 1432156, "per_episode_reward": -134.37, "episode_reward_trend_value": 4.1346578975599695e-05, "biggest_recent_change": 0.1277539255417821},
{"total_number_of_episodes": 12643, "number_of_timesteps": 1433517, "per_episode_reward": -134.41, "episode_reward_trend_value": -0.001767765944127733, "biggest_recent_change": 0.10730827090941375},
{"total_number_of_episodes": 12656, "number_of_timesteps": 1434993, "per_episode_reward": -134.43, "episode_reward_trend_value": -0.0012660312458349508, "biggest_recent_change": 0.10730827090941375},
{"total_number_of_episodes": 12666, "number_of_timesteps": 1436248, "per_episode_reward": -134.44, "episode_reward_trend_value": -0.00013233927206973323, "biggest_recent_change": 0.06676867612810611},
{"total_number_of_episodes": 12676, "number_of_timesteps": 1437583, "per_episode_reward": -134.41, "episode_reward_trend_value": 0.00013301866021069803, "biggest_recent_change": 0.06676867612810611},
{"total_number_of_episodes": 12686, "number_of_timesteps": 1438679, "per_episode_reward": -134.45, "episode_reward_trend_value": -0.000256646055098031, "biggest_recent_change": 0.06676867612810611},
{"total_number_of_episodes": 12696, "number_of_timesteps": 1439987, "per_episode_reward": -134.51, "episode_reward_trend_value": -0.0015716955946342322, "biggest_recent_change": 0.051585782430151994},
{"total_number_of_episodes": 12706, "number_of_timesteps": 1441209, "per_episode_reward": -134.54, "episode_reward_trend_value": -0.0021040365445644383, "biggest_recent_change": 0.051585782430151994},
{"total_number_of_episodes": 12717, "number_of_timesteps": 1442014, "per_episode_reward": -134.48, "episode_reward_trend_value": -0.0016556034828789103, "biggest_recent_change": 0.06098926402790994},
{"total_number_of_episodes": 12727, "number_of_timesteps": 1442878, "per_episode_reward": -134.41, "episode_reward_trend_value": -0.00043975073152340526, "biggest_recent_change": 0.06426877934575259},

{"total_number_of_episodes": 12738, "number_of_timesteps": 1444126, "per_episode_reward": -134.43, "episode_reward_trend_value": -0.0002776610868446975, "biggest_recent_change": 0.06426877934575259},
{"total_number_of_episodes": 12748, "number_of_timesteps": 1445375, "per_episode_reward": -134.56, "episode_reward_trend_value": -0.0013982581279141945, "biggest_recent_change": 0.12723603575190623},
{"total_number_of_episodes": 12758, "number_of_timesteps": 1446976, "per_episode_reward": -134.67, "episode_reward_trend_value": -0.00250869300925937, "biggest_recent_change": 0.12723603575190623},
{"total_number_of_episodes": 12768, "number_of_timesteps": 1448270, "per_episode_reward": -134.56, "episode_reward_trend_value": -0.0016860899093813942, "biggest_recent_change": 0.12723603575190623},
{"total_number_of_episodes": 12778, "number_of_timesteps": 1449574, "per_episode_reward": -134.56, "episode_reward_trend_value": -0.001215047600820185, "biggest_recent_change": 0.12723603575190623},
{"total_number_of_episodes": 12788, "number_of_timesteps": 1451251, "per_episode_reward": -134.55, "episode_reward_trend_value": -0.0005219649971912254, "biggest_recent_change": 0.12723603575190623},
{"total_number_of_episodes": 12798, "number_of_timesteps": 1452371, "per_episode_reward": -134.54, "episode_reward_trend_value": -4.89036582267646e-06, "biggest_recent_change": 0.12723603575190623},
{"total_number_of_episodes": 12808, "number_of_timesteps": 1453430, "per_episode_reward": -134.48, "episode_reward_trend_value": -3.4997268650095575e-05, "biggest_recent_change": 0.12723603575190623},
{"total_number_of_episodes": 12818, "number_of_timesteps": 1454344, "per_episode_reward": -134.38, "episode_reward_trend_value": 0.0003403789631448717, "biggest_recent_change": 0.12723603575190623},
{"total_number_of_episodes": 12828, "number_of_timesteps": 1455337, "per_episode_reward": -134.33, "episode_reward_trend_value": 0.0011199764427863733, "biggest_recent_change": 0.12723603575190623},
{"total_number_of_episodes": 12838, "number_of_timesteps": 1456421, "per_episode_reward": -134.33, "episode_reward_trend_value": 0.002524103417667018, "biggest_recent_change": 0.10521513259160997},
{"total_number_of_episodes": 12848, "number_of_timesteps": 1457336, "per_episode_reward": -134.3, "episode_reward_trend_value": 0.004029376335766541, "biggest_recent_change": 0.1013167308319396},
{"total_number_of_episodes": 12859, "number_of_timesteps": 1458305, "per_episode_reward": -134.29, "episode_reward_trend_value": 0.003074778629919529, "biggest_recent_change": 0.09805264020729965},
{"total_number_of_episodes": 12869, "number_of_timesteps": 1459284, "per_episode_reward": -134.23, "episode_reward_trend_value": 0.0037535055098970815, "biggest_recent_change": 0.09805264020729965},
{"total_number_of_episodes": 12879, "number_of_timesteps": 1460374, "per_episode_reward": -134.13, "episode_reward_trend_value": 0.004735521299341233, "biggest_recent_change": 0.09917307294642796},
{"total_number_of_episodes": 12889, "number_of_timesteps": 1461207, "per_episode_reward": -134.0, "episode_reward_trend_value": 0.005988715937029572, "biggest_recent_change": 0.12791026022580354},
{"total_number_of_episodes": 12900, "number_of_timesteps": 1462259, "per_episode_reward": -133.96, "episode_reward_trend_value": 0.00574165730070288, "biggest_recent_change": 0.12791026022580354},
{"total_number_of_episodes": 12910, "number_of_timesteps": 1463153, "per_episode_reward": -133.91, "episode_reward_trend_value": 0.005218234396387642, "biggest_recent_change": 0.12791026022580354},
{"total_number_of_episodes": 12920, "number_of_timesteps": 1464334, "per_episode_reward": -133.9, "episode_reward_trend_value": 0.004818156389050109, "biggest_recent_change": 0.12791026022580354},
{"total_number_of_episodes": 12930, "number_of_timesteps": 1465471, "per_episode_reward": -133.98, "episode_reward_trend_value": 0.003895977788674701, "biggest_recent_change": 0.12791026022580354},
{"total_number_of_episodes": 12940, "number_of_timesteps": 1466625, "per_episode_reward": -134.0, "episode_reward_trend_value": 0.0033112480133436544, "biggest_recent_change": 0.12791026022580354},
{"total_number_of_episodes": 12950, "number_of_timesteps": 1467976, "per_episode_reward": -134.04, "episode_reward_trend_value": 0.0027592497147307113, "biggest_recent_change": 0.12791026022580354},
{"total_number_of_episodes": 12960, "number_of_timesteps": 1469384, "per_episode_reward": -134.12, "episode_reward_trend_value": 0.0011519364239556277, "biggest_recent_change": 0.12791026022580354},
{"total_number_of_episodes": 12970, "number_of_timesteps": 1470788, "per_episode_reward": -134.06, "episode_reward_trend_value": 0.0007105452660327829, "biggest_recent_change": 0.12791026022580354},
{"total_number_of_episodes": 12981, "number_of_timesteps": 1472129, "per_episode_reward": -134.13, "episode_reward_trend_value": -0.0014347341235912204, "biggest_recent_change": 0.08386068204643493},
{"total_number_of_episodes": 12991, "number_of_timesteps": 1473249, "per_episode_reward": -134.18, "episode_reward_trend_value": -0.00239717155952298, "biggest_recent_change": 0.08386068204643493},
{"total_number_of_episodes": 13001, "number_of_timesteps": 1474312, "per_episode_reward": -134.1, "episode_reward_trend_value": -0.002117133405744198, "biggest_recent_change": 0.08386068204643493},
{"total_number_of_episodes": 13011, "number_of_timesteps": 1475436, "per_episode_reward": -134.03, "episode_reward_trend_value": -0.0014764134256709995, "biggest_recent_change": 0.08386068204643493},
{"total_number_of_episodes": 13021, "number_of_timesteps": 1476432, "per_episode_reward": -134.03, "episode_reward_trend_value": -0.0005166320218803675, "biggest_recent_change": 0.08357277697177778},
{"total_number_of_episodes": 13031, "number_of_timesteps": 1477538, "per_episode_reward": -134.07, "episode_reward_trend_value": -0.0007383194132602157, "biggest_recent_change": 0.08357277697177778},
{"total_number_of_episodes": 13042, "number_of_timesteps": 1478852, "per_episode_reward": -134.04, "episode_reward_trend_value": -2.5400076528588516e-06, "biggest_recent_change": 0.08357277697177778},
{"total_number_of_episodes": 13052, "number_of_timesteps": 1479891, "per_episode_reward": -134.04, "episode_reward_trend_value": 0.0009174863426718756, "biggest_recent_change": 0.0761480126590186},
{"total_number_of_episodes": 13062, "number_of_timesteps": 1481148, "per_episode_reward": -133.98, "episode_reward_trend_value": 0.0008809127630466188, "biggest_recent_change": 0.0761480126590186},
{"total_number_of_episodes": 13072, "number_of_timesteps": 1482293, "per_episode_reward": -134.1, "episode_reward_trend_value": 0.0003564629540417425, "biggest_recent_change": 0.11236536765079563},
{"total_number_of_episodes": 13082, "number_of_timesteps": 1483929, "per_episode_reward": -134.09, "episode_reward_trend_value": 0.0009584832753006367, "biggest_recent_change": 0.11236536765079563},
{"total_number_of_episodes": 13092, "number_of_timesteps": 1484857, "per_episode_reward": -134.03, "episode_reward_trend_value": 0.0008379345364498173, "biggest_recent_change": 0.11236536765079563},
{"total_number_of_episodes": 13102, "number_of_timesteps": 1485912, "per_episode_reward": -134.05, "episode_reward_trend_value": -0.0002520629365392324, "biggest_recent_change": 0.11236536765079563},
{"total_number_of_episodes": 13112, "number_of_timesteps": 1486950, "per_episode_reward": -134.03, "episode_reward_trend_value": 3.3841545671483195e-05, "biggest_recent_change": 0.11236536765079563},
{"total_number_of_episodes": 13122, "number_of_timesteps": 1487875, "per_episode_reward": -134.01, "episode_reward_trend_value": 0.0006853380257451945, "biggest_recent_change": 0.11236536765079563},
{"total_number_of_episodes": 13132, "number_of_timesteps": 1489109, "per_episode_reward": -134.03, "episode_reward_trend_value": 6.846372302757371e-05, "biggest_recent_change": 0.11236536765079563},
{"total_number_of_episodes": 13142, "number_of_timesteps": 1491142, "per_episode_reward": -133.97, "episode_reward_trend_value": 0.0008014524750958825, "biggest_recent_change": 0.11236536765079563},
{"total_number_of_episodes": 13152, "number_of_timesteps": 1492410, "per_episode_reward": -134.01, "episode_reward_trend_value": -0.00030938680518520164, "biggest_recent_change": 0.11236536765079563},
{"total_number_of_episodes": 13163, "number_of_timesteps": 1493775, "per_episode_reward": -134.09, "episode_reward_trend_value": 9.114691507805775e-05, "biggest_recent_change": 0.07631733282710229},
{"total_number_of_episodes": 13173, "number_of_timesteps": 1495034, "per_episode_reward": -133.97, "episode_reward_trend_value": 0.0013859224295427138, "biggest_recent_change": 0.12013662148530102},
{"total_number_of_episodes": 13183, "number_of_timesteps": 1496273, "per_episode_reward": -134.07, "episode_reward_trend_value": -0.000518998853631716, "biggest_recent_change": 0.12013662148530102},
{"total_number_of_episodes": 13193, "number_of_timesteps": 1497415, "per_episode_reward": -134.04, "episode_reward_trend_value": 0.00016796368514791185, "biggest_recent_change": 0.12013662148530102},
{"total_number_of_episodes": 13203, "number_of_timesteps": 1498241, "per_episode_reward": -133.84, "episode_reward_trend_value": 0.0020594762714160374, "biggest_recent_change": 0.19848718045781766},
{"total_number_of_episodes": 13216, "number_of_timesteps": 1499351, "per_episode_reward": -133.66, "episode_reward_trend_value": 0.0038708508819967043, "biggest_recent_change": 0.19848718045781766},
{"total_number_of_episodes": 13226, "number_of_timesteps": 1500135, "per_episode_reward": -133.6, "episode_reward_trend_value": 0.004828894062410111, "biggest_recent_change": 0.19848718045781766},
{"total_number_of_episodes": 13237, "number_of_timesteps": 1500995, "per_episode_reward": -133.44, "episode_reward_trend_value": 0.005840262374993839, "biggest_recent_change": 0.19848718045781766},
{"total_number_of_episodes": 13247, "number_of_timesteps": 1502160, "per_episode_reward": -133.48, "episode_reward_trend_value": 0.0059465173741469046, "biggest_recent_change": 0.19848718045781766},
{"total_number_of_episodes": 13258, "number_of_timesteps": 1503304, "per_episode_reward": -133.38, "episode_reward_trend_value": 0.007904272494091754, "biggest_recent_change": 0.19848718045781766},
{"total_number_of_episodes": 13268, "number_of_timesteps": 1504507, "per_episode_reward": -133.38, "episode_reward_trend_value": 0.006521740811871268, "biggest_recent_change": 0.19848718045781766},
{"total_number_of_episodes": 13278, "number_of_timesteps": 1505975, "per_episode_reward": -133.32, "episode_reward_trend_value": 0.008387267883806102, "biggest_recent_change": 0.19848718045781766},
{"total_number_of_episodes": 13288, "number_of_timesteps": 1507441, "per_episode_reward": -133.33, "episode_reward_trend_value": 0.007857755162983596, "biggest_recent_change": 0.19848718045781766},
{"total_number_of_episodes": 13298, "number_of_timesteps": 1508757, "per_episode_reward": -133.34, "episode_reward_trend_value": 0.005541434968434563, "biggest_recent_change": 0.17934028319226059},
{"total_number_of_episodes": 13308, "number_of_timesteps": 1509713, "per_episode_reward": -133.28, "episode_reward_trend_value": 0.004251587847548106, "biggest_recent_change": 0.15622173037613152},

{"total_number_of_episodes": 13319, "number_of_timesteps": 1511319, "per_episode_reward": -133.32, "episode_reward_trend_value": 0.0030427534962029767, "biggest_recent_change": 0.15622173037613152},
{"total_number_of_episodes": 13329, "number_of_timesteps": 1512322, "per_episode_reward": -133.31, "episode_reward_trend_value": 0.001476096222274729, "biggest_recent_change": 0.09988062796793429},
{"total_number_of_episodes": 13339, "number_of_timesteps": 1513249, "per_episode_reward": -133.22, "episode_reward_trend_value": 0.002811626360162399, "biggest_recent_change": 0.09988062796793429},
{"total_number_of_episodes": 13349, "number_of_timesteps": 1514228, "per_episode_reward": -133.18, "episode_reward_trend_value": 0.002158507285131211, "biggest_recent_change": 0.0859413736754675},
{"total_number_of_episodes": 13359, "number_of_timesteps": 1516165, "per_episode_reward": -133.24, "episode_reward_trend_value": 0.001536341275839782, "biggest_recent_change": 0.0859413736754675},
{"total_number_of_episodes": 13370, "number_of_timesteps": 1517346, "per_episode_reward": -133.19, "episode_reward_trend_value": 0.0014839185836794714, "biggest_recent_change": 0.0859413736754675},
{"total_number_of_episodes": 13380, "number_of_timesteps": 1518201, "per_episode_reward": -133.06, "episode_reward_trend_value": 0.00306823285192858, "biggest_recent_change": 0.13000241238705712},
{"total_number_of_episodes": 13390, "number_of_timesteps": 1519214, "per_episode_reward": -133.07, "episode_reward_trend_value": 0.0029701923224327706, "biggest_recent_change": 0.13000241238705712},
{"total_number_of_episodes": 13400, "number_of_timesteps": 1520505, "per_episode_reward": -133.03, "episode_reward_trend_value": 0.002753331068499026, "biggest_recent_change": 0.13000241238705712},
{"total_number_of_episodes": 13410, "number_of_timesteps": 1521619, "per_episode_reward": -132.99, "episode_reward_trend_value": 0.003713549561260581, "biggest_recent_change": 0.13000241238705712},
{"total_number_of_episodes": 13422, "number_of_timesteps": 1522683, "per_episode_reward": -132.98, "episode_reward_trend_value": 0.0036594643140246156, "biggest_recent_change": 0.13000241238705712},
{"total_number_of_episodes": 13432, "number_of_timesteps": 1523652, "per_episode_reward": -132.91, "episode_reward_trend_value": 0.003508071805712297, "biggest_recent_change": 0.13000241238705712},
{"total_number_of_episodes": 13442, "number_of_timesteps": 1524718, "per_episode_reward": -132.83, "episode_reward_trend_value": 0.0038892306546829208, "biggest_recent_change": 0.13000241238705712},
{"total_number_of_episodes": 13452, "number_of_timesteps": 1526067, "per_episode_reward": -132.8, "episode_reward_trend_value": 0.004905742741622197, "biggest_recent_change": 0.13000241238705712},
{"total_number_of_episodes": 13462, "number_of_timesteps": 1527321, "per_episode_reward": -132.8, "episode_reward_trend_value": 0.004231091390894272, "biggest_recent_change": 0.13000241238705712},
{"total_number_of_episodes": 13472, "number_of_timesteps": 1528431, "per_episode_reward": -132.78, "episode_reward_trend_value": 0.0030855442895974267, "biggest_recent_change": 0.07540420762248345},
{"total_number_of_episodes": 13482, "number_of_timesteps": 1529406, "per_episode_reward": -132.74, "episode_reward_trend_value": 0.0037417443577118722, "biggest_recent_change": 0.07540420762248345},
{"total_number_of_episodes": 13492, "number_of_timesteps": 1530995, "per_episode_reward": -132.69, "episode_reward_trend_value": 0.0037550662408894673, "biggest_recent_change": 0.07540420762248345},
{"total_number_of_episodes": 13502, "number_of_timesteps": 1532373, "per_episode_reward": -132.61, "episode_reward_trend_value": 0.004184260615992091, "biggest_recent_change": 0.07890050241454105},
{"total_number_of_episodes": 13512, "number_of_timesteps": 1533615, "per_episode_reward": -132.56, "episode_reward_trend_value": 0.00471704587826183, "biggest_recent_change": 0.07890050241454105},
{"total_number_of_episodes": 13524, "number_of_timesteps": 1534793, "per_episode_reward": -132.53, "episode_reward_trend_value": 0.004248602927985859, "biggest_recent_change": 0.07890050241454105},
{"total_number_of_episodes": 13534, "number_of_timesteps": 1535855, "per_episode_reward": -132.39, "episode_reward_trend_value": 0.004866595077831133, "biggest_recent_change": 0.1310235011085581},
{"total_number_of_episodes": 13545, "number_of_timesteps": 1536965, "per_episode_reward": -132.31, "episode_reward_trend_value": 0.005504362878631102, "biggest_recent_change": 0.1310235011085581},
{"total_number_of_episodes": 13556, "number_of_timesteps": 1538168, "per_episode_reward": -132.27, "episode_reward_trend_value": 0.005948922667290743, "biggest_recent_change": 0.1310235011085581},
{"total_number_of_episodes": 13566, "number_of_timesteps": 1539285, "per_episode_reward": -132.24, "episode_reward_trend_value": 0.005933977737150384, "biggest_recent_change": 0.1310235011085581},
{"total_number_of_episodes": 13576, "number_of_timesteps": 1539996, "per_episode_reward": -132.17, "episode_reward_trend_value": 0.006344309252456684, "biggest_recent_change": 0.1310235011085581},
{"total_number_of_episodes": 13586, "number_of_timesteps": 1540929, "per_episode_reward": -132.12, "episode_reward_trend_value": 0.006360777057089864, "biggest_recent_change": 0.1310235011085581},
{"total_number_of_episodes": 13597, "number_of_timesteps": 1542533, "per_episode_reward": -132.07, "episode_reward_trend_value": 0.006079300779506033, "biggest_recent_change": 0.1310235011085581},
{"total_number_of_episodes": 13608, "number_of_timesteps": 1543526, "per_episode_reward": -131.97, "episode_reward_trend_value": 0.006466674140939215, "biggest_recent_change": 0.1310235011085581},
{"total_number_of_episodes": 13620, "number_of_timesteps": 1544628, "per_episode_reward": -131.96, "episode_reward_trend_value": 0.006233590578756005, "biggest_recent_change": 0.1310235011085581},
{"total_number_of_episodes": 13632, "number_of_timesteps": 1545727, "per_episode_reward": -131.83, "episode_reward_trend_value": 0.006261764293723597, "biggest_recent_change": 0.13355913545564135},
{"total_number_of_episodes": 13642, "number_of_timesteps": 1546750, "per_episode_reward": -131.84, "episode_reward_trend_value": 0.005185989954933095, "biggest_recent_change": 0.13355913545564135},
{"total_number_of_episodes": 13654, "number_of_timesteps": 1547931, "per_episode_reward": -131.65, "episode_reward_trend_value": 0.006925287271906831, "biggest_recent_change": 0.1928636227979439},
{"total_number_of_episodes": 13664, "number_of_timesteps": 1548848, "per_episode_reward": -131.4, "episode_reward_trend_value": 0.00936340505334259, "biggest_recent_change": 0.2449887298869271},
{"total_number_of_episodes": 13674, "number_of_timesteps": 1549951, "per_episode_reward": -131.26, "episode_reward_trend_value": 0.0101277561198638, "biggest_recent_change": 0.2449887298869271},
{"total_number_of_episodes": 13685, "number_of_timesteps": 1551094, "per_episode_reward": -131.17, "episode_reward_trend_value": 0.010601741520115286, "biggest_recent_change": 0.2449887298869271},
{"total_number_of_episodes": 13696, "number_of_timesteps": 1552365, "per_episode_reward": -131.18, "episode_reward_trend_value": 0.009874910415542911, "biggest_recent_change": 0.2449887298869271},
{"total_number_of_episodes": 13706, "number_of_timesteps": 1553804, "per_episode_reward": -131.19, "episode_reward_trend_value": 0.008715017606388958, "biggest_recent_change": 0.2449887298869271},
{"total_number_of_episodes": 13716, "number_of_timesteps": 1554956, "per_episode_reward": -131.13, "episode_reward_trend_value": 0.009305110269115681, "biggest_recent_change": 0.2449887298869271},
{"total_number_of_episodes": 13726, "number_of_timesteps": 1556048, "per_episode_reward": -131.05, "episode_reward_trend_value": 0.008677624104348386, "biggest_recent_change": 0.2449887298869271},
{"total_number_of_episodes": 13736, "number_of_timesteps": 1557287, "per_episode_reward": -131.03, "episode_reward_trend_value": 0.00895462484958279, "biggest_recent_change": 0.2449887298869271},
{"total_number_of_episodes": 13746, "number_of_timesteps": 1558414, "per_episode_reward": -131.01, "episode_reward_trend_value": 0.007121016259135457, "biggest_recent_change": 0.2449887298869271},
{"total_number_of_episodes": 13756, "number_of_timesteps": 1559993, "per_episode_reward": -130.95, "episode_reward_trend_value": 0.005035537193463963, "biggest_recent_change": 0.14597415378855771},
{"total_number_of_episodes": 13767, "number_of_timesteps": 1561632, "per_episode_reward": -130.95, "episode_reward_trend_value": 0.0033894587460436137, "biggest_recent_change": 0.08907628738404583},
{"total_number_of_episodes": 13777, "number_of_timesteps": 1562417, "per_episode_reward": -130.82, "episode_reward_trend_value": 0.003835155209701055, "biggest_recent_change": 0.12918896911321553},
{"total_number_of_episodes": 13787, "number_of_timesteps": 1563332, "per_episode_reward": -130.77, "episode_reward_trend_value": 0.004531557683253911, "biggest_recent_change": 0.12918896911321553},
{"total_number_of_episodes": 13798, "number_of_timesteps": 1564587, "per_episode_reward": -130.75, "episode_reward_trend_value": 0.004855550671010178, "biggest_recent_change": 0.12918896911321553},
{"total_number_of_episodes": 13808, "number_of_timesteps": 1565424, "per_episode_reward": -130.69, "episode_reward_trend_value": 0.004801482976962272, "biggest_recent_change": 0.12918896911321553},
{"total_number_of_episodes": 13818, "number_of_timesteps": 1566520, "per_episode_reward": -130.64, "episode_reward_trend_value": 0.004600605295013654, "biggest_recent_change": 0.12918896911321553},
{"total_number_of_episodes": 13829, "number_of_timesteps": 1567471, "per_episode_reward": -130.48, "episode_reward_trend_value": 0.006157359800331127, "biggest_recent_change": 0.15681730120428483},
{"total_number_of_episodes": 13840, "number_of_timesteps": 1568369, "per_episode_reward": -130.35, "episode_reward_trend_value": 0.007273522860136457, "biggest_recent_change": 0.15681730120428483},
{"total_number_of_episodes": 13850, "number_of_timesteps": 1569199, "per_episode_reward": -130.28, "episode_reward_trend_value": 0.00738580309247128, "biggest_recent_change": 0.15681730120428483},
{"total_number_of_episodes": 13861, "number_of_timesteps": 1570177, "per_episode_reward": -130.12, "episode_reward_trend_value": 0.009188332583667285, "biggest_recent_change": 0.16005474772836692},
{"total_number_of_episodes": 13871, "number_of_timesteps": 1571176, "per_episode_reward": -129.94, "episode_reward_trend_value": 0.009755435283489077, "biggest_recent_change": 0.18022821209717677},
{"total_number_of_episodes": 13881, "number_of_timesteps": 1572163, "per_episode_reward": -129.85, "episode_reward_trend_value": 0.010247746723480746, "biggest_recent_change": 0.18022821209717677},
{"total_number_of_episodes": 13891, "number_of_timesteps": 1573371, "per_episode_reward": -129.81, "episode_reward_trend_value": 0.010492450138167441, "biggest_recent_change": 0.18022821209717677},
{"total_number_of_episodes": 13901, "number_of_timesteps": 1574744, "per_episode_reward": -129.76, "episode_reward_trend_value": 0.010384145131318216, "biggest_recent_change": 0.18022821209717677},
{"total_number_of_episodes": 13911, "number_of_timesteps": 1575672, "per_episode_reward": -129.7, "episode_reward_trend_value": 0.010350740177719647, "biggest_recent_change": 0.18022821209717677},
{"total_number_of_episodes": 13922, "number_of_timesteps": 1576544, "per_episode_reward": -129.34, "episode_reward_trend_value": 0.012662179578221197, "biggest_recent_change": 0.3648468472494244},
{"total_number_of_episodes": 13933, "number_of_timesteps": 1577508, "per_episode_reward": -129.25, "episode_reward_trend_value": 0.012248377162533883, "biggest_recent_change": 0.3648468472494244},
{"total_number_of_episodes": 13943, "number_of_timesteps": 1578475, "per_episode_reward": -129.17, "episode_reward_trend_value": 0.01234104391179503, "biggest_recent_change": 0.3648468472494244},
{"total_number_of_episodes": 13953, "number_of_timesteps": 1579217, "per_episode_reward": -129.09, "episode_reward_trend_value": 0.011531201018833788, "biggest_recent_change": 0.3648468472494244},
{"total_number_of_episodes": 13963, "number_of_timesteps": 1580244, "per_episode_reward": -128.94, "episode_reward_trend_value": 0.011097302103686325, "biggest_recent_change": 0.3648468472494244},
{"total_number_of_episodes": 13974, "number_of_timesteps": 1581250, "per_episode_reward": -128.82, "episode_reward_trend_value": 0.011437589968605898, "biggest_recent_change": 0.3648468472494244},
{"total_number_of_episodes": 13985, "number_of_timesteps": 1582358, "per_episode_reward": -128.66, "episode_reward_trend_value": 0.012762202248884729, "biggest_recent_change": 0.3648468472494244},
{"total_number_of_episodes": 13996, "number_of_timesteps": 1583710, "per_episode_reward": -128.6, "episode_reward_trend_value": 0.012923007211202275, "biggest_recent_change": 0.3648468472494244},
{"total_number_of_episodes": 14006, "number_of_timesteps": 1584627, "per_episode_reward": -128.55, "episode_reward_trend_value": 0.01286294562534288, "biggest_recent_change": 0.3648468472494244},
{"total_number_of_episodes": 14017, "number_of_timesteps": 1585609, "per_episode_reward": -128.37, "episode_reward_trend_value": 0.010826634900303134, "biggest_recent_change": 0.18157888199584704},
{"total_number_of_episodes": 14027, "number_of_timesteps": 1586893, "per_episode_reward": -128.37, "episode_reward_trend_value": 0.009814953704433076, "biggest_recent_change": 0.18157888199584704},
{"total_number_of_episodes": 14037, "number_of_timesteps": 1588369, "per_episode_reward": -128.21, "episode_reward_trend_value": 0.010727904910032117, "biggest_recent_change": 0.18157888199584704},
{"total_number_of_episodes": 14047, "number_of_timesteps": 1589762, "per_episode_reward": -128.22, "episode_reward_trend_value": 0.009656327897857548, "biggest_recent_change": 0.18157888199584704},
{"total_number_of_episodes": 14057, "number_of_timesteps": 1590821, "per_episode_reward": -128.19, "episode_reward_trend_value": 0.008337274723380183, "biggest_recent_change": 0.18157888199584704},
{"total_number_of_episodes": 14067, "number_of_timesteps": 1591834, "per_episode_reward": -128.16, "episode_reward_trend_value": 0.007361387014006798, "biggest_recent_change": 0.18157888199584704},
{"total_number_of_episodes": 14078, "number_of_timesteps": 1593097, "per_episode_reward": -128.02, "episode_reward_trend_value": 0.007093683724229373, "biggest_recent_change": 0.18157888199584704},
{"total_number_of_episodes": 14088, "number_of_timesteps": 1594282, "per_episode_reward": -127.98, "episode_reward_trend_value": 0.00686667768738008, "biggest_recent_change": 0.18157888199584704},
{"total_number_of_episodes": 14099, "number_of_timesteps": 1595549, "per_episode_reward": -127.9, "episode_reward_trend_value": 0.007172121537561004, "biggest_recent_change": 0.18157888199584704},
{"total_number_of_episodes": 14109, "number_of_timesteps": 1596502, "per_episode_reward": -127.79, "episode_reward_trend_value": 0.006352114591313789, "biggest_recent_change": 0.15790645082404353},
{"total_number_of_episodes": 14119, "number_of_timesteps": 1597491, "per_episode_reward": -127.63, "episode_reward_trend_value": 0.008204992645384362, "biggest_recent_change": 0.16675902486635152},
{"total_number_of_episodes": 14129, "number_of_timesteps": 1598417, "per_episode_reward": -127.56, "episode_reward_trend_value": 0.007147884740013903, "biggest_recent_change": 0.16675902486635152},
{"total_number_of_episodes": 14140, "number_of_timesteps": 1600003, "per_episode_reward": -127.58, "episode_reward_trend_value": 0.007088927607026107, "biggest_recent_change": 0.16675902486635152},
{"total_number_of_episodes": 14150, "number_of_timesteps": 1601104, "per_episode_reward": -127.51, "episode_reward_trend_value": 0.007594074072225965, "biggest_recent_change": 0.16675902486635152},
{"total_number_of_episodes": 14160, "number_of_timesteps": 1602163, "per_episode_reward": -127.4, "episode_reward_trend_value": 0.008455585401824017, "biggest_recent_change": 0.16675902486635152},
{"total_number_of_episodes": 14170, "number_of_timesteps": 1603136, "per_episode_reward": -127.22, "episode_reward_trend_value": 0.008875773140283469, "biggest_recent_change": 0.17290020860710342},
{"total_number_of_episodes": 14180, "number_of_timesteps": 1604081, "per_episode_reward": -127.09, "episode_reward_trend_value": 0.009932074592265867, "biggest_recent_change": 0.17290020860710342},
{"total_number_of_episodes": 14190, "number_of_timesteps": 1605344, "per_episode_reward": -126.95, "episode_reward_trend_value": 0.010535081497677526, "biggest_recent_change": 0.17290020860710342},
{"total_number_of_episodes": 14200, "number_of_timesteps": 1605985, "per_episode_reward": -126.75, "episode_reward_trend_value": 0.01153836892995391, "biggest_recent_change": 0.19807412573847216},
{"total_number_of_episodes": 14210, "number_of_timesteps": 1606893, "per_episode_reward": -126.69, "episode_reward_trend_value": 0.010457898927602275, "biggest_recent_change": 0.19807412573847216},
{"total_number_of_episodes": 14220, "number_of_timesteps": 1607777, "per_episode_reward": -126.46, "episode_reward_trend_value": 0.012246615660401498, "biggest_recent_change": 0.22375124529263246},
{"total_number_of_episodes": 14230, "number_of_timesteps": 1608545, "per_episode_reward": -126.36, "episode_reward_trend_value": 0.013544459801376262, "biggest_recent_change": 0.22375124529263246},
{"total_number_of_episodes": 14240, "number_of_timesteps": 1609286, "per_episode_reward": -126.26, "episode_reward_trend_value": 0.013927983481159523, "biggest_recent_change": 0.22375124529263246},
{"total_number_of_episodes": 14251, "number_of_timesteps": 1610059, "per_episode_reward": -126.18, "episode_reward_trend_value": 0.013451803100668278, "biggest_recent_change": 0.22375124529263246},
{"total_number_of_episodes": 14261, "number_of_timesteps": 1610767, "per_episode_reward": -126.04, "episode_reward_trend_value": 0.013140050790261645, "biggest_recent_change": 0.22375124529263246},
{"total_number_of_episodes": 14271, "number_of_timesteps": 1611789, "per_episode_reward": -125.92, "episode_reward_trend_value": 0.012930339381466479, "biggest_recent_change": 0.22375124529263246},
{"total_number_of_episodes": 14281, "number_of_timesteps": 1612839, "per_episode_reward": -125.8, "episode_reward_trend_value": 0.012800612780891008, "biggest_recent_change": 0.22375124529263246},
{"total_number_of_episodes": 14292, "number_of_timesteps": 1614240, "per_episode_reward": -125.76, "episode_reward_trend_value": 0.011032559168432165, "biggest_recent_change": 0.22375124529263246},
{"total_number_of_episodes": 14302, "number_of_timesteps": 1614958, "per_episode_reward": -125.55, "episode_reward_trend_value": 0.01256172985464856, "biggest_recent_change": 0.22375124529263246},
{"total_number_of_episodes": 14312, "number_of_timesteps": 1615966, "per_episode_reward": -125.37, "episode_reward_trend_value": 0.012141697896670836, "biggest_recent_change": 0.20714208641417997},
{"total_number_of_episodes": 14323, "number_of_timesteps": 1617344, "per_episode_reward": -125.27, "episode_reward_trend_value": 0.012073588591276201, "biggest_recent_change": 0.20714208641417997},
{"total_number_of_episodes": 14333, "number_of_timesteps": 1618394, "per_episode_reward": -125.3, "episode_reward_trend_value": 0.010680263448530524, "biggest_recent_change": 0.20714208641417997},
{"total_number_of_episodes": 14343, "number_of_timesteps": 1619228, "per_episode_reward": -125.14, "episode_reward_trend_value": 0.011623467135086843, "biggest_recent_change": 0.20714208641417997},
{"total_number_of_episodes": 14353, "number_of_timesteps": 1620006, "per_episode_reward": -125.06, "episode_reward_trend_value": 0.010925592077901551, "biggest_recent_change": 0.20714208641417997},
{"total_number_of_episodes": 14363, "number_of_timesteps": 1621058, "per_episode_reward": -124.97, "episode_reward_trend_value": 0.010579137129886836, "biggest_recent_change": 0.20714208641417997},
{"total_number_of_episodes": 14373, "number_of_timesteps": 1622309, "per_episode_reward": -124.93, "episode_reward_trend_value": 0.009652911599990294, "biggest_recent_change": 0.20714208641417997},
{"total_number_of_episodes": 14384, "number_of_timesteps": 1623332, "per_episode_reward": -124.83, "episode_reward_trend_value": 0.010318494811189776, "biggest_recent_change": 0.20714208641417997},
{"total_number_of_episodes": 14394, "number_of_timesteps": 1624076, "per_episode_reward": -124.7, "episode_reward_trend_value": 0.009518857933765269, "biggest_recent_change": 0.1859483690746373},
{"total_number_of_episodes": 14404, "number_of_timesteps": 1624947, "per_episode_reward": -124.46, "episode_reward_trend_value": 0.010056396992737386, "biggest_recent_change": 0.2343268843821278},
{"total_number_of_episodes": 14414, "number_of_timesteps": 1625908, "per_episode_reward": -124.31, "episode_reward_trend_value": 0.01065978832389618, "biggest_recent_change": 0.2343268843821278},
{"total_number_of_episodes": 14425, "number_of_timesteps": 1626984, "per_episode_reward": -124.18, "episode_reward_trend_value": 0.012443299992006492, "biggest_recent_change": 0.2343268843821278},
{"total_number_of_episodes": 14435, "number_of_timesteps": 1627839, "per_episode_reward": -124.09, "episode_reward_trend_value": 0.011646014808502515, "biggest_recent_change": 0.2343268843821278},
{"total_number_of_episodes": 14445, "number_of_timesteps": 1628601, "per_episode_reward": -123.94, "episode_reward_trend_value": 0.012355224811559158, "biggest_recent_change": 0.2343268843821278},
{"total_number_of_episodes": 14455, "number_of_timesteps": 1629432, "per_episode_reward": -123.93, "episode_reward_trend_value": 0.01150578388749829, "biggest_recent_change": 0.2343268843821278},
{"total_number_of_episodes": 14465, "number_of_timesteps": 1630388, "per_episode_reward": -123.85, "episode_reward_trend_value": 0.012025875042914119, "biggest_recent_change": 0.2343268843821278},
{"total_number_of_episodes": 14475, "number_of_timesteps": 1631223, "per_episode_reward": -123.82, "episode_reward_trend_value": 0.011241152610561123, "biggest_recent_change": 0.2343268843821278},
{"total_number_of_episodes": 14485, "number_of_timesteps": 1632142, "per_episode_reward": -123.67, "episode_reward_trend_value": 0.011406562701471994, "biggest_recent_change": 0.2343268843821278},
{"total_number_of_episodes": 14495, "number_of_timesteps": 1633063, "per_episode_reward": -123.61, "episode_reward_trend_value": 0.009477489071008292, "biggest_recent_change": 0.15040216930374584},
{"total_number_of_episodes": 14505, "number_of_timesteps": 1634057, "per_episode_reward": -123.59, "episode_reward_trend_value": 0.008066078445008411, "biggest_recent_change": 0.1500616756279527},
{"total_number_of_episodes": 14515, "number_of_timesteps": 1635214, "per_episode_reward": -123.5, "episode_reward_trend_value": 0.0075234517489886025, "biggest_recent_change": 0.1500616756279527},
{"total_number_of_episodes": 14525, "number_of_timesteps": 1636167, "per_episode_reward": -123.4, "episode_reward_trend_value": 0.007657248427428777, "biggest_recent_change": 0.1500616756279527},
{"total_number_of_episodes": 14537, "number_of_timesteps": 1637698, "per_episode_reward": -123.33, "episode_reward_trend_value": 0.0068308109769039515, "biggest_recent_change": 0.1500616756279527},
{"total_number_of_episodes": 14547, "number_of_timesteps": 1638774, "per_episode_reward": -123.3, "episode_reward_trend_value": 0.00703432900288495, "biggest_recent_change": 0.1500616756279527},
{"total_number_of_episodes": 14558, "number_of_timesteps": 1640018, "per_episode_reward": -123.2, "episode_reward_trend_value": 0.007258137259675992, "biggest_recent_change": 0.1500616756279527},
{"total_number_of_episodes": 14570, "number_of_timesteps": 1641169, "per_episode_reward": -123.08, "episode_reward_trend_value": 0.008263981581054087, "biggest_recent_change": 0.1500616756279527},
{"total_number_of_episodes": 14580, "number_of_timesteps": 1642174, "per_episode_reward": -123.08, "episode_reward_trend_value": 0.006572303877083465, "biggest_recent_change": 0.1187527596373883},
{"total_number_of_episodes": 14590, "number_of_timesteps": 1643142, "per_episode_reward": -122.91, "episode_reward_trend_value": 0.007751795911690351, "biggest_recent_change": 0.16686454075501445},
{"total_number_of_episodes": 14600, "number_of_timesteps": 1644142, "per_episode_reward": -122.83, "episode_reward_trend_value": 0.008443196171276195, "biggest_recent_change": 0.16686454075501445},
{"total_number_of_episodes": 14610, "number_of_timesteps": 1645208, "per_episode_reward": -122.76, "episode_reward_trend_value": 0.008183764361938333, "biggest_recent_change": 0.16686454075501445},
{"total_number_of_episodes": 14622, "number_of_timesteps": 1646354, "per_episode_reward": -122.79, "episode_reward_trend_value": 0.0067538622896609335, "biggest_recent_change": 0.16686454075501445},
{"total_number_of_episodes": 14632, "number_of_timesteps": 1647340, "per_episode_reward": -122.69, "episode_reward_trend_value": 0.007057099731101996, "biggest_recent_change": 0.16686454075501445},
{"total_number_of_episodes": 14642, "number_of_timesteps": 1648509, "per_episode_reward": -122.62, "episode_reward_trend_value": 0.00761608820149762, "biggest_recent_change": 0.16686454075501445},
{"total_number_of_episodes": 14652, "number_of_timesteps": 1649518, "per_episode_reward": -122.54, "episode_reward_trend_value": 0.007270253920282717, "biggest_recent_change": 0.16686454075501445},
{"total_number_of_episodes": 14663, "number_of_timesteps": 1650302, "per_episode_reward": -122.46, "episode_reward_trend_value": 0.00691912911185742, "biggest_recent_change": 0.16686454075501445},
{"total_number_of_episodes": 14673, "number_of_timesteps": 1651143, "per_episode_reward": -122.4, "episode_reward_trend_value": 0.007595546252227495, "biggest_recent_change": 0.16686454075501445},
{"total_number_of_episodes": 14683, "number_of_timesteps": 1652363, "per_episode_reward": -122.29, "episode_reward_trend_value": 0.006950103294810441, "biggest_recent_change": 0.10877467458747958},
{"total_number_of_episodes": 14695, "number_of_timesteps": 1653309, "per_episode_reward": -122.2, "episode_reward_trend_value": 0.00699913399581157, "biggest_recent_change": 0.10877467458747958},
{"total_number_of_episodes": 14705, "number_of_timesteps": 1654107, "per_episode_reward": -122.1, "episode_reward_trend_value": 0.007401028721730698, "biggest_recent_change": 0.10877467458747958},
{"total_number_of_episodes": 14715, "number_of_timesteps": 1655060, "per_episode_reward": -122.0, "episode_reward_trend_value": 0.008819104653707655, "biggest_recent_change": 0.10877467458747958},
{"total_number_of_episodes": 14726, "number_of_timesteps": 1655901, "per_episode_reward": -121.88, "episode_reward_trend_value": 0.009050142731023432, "biggest_recent_change": 0.11956807193980978},
{"total_number_of_episodes": 14736, "number_of_timesteps": 1656730, "per_episode_reward": -121.77, "episode_reward_trend_value": 0.009413476264397976, "biggest_recent_change": 0.11956807193980978},
{"total_number_of_episodes": 14746, "number_of_timesteps": 1657602, "per_episode_reward": -121.68, "episode_reward_trend_value": 0.009547030675551899, "biggest_recent_change": 0.11956807193980978},
{"total_number_of_episodes": 14756, "number_of_timesteps": 1658622, "per_episode_reward": -121.6, "episode_reward_trend_value": 0.009466900363753281, "biggest_recent_change": 0.11956807193980978},
{"total_number_of_episodes": 14766, "number_of_timesteps": 1659621, "per_episode_reward": -121.54, "episode_reward_trend_value": 0.00951616522620845, "biggest_recent_change": 0.11956807193980978},
{"total_number_of_episodes": 14776, "number_of_timesteps": 1660444, "per_episode_reward": -121.45, "episode_reward_trend_value": 0.00930174671982466, "biggest_recent_change": 0.11956807193980978},
{"total_number_of_episodes": 14786, "number_of_timesteps": 1661343, "per_episode_reward": -121.4, "episode_reward_trend_value": 0.008905613190754183, "biggest_recent_change": 0.11956807193980978},
{"total_number_of_episodes": 14796, "number_of_timesteps": 1662243, "per_episode_reward": -121.35, "episode_reward_trend_value": 0.008321736856540776, "biggest_recent_change": 0.11956807193980978},
{"total_number_of_episodes": 14806, "number_of_timesteps": 1663139, "per_episode_reward": -121.13, "episode_reward_trend_value": 0.009711680213071993, "biggest_recent_change": 0.22181780545335528},
{"total_number_of_episodes": 14816, "number_of_timesteps": 1663872, "per_episode_reward": -121.0, "episode_reward_trend_value": 0.00975308549564902, "biggest_recent_change": 0.22181780545335528},
{"total_number_of_episodes": 14826, "number_of_timesteps": 1664721, "per_episode_reward": -120.54, "episode_reward_trend_value": 0.013666971098780007, "biggest_recent_change": 0.4638531440222806},
{"total_number_of_episodes": 14837, "number_of_timesteps": 1665779, "per_episode_reward": -120.44, "episode_reward_trend_value": 0.013839836845275974, "biggest_recent_change": 0.4638531440222806},
{"total_number_of_episodes": 14847, "number_of_timesteps": 1666828, "per_episode_reward": -120.44, "episode_reward_trend_value": 0.012918812866250563, "biggest_recent_change": 0.4638531440222806},
{"total_number_of_episodes": 14857, "number_of_timesteps": 1667694, "per_episode_reward": -120.34, "episode_reward_trend_value": 0.013294543640179925, "biggest_recent_change": 0.4638531440222806},
{"total_number_of_episodes": 14867, "number_of_timesteps": 1668554, "per_episode_reward": -120.39, "episode_reward_trend_value": 0.011801979759695295, "biggest_recent_change": 0.4638531440222806},
{"total_number_of_episodes": 14877, "number_of_timesteps": 1669568, "per_episode_reward": -120.29, "episode_reward_trend_value": 0.012323347096158305, "biggest_recent_change": 0.4638531440222806},
{"total_number_of_episodes": 14887, "number_of_timesteps": 1670424, "per_episode_reward": -120.13, "episode_reward_trend_value": 0.013496516465810593, "biggest_recent_change": 0.4638531440222806},
{"total_number_of_episodes": 14897, "number_of_timesteps": 1671590, "per_episode_reward": -120.12, "episode_reward_trend_value": 0.011156300276551356, "biggest_recent_change": 0.4638531440222806},
{"total_number_of_episodes": 14907, "number_of_timesteps": 1672821, "per_episode_reward": -120.08, "episode_reward_trend_value": 0.01027972594090648, "biggest_recent_change": 0.4638531440222806},
{"total_number_of_episodes": 14917, "number_of_timesteps": 1673762, "per_episode_reward": -119.94, "episode_reward_trend_value": 0.006679550743153901, "biggest_recent_change": 0.15458125740227047},
{"total_number_of_episodes": 14927, "number_of_timesteps": 1674991, "per_episode_reward": -119.9, "episode_reward_trend_value": 0.005926374511882986, "biggest_recent_change": 0.15458125740227047},
{"total_number_of_episodes": 14937, "number_of_timesteps": 1675849, "per_episode_reward": -119.83, "episode_reward_trend_value": 0.006774470051014071, "biggest_recent_change": 0.15458125740227047},
{"total_number_of_episodes": 14948, "number_of_timesteps": 1676799, "per_episode_reward": -119.74, "episode_reward_trend_value": 0.006712328112966759, "biggest_recent_change": 0.15458125740227047},
{"total_number_of_episodes": 14958, "number_of_timesteps": 1677698, "per_episode_reward": -119.63, "episode_reward_trend_value": 0.008388090203018648, "biggest_recent_change": 0.15458125740227047},
{"total_number_of_episodes": 14968, "number_of_timesteps": 1678495, "per_episode_reward": -119.52, "episode_reward_trend_value": 0.008478495304519305, "biggest_recent_change": 0.15458125740227047},
{"total_number_of_episodes": 14978, "number_of_timesteps": 1679477, "per_episode_reward": -119.45, "episode_reward_trend_value": 0.007542814117966322, "biggest_recent_change": 0.1398373762245484},
{"total_number_of_episodes": 14988, "number_of_timesteps": 1680326, "per_episode_reward": -119.31, "episode_reward_trend_value": 0.008967687180621908, "biggest_recent_change": 0.1398373762245484},
{"total_number_of_episodes": 14998, "number_of_timesteps": 1681229, "per_episode_reward": -119.21, "episode_reward_trend_value": 0.009600651979329517, "biggest_recent_change": 0.1398373762245484},
{"total_number_of_episodes": 15008, "number_of_timesteps": 1682071, "per_episode_reward": -119.16, "episode_reward_trend_value": 0.008606294067416167, "biggest_recent_change": 0.13943692405902652},
{"total_number_of_episodes": 15018, "number_of_timesteps": 1682947, "per_episode_reward": -119.11, "episode_reward_trend_value": 0.008817068031229287, "biggest_recent_change": 0.13943692405902652},
{"total_number_of_episodes": 15029, "number_of_timesteps": 1683903, "per_episode_reward": -119.09, "episode_reward_trend_value": 0.008221248990426488, "biggest_recent_change": 0.13943692405902652},
{"total_number_of_episodes": 15039, "number_of_timesteps": 1684791, "per_episode_reward": -118.98, "episode_reward_trend_value": 0.008456045116877123, "biggest_recent_change": 0.13943692405902652},
{"total_number_of_episodes": 15049, "number_of_timesteps": 1685793, "per_episode_reward": -118.83, "episode_reward_trend_value": 0.008962576370130806, "biggest_recent_change": 0.15155266066682316},
{"total_number_of_episodes": 15061, "number_of_timesteps": 1686884, "per_episode_reward": -118.77, "episode_reward_trend_value": 0.008408903932440145, "biggest_recent_change": 0.15155266066682316},
{"total_number_of_episodes": 15071, "number_of_timesteps": 1687689, "per_episode_reward": -118.73, "episode_reward_trend_value": 0.008075398945475518, "biggest_recent_change": 0.15155266066682316},
{"total_number_of_episodes": 15081, "number_of_timesteps": 1688631, "per_episode_reward": -118.66, "episode_reward_trend_value": 0.007319197710723951, "biggest_recent_change": 0.15155266066682316},
{"total_number_of_episodes": 15091, "number_of_timesteps": 1689399, "per_episode_reward": -118.44, "episode_reward_trend_value": 0.008551384346271283, "biggest_recent_change": 0.2122664862466479},
{"total_number_of_episodes": 15101, "number_of_timesteps": 1690209, "per_episode_reward": -118.35, "episode_reward_trend_value": 0.009011148850798633, "biggest_recent_change": 0.2122664862466479},
{"total_number_of_episodes": 15111, "number_of_timesteps": 1691088, "per_episode_reward": -118.32, "episode_reward_trend_value": 0.008754726478992187, "biggest_recent_change": 0.2122664862466479},
{"total_number_of_episodes": 15121, "number_of_timesteps": 1692110, "per_episode_reward": -118.22, "episode_reward_trend_value": 0.009710716442647538, "biggest_recent_change": 0.2122664862466479},
{"total_number_of_episodes": 15131, "number_of_timesteps": 1692909, "per_episode_reward": -118.14, "episode_reward_trend_value": 0.009296420795403213, "biggest_recent_change": 0.2122664862466479},
{"total_number_of_episodes": 15141, "number_of_timesteps": 1693927, "per_episode_reward": -118.1, "episode_reward_trend_value": 0.008032834709919239, "biggest_recent_change": 0.2122664862466479},
{"total_number_of_episodes": 15153, "number_of_timesteps": 1694978, "per_episode_reward": -117.97, "episode_reward_trend_value": 0.008842491303217691, "biggest_recent_change": 0.2122664862466479},
{"total_number_of_episodes": 15163, "number_of_timesteps": 1695872, "per_episode_reward": -117.85, "episode_reward_trend_value": 0.009753065899371114, "biggest_recent_change": 0.2122664862466479},
{"total_number_of_episodes": 15173, "number_of_timesteps": 1696709, "per_episode_reward": -117.79, "episode_reward_trend_value": 0.009577155552262046, "biggest_recent_change": 0.2122664862466479},
{"total_number_of_episodes": 15183, "number_of_timesteps": 1697695, "per_episode_reward": -117.59, "episode_reward_trend_value": 0.009433512562172553, "biggest_recent_change": 0.19933861713859358},
{"total_number_of_episodes": 15193, "number_of_timesteps": 1698678, "per_episode_reward": -117.51, "episode_reward_trend_value": 0.009365380494030578, "biggest_recent_change": 0.19933861713859358},
{"total_number_of_episodes": 15203, "number_of_timesteps": 1699687, "per_episode_reward": -117.41, "episode_reward_trend_value": 0.010119768838307171, "biggest_recent_change": 0.19933861713859358},
{"total_number_of_episodes": 15213, "number_of_timesteps": 1700561, "per_episode_reward": -117.33, "episode_reward_trend_value": 0.00984224481589943, "biggest_recent_change": 0.19933861713859358},
{"total_number_of_episodes": 15223, "number_of_timesteps": 1701429, "per_episode_reward": -117.04, "episode_reward_trend_value": 0.012274809341923603, "biggest_recent_change": 0.2941209082249969},
{"total_number_of_episodes": 15233, "number_of_timesteps": 1702378, "per_episode_reward": -116.96, "episode_reward_trend_value": 0.012708382976491192, "biggest_recent_change": 0.2941209082249969},
{"total_number_of_episodes": 15244, "number_of_timesteps": 1703484, "per_episode_reward": -116.87, "episode_reward_trend_value": 0.012250146019501546, "biggest_recent_change": 0.2941209082249969},
{"total_number_of_episodes": 15254, "number_of_timesteps": 1704574, "per_episode_reward": -116.77, "episode_reward_trend_value": 0.011971347951343286, "biggest_recent_change": 0.2941209082249969},
{"total_number_of_episodes": 15265, "number_of_timesteps": 1705586, "per_episode_reward": -116.72, "episode_reward_trend_value": 0.011895701641196865, "biggest_recent_change": 0.2941209082249969},
{"total_number_of_episodes": 15276, "number_of_timesteps": 1706507, "per_episode_reward": -116.59, "episode_reward_trend_value": 0.0111873208713037, "biggest_recent_change": 0.2941209082249969},
{"total_number_of_episodes": 15286, "number_of_timesteps": 1707450, "per_episode_reward": -116.46, "episode_reward_trend_value": 0.011674395892993693, "biggest_recent_change": 0.2941209082249969},
{"total_number_of_episodes": 15296, "number_of_timesteps": 1708497, "per_episode_reward": -116.42, "episode_reward_trend_value": 0.01106266393624114, "biggest_recent_change": 0.2941209082249969},
{"total_number_of_episodes": 15306, "number_of_timesteps": 1709227, "per_episode_reward": -116.3, "episode_reward_trend_value": 0.011486507390755208, "biggest_recent_change": 0.2941209082249969},
{"total_number_of_episodes": 15316, "number_of_timesteps": 1710197, "per_episode_reward": -116.18, "episode_reward_trend_value": 0.009474882022956876, "biggest_recent_change": 0.1355843478482086},
{"total_number_of_episodes": 15326, "number_of_timesteps": 1711181, "per_episode_reward": -116.12, "episode_reward_trend_value": 0.009317632769454715, "biggest_recent_change": 0.1355843478482086},
{"total_number_of_episodes": 15336, "number_of_timesteps": 1712095, "per_episode_reward": -115.91, "episode_reward_trend_value": 0.010608286036570292, "biggest_recent_change": 0.20737754313300627},
{"total_number_of_episodes": 15346, "number_of_timesteps": 1713072, "per_episode_reward": -115.62, "episode_reward_trend_value": 0.012748855045875807, "biggest_recent_change": 0.28986560014274687},
{"total_number_of_episodes": 15356, "number_of_timesteps": 1714031, "per_episode_reward": -115.49, "episode_reward_trend_value": 0.013741889100000215, "biggest_recent_change": 0.28986560014274687},
{"total_number_of_episodes": 15366, "number_of_timesteps": 1714887, "per_episode_reward": -115.47, "episode_reward_trend_value": 0.012451474496190605, "biggest_recent_change": 0.28986560014274687},
{"total_number_of_episodes": 15376, "number_of_timesteps": 1715753, "per_episode_reward": -115.39, "episode_reward_trend_value": 0.011848842110761223, "biggest_recent_change": 0.28986560014274687},
{"total_number_of_episodes": 15386, "number_of_timesteps": 1716636, "per_episode_reward": -115.34, "episode_reward_trend_value": 0.011919634350336456, "biggest_recent_change": 0.28986560014274687},
{"total_number_of_episodes": 15396, "number_of_timesteps": 1717600, "per_episode_reward": -115.27, "episode_reward_trend_value": 0.01139091161943892, "biggest_recent_change": 0.28986560014274687},
{"total_number_of_episodes": 15406, "number_of_timesteps": 1718492, "per_episode_reward": -115.14, "episode_reward_trend_value": 0.011556144364149961, "biggest_recent_change": 0.28986560014274687},
{"total_number_of_episodes": 15416, "number_of_timesteps": 1719604, "per_episode_reward": -115.02, "episode_reward_trend_value": 0.012196275250212964, "biggest_recent_change": 0.28986560014274687},
{"total_number_of_episodes": 15427, "number_of_timesteps": 1720450, "per_episode_reward": -114.91, "episode_reward_trend_value": 0.01120325367703114, "biggest_recent_change": 0.28986560014274687},
{"total_number_of_episodes": 15437, "number_of_timesteps": 1721462, "per_episode_reward": -114.79, "episode_reward_trend_value": 0.009282082300985905, "biggest_recent_change": 0.1381117786495878},
{"total_number_of_episodes": 15447, "number_of_timesteps": 1722397, "per_episode_reward": -114.7, "episode_reward_trend_value": 0.00869552445155727, "biggest_recent_change": 0.12794557214714075},
{"total_number_of_episodes": 15457, "number_of_timesteps": 1723443, "per_episode_reward": -114.67, "episode_reward_trend_value": 0.008810198973257855, "biggest_recent_change": 0.12794557214714075},
{"total_number_of_episodes": 15467, "number_of_timesteps": 1724536, "per_episode_reward": -114.63, "episode_reward_trend_value": 0.008466692841857082, "biggest_recent_change": 0.12794557214714075},
{"total_number_of_episodes": 15477, "number_of_timesteps": 1725538, "per_episode_reward": -114.57, "episode_reward_trend_value": 0.008626055847379159, "biggest_recent_change": 0.12794557214714075},
{"total_number_of_episodes": 15487, "number_of_timesteps": 1726953, "per_episode_reward": -114.54, "episode_reward_trend_value": 0.008093349355095824, "biggest_recent_change": 0.12794557214714075},
{"total_number_of_episodes": 15497, "number_of_timesteps": 1728183, "per_episode_reward": -114.55, "episode_reward_trend_value": 0.006633812647167285, "biggest_recent_change": 0.12031088701482417},
{"total_number_of_episodes": 15507, "number_of_timesteps": 1729485, "per_episode_reward": -114.54, "episode_reward_trend_value": 0.005366285415214299, "biggest_recent_change": 0.11800560154664197},
{"total_number_of_episodes": 15518, "number_of_timesteps": 1730587, "per_episode_reward": -114.54, "episode_reward_trend_value": 0.00406808601430776, "biggest_recent_change": 0.11696017629867583},
{"total_number_of_episodes": 15528, "number_of_timesteps": 1731801, "per_episode_reward": -114.55, "episode_reward_trend_value": 0.002630810935615892, "biggest_recent_change": 0.08532157220101055},
{"total_number_of_episodes": 15538, "number_of_timesteps": 1732972, "per_episode_reward": -114.52, "episode_reward_trend_value": 0.002062194517330498, "biggest_recent_change": 0.06238178234075065},
{"total_number_of_episodes": 15548, "number_of_timesteps": 1733908, "per_episode_reward": -114.5, "episode_reward_trend_value": 0.0019183408670440058, "biggest_recent_change": 0.06238178234075065},

{"total_number_of_episodes": 15558, "number_of_timesteps": 1735088, "per_episode_reward": -114.43, "episode_reward_trend_value": 0.0022161240017564096, "biggest_recent_change": 0.07107685098853267},
{"total_number_of_episodes": 15568, "number_of_timesteps": 1736174, "per_episode_reward": -114.35, "episode_reward_trend_value": 0.002396543768243002, "biggest_recent_change": 0.07861956132454395},
{"total_number_of_episodes": 15578, "number_of_timesteps": 1737278, "per_episode_reward": -114.34, "episode_reward_trend_value": 0.002207990832197974, "biggest_recent_change": 0.07861956132454395},
{"total_number_of_episodes": 15588, "number_of_timesteps": 1738244, "per_episode_reward": -114.24, "episode_reward_trend_value": 0.003378773916881686, "biggest_recent_change": 0.10195774605510621},
{"total_number_of_episodes": 15598, "number_of_timesteps": 1739124, "per_episode_reward": -114.14, "episode_reward_trend_value": 0.004456782148399441, "biggest_recent_change": 0.10325417697565342},
{"total_number_of_episodes": 15608, "number_of_timesteps": 1740303, "per_episode_reward": -114.08, "episode_reward_trend_value": 0.005118100159643765, "biggest_recent_change": 0.10325417697565342},
{"total_number_of_episodes": 15618, "number_of_timesteps": 1741249, "per_episode_reward": -113.99, "episode_reward_trend_value": 0.006291807140280367, "biggest_recent_change": 0.10325417697565342},
{"total_number_of_episodes": 15628, "number_of_timesteps": 1742141, "per_episode_reward": -113.89, "episode_reward_trend_value": 0.006923872705764704, "biggest_recent_change": 0.10325417697565342},
{"total_number_of_episodes": 15638, "number_of_timesteps": 1743004, "per_episode_reward": -113.78, "episode_reward_trend_value": 0.007998774077865771, "biggest_recent_change": 0.11356203542170817},
{"total_number_of_episodes": 15650, "number_of_timesteps": 1744078, "per_episode_reward": -113.62, "episode_reward_trend_value": 0.00900989679168131, "biggest_recent_change": 0.16207789523193128},
{"total_number_of_episodes": 15660, "number_of_timesteps": 1745023, "per_episode_reward": -113.55, "episode_reward_trend_value": 0.008892331729301855, "biggest_recent_change": 0.16207789523193128},
{"total_number_of_episodes": 15671, "number_of_timesteps": 1745964, "per_episode_reward": -113.46, "episode_reward_trend_value": 0.009841290593516936, "biggest_recent_change": 0.16207789523193128},
{"total_number_of_episodes": 15681, "number_of_timesteps": 1746969, "per_episode_reward": -113.33, "episode_reward_trend_value": 0.010188849526967341, "biggest_recent_change": 0.16207789523193128},
{"total_number_of_episodes": 15691, "number_of_timesteps": 1747964, "per_episode_reward": -113.24, "episode_reward_trend_value": 0.009983033473749162, "biggest_recent_change": 0.16207789523193128},
{"total_number_of_episodes": 15701, "number_of_timesteps": 1748786, "per_episode_reward": -113.16, "episode_reward_trend_value": 0.010191463176226831, "biggest_recent_change": 0.16207789523193128},
{"total_number_of_episodes": 15712, "number_of_timesteps": 1749698, "per_episode_reward": -113.07, "episode_reward_trend_value": 0.010212082068555775, "biggest_recent_change": 0.16207789523193128},
{"total_number_of_episodes": 15722, "number_of_timesteps": 1750937, "per_episode_reward": -112.88, "episode_reward_trend_value": 0.01125088459218612, "biggest_recent_change": 0.1845242225756465},
{"total_number_of_episodes": 15732, "number_of_timesteps": 1751772, "per_episode_reward": -112.76, "episode_reward_trend_value": 0.011338745108936779, "biggest_recent_change": 0.1845242225756465},
{"total_number_of_episodes": 15742, "number_of_timesteps": 1752537, "per_episode_reward": -112.62, "episode_reward_trend_value": 0.011047204601726594, "biggest_recent_change": 0.1845242225756465},
{"total_number_of_episodes": 15752, "number_of_timesteps": 1753383, "per_episode_reward": -112.62, "episode_reward_trend_value": 0.01031527650266513, "biggest_recent_change": 0.1845242225756465},
{"total_number_of_episodes": 15762, "number_of_timesteps": 1754422, "per_episode_reward": -112.52, "episode_reward_trend_value": 0.010400343089044067, "biggest_recent_change": 0.1845242225756465},
{"total_number_of_episodes": 15773, "number_of_timesteps": 1755730, "per_episode_reward": -112.46, "episode_reward_trend_value": 0.009669092123298305, "biggest_recent_change": 0.1845242225756465},
{"total_number_of_episodes": 15783, "number_of_timesteps": 1756935, "per_episode_reward": -112.46, "episode_reward_trend_value": 0.008668692623232409, "biggest_recent_change": 0.1845242225756465},
{"total_number_of_episodes": 15793, "number_of_timesteps": 1757970, "per_episode_reward": -112.44, "episode_reward_trend_value": 0.00803094151476071, "biggest_recent_change": 0.1845242225756465},
{"total_number_of_episodes": 15803, "number_of_timesteps": 1759188, "per_episode_reward": -112.37, "episode_reward_trend_value": 0.007703575512467371, "biggest_recent_change": 0.1845242225756465},
{"total_number_of_episodes": 15813, "number_of_timesteps": 1760367, "per_episode_reward": -112.38, "episode_reward_trend_value": 0.005532474890519268, "biggest_recent_change": 0.13583924958301452},
{"total_number_of_episodes": 15823, "number_of_timesteps": 1761919, "per_episode_reward": -112.34, "episode_reward_trend_value": 0.00463046471086462, "biggest_recent_change": 0.13583924958301452},
{"total_number_of_episodes": 15833, "number_of_timesteps": 1762997, "per_episode_reward": -112.27, "episode_reward_trend_value": 0.0039069446467863145, "biggest_recent_change": 0.09952426739617692},
{"total_number_of_episodes": 15844, "number_of_timesteps": 1764132, "per_episode_reward": -112.2, "episode_reward_trend_value": 0.00465448166691576, "biggest_recent_change": 0.09952426739617692},
{"total_number_of_episodes": 15854, "number_of_timesteps": 1765190, "per_episode_reward": -112.12, "episode_reward_trend_value": 0.004508824283525333, "biggest_recent_change": 0.08641510289103849},
{"total_number_of_episodes": 15864, "number_of_timesteps": 1766196, "per_episode_reward": -111.98, "episode_reward_trend_value": 0.005238586533961135, "biggest_recent_change": 0.13310406568774624},
{"total_number_of_episodes": 15874, "number_of_timesteps": 1767130, "per_episode_reward": -111.89, "episode_reward_trend_value": 0.006364758860399888, "biggest_recent_change": 0.13310406568774624},
{"total_number_of_episodes": 15884, "number_of_timesteps": 1768636, "per_episode_reward": -111.98, "episode_reward_trend_value": 0.0051361118979367385, "biggest_recent_change": 0.13310406568774624},
{"total_number_of_episodes": 15895, "number_of_timesteps": 1770438, "per_episode_reward": -111.85, "episode_reward_trend_value": 0.005824033585572863, "biggest_recent_change": 0.13310406568774624},
{"total_number_of_episodes": 15905, "number_of_timesteps": 1771652, "per_episode_reward": -111.79, "episode_reward_trend_value": 0.006612788507897783, "biggest_recent_change": 0.13310406568774624},
{"total_number_of_episodes": 15915, "number_of_timesteps": 1772660, "per_episode_reward": -111.72, "episode_reward_trend_value": 0.006972199842133857, "biggest_recent_change": 0.13310406568774624},
{"total_number_of_episodes": 15925, "number_of_timesteps": 1773730, "per_episode_reward": -111.69, "episode_reward_trend_value": 0.006491735441828439, "biggest_recent_change": 0.13310406568774624},
{"total_number_of_episodes": 15935, "number_of_timesteps": 1774651, "per_episode_reward": -111.6, "episode_reward_trend_value": 0.006757504463127855, "biggest_recent_change": 0.13310406568774624},
{"total_number_of_episodes": 15945, "number_of_timesteps": 1775888, "per_episode_reward": -111.52, "episode_reward_trend_value": 0.0066383731467914864, "biggest_recent_change": 0.13310406568774624},
{"total_number_of_episodes": 15955, "number_of_timesteps": 1776992, "per_episode_reward": -111.5, "episode_reward_trend_value": 0.005404566887234333, "biggest_recent_change": 0.12754475946415766},
{"total_number_of_episodes": 15965, "number_of_timesteps": 1777888, "per_episode_reward": -111.49, "episode_reward_trend_value": 0.004429343196943276, "biggest_recent_change": 0.12754475946415766},
{"total_number_of_episodes": 15975, "number_of_timesteps": 1778892, "per_episode_reward": -111.45, "episode_reward_trend_value": 0.0058805698096888485, "biggest_recent_change": 0.12754475946415766},
{"total_number_of_episodes": 15985, "number_of_timesteps": 1779753, "per_episode_reward": -111.35, "episode_reward_trend_value": 0.005519070705838184, "biggest_recent_change": 0.09500984011759783},
{"total_number_of_episodes": 15996, "number_of_timesteps": 1780837, "per_episode_reward": -111.3, "episode_reward_trend_value": 0.0054312114383205, "biggest_recent_change": 0.09500984011759783},
{"total_number_of_episodes": 16006, "number_of_timesteps": 1781637, "per_episode_reward": -111.19, "episode_reward_trend_value": 0.005870538078733034, "biggest_recent_change": 0.11217498347872379},
{"total_number_of_episodes": 16016, "number_of_timesteps": 1782574, "per_episode_reward": -111.1, "episode_reward_trend_value": 0.006595858282680922, "biggest_recent_change": 0.11217498347872379},
{"total_number_of_episodes": 16026, "number_of_timesteps": 1783436, "per_episode_reward": -110.93, "episode_reward_trend_value": 0.007434431511835903, "biggest_recent_change": 0.16883431114740688},
{"total_number_of_episodes": 16036, "number_of_timesteps": 1784237, "per_episode_reward": -110.79, "episode_reward_trend_value": 0.008141689045780571, "biggest_recent_change": 0.16883431114740688},
{"total_number_of_episodes": 16046, "number_of_timesteps": 1784934, "per_episode_reward": -110.68, "episode_reward_trend_value": 0.009044063143188275, "biggest_recent_change": 0.16883431114740688},
{"total_number_of_episodes": 16057, "number_of_timesteps": 1785862, "per_episode_reward": -110.66, "episode_reward_trend_value": 0.00919295138302674, "biggest_recent_change": 0.16883431114740688},
{"total_number_of_episodes": 16067, "number_of_timesteps": 1786594, "per_episode_reward": -110.59, "episode_reward_trend_value": 0.00949149939187824, "biggest_recent_change": 0.16883431114740688},
{"total_number_of_episodes": 16077, "number_of_timesteps": 1787477, "per_episode_reward": -110.47, "episode_reward_trend_value": 0.00982931497488298, "biggest_recent_change": 0.16883431114740688},
{"total_number_of_episodes": 16088, "number_of_timesteps": 1788337, "per_episode_reward": -110.36, "episode_reward_trend_value": 0.01042715707995367, "biggest_recent_change": 0.16883431114740688},
{"total_number_of_episodes": 16100, "number_of_timesteps": 1789274, "per_episode_reward": -110.26, "episode_reward_trend_value": 0.010271916876886816, "biggest_recent_change": 0.16883431114740688},
{"total_number_of_episodes": 16110, "number_of_timesteps": 1790095, "per_episode_reward": -110.14, "episode_reward_trend_value": 0.010605335222451294, "biggest_recent_change": 0.16883431114740688},
{"total_number_of_episodes": 16120, "number_of_timesteps": 1790953, "per_episode_reward": -110.06, "episode_reward_trend_value": 0.009597156652794562, "biggest_recent_change": 0.13934646247578542},
{"total_number_of_episodes": 16130, "number_of_timesteps": 1791836, "per_episode_reward": -109.96, "episode_reward_trend_value": 0.009183651721589253, "biggest_recent_change": 0.12541324258802433},
{"total_number_of_episodes": 16140, "number_of_timesteps": 1792888, "per_episode_reward": -109.89, "episode_reward_trend_value": 0.008820132890103121, "biggest_recent_change": 0.12541324258802433},
{"total_number_of_episodes": 16150, "number_of_timesteps": 1794097, "per_episode_reward": -109.67, "episode_reward_trend_value": 0.01097446980594504, "biggest_recent_change": 0.21557041844461367},
{"total_number_of_episodes": 16160, "number_of_timesteps": 1795117, "per_episode_reward": -109.65, "episode_reward_trend_value": 0.010492807014274774, "biggest_recent_change": 0.21557041844461367},
{"total_number_of_episodes": 16170, "number_of_timesteps": 1796199, "per_episode_reward": -109.5, "episode_reward_trend_value": 0.010788207870723454, "biggest_recent_change": 0.21557041844461367},
{"total_number_of_episodes": 16181, "number_of_timesteps": 1797387, "per_episode_reward": -109.57, "episode_reward_trend_value": 0.00882600004326185, "biggest_recent_change": 0.21557041844461367},
{"total_number_of_episodes": 16192, "number_of_timesteps": 1798327, "per_episode_reward": -109.5, "episode_reward_trend_value": 0.00851621087979358, "biggest_recent_change": 0.21557041844461367},
{"total_number_of_episodes": 16202, "number_of_timesteps": 1799175, "per_episode_reward": -109.48, "episode_reward_trend_value": 0.007359234244790179, "biggest_recent_change": 0.21557041844461367},
{"total_number_of_episodes": 16212, "number_of_timesteps": 1800064, "per_episode_reward": -109.43, "episode_reward_trend_value": 0.006982149848088505, "biggest_recent_change": 0.21557041844461367},
{"total_number_of_episodes": 16222, "number_of_timesteps": 1801174, "per_episode_reward": -109.33, "episode_reward_trend_value": 0.0069869173656998546, "biggest_recent_change": 0.21557041844461367},
{"total_number_of_episodes": 16232, "number_of_timesteps": 1802271, "per_episode_reward": -109.26, "episode_reward_trend_value": 0.006972034241157133, "biggest_recent_change": 0.21557041844461367},
{"total_number_of_episodes": 16242, "number_of_timesteps": 1803522, "per_episode_reward": -109.22, "episode_reward_trend_value": 0.005017115503686398, "biggest_recent_change": 0.15199931966840552},
{"total_number_of_episodes": 16252, "number_of_timesteps": 1804847, "per_episode_reward": -109.23, "episode_reward_trend_value": 0.004599753430182179, "biggest_recent_change": 0.15199931966840552},
{"total_number_of_episodes": 16262, "number_of_timesteps": 1806094, "per_episode_reward": -109.17, "episode_reward_trend_value": 0.0036200381790365554, "biggest_recent_change": 0.10256009525232912},
{"total_number_of_episodes": 16272, "number_of_timesteps": 1807702, "per_episode_reward": -109.11, "episode_reward_trend_value": 0.005100530281834716, "biggest_recent_change": 0.10256009525232912},
{"total_number_of_episodes": 16282, "number_of_timesteps": 1808835, "per_episode_reward": -109.1, "episode_reward_trend_value": 0.004440625341213749, "biggest_recent_change": 0.10256009525232912},
{"total_number_of_episodes": 16292, "number_of_timesteps": 1810065, "per_episode_reward": -109.07, "episode_reward_trend_value": 0.004588018029797228, "biggest_recent_change": 0.10256009525232912},
{"total_number_of_episodes": 16302, "number_of_timesteps": 1811479, "per_episode_reward": -109.0, "episode_reward_trend_value": 0.004777800606303609, "biggest_recent_change": 0.10256009525232912},
{"total_number_of_episodes": 16314, "number_of_timesteps": 1812571, "per_episode_reward": -108.96, "episode_reward_trend_value": 0.004077619954963375, "biggest_recent_change": 0.06921899505169904},
{"total_number_of_episodes": 16324, "number_of_timesteps": 1813722, "per_episode_reward": -108.86, "episode_reward_trend_value": 0.004514544920442316, "biggest_recent_change": 0.10854224194480366},
{"total_number_of_episodes": 16335, "number_of_timesteps": 1814603, "per_episode_reward": -108.78, "episode_reward_trend_value": 0.00491439333525913, "biggest_recent_change": 0.10854224194480366},
{"total_number_of_episodes": 16345, "number_of_timesteps": 1815529, "per_episode_reward": -108.65, "episode_reward_trend_value": 0.00652552540258237, "biggest_recent_change": 0.13303848745302105},
{"total_number_of_episodes": 16355, "number_of_timesteps": 1816461, "per_episode_reward": -108.54, "episode_reward_trend_value": 0.007024872126714696, "biggest_recent_change": 0.13303848745302105},
{"total_number_of_episodes": 16365, "number_of_timesteps": 1817344, "per_episode_reward": -108.47, "episode_reward_trend_value": 0.0070906699541028375, "biggest_recent_change": 0.13303848745302105},
{"total_number_of_episodes": 16375, "number_of_timesteps": 1818395, "per_episode_reward": -108.39, "episode_reward_trend_value": 0.007854646703093554, "biggest_recent_change": 0.13303848745302105},
{"total_number_of_episodes": 16385, "number_of_timesteps": 1819321, "per_episode_reward": -108.34, "episode_reward_trend_value": 0.008030519166103369, "biggest_recent_change": 0.13303848745302105},
{"total_number_of_episodes": 16395, "number_of_timesteps": 1820357, "per_episode_reward": -108.19, "episode_reward_trend_value": 0.009082640380662907, "biggest_recent_change": 0.15593198537108321},
{"total_number_of_episodes": 16405, "number_of_timesteps": 1821152, "per_episode_reward": -108.13, "episode_reward_trend_value": 0.009294612057682469, "biggest_recent_change": 0.15593198537108321},
{"total_number_of_episodes": 16416, "number_of_timesteps": 1822139, "per_episode_reward": -108.13, "episode_reward_trend_value": 0.008106937570926852, "biggest_recent_change": 0.15593198537108321},
{"total_number_of_episodes": 16426, "number_of_timesteps": 1823024, "per_episode_reward": -108.06, "episode_reward_trend_value": 0.007989720429161512, "biggest_recent_change": 0.15593198537108321},
{"total_number_of_episodes": 16436, "number_of_timesteps": 1823794, "per_episode_reward": -108.05, "episode_reward_trend_value": 0.0066170226994474194, "biggest_recent_change": 0.15593198537108321},
{"total_number_of_episodes": 16446, "number_of_timesteps": 1824564, "per_episode_reward": -107.97, "episode_reward_trend_value": 0.006342155721508253, "biggest_recent_change": 0.15593198537108321},
{"total_number_of_episodes": 16456, "number_of_timesteps": 1825345, "per_episode_reward": -107.91, "episode_reward_trend_value": 0.006258347719278528, "biggest_recent_change": 0.15593198537108321},
{"total_number_of_episodes": 16466, "number_of_timesteps": 1826430, "per_episode_reward": -107.86, "episode_reward_trend_value": 0.005916605912814848, "biggest_recent_change": 0.15593198537108321},
{"total_number_of_episodes": 16476, "number_of_timesteps": 1827531, "per_episode_reward": -107.78, "episode_reward_trend_value": 0.006287273390570489, "biggest_recent_change": 0.15593198537108321},
{"total_number_of_episodes": 16486, "number_of_timesteps": 1828412, "per_episode_reward": -107.71, "episode_reward_trend_value": 0.00533732149913517, "biggest_recent_change": 0.08402812422268369},
{"total_number_of_episodes": 16496, "number_of_timesteps": 1829261, "per_episode_reward": -107.59, "episode_reward_trend_value": 0.005956152483143266, "biggest_recent_change": 0.11431607612419725},
{"total_number_of_episodes": 16507, "number_of_timesteps": 1830286, "per_episode_reward": -107.56, "episode_reward_trend_value": 0.006283627811860508, "biggest_recent_change": 0.11431607612419725},
{"total_number_of_episodes": 16517, "number_of_timesteps": 1831131, "per_episode_reward": -107.51, "episode_reward_trend_value": 0.0060883031281711115, "biggest_recent_change": 0.11431607612419725},
{"total_number_of_episodes": 16527, "number_of_timesteps": 1832123, "per_episode_reward": -107.47, "episode_reward_trend_value": 0.0065191185471415265, "biggest_recent_change": 0.11431607612419725},
{"total_number_of_episodes": 16537, "number_of_timesteps": 1833112, "per_episode_reward": -107.39, "episode_reward_trend_value": 0.0063859443120673764, "biggest_recent_change": 0.11431607612419725},
{"total_number_of_episodes": 16547, "number_of_timesteps": 1833889, "per_episode_reward": -107.32, "episode_reward_trend_value": 0.0065709349374661954, "biggest_recent_change": 0.11431607612419725},
{"total_number_of_episodes": 16557, "number_of_timesteps": 1834746, "per_episode_reward": -107.28, "episode_reward_trend_value": 0.006411171416779699, "biggest_recent_change": 0.11431607612419725},
{"total_number_of_episodes": 16567, "number_of_timesteps": 1835586, "per_episode_reward": -107.26, "episode_reward_trend_value": 0.005792567166370727, "biggest_recent_change": 0.11431607612419725},
{"total_number_of_episodes": 16577, "number_of_timesteps": 1836526, "per_episode_reward": -107.19, "episode_reward_trend_value": 0.005711380993287523, "biggest_recent_change": 0.11431607612419725},
{"total_number_of_episodes": 16587, "number_of_timesteps": 1837554, "per_episode_reward": -107.2, "episode_reward_trend_value": 0.00430809372412742, "biggest_recent_change": 0.07768539031977184},
{"total_number_of_episodes": 16597, "number_of_timesteps": 1838798, "per_episode_reward": -107.02, "episode_reward_trend_value": 0.005958963432907498, "biggest_recent_change": 0.17970259151155688},
{"total_number_of_episodes": 16608, "number_of_timesteps": 1840140, "per_episode_reward": -106.93, "episode_reward_trend_value": 0.006516933130187713, "biggest_recent_change": 0.17970259151155688},
{"total_number_of_episodes": 16618, "number_of_timesteps": 1841276, "per_episode_reward": -106.88, "episode_reward_trend_value": 0.006540490290070977, "biggest_recent_change": 0.17970259151155688},
{"total_number_of_episodes": 16628, "number_of_timesteps": 1842595, "per_episode_reward": -106.92, "episode_reward_trend_value": 0.0052317875088742005, "biggest_recent_change": 0.17970259151155688},
{"total_number_of_episodes": 16638, "number_of_timesteps": 1843679, "per_episode_reward": -106.85, "episode_reward_trend_value": 0.005209237441434153, "biggest_recent_change": 0.17970259151155688},
{"total_number_of_episodes": 16648, "number_of_timesteps": 1844786, "per_episode_reward": -106.69, "episode_reward_trend_value": 0.006584570808383698, "biggest_recent_change": 0.17970259151155688},
{"total_number_of_episodes": 16658, "number_of_timesteps": 1845944, "per_episode_reward": -106.5, "episode_reward_trend_value": 0.008435089829327403, "biggest_recent_change": 0.19196548608381647},
{"total_number_of_episodes": 16668, "number_of_timesteps": 1847132, "per_episode_reward": -106.39, "episode_reward_trend_value": 0.008938469217621838, "biggest_recent_change": 0.19196548608381647},
{"total_number_of_episodes": 16678, "number_of_timesteps": 1848366, "per_episode_reward": -106.35, "episode_reward_trend_value": 0.009455285936947968, "biggest_recent_change": 0.19196548608381647},
{"total_number_of_episodes": 16688, "number_of_timesteps": 1849907, "per_episode_reward": -106.28, "episode_reward_trend_value": 0.008233590322405683, "biggest_recent_change": 0.19196548608381647},
{"total_number_of_episodes": 16698, "number_of_timesteps": 1851689, "per_episode_reward": -106.27, "episode_reward_trend_value": 0.007265274993730013, "biggest_recent_change": 0.19196548608381647},
{"total_number_of_episodes": 16708, "number_of_timesteps": 1853171, "per_episode_reward": -106.2, "episode_reward_trend_value": 0.00751289229389474, "biggest_recent_change": 0.19196548608381647},

{"total_number_of_episodes": 16718, "number_of_timesteps": 1854033, "per_episode_reward": -106.04, "episode_reward_trend_value": 0.009768668761031545, "biggest_recent_change": 0.19196548608381647},
{"total_number_of_episodes": 16728, "number_of_timesteps": 1854924, "per_episode_reward": -106.1, "episode_reward_trend_value": 0.00832615429760845, "biggest_recent_change": 0.19196548608381647},
{"total_number_of_episodes": 16738, "number_of_timesteps": 1855795, "per_episode_reward": -106.06, "episode_reward_trend_value": 0.006988146957686405, "biggest_recent_change": 0.19196548608381647},
{"total_number_of_episodes": 16748, "number_of_timesteps": 1856952, "per_episode_reward": -105.97, "episode_reward_trend_value": 0.005872948304264646, "biggest_recent_change": 0.15727907480061276},
{"total_number_of_episodes": 16758, "number_of_timesteps": 1858002, "per_episode_reward": -105.88, "episode_reward_trend_value": 0.005666147716422327, "biggest_recent_change": 0.15727907480061276},
{"total_number_of_episodes": 16769, "number_of_timesteps": 1859386, "per_episode_reward": -105.79, "episode_reward_trend_value": 0.006299109157098333, "biggest_recent_change": 0.15727907480061276},
{"total_number_of_episodes": 16779, "number_of_timesteps": 1860499, "per_episode_reward": -105.73, "episode_reward_trend_value": 0.006144735006748192, "biggest_recent_change": 0.15727907480061276},
{"total_number_of_episodes": 16789, "number_of_timesteps": 1861441, "per_episode_reward": -105.69, "episode_reward_trend_value": 0.00643925627218304, "biggest_recent_change": 0.15727907480061276},
{"total_number_of_episodes": 16799, "number_of_timesteps": 1862699, "per_episode_reward": -105.51, "episode_reward_trend_value": 0.007627049630706988, "biggest_recent_change": 0.17957618315756463},
{"total_number_of_episodes": 16809, "number_of_timesteps": 1863801, "per_episode_reward": -105.38, "episode_reward_trend_value": 0.007369719845543285, "biggest_recent_change": 0.17957618315756463},
{"total_number_of_episodes": 16820, "number_of_timesteps": 1864853, "per_episode_reward": -105.32, "episode_reward_trend_value": 0.008666439528311148, "biggest_recent_change": 0.17957618315756463},
{"total_number_of_episodes": 16830, "number_of_timesteps": 1865758, "per_episode_reward": -105.3, "episode_reward_trend_value": 0.00845988773944018, "biggest_recent_change": 0.17957618315756463},
{"total_number_of_episodes": 16841, "number_of_timesteps": 1866756, "per_episode_reward": -105.25, "episode_reward_trend_value": 0.007963174484341886, "biggest_recent_change": 0.17957618315756463},
{"total_number_of_episodes": 16852, "number_of_timesteps": 1867875, "per_episode_reward": -105.22, "episode_reward_trend_value": 0.007330243700790599, "biggest_recent_change": 0.17957618315756463},
{"total_number_of_episodes": 16862, "number_of_timesteps": 1868880, "per_episode_reward": -105.15, "episode_reward_trend_value": 0.007026242357565593, "biggest_recent_change": 0.17957618315756463},
{"total_number_of_episodes": 16872, "number_of_timesteps": 1869873, "per_episode_reward": -105.14, "episode_reward_trend_value": 0.00661380211007317, "biggest_recent_change": 0.17957618315756463},
{"total_number_of_episodes": 16885, "number_of_timesteps": 1871382, "per_episode_reward": -105.06, "episode_reward_trend_value": 0.007010065937300662, "biggest_recent_change": 0.17957618315756463},
{"total_number_of_episodes": 16895, "number_of_timesteps": 1872378, "per_episode_reward": -105.03, "episode_reward_trend_value": 0.0054298699883512805, "biggest_recent_change": 0.1341193941358796},
{"total_number_of_episodes": 16905, "number_of_timesteps": 1873497, "per_episode_reward": -104.98, "episode_reward_trend_value": 0.004459382498387123, "biggest_recent_change": 0.07272487662885396},
{"total_number_of_episodes": 16916, "number_of_timesteps": 1874945, "per_episode_reward": -104.72, "episode_reward_trend_value": 0.006652892772057978, "biggest_recent_change": 0.2599502786215737},
{"total_number_of_episodes": 16926, "number_of_timesteps": 1876447, "per_episode_reward": -104.64, "episode_reward_trend_value": 0.0072753856923302215, "biggest_recent_change": 0.2599502786215737},
{"total_number_of_episodes": 16936, "number_of_timesteps": 1877676, "per_episode_reward": -104.55, "episode_reward_trend_value": 0.007819626627748415, "biggest_recent_change": 0.2599502786215737},
{"total_number_of_episodes": 16946, "number_of_timesteps": 1879235, "per_episode_reward": -104.44, "episode_reward_trend_value": 0.008671527008947225, "biggest_recent_change": 0.2599502786215737},
{"total_number_of_episodes": 16956, "number_of_timesteps": 1880883, "per_episode_reward": -104.33, "episode_reward_trend_value": 0.009127080713951822, "biggest_recent_change": 0.2599502786215737},
{"total_number_of_episodes": 16966, "number_of_timesteps": 1882857, "per_episode_reward": -104.29, "episode_reward_trend_value": 0.009348628884619676, "biggest_recent_change": 0.2599502786215737},
{"total_number_of_episodes": 16976, "number_of_timesteps": 1884498, "per_episode_reward": -104.21, "episode_reward_trend_value": 0.00949658657691038, "biggest_recent_change": 0.2599502786215737},
{"total_number_of_episodes": 16986, "number_of_timesteps": 1885886, "per_episode_reward": -104.12, "episode_reward_trend_value": 0.010080001886590789, "biggest_recent_change": 0.2599502786215737},
{"total_number_of_episodes": 16996, "number_of_timesteps": 1887753, "per_episode_reward": -104.03, "episode_reward_trend_value": 0.01053966467999427, "biggest_recent_change": 0.2599502786215737},
{"total_number_of_episodes": 17006, "number_of_timesteps": 1889157, "per_episode_reward": -103.99, "episode_reward_trend_value": 0.008046484477784095, "biggest_recent_change": 0.10952891539338339},
{"total_number_of_episodes": 17016, "number_of_timesteps": 1890754, "per_episode_reward": -103.94, "episode_reward_trend_value": 0.007804679848301374, "biggest_recent_change": 0.10952891539338339},
{"total_number_of_episodes": 17027, "number_of_timesteps": 1892455, "per_episode_reward": -103.84, "episode_reward_trend_value": 0.007896809066409263, "biggest_recent_change": 0.10952891539338339},
{"total_number_of_episodes": 17037, "number_of_timesteps": 1893969, "per_episode_reward": -103.68, "episode_reward_trend_value": 0.008372427273752219, "biggest_recent_change": 0.15233455405424934},
{"total_number_of_episodes": 17047, "number_of_timesteps": 1895670, "per_episode_reward": -103.63, "episode_reward_trend_value": 0.007833097052301083, "biggest_recent_change": 0.15233455405424934},
{"total_number_of_episodes": 17058, "number_of_timesteps": 1897708, "per_episode_reward": -103.58, "episode_reward_trend_value": 0.007909631821066417, "biggest_recent_change": 0.15233455405424934},
{"total_number_of_episodes": 17068, "number_of_timesteps": 1899568, "per_episode_reward": -103.55, "episode_reward_trend_value": 0.00736657316424451, "biggest_recent_change": 0.15233455405424934},
{"total_number_of_episodes": 17080, "number_of_timesteps": 1901346, "per_episode_reward": -103.49, "episode_reward_trend_value": 0.0069587838692887274, "biggest_recent_change": 0.15233455405424934},
{"total_number_of_episodes": 17090, "number_of_timesteps": 1902705, "per_episode_reward": -103.43, "episode_reward_trend_value": 0.006655641642663095, "biggest_recent_change": 0.15233455405424934},
{"total_number_of_episodes": 17100, "number_of_timesteps": 1904686, "per_episode_reward": -103.38, "episode_reward_trend_value": 0.006791402693936119, "biggest_recent_change": 0.15233455405424934},
{"total_number_of_episodes": 17110, "number_of_timesteps": 1906111, "per_episode_reward": -103.34, "episode_reward_trend_value": 0.006660724355448148, "biggest_recent_change": 0.15233455405424934},
{"total_number_of_episodes": 17121, "number_of_timesteps": 1907527, "per_episode_reward": -103.19, "episode_reward_trend_value": 0.007175469166332801, "biggest_recent_change": 0.15233455405424934},
{"total_number_of_episodes": 17132, "number_of_timesteps": 1909203, "per_episode_reward": -103.1, "episode_reward_trend_value": 0.006549467581967229, "biggest_recent_change": 0.15049376111397805},
{"total_number_of_episodes": 17142, "number_of_timesteps": 1911530, "per_episode_reward": -103.11, "episode_reward_trend_value": 0.005713451243124565, "biggest_recent_change": 0.15049376111397805},
{"total_number_of_episodes": 17153, "number_of_timesteps": 1914044, "per_episode_reward": -103.04, "episode_reward_trend_value": 0.005977055767858669, "biggest_recent_change": 0.15049376111397805},
{"total_number_of_episodes": 17163, "number_of_timesteps": 1916939, "per_episode_reward": -102.95, "episode_reward_trend_value": 0.006560300079329314, "biggest_recent_change": 0.15049376111397805},
{"total_number_of_episodes": 17173, "number_of_timesteps": 1918779, "per_episode_reward": -102.67, "episode_reward_trend_value": 0.009089113224477153, "biggest_recent_change": 0.2807580721406424},
{"total_number_of_episodes": 17183, "number_of_timesteps": 1920813, "per_episode_reward": -102.59, "episode_reward_trend_value": 0.009388895142752556, "biggest_recent_change": 0.2807580721406424},
{"total_number_of_episodes": 17193, "number_of_timesteps": 1924515, "per_episode_reward": -102.53, "episode_reward_trend_value": 0.009445174553055817, "biggest_recent_change": 0.2807580721406424},
{"total_number_of_episodes": 17203, "number_of_timesteps": 1926697, "per_episode_reward": -102.44, "episode_reward_trend_value": 0.010067705896326294, "biggest_recent_change": 0.2807580721406424},
{"total_number_of_episodes": 17213, "number_of_timesteps": 1929297, "per_episode_reward": -102.41, "episode_reward_trend_value": 0.008711519107033735, "biggest_recent_change": 0.2807580721406424},
{"total_number_of_episodes": 17224, "number_of_timesteps": 1932156, "per_episode_reward": -102.43, "episode_reward_trend_value": 0.0074047947390872716, "biggest_recent_change": 0.2807580721406424},
{"total_number_of_episodes": 17234, "number_of_timesteps": 1936152, "per_episode_reward": -102.4, "episode_reward_trend_value": 0.007878771882081675, "biggest_recent_change": 0.2807580721406424},
{"total_number_of_episodes": 17244, "number_of_timesteps": 1939017, "per_episode_reward": -102.38, "episode_reward_trend_value": 0.007396791996016816, "biggest_recent_change": 0.2807580721406424},
{"total_number_of_episodes": 17255, "number_of_timesteps": 1942004, "per_episode_reward": -102.36, "episode_reward_trend_value": 0.006609964314589137, "biggest_recent_change": 0.2807580721406424},
{"total_number_of_episodes": 17265, "number_of_timesteps": 1944441, "per_episode_reward": -102.28, "episode_reward_trend_value": 0.00442006661837695, "biggest_recent_change": 0.09785172183589452},
{"total_number_of_episodes": 17276, "number_of_timesteps": 1947467, "per_episode_reward": -102.18, "episode_reward_trend_value": 0.004482269547984351, "biggest_recent_change": 0.09785172183589452},
{"total_number_of_episodes": 17286, "number_of_timesteps": 1948858, "per_episode_reward": -102.09, "episode_reward_trend_value": 0.004907234874491135, "biggest_recent_change": 0.09785172183589452},
{"total_number_of_episodes": 17296, "number_of_timesteps": 1951923, "per_episode_reward": -102.04, "episode_reward_trend_value": 0.0043971487244012526, "biggest_recent_change": 0.09344100735856387},
{"total_number_of_episodes": 17306, "number_of_timesteps": 1954459, "per_episode_reward": -101.98, "episode_reward_trend_value": 0.004773727337466482, "biggest_recent_change": 0.09344100735856387},
{"total_number_of_episodes": 17316, "number_of_timesteps": 1956862, "per_episode_reward": -101.92, "episode_reward_trend_value": 0.005595895564244794, "biggest_recent_change": 0.09344100735856387},
{"total_number_of_episodes": 17326, "number_of_timesteps": 1959810, "per_episode_reward": -101.81, "episode_reward_trend_value": 0.006580664097988473, "biggest_recent_change": 0.1126458893401292},
{"total_number_of_episodes": 17336, "number_of_timesteps": 1963138, "per_episode_reward": -101.77, "episode_reward_trend_value": 0.006729846176021207, "biggest_recent_change": 0.1126458893401292},
{"total_number_of_episodes": 17346, "number_of_timesteps": 1966630, "per_episode_reward": -101.69, "episode_reward_trend_value": 0.007435596974553487, "biggest_recent_change": 0.1126458893401292},
{"total_number_of_episodes": 17356, "number_of_timesteps": 1969006, "per_episode_reward": -101.66, "episode_reward_trend_value": 0.006886315250660699, "biggest_recent_change": 0.1126458893401292},
{"total_number_of_episodes": 17366, "number_of_timesteps": 1971657, "per_episode_reward": -101.58, "episode_reward_trend_value": 0.00666395363013837, "biggest_recent_change": 0.1126458893401292},
{"total_number_of_episodes": 17376, "number_of_timesteps": 1975438, "per_episode_reward": -101.59, "episode_reward_trend_value": 0.0055253975761941215, "biggest_recent_change": 0.1126458893401292},
{"total_number_of_episodes": 17386, "number_of_timesteps": 1978902, "per_episode_reward": -101.54, "episode_reward_trend_value": 0.0055051509022681615, "biggest_recent_change": 0.1126458893401292},
{"total_number_of_episodes": 17396, "number_of_timesteps": 1980498, "per_episode_reward": -101.5, "episode_reward_trend_value": 0.005251611018471497, "biggest_recent_change": 0.1126458893401292},
{"total_number_of_episodes": 17406, "number_of_timesteps": 1985148, "per_episode_reward": -101.49, "episode_reward_trend_value": 0.0048179825288432055, "biggest_recent_change": 0.1126458893401292},
{"total_number_of_episodes": 17416, "number_of_timesteps": 1988725, "per_episode_reward": -101.45, "episode_reward_trend_value": 0.004078946708466131, "biggest_recent_change": 0.0823608583928177},
{"total_number_of_episodes": 17427, "number_of_timesteps": 1992458, "per_episode_reward": -101.41, "episode_reward_trend_value": 0.004075675395164858, "biggest_recent_change": 0.0823608583928177},
{"total_number_of_episodes": 17437, "number_of_timesteps": 1994097, "per_episode_reward": -101.39, "episode_reward_trend_value": 0.0033061778878260067, "biggest_recent_change": 0.07342846151155413},
{"total_number_of_episodes": 17447, "number_of_timesteps": 1999720, "per_episode_reward": -101.37, "episode_reward_trend_value": 0.0031673211659594357, "biggest_recent_change": 0.07342846151155413},
{"total_number_of_episodes": 17457, "number_of_timesteps": 2004366, "per_episode_reward": -101.32, "episode_reward_trend_value": 0.0029553793276240487, "biggest_recent_change": 0.054353696061369305},
{"total_number_of_episodes": 17467, "number_of_timesteps": 2010206, "per_episode_reward": -101.25, "episode_reward_trend_value": 0.003828152063412441, "biggest_recent_change": 0.06717408271610736},
{"total_number_of_episodes": 17477, "number_of_timesteps": 2012017, "per_episode_reward": -101.19, "episode_reward_trend_value": 0.0039232008868347, "biggest_recent_change": 0.06717408271610736},
{"total_number_of_episodes": 17488, "number_of_timesteps": 2013885, "per_episode_reward": -101.06, "episode_reward_trend_value": 0.004911716642918407, "biggest_recent_change": 0.12847685375935214},
{"total_number_of_episodes": 17499, "number_of_timesteps": 2016712, "per_episode_reward": -101.05, "episode_reward_trend_value": 0.004928488230668885, "biggest_recent_change": 0.12847685375935214},
{"total_number_of_episodes": 17510, "number_of_timesteps": 2019791, "per_episode_reward": -100.96, "episode_reward_trend_value": 0.005382115361783077, "biggest_recent_change": 0.12847685375935214},
{"total_number_of_episodes": 17520, "number_of_timesteps": 2023187, "per_episode_reward": -100.87, "episode_reward_trend_value": 0.0059827416245852305, "biggest_recent_change": 0.12847685375935214},
{"total_number_of_episodes": 17530, "number_of_timesteps": 2027495, "per_episode_reward": -100.73, "episode_reward_trend_value": 0.007327078211991672, "biggest_recent_change": 0.13409637559890086},
{"total_number_of_episodes": 17540, "number_of_timesteps": 2029599, "per_episode_reward": -100.59, "episode_reward_trend_value": 0.008698843006147348, "biggest_recent_change": 0.14519365083721425},
{"total_number_of_episodes": 17551, "number_of_timesteps": 2032020, "per_episode_reward": -100.55, "episode_reward_trend_value": 0.008505616988425243, "biggest_recent_change": 0.14519365083721425},
{"total_number_of_episodes": 17561, "number_of_timesteps": 2034280, "per_episode_reward": -100.54, "episode_reward_trend_value": 0.007890650497481664, "biggest_recent_change": 0.14519365083721425},
{"total_number_of_episodes": 17571, "number_of_timesteps": 2037866, "per_episode_reward": -100.32, "episode_reward_trend_value": 0.009634686218268327, "biggest_recent_change": 0.2156393766532716},
{"total_number_of_episodes": 17582, "number_of_timesteps": 2039870, "per_episode_reward": -100.23, "episode_reward_trend_value": 0.00921025625664637, "biggest_recent_change": 0.2156393766532716},
{"total_number_of_episodes": 17592, "number_of_timesteps": 2041717, "per_episode_reward": -100.2, "episode_reward_trend_value": 0.009457761417984677, "biggest_recent_change": 0.2156393766532716},
{"total_number_of_episodes": 17602, "number_of_timesteps": 2043355, "per_episode_reward": -100.13, "episode_reward_trend_value": 0.009262645816992826, "biggest_recent_change": 0.2156393766532716},
{"total_number_of_episodes": 17612, "number_of_timesteps": 2045233, "per_episode_reward": -100.05, "episode_reward_trend_value": 0.009087296113189008, "biggest_recent_change": 0.2156393766532716},
{"total_number_of_episodes": 17622, "number_of_timesteps": 2047218, "per_episode_reward": -100.0, "episode_reward_trend_value": 0.008116590650216754, "biggest_recent_change": 0.2156393766532716},
{"total_number_of_episodes": 17632, "number_of_timesteps": 2050662, "per_episode_reward": -99.95, "episode_reward_trend_value": 0.007134805300708378, "biggest_recent_change": 0.2156393766532716},
{"total_number_of_episodes": 17642, "number_of_timesteps": 2053171, "per_episode_reward": -99.91, "episode_reward_trend_value": 0.00708600429509766, "biggest_recent_change": 0.2156393766532716},
{"total_number_of_episodes": 17652, "number_of_timesteps": 2056435, "per_episode_reward": -99.85, "episode_reward_trend_value": 0.0076137440774636566, "biggest_recent_change": 0.2156393766532716},
{"total_number_of_episodes": 17662, "number_of_timesteps": 2060338, "per_episode_reward": -99.8, "episode_reward_trend_value": 0.00586477838938306, "biggest_recent_change": 0.09027815721337618},
{"total_number_of_episodes": 17672, "number_of_timesteps": 2062530, "per_episode_reward": -99.73, "episode_reward_trend_value": 0.00558854474851529, "biggest_recent_change": 0.07731723156182113},
{"total_number_of_episodes": 17682, "number_of_timesteps": 2065004, "per_episode_reward": -99.61, "episode_reward_trend_value": 0.006528234069667842, "biggest_recent_change": 0.12171474101138813},
{"total_number_of_episodes": 17692, "number_of_timesteps": 2070573, "per_episode_reward": -99.4, "episode_reward_trend_value": 0.008094872636597946, "biggest_recent_change": 0.21039617424091261},
{"total_number_of_episodes": 17702, "number_of_timesteps": 2074548, "per_episode_reward": -99.3, "episode_reward_trend_value": 0.008340301212805438, "biggest_recent_change": 0.21039617424091261},
{"total_number_of_episodes": 17712, "number_of_timesteps": 2080569, "per_episode_reward": -99.26, "episode_reward_trend_value": 0.008244932316706866, "biggest_recent_change": 0.21039617424091261},
{"total_number_of_episodes": 17722, "number_of_timesteps": 2084015, "per_episode_reward": -99.17, "episode_reward_trend_value": 0.008656527115565875, "biggest_recent_change": 0.21039617424091261},
{"total_number_of_episodes": 17732, "number_of_timesteps": 2087381, "per_episode_reward": -99.04, "episode_reward_trend_value": 0.009756176946173728, "biggest_recent_change": 0.21039617424091261},
{"total_number_of_episodes": 17742, "number_of_timesteps": 2091025, "per_episode_reward": -98.95, "episode_reward_trend_value": 0.010044094239996564, "biggest_recent_change": 0.21039617424091261},
{"total_number_of_episodes": 17752, "number_of_timesteps": 2093180, "per_episode_reward": -98.89, "episode_reward_trend_value": 0.010120915785212344, "biggest_recent_change": 0.21039617424091261},
{"total_number_of_episodes": 17762, "number_of_timesteps": 2096368, "per_episode_reward": -98.79, "episode_reward_trend_value": 0.01043400455709218, "biggest_recent_change": 0.21039617424091261},
{"total_number_of_episodes": 17773, "number_of_timesteps": 2100431, "per_episode_reward": -98.71, "episode_reward_trend_value": 0.009949357075432078, "biggest_recent_change": 0.21039617424091261},
{"total_number_of_episodes": 17783, "number_of_timesteps": 2106262, "per_episode_reward": -98.64, "episode_reward_trend_value": 0.00848372202899365, "biggest_recent_change": 0.13153974871612206},
{"total_number_of_episodes": 17793, "number_of_timesteps": 2110334, "per_episode_reward": -98.55, "episode_reward_trend_value": 0.008317549341518947, "biggest_recent_change": 0.13153974871612206},
{"total_number_of_episodes": 17803, "number_of_timesteps": 2118890, "per_episode_reward": -98.48, "episode_reward_trend_value": 0.008706964943043419, "biggest_recent_change": 0.13153974871612206},
{"total_number_of_episodes": 17813, "number_of_timesteps": 2123850, "per_episode_reward": -98.44, "episode_reward_trend_value": 0.008045039253767703, "biggest_recent_change": 0.13153974871612206},
{"total_number_of_episodes": 17823, "number_of_timesteps": 2130210, "per_episode_reward": -98.35, "episode_reward_trend_value": 0.007657321986393445, "biggest_recent_change": 0.0966451946524387},
{"total_number_of_episodes": 17833, "number_of_timesteps": 2135271, "per_episode_reward": -98.24, "episode_reward_trend_value": 0.007865784663557602, "biggest_recent_change": 0.10399787633295432},
{"total_number_of_episodes": 17843, "number_of_timesteps": 2140097, "per_episode_reward": -98.18, "episode_reward_trend_value": 0.007847744461715916, "biggest_recent_change": 0.10399787633295432},
{"total_number_of_episodes": 17853, "number_of_timesteps": 2143443, "per_episode_reward": -98.12, "episode_reward_trend_value": 0.007421474805256562, "biggest_recent_change": 0.10399787633295432},
{"total_number_of_episodes": 17863, "number_of_timesteps": 2147476, "per_episode_reward": -98.07, "episode_reward_trend_value": 0.007153220260620527, "biggest_recent_change": 0.10399787633295432},
{"total_number_of_episodes": 17873, "number_of_timesteps": 2152047, "per_episode_reward": -98.02, "episode_reward_trend_value": 0.006881135865426163, "biggest_recent_change": 0.10399787633295432},
{"total_number_of_episodes": 17883, "number_of_timesteps": 2155446, "per_episode_reward": -97.95, "episode_reward_trend_value": 0.006654607538588981, "biggest_recent_change": 0.10399787633295432},
{"total_number_of_episodes": 17893, "number_of_timesteps": 2157690, "per_episode_reward": -97.94, "episode_reward_trend_value": 0.005963820048415079, "biggest_recent_change": 0.10399787633295432},
{"total_number_of_episodes": 17904, "number_of_timesteps": 2160652, "per_episode_reward": -97.89, "episode_reward_trend_value": 0.0061288599858637365, "biggest_recent_change": 0.10399787633295432},
{"total_number_of_episodes": 17914, "number_of_timesteps": 2164876, "per_episode_reward": -97.87, "episode_reward_trend_value": 0.005299857991847527, "biggest_recent_change": 0.10399787633295432},
{"total_number_of_episodes": 17924, "number_of_timesteps": 2167995, "per_episode_reward": -97.8, "episode_reward_trend_value": 0.004890744973598436, "biggest_recent_change": 0.06717770469053619},
{"total_number_of_episodes": 17934, "number_of_timesteps": 2174767, "per_episode_reward": -97.75, "episode_reward_trend_value": 0.004767155688322097, "biggest_recent_change": 0.06717770469053619},
{"total_number_of_episodes": 17944, "number_of_timesteps": 2179900, "per_episode_reward": -97.71, "episode_reward_trend_value": 0.004543741889393339, "biggest_recent_change": 0.06717770469053619},
{"total_number_of_episodes": 17954, "number_of_timesteps": 2182980, "per_episode_reward": -97.5, "episode_reward_trend_value": 0.006279616935851588, "biggest_recent_change": 0.2101823128259781},
{"total_number_of_episodes": 17964, "number_of_timesteps": 2184852, "per_episode_reward": -97.46, "episode_reward_trend_value": 0.006199007092036229, "biggest_recent_change": 0.2101823128259781},
{"total_number_of_episodes": 17974, "number_of_timesteps": 2186627, "per_episode_reward": -97.33, "episode_reward_trend_value": 0.006922816740662717, "biggest_recent_change": 0.2101823128259781},
{"total_number_of_episodes": 17984, "number_of_timesteps": 2188518, "per_episode_reward": -97.2, "episode_reward_trend_value": 0.008205758915965727, "biggest_recent_change": 0.2101823128259781},
{"total_number_of_episodes": 17994, "number_of_timesteps": 2190640, "per_episode_reward": -97.17, "episode_reward_trend_value": 0.007995744133858156, "biggest_recent_change": 0.2101823128259781},
{"total_number_of_episodes": 18005, "number_of_timesteps": 2194296, "per_episode_reward": -97.12, "episode_reward_trend_value": 0.00829563814870274, "biggest_recent_change": 0.2101823128259781},
{"total_number_of_episodes": 18015, "number_of_timesteps": 2197621, "per_episode_reward": -97.07, "episode_reward_trend_value": 0.008098739985155293, "biggest_recent_change": 0.2101823128259781},
{"total_number_of_episodes": 18025, "number_of_timesteps": 2203388, "per_episode_reward": -97.03, "episode_reward_trend_value": 0.008046636222814622, "biggest_recent_change": 0.2101823128259781},
{"total_number_of_episodes": 18035, "number_of_timesteps": 2207422, "per_episode_reward": -97.03, "episode_reward_trend_value": 0.007580386667115452, "biggest_recent_change": 0.2101823128259781},
{"total_number_of_episodes": 18045, "number_of_timesteps": 2211898, "per_episode_reward": -97.01, "episode_reward_trend_value": 0.005496197348463265, "biggest_recent_change": 0.1292055805088097},
{"total_number_of_episodes": 18055, "number_of_timesteps": 2215558, "per_episode_reward": -96.96, "episode_reward_trend_value": 0.0054888158895298345, "biggest_recent_change": 0.1292055805088097},
{"total_number_of_episodes": 18065, "number_of_timesteps": 2217628, "per_episode_reward": -96.94, "episode_reward_trend_value": 0.004268540371000206, "biggest_recent_change": 0.1264910090813487},
{"total_number_of_episodes": 18075, "number_of_timesteps": 2219548, "per_episode_reward": -96.92, "episode_reward_trend_value": 0.003094788515393532, "biggest_recent_change": 0.04945686997126586},
{"total_number_of_episodes": 18085, "number_of_timesteps": 2221538, "per_episode_reward": -96.9, "episode_reward_trend_value": 0.003039244917653308, "biggest_recent_change": 0.04945686997126586},
{"total_number_of_episodes": 18095, "number_of_timesteps": 2223331, "per_episode_reward": -96.89, "episode_reward_trend_value": 0.002596716247037989, "biggest_recent_change": 0.04945686997126586},
{"total_number_of_episodes": 18105, "number_of_timesteps": 2225334, "per_episode_reward": -96.89, "episode_reward_trend_value": 0.0020392989756208143, "biggest_recent_change": 0.047710411344155546},
{"total_number_of_episodes": 18115, "number_of_timesteps": 2228827, "per_episode_reward": -96.86, "episode_reward_trend_value": 0.0018020256962950991, "biggest_recent_change": 0.046082207246570306},
{"total_number_of_episodes": 18125, "number_of_timesteps": 2232170, "per_episode_reward": -96.83, "episode_reward_trend_value": 0.0022050519725679706, "biggest_recent_change": 0.046082207246570306},
{"total_number_of_episodes": 18135, "number_of_timesteps": 2236168, "per_episode_reward": -96.84, "episode_reward_trend_value": 0.0018811831706487838, "biggest_recent_change": 0.046082207246570306},
{"total_number_of_episodes": 18145, "number_of_timesteps": 2240932, "per_episode_reward": -96.82, "episode_reward_trend_value": 0.0016138630865804595, "biggest_recent_change": 0.029433512871165135},
{"total_number_of_episodes": 18155, "number_of_timesteps": 2247040, "per_episode_reward": -96.81, "episode_reward_trend_value": 0.0015127440590652617, "biggest_recent_change": 0.029433512871165135},
{"total_number_of_episodes": 18165, "number_of_timesteps": 2252473, "per_episode_reward": -96.77, "episode_reward_trend_value": 0.001653839962370777, "biggest_recent_change": 0.033551973374244426},
{"total_number_of_episodes": 18175, "number_of_timesteps": 2258523, "per_episode_reward": -96.76, "episode_reward_trend_value": 0.0015096583074242491, "biggest_recent_change": 0.033551973374244426},
{"total_number_of_episodes": 18185, "number_of_timesteps": 2266310, "per_episode_reward": -96.74, "episode_reward_trend_value": 0.0017062762323220681, "biggest_recent_change": 0.033551973374244426},
{"total_number_of_episodes": 18195, "number_of_timesteps": 2271398, "per_episode_reward": -96.7, "episode_reward_trend_value": 0.002077455571473605, "biggest_recent_change": 0.033551973374244426},
{"total_number_of_episodes": 18205, "number_of_timesteps": 2277273, "per_episode_reward": -96.67, "episode_reward_trend_value": 0.002141404731575057, "biggest_recent_change": 0.033551973374244426},
{"total_number_of_episodes": 18215, "number_of_timesteps": 2283876, "per_episode_reward": -96.6, "episode_reward_trend_value": 0.002588491633411157, "biggest_recent_change": 0.06967133403641412},
{"total_number_of_episodes": 18225, "number_of_timesteps": 2289561, "per_episode_reward": -96.52, "episode_reward_trend_value": 0.0035568567260260884, "biggest_recent_change": 0.08060994030989832},
{"total_number_of_episodes": 18235, "number_of_timesteps": 2295704, "per_episode_reward": -96.46, "episode_reward_trend_value": 0.003948980385359688, "biggest_recent_change": 0.08060994030989832},
{"total_number_of_episodes": 18245, "number_of_timesteps": 2300524, "per_episode_reward": -96.41, "episode_reward_trend_value": 0.004425447018619542, "biggest_recent_change": 0.08060994030989832},
{"total_number_of_episodes": 18255, "number_of_timesteps": 2307047, "per_episode_reward": -96.36, "episode_reward_trend_value": 0.004601416228889516, "biggest_recent_change": 0.08060994030989832},
{"total_number_of_episodes": 18265, "number_of_timesteps": 2310383, "per_episode_reward": -96.33, "episode_reward_trend_value": 0.004789248499514542, "biggest_recent_change": 0.08060994030989832},
{"total_number_of_episodes": 18275, "number_of_timesteps": 2316941, "per_episode_reward": -96.23, "episode_reward_trend_value": 0.005660116321233488, "biggest_recent_change": 0.10527161336712254},
{"total_number_of_episodes": 18286, "number_of_timesteps": 2321546, "per_episode_reward": -96.17, "episode_reward_trend_value": 0.005887210716922197, "biggest_recent_change": 0.10527161336712254},
{"total_number_of_episodes": 18296, "number_of_timesteps": 2323880, "per_episode_reward": -96.04, "episode_reward_trend_value": 0.007049997233367201, "biggest_recent_change": 0.1367620270940222},
{"total_number_of_episodes": 18306, "number_of_timesteps": 2326695, "per_episode_reward": -95.95, "episode_reward_trend_value": 0.007238924854060099, "biggest_recent_change": 0.1367620270940222},
{"total_number_of_episodes": 18316, "number_of_timesteps": 2329101, "per_episode_reward": -95.91, "episode_reward_trend_value": 0.0067931658465413295, "biggest_recent_change": 0.1367620270940222},
{"total_number_of_episodes": 18326, "number_of_timesteps": 2331701, "per_episode_reward": -95.89, "episode_reward_trend_value": 0.006373095478248716, "biggest_recent_change": 0.1367620270940222},
{"total_number_of_episodes": 18336, "number_of_timesteps": 2334691, "per_episode_reward": -95.84, "episode_reward_trend_value": 0.006291890761670989, "biggest_recent_change": 0.1367620270940222},
{"total_number_of_episodes": 18346, "number_of_timesteps": 2342016, "per_episode_reward": -95.72, "episode_reward_trend_value": 0.007122378590810602, "biggest_recent_change": 0.1367620270940222},
{"total_number_of_episodes": 18356, "number_of_timesteps": 2350754, "per_episode_reward": -95.67, "episode_reward_trend_value": 0.007312413781825772, "biggest_recent_change": 0.1367620270940222},
{"total_number_of_episodes": 18367, "number_of_timesteps": 2357786, "per_episode_reward": -95.64, "episode_reward_trend_value": 0.006508584083414348, "biggest_recent_change": 0.1367620270940222},
{"total_number_of_episodes": 18377, "number_of_timesteps": 2363104, "per_episode_reward": -95.58, "episode_reward_trend_value": 0.006549858363464346, "biggest_recent_change": 0.1367620270940222},
{"total_number_of_episodes": 18387, "number_of_timesteps": 2366371, "per_episode_reward": -95.49, "episode_reward_trend_value": 0.0060542249039422635, "biggest_recent_change": 0.12413310692110713},
{"total_number_of_episodes": 18397, "number_of_timesteps": 2369930, "per_episode_reward": -95.46, "episode_reward_trend_value": 0.005439094501827431, "biggest_recent_change": 0.12413310692110713},
{"total_number_of_episodes": 18407, "number_of_timesteps": 2372618, "per_episode_reward": -95.42, "episode_reward_trend_value": 0.005442005164896576, "biggest_recent_change": 0.12413310692110713},
{"total_number_of_episodes": 18417, "number_of_timesteps": 2375696, "per_episode_reward": -95.36, "episode_reward_trend_value": 0.005908238629678111, "biggest_recent_change": 0.12413310692110713},
{"total_number_of_episodes": 18427, "number_of_timesteps": 2384319, "per_episode_reward": -95.31, "episode_reward_trend_value": 0.005907599849738037, "biggest_recent_change": 0.12413310692110713},
{"total_number_of_episodes": 18437, "number_of_timesteps": 2389575, "per_episode_reward": -95.23, "episode_reward_trend_value": 0.005470017687069154, "biggest_recent_change": 0.09215501573703477},
{"total_number_of_episodes": 18447, "number_of_timesteps": 2396652, "per_episode_reward": -95.18, "episode_reward_trend_value": 0.005482329771861158, "biggest_recent_change": 0.09215501573703477},
{"total_number_of_episodes": 18457, "number_of_timesteps": 2402834, "per_episode_reward": -95.14, "episode_reward_trend_value": 0.005611495580550417, "biggest_recent_change": 0.09215501573703477},
{"total_number_of_episodes": 18467, "number_of_timesteps": 2407274, "per_episode_reward": -95.05, "episode_reward_trend_value": 0.00592349401802513, "biggest_recent_change": 0.09215501573703477},
{"total_number_of_episodes": 18477, "number_of_timesteps": 2416159, "per_episode_reward": -94.99, "episode_reward_trend_value": 0.00560676257571752, "biggest_recent_change": 0.08492849625656618},
{"total_number_of_episodes": 18487, "number_of_timesteps": 2423009, "per_episode_reward": -94.93, "episode_reward_trend_value": 0.005898724812321632, "biggest_recent_change": 0.08492849625656618},
{"total_number_of_episodes": 18497, "number_of_timesteps": 2427621, "per_episode_reward": -94.89, "episode_reward_trend_value": 0.005888141296652015, "biggest_recent_change": 0.08492849625656618},
{"total_number_of_episodes": 18507, "number_of_timesteps": 2432667, "per_episode_reward": -94.87, "episode_reward_trend_value": 0.005435627852376021, "biggest_recent_change": 0.08492849625656618},
{"total_number_of_episodes": 18517, "number_of_timesteps": 2440320, "per_episode_reward": -94.86, "episode_reward_trend_value": 0.005019193263644044, "biggest_recent_change": 0.08492849625656618},
{"total_number_of_episodes": 18527, "number_of_timesteps": 2445711, "per_episode_reward": -94.8, "episode_reward_trend_value": 0.0047213429439025845, "biggest_recent_change": 0.08492849625656618},
{"total_number_of_episodes": 18537, "number_of_timesteps": 2449647, "per_episode_reward": -94.77, "episode_reward_trend_value": 0.004570238967604547, "biggest_recent_change": 0.08492849625656618},
{"total_number_of_episodes": 18547, "number_of_timesteps": 2454308, "per_episode_reward": -94.71, "episode_reward_trend_value": 0.004697181577787686, "biggest_recent_change": 0.08492849625656618},
{"total_number_of_episodes": 18557, "number_of_timesteps": 2458926, "per_episode_reward": -94.7, "episode_reward_trend_value": 0.003903675025305296, "biggest_recent_change": 0.06364918592934998},
{"total_number_of_episodes": 18567, "number_of_timesteps": 2464986, "per_episode_reward": -94.66, "episode_reward_trend_value": 0.0036515123306584325, "biggest_recent_change": 0.057944183504176294},
{"total_number_of_episodes": 18577, "number_of_timesteps": 2469997, "per_episode_reward": -94.64, "episode_reward_trend_value": 0.003193780006167578, "biggest_recent_change": 0.057944183504176294},
{"total_number_of_episodes": 18587, "number_of_timesteps": 2474215, "per_episode_reward": -94.59, "episode_reward_trend_value": 0.0032884990744266123, "biggest_recent_change": 0.057944183504176294},
{"total_number_of_episodes": 18598, "number_of_timesteps": 2477170, "per_episode_reward": -94.57, "episode_reward_trend_value": 0.0033365986751727897, "biggest_recent_change": 0.057944183504176294},
{"total_number_of_episodes": 18608, "number_of_timesteps": 2481004, "per_episode_reward": -94.55, "episode_reward_trend_value": 0.0034690726853687202, "biggest_recent_change": 0.057944183504176294},
{"total_number_of_episodes": 18618, "number_of_timesteps": 2484398, "per_episode_reward": -94.45, "episode_reward_trend_value": 0.0038929451350703122, "biggest_recent_change": 0.09609270397731962},
{"total_number_of_episodes": 18629, "number_of_timesteps": 2488551, "per_episode_reward": -94.37, "episode_reward_trend_value": 0.004402351720026035, "biggest_recent_change": 0.09609270397731962},
{"total_number_of_episodes": 18639, "number_of_timesteps": 2491175, "per_episode_reward": -94.37, "episode_reward_trend_value": 0.003854519614530242, "biggest_recent_change": 0.09609270397731962},
{"total_number_of_episodes": 18649, "number_of_timesteps": 2494057, "per_episode_reward": -94.24, "episode_reward_trend_value": 0.005133341280117539, "biggest_recent_change": 0.1286068564360079},
{"total_number_of_episodes": 18659, "number_of_timesteps": 2496581, "per_episode_reward": -94.22, "episode_reward_trend_value": 0.004895077437817798, "biggest_recent_change": 0.1286068564360079},
{"total_number_of_episodes": 18669, "number_of_timesteps": 2498990, "per_episode_reward": -94.17, "episode_reward_trend_value": 0.005289272963323002, "biggest_recent_change": 0.1286068564360079},
{"total_number_of_episodes": 18680, "number_of_timesteps": 2501760, "per_episode_reward": -94.11, "episode_reward_trend_value": 0.005322050176500821, "biggest_recent_change": 0.1286068564360079},
{"total_number_of_episodes": 18690, "number_of_timesteps": 2504743, "per_episode_reward": -94.08, "episode_reward_trend_value": 0.005448636693103342, "biggest_recent_change": 0.1286068564360079},
{"total_number_of_episodes": 18700, "number_of_timesteps": 2509647, "per_episode_reward": -94.04, "episode_reward_trend_value": 0.005634880457940028, "biggest_recent_change": 0.1286068564360079},
{"total_number_of_episodes": 18710, "number_of_timesteps": 2515986, "per_episode_reward": -94.02, "episode_reward_trend_value": 0.004803524619414961, "biggest_recent_change": 0.1286068564360079},
{"total_number_of_episodes": 18720, "number_of_timesteps": 2523536, "per_episode_reward": -94.01, "episode_reward_trend_value": 0.0040364928972696, "biggest_recent_change": 0.1286068564360079},
{"total_number_of_episodes": 18730, "number_of_timesteps": 2530168, "per_episode_reward": -93.97, "episode_reward_trend_value": 0.004393719586533803, "biggest_recent_change": 0.1286068564360079},
{"total_number_of_episodes": 18740, "number_of_timesteps": 2535156, "per_episode_reward": -93.93, "episode_reward_trend_value": 0.0033766348294523457, "biggest_recent_change": 0.051871373094101614},
{"total_number_of_episodes": 18750, "number_of_timesteps": 2539388, "per_episode_reward": -93.84, "episode_reward_trend_value": 0.004181318214113282, "biggest_recent_change": 0.0919323022236398},
{"total_number_of_episodes": 18760, "number_of_timesteps": 2543083, "per_episode_reward": -93.79, "episode_reward_trend_value": 0.004225767313257399, "biggest_recent_change": 0.0919323022236398},
{"total_number_of_episodes": 18770, "number_of_timesteps": 2547279, "per_episode_reward": -93.71, "episode_reward_trend_value": 0.004478775945101493, "biggest_recent_change": 0.0919323022236398},
{"total_number_of_episodes": 18780, "number_of_timesteps": 2551664, "per_episode_reward": -93.68, "episode_reward_trend_value": 0.00442536397918079, "biggest_recent_change": 0.0919323022236398},
{"total_number_of_episodes": 18790, "number_of_timesteps": 2554939, "per_episode_reward": -93.65, "episode_reward_trend_value": 0.004360456200919316, "biggest_recent_change": 0.0919323022236398},
{"total_number_of_episodes": 18800, "number_of_timesteps": 2562589, "per_episode_reward": -93.58, "episode_reward_trend_value": 0.004919292255452964, "biggest_recent_change": 0.0919323022236398},
{"total_number_of_episodes": 18810, "number_of_timesteps": 2568559, "per_episode_reward": -93.49, "episode_reward_trend_value": 0.0057131399650678025, "biggest_recent_change": 0.0919323022236398},
{"total_number_of_episodes": 18821, "number_of_timesteps": 2573548, "per_episode_reward": -93.48, "episode_reward_trend_value": 0.005455768438775818, "biggest_recent_change": 0.0919323022236398},
{"total_number_of_episodes": 18831, "number_of_timesteps": 2579753, "per_episode_reward": -93.44, "episode_reward_trend_value": 0.005506874558014532, "biggest_recent_change": 0.0919323022236398},
{"total_number_of_episodes": 18841, "number_of_timesteps": 2585838, "per_episode_reward": -93.42, "episode_reward_trend_value": 0.004679248301921271, "biggest_recent_change": 0.08205701331318949},
{"total_number_of_episodes": 18851, "number_of_timesteps": 2592876, "per_episode_reward": -93.4, "episode_reward_trend_value": 0.004252873945865095, "biggest_recent_change": 0.08205701331318949},

{"total_number_of_episodes": 18861, "number_of_timesteps": 2598334, "per_episode_reward": -93.3, "episode_reward_trend_value": 0.00455965661196858, "biggest_recent_change": 0.10165695504376515},
{"total_number_of_episodes": 18871, "number_of_timesteps": 2602583, "per_episode_reward": -93.2, "episode_reward_trend_value": 0.005317853966301635, "biggest_recent_change": 0.10165695504376515},
{"total_number_of_episodes": 18881, "number_of_timesteps": 2605951, "per_episode_reward": -93.13, "episode_reward_trend_value": 0.005777332201106825, "biggest_recent_change": 0.10165695504376515},

{"total_number_of_episodes": 18891, "number_of_timesteps": 2608893, "per_episode_reward": -93.08, "episode_reward_trend_value": 0.005494639478719263, "biggest_recent_change": 0.10165695504376515},
{"total_number_of_episodes": 18901, "number_of_timesteps": 2615519, "per_episode_reward": -93.06, "episode_reward_trend_value": 0.0048321210202420025, "biggest_recent_change": 0.10165695504376515},
{"total_number_of_episodes": 18911, "number_of_timesteps": 2623356, "per_episode_reward": -93.02, "episode_reward_trend_value": 0.005082114309426958, "biggest_recent_change": 0.10165695504376515},
{"total_number_of_episodes": 18921, "number_of_timesteps": 2629463, "per_episode_reward": -92.98, "episode_reward_trend_value": 0.005071994398688654, "biggest_recent_change": 0.10165695504376515},
{"total_number_of_episodes": 18931, "number_of_timesteps": 2635312, "per_episode_reward": -92.92, "episode_reward_trend_value": 0.005571866597956583, "biggest_recent_change": 0.10165695504376515},
{"total_number_of_episodes": 18942, "number_of_timesteps": 2642863, "per_episode_reward": -92.85, "episode_reward_trend_value": 0.006087487999093197, "biggest_recent_change": 0.10165695504376515},
{"total_number_of_episodes": 18952, "number_of_timesteps": 2648187, "per_episode_reward": -92.79, "episode_reward_trend_value": 0.005635365103612836, "biggest_recent_change": 0.09989543323810324},
{"total_number_of_episodes": 18962, "number_of_timesteps": 2655486, "per_episode_reward": -92.74, "episode_reward_trend_value": 0.005145863013852963, "biggest_recent_change": 0.07251298152755226},
{"total_number_of_episodes": 18973, "number_of_timesteps": 2662332, "per_episode_reward": -92.71, "episode_reward_trend_value": 0.004671494462288845, "biggest_recent_change": 0.06390402607431156},
{"total_number_of_episodes": 18983, "number_of_timesteps": 2669597, "per_episode_reward": -92.68, "episode_reward_trend_value": 0.004432958243420633, "biggest_recent_change": 0.06390402607431156},
{"total_number_of_episodes": 18994, "number_of_timesteps": 2674776, "per_episode_reward": -92.52, "episode_reward_trend_value": 0.005973772148920867, "biggest_recent_change": 0.1611036035452571},
{"total_number_of_episodes": 19005, "number_of_timesteps": 2679924, "per_episode_reward": -92.5, "episode_reward_trend_value": 0.005805500277422956, "biggest_recent_change": 0.1611036035452571},
{"total_number_of_episodes": 19015, "number_of_timesteps": 2685548, "per_episode_reward": -92.46, "episode_reward_trend_value": 0.005760854365596105, "biggest_recent_change": 0.1611036035452571},
{"total_number_of_episodes": 19025, "number_of_timesteps": 2689862, "per_episode_reward": -92.42, "episode_reward_trend_value": 0.005576291880585732, "biggest_recent_change": 0.1611036035452571},
{"total_number_of_episodes": 19035, "number_of_timesteps": 2695352, "per_episode_reward": -92.39, "episode_reward_trend_value": 0.005127070242227837, "biggest_recent_change": 0.1611036035452571},
{"total_number_of_episodes": 19045, "number_of_timesteps": 2701056, "per_episode_reward": -92.37, "episode_reward_trend_value": 0.004753289560710212, "biggest_recent_change": 0.1611036035452571},
{"total_number_of_episodes": 19055, "number_of_timesteps": 2706613, "per_episode_reward": -92.32, "episode_reward_trend_value": 0.004606662067816577, "biggest_recent_change": 0.1611036035452571},
{"total_number_of_episodes": 19065, "number_of_timesteps": 2711310, "per_episode_reward": -92.3, "episode_reward_trend_value": 0.004517957429883602, "biggest_recent_change": 0.1611036035452571},
{"total_number_of_episodes": 19075, "number_of_timesteps": 2715177, "per_episode_reward": -92.22, "episode_reward_trend_value": 0.005165998293525971, "biggest_recent_change": 0.1611036035452571},
{"total_number_of_episodes": 19085, "number_of_timesteps": 2721958, "per_episode_reward": -92.15, "episode_reward_trend_value": 0.004141745053956135, "biggest_recent_change": 0.08297899643288531},
{"total_number_of_episodes": 19095, "number_of_timesteps": 2729600, "per_episode_reward": -92.1, "episode_reward_trend_value": 0.004383724899331298, "biggest_recent_change": 0.08297899643288531},

{"total_number_of_episodes": 19105, "number_of_timesteps": 2734876, "per_episode_reward": -92.07, "episode_reward_trend_value": 0.0044029722397948175, "biggest_recent_change": 0.08297899643288531},
{"total_number_of_episodes": 19115, "number_of_timesteps": 2740631, "per_episode_reward": -92.01, "episode_reward_trend_value": 0.004531447900351616, "biggest_recent_change": 0.08297899643288531},
{"total_number_of_episodes": 19125, "number_of_timesteps": 2745108, "per_episode_reward": -91.87, "episode_reward_trend_value": 0.005855685037655039, "biggest_recent_change": 0.1426554209794091},
{"total_number_of_episodes": 19135, "number_of_timesteps": 2749194, "per_episode_reward": -91.84, "episode_reward_trend_value": 0.0058976625223868, "biggest_recent_change": 0.1426554209794091},
{"total_number_of_episodes": 19145, "number_of_timesteps": 2752224, "per_episode_reward": -91.8, "episode_reward_trend_value": 0.005848901338299109, "biggest_recent_change": 0.1426554209794091},
{"total_number_of_episodes": 19155, "number_of_timesteps": 2755155, "per_episode_reward": -91.72, "episode_reward_trend_value": 0.006444493790857564, "biggest_recent_change": 0.1426554209794091},
{"total_number_of_episodes": 19165, "number_of_timesteps": 2758935, "per_episode_reward": -91.67, "episode_reward_trend_value": 0.006151204628280027, "biggest_recent_change": 0.1426554209794091},
{"total_number_of_episodes": 19175, "number_of_timesteps": 2763544, "per_episode_reward": -91.65, "episode_reward_trend_value": 0.005558802078692319, "biggest_recent_change": 0.1426554209794091},
{"total_number_of_episodes": 19185, "number_of_timesteps": 2768372, "per_episode_reward": -91.61, "episode_reward_trend_value": 0.005457151951242009, "biggest_recent_change": 0.1426554209794091},
{"total_number_of_episodes": 19195, "number_of_timesteps": 2771817, "per_episode_reward": -91.57, "episode_reward_trend_value": 0.005468561707521266, "biggest_recent_change": 0.1426554209794091},
{"total_number_of_episodes": 19205, "number_of_timesteps": 2775298, "per_episode_reward": -91.52, "episode_reward_trend_value": 0.005397064754970574, "biggest_recent_change": 0.1426554209794091},
{"total_number_of_episodes": 19215, "number_of_timesteps": 2778843, "per_episode_reward": -91.46, "episode_reward_trend_value": 0.004477867153125854, "biggest_recent_change": 0.0754397152030748},
{"total_number_of_episodes": 19225, "number_of_timesteps": 2782670, "per_episode_reward": -91.43, "episode_reward_trend_value": 0.004548525019464478, "biggest_recent_change": 0.0754397152030748},
{"total_number_of_episodes": 19235, "number_of_timesteps": 2786302, "per_episode_reward": -91.36, "episode_reward_trend_value": 0.004819025206509922, "biggest_recent_change": 0.0754397152030748},
{"total_number_of_episodes": 19246, "number_of_timesteps": 2790354, "per_episode_reward": -91.31, "episode_reward_trend_value": 0.004582715652626569, "biggest_recent_change": 0.06260028106548532},
{"total_number_of_episodes": 19256, "number_of_timesteps": 2793802, "per_episode_reward": -91.25, "episode_reward_trend_value": 0.004658203734743753, "biggest_recent_change": 0.06337689919145362},
{"total_number_of_episodes": 19266, "number_of_timesteps": 2796461, "per_episode_reward": -91.22, "episode_reward_trend_value": 0.004800275859054655, "biggest_recent_change": 0.06337689919145362},
{"total_number_of_episodes": 19276, "number_of_timesteps": 2800464, "per_episode_reward": -91.18, "episode_reward_trend_value": 0.004823431357958125, "biggest_recent_change": 0.06337689919145362},
{"total_number_of_episodes": 19286, "number_of_timesteps": 2804089, "per_episode_reward": -91.15, "episode_reward_trend_value": 0.004700311932763965, "biggest_recent_change": 0.06337689919145362},
{"total_number_of_episodes": 19296, "number_of_timesteps": 2807849, "per_episode_reward": -91.1, "episode_reward_trend_value": 0.00475482425781261, "biggest_recent_change": 0.06337689919145362},
{"total_number_of_episodes": 19307, "number_of_timesteps": 2814379, "per_episode_reward": -91.01, "episode_reward_trend_value": 0.005081848953346303, "biggest_recent_change": 0.08935985941141666},
{"total_number_of_episodes": 19317, "number_of_timesteps": 2818545, "per_episode_reward": -90.97, "episode_reward_trend_value": 0.005061094812856956, "biggest_recent_change": 0.08935985941141666},
{"total_number_of_episodes": 19328, "number_of_timesteps": 2821449, "per_episode_reward": -90.93, "episode_reward_trend_value": 0.004775380696725051, "biggest_recent_change": 0.08935985941141666},
{"total_number_of_episodes": 19338, "number_of_timesteps": 2824379, "per_episode_reward": -90.91, "episode_reward_trend_value": 0.004479299050541701, "biggest_recent_change": 0.08935985941141666},
{"total_number_of_episodes": 19348, "number_of_timesteps": 2828237, "per_episode_reward": -90.86, "episode_reward_trend_value": 0.004287575023082487, "biggest_recent_change": 0.08935985941141666},
{"total_number_of_episodes": 19358, "number_of_timesteps": 2831134, "per_episode_reward": -90.8, "episode_reward_trend_value": 0.004597564252487669, "biggest_recent_change": 0.08935985941141666},
{"total_number_of_episodes": 19368, "number_of_timesteps": 2835447, "per_episode_reward": -90.77, "episode_reward_trend_value": 0.004537711578400503, "biggest_recent_change": 0.08935985941141666},
{"total_number_of_episodes": 19378, "number_of_timesteps": 2838714, "per_episode_reward": -90.66, "episode_reward_trend_value": 0.005426702005940677, "biggest_recent_change": 0.10842738391728801},
{"total_number_of_episodes": 19388, "number_of_timesteps": 2840867, "per_episode_reward": -90.63, "episode_reward_trend_value": 0.0051594657103587824, "biggest_recent_change": 0.10842738391728801},
{"total_number_of_episodes": 19398, "number_of_timesteps": 2843458, "per_episode_reward": -90.59, "episode_reward_trend_value": 0.0046365385162673075, "biggest_recent_change": 0.10842738391728801},
{"total_number_of_episodes": 19408, "number_of_timesteps": 2845603, "per_episode_reward": -90.51, "episode_reward_trend_value": 0.00506683869206294, "biggest_recent_change": 0.10842738391728801},
{"total_number_of_episodes": 19418, "number_of_timesteps": 2848308, "per_episode_reward": -90.4, "episode_reward_trend_value": 0.00589268710846669, "biggest_recent_change": 0.1112123680899515},
{"total_number_of_episodes": 19429, "number_of_timesteps": 2852073, "per_episode_reward": -90.35, "episode_reward_trend_value": 0.0061563779505732445, "biggest_recent_change": 0.1112123680899515},
{"total_number_of_episodes": 19439, "number_of_timesteps": 2855783, "per_episode_reward": -90.26, "episode_reward_trend_value": 0.006707790497700551, "biggest_recent_change": 0.1112123680899515},

{"total_number_of_episodes": 19449, "number_of_timesteps": 2858031, "per_episode_reward": -90.19, "episode_reward_trend_value": 0.006794100521156724, "biggest_recent_change": 0.1112123680899515},
{"total_number_of_episodes": 19459, "number_of_timesteps": 2860753, "per_episode_reward": -90.15, "episode_reward_trend_value": 0.0068717381049959655, "biggest_recent_change": 0.1112123680899515},
{"total_number_of_episodes": 19469, "number_of_timesteps": 2863728, "per_episode_reward": -90.1, "episode_reward_trend_value": 0.006253471288587933, "biggest_recent_change": 0.1112123680899515},
{"total_number_of_episodes": 19479, "number_of_timesteps": 2865852, "per_episode_reward": -90.03, "episode_reward_trend_value": 0.00665762140108907, "biggest_recent_change": 0.1112123680899515},
{"total_number_of_episodes": 19489, "number_of_timesteps": 2867761, "per_episode_reward": -89.99, "episode_reward_trend_value": 0.0066165944608932315, "biggest_recent_change": 0.1112123680899515},
{"total_number_of_episodes": 19499, "number_of_timesteps": 2869996, "per_episode_reward": -89.97, "episode_reward_trend_value": 0.006013794056585671, "biggest_recent_change": 0.1112123680899515},
{"total_number_of_episodes": 19509, "number_of_timesteps": 2871924, "per_episode_reward": -89.88, "episode_reward_trend_value": 0.005817405189302525, "biggest_recent_change": 0.09574886596158194},
{"total_number_of_episodes": 19519, "number_of_timesteps": 2874732, "per_episode_reward": -89.85, "episode_reward_trend_value": 0.005574677257546688, "biggest_recent_change": 0.09574886596158194},
{"total_number_of_episodes": 19529, "number_of_timesteps": 2877954, "per_episode_reward": -89.83, "episode_reward_trend_value": 0.004749916916367959, "biggest_recent_change": 0.09353737003446838},
{"total_number_of_episodes": 19539, "number_of_timesteps": 2881220, "per_episode_reward": -89.82, "episode_reward_trend_value": 0.004104259695910489, "biggest_recent_change": 0.09353737003446838},
{"total_number_of_episodes": 19549, "number_of_timesteps": 2884099, "per_episode_reward": -89.79, "episode_reward_trend_value": 0.004086135706325441, "biggest_recent_change": 0.09353737003446838},
{"total_number_of_episodes": 19559, "number_of_timesteps": 2887232, "per_episode_reward": -89.74, "episode_reward_trend_value": 0.003964314021267354, "biggest_recent_change": 0.09353737003446838},
{"total_number_of_episodes": 19569, "number_of_timesteps": 2890811, "per_episode_reward": -89.7, "episode_reward_trend_value": 0.003639632748503314, "biggest_recent_change": 0.09353737003446838},
{"total_number_of_episodes": 19579, "number_of_timesteps": 2895900, "per_episode_reward": -89.68, "episode_reward_trend_value": 0.003486037208504437, "biggest_recent_change": 0.09353737003446838},
{"total_number_of_episodes": 19589, "number_of_timesteps": 2901826, "per_episode_reward": -89.63, "episode_reward_trend_value": 0.003811503559736056, "biggest_recent_change": 0.09353737003446838},
{"total_number_of_episodes": 19600, "number_of_timesteps": 2905637, "per_episode_reward": -89.56, "episode_reward_trend_value": 0.0035405015702830644, "biggest_recent_change": 0.06914719098369915},
{"total_number_of_episodes": 19610, "number_of_timesteps": 2908997, "per_episode_reward": -89.51, "episode_reward_trend_value": 0.0037457184140556087, "biggest_recent_change": 0.06914719098369915},
{"total_number_of_episodes": 19620, "number_of_timesteps": 2912748, "per_episode_reward": -89.51, "episode_reward_trend_value": 0.0035486634272907562, "biggest_recent_change": 0.06914719098369915},
{"total_number_of_episodes": 19630, "number_of_timesteps": 2918766, "per_episode_reward": -89.44, "episode_reward_trend_value": 0.00421768631902037, "biggest_recent_change": 0.06914719098369915},
{"total_number_of_episodes": 19641, "number_of_timesteps": 2926096, "per_episode_reward": -89.34, "episode_reward_trend_value": 0.004896733859029704, "biggest_recent_change": 0.09881113190374435},
{"total_number_of_episodes": 19651, "number_of_timesteps": 2931514, "per_episode_reward": -89.33, "episode_reward_trend_value": 0.0046334942762775375, "biggest_recent_change": 0.09881113190374435},
{"total_number_of_episodes": 19661, "number_of_timesteps": 2934223, "per_episode_reward": -89.31, "episode_reward_trend_value": 0.0044101932761323485, "biggest_recent_change": 0.09881113190374435},
{"total_number_of_episodes": 19671, "number_of_timesteps": 2936615, "per_episode_reward": -89.29, "episode_reward_trend_value": 0.004324397841751843, "biggest_recent_change": 0.09881113190374435},
{"total_number_of_episodes": 19681, "number_of_timesteps": 2939436, "per_episode_reward": -89.27, "episode_reward_trend_value": 0.003964326902053649, "biggest_recent_change": 0.09881113190374435},
{"total_number_of_episodes": 19692, "number_of_timesteps": 2941919, "per_episode_reward": -89.23, "episode_reward_trend_value": 0.0037135032597940187, "biggest_recent_change": 0.09881113190374435},
{"total_number_of_episodes": 19702, "number_of_timesteps": 2944260, "per_episode_reward": -89.19, "episode_reward_trend_value": 0.003550827577216688, "biggest_recent_change": 0.09881113190374435},
{"total_number_of_episodes": 19712, "number_of_timesteps": 2947195, "per_episode_reward": -89.16, "episode_reward_trend_value": 0.0038557537158387355, "biggest_recent_change": 0.09881113190374435},
{"total_number_of_episodes": 19723, "number_of_timesteps": 2950263, "per_episode_reward": -89.09, "episode_reward_trend_value": 0.003890276238973595, "biggest_recent_change": 0.09881113190374435},
{"total_number_of_episodes": 19733, "number_of_timesteps": 2952591, "per_episode_reward": -89.03, "episode_reward_trend_value": 0.0034489347725899697, "biggest_recent_change": 0.06926794396321156},
{"total_number_of_episodes": 19743, "number_of_timesteps": 2954945, "per_episode_reward": -88.98, "episode_reward_trend_value": 0.0038824292219272944, "biggest_recent_change": 0.06926794396321156},
{"total_number_of_episodes": 19753, "number_of_timesteps": 2957579, "per_episode_reward": -88.94, "episode_reward_trend_value": 0.00412841354641292, "biggest_recent_change": 0.06926794396321156},
{"total_number_of_episodes": 19763, "number_of_timesteps": 2960806, "per_episode_reward": -88.9, "episode_reward_trend_value": 0.004325869680411011, "biggest_recent_change": 0.06926794396321156},
{"total_number_of_episodes": 19773, "number_of_timesteps": 2963769, "per_episode_reward": -88.84, "episode_reward_trend_value": 0.004783293545405658, "biggest_recent_change": 0.06926794396321156},
{"total_number_of_episodes": 19783, "number_of_timesteps": 2966998, "per_episode_reward": -88.82, "episode_reward_trend_value": 0.004481740938768534, "biggest_recent_change": 0.06926794396321156},
{"total_number_of_episodes": 19793, "number_of_timesteps": 2969631, "per_episode_reward": -88.81, "episode_reward_trend_value": 0.004274353426481525, "biggest_recent_change": 0.06926794396321156},
{"total_number_of_episodes": 19803, "number_of_timesteps": 2972782, "per_episode_reward": -88.74, "episode_reward_trend_value": 0.004708606056539742, "biggest_recent_change": 0.07031157562788337},
{"total_number_of_episodes": 19813, "number_of_timesteps": 2976085, "per_episode_reward": -88.7, "episode_reward_trend_value": 0.004421129136548371, "biggest_recent_change": 0.07031157562788337},
{"total_number_of_episodes": 19823, "number_of_timesteps": 2978562, "per_episode_reward": -88.67, "episode_reward_trend_value": 0.0040924187976322125, "biggest_recent_change": 0.07031157562788337},
{"total_number_of_episodes": 19833, "number_of_timesteps": 2981755, "per_episode_reward": -88.63, "episode_reward_trend_value": 0.0038342816847909316, "biggest_recent_change": 0.07031157562788337},
{"total_number_of_episodes": 19843, "number_of_timesteps": 2987224, "per_episode_reward": -88.59, "episode_reward_trend_value": 0.00381711203994273, "biggest_recent_change": 0.07031157562788337},
{"total_number_of_episodes": 19853, "number_of_timesteps": 2990008, "per_episode_reward": -88.55, "episode_reward_trend_value": 0.0038792599340793125, "biggest_recent_change": 0.07031157562788337},
{"total_number_of_episodes": 19863, "number_of_timesteps": 2993974, "per_episode_reward": -88.54, "episode_reward_trend_value": 0.0033206470884252328, "biggest_recent_change": 0.07031157562788337},
{"total_number_of_episodes": 19874, "number_of_timesteps": 2998184, "per_episode_reward": -88.52, "episode_reward_trend_value": 0.003402482531834513, "biggest_recent_change": 0.07031157562788337},
{"total_number_of_episodes": 19885, "number_of_timesteps": 3002199, "per_episode_reward": -88.49, "episode_reward_trend_value": 0.0035972761746694776, "biggest_recent_change": 0.07031157562788337},
{"total_number_of_episodes": 19895, "number_of_timesteps": 3004656, "per_episode_reward": -88.46, "episode_reward_trend_value": 0.003079670965079768, "biggest_recent_change": 0.04339502116398819},
{"total_number_of_episodes": 19906, "number_of_timesteps": 3008014, "per_episode_reward": -88.41, "episode_reward_trend_value": 0.0031957268090321927, "biggest_recent_change": 0.05384004711970647},
{"total_number_of_episodes": 19916, "number_of_timesteps": 3012533, "per_episode_reward": -88.35, "episode_reward_trend_value": 0.0034766201323108703, "biggest_recent_change": 0.05478686852184467},
{"total_number_of_episodes": 19926, "number_of_timesteps": 3016451, "per_episode_reward": -88.31, "episode_reward_trend_value": 0.0035678902414321414, "biggest_recent_change": 0.05478686852184467},
{"total_number_of_episodes": 19936, "number_of_timesteps": 3020247, "per_episode_reward": -88.29, "episode_reward_trend_value": 0.0033503373583878707, "biggest_recent_change": 0.05478686852184467},
{"total_number_of_episodes": 19946, "number_of_timesteps": 3024089, "per_episode_reward": -88.26, "episode_reward_trend_value": 0.0031978429488274977, "biggest_recent_change": 0.05478686852184467},
{"total_number_of_episodes": 19956, "number_of_timesteps": 3025916, "per_episode_reward": -88.25, "episode_reward_trend_value": 0.003309746843910785, "biggest_recent_change": 0.05478686852184467},
{"total_number_of_episodes": 19966, "number_of_timesteps": 3031492, "per_episode_reward": -88.21, "episode_reward_trend_value": 0.0034420340484782883, "biggest_recent_change": 0.05478686852184467},
{"total_number_of_episodes": 19976, "number_of_timesteps": 3035267, "per_episode_reward": -88.16, "episode_reward_trend_value": 0.0036616910495005247, "biggest_recent_change": 0.05478686852184467},
{"total_number_of_episodes": 19987, "number_of_timesteps": 3037834, "per_episode_reward": -88.12, "episode_reward_trend_value": 0.0038034162051429924, "biggest_recent_change": 0.05478686852184467},
{"total_number_of_episodes": 19997, "number_of_timesteps": 3040526, "per_episode_reward": -88.07, "episode_reward_trend_value": 0.0037842126468010267, "biggest_recent_change": 0.05478686852184467},
{"total_number_of_episodes": 20007, "number_of_timesteps": 3045024, "per_episode_reward": -88.03, "episode_reward_trend_value": 0.0036336220227151253, "biggest_recent_change": 0.05211172686892951},
{"total_number_of_episodes": 20017, "number_of_timesteps": 3049904, "per_episode_reward": -87.97, "episode_reward_trend_value": 0.0037533476332291746, "biggest_recent_change": 0.052899631389465185},
{"total_number_of_episodes": 20027, "number_of_timesteps": 3054647, "per_episode_reward": -87.93, "episode_reward_trend_value": 0.0040198347992608146, "biggest_recent_change": 0.052899631389465185},
{"total_number_of_episodes": 20037, "number_of_timesteps": 3059191, "per_episode_reward": -87.88, "episode_reward_trend_value": 0.004300570615815344, "biggest_recent_change": 0.052899631389465185},
{"total_number_of_episodes": 20047, "number_of_timesteps": 3061830, "per_episode_reward": -87.86, "episode_reward_trend_value": 0.004257658096041913, "biggest_recent_change": 0.052899631389465185},
{"total_number_of_episodes": 20057, "number_of_timesteps": 3066087, "per_episode_reward": -87.82, "episode_reward_trend_value": 0.00425408309262786, "biggest_recent_change": 0.052899631389465185},
{"total_number_of_episodes": 20067, "number_of_timesteps": 3069727, "per_episode_reward": -87.74, "episode_reward_trend_value": 0.004638395001678772, "biggest_recent_change": 0.08646362729210466},
{"total_number_of_episodes": 20077, "number_of_timesteps": 3075753, "per_episode_reward": -87.71, "episode_reward_trend_value": 0.004509341270226881, "biggest_recent_change": 0.08646362729210466},
{"total_number_of_episodes": 20087, "number_of_timesteps": 3080086, "per_episode_reward": -87.69, "episode_reward_trend_value": 0.004165833940301411, "biggest_recent_change": 0.08646362729210466},
{"total_number_of_episodes": 20097, "number_of_timesteps": 3084959, "per_episode_reward": -87.66, "episode_reward_trend_value": 0.004024986585918574, "biggest_recent_change": 0.08646362729210466},
{"total_number_of_episodes": 20107, "number_of_timesteps": 3091146, "per_episode_reward": -87.61, "episode_reward_trend_value": 0.0040488765976945725, "biggest_recent_change": 0.08646362729210466},
{"total_number_of_episodes": 20117, "number_of_timesteps": 3098747, "per_episode_reward": -87.59, "episode_reward_trend_value": 0.0038192910831791474, "biggest_recent_change": 0.08646362729210466},
{"total_number_of_episodes": 20127, "number_of_timesteps": 3103278, "per_episode_reward": -87.57, "episode_reward_trend_value": 0.0034126248525859007, "biggest_recent_change": 0.08646362729210466},
{"total_number_of_episodes": 20137, "number_of_timesteps": 3105808, "per_episode_reward": -87.54, "episode_reward_trend_value": 0.003559821661230463, "biggest_recent_change": 0.08646362729210466},
{"total_number_of_episodes": 20147, "number_of_timesteps": 3108259, "per_episode_reward": -87.5, "episode_reward_trend_value": 0.003579547640066494, "biggest_recent_change": 0.08646362729210466},
{"total_number_of_episodes": 20157, "number_of_timesteps": 3112018, "per_episode_reward": -87.46, "episode_reward_trend_value": 0.0031044200336337565, "biggest_recent_change": 0.05504973244930511},
{"total_number_of_episodes": 20167, "number_of_timesteps": 3116555, "per_episode_reward": -87.41, "episode_reward_trend_value": 0.0033228295380990543, "biggest_recent_change": 0.05504973244930511},
{"total_number_of_episodes": 20177, "number_of_timesteps": 3121197, "per_episode_reward": -87.39, "episode_reward_trend_value": 0.003322034731096027, "biggest_recent_change": 0.05504973244930511},
{"total_number_of_episodes": 20187, "number_of_timesteps": 3127865, "per_episode_reward": -87.34, "episode_reward_trend_value": 0.003539396100897818, "biggest_recent_change": 0.05504973244930511},
{"total_number_of_episodes": 20197, "number_of_timesteps": 3136616, "per_episode_reward": -87.31, "episode_reward_trend_value": 0.0033536987958940915, "biggest_recent_change": 0.04811997374181942},
{"total_number_of_episodes": 20207, "number_of_timesteps": 3141007, "per_episode_reward": -87.3, "episode_reward_trend_value": 0.0032023123374705794, "biggest_recent_change": 0.04811997374181942},
{"total_number_of_episodes": 20218, "number_of_timesteps": 3146910, "per_episode_reward": -87.27, "episode_reward_trend_value": 0.0033557423552529205, "biggest_recent_change": 0.04811997374181942},
{"total_number_of_episodes": 20228, "number_of_timesteps": 3150145, "per_episode_reward": -87.22, "episode_reward_trend_value": 0.0035649452724522725, "biggest_recent_change": 0.04811997374181942},
{"total_number_of_episodes": 20238, "number_of_timesteps": 3155306, "per_episode_reward": -87.19, "episode_reward_trend_value": 0.003417762193460937, "biggest_recent_change": 0.04811997374181942},
{"total_number_of_episodes": 20248, "number_of_timesteps": 3160528, "per_episode_reward": -87.14, "episode_reward_trend_value": 0.0035638563716610685, "biggest_recent_change": 0.056850618751170146},
{"total_number_of_episodes": 20258, "number_of_timesteps": 3164869, "per_episode_reward": -87.07, "episode_reward_trend_value": 0.0038212225458273174, "biggest_recent_change": 0.06768734601880055},
{"total_number_of_episodes": 20268, "number_of_timesteps": 3169762, "per_episode_reward": -87.02, "episode_reward_trend_value": 0.004120509003287193, "biggest_recent_change": 0.06768734601880055},
{"total_number_of_episodes": 20278, "number_of_timesteps": 3174678, "per_episode_reward": -86.95, "episode_reward_trend_value": 0.004345967058047822, "biggest_recent_change": 0.06841119867027601},
{"total_number_of_episodes": 20288, "number_of_timesteps": 3179516, "per_episode_reward": -86.83, "episode_reward_trend_value": 0.00534088815985301, "biggest_recent_change": 0.12787987416143665},
{"total_number_of_episodes": 20298, "number_of_timesteps": 3182972, "per_episode_reward": -86.79, "episode_reward_trend_value": 0.005584470943059709, "biggest_recent_change": 0.12787987416143665},
{"total_number_of_episodes": 20308, "number_of_timesteps": 3186230, "per_episode_reward": -86.75, "episode_reward_trend_value": 0.005766786930193115, "biggest_recent_change": 0.12787987416143665},
{"total_number_of_episodes": 20318, "number_of_timesteps": 3189360, "per_episode_reward": -86.7, "episode_reward_trend_value": 0.005793844958166971, "biggest_recent_change": 0.12787987416143665},
{"total_number_of_episodes": 20328, "number_of_timesteps": 3192016, "per_episode_reward": -86.67, "episode_reward_trend_value": 0.005861192952394055, "biggest_recent_change": 0.12787987416143665},
{"total_number_of_episodes": 20338, "number_of_timesteps": 3194382, "per_episode_reward": -86.59, "episode_reward_trend_value": 0.006101783707711977, "biggest_recent_change": 0.12787987416143665},
{"total_number_of_episodes": 20348, "number_of_timesteps": 3197071, "per_episode_reward": -86.54, "episode_reward_trend_value": 0.005890096663993442, "biggest_recent_change": 0.12787987416143665},
{"total_number_of_episodes": 20358, "number_of_timesteps": 3199571, "per_episode_reward": -86.5, "episode_reward_trend_value": 0.005779304134720241, "biggest_recent_change": 0.12787987416143665},
{"total_number_of_episodes": 20368, "number_of_timesteps": 3201990, "per_episode_reward": -86.45, "episode_reward_trend_value": 0.005626536060617424, "biggest_recent_change": 0.12787987416143665},
{"total_number_of_episodes": 20379, "number_of_timesteps": 3204695, "per_episode_reward": -86.38, "episode_reward_trend_value": 0.004929397204467831, "biggest_recent_change": 0.07850378672978309},
{"total_number_of_episodes": 20389, "number_of_timesteps": 3207079, "per_episode_reward": -86.36, "episode_reward_trend_value": 0.0048761409768442515, "biggest_recent_change": 0.07850378672978309},
{"total_number_of_episodes": 20400, "number_of_timesteps": 3210003, "per_episode_reward": -86.34, "episode_reward_trend_value": 0.004573267364525515, "biggest_recent_change": 0.07850378672978309},
{"total_number_of_episodes": 20410, "number_of_timesteps": 3212568, "per_episode_reward": -86.31, "episode_reward_trend_value": 0.004281840553368473, "biggest_recent_change": 0.07850378672978309},
{"total_number_of_episodes": 20420, "number_of_timesteps": 3215423, "per_episode_reward": -86.22, "episode_reward_trend_value": 0.0049776483662281774, "biggest_recent_change": 0.09559550021747043},
{"total_number_of_episodes": 20430, "number_of_timesteps": 3219131, "per_episode_reward": -86.16, "episode_reward_trend_value": 0.004753162595955177, "biggest_recent_change": 0.09559550021747043},
{"total_number_of_episodes": 20440, "number_of_timesteps": 3221725, "per_episode_reward": -86.12, "episode_reward_trend_value": 0.0046226684055508515, "biggest_recent_change": 0.09559550021747043},
{"total_number_of_episodes": 20450, "number_of_timesteps": 3227950, "per_episode_reward": -86.11, "episode_reward_trend_value": 0.004364684152783285, "biggest_recent_change": 0.09559550021747043},
{"total_number_of_episodes": 20460, "number_of_timesteps": 3234397, "per_episode_reward": -86.09, "episode_reward_trend_value": 0.003975428210973556, "biggest_recent_change": 0.09559550021747043},
{"total_number_of_episodes": 20470, "number_of_timesteps": 3238848, "per_episode_reward": -86.03, "episode_reward_trend_value": 0.003945298663387891, "biggest_recent_change": 0.09559550021747043},
{"total_number_of_episodes": 20480, "number_of_timesteps": 3242313, "per_episode_reward": -85.96, "episode_reward_trend_value": 0.004396072631019857, "biggest_recent_change": 0.09559550021747043},
{"total_number_of_episodes": 20490, "number_of_timesteps": 3246739, "per_episode_reward": -85.93, "episode_reward_trend_value": 0.00447023668225831, "biggest_recent_change": 0.09559550021747043},
{"total_number_of_episodes": 20500, "number_of_timesteps": 3254063, "per_episode_reward": -85.86, "episode_reward_trend_value": 0.005025195093063277, "biggest_recent_change": 0.09559550021747043},

{"total_number_of_episodes": 20510, "number_of_timesteps": 3260019, "per_episode_reward": -85.82, "episode_reward_trend_value": 0.004425002930459717, "biggest_recent_change": 0.07228676586862548},
{"total_number_of_episodes": 20520, "number_of_timesteps": 3263839, "per_episode_reward": -85.8, "episode_reward_trend_value": 0.00403568265198165, "biggest_recent_change": 0.07228676586862548},
{"total_number_of_episodes": 20530, "number_of_timesteps": 3267533, "per_episode_reward": -85.78, "episode_reward_trend_value": 0.0037853163554815855, "biggest_recent_change": 0.07228676586862548},
{"total_number_of_episodes": 20540, "number_of_timesteps": 3270531, "per_episode_reward": -85.76, "episode_reward_trend_value": 0.0038312908751440963, "biggest_recent_change": 0.07228676586862548},
{"total_number_of_episodes": 20551, "number_of_timesteps": 3273354, "per_episode_reward": -85.72, "episode_reward_trend_value": 0.0041481660372723024, "biggest_recent_change": 0.07228676586862548},
{"total_number_of_episodes": 20561, "number_of_timesteps": 3275867, "per_episode_reward": -85.66, "episode_reward_trend_value": 0.004095166985480918, "biggest_recent_change": 0.07228676586862548},
{"total_number_of_episodes": 20571, "number_of_timesteps": 3278925, "per_episode_reward": -85.58, "episode_reward_trend_value": 0.004266051175031452, "biggest_recent_change": 0.08265039861488788},
{"total_number_of_episodes": 20582, "number_of_timesteps": 3282193, "per_episode_reward": -85.54, "episode_reward_trend_value": 0.004368888811402548, "biggest_recent_change": 0.08265039861488788},
{"total_number_of_episodes": 20592, "number_of_timesteps": 3285269, "per_episode_reward": -85.52, "episode_reward_trend_value": 0.0038434752766488287, "biggest_recent_change": 0.08265039861488788},
{"total_number_of_episodes": 20602, "number_of_timesteps": 3288535, "per_episode_reward": -85.48, "episode_reward_trend_value": 0.0038104303470089147, "biggest_recent_change": 0.08265039861488788},
{"total_number_of_episodes": 20613, "number_of_timesteps": 3293872, "per_episode_reward": -85.45, "episode_reward_trend_value": 0.0038919700544806485, "biggest_recent_change": 0.08265039861488788},
{"total_number_of_episodes": 20623, "number_of_timesteps": 3298709, "per_episode_reward": -85.41, "episode_reward_trend_value": 0.004109974771337477, "biggest_recent_change": 0.08265039861488788},
{"total_number_of_episodes": 20633, "number_of_timesteps": 3302305, "per_episode_reward": -85.39, "episode_reward_trend_value": 0.004199450339265651, "biggest_recent_change": 0.08265039861488788},
{"total_number_of_episodes": 20643, "number_of_timesteps": 3305646, "per_episode_reward": -85.32, "episode_reward_trend_value": 0.004388128457796528, "biggest_recent_change": 0.08265039861488788},
{"total_number_of_episodes": 20653, "number_of_timesteps": 3308252, "per_episode_reward": -85.3, "episode_reward_trend_value": 0.0040132851431208235, "biggest_recent_change": 0.08265039861488788},
{"total_number_of_episodes": 20663, "number_of_timesteps": 3310738, "per_episode_reward": -85.27, "episode_reward_trend_value": 0.003374407907437179, "biggest_recent_change": 0.06512883249746437},
{"total_number_of_episodes": 20673, "number_of_timesteps": 3314241, "per_episode_reward": -85.19, "episode_reward_trend_value": 0.0038589772698390196, "biggest_recent_change": 0.07786483787437248},
{"total_number_of_episodes": 20683, "number_of_timesteps": 3317930, "per_episode_reward": -85.05, "episode_reward_trend_value": 0.005145351754519507, "biggest_recent_change": 0.14077325136203456},
{"total_number_of_episodes": 20693, "number_of_timesteps": 3322529, "per_episode_reward": -85.03, "episode_reward_trend_value": 0.004930215409409458, "biggest_recent_change": 0.14077325136203456},
{"total_number_of_episodes": 20704, "number_of_timesteps": 3327974, "per_episode_reward": -84.98, "episode_reward_trend_value": 0.00524192880661979, "biggest_recent_change": 0.14077325136203456},
{"total_number_of_episodes": 20714, "number_of_timesteps": 3331162, "per_episode_reward": -84.97, "episode_reward_trend_value": 0.0049786842178030435, "biggest_recent_change": 0.14077325136203456},
{"total_number_of_episodes": 20724, "number_of_timesteps": 3333209, "per_episode_reward": -84.9, "episode_reward_trend_value": 0.005380511192927094, "biggest_recent_change": 0.14077325136203456},
{"total_number_of_episodes": 20734, "number_of_timesteps": 3336153, "per_episode_reward": -84.83, "episode_reward_trend_value": 0.005406897394439941, "biggest_recent_change": 0.14077325136203456},
{"total_number_of_episodes": 20744, "number_of_timesteps": 3339235, "per_episode_reward": -84.8, "episode_reward_trend_value": 0.0055531313935814645, "biggest_recent_change": 0.14077325136203456},
{"total_number_of_episodes": 20754, "number_of_timesteps": 3342365, "per_episode_reward": -84.77, "episode_reward_trend_value": 0.005629330214116458, "biggest_recent_change": 0.14077325136203456},
{"total_number_of_episodes": 20764, "number_of_timesteps": 3345833, "per_episode_reward": -84.74, "episode_reward_trend_value": 0.005090815226374919, "biggest_recent_change": 0.14077325136203456},
{"total_number_of_episodes": 20774, "number_of_timesteps": 3350689, "per_episode_reward": -84.71, "episode_reward_trend_value": 0.0037831876364003217, "biggest_recent_change": 0.06750359063362055},
{"total_number_of_episodes": 20784, "number_of_timesteps": 3355128, "per_episode_reward": -84.68, "episode_reward_trend_value": 0.003950191258122496, "biggest_recent_change": 0.06750359063362055},
{"total_number_of_episodes": 20795, "number_of_timesteps": 3358839, "per_episode_reward": -84.66, "episode_reward_trend_value": 0.0035204907448000236, "biggest_recent_change": 0.06750359063362055},
{"total_number_of_episodes": 20805, "number_of_timesteps": 3362049, "per_episode_reward": -84.61, "episode_reward_trend_value": 0.003910589408985427, "biggest_recent_change": 0.06750359063362055},
{"total_number_of_episodes": 20815, "number_of_timesteps": 3365038, "per_episode_reward": -84.6, "episode_reward_trend_value": 0.0033244334426795613, "biggest_recent_change": 0.06750359063362055},
{"total_number_of_episodes": 20826, "number_of_timesteps": 3369693, "per_episode_reward": -84.52, "episode_reward_trend_value": 0.0035197954038579836, "biggest_recent_change": 0.08508616713967854},
{"total_number_of_episodes": 20836, "number_of_timesteps": 3371668, "per_episode_reward": -84.49, "episode_reward_trend_value": 0.0034220333186152315, "biggest_recent_change": 0.08508616713967854},
{"total_number_of_episodes": 20846, "number_of_timesteps": 3374774, "per_episode_reward": -84.46, "episode_reward_trend_value": 0.0033585926489392488, "biggest_recent_change": 0.08508616713967854},
{"total_number_of_episodes": 20856, "number_of_timesteps": 3377201, "per_episode_reward": -84.41, "episode_reward_trend_value": 0.0036231116745497616, "biggest_recent_change": 0.08508616713967854},
{"total_number_of_episodes": 20866, "number_of_timesteps": 3379511, "per_episode_reward": -84.38, "episode_reward_trend_value": 0.0036995490932143745, "biggest_recent_change": 0.08508616713967854},
{"total_number_of_episodes": 20876, "number_of_timesteps": 3382025, "per_episode_reward": -84.36, "episode_reward_trend_value": 0.0035227950364276556, "biggest_recent_change": 0.08508616713967854},
{"total_number_of_episodes": 20886, "number_of_timesteps": 3385222, "per_episode_reward": -84.31, "episode_reward_trend_value": 0.0038651637514740224, "biggest_recent_change": 0.08508616713967854},
{"total_number_of_episodes": 20896, "number_of_timesteps": 3393258, "per_episode_reward": -84.27, "episode_reward_trend_value": 0.0038459852100748058, "biggest_recent_change": 0.08508616713967854},
{"total_number_of_episodes": 20906, "number_of_timesteps": 3397959, "per_episode_reward": -84.25, "episode_reward_trend_value": 0.003969202550734331, "biggest_recent_change": 0.08508616713967854},
{"total_number_of_episodes": 20917, "number_of_timesteps": 3402735, "per_episode_reward": -84.2, "episode_reward_trend_value": 0.0035565285104758636, "biggest_recent_change": 0.053205201282580106},
{"total_number_of_episodes": 20927, "number_of_timesteps": 3406695, "per_episode_reward": -84.15, "episode_reward_trend_value": 0.0037293357420911852, "biggest_recent_change": 0.053205201282580106},
{"total_number_of_episodes": 20937, "number_of_timesteps": 3412184, "per_episode_reward": -84.03, "episode_reward_trend_value": 0.004775943374143152, "biggest_recent_change": 0.12049436786534784},
{"total_number_of_episodes": 20947, "number_of_timesteps": 3417034, "per_episode_reward": -84.01, "episode_reward_trend_value": 0.0044605324570686855, "biggest_recent_change": 0.12049436786534784},
{"total_number_of_episodes": 20957, "number_of_timesteps": 3421999, "per_episode_reward": -83.96, "episode_reward_trend_value": 0.004655046858581436, "biggest_recent_change": 0.12049436786534784},
{"total_number_of_episodes": 20968, "number_of_timesteps": 3426366, "per_episode_reward": -83.92, "episode_reward_trend_value": 0.004894320635236227, "biggest_recent_change": 0.12049436786534784},
{"total_number_of_episodes": 20979, "number_of_timesteps": 3430098, "per_episode_reward": -83.87, "episode_reward_trend_value": 0.004895661555928951, "biggest_recent_change": 0.12049436786534784},
{"total_number_of_episodes": 20990, "number_of_timesteps": 3433676, "per_episode_reward": -83.81, "episode_reward_trend_value": 0.005045400990854097, "biggest_recent_change": 0.12049436786534784},
{"total_number_of_episodes": 21000, "number_of_timesteps": 3436810, "per_episode_reward": -83.77, "episode_reward_trend_value": 0.00532336529770687, "biggest_recent_change": 0.12049436786534784},
{"total_number_of_episodes": 21010, "number_of_timesteps": 3440180, "per_episode_reward": -83.71, "episode_reward_trend_value": 0.005415302856631064, "biggest_recent_change": 0.12049436786534784},
{"total_number_of_episodes": 21021, "number_of_timesteps": 3443942, "per_episode_reward": -83.65, "episode_reward_trend_value": 0.005588686328063533, "biggest_recent_change": 0.12049436786534784},
{"total_number_of_episodes": 21031, "number_of_timesteps": 3447262, "per_episode_reward": -83.63, "episode_reward_trend_value": 0.004506723403328926, "biggest_recent_change": 0.05943954036841603},
{"total_number_of_episodes": 21041, "number_of_timesteps": 3450128, "per_episode_reward": -83.58, "episode_reward_trend_value": 0.0048118512764955, "biggest_recent_change": 0.05943954036841603},
{"total_number_of_episodes": 21051, "number_of_timesteps": 3453673, "per_episode_reward": -83.52, "episode_reward_trend_value": 0.004904989885481983, "biggest_recent_change": 0.05943954036841603},
{"total_number_of_episodes": 21061, "number_of_timesteps": 3457259, "per_episode_reward": -83.46, "episode_reward_trend_value": 0.00514643211910971, "biggest_recent_change": 0.06162879262527099},
{"total_number_of_episodes": 21071, "number_of_timesteps": 3460848, "per_episode_reward": -83.42, "episode_reward_trend_value": 0.005028926619150948, "biggest_recent_change": 0.06162879262527099},
{"total_number_of_episodes": 21081, "number_of_timesteps": 3464893, "per_episode_reward": -83.42, "episode_reward_trend_value": 0.00442486380170032, "biggest_recent_change": 0.06162879262527099},
{"total_number_of_episodes": 21091, "number_of_timesteps": 3468067, "per_episode_reward": -83.38, "episode_reward_trend_value": 0.004317394859725867, "biggest_recent_change": 0.06162879262527099},
{"total_number_of_episodes": 21101, "number_of_timesteps": 3471426, "per_episode_reward": -83.3, "episode_reward_trend_value": 0.004526175477550175, "biggest_recent_change": 0.07501013942378165},
{"total_number_of_episodes": 21112, "number_of_timesteps": 3475035, "per_episode_reward": -83.28, "episode_reward_trend_value": 0.0040926178449421655, "biggest_recent_change": 0.07501013942378165},
{"total_number_of_episodes": 21122, "number_of_timesteps": 3478006, "per_episode_reward": -83.27, "episode_reward_trend_value": 0.003957718687309056, "biggest_recent_change": 0.07501013942378165},
{"total_number_of_episodes": 21132, "number_of_timesteps": 3481054, "per_episode_reward": -83.24, "episode_reward_trend_value": 0.0036897861925072875, "biggest_recent_change": 0.07501013942378165},
{"total_number_of_episodes": 21142, "number_of_timesteps": 3484497, "per_episode_reward": -83.21, "episode_reward_trend_value": 0.0034082580191879845, "biggest_recent_change": 0.07501013942378165},
{"total_number_of_episodes": 21152, "number_of_timesteps": 3487857, "per_episode_reward": -83.17, "episode_reward_trend_value": 0.0032258234876362873, "biggest_recent_change": 0.07501013942378165},

{"total_number_of_episodes": 21162, "number_of_timesteps": 3490866, "per_episode_reward": -83.11, "episode_reward_trend_value": 0.0033732625027479597, "biggest_recent_change": 0.07501013942378165},
{"total_number_of_episodes": 21172, "number_of_timesteps": 3492797, "per_episode_reward": -83.06, "episode_reward_trend_value": 0.003948845761362918, "biggest_recent_change": 0.07501013942378165},
{"total_number_of_episodes": 21182, "number_of_timesteps": 3495214, "per_episode_reward": -83.05, "episode_reward_trend_value": 0.003669239630176138, "biggest_recent_change": 0.07501013942378165},
{"total_number_of_episodes": 21193, "number_of_timesteps": 3498256, "per_episode_reward": -83.0, "episode_reward_trend_value": 0.0033231494003064512, "biggest_recent_change": 0.05458267968515429},
{"total_number_of_episodes": 21203, "number_of_timesteps": 3501326, "per_episode_reward": -82.96, "episode_reward_trend_value": 0.003552734835128667, "biggest_recent_change": 0.05458267968515429},
{"total_number_of_episodes": 21213, "number_of_timesteps": 3504138, "per_episode_reward": -82.92, "episode_reward_trend_value": 0.003913481606846384, "biggest_recent_change": 0.05458267968515429},
{"total_number_of_episodes": 21223, "number_of_timesteps": 3507164, "per_episode_reward": -82.9, "episode_reward_trend_value": 0.0038480844341726257, "biggest_recent_change": 0.05458267968515429},
{"total_number_of_episodes": 21234, "number_of_timesteps": 3510982, "per_episode_reward": -82.86, "episode_reward_trend_value": 0.0038850135836642923, "biggest_recent_change": 0.05458267968515429},

{"total_number_of_episodes": 21244, "number_of_timesteps": 3514408, "per_episode_reward": -82.81, "episode_reward_trend_value": 0.003936616033741321, "biggest_recent_change": 0.05458267968515429},
{"total_number_of_episodes": 21254, "number_of_timesteps": 3518606, "per_episode_reward": -82.8, "episode_reward_trend_value": 0.0034859563687043584, "biggest_recent_change": 0.05458267968515429},
{"total_number_of_episodes": 21264, "number_of_timesteps": 3521160, "per_episode_reward": -82.77, "episode_reward_trend_value": 0.003239638015061056, "biggest_recent_change": 0.04985390529255085},
{"total_number_of_episodes": 21274, "number_of_timesteps": 3523525, "per_episode_reward": -82.76, "episode_reward_trend_value": 0.00322116791953088, "biggest_recent_change": 0.04985390529255085},
{"total_number_of_episodes": 21284, "number_of_timesteps": 3526588, "per_episode_reward": -82.72, "episode_reward_trend_value": 0.003148903991878487, "biggest_recent_change": 0.04985390529255085},
{"total_number_of_episodes": 21294, "number_of_timesteps": 3531605, "per_episode_reward": -82.7, "episode_reward_trend_value": 0.002876240776528347, "biggest_recent_change": 0.04985390529255085},
{"total_number_of_episodes": 21304, "number_of_timesteps": 3536314, "per_episode_reward": -82.67, "episode_reward_trend_value": 0.00280062134238632, "biggest_recent_change": 0.04985390529255085},
{"total_number_of_episodes": 21314, "number_of_timesteps": 3542510, "per_episode_reward": -82.64, "episode_reward_trend_value": 0.0028783324087249358, "biggest_recent_change": 0.04985390529255085},
{"total_number_of_episodes": 21324, "number_of_timesteps": 3546370, "per_episode_reward": -82.56, "episode_reward_trend_value": 0.003326044255018227, "biggest_recent_change": 0.07413506091097588},
{"total_number_of_episodes": 21334, "number_of_timesteps": 3549400, "per_episode_reward": -82.53, "episode_reward_trend_value": 0.003101194351914829, "biggest_recent_change": 0.07413506091097588},
{"total_number_of_episodes": 21344, "number_of_timesteps": 3551839, "per_episode_reward": -82.5, "episode_reward_trend_value": 0.0032964516804143947, "biggest_recent_change": 0.07413506091097588},
{"total_number_of_episodes": 21354, "number_of_timesteps": 3554342, "per_episode_reward": -82.47, "episode_reward_trend_value": 0.0033149483326811143, "biggest_recent_change": 0.07413506091097588},
{"total_number_of_episodes": 21364, "number_of_timesteps": 3556352, "per_episode_reward": -82.45, "episode_reward_trend_value": 0.0034021849492756615, "biggest_recent_change": 0.07413506091097588},
{"total_number_of_episodes": 21374, "number_of_timesteps": 3558275, "per_episode_reward": -82.42, "episode_reward_trend_value": 0.003318825787415531, "biggest_recent_change": 0.07413506091097588},
{"total_number_of_episodes": 21384, "number_of_timesteps": 3560436, "per_episode_reward": -82.35, "episode_reward_trend_value": 0.0038869913488794178, "biggest_recent_change": 0.07413506091097588},
{"total_number_of_episodes": 21394, "number_of_timesteps": 3562469, "per_episode_reward": -82.3, "episode_reward_trend_value": 0.004135641305722339, "biggest_recent_change": 0.07413506091097588},
{"total_number_of_episodes": 21404, "number_of_timesteps": 3564956, "per_episode_reward": -82.25, "episode_reward_trend_value": 0.0043028541369036725, "biggest_recent_change": 0.07413506091097588},

{"total_number_of_episodes": 21415, "number_of_timesteps": 3567311, "per_episode_reward": -82.21, "episode_reward_trend_value": 0.003949029413828163, "biggest_recent_change": 0.06767725371793176},
{"total_number_of_episodes": 21426, "number_of_timesteps": 3569984, "per_episode_reward": -82.17, "episode_reward_trend_value": 0.0040801294603443556, "biggest_recent_change": 0.06767725371793176},
{"total_number_of_episodes": 21437, "number_of_timesteps": 3572796, "per_episode_reward": -82.12, "episode_reward_trend_value": 0.004265191628449985, "biggest_recent_change": 0.06767725371793176},
{"total_number_of_episodes": 21447, "number_of_timesteps": 3576547, "per_episode_reward": -82.0, "episode_reward_trend_value": 0.005198312551565544, "biggest_recent_change": 0.11805960964166218},
{"total_number_of_episodes": 21457, "number_of_timesteps": 3579799, "per_episode_reward": -81.93, "episode_reward_trend_value": 0.005796402449158064, "biggest_recent_change": 0.11805960964166218},
{"total_number_of_episodes": 21467, "number_of_timesteps": 3583362, "per_episode_reward": -81.9, "episode_reward_trend_value": 0.005845992125510532, "biggest_recent_change": 0.11805960964166218},
{"total_number_of_episodes": 21477, "number_of_timesteps": 3586316, "per_episode_reward": -81.87, "episode_reward_trend_value": 0.005414122398861012, "biggest_recent_change": 0.11805960964166218},
{"total_number_of_episodes": 21487, "number_of_timesteps": 3589790, "per_episode_reward": -81.82, "episode_reward_trend_value": 0.005314138987454776, "biggest_recent_change": 0.11805960964166218},
{"total_number_of_episodes": 21497, "number_of_timesteps": 3593685, "per_episode_reward": -81.75, "episode_reward_trend_value": 0.0055399015737535254, "biggest_recent_change": 0.11805960964166218},
{"total_number_of_episodes": 21507, "number_of_timesteps": 3596026, "per_episode_reward": -81.7, "episode_reward_trend_value": 0.005613825388773977, "biggest_recent_change": 0.11805960964166218},
{"total_number_of_episodes": 21517, "number_of_timesteps": 3598286, "per_episode_reward": -81.68, "episode_reward_trend_value": 0.005371788667695575, "biggest_recent_change": 0.11805960964166218},
{"total_number_of_episodes": 21527, "number_of_timesteps": 3600907, "per_episode_reward": -81.67, "episode_reward_trend_value": 0.004966716467913715, "biggest_recent_change": 0.11805960964166218},
{"total_number_of_episodes": 21537, "number_of_timesteps": 3604557, "per_episode_reward": -81.65, "episode_reward_trend_value": 0.003924114465358741, "biggest_recent_change": 0.07175797338059908},
{"total_number_of_episodes": 21547, "number_of_timesteps": 3607663, "per_episode_reward": -81.65, "episode_reward_trend_value": 0.0031228458215140776, "biggest_recent_change": 0.06464184080175528},
{"total_number_of_episodes": 21557, "number_of_timesteps": 3610550, "per_episode_reward": -81.62, "episode_reward_trend_value": 0.0030380957193249475, "biggest_recent_change": 0.06464184080175528},
{"total_number_of_episodes": 21567, "number_of_timesteps": 3614016, "per_episode_reward": -81.6, "episode_reward_trend_value": 0.0030091032917673663, "biggest_recent_change": 0.06464184080175528},
{"total_number_of_episodes": 21577, "number_of_timesteps": 3617036, "per_episode_reward": -81.58, "episode_reward_trend_value": 0.002595510154210956, "biggest_recent_change": 0.06464184080175528},
{"total_number_of_episodes": 21587, "number_of_timesteps": 3620334, "per_episode_reward": -81.5, "episode_reward_trend_value": 0.0028449889590221903, "biggest_recent_change": 0.08709493323476636},
{"total_number_of_episodes": 21597, "number_of_timesteps": 3623828, "per_episode_reward": -81.45, "episode_reward_trend_value": 0.002850314344800293, "biggest_recent_change": 0.08709493323476636},
{"total_number_of_episodes": 21607, "number_of_timesteps": 3628180, "per_episode_reward": -81.42, "episode_reward_trend_value": 0.002926442685292822, "biggest_recent_change": 0.08709493323476636},
{"total_number_of_episodes": 21617, "number_of_timesteps": 3631576, "per_episode_reward": -81.38, "episode_reward_trend_value": 0.0033028253311633824, "biggest_recent_change": 0.08709493323476636},
{"total_number_of_episodes": 21627, "number_of_timesteps": 3635420, "per_episode_reward": -81.34, "episode_reward_trend_value": 0.0034052745027832684, "biggest_recent_change": 0.08709493323476636},
{"total_number_of_episodes": 21637, "number_of_timesteps": 3642099, "per_episode_reward": -81.32, "episode_reward_trend_value": 0.003701700868630553, "biggest_recent_change": 0.08709493323476636},
{"total_number_of_episodes": 21647, "number_of_timesteps": 3645516, "per_episode_reward": -81.3, "episode_reward_trend_value": 0.0035768001611205906, "biggest_recent_change": 0.08709493323476636},
{"total_number_of_episodes": 21657, "number_of_timesteps": 3648702, "per_episode_reward": -81.26, "episode_reward_trend_value": 0.0037010331999599404, "biggest_recent_change": 0.08709493323476636},
{"total_number_of_episodes": 21667, "number_of_timesteps": 3652561, "per_episode_reward": -81.24, "episode_reward_trend_value": 0.003870036303234454, "biggest_recent_change": 0.08709493323476636},
{"total_number_of_episodes": 21677, "number_of_timesteps": 3656954, "per_episode_reward": -81.17, "episode_reward_trend_value": 0.0035826328144213763, "biggest_recent_change": 0.0612286192415894},
{"total_number_of_episodes": 21687, "number_of_timesteps": 3662765, "per_episode_reward": -81.12, "episode_reward_trend_value": 0.0036794237243667123, "biggest_recent_change": 0.0612286192415894},
{"total_number_of_episodes": 21697, "number_of_timesteps": 3670278, "per_episode_reward": -81.07, "episode_reward_trend_value": 0.0038556741756126363, "biggest_recent_change": 0.0612286192415894},
{"total_number_of_episodes": 21707, "number_of_timesteps": 3673868, "per_episode_reward": -81.04, "episode_reward_trend_value": 0.0037347827789225283, "biggest_recent_change": 0.0612286192415894},
{"total_number_of_episodes": 21717, "number_of_timesteps": 3680199, "per_episode_reward": -81.01, "episode_reward_trend_value": 0.003707833117560395, "biggest_recent_change": 0.0612286192415894},
{"total_number_of_episodes": 21727, "number_of_timesteps": 3683730, "per_episode_reward": -80.96, "episode_reward_trend_value": 0.003916175828630881, "biggest_recent_change": 0.0612286192415894},
{"total_number_of_episodes": 21737, "number_of_timesteps": 3686761, "per_episode_reward": -80.91, "episode_reward_trend_value": 0.004327879747321441, "biggest_recent_change": 0.0612286192415894},
{"total_number_of_episodes": 21747, "number_of_timesteps": 3691261, "per_episode_reward": -80.87, "episode_reward_trend_value": 0.004334416349830879, "biggest_recent_change": 0.0612286192415894},
{"total_number_of_episodes": 21757, "number_of_timesteps": 3693546, "per_episode_reward": -80.87, "episode_reward_trend_value": 0.004093288481075143, "biggest_recent_change": 0.0612286192415894},
{"total_number_of_episodes": 21767, "number_of_timesteps": 3696395, "per_episode_reward": -80.81, "episode_reward_trend_value": 0.004096234572383, "biggest_recent_change": 0.06149376745929658},
{"total_number_of_episodes": 21777, "number_of_timesteps": 3699440, "per_episode_reward": -80.74, "episode_reward_trend_value": 0.004166549613802159, "biggest_recent_change": 0.06446279952885448},
{"total_number_of_episodes": 21787, "number_of_timesteps": 3703453, "per_episode_reward": -80.65, "episode_reward_trend_value": 0.004724410295822186, "biggest_recent_change": 0.09255466594090933},
{"total_number_of_episodes": 21797, "number_of_timesteps": 3707917, "per_episode_reward": -80.64, "episode_reward_trend_value": 0.0044246399045769005, "biggest_recent_change": 0.09255466594090933},
{"total_number_of_episodes": 21807, "number_of_timesteps": 3711291, "per_episode_reward": -80.57, "episode_reward_trend_value": 0.004838518552157862, "biggest_recent_change": 0.09255466594090933},
{"total_number_of_episodes": 21817, "number_of_timesteps": 3715080, "per_episode_reward": -80.47, "episode_reward_trend_value": 0.005437210744822904, "biggest_recent_change": 0.09895530969703259},
{"total_number_of_episodes": 21827, "number_of_timesteps": 3717819, "per_episode_reward": -80.45, "episode_reward_trend_value": 0.005147868701322188, "biggest_recent_change": 0.09895530969703259},
{"total_number_of_episodes": 21837, "number_of_timesteps": 3720660, "per_episode_reward": -80.42, "episode_reward_trend_value": 0.005024463990032915, "biggest_recent_change": 0.09895530969703259},
{"total_number_of_episodes": 21848, "number_of_timesteps": 3723883, "per_episode_reward": -80.33, "episode_reward_trend_value": 0.005980079502744849, "biggest_recent_change": 0.09895530969703259},
{"total_number_of_episodes": 21858, "number_of_timesteps": 3726032, "per_episode_reward": -80.3, "episode_reward_trend_value": 0.0056532750467860006, "biggest_recent_change": 0.09895530969703259},
{"total_number_of_episodes": 21868, "number_of_timesteps": 3727963, "per_episode_reward": -80.25, "episode_reward_trend_value": 0.005474122575522244, "biggest_recent_change": 0.09895530969703259},

{"total_number_of_episodes": 21878, "number_of_timesteps": 3730192, "per_episode_reward": -80.22, "episode_reward_trend_value": 0.004761161237515429, "biggest_recent_change": 0.09895530969703259},
{"total_number_of_episodes": 21888, "number_of_timesteps": 3731941, "per_episode_reward": -80.18, "episode_reward_trend_value": 0.005103699046786718, "biggest_recent_change": 0.09895530969703259},
{"total_number_of_episodes": 21898, "number_of_timesteps": 3733390, "per_episode_reward": -80.14, "episode_reward_trend_value": 0.004839343776896657, "biggest_recent_change": 0.09895530969703259},
{"total_number_of_episodes": 21908, "number_of_timesteps": 3735144, "per_episode_reward": -80.1, "episode_reward_trend_value": 0.004199777217229439, "biggest_recent_change": 0.09230901479405418},
{"total_number_of_episodes": 21918, "number_of_timesteps": 3737887, "per_episode_reward": -80.05, "episode_reward_trend_value": 0.0044307538398685314, "biggest_recent_change": 0.09230901479405418},
{"total_number_of_episodes": 21929, "number_of_timesteps": 3739614, "per_episode_reward": -80.0, "episode_reward_trend_value": 0.00471899857416389, "biggest_recent_change": 0.09230901479405418},
{"total_number_of_episodes": 21940, "number_of_timesteps": 3741956, "per_episode_reward": -79.95, "episode_reward_trend_value": 0.0041630805425204665, "biggest_recent_change": 0.05280452963123139},
{"total_number_of_episodes": 21950, "number_of_timesteps": 3743324, "per_episode_reward": -79.93, "episode_reward_trend_value": 0.00411939260049997, "biggest_recent_change": 0.05280452963123139},
{"total_number_of_episodes": 21960, "number_of_timesteps": 3745039, "per_episode_reward": -79.9, "episode_reward_trend_value": 0.0038309311736434717, "biggest_recent_change": 0.05280452963123139},
{"total_number_of_episodes": 21970, "number_of_timesteps": 3746656, "per_episode_reward": -79.89, "episode_reward_trend_value": 0.0036314235464511547, "biggest_recent_change": 0.05280452963123139},
{"total_number_of_episodes": 21981, "number_of_timesteps": 3748787, "per_episode_reward": -79.84, "episode_reward_trend_value": 0.003838584898001803, "biggest_recent_change": 0.05630954769374341},
{"total_number_of_episodes": 21992, "number_of_timesteps": 3751130, "per_episode_reward": -79.8, "episode_reward_trend_value": 0.003697013099482168, "biggest_recent_change": 0.05630954769374341},
{"total_number_of_episodes": 22002, "number_of_timesteps": 3753063, "per_episode_reward": -79.74, "episode_reward_trend_value": 0.003947724535845193, "biggest_recent_change": 0.06395834859965532},
{"total_number_of_episodes": 22012, "number_of_timesteps": 3756420, "per_episode_reward": -79.68, "episode_reward_trend_value": 0.004068303817341088, "biggest_recent_change": 0.06395834859965532},
{"total_number_of_episodes": 22022, "number_of_timesteps": 3762003, "per_episode_reward": -79.68, "episode_reward_trend_value": 0.0035605004910078406, "biggest_recent_change": 0.06395834859965532},
{"total_number_of_episodes": 22032, "number_of_timesteps": 3766879, "per_episode_reward": -79.67, "episode_reward_trend_value": 0.0031899476309358, "biggest_recent_change": 0.06395834859965532},
{"total_number_of_episodes": 22042, "number_of_timesteps": 3771070, "per_episode_reward": -79.63, "episode_reward_trend_value": 0.0032840908378577497, "biggest_recent_change": 0.06395834859965532},
{"total_number_of_episodes": 22052, "number_of_timesteps": 3775611, "per_episode_reward": -79.63, "episode_reward_trend_value": 0.0030358891980235905, "biggest_recent_change": 0.06395834859965532},
{"total_number_of_episodes": 22062, "number_of_timesteps": 3778818, "per_episode_reward": -79.62, "episode_reward_trend_value": 0.0030150506191716888, "biggest_recent_change": 0.06395834859965532},
{"total_number_of_episodes": 22072, "number_of_timesteps": 3782466, "per_episode_reward": -79.58, "episode_reward_trend_value": 0.0028878138018304375, "biggest_recent_change": 0.06395834859965532},
{"total_number_of_episodes": 22082, "number_of_timesteps": 3788456, "per_episode_reward": -79.5, "episode_reward_trend_value": 0.0033326964564872066, "biggest_recent_change": 0.07177546637943522},
{"total_number_of_episodes": 22092, "number_of_timesteps": 3791755, "per_episode_reward": -79.45, "episode_reward_trend_value": 0.0032601237997119544, "biggest_recent_change": 0.07177546637943522},
{"total_number_of_episodes": 22102, "number_of_timesteps": 3796377, "per_episode_reward": -79.41, "episode_reward_trend_value": 0.0030538715141549093, "biggest_recent_change": 0.07177546637943522},
{"total_number_of_episodes": 22112, "number_of_timesteps": 3801654, "per_episode_reward": -79.38, "episode_reward_trend_value": 0.0032570269139768015, "biggest_recent_change": 0.07177546637943522},
{"total_number_of_episodes": 22122, "number_of_timesteps": 3805591, "per_episode_reward": -79.33, "episode_reward_trend_value": 0.0037253839496969475, "biggest_recent_change": 0.07177546637943522},
{"total_number_of_episodes": 22132, "number_of_timesteps": 3809606, "per_episode_reward": -79.31, "episode_reward_trend_value": 0.0035646673603516713, "biggest_recent_change": 0.07177546637943522},
{"total_number_of_episodes": 22142, "number_of_timesteps": 3814806, "per_episode_reward": -79.29, "episode_reward_trend_value": 0.003804901230821321, "biggest_recent_change": 0.07177546637943522},
{"total_number_of_episodes": 22152, "number_of_timesteps": 3819137, "per_episode_reward": -79.27, "episode_reward_trend_value": 0.0039013549805604147, "biggest_recent_change": 0.07177546637943522},
{"total_number_of_episodes": 22162, "number_of_timesteps": 3823353, "per_episode_reward": -79.23, "episode_reward_trend_value": 0.0038592750961392933, "biggest_recent_change": 0.07177546637943522},
{"total_number_of_episodes": 22172, "number_of_timesteps": 3827779, "per_episode_reward": -79.18, "episode_reward_trend_value": 0.003600084197985451, "biggest_recent_change": 0.05742680948988266},
{"total_number_of_episodes": 22182, "number_of_timesteps": 3831210, "per_episode_reward": -79.17, "episode_reward_trend_value": 0.0030801559874127013, "biggest_recent_change": 0.05107876775447551},
{"total_number_of_episodes": 22192, "number_of_timesteps": 3835335, "per_episode_reward": -79.14, "episode_reward_trend_value": 0.0029324348685101933, "biggest_recent_change": 0.05107876775447551},
{"total_number_of_episodes": 22202, "number_of_timesteps": 3839633, "per_episode_reward": -79.12, "episode_reward_trend_value": 0.0029506780605733714, "biggest_recent_change": 0.05107876775447551},
{"total_number_of_episodes": 22212, "number_of_timesteps": 3842988, "per_episode_reward": -79.06, "episode_reward_trend_value": 0.0030264949141173107, "biggest_recent_change": 0.05790228457343005},
{"total_number_of_episodes": 22222, "number_of_timesteps": 3847182, "per_episode_reward": -79.01, "episode_reward_trend_value": 0.0033136000541910938, "biggest_recent_change": 0.05790228457343005},
{"total_number_of_episodes": 22232, "number_of_timesteps": 3851967, "per_episode_reward": -79.0, "episode_reward_trend_value": 0.0032358194326222805, "biggest_recent_change": 0.05790228457343005},
{"total_number_of_episodes": 22242, "number_of_timesteps": 3855670, "per_episode_reward": -78.85, "episode_reward_trend_value": 0.0047062736009609, "biggest_recent_change": 0.14957869960331038},
{"total_number_of_episodes": 22252, "number_of_timesteps": 3859780, "per_episode_reward": -78.83, "episode_reward_trend_value": 0.004427193779407743, "biggest_recent_change": 0.14957869960331038},
{"total_number_of_episodes": 22262, "number_of_timesteps": 3863974, "per_episode_reward": -78.81, "episode_reward_trend_value": 0.004080218472516764, "biggest_recent_change": 0.14957869960331038},
{"total_number_of_episodes": 22272, "number_of_timesteps": 3868269, "per_episode_reward": -78.77, "episode_reward_trend_value": 0.004446372230774879, "biggest_recent_change": 0.14957869960331038},
{"total_number_of_episodes": 22282, "number_of_timesteps": 3872230, "per_episode_reward": -78.76, "episode_reward_trend_value": 0.0042567558386033336, "biggest_recent_change": 0.14957869960331038},
{"total_number_of_episodes": 22292, "number_of_timesteps": 3875679, "per_episode_reward": -78.73, "episode_reward_trend_value": 0.004339187532592506, "biggest_recent_change": 0.14957869960331038},
{"total_number_of_episodes": 22302, "number_of_timesteps": 3879199, "per_episode_reward": -78.7, "episode_reward_trend_value": 0.004042413586512339, "biggest_recent_change": 0.14957869960331038},
{"total_number_of_episodes": 22312, "number_of_timesteps": 3882218, "per_episode_reward": -78.68, "episode_reward_trend_value": 0.0037211759536701387, "biggest_recent_change": 0.14957869960331038},
{"total_number_of_episodes": 22322, "number_of_timesteps": 3885080, "per_episode_reward": -78.65, "episode_reward_trend_value": 0.003807256652111354, "biggest_recent_change": 0.14957869960331038},
{"total_number_of_episodes": 22332, "number_of_timesteps": 3888055, "per_episode_reward": -78.62, "episode_reward_trend_value": 0.0025636355633140953, "biggest_recent_change": 0.043587108781565576},
{"total_number_of_episodes": 22342, "number_of_timesteps": 3890655, "per_episode_reward": -78.59, "episode_reward_trend_value": 0.002713933293159067, "biggest_recent_change": 0.043587108781565576},
{"total_number_of_episodes": 22352, "number_of_timesteps": 3895350, "per_episode_reward": -78.56, "episode_reward_trend_value": 0.0028401844718484565, "biggest_recent_change": 0.043587108781565576},
{"total_number_of_episodes": 22362, "number_of_timesteps": 3899631, "per_episode_reward": -78.52, "episode_reward_trend_value": 0.0028034064163729036, "biggest_recent_change": 0.04027708378876582},
{"total_number_of_episodes": 22372, "number_of_timesteps": 3902156, "per_episode_reward": -78.47, "episode_reward_trend_value": 0.003243999047750713, "biggest_recent_change": 0.04883329394462521},
{"total_number_of_episodes": 22382, "number_of_timesteps": 3906600, "per_episode_reward": -78.44, "episode_reward_trend_value": 0.0031643095292006743, "biggest_recent_change": 0.04883329394462521},
{"total_number_of_episodes": 22392, "number_of_timesteps": 3911287, "per_episode_reward": -78.41, "episode_reward_trend_value": 0.003122845211659669, "biggest_recent_change": 0.04883329394462521},
{"total_number_of_episodes": 22402, "number_of_timesteps": 3916089, "per_episode_reward": -78.37, "episode_reward_trend_value": 0.0033676090690620856, "biggest_recent_change": 0.04883329394462521},

{"total_number_of_episodes": 22412, "number_of_timesteps": 3923008, "per_episode_reward": -78.36, "episode_reward_trend_value": 0.0033115775783414845, "biggest_recent_change": 0.04883329394462521},
{"total_number_of_episodes": 22422, "number_of_timesteps": 3926492, "per_episode_reward": -78.34, "episode_reward_trend_value": 0.0031072969616640004, "biggest_recent_change": 0.04883329394462521},
{"total_number_of_episodes": 22432, "number_of_timesteps": 3931720, "per_episode_reward": -78.24, "episode_reward_trend_value": 0.0038132998435183177, "biggest_recent_change": 0.09302091564828174},
{"total_number_of_episodes": 22442, "number_of_timesteps": 3939282, "per_episode_reward": -78.22, "episode_reward_trend_value": 0.0037758080596379134, "biggest_recent_change": 0.09302091564828174},
{"total_number_of_episodes": 22452, "number_of_timesteps": 3947343, "per_episode_reward": -78.19, "episode_reward_trend_value": 0.0036834690617008428, "biggest_recent_change": 0.09302091564828174},
{"total_number_of_episodes": 22462, "number_of_timesteps": 3951792, "per_episode_reward": -78.18, "episode_reward_trend_value": 0.0032019298009204693, "biggest_recent_change": 0.09302091564828174},
{"total_number_of_episodes": 22472, "number_of_timesteps": 3956978, "per_episode_reward": -78.15, "episode_reward_trend_value": 0.003226878626033643, "biggest_recent_change": 0.09302091564828174},
{"total_number_of_episodes": 22482, "number_of_timesteps": 3965229, "per_episode_reward": -78.11, "episode_reward_trend_value": 0.003328710419430555, "biggest_recent_change": 0.09302091564828174},
{"total_number_of_episodes": 22492, "number_of_timesteps": 3971398, "per_episode_reward": -78.09, "episode_reward_trend_value": 0.003104359089840614, "biggest_recent_change": 0.09302091564828174},
{"total_number_of_episodes": 22502, "number_of_timesteps": 3976334, "per_episode_reward": -78.04, "episode_reward_trend_value": 0.0035613992456319465, "biggest_recent_change": 0.09302091564828174},
{"total_number_of_episodes": 22512, "number_of_timesteps": 3981977, "per_episode_reward": -78.0, "episode_reward_trend_value": 0.0037060009755047452, "biggest_recent_change": 0.09302091564828174},
{"total_number_of_episodes": 22522, "number_of_timesteps": 3985379, "per_episode_reward": -77.97, "episode_reward_trend_value": 0.0030853463850070914, "biggest_recent_change": 0.058498236230107636},
{"total_number_of_episodes": 22532, "number_of_timesteps": 3989945, "per_episode_reward": -77.92, "episode_reward_trend_value": 0.0032581480600141627, "biggest_recent_change": 0.058498236230107636},
{"total_number_of_episodes": 22542, "number_of_timesteps": 3996625, "per_episode_reward": -77.9, "episode_reward_trend_value": 0.0031283735206702407, "biggest_recent_change": 0.058498236230107636},
{"total_number_of_episodes": 22552, "number_of_timesteps": 4000488, "per_episode_reward": -77.85, "episode_reward_trend_value": 0.0036243272866019853, "biggest_recent_change": 0.058498236230107636},
{"total_number_of_episodes": 22562, "number_of_timesteps": 4005566, "per_episode_reward": -77.82, "episode_reward_trend_value": 0.0036304251678026212, "biggest_recent_change": 0.058498236230107636},
{"total_number_of_episodes": 22572, "number_of_timesteps": 4009204, "per_episode_reward": -77.82, "episode_reward_trend_value": 0.0032914537453388936, "biggest_recent_change": 0.058498236230107636},
{"total_number_of_episodes": 22582, "number_of_timesteps": 4012845, "per_episode_reward": -77.77, "episode_reward_trend_value": 0.00364973541121461, "biggest_recent_change": 0.058498236230107636},
{"total_number_of_episodes": 22592, "number_of_timesteps": 4016498, "per_episode_reward": -77.69, "episode_reward_trend_value": 0.003821258393821046, "biggest_recent_change": 0.0739353046646869},
{"total_number_of_episodes": 22602, "number_of_timesteps": 4019815, "per_episode_reward": -77.69, "episode_reward_trend_value": 0.00348857977278543, "biggest_recent_change": 0.0739353046646869},
{"total_number_of_episodes": 22612, "number_of_timesteps": 4025187, "per_episode_reward": -77.65, "episode_reward_trend_value": 0.0035240830487833505, "biggest_recent_change": 0.0739353046646869},
{"total_number_of_episodes": 22622, "number_of_timesteps": 4029096, "per_episode_reward": -77.62, "episode_reward_trend_value": 0.003419760441830988, "biggest_recent_change": 0.0739353046646869},
{"total_number_of_episodes": 22632, "number_of_timesteps": 4032563, "per_episode_reward": -77.59, "episode_reward_trend_value": 0.0035095871994245604, "biggest_recent_change": 0.0739353046646869},
{"total_number_of_episodes": 22642, "number_of_timesteps": 4036545, "per_episode_reward": -77.56, "episode_reward_trend_value": 0.003246563592140066, "biggest_recent_change": 0.0739353046646869},
{"total_number_of_episodes": 22653, "number_of_timesteps": 4043420, "per_episode_reward": -77.54, "episode_reward_trend_value": 0.0031560520211816843, "biggest_recent_change": 0.0739353046646869},
{"total_number_of_episodes": 22663, "number_of_timesteps": 4047683, "per_episode_reward": -77.51, "episode_reward_trend_value": 0.0034038808550167546, "biggest_recent_change": 0.0739353046646869},
{"total_number_of_episodes": 22674, "number_of_timesteps": 4050690, "per_episode_reward": -77.5, "episode_reward_trend_value": 0.0029272964045012548, "biggest_recent_change": 0.0739353046646869},
{"total_number_of_episodes": 22684, "number_of_timesteps": 4054332, "per_episode_reward": -77.48, "episode_reward_trend_value": 0.002302045909529858, "biggest_recent_change": 0.04035729734330573},
{"total_number_of_episodes": 22694, "number_of_timesteps": 4058456, "per_episode_reward": -77.43, "episode_reward_trend_value": 0.002916044141371306, "biggest_recent_change": 0.05760046677166031},
{"total_number_of_episodes": 22704, "number_of_timesteps": 4063520, "per_episode_reward": -77.38, "episode_reward_trend_value": 0.002937967435530216, "biggest_recent_change": 0.05760046677166031},
{"total_number_of_episodes": 22714, "number_of_timesteps": 4068574, "per_episode_reward": -77.35, "episode_reward_trend_value": 0.002959802481743168, "biggest_recent_change": 0.05760046677166031},
{"total_number_of_episodes": 22724, "number_of_timesteps": 4072514, "per_episode_reward": -77.31, "episode_reward_trend_value": 0.0030666741595257777, "biggest_recent_change": 0.05760046677166031},
{"total_number_of_episodes": 22734, "number_of_timesteps": 4078867, "per_episode_reward": -77.28, "episode_reward_trend_value": 0.003111791069357474, "biggest_recent_change": 0.05760046677166031},
{"total_number_of_episodes": 22744, "number_of_timesteps": 4084314, "per_episode_reward": -77.28, "episode_reward_trend_value": 0.0029030334957740123, "biggest_recent_change": 0.05760046677166031},
{"total_number_of_episodes": 22754, "number_of_timesteps": 4087788, "per_episode_reward": -77.15, "episode_reward_trend_value": 0.0040677045755768085, "biggest_recent_change": 0.13324326645891915},
{"total_number_of_episodes": 22764, "number_of_timesteps": 4091693, "per_episode_reward": -77.12, "episode_reward_trend_value": 0.0042685934974688025, "biggest_recent_change": 0.13324326645891915},
{"total_number_of_episodes": 22774, "number_of_timesteps": 4095878, "per_episode_reward": -77.07, "episode_reward_trend_value": 0.004586786857655372, "biggest_recent_change": 0.13324326645891915},
{"total_number_of_episodes": 22784, "number_of_timesteps": 4099735, "per_episode_reward": -77.06, "episode_reward_trend_value": 0.004084733451133123, "biggest_recent_change": 0.13324326645891915},
{"total_number_of_episodes": 22795, "number_of_timesteps": 4104703, "per_episode_reward": -77.05, "episode_reward_trend_value": 0.0036722125490420074, "biggest_recent_change": 0.13324326645891915},
{"total_number_of_episodes": 22805, "number_of_timesteps": 4109865, "per_episode_reward": -77.05, "episode_reward_trend_value": 0.003389640667320748, "biggest_recent_change": 0.13324326645891915},
{"total_number_of_episodes": 22815, "number_of_timesteps": 4114714, "per_episode_reward": -77.04, "episode_reward_trend_value": 0.003051641782968457, "biggest_recent_change": 0.13324326645891915},
{"total_number_of_episodes": 22825, "number_of_timesteps": 4119117, "per_episode_reward": -77.03, "episode_reward_trend_value": 0.0027867065045798414, "biggest_recent_change": 0.13324326645891915},
{"total_number_of_episodes": 22836, "number_of_timesteps": 4124578, "per_episode_reward": -76.99, "episode_reward_trend_value": 0.0031740853032166194, "biggest_recent_change": 0.13324326645891915},
{"total_number_of_episodes": 22846, "number_of_timesteps": 4129974, "per_episode_reward": -76.98, "episode_reward_trend_value": 0.001864548368582872, "biggest_recent_change": 0.04630016253405245},
{"total_number_of_episodes": 22856, "number_of_timesteps": 4134146, "per_episode_reward": -76.95, "episode_reward_trend_value": 0.0019028477511072752, "biggest_recent_change": 0.04630016253405245},
{"total_number_of_episodes": 22867, "number_of_timesteps": 4136816, "per_episode_reward": -76.9, "episode_reward_trend_value": 0.001888453645881485, "biggest_recent_change": 0.04500469306373134},
{"total_number_of_episodes": 22877, "number_of_timesteps": 4139853, "per_episode_reward": -76.87, "episode_reward_trend_value": 0.0021211637766446263, "biggest_recent_change": 0.04500469306373134},
{"total_number_of_episodes": 22887, "number_of_timesteps": 4141641, "per_episode_reward": -76.85, "episode_reward_trend_value": 0.002241046252943117, "biggest_recent_change": 0.04500469306373134},
{"total_number_of_episodes": 22897, "number_of_timesteps": 4144542, "per_episode_reward": -76.81, "episode_reward_trend_value": 0.002613215306430226, "biggest_recent_change": 0.04500469306373134},
{"total_number_of_episodes": 22908, "number_of_timesteps": 4147074, "per_episode_reward": -76.77, "episode_reward_trend_value": 0.002971780271364979, "biggest_recent_change": 0.04500469306373134},
{"total_number_of_episodes": 22918, "number_of_timesteps": 4151192, "per_episode_reward": -76.75, "episode_reward_trend_value": 0.003172111030640047, "biggest_recent_change": 0.04500469306373134},
{"total_number_of_episodes": 22928, "number_of_timesteps": 4156501, "per_episode_reward": -76.75, "episode_reward_trend_value": 0.0027077418595977875, "biggest_recent_change": 0.04500469306373134},
{"total_number_of_episodes": 22938, "number_of_timesteps": 4160550, "per_episode_reward": -76.71, "episode_reward_trend_value": 0.0030255029623813498, "biggest_recent_change": 0.04500469306373134},
{"total_number_of_episodes": 22948, "number_of_timesteps": 4165196, "per_episode_reward": -76.68, "episode_reward_trend_value": 0.002988058709209756, "biggest_recent_change": 0.04500469306373134},
{"total_number_of_episodes": 22958, "number_of_timesteps": 4170272, "per_episode_reward": -76.65, "episode_reward_trend_value": 0.00276608402403882, "biggest_recent_change": 0.04398344159240253},
{"total_number_of_episodes": 22968, "number_of_timesteps": 4175243, "per_episode_reward": -76.61, "episode_reward_trend_value": 0.0029153036939398983, "biggest_recent_change": 0.04678934224443765},
{"total_number_of_episodes": 22978, "number_of_timesteps": 4179188, "per_episode_reward": -76.55, "episode_reward_trend_value": 0.003307472961852101, "biggest_recent_change": 0.05128816960836957},
{"total_number_of_episodes": 22988, "number_of_timesteps": 4182147, "per_episode_reward": -76.53, "episode_reward_trend_value": 0.003155193172989357, "biggest_recent_change": 0.05128816960836957},
{"total_number_of_episodes": 22998, "number_of_timesteps": 4186130, "per_episode_reward": -76.52, "episode_reward_trend_value": 0.002810017387418719, "biggest_recent_change": 0.05128816960836957},
{"total_number_of_episodes": 23008, "number_of_timesteps": 4192610, "per_episode_reward": -76.48, "episode_reward_trend_value": 0.002907697362116184, "biggest_recent_change": 0.05128816960836957},
{"total_number_of_episodes": 23018, "number_of_timesteps": 4196417, "per_episode_reward": -76.44, "episode_reward_trend_value": 0.003474360649762471, "biggest_recent_change": 0.05128816960836957},
{"total_number_of_episodes": 23028, "number_of_timesteps": 4202752, "per_episode_reward": -76.38, "episode_reward_trend_value": 0.003583406903159098, "biggest_recent_change": 0.053797604398099},
{"total_number_of_episodes": 23038, "number_of_timesteps": 4206306, "per_episode_reward": -76.34, "episode_reward_trend_value": 0.0037849723661640016, "biggest_recent_change": 0.053797604398099},
{"total_number_of_episodes": 23049, "number_of_timesteps": 4213560, "per_episode_reward": -76.32, "episode_reward_trend_value": 0.00369035426173983, "biggest_recent_change": 0.053797604398099},
{"total_number_of_episodes": 23059, "number_of_timesteps": 4218253, "per_episode_reward": -76.26, "episode_reward_trend_value": 0.00384930666870231, "biggest_recent_change": 0.061095058871060814},
{"total_number_of_episodes": 23069, "number_of_timesteps": 4221738, "per_episode_reward": -76.21, "episode_reward_trend_value": 0.003776173155518355, "biggest_recent_change": 0.061095058871060814},
{"total_number_of_episodes": 23080, "number_of_timesteps": 4226075, "per_episode_reward": -76.19, "episode_reward_trend_value": 0.0037520058261703874, "biggest_recent_change": 0.061095058871060814},
{"total_number_of_episodes": 23090, "number_of_timesteps": 4230557, "per_episode_reward": -76.16, "episode_reward_trend_value": 0.003979440451270951, "biggest_recent_change": 0.061095058871060814},
{"total_number_of_episodes": 23100, "number_of_timesteps": 4234318, "per_episode_reward": -76.11, "episode_reward_trend_value": 0.004188961431200748, "biggest_recent_change": 0.061095058871060814},
{"total_number_of_episodes": 23110, "number_of_timesteps": 4236974, "per_episode_reward": -76.08, "episode_reward_trend_value": 0.003933180109602733, "biggest_recent_change": 0.061095058871060814},
{"total_number_of_episodes": 23120, "number_of_timesteps": 4241225, "per_episode_reward": -76.01, "episode_reward_trend_value": 0.004094204119211674, "biggest_recent_change": 0.06828976526290376},
{"total_number_of_episodes": 23130, "number_of_timesteps": 4247742, "per_episode_reward": -75.99, "episode_reward_trend_value": 0.0038773872639830467, "biggest_recent_change": 0.06828976526290376},
{"total_number_of_episodes": 23140, "number_of_timesteps": 4254122, "per_episode_reward": -75.94, "episode_reward_trend_value": 0.004178013218614277, "biggest_recent_change": 0.06828976526290376},
{"total_number_of_episodes": 23150, "number_of_timesteps": 4259133, "per_episode_reward": -75.81, "episode_reward_trend_value": 0.005006152869462552, "biggest_recent_change": 0.13562762744740553},
{"total_number_of_episodes": 23160, "number_of_timesteps": 4263115, "per_episode_reward": -75.75, "episode_reward_trend_value": 0.005168298069730623, "biggest_recent_change": 0.13562762744740553},
{"total_number_of_episodes": 23170, "number_of_timesteps": 4267482, "per_episode_reward": -75.7, "episode_reward_trend_value": 0.005484074349096426, "biggest_recent_change": 0.13562762744740553},
{"total_number_of_episodes": 23180, "number_of_timesteps": 4273269, "per_episode_reward": -75.63, "episode_reward_trend_value": 0.0058779904336159604, "biggest_recent_change": 0.13562762744740553},
{"total_number_of_episodes": 23190, "number_of_timesteps": 4278627, "per_episode_reward": -75.58, "episode_reward_trend_value": 0.005834767502791275, "biggest_recent_change": 0.13562762744740553},
{"total_number_of_episodes": 23200, "number_of_timesteps": 4284245, "per_episode_reward": -75.52, "episode_reward_trend_value": 0.006300898986422175, "biggest_recent_change": 0.13562762744740553},
{"total_number_of_episodes": 23210, "number_of_timesteps": 4287517, "per_episode_reward": -75.47, "episode_reward_trend_value": 0.006014220615987635, "biggest_recent_change": 0.13562762744740553},
{"total_number_of_episodes": 23220, "number_of_timesteps": 4292896, "per_episode_reward": -75.41, "episode_reward_trend_value": 0.006442614895389278, "biggest_recent_change": 0.13562762744740553},
{"total_number_of_episodes": 23230, "number_of_timesteps": 4297256, "per_episode_reward": -75.37, "episode_reward_trend_value": 0.006403309884037374, "biggest_recent_change": 0.13562762744740553},
{"total_number_of_episodes": 23240, "number_of_timesteps": 4301281, "per_episode_reward": -75.34, "episode_reward_trend_value": 0.0051642304880347625, "biggest_recent_change": 0.06613695683452647},
{"total_number_of_episodes": 23250, "number_of_timesteps": 4304025, "per_episode_reward": -75.32, "episode_reward_trend_value": 0.004816084586111439, "biggest_recent_change": 0.06613695683452647},
{"total_number_of_episodes": 23260, "number_of_timesteps": 4307708, "per_episode_reward": -75.27, "episode_reward_trend_value": 0.004771761292082191, "biggest_recent_change": 0.06613695683452647},
{"total_number_of_episodes": 23270, "number_of_timesteps": 4310841, "per_episode_reward": -75.26, "episode_reward_trend_value": 0.004122054355701405, "biggest_recent_change": 0.06613695683452647},
{"total_number_of_episodes": 23280, "number_of_timesteps": 4312966, "per_episode_reward": -75.21, "episode_reward_trend_value": 0.0040907946604328855, "biggest_recent_change": 0.06613695683452647},
{"total_number_of_episodes": 23290, "number_of_timesteps": 4316105, "per_episode_reward": -75.14, "episode_reward_trend_value": 0.004207157480172599, "biggest_recent_change": 0.07660961061110072},
{"total_number_of_episodes": 23301, "number_of_timesteps": 4318706, "per_episode_reward": -75.09, "episode_reward_trend_value": 0.004227766436640619, "biggest_recent_change": 0.07660961061110072},
{"total_number_of_episodes": 23312, "number_of_timesteps": 4321437, "per_episode_reward": -75.06, "episode_reward_trend_value": 0.003919935804109779, "biggest_recent_change": 0.07660961061110072},
{"total_number_of_episodes": 23322, "number_of_timesteps": 4325238, "per_episode_reward": -75.01, "episode_reward_trend_value": 0.00403032316112378, "biggest_recent_change": 0.07660961061110072},
{"total_number_of_episodes": 23332, "number_of_timesteps": 4329192, "per_episode_reward": -74.98, "episode_reward_trend_value": 0.004010707471043733, "biggest_recent_change": 0.07660961061110072},
{"total_number_of_episodes": 23342, "number_of_timesteps": 4332835, "per_episode_reward": -74.96, "episode_reward_trend_value": 0.003922921093504625, "biggest_recent_change": 0.07660961061110072},
{"total_number_of_episodes": 23352, "number_of_timesteps": 4334874, "per_episode_reward": -74.9, "episode_reward_trend_value": 0.004050240738188569, "biggest_recent_change": 0.07660961061110072},
{"total_number_of_episodes": 23362, "number_of_timesteps": 4337772, "per_episode_reward": -74.82, "episode_reward_trend_value": 0.00484910606612298, "biggest_recent_change": 0.07812067027403202},
{"total_number_of_episodes": 23372, "number_of_timesteps": 4340928, "per_episode_reward": -74.81, "episode_reward_trend_value": 0.004457889418382245, "biggest_recent_change": 0.07812067027403202},
{"total_number_of_episodes": 23382, "number_of_timesteps": 4344779, "per_episode_reward": -74.79, "episode_reward_trend_value": 0.003907987397171395, "biggest_recent_change": 0.07812067027403202},
{"total_number_of_episodes": 23392, "number_of_timesteps": 4348714, "per_episode_reward": -74.73, "episode_reward_trend_value": 0.003982569036122483, "biggest_recent_change": 0.07812067027403202},
{"total_number_of_episodes": 23402, "number_of_timesteps": 4353019, "per_episode_reward": -74.6, "episode_reward_trend_value": 0.005023766526723724, "biggest_recent_change": 0.13161864144382207},
{"total_number_of_episodes": 23413, "number_of_timesteps": 4358732, "per_episode_reward": -74.56, "episode_reward_trend_value": 0.004992858576902867, "biggest_recent_change": 0.13161864144382207},
{"total_number_of_episodes": 23423, "number_of_timesteps": 4363802, "per_episode_reward": -74.55, "episode_reward_trend_value": 0.004824862672930408, "biggest_recent_change": 0.13161864144382207},
{"total_number_of_episodes": 23434, "number_of_timesteps": 4368284, "per_episode_reward": -74.53, "episode_reward_trend_value": 0.004855879795051818, "biggest_recent_change": 0.13161864144382207},
{"total_number_of_episodes": 23444, "number_of_timesteps": 4372055, "per_episode_reward": -74.51, "episode_reward_trend_value": 0.004369204439975426, "biggest_recent_change": 0.13161864144382207},
{"total_number_of_episodes": 23454, "number_of_timesteps": 4375288, "per_episode_reward": -74.46, "episode_reward_trend_value": 0.00401560207268277, "biggest_recent_change": 0.13161864144382207},
{"total_number_of_episodes": 23464, "number_of_timesteps": 4379049, "per_episode_reward": -74.43, "episode_reward_trend_value": 0.004264342990749034, "biggest_recent_change": 0.13161864144382207},
{"total_number_of_episodes": 23474, "number_of_timesteps": 4381621, "per_episode_reward": -74.38, "episode_reward_trend_value": 0.004540157998448535, "biggest_recent_change": 0.13161864144382207},
{"total_number_of_episodes": 23484, "number_of_timesteps": 4383906, "per_episode_reward": -74.35, "episode_reward_trend_value": 0.004288719286386803, "biggest_recent_change": 0.13161864144382207},
{"total_number_of_episodes": 23494, "number_of_timesteps": 4387416, "per_episode_reward": -74.33, "episode_reward_trend_value": 0.003042582560582869, "biggest_recent_change": 0.05194177939507938},
{"total_number_of_episodes": 23504, "number_of_timesteps": 4389872, "per_episode_reward": -74.29, "episode_reward_trend_value": 0.002934066917934312, "biggest_recent_change": 0.05194177939507938},
{"total_number_of_episodes": 23514, "number_of_timesteps": 4393860, "per_episode_reward": -74.26, "episode_reward_trend_value": 0.0031889644850874926, "biggest_recent_change": 0.05194177939507938},
{"total_number_of_episodes": 23524, "number_of_timesteps": 4396915, "per_episode_reward": -74.24, "episode_reward_trend_value": 0.0031583076271750263, "biggest_recent_change": 0.05194177939507938},
{"total_number_of_episodes": 23534, "number_of_timesteps": 4400649, "per_episode_reward": -74.16, "episode_reward_trend_value": 0.0038160454516844625, "biggest_recent_change": 0.07680578751308076},
{"total_number_of_episodes": 23544, "number_of_timesteps": 4404610, "per_episode_reward": -74.14, "episode_reward_trend_value": 0.0035965963036831443, "biggest_recent_change": 0.07680578751308076},
{"total_number_of_episodes": 23554, "number_of_timesteps": 4409725, "per_episode_reward": -74.1, "episode_reward_trend_value": 0.0036813612326383805, "biggest_recent_change": 0.07680578751308076},
{"total_number_of_episodes": 23564, "number_of_timesteps": 4415780, "per_episode_reward": -74.07, "episode_reward_trend_value": 0.003395512168517851, "biggest_recent_change": 0.07680578751308076},
{"total_number_of_episodes": 23574, "number_of_timesteps": 4420095, "per_episode_reward": -74.04, "episode_reward_trend_value": 0.0034331831148135287, "biggest_recent_change": 0.07680578751308076},
{"total_number_of_episodes": 23584, "number_of_timesteps": 4427837, "per_episode_reward": -74.0, "episode_reward_trend_value": 0.003687219957885822, "biggest_recent_change": 0.07680578751308076},
{"total_number_of_episodes": 23594, "number_of_timesteps": 4433140, "per_episode_reward": -73.94, "episode_reward_trend_value": 0.0038673354983092484, "biggest_recent_change": 0.07680578751308076},
{"total_number_of_episodes": 23604, "number_of_timesteps": 4439535, "per_episode_reward": -73.92, "episode_reward_trend_value": 0.003744753374132554, "biggest_recent_change": 0.07680578751308076},
{"total_number_of_episodes": 23614, "number_of_timesteps": 4444379, "per_episode_reward": -73.9, "episode_reward_trend_value": 0.0038446990572918735, "biggest_recent_change": 0.07680578751308076},
{"total_number_of_episodes": 23624, "number_of_timesteps": 4448377, "per_episode_reward": -73.87, "episode_reward_trend_value": 0.0032570724591312545, "biggest_recent_change": 0.053627364342432315},
{"total_number_of_episodes": 23634, "number_of_timesteps": 4451901, "per_episode_reward": -73.84, "episode_reward_trend_value": 0.0032785309644662816, "biggest_recent_change": 0.053627364342432315},
{"total_number_of_episodes": 23644, "number_of_timesteps": 4456737, "per_episode_reward": -73.81, "episode_reward_trend_value": 0.0031490361101649315, "biggest_recent_change": 0.053627364342432315},
{"total_number_of_episodes": 23654, "number_of_timesteps": 4461170, "per_episode_reward": -73.79, "episode_reward_trend_value": 0.0031732934197107295, "biggest_recent_change": 0.053627364342432315},
{"total_number_of_episodes": 23664, "number_of_timesteps": 4465888, "per_episode_reward": -73.76, "episode_reward_trend_value": 0.0031339887205638836, "biggest_recent_change": 0.053627364342432315},
{"total_number_of_episodes": 23674, "number_of_timesteps": 4469427, "per_episode_reward": -73.71, "episode_reward_trend_value": 0.0032013714369801016, "biggest_recent_change": 0.053627364342432315},
{"total_number_of_episodes": 23684, "number_of_timesteps": 4471774, "per_episode_reward": -73.66, "episode_reward_trend_value": 0.003194941638535435, "biggest_recent_change": 0.053048682482412346},
{"total_number_of_episodes": 23694, "number_of_timesteps": 4475411, "per_episode_reward": -73.65, "episode_reward_trend_value": 0.003076460829215459, "biggest_recent_change": 0.053048682482412346},
{"total_number_of_episodes": 23704, "number_of_timesteps": 4481475, "per_episode_reward": -73.63, "episode_reward_trend_value": 0.002936251147761166, "biggest_recent_change": 0.053048682482412346},
{"total_number_of_episodes": 23714, "number_of_timesteps": 4488971, "per_episode_reward": -73.59, "episode_reward_trend_value": 0.0031532407464295725, "biggest_recent_change": 0.053048682482412346},
{"total_number_of_episodes": 23724, "number_of_timesteps": 4496121, "per_episode_reward": -73.56, "episode_reward_trend_value": 0.0031807970141749646, "biggest_recent_change": 0.053048682482412346},
{"total_number_of_episodes": 23734, "number_of_timesteps": 4500540, "per_episode_reward": -73.53, "episode_reward_trend_value": 0.003145031583119362, "biggest_recent_change": 0.053048682482412346},
{"total_number_of_episodes": 23744, "number_of_timesteps": 4505582, "per_episode_reward": -73.51, "episode_reward_trend_value": 0.003036186147192173, "biggest_recent_change": 0.053048682482412346},
{"total_number_of_episodes": 23754, "number_of_timesteps": 4509275, "per_episode_reward": -73.49, "episode_reward_trend_value": 0.0029671109351351926, "biggest_recent_change": 0.053048682482412346},
{"total_number_of_episodes": 23764, "number_of_timesteps": 4513849, "per_episode_reward": -73.46, "episode_reward_trend_value": 0.0027739022681629423, "biggest_recent_change": 0.053048682482412346},
{"total_number_of_episodes": 23774, "number_of_timesteps": 4517610, "per_episode_reward": -73.41, "episode_reward_trend_value": 0.002785342081570421, "biggest_recent_change": 0.05407826568908547},
{"total_number_of_episodes": 23784, "number_of_timesteps": 4521220, "per_episode_reward": -73.37, "episode_reward_trend_value": 0.0030908265511159685, "biggest_recent_change": 0.05407826568908547},
{"total_number_of_episodes": 23794, "number_of_timesteps": 4526988, "per_episode_reward": -73.31, "episode_reward_trend_value": 0.0036129280438940564, "biggest_recent_change": 0.06346311457660647},
{"total_number_of_episodes": 23804, "number_of_timesteps": 4532397, "per_episode_reward": -73.29, "episode_reward_trend_value": 0.003296992233719228, "biggest_recent_change": 0.06346311457660647},
{"total_number_of_episodes": 23815, "number_of_timesteps": 4539125, "per_episode_reward": -73.26, "episode_reward_trend_value": 0.0033048947093612295, "biggest_recent_change": 0.06346311457660647},
{"total_number_of_episodes": 23825, "number_of_timesteps": 4543120, "per_episode_reward": -73.24, "episode_reward_trend_value": 0.003223077470581694, "biggest_recent_change": 0.06346311457660647},
{"total_number_of_episodes": 23835, "number_of_timesteps": 4547235, "per_episode_reward": -73.2, "episode_reward_trend_value": 0.003524766741074043, "biggest_recent_change": 0.06346311457660647},
{"total_number_of_episodes": 23845, "number_of_timesteps": 4551138, "per_episode_reward": -73.16, "episode_reward_trend_value": 0.003644788029500982, "biggest_recent_change": 0.06346311457660647},
{"total_number_of_episodes": 23855, "number_of_timesteps": 4557361, "per_episode_reward": -73.13, "episode_reward_trend_value": 0.0036098792853978684, "biggest_recent_change": 0.06346311457660647},
{"total_number_of_episodes": 23865, "number_of_timesteps": 4560855, "per_episode_reward": -73.11, "episode_reward_trend_value": 0.0032599953681145483, "biggest_recent_change": 0.06346311457660647},
{"total_number_of_episodes": 23875, "number_of_timesteps": 4564495, "per_episode_reward": -73.09, "episode_reward_trend_value": 0.003071732814633303, "biggest_recent_change": 0.06346311457660647},
{"total_number_of_episodes": 23885, "number_of_timesteps": 4567060, "per_episode_reward": -73.08, "episode_reward_trend_value": 0.002488809249798231, "biggest_recent_change": 0.045754466594218},
{"total_number_of_episodes": 23895, "number_of_timesteps": 4571182, "per_episode_reward": -73.06, "episode_reward_trend_value": 0.0025756228196576734, "biggest_recent_change": 0.045754466594218},
{"total_number_of_episodes": 23905, "number_of_timesteps": 4576120, "per_episode_reward": -73.04, "episode_reward_trend_value": 0.0024697586943092788, "biggest_recent_change": 0.045754466594218},
{"total_number_of_episodes": 23915, "number_of_timesteps": 4579396, "per_episode_reward": -73.01, "episode_reward_trend_value": 0.0025429673939866703, "biggest_recent_change": 0.045754466594218},
{"total_number_of_episodes": 23925, "number_of_timesteps": 4582268, "per_episode_reward": -72.98, "episode_reward_trend_value": 0.0024384354790272923, "biggest_recent_change": 0.03634659424787401},
{"total_number_of_episodes": 23936, "number_of_timesteps": 4586932, "per_episode_reward": -72.82, "episode_reward_trend_value": 0.003770771360456296, "biggest_recent_change": 0.15277471987126034},
{"total_number_of_episodes": 23946, "number_of_timesteps": 4592111, "per_episode_reward": -72.81, "episode_reward_trend_value": 0.003559714023613796, "biggest_recent_change": 0.15277471987126034},
{"total_number_of_episodes": 23956, "number_of_timesteps": 4596603, "per_episode_reward": -72.78, "episode_reward_trend_value": 0.0037435738569933444, "biggest_recent_change": 0.15277471987126034},
{"total_number_of_episodes": 23966, "number_of_timesteps": 4600663, "per_episode_reward": -72.76, "episode_reward_trend_value": 0.0036761626543062044, "biggest_recent_change": 0.15277471987126034},
{"total_number_of_episodes": 23976, "number_of_timesteps": 4605622, "per_episode_reward": -72.69, "episode_reward_trend_value": 0.004362852578250119, "biggest_recent_change": 0.15277471987126034},
{"total_number_of_episodes": 23986, "number_of_timesteps": 4609226, "per_episode_reward": -72.64, "episode_reward_trend_value": 0.004654639565782917, "biggest_recent_change": 0.15277471987126034},
{"total_number_of_episodes": 23996, "number_of_timesteps": 4613553, "per_episode_reward": -72.58, "episode_reward_trend_value": 0.005049798260494577, "biggest_recent_change": 0.15277471987126034},
{"total_number_of_episodes": 24006, "number_of_timesteps": 4617099, "per_episode_reward": -72.52, "episode_reward_trend_value": 0.005510050516217607, "biggest_recent_change": 0.15277471987126034},
{"total_number_of_episodes": 24016, "number_of_timesteps": 4622475, "per_episode_reward": -72.48, "episode_reward_trend_value": 0.005547699919168597, "biggest_recent_change": 0.15277471987126034},
{"total_number_of_episodes": 24026, "number_of_timesteps": 4627323, "per_episode_reward": -72.46, "episode_reward_trend_value": 0.004047300698161551, "biggest_recent_change": 0.07280208689640233},
{"total_number_of_episodes": 24036, "number_of_timesteps": 4631248, "per_episode_reward": -72.44, "episode_reward_trend_value": 0.004158185431203441, "biggest_recent_change": 0.07280208689640233},
{"total_number_of_episodes": 24047, "number_of_timesteps": 4636969, "per_episode_reward": -72.41, "episode_reward_trend_value": 0.004022858402406845, "biggest_recent_change": 0.07280208689640233},
{"total_number_of_episodes": 24057, "number_of_timesteps": 4640043, "per_episode_reward": -72.35, "episode_reward_trend_value": 0.0046171792313346475, "biggest_recent_change": 0.07280208689640233},
{"total_number_of_episodes": 24067, "number_of_timesteps": 4644324, "per_episode_reward": -72.33, "episode_reward_trend_value": 0.004042020651852201, "biggest_recent_change": 0.06644239417897779},
{"total_number_of_episodes": 24077, "number_of_timesteps": 4647439, "per_episode_reward": -72.29, "episode_reward_trend_value": 0.003914264580106577, "biggest_recent_change": 0.06644239417897779},
{"total_number_of_episodes": 24087, "number_of_timesteps": 4652616, "per_episode_reward": -72.26, "episode_reward_trend_value": 0.003579407700675574, "biggest_recent_change": 0.06644239417897779},
{"total_number_of_episodes": 24097, "number_of_timesteps": 4655962, "per_episode_reward": -72.2, "episode_reward_trend_value": 0.0035388087049732855, "biggest_recent_change": 0.06644239417897779},
{"total_number_of_episodes": 24107, "number_of_timesteps": 4658232, "per_episode_reward": -72.13, "episode_reward_trend_value": 0.003857954095888437, "biggest_recent_change": 0.06845812569582677},
{"total_number_of_episodes": 24117, "number_of_timesteps": 4661555, "per_episode_reward": -72.1, "episode_reward_trend_value": 0.0039719538378285, "biggest_recent_change": 0.06845812569582677},
{"total_number_of_episodes": 24127, "number_of_timesteps": 4665126, "per_episode_reward": -72.07, "episode_reward_trend_value": 0.004145677643715197, "biggest_recent_change": 0.06845812569582677},
{"total_number_of_episodes": 24137, "number_of_timesteps": 4667506, "per_episode_reward": -72.06, "episode_reward_trend_value": 0.003892625310268411, "biggest_recent_change": 0.06845812569582677},
{"total_number_of_episodes": 24147, "number_of_timesteps": 4670317, "per_episode_reward": -72.03, "episode_reward_trend_value": 0.0035416479761472093, "biggest_recent_change": 0.06845812569582677},
{"total_number_of_episodes": 24157, "number_of_timesteps": 4673361, "per_episode_reward": -71.98, "episode_reward_trend_value": 0.0038360192353189227, "biggest_recent_change": 0.06845812569582677},
{"total_number_of_episodes": 24167, "number_of_timesteps": 4676167, "per_episode_reward": -71.96, "episode_reward_trend_value": 0.003676841676832825, "biggest_recent_change": 0.06845812569582677},
{"total_number_of_episodes": 24177, "number_of_timesteps": 4679503, "per_episode_reward": -71.93, "episode_reward_trend_value": 0.0036379809141056144, "biggest_recent_change": 0.06845812569582677},
{"total_number_of_episodes": 24189, "number_of_timesteps": 4682787, "per_episode_reward": -71.84, "episode_reward_trend_value": 0.003921277672839096, "biggest_recent_change": 0.0880725749071729},
{"total_number_of_episodes": 24199, "number_of_timesteps": 4686114, "per_episode_reward": -71.82, "episode_reward_trend_value": 0.0034471419213215567, "biggest_recent_change": 0.0880725749071729},
{"total_number_of_episodes": 24209, "number_of_timesteps": 4690039, "per_episode_reward": -71.77, "episode_reward_trend_value": 0.0036855452645805065, "biggest_recent_change": 0.0880725749071729},
{"total_number_of_episodes": 24219, "number_of_timesteps": 4695001, "per_episode_reward": -71.75, "episode_reward_trend_value": 0.0035444159002144225, "biggest_recent_change": 0.0880725749071729},
{"total_number_of_episodes": 24229, "number_of_timesteps": 4701627, "per_episode_reward": -71.69, "episode_reward_trend_value": 0.00414023968026432, "biggest_recent_change": 0.0880725749071729},
{"total_number_of_episodes": 24239, "number_of_timesteps": 4707110, "per_episode_reward": -71.64, "episode_reward_trend_value": 0.00431106789764581, "biggest_recent_change": 0.0880725749071729},
{"total_number_of_episodes": 24249, "number_of_timesteps": 4710960, "per_episode_reward": -71.59, "episode_reward_trend_value": 0.004378184379125906, "biggest_recent_change": 0.0880725749071729},

{"total_number_of_episodes": 24259, "number_of_timesteps": 4717481, "per_episode_reward": -71.57, "episode_reward_trend_value": 0.0043479525052598925, "biggest_recent_change": 0.0880725749071729},
{"total_number_of_episodes": 24269, "number_of_timesteps": 4720992, "per_episode_reward": -71.55, "episode_reward_trend_value": 0.0042763373861455355, "biggest_recent_change": 0.0880725749071729},
{"total_number_of_episodes": 24279, "number_of_timesteps": 4725136, "per_episode_reward": -71.53, "episode_reward_trend_value": 0.003546902877656856, "biggest_recent_change": 0.05780609574033235},
{"total_number_of_episodes": 24289, "number_of_timesteps": 4731801, "per_episode_reward": -71.5, "episode_reward_trend_value": 0.003527306916727784, "biggest_recent_change": 0.05780609574033235},
{"total_number_of_episodes": 24299, "number_of_timesteps": 4737833, "per_episode_reward": -71.47, "episode_reward_trend_value": 0.0033522749173040245, "biggest_recent_change": 0.05780609574033235},
{"total_number_of_episodes": 24310, "number_of_timesteps": 4741936, "per_episode_reward": -71.43, "episode_reward_trend_value": 0.0035238415530081902, "biggest_recent_change": 0.05780609574033235},
{"total_number_of_episodes": 24320, "number_of_timesteps": 4744910, "per_episode_reward": -71.38, "episode_reward_trend_value": 0.0034866307991653876, "biggest_recent_change": 0.054457127894480095},
{"total_number_of_episodes": 24330, "number_of_timesteps": 4749088, "per_episode_reward": -71.34, "episode_reward_trend_value": 0.003385308314503277, "biggest_recent_change": 0.054457127894480095},
{"total_number_of_episodes": 24340, "number_of_timesteps": 4751824, "per_episode_reward": -71.3, "episode_reward_trend_value": 0.003185286056225323, "biggest_recent_change": 0.054457127894480095},
{"total_number_of_episodes": 24350, "number_of_timesteps": 4755296, "per_episode_reward": -71.27, "episode_reward_trend_value": 0.0033306520786742532, "biggest_recent_change": 0.054457127894480095},
{"total_number_of_episodes": 24361, "number_of_timesteps": 4759417, "per_episode_reward": -71.25, "episode_reward_trend_value": 0.0033066479577567205, "biggest_recent_change": 0.054457127894480095},
{"total_number_of_episodes": 24371, "number_of_timesteps": 4762857, "per_episode_reward": -71.23, "episode_reward_trend_value": 0.0033405821242046352, "biggest_recent_change": 0.054457127894480095},
{"total_number_of_episodes": 24381, "number_of_timesteps": 4766493, "per_episode_reward": -71.2, "episode_reward_trend_value": 0.0033461637357131875, "biggest_recent_change": 0.054457127894480095},
{"total_number_of_episodes": 24391, "number_of_timesteps": 4769098, "per_episode_reward": -71.14, "episode_reward_trend_value": 0.003609509886100347, "biggest_recent_change": 0.05740334123524349},
{"total_number_of_episodes": 24401, "number_of_timesteps": 4773152, "per_episode_reward": -71.05, "episode_reward_trend_value": 0.004258013399085314, "biggest_recent_change": 0.0955878082554733},
{"total_number_of_episodes": 24411, "number_of_timesteps": 4775785, "per_episode_reward": -71.01, "episode_reward_trend_value": 0.004054494609841521, "biggest_recent_change": 0.0955878082554733},
{"total_number_of_episodes": 24421, "number_of_timesteps": 4779822, "per_episode_reward": -71.0, "episode_reward_trend_value": 0.003738482160748112, "biggest_recent_change": 0.0955878082554733},
{"total_number_of_episodes": 24431, "number_of_timesteps": 4783153, "per_episode_reward": -70.99, "episode_reward_trend_value": 0.0034335686872397435, "biggest_recent_change": 0.0955878082554733},
{"total_number_of_episodes": 24441, "number_of_timesteps": 4786315, "per_episode_reward": -70.96, "episode_reward_trend_value": 0.0033452248701054703, "biggest_recent_change": 0.0955878082554733},
{"total_number_of_episodes": 24451, "number_of_timesteps": 4788982, "per_episode_reward": -70.84, "episode_reward_trend_value": 0.004532594770484069, "biggest_recent_change": 0.12232806916225059},
{"total_number_of_episodes": 24461, "number_of_timesteps": 4792195, "per_episode_reward": -70.82, "episode_reward_trend_value": 0.0044451038520484255, "biggest_recent_change": 0.12232806916225059},
{"total_number_of_episodes": 24471, "number_of_timesteps": 4796084, "per_episode_reward": -70.81, "episode_reward_trend_value": 0.004304618977515733, "biggest_recent_change": 0.12232806916225059},
{"total_number_of_episodes": 24481, "number_of_timesteps": 4798632, "per_episode_reward": -70.79, "episode_reward_trend_value": 0.0039060846613736544, "biggest_recent_change": 0.12232806916225059},
{"total_number_of_episodes": 24491, "number_of_timesteps": 4802181, "per_episode_reward": -70.78, "episode_reward_trend_value": 0.002957116781736128, "biggest_recent_change": 0.12232806916225059},
{"total_number_of_episodes": 24501, "number_of_timesteps": 4805282, "per_episode_reward": -70.74, "episode_reward_trend_value": 0.0030052705259909847, "biggest_recent_change": 0.12232806916225059},
{"total_number_of_episodes": 24511, "number_of_timesteps": 4810497, "per_episode_reward": -70.69, "episode_reward_trend_value": 0.0034491171642173414, "biggest_recent_change": 0.12232806916225059},
{"total_number_of_episodes": 24521, "number_of_timesteps": 4813692, "per_episode_reward": -70.64, "episode_reward_trend_value": 0.003847789859406861, "biggest_recent_change": 0.12232806916225059},
{"total_number_of_episodes": 24531, "number_of_timesteps": 4817241, "per_episode_reward": -70.59, "episode_reward_trend_value": 0.0041137122178172255, "biggest_recent_change": 0.12232806916225059},
{"total_number_of_episodes": 24541, "number_of_timesteps": 4821932, "per_episode_reward": -70.56, "episode_reward_trend_value": 0.003088892357139312, "biggest_recent_change": 0.052615027074779164},
{"total_number_of_episodes": 24551, "number_of_timesteps": 4826049, "per_episode_reward": -70.55, "episode_reward_trend_value": 0.0030552644567189684, "biggest_recent_change": 0.052615027074779164},
{"total_number_of_episodes": 24561, "number_of_timesteps": 4829137, "per_episode_reward": -70.51, "episode_reward_trend_value": 0.0033304956586453238, "biggest_recent_change": 0.052615027074779164},
{"total_number_of_episodes": 24571, "number_of_timesteps": 4833606, "per_episode_reward": -70.45, "episode_reward_trend_value": 0.00383110934761043, "biggest_recent_change": 0.06659048478931595},
{"total_number_of_episodes": 24581, "number_of_timesteps": 4835596, "per_episode_reward": -70.3, "episode_reward_trend_value": 0.005331725479125913, "biggest_recent_change": 0.1452361509244895},
{"total_number_of_episodes": 24591, "number_of_timesteps": 4837430, "per_episode_reward": -70.27, "episode_reward_trend_value": 0.005188483737790742, "biggest_recent_change": 0.1452361509244895},
{"total_number_of_episodes": 24601, "number_of_timesteps": 4839834, "per_episode_reward": -70.25, "episode_reward_trend_value": 0.004925316486967941, "biggest_recent_change": 0.1452361509244895},
{"total_number_of_episodes": 24612, "number_of_timesteps": 4842554, "per_episode_reward": -70.23, "episode_reward_trend_value": 0.0046544879513701985, "biggest_recent_change": 0.1452361509244895},
{"total_number_of_episodes": 24622, "number_of_timesteps": 4845792, "per_episode_reward": -70.21, "episode_reward_trend_value": 0.004292834818449541, "biggest_recent_change": 0.1452361509244895},
{"total_number_of_episodes": 24632, "number_of_timesteps": 4848543, "per_episode_reward": -70.16, "episode_reward_trend_value": 0.004502576230657161, "biggest_recent_change": 0.1452361509244895},
{"total_number_of_episodes": 24642, "number_of_timesteps": 4851693, "per_episode_reward": -70.11, "episode_reward_trend_value": 0.004875331751591716, "biggest_recent_change": 0.1452361509244895},
{"total_number_of_episodes": 24652, "number_of_timesteps": 4855660, "per_episode_reward": -70.1, "episode_reward_trend_value": 0.004648020854682184, "biggest_recent_change": 0.1452361509244895},
{"total_number_of_episodes": 24662, "number_of_timesteps": 4859309, "per_episode_reward": -70.08, "episode_reward_trend_value": 0.004119288764447839, "biggest_recent_change": 0.1452361509244895},
{"total_number_of_episodes": 24672, "number_of_timesteps": 4863450, "per_episode_reward": -70.06, "episode_reward_trend_value": 0.002628751850881075, "biggest_recent_change": 0.04897100879992422},
{"total_number_of_episodes": 24682, "number_of_timesteps": 4867150, "per_episode_reward": -70.05, "episode_reward_trend_value": 0.0024621945528319126, "biggest_recent_change": 0.04897100879992422},
{"total_number_of_episodes": 24692, "number_of_timesteps": 4871267, "per_episode_reward": -70.03, "episode_reward_trend_value": 0.002368003448481204, "biggest_recent_change": 0.04897100879992422},
{"total_number_of_episodes": 24702, "number_of_timesteps": 4875135, "per_episode_reward": -70.01, "episode_reward_trend_value": 0.0024445071215440507, "biggest_recent_change": 0.04897100879992422},
{"total_number_of_episodes": 24712, "number_of_timesteps": 4878917, "per_episode_reward": -69.88, "episode_reward_trend_value": 0.0036024187802411235, "biggest_recent_change": 0.12127166749468188},
{"total_number_of_episodes": 24722, "number_of_timesteps": 4884034, "per_episode_reward": -69.85, "episode_reward_trend_value": 0.003416163800279529, "biggest_recent_change": 0.12127166749468188},
{"total_number_of_episodes": 24732, "number_of_timesteps": 4888578, "per_episode_reward": -69.81, "episode_reward_trend_value": 0.003350915033048965, "biggest_recent_change": 0.12127166749468188},
{"total_number_of_episodes": 24742, "number_of_timesteps": 4892210, "per_episode_reward": -69.78, "episode_reward_trend_value": 0.003460232518250292, "biggest_recent_change": 0.12127166749468188},
{"total_number_of_episodes": 24752, "number_of_timesteps": 4894753, "per_episode_reward": -69.77, "episode_reward_trend_value": 0.003414664875726695, "biggest_recent_change": 0.12127166749468188},
{"total_number_of_episodes": 24762, "number_of_timesteps": 4899394, "per_episode_reward": -69.76, "episode_reward_trend_value": 0.003381282305397962, "biggest_recent_change": 0.12127166749468188},
{"total_number_of_episodes": 24772, "number_of_timesteps": 4904158, "per_episode_reward": -69.73, "episode_reward_trend_value": 0.0035994719781716833, "biggest_recent_change": 0.12127166749468188},
{"total_number_of_episodes": 24782, "number_of_timesteps": 4907778, "per_episode_reward": -69.69, "episode_reward_trend_value": 0.0038246716527478635, "biggest_recent_change": 0.12127166749468188},

{"total_number_of_episodes": 24792, "number_of_timesteps": 4912348, "per_episode_reward": -69.63, "episode_reward_trend_value": 0.004161786046149669, "biggest_recent_change": 0.12127166749468188},
{"total_number_of_episodes": 24802, "number_of_timesteps": 4918186, "per_episode_reward": -69.6, "episode_reward_trend_value": 0.0031865251973133327, "biggest_recent_change": 0.0568590958859545},
{"total_number_of_episodes": 24813, "number_of_timesteps": 4923120, "per_episode_reward": -69.57, "episode_reward_trend_value": 0.0030779271979506956, "biggest_recent_change": 0.0568590958859545},
{"total_number_of_episodes": 24823, "number_of_timesteps": 4926381, "per_episode_reward": -69.56, "episode_reward_trend_value": 0.0027965628553537334, "biggest_recent_change": 0.0568590958859545},
{"total_number_of_episodes": 24833, "number_of_timesteps": 4929810, "per_episode_reward": -69.51, "episode_reward_trend_value": 0.003024843399029622, "biggest_recent_change": 0.0568590958859545},
{"total_number_of_episodes": 24843, "number_of_timesteps": 4932949, "per_episode_reward": -69.5, "episode_reward_trend_value": 0.003024709402786938, "biggest_recent_change": 0.0568590958859545},
{"total_number_of_episodes": 24853, "number_of_timesteps": 4938679, "per_episode_reward": -69.47, "episode_reward_trend_value": 0.003280336084210313, "biggest_recent_change": 0.0568590958859545},
{"total_number_of_episodes": 24864, "number_of_timesteps": 4943312, "per_episode_reward": -69.42, "episode_reward_trend_value": 0.003437955415036084, "biggest_recent_change": 0.0568590958859545},

{"total_number_of_episodes": 24874, "number_of_timesteps": 4945975, "per_episode_reward": -69.39, "episode_reward_trend_value": 0.0032604044072273713, "biggest_recent_change": 0.0568590958859545},
{"total_number_of_episodes": 24884, "number_of_timesteps": 4949128, "per_episode_reward": -69.36, "episode_reward_trend_value": 0.0029555077966504782, "biggest_recent_change": 0.04657762795392273},
{"total_number_of_episodes": 24894, "number_of_timesteps": 4952624, "per_episode_reward": -69.33, "episode_reward_trend_value": 0.0029158605791606207, "biggest_recent_change": 0.04657762795392273},
{"total_number_of_episodes": 24904, "number_of_timesteps": 4957722, "per_episode_reward": -69.32, "episode_reward_trend_value": 0.0028741887845814378, "biggest_recent_change": 0.04657762795392273},
{"total_number_of_episodes": 24914, "number_of_timesteps": 4961390, "per_episode_reward": -69.31, "episode_reward_trend_value": 0.002735392654299397, "biggest_recent_change": 0.04657762795392273},
{"total_number_of_episodes": 24924, "number_of_timesteps": 4964606, "per_episode_reward": -69.3, "episode_reward_trend_value": 0.002377410451622255, "biggest_recent_change": 0.04641517062484013},
{"total_number_of_episodes": 24934, "number_of_timesteps": 4969484, "per_episode_reward": -69.27, "episode_reward_trend_value": 0.002553380564168764, "biggest_recent_change": 0.04641517062484013},
{"total_number_of_episodes": 24944, "number_of_timesteps": 4973334, "per_episode_reward": -69.24, "episode_reward_trend_value": 0.0024828086824483205, "biggest_recent_change": 0.04641517062484013},
{"total_number_of_episodes": 24955, "number_of_timesteps": 4979067, "per_episode_reward": -69.19, "episode_reward_trend_value": 0.0025918746856251887, "biggest_recent_change": 0.056231110910758275},
{"total_number_of_episodes": 24965, "number_of_timesteps": 4983366, "per_episode_reward": -69.16, "episode_reward_trend_value": 0.0026165299155606033, "biggest_recent_change": 0.056231110910758275},
{"total_number_of_episodes": 24975, "number_of_timesteps": 4986427, "per_episode_reward": -69.14, "episode_reward_trend_value": 0.002536492615481715, "biggest_recent_change": 0.056231110910758275},
{"total_number_of_episodes": 24986, "number_of_timesteps": 4990006, "per_episode_reward": -69.11, "episode_reward_trend_value": 0.0024625836352842926, "biggest_recent_change": 0.056231110910758275},
{"total_number_of_episodes": 24996, "number_of_timesteps": 4993558, "per_episode_reward": -69.1, "episode_reward_trend_value": 0.0024301512408619096, "biggest_recent_change": 0.056231110910758275},
{"total_number_of_episodes": 25006, "number_of_timesteps": 4996923, "per_episode_reward": -69.08, "episode_reward_trend_value": 0.0025775902441259923, "biggest_recent_change": 0.056231110910758275},
{"total_number_of_episodes": 25016, "number_of_timesteps": 4999181, "per_episode_reward": -69.06, "episode_reward_trend_value": 0.0026513523203391285, "biggest_recent_change": 0.056231110910758275},
{"total_number_of_episodes": 25026, "number_of_timesteps": 5002066, "per_episode_reward": -69.03, "episode_reward_trend_value": 0.0026260891227527358, "biggest_recent_change": 0.056231110910758275},
{"total_number_of_episodes": 25036, "number_of_timesteps": 5004697, "per_episode_reward": -69.0, "episode_reward_trend_value": 0.002682153328494034, "biggest_recent_change": 0.056231110910758275},
{"total_number_of_episodes": 25046, "number_of_timesteps": 5009309, "per_episode_reward": -68.96, "episode_reward_trend_value": 0.0025218250845093675, "biggest_recent_change": 0.04180156895213827},
{"total_number_of_episodes": 25056, "number_of_timesteps": 5015975, "per_episode_reward": -68.93, "episode_reward_trend_value": 0.002547724410758671, "biggest_recent_change": 0.04180156895213827},
{"total_number_of_episodes": 25066, "number_of_timesteps": 5019351, "per_episode_reward": -68.88, "episode_reward_trend_value": 0.0028106663244047226, "biggest_recent_change": 0.045879816155078856},
{"total_number_of_episodes": 25076, "number_of_timesteps": 5023461, "per_episode_reward": -68.84, "episode_reward_trend_value": 0.0030577458165366367, "biggest_recent_change": 0.045879816155078856},
{"total_number_of_episodes": 25087, "number_of_timesteps": 5028422, "per_episode_reward": -68.82, "episode_reward_trend_value": 0.003069963209573719, "biggest_recent_change": 0.045879816155078856},
{"total_number_of_episodes": 25097, "number_of_timesteps": 5032535, "per_episode_reward": -68.75, "episode_reward_trend_value": 0.0036763334164198287, "biggest_recent_change": 0.07228084461063133},
{"total_number_of_episodes": 25107, "number_of_timesteps": 5036688, "per_episode_reward": -68.7, "episode_reward_trend_value": 0.004003282502062354, "biggest_recent_change": 0.07228084461063133},
{"total_number_of_episodes": 25117, "number_of_timesteps": 5039491, "per_episode_reward": -68.65, "episode_reward_trend_value": 0.004268289082863438, "biggest_recent_change": 0.07228084461063133},
{"total_number_of_episodes": 25127, "number_of_timesteps": 5042121, "per_episode_reward": -68.57, "episode_reward_trend_value": 0.004783425816015097, "biggest_recent_change": 0.07614641384752474},
{"total_number_of_episodes": 25137, "number_of_timesteps": 5045244, "per_episode_reward": -68.54, "episode_reward_trend_value": 0.004600137539454529, "biggest_recent_change": 0.07614641384752474},
{"total_number_of_episodes": 25147, "number_of_timesteps": 5048706, "per_episode_reward": -68.52, "episode_reward_trend_value": 0.0045815547492231365, "biggest_recent_change": 0.07614641384752474},
{"total_number_of_episodes": 25157, "number_of_timesteps": 5053107, "per_episode_reward": -68.49, "episode_reward_trend_value": 0.004401120696864621, "biggest_recent_change": 0.07614641384752474},
{"total_number_of_episodes": 25167, "number_of_timesteps": 5056924, "per_episode_reward": -68.46, "episode_reward_trend_value": 0.004202947252938808, "biggest_recent_change": 0.07614641384752474},
{"total_number_of_episodes": 25177, "number_of_timesteps": 5060934, "per_episode_reward": -68.42, "episode_reward_trend_value": 0.0044862768185502154, "biggest_recent_change": 0.07614641384752474},
{"total_number_of_episodes": 25188, "number_of_timesteps": 5066066, "per_episode_reward": -68.39, "episode_reward_trend_value": 0.003979856783326833, "biggest_recent_change": 0.07614641384752474},

{"total_number_of_episodes": 25198, "number_of_timesteps": 5071834, "per_episode_reward": -68.35, "episode_reward_trend_value": 0.0038455967728991264, "biggest_recent_change": 0.07614641384752474},
{"total_number_of_episodes": 25208, "number_of_timesteps": 5076630, "per_episode_reward": -68.33, "episode_reward_trend_value": 0.003532718541486367, "biggest_recent_change": 0.07614641384752474},
{"total_number_of_episodes": 25219, "number_of_timesteps": 5081759, "per_episode_reward": -68.31, "episode_reward_trend_value": 0.0028770526693586854, "biggest_recent_change": 0.042364089928966564},
{"total_number_of_episodes": 25229, "number_of_timesteps": 5086825, "per_episode_reward": -68.2, "episode_reward_trend_value": 0.0038675574033002627, "biggest_recent_change": 0.11445105011642909},
{"total_number_of_episodes": 25239, "number_of_timesteps": 5091856, "per_episode_reward": -68.16, "episode_reward_trend_value": 0.004000469087936488, "biggest_recent_change": 0.11445105011642909},
{"total_number_of_episodes": 25249, "number_of_timesteps": 5096316, "per_episode_reward": -68.12, "episode_reward_trend_value": 0.004069490346572972, "biggest_recent_change": 0.11445105011642909},
{"total_number_of_episodes": 25259, "number_of_timesteps": 5099146, "per_episode_reward": -68.1, "episode_reward_trend_value": 0.0040239626632280565, "biggest_recent_change": 0.11445105011642909},
{"total_number_of_episodes": 25269, "number_of_timesteps": 5102854, "per_episode_reward": -68.07, "episode_reward_trend_value": 0.0038103301263720684, "biggest_recent_change": 0.11445105011642909},
{"total_number_of_episodes": 25279, "number_of_timesteps": 5106742, "per_episode_reward": -68.06, "episode_reward_trend_value": 0.0036699783688555324, "biggest_recent_change": 0.11445105011642909},
{"total_number_of_episodes": 25289, "number_of_timesteps": 5110365, "per_episode_reward": -68.04, "episode_reward_trend_value": 0.0034220031892017583, "biggest_recent_change": 0.11445105011642909},
{"total_number_of_episodes": 25299, "number_of_timesteps": 5114645, "per_episode_reward": -68.04, "episode_reward_trend_value": 0.003168275188592576, "biggest_recent_change": 0.11445105011642909},
{"total_number_of_episodes": 25309, "number_of_timesteps": 5118650, "per_episode_reward": -68.01, "episode_reward_trend_value": 0.0033044009667792, "biggest_recent_change": 0.11445105011642909},
{"total_number_of_episodes": 25319, "number_of_timesteps": 5124528, "per_episode_reward": -67.97, "episode_reward_trend_value": 0.0025019690789671737, "biggest_recent_change": 0.04223218021334674},
{"total_number_of_episodes": 25329, "number_of_timesteps": 5130877, "per_episode_reward": -67.94, "episode_reward_trend_value": 0.00246173244244861, "biggest_recent_change": 0.04223218021334674},
{"total_number_of_episodes": 25339, "number_of_timesteps": 5133606, "per_episode_reward": -67.92, "episode_reward_trend_value": 0.0022805694372342107, "biggest_recent_change": 0.04223218021334674},
{"total_number_of_episodes": 25349, "number_of_timesteps": 5137333, "per_episode_reward": -67.9, "episode_reward_trend_value": 0.0022381962872651054, "biggest_recent_change": 0.04223218021334674},
{"total_number_of_episodes": 25359, "number_of_timesteps": 5140579, "per_episode_reward": -67.78, "episode_reward_trend_value": 0.0032653926786101314, "biggest_recent_change": 0.11558483683297993},
{"total_number_of_episodes": 25369, "number_of_timesteps": 5143039, "per_episode_reward": -67.71, "episode_reward_trend_value": 0.003882285252365452, "biggest_recent_change": 0.11558483683297993},
{"total_number_of_episodes": 25379, "number_of_timesteps": 5146162, "per_episode_reward": -67.7, "episode_reward_trend_value": 0.003875494940924461, "biggest_recent_change": 0.11558483683297993},
{"total_number_of_episodes": 25389, "number_of_timesteps": 5149382, "per_episode_reward": -67.61, "episode_reward_trend_value": 0.004867228555404621, "biggest_recent_change": 0.11558483683297993},
{"total_number_of_episodes": 25399, "number_of_timesteps": 5151894, "per_episode_reward": -67.58, "episode_reward_trend_value": 0.004831015671687706, "biggest_recent_change": 0.11558483683297993},
{"total_number_of_episodes": 25409, "number_of_timesteps": 5155232, "per_episode_reward": -67.54, "episode_reward_trend_value": 0.004773061492436486, "biggest_recent_change": 0.11558483683297993},
{"total_number_of_episodes": 25419, "number_of_timesteps": 5159396, "per_episode_reward": -67.53, "episode_reward_trend_value": 0.00455847557577537, "biggest_recent_change": 0.11558483683297993},
{"total_number_of_episodes": 25429, "number_of_timesteps": 5163035, "per_episode_reward": -67.5, "episode_reward_trend_value": 0.00464546915217991, "biggest_recent_change": 0.11558483683297993},
{"total_number_of_episodes": 25439, "number_of_timesteps": 5165986, "per_episode_reward": -67.45, "episode_reward_trend_value": 0.0049145526830227165, "biggest_recent_change": 0.11558483683297993},
{"total_number_of_episodes": 25449, "number_of_timesteps": 5169234, "per_episode_reward": -67.4, "episode_reward_trend_value": 0.004203515957661984, "biggest_recent_change": 0.09056712821900703},
{"total_number_of_episodes": 25459, "number_of_timesteps": 5174414, "per_episode_reward": -67.41, "episode_reward_trend_value": 0.003359898265868663, "biggest_recent_change": 0.09056712821900703},
{"total_number_of_episodes": 25469, "number_of_timesteps": 5180219, "per_episode_reward": -67.37, "episode_reward_trend_value": 0.0035662160239029266, "biggest_recent_change": 0.09056712821900703},
{"total_number_of_episodes": 25479, "number_of_timesteps": 5183243, "per_episode_reward": -67.26, "episode_reward_trend_value": 0.0037924936497056986, "biggest_recent_change": 0.11093211454125651},
{"total_number_of_episodes": 25489, "number_of_timesteps": 5187999, "per_episode_reward": -67.19, "episode_reward_trend_value": 0.004271051053423017, "biggest_recent_change": 0.11093211454125651},
{"total_number_of_episodes": 25499, "number_of_timesteps": 5192477, "per_episode_reward": -67.18, "episode_reward_trend_value": 0.0040653443615257055, "biggest_recent_change": 0.11093211454125651},
{"total_number_of_episodes": 25509, "number_of_timesteps": 5195272, "per_episode_reward": -67.14, "episode_reward_trend_value": 0.004278765612346388, "biggest_recent_change": 0.11093211454125651},
{"total_number_of_episodes": 25519, "number_of_timesteps": 5198296, "per_episode_reward": -67.11, "episode_reward_trend_value": 0.0043122921232274, "biggest_recent_change": 0.11093211454125651},
{"total_number_of_episodes": 25530, "number_of_timesteps": 5201932, "per_episode_reward": -67.09, "episode_reward_trend_value": 0.004071744477457805, "biggest_recent_change": 0.11093211454125651},
{"total_number_of_episodes": 25540, "number_of_timesteps": 5204228, "per_episode_reward": -67.05, "episode_reward_trend_value": 0.003922300675388297, "biggest_recent_change": 0.11093211454125651},
{"total_number_of_episodes": 25550, "number_of_timesteps": 5207522, "per_episode_reward": -67.03, "episode_reward_trend_value": 0.004207660401264787, "biggest_recent_change": 0.11093211454125651},
{"total_number_of_episodes": 25560, "number_of_timesteps": 5211142, "per_episode_reward": -67.01, "episode_reward_trend_value": 0.004105476220304796, "biggest_recent_change": 0.11093211454125651},
{"total_number_of_episodes": 25570, "number_of_timesteps": 5214478, "per_episode_reward": -66.95, "episode_reward_trend_value": 0.003538960834917601, "biggest_recent_change": 0.06919881219286594},
{"total_number_of_episodes": 25580, "number_of_timesteps": 5217539, "per_episode_reward": -66.93, "episode_reward_trend_value": 0.00293566284490178, "biggest_recent_change": 0.059945729856409},
{"total_number_of_episodes": 25590, "number_of_timesteps": 5221073, "per_episode_reward": -66.87, "episode_reward_trend_value": 0.003387639325329101, "biggest_recent_change": 0.059945729856409},
{"total_number_of_episodes": 25600, "number_of_timesteps": 5225190, "per_episode_reward": -66.82, "episode_reward_trend_value": 0.0035830181851434556, "biggest_recent_change": 0.059945729856409},
{"total_number_of_episodes": 25610, "number_of_timesteps": 5230140, "per_episode_reward": -66.76, "episode_reward_trend_value": 0.003937649367488581, "biggest_recent_change": 0.06231160851756101},
{"total_number_of_episodes": 25620, "number_of_timesteps": 5234647, "per_episode_reward": -66.7, "episode_reward_trend_value": 0.004285355904283487, "biggest_recent_change": 0.06231160851756101},
{"total_number_of_episodes": 25630, "number_of_timesteps": 5237394, "per_episode_reward": -66.61, "episode_reward_trend_value": 0.004868046270596457, "biggest_recent_change": 0.09058372233242551},
{"total_number_of_episodes": 25640, "number_of_timesteps": 5240574, "per_episode_reward": -66.5, "episode_reward_trend_value": 0.005938308931118917, "biggest_recent_change": 0.11567213741652438},
{"total_number_of_episodes": 25650, "number_of_timesteps": 5243490, "per_episode_reward": -66.47, "episode_reward_trend_value": 0.005938055244791782, "biggest_recent_change": 0.11567213741652438},
{"total_number_of_episodes": 25661, "number_of_timesteps": 5247159, "per_episode_reward": -66.44, "episode_reward_trend_value": 0.0056508744741495635, "biggest_recent_change": 0.11567213741652438},
{"total_number_of_episodes": 25672, "number_of_timesteps": 5251233, "per_episode_reward": -66.43, "episode_reward_trend_value": 0.005581133108197081, "biggest_recent_change": 0.11567213741652438},
{"total_number_of_episodes": 25682, "number_of_timesteps": 5254673, "per_episode_reward": -66.37, "episode_reward_trend_value": 0.005594046654998092, "biggest_recent_change": 0.11567213741652438},
{"total_number_of_episodes": 25692, "number_of_timesteps": 5257081, "per_episode_reward": -66.34, "episode_reward_trend_value": 0.005272287292227576, "biggest_recent_change": 0.11567213741652438},
{"total_number_of_episodes": 25702, "number_of_timesteps": 5259510, "per_episode_reward": -66.3, "episode_reward_trend_value": 0.005106382107581453, "biggest_recent_change": 0.11567213741652438},
{"total_number_of_episodes": 25712, "number_of_timesteps": 5262375, "per_episode_reward": -66.26, "episode_reward_trend_value": 0.004939913244005664, "biggest_recent_change": 0.11567213741652438},
{"total_number_of_episodes": 25722, "number_of_timesteps": 5264793, "per_episode_reward": -66.23, "episode_reward_trend_value": 0.004226033639743952, "biggest_recent_change": 0.11567213741652438},
{"total_number_of_episodes": 25732, "number_of_timesteps": 5266907, "per_episode_reward": -66.22, "episode_reward_trend_value": 0.003056947422133918, "biggest_recent_change": 0.06034280426052874},
{"total_number_of_episodes": 25742, "number_of_timesteps": 5269360, "per_episode_reward": -66.19, "episode_reward_trend_value": 0.0031106376659309374, "biggest_recent_change": 0.06034280426052874},
{"total_number_of_episodes": 25752, "number_of_timesteps": 5272003, "per_episode_reward": -66.17, "episode_reward_trend_value": 0.0029310165349119505, "biggest_recent_change": 0.06034280426052874},
{"total_number_of_episodes": 25762, "number_of_timesteps": 5275341, "per_episode_reward": -66.07, "episode_reward_trend_value": 0.003950054803539792, "biggest_recent_change": 0.1003387143322243},
{"total_number_of_episodes": 25772, "number_of_timesteps": 5277808, "per_episode_reward": -66.05, "episode_reward_trend_value": 0.003543056802021264, "biggest_recent_change": 0.1003387143322243},
{"total_number_of_episodes": 25782, "number_of_timesteps": 5280665, "per_episode_reward": -66.03, "episode_reward_trend_value": 0.0034591832738327193, "biggest_recent_change": 0.1003387143322243},
{"total_number_of_episodes": 25792, "number_of_timesteps": 5284314, "per_episode_reward": -66.03, "episode_reward_trend_value": 0.0029573800636095863, "biggest_recent_change": 0.1003387143322243},
{"total_number_of_episodes": 25802, "number_of_timesteps": 5286267, "per_episode_reward": -66.01, "episode_reward_trend_value": 0.0027879054921972585, "biggest_recent_change": 0.1003387143322243},
{"total_number_of_episodes": 25812, "number_of_timesteps": 5288737, "per_episode_reward": -65.9, "episode_reward_trend_value": 0.0036823307259264007, "biggest_recent_change": 0.1068328289844942},
{"total_number_of_episodes": 25822, "number_of_timesteps": 5291319, "per_episode_reward": -65.84, "episode_reward_trend_value": 0.004211604561507443, "biggest_recent_change": 0.1068328289844942},
{"total_number_of_episodes": 25832, "number_of_timesteps": 5294613, "per_episode_reward": -65.8, "episode_reward_trend_value": 0.004366103694007803, "biggest_recent_change": 0.1068328289844942},
{"total_number_of_episodes": 25842, "number_of_timesteps": 5297089, "per_episode_reward": -65.76, "episode_reward_trend_value": 0.004599297742107132, "biggest_recent_change": 0.1068328289844942},
{"total_number_of_episodes": 25852, "number_of_timesteps": 5301234, "per_episode_reward": -65.73, "episode_reward_trend_value": 0.0037982350765329584, "biggest_recent_change": 0.1068328289844942},
{"total_number_of_episodes": 25862, "number_of_timesteps": 5303693, "per_episode_reward": -65.7, "episode_reward_trend_value": 0.0038558230395370034, "biggest_recent_change": 0.1068328289844942},
{"total_number_of_episodes": 25872, "number_of_timesteps": 5306268, "per_episode_reward": -65.68, "episode_reward_trend_value": 0.00395891878623268, "biggest_recent_change": 0.1068328289844942},
{"total_number_of_episodes": 25882, "number_of_timesteps": 5309147, "per_episode_reward": -65.53, "episode_reward_trend_value": 0.005504786652318848, "biggest_recent_change": 0.14134596092708307},
{"total_number_of_episodes": 25892, "number_of_timesteps": 5313926, "per_episode_reward": -65.51, "episode_reward_trend_value": 0.00546558397633245, "biggest_recent_change": 0.14134596092708307},
{"total_number_of_episodes": 25902, "number_of_timesteps": 5318914, "per_episode_reward": -65.49, "episode_reward_trend_value": 0.00457073919685374, "biggest_recent_change": 0.14134596092708307},
{"total_number_of_episodes": 25912, "number_of_timesteps": 5322499, "per_episode_reward": -65.43, "episode_reward_trend_value": 0.004544419299485803, "biggest_recent_change": 0.14134596092708307},

{"total_number_of_episodes": 25922, "number_of_timesteps": 5327463, "per_episode_reward": -65.38, "episode_reward_trend_value": 0.004695259821351448, "biggest_recent_change": 0.14134596092708307},
{"total_number_of_episodes": 25932, "number_of_timesteps": 5331976, "per_episode_reward": -65.36, "episode_reward_trend_value": 0.004474621411771156, "biggest_recent_change": 0.14134596092708307},
{"total_number_of_episodes": 25942, "number_of_timesteps": 5337216, "per_episode_reward": -65.32, "episode_reward_trend_value": 0.004535583809203716, "biggest_recent_change": 0.14134596092708307},
{"total_number_of_episodes": 25952, "number_of_timesteps": 5339878, "per_episode_reward": -65.28, "episode_reward_trend_value": 0.004719372705566608, "biggest_recent_change": 0.14134596092708307},
{"total_number_of_episodes": 25962, "number_of_timesteps": 5343699, "per_episode_reward": -65.25, "episode_reward_trend_value": 0.004752116725544574, "biggest_recent_change": 0.14134596092708307},
{"total_number_of_episodes": 25972, "number_of_timesteps": 5346542, "per_episode_reward": -65.21, "episode_reward_trend_value": 0.003573339098315071, "biggest_recent_change": 0.057072820144881575},
{"total_number_of_episodes": 25982, "number_of_timesteps": 5349053, "per_episode_reward": -65.16, "episode_reward_trend_value": 0.0038853505571980113, "biggest_recent_change": 0.057072820144881575},
{"total_number_of_episodes": 25992, "number_of_timesteps": 5351016, "per_episode_reward": -65.14, "episode_reward_trend_value": 0.0038933052195973678, "biggest_recent_change": 0.057072820144881575},
{"total_number_of_episodes": 26002, "number_of_timesteps": 5354748, "per_episode_reward": -65.11, "episode_reward_trend_value": 0.003536244262331599, "biggest_recent_change": 0.057072820144881575},
{"total_number_of_episodes": 26012, "number_of_timesteps": 5357259, "per_episode_reward": -65.09, "episode_reward_trend_value": 0.0031644321839342147, "biggest_recent_change": 0.04794830192773247},
{"total_number_of_episodes": 26022, "number_of_timesteps": 5360151, "per_episode_reward": -65.06, "episode_reward_trend_value": 0.003344972570516328, "biggest_recent_change": 0.04794830192773247},
{"total_number_of_episodes": 26032, "number_of_timesteps": 5363783, "per_episode_reward": -65.03, "episode_reward_trend_value": 0.0032633575451950178, "biggest_recent_change": 0.04794830192773247},
{"total_number_of_episodes": 26042, "number_of_timesteps": 5366570, "per_episode_reward": -65.0, "episode_reward_trend_value": 0.0030707919016881155, "biggest_recent_change": 0.04794830192773247},
{"total_number_of_episodes": 26052, "number_of_timesteps": 5368697, "per_episode_reward": -64.97, "episode_reward_trend_value": 0.003121581626772417, "biggest_recent_change": 0.04794830192773247},
{"total_number_of_episodes": 26063, "number_of_timesteps": 5371525, "per_episode_reward": -64.93, "episode_reward_trend_value": 0.003183045717593953, "biggest_recent_change": 0.04794830192773247},
{"total_number_of_episodes": 26073, "number_of_timesteps": 5374975, "per_episode_reward": -64.86, "episode_reward_trend_value": 0.003333272088581099, "biggest_recent_change": 0.06146867531657563},
{"total_number_of_episodes": 26083, "number_of_timesteps": 5379608, "per_episode_reward": -64.83, "episode_reward_trend_value": 0.0033795644247972072, "biggest_recent_change": 0.06146867531657563},
{"total_number_of_episodes": 26093, "number_of_timesteps": 5383250, "per_episode_reward": -64.81, "episode_reward_trend_value": 0.003407804365922434, "biggest_recent_change": 0.06146867531657563},
{"total_number_of_episodes": 26103, "number_of_timesteps": 5386303, "per_episode_reward": -64.77, "episode_reward_trend_value": 0.0035163262799149685, "biggest_recent_change": 0.06146867531657563},
{"total_number_of_episodes": 26113, "number_of_timesteps": 5391173, "per_episode_reward": -64.74, "episode_reward_trend_value": 0.0035363358784399187, "biggest_recent_change": 0.06146867531657563},
{"total_number_of_episodes": 26124, "number_of_timesteps": 5396115, "per_episode_reward": -64.68, "episode_reward_trend_value": 0.003850183000247398, "biggest_recent_change": 0.06146867531657563},
{"total_number_of_episodes": 26134, "number_of_timesteps": 5400646, "per_episode_reward": -64.65, "episode_reward_trend_value": 0.0038553997953201247, "biggest_recent_change": 0.06146867531657563},
{"total_number_of_episodes": 26144, "number_of_timesteps": 5404534, "per_episode_reward": -64.56, "episode_reward_trend_value": 0.004573329051100612, "biggest_recent_change": 0.0983419729344206},
{"total_number_of_episodes": 26154, "number_of_timesteps": 5410684, "per_episode_reward": -64.52, "episode_reward_trend_value": 0.004478756765921174, "biggest_recent_change": 0.0983419729344206},
{"total_number_of_episodes": 26164, "number_of_timesteps": 5414562, "per_episode_reward": -64.5, "episode_reward_trend_value": 0.004002967721561706, "biggest_recent_change": 0.0983419729344206},
{"total_number_of_episodes": 26174, "number_of_timesteps": 5419319, "per_episode_reward": -64.43, "episode_reward_trend_value": 0.00450897538456224, "biggest_recent_change": 0.0983419729344206},
{"total_number_of_episodes": 26184, "number_of_timesteps": 5422916, "per_episode_reward": -64.37, "episode_reward_trend_value": 0.004848209196831496, "biggest_recent_change": 0.0983419729344206},
{"total_number_of_episodes": 26194, "number_of_timesteps": 5426063, "per_episode_reward": -64.37, "episode_reward_trend_value": 0.0045124603492538995, "biggest_recent_change": 0.0983419729344206},
{"total_number_of_episodes": 26204, "number_of_timesteps": 5429365, "per_episode_reward": -64.35, "episode_reward_trend_value": 0.004249848983014696, "biggest_recent_change": 0.0983419729344206},
{"total_number_of_episodes": 26214, "number_of_timesteps": 5431897, "per_episode_reward": -64.33, "episode_reward_trend_value": 0.0038893372707391903, "biggest_recent_change": 0.0983419729344206},
{"total_number_of_episodes": 26224, "number_of_timesteps": 5435131, "per_episode_reward": -64.29, "episode_reward_trend_value": 0.00404262431545419, "biggest_recent_change": 0.0983419729344206},
{"total_number_of_episodes": 26234, "number_of_timesteps": 5439551, "per_episode_reward": -64.25, "episode_reward_trend_value": 0.003407030810968889, "biggest_recent_change": 0.07671971837685021},
{"total_number_of_episodes": 26244, "number_of_timesteps": 5442522, "per_episode_reward": -64.17, "episode_reward_trend_value": 0.003977991162166777, "biggest_recent_change": 0.08366266859202653},
{"total_number_of_episodes": 26254, "number_of_timesteps": 5446806, "per_episode_reward": -64.13, "episode_reward_trend_value": 0.004112088651335455, "biggest_recent_change": 0.08366266859202653},
{"total_number_of_episodes": 26264, "number_of_timesteps": 5450148, "per_episode_reward": -64.09, "episode_reward_trend_value": 0.0037921462506321606, "biggest_recent_change": 0.08366266859202653},
{"total_number_of_episodes": 26274, "number_of_timesteps": 5454509, "per_episode_reward": -64.03, "episode_reward_trend_value": 0.003803332515694851, "biggest_recent_change": 0.08366266859202653},
{"total_number_of_episodes": 26284, "number_of_timesteps": 5460628, "per_episode_reward": -63.98, "episode_reward_trend_value": 0.00425667198991838, "biggest_recent_change": 0.08366266859202653},
{"total_number_of_episodes": 26294, "number_of_timesteps": 5464293, "per_episode_reward": -63.96, "episode_reward_trend_value": 0.004376376618015835, "biggest_recent_change": 0.08366266859202653},
{"total_number_of_episodes": 26306, "number_of_timesteps": 5469238, "per_episode_reward": -63.88, "episode_reward_trend_value": 0.0050467003285554314, "biggest_recent_change": 0.08366266859202653},
{"total_number_of_episodes": 26316, "number_of_timesteps": 5472654, "per_episode_reward": -63.82, "episode_reward_trend_value": 0.005258299315461793, "biggest_recent_change": 0.08366266859202653},
{"total_number_of_episodes": 26326, "number_of_timesteps": 5477545, "per_episode_reward": -63.79, "episode_reward_trend_value": 0.005091146218313093, "biggest_recent_change": 0.08366266859202653},
{"total_number_of_episodes": 26336, "number_of_timesteps": 5481262, "per_episode_reward": -63.76, "episode_reward_trend_value": 0.004456329707482512, "biggest_recent_change": 0.08251365872700234},
{"total_number_of_episodes": 26346, "number_of_timesteps": 5484419, "per_episode_reward": -63.74, "episode_reward_trend_value": 0.0043744430000051205, "biggest_recent_change": 0.08251365872700234},
{"total_number_of_episodes": 26356, "number_of_timesteps": 5487434, "per_episode_reward": -63.72, "episode_reward_trend_value": 0.004099713183581915, "biggest_recent_change": 0.08251365872700234},
{"total_number_of_episodes": 26366, "number_of_timesteps": 5491550, "per_episode_reward": -63.7, "episode_reward_trend_value": 0.0035995284004077316, "biggest_recent_change": 0.08251365872700234},
{"total_number_of_episodes": 26376, "number_of_timesteps": 5495113, "per_episode_reward": -63.62, "episode_reward_trend_value": 0.004032671046272264, "biggest_recent_change": 0.08294269987438696},
{"total_number_of_episodes": 26386, "number_of_timesteps": 5499043, "per_episode_reward": -63.56, "episode_reward_trend_value": 0.004416178136135487, "biggest_recent_change": 0.08294269987438696},
{"total_number_of_episodes": 26396, "number_of_timesteps": 5502542, "per_episode_reward": -63.52, "episode_reward_trend_value": 0.003986048420267549, "biggest_recent_change": 0.08294269987438696},
{"total_number_of_episodes": 26406, "number_of_timesteps": 5506292, "per_episode_reward": -63.49, "episode_reward_trend_value": 0.0036477703659544307, "biggest_recent_change": 0.08294269987438696},
{"total_number_of_episodes": 26416, "number_of_timesteps": 5509676, "per_episode_reward": -63.48, "episode_reward_trend_value": 0.0034806344579108224, "biggest_recent_change": 0.08294269987438696},
{"total_number_of_episodes": 26427, "number_of_timesteps": 5514393, "per_episode_reward": -63.45, "episode_reward_trend_value": 0.003512234047300053, "biggest_recent_change": 0.08294269987438696},
{"total_number_of_episodes": 26437, "number_of_timesteps": 5517894, "per_episode_reward": -63.44, "episode_reward_trend_value": 0.0033193195227048653, "biggest_recent_change": 0.08294269987438696},
{"total_number_of_episodes": 26447, "number_of_timesteps": 5522638, "per_episode_reward": -63.43, "episode_reward_trend_value": 0.0031839174153137466, "biggest_recent_change": 0.08294269987438696},

{"total_number_of_episodes": 26457, "number_of_timesteps": 5527351, "per_episode_reward": -63.41, "episode_reward_trend_value": 0.0032632577431296597, "biggest_recent_change": 0.08294269987438696},
{"total_number_of_episodes": 26467, "number_of_timesteps": 5531314, "per_episode_reward": -63.39, "episode_reward_trend_value": 0.0026193490762587146, "biggest_recent_change": 0.05876709648818235},
{"total_number_of_episodes": 26477, "number_of_timesteps": 5536034, "per_episode_reward": -63.35, "episode_reward_trend_value": 0.0023223192507550216, "biggest_recent_change": 0.04380198429888793},
{"total_number_of_episodes": 26487, "number_of_timesteps": 5539140, "per_episode_reward": -63.32, "episode_reward_trend_value": 0.002160960492945918, "biggest_recent_change": 0.03203441219284997},
{"total_number_of_episodes": 26497, "number_of_timesteps": 5543511, "per_episode_reward": -63.3, "episode_reward_trend_value": 0.0021174316188956746, "biggest_recent_change": 0.03203441219284997},
{"total_number_of_episodes": 26507, "number_of_timesteps": 5546676, "per_episode_reward": -63.27, "episode_reward_trend_value": 0.0023062574114312896, "biggest_recent_change": 0.03203441219284997},
{"total_number_of_episodes": 26517, "number_of_timesteps": 5549404, "per_episode_reward": -63.23, "episode_reward_trend_value": 0.0023992452091337983, "biggest_recent_change": 0.03774204745553078},
{"total_number_of_episodes": 26527, "number_of_timesteps": 5552750, "per_episode_reward": -63.19, "episode_reward_trend_value": 0.0027572312295969285, "biggest_recent_change": 0.038203066304554056},
{"total_number_of_episodes": 26538, "number_of_timesteps": 5556705, "per_episode_reward": -63.15, "episode_reward_trend_value": 0.0031532000459691288, "biggest_recent_change": 0.04665022264376262},
{"total_number_of_episodes": 26548, "number_of_timesteps": 5559786, "per_episode_reward": -63.1, "episode_reward_trend_value": 0.0035000546087167726, "biggest_recent_change": 0.05100505744307071},
{"total_number_of_episodes": 26558, "number_of_timesteps": 5562768, "per_episode_reward": -63.07, "episode_reward_trend_value": 0.0035434521242249184, "biggest_recent_change": 0.05100505744307071},
{"total_number_of_episodes": 26568, "number_of_timesteps": 5565209, "per_episode_reward": -63.0, "episode_reward_trend_value": 0.003904876081508332, "biggest_recent_change": 0.06456256834835727},
{"total_number_of_episodes": 26579, "number_of_timesteps": 5568173, "per_episode_reward": -62.94, "episode_reward_trend_value": 0.0043120156387652115, "biggest_recent_change": 0.06592225624918768},

{"total_number_of_episodes": 26589, "number_of_timesteps": 5571220, "per_episode_reward": -62.88, "episode_reward_trend_value": 0.004601365885237937, "biggest_recent_change": 0.06592225624918768},
{"total_number_of_episodes": 26599, "number_of_timesteps": 5575564, "per_episode_reward": -62.86, "episode_reward_trend_value": 0.0045199022734394925, "biggest_recent_change": 0.06592225624918768},
{"total_number_of_episodes": 26609, "number_of_timesteps": 5578224, "per_episode_reward": -62.86, "episode_reward_trend_value": 0.00415818806796319, "biggest_recent_change": 0.06592225624918768},
{"total_number_of_episodes": 26619, "number_of_timesteps": 5581045, "per_episode_reward": -62.83, "episode_reward_trend_value": 0.0040493421396831765, "biggest_recent_change": 0.06592225624918768},
{"total_number_of_episodes": 26629, "number_of_timesteps": 5585252, "per_episode_reward": -62.81, "episode_reward_trend_value": 0.003750397899203664, "biggest_recent_change": 0.06592225624918768},
{"total_number_of_episodes": 26639, "number_of_timesteps": 5588546, "per_episode_reward": -62.78, "episode_reward_trend_value": 0.003463458472656337, "biggest_recent_change": 0.06592225624918768},
{"total_number_of_episodes": 26649, "number_of_timesteps": 5592012, "per_episode_reward": -62.75, "episode_reward_trend_value": 0.003506849422815369, "biggest_recent_change": 0.06592225624918768},
{"total_number_of_episodes": 26659, "number_of_timesteps": 5595554, "per_episode_reward": -62.71, "episode_reward_trend_value": 0.0032668644880685187, "biggest_recent_change": 0.06592225624918768},
{"total_number_of_episodes": 26669, "number_of_timesteps": 5599625, "per_episode_reward": -62.66, "episode_reward_trend_value": 0.0030456805050779363, "biggest_recent_change": 0.05309414658357525},
{"total_number_of_episodes": 26679, "number_of_timesteps": 5602467, "per_episode_reward": -62.6, "episode_reward_trend_value": 0.0031925838822384695, "biggest_recent_change": 0.06631545052802323},
{"total_number_of_episodes": 26689, "number_of_timesteps": 5605299, "per_episode_reward": -62.53, "episode_reward_trend_value": 0.0036658489759890897, "biggest_recent_change": 0.06631545052802323},
{"total_number_of_episodes": 26699, "number_of_timesteps": 5609006, "per_episode_reward": -62.46, "episode_reward_trend_value": 0.004468574823721541, "biggest_recent_change": 0.07743309525858422},
{"total_number_of_episodes": 26709, "number_of_timesteps": 5612657, "per_episode_reward": -62.43, "episode_reward_trend_value": 0.00445500131084218, "biggest_recent_change": 0.07743309525858422},
{"total_number_of_episodes": 26719, "number_of_timesteps": 5615374, "per_episode_reward": -62.39, "episode_reward_trend_value": 0.004642743184456321, "biggest_recent_change": 0.07743309525858422},
{"total_number_of_episodes": 26729, "number_of_timesteps": 5618529, "per_episode_reward": -62.36, "episode_reward_trend_value": 0.004669772047717421, "biggest_recent_change": 0.07743309525858422},
{"total_number_of_episodes": 26740, "number_of_timesteps": 5621900, "per_episode_reward": -62.34, "episode_reward_trend_value": 0.0045958442824388926, "biggest_recent_change": 0.07743309525858422},
{"total_number_of_episodes": 26750, "number_of_timesteps": 5625611, "per_episode_reward": -62.32, "episode_reward_trend_value": 0.004284040778705231, "biggest_recent_change": 0.07743309525858422},
{"total_number_of_episodes": 26760, "number_of_timesteps": 5628848, "per_episode_reward": -62.29, "episode_reward_trend_value": 0.004133196077446241, "biggest_recent_change": 0.07743309525858422},
{"total_number_of_episodes": 26770, "number_of_timesteps": 5633273, "per_episode_reward": -62.27, "episode_reward_trend_value": 0.003622425372319861, "biggest_recent_change": 0.07743309525858422},
{"total_number_of_episodes": 26780, "number_of_timesteps": 5640025, "per_episode_reward": -62.25, "episode_reward_trend_value": 0.003186398022720817, "biggest_recent_change": 0.07743309525858422},
{"total_number_of_episodes": 26790, "number_of_timesteps": 5646115, "per_episode_reward": -62.21, "episode_reward_trend_value": 0.002721477399339436, "biggest_recent_change": 0.03664200962587927},
{"total_number_of_episodes": 26800, "number_of_timesteps": 5651344, "per_episode_reward": -62.17, "episode_reward_trend_value": 0.002819382331609985, "biggest_recent_change": 0.03664200962587927},
{"total_number_of_episodes": 26810, "number_of_timesteps": 5656184, "per_episode_reward": -62.14, "episode_reward_trend_value": 0.00285083552146964, "biggest_recent_change": 0.039472796713248215},
{"total_number_of_episodes": 26820, "number_of_timesteps": 5659260, "per_episode_reward": -62.1, "episode_reward_trend_value": 0.002920528754008779, "biggest_recent_change": 0.039472796713248215},
{"total_number_of_episodes": 26830, "number_of_timesteps": 5662063, "per_episode_reward": -62.08, "episode_reward_trend_value": 0.0028896059197006394, "biggest_recent_change": 0.039472796713248215},
{"total_number_of_episodes": 26840, "number_of_timesteps": 5664322, "per_episode_reward": -62.05, "episode_reward_trend_value": 0.0030290743707726935, "biggest_recent_change": 0.039472796713248215},
{"total_number_of_episodes": 26850, "number_of_timesteps": 5667718, "per_episode_reward": -62.02, "episode_reward_trend_value": 0.003026409726474573, "biggest_recent_change": 0.039472796713248215},
{"total_number_of_episodes": 26860, "number_of_timesteps": 5670946, "per_episode_reward": -61.98, "episode_reward_trend_value": 0.0032254286529326097, "biggest_recent_change": 0.039472796713248215},
{"total_number_of_episodes": 26870, "number_of_timesteps": 5674805, "per_episode_reward": -61.96, "episode_reward_trend_value": 0.003212081315670269, "biggest_recent_change": 0.039472796713248215},
{"total_number_of_episodes": 26880, "number_of_timesteps": 5678381, "per_episode_reward": -61.92, "episode_reward_trend_value": 0.003175632794295464, "biggest_recent_change": 0.039472796713248215},
{"total_number_of_episodes": 26890, "number_of_timesteps": 5680881, "per_episode_reward": -61.89, "episode_reward_trend_value": 0.0031916193974565327, "biggest_recent_change": 0.039472796713248215},
{"total_number_of_episodes": 26900, "number_of_timesteps": 5686350, "per_episode_reward": -61.84, "episode_reward_trend_value": 0.0032781263551857225, "biggest_recent_change": 0.047258422908875275},
{"total_number_of_episodes": 26910, "number_of_timesteps": 5689888, "per_episode_reward": -61.82, "episode_reward_trend_value": 0.003149059297751538, "biggest_recent_change": 0.047258422908875275},
{"total_number_of_episodes": 26920, "number_of_timesteps": 5695824, "per_episode_reward": -61.71, "episode_reward_trend_value": 0.004068335440355656, "biggest_recent_change": 0.10610018063761828},
{"total_number_of_episodes": 26930, "number_of_timesteps": 5699363, "per_episode_reward": -61.69, "episode_reward_trend_value": 0.003962427168349573, "biggest_recent_change": 0.10610018063761828},
{"total_number_of_episodes": 26940, "number_of_timesteps": 5703082, "per_episode_reward": -61.68, "episode_reward_trend_value": 0.003735593419287239, "biggest_recent_change": 0.10610018063761828},
{"total_number_of_episodes": 26950, "number_of_timesteps": 5708580, "per_episode_reward": -61.67, "episode_reward_trend_value": 0.0034929356367424053, "biggest_recent_change": 0.10610018063761828},
{"total_number_of_episodes": 26960, "number_of_timesteps": 5711463, "per_episode_reward": -61.64, "episode_reward_trend_value": 0.003502917418509889, "biggest_recent_change": 0.10610018063761828},
{"total_number_of_episodes": 26970, "number_of_timesteps": 5714296, "per_episode_reward": -61.61, "episode_reward_trend_value": 0.0034988253121652074, "biggest_recent_change": 0.10610018063761828},
{"total_number_of_episodes": 26980, "number_of_timesteps": 5718079, "per_episode_reward": -61.54, "episode_reward_trend_value": 0.0038361075913775898, "biggest_recent_change": 0.10610018063761828},
{"total_number_of_episodes": 26990, "number_of_timesteps": 5720958, "per_episode_reward": -61.53, "episode_reward_trend_value": 0.0034826418911853645, "biggest_recent_change": 0.10610018063761828},
{"total_number_of_episodes": 27000, "number_of_timesteps": 5725176, "per_episode_reward": -61.5, "episode_reward_trend_value": 0.003486402833860483, "biggest_recent_change": 0.10610018063761828},
{"total_number_of_episodes": 27011, "number_of_timesteps": 5729346, "per_episode_reward": -61.49, "episode_reward_trend_value": 0.002515526419550756, "biggest_recent_change": 0.0677909599181703},
{"total_number_of_episodes": 27021, "number_of_timesteps": 5732178, "per_episode_reward": -61.47, "episode_reward_trend_value": 0.0024971082538334443, "biggest_recent_change": 0.0677909599181703},
{"total_number_of_episodes": 27032, "number_of_timesteps": 5735859, "per_episode_reward": -61.34, "episode_reward_trend_value": 0.003839259986613541, "biggest_recent_change": 0.13257847521449406},
{"total_number_of_episodes": 27042, "number_of_timesteps": 5740220, "per_episode_reward": -61.29, "episode_reward_trend_value": 0.0041596161645375985, "biggest_recent_change": 0.13257847521449406},
{"total_number_of_episodes": 27052, "number_of_timesteps": 5744828, "per_episode_reward": -61.25, "episode_reward_trend_value": 0.004407298783735235, "biggest_recent_change": 0.13257847521449406},
{"total_number_of_episodes": 27062, "number_of_timesteps": 5749275, "per_episode_reward": -61.13, "episode_reward_trend_value": 0.005325806315009077, "biggest_recent_change": 0.13257847521449406},
{"total_number_of_episodes": 27072, "number_of_timesteps": 5753107, "per_episode_reward": -61.1, "episode_reward_trend_value": 0.004938759832505784, "biggest_recent_change": 0.13257847521449406},
{"total_number_of_episodes": 27082, "number_of_timesteps": 5756632, "per_episode_reward": -61.06, "episode_reward_trend_value": 0.005155710530950901, "biggest_recent_change": 0.13257847521449406},
{"total_number_of_episodes": 27092, "number_of_timesteps": 5763572, "per_episode_reward": -61.05, "episode_reward_trend_value": 0.005073661472057012, "biggest_recent_change": 0.13257847521449406},
{"total_number_of_episodes": 27102, "number_of_timesteps": 5766997, "per_episode_reward": -61.03, "episode_reward_trend_value": 0.0050242703899096046, "biggest_recent_change": 0.13257847521449406},
{"total_number_of_episodes": 27112, "number_of_timesteps": 5771639, "per_episode_reward": -61.0, "episode_reward_trend_value": 0.005162642178592117, "biggest_recent_change": 0.13257847521449406},
{"total_number_of_episodes": 27122, "number_of_timesteps": 5775665, "per_episode_reward": -60.99, "episode_reward_trend_value": 0.003877215378392012, "biggest_recent_change": 0.11460726047415193},
{"total_number_of_episodes": 27132, "number_of_timesteps": 5781694, "per_episode_reward": -60.95, "episode_reward_trend_value": 0.003736728400360789, "biggest_recent_change": 0.11460726047415193},
{"total_number_of_episodes": 27142, "number_of_timesteps": 5785358, "per_episode_reward": -60.92, "episode_reward_trend_value": 0.0035744811312718463, "biggest_recent_change": 0.11460726047415193},
{"total_number_of_episodes": 27152, "number_of_timesteps": 5788548, "per_episode_reward": -60.9, "episode_reward_trend_value": 0.0025785838929095915, "biggest_recent_change": 0.03497207275163561},
{"total_number_of_episodes": 27162, "number_of_timesteps": 5795481, "per_episode_reward": -60.85, "episode_reward_trend_value": 0.0026999951061839056, "biggest_recent_change": 0.04388378568756224},
{"total_number_of_episodes": 27172, "number_of_timesteps": 5800822, "per_episode_reward": -60.84, "episode_reward_trend_value": 0.002507156731647658, "biggest_recent_change": 0.04388378568756224},
{"total_number_of_episodes": 27182, "number_of_timesteps": 5805567, "per_episode_reward": -60.82, "episode_reward_trend_value": 0.002474396289687459, "biggest_recent_change": 0.04388378568756224},
{"total_number_of_episodes": 27192, "number_of_timesteps": 5809502, "per_episode_reward": -60.8, "episode_reward_trend_value": 0.002554745015682632, "biggest_recent_change": 0.04388378568756224},
{"total_number_of_episodes": 27202, "number_of_timesteps": 5812471, "per_episode_reward": -60.77, "episode_reward_trend_value": 0.002635150381511882, "biggest_recent_change": 0.04388378568756224},
{"total_number_of_episodes": 27212, "number_of_timesteps": 5816092, "per_episode_reward": -60.72, "episode_reward_trend_value": 0.0029676261179233956, "biggest_recent_change": 0.04681287947352075},
{"total_number_of_episodes": 27222, "number_of_timesteps": 5818551, "per_episode_reward": -60.7, "episode_reward_trend_value": 0.0028575695164657117, "biggest_recent_change": 0.04681287947352075},
{"total_number_of_episodes": 27232, "number_of_timesteps": 5821432, "per_episode_reward": -60.66, "episode_reward_trend_value": 0.002905349261802965, "biggest_recent_change": 0.04681287947352075},
{"total_number_of_episodes": 27242, "number_of_timesteps": 5824300, "per_episode_reward": -60.64, "episode_reward_trend_value": 0.0029189196622616638, "biggest_recent_change": 0.04681287947352075},
{"total_number_of_episodes": 27253, "number_of_timesteps": 5829955, "per_episode_reward": -60.61, "episode_reward_trend_value": 0.0027188892573729757, "biggest_recent_change": 0.04681287947352075},
{"total_number_of_episodes": 27263, "number_of_timesteps": 5833500, "per_episode_reward": -60.61, "episode_reward_trend_value": 0.0025570890093038184, "biggest_recent_change": 0.04681287947352075},
{"total_number_of_episodes": 27273, "number_of_timesteps": 5839655, "per_episode_reward": -60.57, "episode_reward_trend_value": 0.002787193884223724, "biggest_recent_change": 0.04681287947352075},
{"total_number_of_episodes": 27283, "number_of_timesteps": 5842103, "per_episode_reward": -60.53, "episode_reward_trend_value": 0.003015127962719709, "biggest_recent_change": 0.04681287947352075},
{"total_number_of_episodes": 27294, "number_of_timesteps": 5845598, "per_episode_reward": -60.49, "episode_reward_trend_value": 0.003057029483381986, "biggest_recent_change": 0.04681287947352075},
{"total_number_of_episodes": 27306, "number_of_timesteps": 5849061, "per_episode_reward": -60.39, "episode_reward_trend_value": 0.0036650250186373197, "biggest_recent_change": 0.10153247764650075},
{"total_number_of_episodes": 27316, "number_of_timesteps": 5852910, "per_episode_reward": -60.37, "episode_reward_trend_value": 0.0036092954807110623, "biggest_recent_change": 0.10153247764650075},
{"total_number_of_episodes": 27326, "number_of_timesteps": 5856348, "per_episode_reward": -60.32, "episode_reward_trend_value": 0.0038028035861436315, "biggest_recent_change": 0.10153247764650075},
{"total_number_of_episodes": 27337, "number_of_timesteps": 5861402, "per_episode_reward": -60.3, "episode_reward_trend_value": 0.0036824829323257465, "biggest_recent_change": 0.10153247764650075},
{"total_number_of_episodes": 27347, "number_of_timesteps": 5864261, "per_episode_reward": -60.26, "episode_reward_trend_value": 0.003884937126774367, "biggest_recent_change": 0.10153247764650075},
{"total_number_of_episodes": 27357, "number_of_timesteps": 5868309, "per_episode_reward": -60.22, "episode_reward_trend_value": 0.0042726677862515005, "biggest_recent_change": 0.10153247764650075},
{"total_number_of_episodes": 27368, "number_of_timesteps": 5874018, "per_episode_reward": -60.22, "episode_reward_trend_value": 0.003955977467819909, "biggest_recent_change": 0.10153247764650075},
{"total_number_of_episodes": 27378, "number_of_timesteps": 5877664, "per_episode_reward": -60.17, "episode_reward_trend_value": 0.0039661826934338906, "biggest_recent_change": 0.10153247764650075},

{"total_number_of_episodes": 27388, "number_of_timesteps": 5883518, "per_episode_reward": -60.14, "episode_reward_trend_value": 0.003885835314721299, "biggest_recent_change": 0.10153247764650075},
{"total_number_of_episodes": 27398, "number_of_timesteps": 5888085, "per_episode_reward": -60.1, "episode_reward_trend_value": 0.0032566449998415216, "biggest_recent_change": 0.05316872838795206},
{"total_number_of_episodes": 27408, "number_of_timesteps": 5892084, "per_episode_reward": -60.06, "episode_reward_trend_value": 0.0034572562016868522, "biggest_recent_change": 0.05316872838795206},
{"total_number_of_episodes": 27418, "number_of_timesteps": 5895168, "per_episode_reward": -60.0, "episode_reward_trend_value": 0.003569217978959611, "biggest_recent_change": 0.06324528834250032},
{"total_number_of_episodes": 27428, "number_of_timesteps": 5901264, "per_episode_reward": -59.96, "episode_reward_trend_value": 0.0038098627962400633, "biggest_recent_change": 0.06324528834250032},
{"total_number_of_episodes": 27438, "number_of_timesteps": 5906201, "per_episode_reward": -59.92, "episode_reward_trend_value": 0.0037951459124282707, "biggest_recent_change": 0.06324528834250032},
{"total_number_of_episodes": 27448, "number_of_timesteps": 5909901, "per_episode_reward": -59.83, "episode_reward_trend_value": 0.004390402052489151, "biggest_recent_change": 0.0915234086755703},
{"total_number_of_episodes": 27458, "number_of_timesteps": 5912572, "per_episode_reward": -59.79, "episode_reward_trend_value": 0.004727128349545259, "biggest_recent_change": 0.0915234086755703},
{"total_number_of_episodes": 27468, "number_of_timesteps": 5916671, "per_episode_reward": -59.78, "episode_reward_trend_value": 0.00443626997415273, "biggest_recent_change": 0.0915234086755703},
{"total_number_of_episodes": 27478, "number_of_timesteps": 5920385, "per_episode_reward": -59.76, "episode_reward_trend_value": 0.0042779650250504946, "biggest_recent_change": 0.0915234086755703},
{"total_number_of_episodes": 27488, "number_of_timesteps": 5923789, "per_episode_reward": -59.74, "episode_reward_trend_value": 0.003941052284475748, "biggest_recent_change": 0.0915234086755703},
{"total_number_of_episodes": 27498, "number_of_timesteps": 5927310, "per_episode_reward": -59.73, "episode_reward_trend_value": 0.003706685451978902, "biggest_recent_change": 0.0915234086755703},
{"total_number_of_episodes": 27508, "number_of_timesteps": 5931380, "per_episode_reward": -59.65, "episode_reward_trend_value": 0.0038224176594460523, "biggest_recent_change": 0.0915234086755703},
{"total_number_of_episodes": 27518, "number_of_timesteps": 5935981, "per_episode_reward": -59.64, "episode_reward_trend_value": 0.0035194394099222217, "biggest_recent_change": 0.0915234086755703},
{"total_number_of_episodes": 27528, "number_of_timesteps": 5940656, "per_episode_reward": -59.6, "episode_reward_trend_value": 0.0035229395710869777, "biggest_recent_change": 0.0915234086755703},
{"total_number_of_episodes": 27538, "number_of_timesteps": 5944793, "per_episode_reward": -59.55, "episode_reward_trend_value": 0.003093541580749341, "biggest_recent_change": 0.07366118701454383},
{"total_number_of_episodes": 27548, "number_of_timesteps": 5949160, "per_episode_reward": -59.49, "episode_reward_trend_value": 0.0034015557848283444, "biggest_recent_change": 0.07366118701454383},
{"total_number_of_episodes": 27558, "number_of_timesteps": 5951880, "per_episode_reward": -59.43, "episode_reward_trend_value": 0.003792170703169736, "biggest_recent_change": 0.07366118701454383},
{"total_number_of_episodes": 27568, "number_of_timesteps": 5955655, "per_episode_reward": -59.38, "episode_reward_trend_value": 0.0041438129663036866, "biggest_recent_change": 0.07366118701454383},
{"total_number_of_episodes": 27578, "number_of_timesteps": 5959728, "per_episode_reward": -59.35, "episode_reward_trend_value": 0.004365957818256936, "biggest_recent_change": 0.07366118701454383},
{"total_number_of_episodes": 27588, "number_of_timesteps": 5966049, "per_episode_reward": -59.31, "episode_reward_trend_value": 0.004656777101182996, "biggest_recent_change": 0.07366118701454383},
{"total_number_of_episodes": 27598, "number_of_timesteps": 5970836, "per_episode_reward": -59.27, "episode_reward_trend_value": 0.004323977199669019, "biggest_recent_change": 0.06250904745675712},
{"total_number_of_episodes": 27608, "number_of_timesteps": 5975435, "per_episode_reward": -59.26, "episode_reward_trend_value": 0.004319418367381505, "biggest_recent_change": 0.06250904745675712},
{"total_number_of_episodes": 27618, "number_of_timesteps": 5979999, "per_episode_reward": -59.23, "episode_reward_trend_value": 0.004166054115748826, "biggest_recent_change": 0.06250904745675712},
{"total_number_of_episodes": 27628, "number_of_timesteps": 5986011, "per_episode_reward": -59.2, "episode_reward_trend_value": 0.003911782538347649, "biggest_recent_change": 0.06250904745675712},
{"total_number_of_episodes": 27639, "number_of_timesteps": 5991561, "per_episode_reward": -59.13, "episode_reward_trend_value": 0.003951185934450526, "biggest_recent_change": 0.06605535310601596},
{"total_number_of_episodes": 27649, "number_of_timesteps": 5994904, "per_episode_reward": -59.07, "episode_reward_trend_value": 0.003999411053258781, "biggest_recent_change": 0.06605535310601596},
{"total_number_of_episodes": 27659, "number_of_timesteps": 5998795, "per_episode_reward": -59.07, "episode_reward_trend_value": 0.003519182835255682, "biggest_recent_change": 0.06605535310601596},
{"total_number_of_episodes": 27669, "number_of_timesteps": 6001090, "per_episode_reward": -59.05, "episode_reward_trend_value": 0.0032956717689816154, "biggest_recent_change": 0.06605535310601596},
{"total_number_of_episodes": 27679, "number_of_timesteps": 6003822, "per_episode_reward": -58.99, "episode_reward_trend_value": 0.003576549946272836, "biggest_recent_change": 0.06610083012555634},
{"total_number_of_episodes": 27689, "number_of_timesteps": 6009711, "per_episode_reward": -58.98, "episode_reward_trend_value": 0.003180804750001206, "biggest_recent_change": 0.06610083012555634},
{"total_number_of_episodes": 27699, "number_of_timesteps": 6016071, "per_episode_reward": -58.93, "episode_reward_trend_value": 0.003675610505737205, "biggest_recent_change": 0.06610083012555634},
{"total_number_of_episodes": 27709, "number_of_timesteps": 6022000, "per_episode_reward": -58.9, "episode_reward_trend_value": 0.0036401498685025993, "biggest_recent_change": 0.06610083012555634},
{"total_number_of_episodes": 27719, "number_of_timesteps": 6025596, "per_episode_reward": -58.87, "episode_reward_trend_value": 0.0036073914296639803, "biggest_recent_change": 0.06610083012555634},
{"total_number_of_episodes": 27729, "number_of_timesteps": 6031228, "per_episode_reward": -58.85, "episode_reward_trend_value": 0.0030947230395560786, "biggest_recent_change": 0.06610083012555634},
{"total_number_of_episodes": 27739, "number_of_timesteps": 6036654, "per_episode_reward": -58.85, "episode_reward_trend_value": 0.0025481470623558286, "biggest_recent_change": 0.06610083012555634},
{"total_number_of_episodes": 27749, "number_of_timesteps": 6042056, "per_episode_reward": -58.81, "episode_reward_trend_value": 0.0028420438254222803, "biggest_recent_change": 0.06610083012555634},
{"total_number_of_episodes": 27759, "number_of_timesteps": 6047270, "per_episode_reward": -58.77, "episode_reward_trend_value": 0.0031103139085571583, "biggest_recent_change": 0.06610083012555634},
{"total_number_of_episodes": 27769, "number_of_timesteps": 6050553, "per_episode_reward": -58.73, "episode_reward_trend_value": 0.0028382893770370287, "biggest_recent_change": 0.053881200427682074},
{"total_number_of_episodes": 27779, "number_of_timesteps": 6055785, "per_episode_reward": -58.71, "episode_reward_trend_value": 0.0029841099452168705, "biggest_recent_change": 0.053881200427682074},
{"total_number_of_episodes": 27789, "number_of_timesteps": 6061170, "per_episode_reward": -58.68, "episode_reward_trend_value": 0.0027320616398537508, "biggest_recent_change": 0.04161862228874469},
{"total_number_of_episodes": 27799, "number_of_timesteps": 6067030, "per_episode_reward": -58.65, "episode_reward_trend_value": 0.002730949404601388, "biggest_recent_change": 0.04161862228874469},
{"total_number_of_episodes": 27809, "number_of_timesteps": 6072664, "per_episode_reward": -58.62, "episode_reward_trend_value": 0.002806411217785154, "biggest_recent_change": 0.04161862228874469},
{"total_number_of_episodes": 27819, "number_of_timesteps": 6076066, "per_episode_reward": -58.56, "episode_reward_trend_value": 0.003203632556449618, "biggest_recent_change": 0.055665118476106556},
{"total_number_of_episodes": 27829, "number_of_timesteps": 6078886, "per_episode_reward": -58.52, "episode_reward_trend_value": 0.003591574168621116, "biggest_recent_change": 0.055665118476106556},
{"total_number_of_episodes": 27839, "number_of_timesteps": 6082071, "per_episode_reward": -58.51, "episode_reward_trend_value": 0.00330472229445541, "biggest_recent_change": 0.055665118476106556},
{"total_number_of_episodes": 27849, "number_of_timesteps": 6084954, "per_episode_reward": -58.48, "episode_reward_trend_value": 0.0032691870566552775, "biggest_recent_change": 0.055665118476106556},
{"total_number_of_episodes": 27860, "number_of_timesteps": 6089274, "per_episode_reward": -58.43, "episode_reward_trend_value": 0.00332700443422406, "biggest_recent_change": 0.055665118476106556},
{"total_number_of_episodes": 27870, "number_of_timesteps": 6094174, "per_episode_reward": -58.38, "episode_reward_trend_value": 0.0036858532169547057, "biggest_recent_change": 0.055665118476106556},
{"total_number_of_episodes": 27880, "number_of_timesteps": 6097794, "per_episode_reward": -58.35, "episode_reward_trend_value": 0.0036767105415550978, "biggest_recent_change": 0.055665118476106556},
{"total_number_of_episodes": 27890, "number_of_timesteps": 6100794, "per_episode_reward": -58.34, "episode_reward_trend_value": 0.0035125517990549165, "biggest_recent_change": 0.055665118476106556},
{"total_number_of_episodes": 27900, "number_of_timesteps": 6104561, "per_episode_reward": -58.32, "episode_reward_trend_value": 0.0033795603012412322, "biggest_recent_change": 0.055665118476106556},
{"total_number_of_episodes": 27911, "number_of_timesteps": 6108411, "per_episode_reward": -58.29, "episode_reward_trend_value": 0.0030295841029263056, "biggest_recent_change": 0.05351236979578289},
{"total_number_of_episodes": 27921, "number_of_timesteps": 6115193, "per_episode_reward": -58.29, "episode_reward_trend_value": 0.002532051332115515, "biggest_recent_change": 0.05351236979578289},
{"total_number_of_episodes": 27931, "number_of_timesteps": 6119404, "per_episode_reward": -58.26, "episode_reward_trend_value": 0.0028714546472926373, "biggest_recent_change": 0.05351236979578289},
{"total_number_of_episodes": 27941, "number_of_timesteps": 6124566, "per_episode_reward": -58.24, "episode_reward_trend_value": 0.002631435016290832, "biggest_recent_change": 0.05351236979578289},
{"total_number_of_episodes": 27951, "number_of_timesteps": 6127536, "per_episode_reward": -58.23, "episode_reward_trend_value": 0.002205837250703584, "biggest_recent_change": 0.05351236979578289},
{"total_number_of_episodes": 27961, "number_of_timesteps": 6130729, "per_episode_reward": -58.21, "episode_reward_trend_value": 0.001883589651289381, "biggest_recent_change": 0.03785436377760476},
{"total_number_of_episodes": 27971, "number_of_timesteps": 6135072, "per_episode_reward": -58.18, "episode_reward_trend_value": 0.0018223221979192141, "biggest_recent_change": 0.03785436377760476},
{"total_number_of_episodes": 27981, "number_of_timesteps": 6138755, "per_episode_reward": -58.16, "episode_reward_trend_value": 0.001980428424159284, "biggest_recent_change": 0.03785436377760476},
{"total_number_of_episodes": 27991, "number_of_timesteps": 6141751, "per_episode_reward": -58.15, "episode_reward_trend_value": 0.0018729353134029718, "biggest_recent_change": 0.03785436377760476},
{"total_number_of_episodes": 28001, "number_of_timesteps": 6145419, "per_episode_reward": -58.11, "episode_reward_trend_value": 0.002025322629547885, "biggest_recent_change": 0.03788211908080541},
{"total_number_of_episodes": 28011, "number_of_timesteps": 6148594, "per_episode_reward": -58.09, "episode_reward_trend_value": 0.0022673542075303033, "biggest_recent_change": 0.03788211908080541},
{"total_number_of_episodes": 28021, "number_of_timesteps": 6152405, "per_episode_reward": -58.05, "episode_reward_trend_value": 0.0023095203386488726, "biggest_recent_change": 0.041649315578276},
{"total_number_of_episodes": 28031, "number_of_timesteps": 6155010, "per_episode_reward": -58.01, "episode_reward_trend_value": 0.002594639614753981, "biggest_recent_change": 0.041649315578276},
{"total_number_of_episodes": 28041, "number_of_timesteps": 6157198, "per_episode_reward": -58.0, "episode_reward_trend_value": 0.0025847302641097596, "biggest_recent_change": 0.041649315578276},
{"total_number_of_episodes": 28051, "number_of_timesteps": 6160065, "per_episode_reward": -57.97, "episode_reward_trend_value": 0.0026284712807204693, "biggest_recent_change": 0.041649315578276},
{"total_number_of_episodes": 28061, "number_of_timesteps": 6161976, "per_episode_reward": -57.95, "episode_reward_trend_value": 0.0026214559160969487, "biggest_recent_change": 0.041649315578276},
{"total_number_of_episodes": 28071, "number_of_timesteps": 6164226, "per_episode_reward": -57.93, "episode_reward_trend_value": 0.002597257542796743, "biggest_recent_change": 0.041649315578276},
{"total_number_of_episodes": 28081, "number_of_timesteps": 6166834, "per_episode_reward": -57.91, "episode_reward_trend_value": 0.0026015852346772937, "biggest_recent_change": 0.041649315578276},
{"total_number_of_episodes": 28091, "number_of_timesteps": 6169601, "per_episode_reward": -57.86, "episode_reward_trend_value": 0.0027525230329507465, "biggest_recent_change": 0.05146652092541615},
{"total_number_of_episodes": 28101, "number_of_timesteps": 6174980, "per_episode_reward": -57.82, "episode_reward_trend_value": 0.002995810676024667, "biggest_recent_change": 0.05146652092541615},

{"total_number_of_episodes": 28111, "number_of_timesteps": 6177474, "per_episode_reward": -57.81, "episode_reward_trend_value": 0.002680494592650638, "biggest_recent_change": 0.05146652092541615},
{"total_number_of_episodes": 28121, "number_of_timesteps": 6183332, "per_episode_reward": -57.76, "episode_reward_trend_value": 0.0027838996414306255, "biggest_recent_change": 0.05146652092541615},
{"total_number_of_episodes": 28131, "number_of_timesteps": 6188199, "per_episode_reward": -57.72, "episode_reward_trend_value": 0.0031330243124404293, "biggest_recent_change": 0.05146652092541615},
{"total_number_of_episodes": 28141, "number_of_timesteps": 6193426, "per_episode_reward": -57.65, "episode_reward_trend_value": 0.0036066144913735657, "biggest_recent_change": 0.07106989344745074},
{"total_number_of_episodes": 28151, "number_of_timesteps": 6197486, "per_episode_reward": -57.6, "episode_reward_trend_value": 0.0039176959734165155, "biggest_recent_change": 0.07106989344745074},
{"total_number_of_episodes": 28161, "number_of_timesteps": 6203588, "per_episode_reward": -57.53, "episode_reward_trend_value": 0.004363575228824837, "biggest_recent_change": 0.07106989344745074},
{"total_number_of_episodes": 28171, "number_of_timesteps": 6207624, "per_episode_reward": -57.53, "episode_reward_trend_value": 0.0042748020872841784, "biggest_recent_change": 0.07106989344745074},
{"total_number_of_episodes": 28181, "number_of_timesteps": 6214572, "per_episode_reward": -57.48, "episode_reward_trend_value": 0.004195786541176795, "biggest_recent_change": 0.07106989344745074},
{"total_number_of_episodes": 28191, "number_of_timesteps": 6218418, "per_episode_reward": -57.46, "episode_reward_trend_value": 0.003974409050834361, "biggest_recent_change": 0.07106989344745074},
{"total_number_of_episodes": 28201, "number_of_timesteps": 6223785, "per_episode_reward": -57.41, "episode_reward_trend_value": 0.004444614458910855, "biggest_recent_change": 0.07106989344745074},
{"total_number_of_episodes": 28211, "number_of_timesteps": 6226740, "per_episode_reward": -57.38, "episode_reward_trend_value": 0.004213344921713732, "biggest_recent_change": 0.07106989344745074},
{"total_number_of_episodes": 28221, "number_of_timesteps": 6230943, "per_episode_reward": -57.34, "episode_reward_trend_value": 0.004223565020253201, "biggest_recent_change": 0.07106989344745074},
{"total_number_of_episodes": 28232, "number_of_timesteps": 6237657, "per_episode_reward": -57.24, "episode_reward_trend_value": 0.004546223690756237, "biggest_recent_change": 0.100109173792724},
{"total_number_of_episodes": 28242, "number_of_timesteps": 6241336, "per_episode_reward": -57.18, "episode_reward_trend_value": 0.004667824953719682, "biggest_recent_change": 0.100109173792724},
{"total_number_of_episodes": 28252, "number_of_timesteps": 6247274, "per_episode_reward": -57.14, "episode_reward_trend_value": 0.004405326460275758, "biggest_recent_change": 0.100109173792724},
{"total_number_of_episodes": 28262, "number_of_timesteps": 6250851, "per_episode_reward": -57.12, "episode_reward_trend_value": 0.004585059083204139, "biggest_recent_change": 0.100109173792724},
{"total_number_of_episodes": 28272, "number_of_timesteps": 6255036, "per_episode_reward": -57.09, "episode_reward_trend_value": 0.004317120234328087, "biggest_recent_change": 0.100109173792724},

{"total_number_of_episodes": 28282, "number_of_timesteps": 6258405, "per_episode_reward": -57.06, "episode_reward_trend_value": 0.004441204879301037, "biggest_recent_change": 0.100109173792724},
{"total_number_of_episodes": 28292, "number_of_timesteps": 6261116, "per_episode_reward": -57.03, "episode_reward_trend_value": 0.004172044654718673, "biggest_recent_change": 0.100109173792724},
{"total_number_of_episodes": 28302, "number_of_timesteps": 6265941, "per_episode_reward": -57.01, "episode_reward_trend_value": 0.004050045520458826, "biggest_recent_change": 0.100109173792724},
{"total_number_of_episodes": 28312, "number_of_timesteps": 6269592, "per_episode_reward": -56.99, "episode_reward_trend_value": 0.003850954320723727, "biggest_recent_change": 0.100109173792724},
{"total_number_of_episodes": 28322, "number_of_timesteps": 6272372, "per_episode_reward": -56.95, "episode_reward_trend_value": 0.0031701889375861632, "biggest_recent_change": 0.06317000559018027},
{"total_number_of_episodes": 28332, "number_of_timesteps": 6277447, "per_episode_reward": -56.93, "episode_reward_trend_value": 0.002720449091565216, "biggest_recent_change": 0.03977976905532188},
{"total_number_of_episodes": 28342, "number_of_timesteps": 6281137, "per_episode_reward": -56.9, "episode_reward_trend_value": 0.0026173296617160073, "biggest_recent_change": 0.03884028931034322},
{"total_number_of_episodes": 28352, "number_of_timesteps": 6286363, "per_episode_reward": -56.8, "episode_reward_trend_value": 0.0035429888424249926, "biggest_recent_change": 0.10407800835679382},
{"total_number_of_episodes": 28362, "number_of_timesteps": 6292011, "per_episode_reward": -56.78, "episode_reward_trend_value": 0.003546106084739304, "biggest_recent_change": 0.10407800835679382},
{"total_number_of_episodes": 28372, "number_of_timesteps": 6295495, "per_episode_reward": -56.74, "episode_reward_trend_value": 0.0036067654829317064, "biggest_recent_change": 0.10407800835679382},
{"total_number_of_episodes": 28382, "number_of_timesteps": 6300186, "per_episode_reward": -56.66, "episode_reward_trend_value": 0.004137240648852409, "biggest_recent_change": 0.10407800835679382},
{"total_number_of_episodes": 28392, "number_of_timesteps": 6304893, "per_episode_reward": -56.64, "episode_reward_trend_value": 0.004194803694752696, "biggest_recent_change": 0.10407800835679382},
{"total_number_of_episodes": 28402, "number_of_timesteps": 6309237, "per_episode_reward": -56.61, "episode_reward_trend_value": 0.004198625294360011, "biggest_recent_change": 0.10407800835679382},
{"total_number_of_episodes": 28412, "number_of_timesteps": 6313723, "per_episode_reward": -56.6, "episode_reward_trend_value": 0.003941187611752481, "biggest_recent_change": 0.10407800835679382},
{"total_number_of_episodes": 28422, "number_of_timesteps": 6319152, "per_episode_reward": -56.57, "episode_reward_trend_value": 0.004043782630866054, "biggest_recent_change": 0.10407800835679382},
{"total_number_of_episodes": 28432, "number_of_timesteps": 6323107, "per_episode_reward": -56.54, "episode_reward_trend_value": 0.004034087036553066, "biggest_recent_change": 0.10407800835679382},
{"total_number_of_episodes": 28442, "number_of_timesteps": 6326885, "per_episode_reward": -56.51, "episode_reward_trend_value": 0.003156954773866813, "biggest_recent_change": 0.0791076995219484},
{"total_number_of_episodes": 28452, "number_of_timesteps": 6330335, "per_episode_reward": -56.45, "episode_reward_trend_value": 0.0035882973496931133, "biggest_recent_change": 0.0791076995219484},
{"total_number_of_episodes": 28462, "number_of_timesteps": 6334730, "per_episode_reward": -56.41, "episode_reward_trend_value": 0.003611375955019093, "biggest_recent_change": 0.0791076995219484},
{"total_number_of_episodes": 28472, "number_of_timesteps": 6337029, "per_episode_reward": -56.38, "episode_reward_trend_value": 0.0030554981227911386, "biggest_recent_change": 0.05934200900956199},
{"total_number_of_episodes": 28482, "number_of_timesteps": 6341853, "per_episode_reward": -56.33, "episode_reward_trend_value": 0.0034005783236546157, "biggest_recent_change": 0.05934200900956199},
{"total_number_of_episodes": 28492, "number_of_timesteps": 6346533, "per_episode_reward": -56.3, "episode_reward_trend_value": 0.0034862876321890704, "biggest_recent_change": 0.05934200900956199},
{"total_number_of_episodes": 28502, "number_of_timesteps": 6349408, "per_episode_reward": -56.27, "episode_reward_trend_value": 0.003678455875074052, "biggest_recent_change": 0.05934200900956199},
{"total_number_of_episodes": 28512, "number_of_timesteps": 6352646, "per_episode_reward": -56.22, "episode_reward_trend_value": 0.0038268392183481758, "biggest_recent_change": 0.05934200900956199},
{"total_number_of_episodes": 28522, "number_of_timesteps": 6356543, "per_episode_reward": -56.18, "episode_reward_trend_value": 0.003944772772349915, "biggest_recent_change": 0.05934200900956199},
{"total_number_of_episodes": 28532, "number_of_timesteps": 6359032, "per_episode_reward": -56.14, "episode_reward_trend_value": 0.004081819597851282, "biggest_recent_change": 0.05934200900956199},
{"total_number_of_episodes": 28542, "number_of_timesteps": 6364151, "per_episode_reward": -56.12, "episode_reward_trend_value": 0.0037198316610063072, "biggest_recent_change": 0.05321551367395472},
{"total_number_of_episodes": 28552, "number_of_timesteps": 6369059, "per_episode_reward": -56.07, "episode_reward_trend_value": 0.0038683752604656424, "biggest_recent_change": 0.05321551367395472},
{"total_number_of_episodes": 28562, "number_of_timesteps": 6374282, "per_episode_reward": -56.02, "episode_reward_trend_value": 0.004044586092667165, "biggest_recent_change": 0.05321551367395472},
{"total_number_of_episodes": 28573, "number_of_timesteps": 6377332, "per_episode_reward": -56.0, "episode_reward_trend_value": 0.003727753615398891, "biggest_recent_change": 0.05303105407833186},
{"total_number_of_episodes": 28583, "number_of_timesteps": 6380459, "per_episode_reward": -55.97, "episode_reward_trend_value": 0.0036286008574964827, "biggest_recent_change": 0.05303105407833186},
{"total_number_of_episodes": 28593, "number_of_timesteps": 6382746, "per_episode_reward": -55.95, "episode_reward_trend_value": 0.003523500913099693, "biggest_recent_change": 0.05303105407833186},

{"total_number_of_episodes": 28603, "number_of_timesteps": 6387554, "per_episode_reward": -55.92, "episode_reward_trend_value": 0.0033191256851855164, "biggest_recent_change": 0.05303105407833186},
{"total_number_of_episodes": 28614, "number_of_timesteps": 6390590, "per_episode_reward": -55.81, "episode_reward_trend_value": 0.004143677696035534, "biggest_recent_change": 0.11445011771738223},
{"total_number_of_episodes": 28624, "number_of_timesteps": 6393453, "per_episode_reward": -55.78, "episode_reward_trend_value": 0.004098943953681081, "biggest_recent_change": 0.11445011771738223},
{"total_number_of_episodes": 28634, "number_of_timesteps": 6397657, "per_episode_reward": -55.73, "episode_reward_trend_value": 0.004258554416924672, "biggest_recent_change": 0.11445011771738223},
{"total_number_of_episodes": 28644, "number_of_timesteps": 6401576, "per_episode_reward": -55.71, "episode_reward_trend_value": 0.00395359660904262, "biggest_recent_change": 0.11445011771738223},
{"total_number_of_episodes": 28654, "number_of_timesteps": 6405358, "per_episode_reward": -55.68, "episode_reward_trend_value": 0.003761051544118585, "biggest_recent_change": 0.11445011771738223},
{"total_number_of_episodes": 28665, "number_of_timesteps": 6408097, "per_episode_reward": -55.65, "episode_reward_trend_value": 0.0038872531706649247, "biggest_recent_change": 0.11445011771738223},
{"total_number_of_episodes": 28675, "number_of_timesteps": 6410451, "per_episode_reward": -55.63, "episode_reward_trend_value": 0.0038601759202063273, "biggest_recent_change": 0.11445011771738223},
{"total_number_of_episodes": 28685, "number_of_timesteps": 6414488, "per_episode_reward": -55.6, "episode_reward_trend_value": 0.003911696808317089, "biggest_recent_change": 0.11445011771738223},
{"total_number_of_episodes": 28695, "number_of_timesteps": 6417391, "per_episode_reward": -55.57, "episode_reward_trend_value": 0.003910967134784866, "biggest_recent_change": 0.11445011771738223},
{"total_number_of_episodes": 28705, "number_of_timesteps": 6419377, "per_episode_reward": -55.54, "episode_reward_trend_value": 0.002984409809637138, "biggest_recent_change": 0.04112803638543738},
{"total_number_of_episodes": 28715, "number_of_timesteps": 6421042, "per_episode_reward": -55.51, "episode_reward_trend_value": 0.002942656503391798, "biggest_recent_change": 0.04112803638543738},
{"total_number_of_episodes": 28725, "number_of_timesteps": 6424222, "per_episode_reward": -55.48, "episode_reward_trend_value": 0.0028530963054516673, "biggest_recent_change": 0.036058737108980665},
{"total_number_of_episodes": 28735, "number_of_timesteps": 6427389, "per_episode_reward": -55.45, "episode_reward_trend_value": 0.0029170438434699504, "biggest_recent_change": 0.036058737108980665},
{"total_number_of_episodes": 28745, "number_of_timesteps": 6429809, "per_episode_reward": -55.35, "episode_reward_trend_value": 0.003633545493422474, "biggest_recent_change": 0.09209376217213361},
{"total_number_of_episodes": 28755, "number_of_timesteps": 6431956, "per_episode_reward": -55.3, "episode_reward_trend_value": 0.0038363368115743096, "biggest_recent_change": 0.09209376217213361},
{"total_number_of_episodes": 28765, "number_of_timesteps": 6433918, "per_episode_reward": -55.29, "episode_reward_trend_value": 0.0037342305428832703, "biggest_recent_change": 0.09209376217213361},
{"total_number_of_episodes": 28775, "number_of_timesteps": 6436761, "per_episode_reward": -55.25, "episode_reward_trend_value": 0.003840363367413128, "biggest_recent_change": 0.09209376217213361},
{"total_number_of_episodes": 28785, "number_of_timesteps": 6440946, "per_episode_reward": -55.23, "episode_reward_trend_value": 0.0038000462891113946, "biggest_recent_change": 0.09209376217213361},
{"total_number_of_episodes": 28796, "number_of_timesteps": 6443911, "per_episode_reward": -55.18, "episode_reward_trend_value": 0.003981183512028647, "biggest_recent_change": 0.09209376217213361},
{"total_number_of_episodes": 28806, "number_of_timesteps": 6447521, "per_episode_reward": -55.16, "episode_reward_trend_value": 0.003955500826681736, "biggest_recent_change": 0.09209376217213361},
{"total_number_of_episodes": 28816, "number_of_timesteps": 6450257, "per_episode_reward": -55.14, "episode_reward_trend_value": 0.003747892549087576, "biggest_recent_change": 0.09209376217213361},
{"total_number_of_episodes": 28826, "number_of_timesteps": 6452127, "per_episode_reward": -55.12, "episode_reward_trend_value": 0.003685562243325554, "biggest_recent_change": 0.09209376217213361},
{"total_number_of_episodes": 28836, "number_of_timesteps": 6453783, "per_episode_reward": -55.1, "episode_reward_trend_value": 0.0028536232202159323, "biggest_recent_change": 0.054309955742645855},
{"total_number_of_episodes": 28846, "number_of_timesteps": 6457612, "per_episode_reward": -55.07, "episode_reward_trend_value": 0.0025726599859802316, "biggest_recent_change": 0.04736230851663947},
{"total_number_of_episodes": 28856, "number_of_timesteps": 6461045, "per_episode_reward": -55.03, "episode_reward_trend_value": 0.002906662832293547, "biggest_recent_change": 0.04736230851663947},
{"total_number_of_episodes": 28866, "number_of_timesteps": 6464292, "per_episode_reward": -54.96, "episode_reward_trend_value": 0.003210718059758556, "biggest_recent_change": 0.06506084934910916},
{"total_number_of_episodes": 28876, "number_of_timesteps": 6466314, "per_episode_reward": -54.96, "episode_reward_trend_value": 0.0030255351252088916, "biggest_recent_change": 0.06506084934910916},
{"total_number_of_episodes": 28886, "number_of_timesteps": 6469489, "per_episode_reward": -54.93, "episode_reward_trend_value": 0.002798678105970017, "biggest_recent_change": 0.06506084934910916},
{"total_number_of_episodes": 28897, "number_of_timesteps": 6472081, "per_episode_reward": -54.88, "episode_reward_trend_value": 0.0031112704980362734, "biggest_recent_change": 0.06506084934910916},
{"total_number_of_episodes": 28907, "number_of_timesteps": 6475152, "per_episode_reward": -54.86, "episode_reward_trend_value": 0.0031702519305133433, "biggest_recent_change": 0.06506084934910916},
{"total_number_of_episodes": 28917, "number_of_timesteps": 6477497, "per_episode_reward": -54.83, "episode_reward_trend_value": 0.0031319485664562468, "biggest_recent_change": 0.06506084934910916},
{"total_number_of_episodes": 28927, "number_of_timesteps": 6479788, "per_episode_reward": -54.78, "episode_reward_trend_value": 0.0035309114523341145, "biggest_recent_change": 0.06506084934910916},
{"total_number_of_episodes": 28937, "number_of_timesteps": 6481744, "per_episode_reward": -54.73, "episode_reward_trend_value": 0.003737842430540342, "biggest_recent_change": 0.06506084934910916},
{"total_number_of_episodes": 28947, "number_of_timesteps": 6484298, "per_episode_reward": -54.69, "episode_reward_trend_value": 0.00372389295589007, "biggest_recent_change": 0.06506084934910916},

{"total_number_of_episodes": 28957, "number_of_timesteps": 6487450, "per_episode_reward": -54.66, "episode_reward_trend_value": 0.003329336913201865, "biggest_recent_change": 0.055508358240913935},
{"total_number_of_episodes": 28968, "number_of_timesteps": 6491392, "per_episode_reward": -54.65, "episode_reward_trend_value": 0.0034166097345152005, "biggest_recent_change": 0.055508358240913935},
{"total_number_of_episodes": 28978, "number_of_timesteps": 6495592, "per_episode_reward": -54.61, "episode_reward_trend_value": 0.003518561201319178, "biggest_recent_change": 0.055508358240913935},
{"total_number_of_episodes": 28988, "number_of_timesteps": 6499434, "per_episode_reward": -54.56, "episode_reward_trend_value": 0.0035309665511311845, "biggest_recent_change": 0.05662483972399457},
{"total_number_of_episodes": 28999, "number_of_timesteps": 6502162, "per_episode_reward": -54.51, "episode_reward_trend_value": 0.003789094154216047, "biggest_recent_change": 0.05662483972399457},
{"total_number_of_episodes": 29010, "number_of_timesteps": 6505036, "per_episode_reward": -54.5, "episode_reward_trend_value": 0.0036983054375342465, "biggest_recent_change": 0.05662483972399457},
{"total_number_of_episodes": 29020, "number_of_timesteps": 6508481, "per_episode_reward": -54.44, "episode_reward_trend_value": 0.0037938920823958394, "biggest_recent_change": 0.06172870785881912},
{"total_number_of_episodes": 29030, "number_of_timesteps": 6513625, "per_episode_reward": -54.43, "episode_reward_trend_value": 0.00335954189456176, "biggest_recent_change": 0.06172870785881912},
{"total_number_of_episodes": 29040, "number_of_timesteps": 6517746, "per_episode_reward": -54.39, "episode_reward_trend_value": 0.0033235313001159263, "biggest_recent_change": 0.06172870785881912},
{"total_number_of_episodes": 29050, "number_of_timesteps": 6520805, "per_episode_reward": -54.35, "episode_reward_trend_value": 0.0034527128357423305, "biggest_recent_change": 0.06172870785881912},
{"total_number_of_episodes": 29060, "number_of_timesteps": 6524175, "per_episode_reward": -54.32, "episode_reward_trend_value": 0.0036279895388540402, "biggest_recent_change": 0.06172870785881912},
{"total_number_of_episodes": 29070, "number_of_timesteps": 6527627, "per_episode_reward": -54.31, "episode_reward_trend_value": 0.003425953809439935, "biggest_recent_change": 0.06172870785881912},
{"total_number_of_episodes": 29080, "number_of_timesteps": 6531398, "per_episode_reward": -54.26, "episode_reward_trend_value": 0.003338515020533745, "biggest_recent_change": 0.06172870785881912},
{"total_number_of_episodes": 29090, "number_of_timesteps": 6536714, "per_episode_reward": -54.25, "episode_reward_trend_value": 0.002978233343559111, "biggest_recent_change": 0.06172870785881912},
{"total_number_of_episodes": 29100, "number_of_timesteps": 6540377, "per_episode_reward": -54.2, "episode_reward_trend_value": 0.003329685810294652, "biggest_recent_change": 0.06172870785881912},
{"total_number_of_episodes": 29110, "number_of_timesteps": 6543364, "per_episode_reward": -54.17, "episode_reward_trend_value": 0.00301552401652698, "biggest_recent_change": 0.048755348722437475},
{"total_number_of_episodes": 29120, "number_of_timesteps": 6547061, "per_episode_reward": -54.12, "episode_reward_trend_value": 0.00341789017395584, "biggest_recent_change": 0.048755348722437475},
{"total_number_of_episodes": 29130, "number_of_timesteps": 6549612, "per_episode_reward": -53.99, "episode_reward_trend_value": 0.004493046917034604, "biggest_recent_change": 0.13188484071709183},
{"total_number_of_episodes": 29141, "number_of_timesteps": 6554538, "per_episode_reward": -53.97, "episode_reward_trend_value": 0.004281271953090027, "biggest_recent_change": 0.13188484071709183},
{"total_number_of_episodes": 29151, "number_of_timesteps": 6557820, "per_episode_reward": -53.95, "episode_reward_trend_value": 0.0042005596198304174, "biggest_recent_change": 0.13188484071709183},
{"total_number_of_episodes": 29161, "number_of_timesteps": 6562464, "per_episode_reward": -53.88, "episode_reward_trend_value": 0.0047301386895737116, "biggest_recent_change": 0.13188484071709183},
{"total_number_of_episodes": 29171, "number_of_timesteps": 6564767, "per_episode_reward": -53.83, "episode_reward_trend_value": 0.004786419965470164, "biggest_recent_change": 0.13188484071709183},
{"total_number_of_episodes": 29181, "number_of_timesteps": 6568453, "per_episode_reward": -53.78, "episode_reward_trend_value": 0.005196951053084101, "biggest_recent_change": 0.13188484071709183},
{"total_number_of_episodes": 29191, "number_of_timesteps": 6571162, "per_episode_reward": -53.75, "episode_reward_trend_value": 0.005010279794720024, "biggest_recent_change": 0.13188484071709183},
{"total_number_of_episodes": 29201, "number_of_timesteps": 6573481, "per_episode_reward": -53.7, "episode_reward_trend_value": 0.005167667275137925, "biggest_recent_change": 0.13188484071709183},
{"total_number_of_episodes": 29211, "number_of_timesteps": 6576575, "per_episode_reward": -53.67, "episode_reward_trend_value": 0.0049906807903704635, "biggest_recent_change": 0.13188484071709183},
{"total_number_of_episodes": 29221, "number_of_timesteps": 6582711, "per_episode_reward": -53.62, "episode_reward_trend_value": 0.004102791090003263, "biggest_recent_change": 0.06559970942712567},
{"total_number_of_episodes": 29231, "number_of_timesteps": 6584926, "per_episode_reward": -53.53, "episode_reward_trend_value": 0.004820734704817811, "biggest_recent_change": 0.08673232229184435},
{"total_number_of_episodes": 29241, "number_of_timesteps": 6587256, "per_episode_reward": -53.52, "episode_reward_trend_value": 0.004763543845582932, "biggest_recent_change": 0.08673232229184435},
{"total_number_of_episodes": 29251, "number_of_timesteps": 6589527, "per_episode_reward": -53.49, "episode_reward_trend_value": 0.004328528183561846, "biggest_recent_change": 0.08673232229184435},
{"total_number_of_episodes": 29262, "number_of_timesteps": 6591819, "per_episode_reward": -53.39, "episode_reward_trend_value": 0.004885962232610552, "biggest_recent_change": 0.10398972796750172},
{"total_number_of_episodes": 29272, "number_of_timesteps": 6593942, "per_episode_reward": -53.34, "episode_reward_trend_value": 0.004849710325992539, "biggest_recent_change": 0.10398972796750172},
{"total_number_of_episodes": 29282, "number_of_timesteps": 6596464, "per_episode_reward": -53.29, "episode_reward_trend_value": 0.005089361483377925, "biggest_recent_change": 0.10398972796750172},
{"total_number_of_episodes": 29292, "number_of_timesteps": 6598534, "per_episode_reward": -53.27, "episode_reward_trend_value": 0.004765382655809307, "biggest_recent_change": 0.10398972796750172},
{"total_number_of_episodes": 29302, "number_of_timesteps": 6599998, "per_episode_reward": -53.24, "episode_reward_trend_value": 0.0047649695110892135, "biggest_recent_change": 0.10398972796750172},
{"total_number_of_episodes": 29313, "number_of_timesteps": 6601847, "per_episode_reward": -53.21, "episode_reward_trend_value": 0.00455129328184714, "biggest_recent_change": 0.10398972796750172},
{"total_number_of_episodes": 29323, "number_of_timesteps": 6603369, "per_episode_reward": -53.18, "episode_reward_trend_value": 0.003964837275931248, "biggest_recent_change": 0.10398972796750172},
{"total_number_of_episodes": 29333, "number_of_timesteps": 6605269, "per_episode_reward": -53.16, "episode_reward_trend_value": 0.0039653825642651614, "biggest_recent_change": 0.10398972796750172},
{"total_number_of_episodes": 29343, "number_of_timesteps": 6606781, "per_episode_reward": -53.12, "episode_reward_trend_value": 0.004081027197059465, "biggest_recent_change": 0.10398972796750172},
{"total_number_of_episodes": 29353, "number_of_timesteps": 6610113, "per_episode_reward": -53.08, "episode_reward_trend_value": 0.0034486713935870566, "biggest_recent_change": 0.05051102792362627},
{"total_number_of_episodes": 29363, "number_of_timesteps": 6612624, "per_episode_reward": -53.05, "episode_reward_trend_value": 0.0032707497077881934, "biggest_recent_change": 0.05051102792362627},
{"total_number_of_episodes": 29373, "number_of_timesteps": 6615010, "per_episode_reward": -53.04, "episode_reward_trend_value": 0.0028152216614245164, "biggest_recent_change": 0.047077705654984925},
{"total_number_of_episodes": 29383, "number_of_timesteps": 6617648, "per_episode_reward": -52.94, "episode_reward_trend_value": 0.0037147114922222594, "biggest_recent_change": 0.09941500994796115},
{"total_number_of_episodes": 29393, "number_of_timesteps": 6620336, "per_episode_reward": -52.91, "episode_reward_trend_value": 0.003686415134556537, "biggest_recent_change": 0.09941500994796115},
{"total_number_of_episodes": 29403, "number_of_timesteps": 6622189, "per_episode_reward": -52.89, "episode_reward_trend_value": 0.0035776188462214977, "biggest_recent_change": 0.09941500994796115},
{"total_number_of_episodes": 29413, "number_of_timesteps": 6623905, "per_episode_reward": -52.85, "episode_reward_trend_value": 0.003609442117084506, "biggest_recent_change": 0.09941500994796115},
{"total_number_of_episodes": 29423, "number_of_timesteps": 6626491, "per_episode_reward": -52.82, "episode_reward_trend_value": 0.00375012777272477, "biggest_recent_change": 0.09941500994796115},
{"total_number_of_episodes": 29433, "number_of_timesteps": 6628181, "per_episode_reward": -52.79, "episode_reward_trend_value": 0.0037108365347819474, "biggest_recent_change": 0.09941500994796115},
{"total_number_of_episodes": 29443, "number_of_timesteps": 6629872, "per_episode_reward": -52.69, "episode_reward_trend_value": 0.004282604122237407, "biggest_recent_change": 0.09941500994796115},
{"total_number_of_episodes": 29453, "number_of_timesteps": 6632006, "per_episode_reward": -52.68, "episode_reward_trend_value": 0.004107742825036098, "biggest_recent_change": 0.09941500994796115},
{"total_number_of_episodes": 29463, "number_of_timesteps": 6634546, "per_episode_reward": -52.64, "episode_reward_trend_value": 0.004457798758987429, "biggest_recent_change": 0.09941500994796115},
{"total_number_of_episodes": 29473, "number_of_timesteps": 6636285, "per_episode_reward": -52.59, "episode_reward_trend_value": 0.003836752547462336, "biggest_recent_change": 0.09853678852597625},
{"total_number_of_episodes": 29483, "number_of_timesteps": 6638120, "per_episode_reward": -52.56, "episode_reward_trend_value": 0.003928514920910371, "biggest_recent_change": 0.09853678852597625},
{"total_number_of_episodes": 29493, "number_of_timesteps": 6639691, "per_episode_reward": -52.53, "episode_reward_trend_value": 0.004043127654413404, "biggest_recent_change": 0.09853678852597625},
{"total_number_of_episodes": 29503, "number_of_timesteps": 6642045, "per_episode_reward": -52.52, "episode_reward_trend_value": 0.003686708196320391, "biggest_recent_change": 0.09853678852597625},
{"total_number_of_episodes": 29513, "number_of_timesteps": 6645163, "per_episode_reward": -52.51, "episode_reward_trend_value": 0.0035057629290198926, "biggest_recent_change": 0.09853678852597625},
{"total_number_of_episodes": 29523, "number_of_timesteps": 6646874, "per_episode_reward": -52.48, "episode_reward_trend_value": 0.0034354226716506752, "biggest_recent_change": 0.09853678852597625},
{"total_number_of_episodes": 29533, "number_of_timesteps": 6649098, "per_episode_reward": -52.45, "episode_reward_trend_value": 0.0027270459933211397, "biggest_recent_change": 0.04352085091070279},
{"total_number_of_episodes": 29543, "number_of_timesteps": 6651399, "per_episode_reward": -52.41, "episode_reward_trend_value": 0.002946244585637064, "biggest_recent_change": 0.04352085091070279},
{"total_number_of_episodes": 29553, "number_of_timesteps": 6653246, "per_episode_reward": -52.38, "episode_reward_trend_value": 0.0028046619192447822, "biggest_recent_change": 0.04352085091070279},
{"total_number_of_episodes": 29563, "number_of_timesteps": 6655219, "per_episode_reward": -52.35, "episode_reward_trend_value": 0.0026859477113414226, "biggest_recent_change": 0.03478288747631808},
{"total_number_of_episodes": 29573, "number_of_timesteps": 6657083, "per_episode_reward": -52.34, "episode_reward_trend_value": 0.0024816716201137012, "biggest_recent_change": 0.03478288747631808},
{"total_number_of_episodes": 29583, "number_of_timesteps": 6659059, "per_episode_reward": -52.28, "episode_reward_trend_value": 0.0027276341308068355, "biggest_recent_change": 0.05540401307975884},
{"total_number_of_episodes": 29593, "number_of_timesteps": 6661597, "per_episode_reward": -52.23, "episode_reward_trend_value": 0.003198000427450312, "biggest_recent_change": 0.05540401307975884},
{"total_number_of_episodes": 29603, "number_of_timesteps": 6664552, "per_episode_reward": -52.2, "episode_reward_trend_value": 0.0034582300820533854, "biggest_recent_change": 0.05540401307975884},
{"total_number_of_episodes": 29613, "number_of_timesteps": 6667260, "per_episode_reward": -52.16, "episode_reward_trend_value": 0.003589428581232173, "biggest_recent_change": 0.05540401307975884},
{"total_number_of_episodes": 29623, "number_of_timesteps": 6669687, "per_episode_reward": -52.07, "episode_reward_trend_value": 0.004167599958139019, "biggest_recent_change": 0.08681831139793417},
{"total_number_of_episodes": 29633, "number_of_timesteps": 6673823, "per_episode_reward": -52.0, "episode_reward_trend_value": 0.004561681321614941, "biggest_recent_change": 0.08681831139793417},
{"total_number_of_episodes": 29643, "number_of_timesteps": 6676282, "per_episode_reward": -51.79, "episode_reward_trend_value": 0.0065650913172350545, "biggest_recent_change": 0.2085829974370199},
{"total_number_of_episodes": 29653, "number_of_timesteps": 6679814, "per_episode_reward": -51.74, "episode_reward_trend_value": 0.006817671566546895, "biggest_recent_change": 0.2085829974370199},
{"total_number_of_episodes": 29663, "number_of_timesteps": 6681734, "per_episode_reward": -51.73, "episode_reward_trend_value": 0.006690852970365234, "biggest_recent_change": 0.2085829974370199},
{"total_number_of_episodes": 29673, "number_of_timesteps": 6684993, "per_episode_reward": -51.71, "episode_reward_trend_value": 0.006359789234724171, "biggest_recent_change": 0.2085829974370199},
{"total_number_of_episodes": 29683, "number_of_timesteps": 6688140, "per_episode_reward": -51.69, "episode_reward_trend_value": 0.006011738338950244, "biggest_recent_change": 0.2085829974370199},
{"total_number_of_episodes": 29693, "number_of_timesteps": 6690083, "per_episode_reward": -51.67, "episode_reward_trend_value": 0.005890307002337715, "biggest_recent_change": 0.2085829974370199},
{"total_number_of_episodes": 29703, "number_of_timesteps": 6692132, "per_episode_reward": -51.63, "episode_reward_trend_value": 0.005851900273038603, "biggest_recent_change": 0.2085829974370199},
{"total_number_of_episodes": 29714, "number_of_timesteps": 6697546, "per_episode_reward": -51.58, "episode_reward_trend_value": 0.005401865126318404, "biggest_recent_change": 0.2085829974370199},
{"total_number_of_episodes": 29724, "number_of_timesteps": 6701761, "per_episode_reward": -51.54, "episode_reward_trend_value": 0.00511336893407059, "biggest_recent_change": 0.2085829974370199},
{"total_number_of_episodes": 29734, "number_of_timesteps": 6705196, "per_episode_reward": -51.49, "episode_reward_trend_value": 0.0033470672957759484, "biggest_recent_change": 0.05556879463746611},
{"total_number_of_episodes": 29744, "number_of_timesteps": 6708152, "per_episode_reward": -51.48, "episode_reward_trend_value": 0.0028544851739500782, "biggest_recent_change": 0.04961584999050217},
{"total_number_of_episodes": 29754, "number_of_timesteps": 6710628, "per_episode_reward": -51.47, "episode_reward_trend_value": 0.002875921516074224, "biggest_recent_change": 0.04961584999050217},
{"total_number_of_episodes": 29764, "number_of_timesteps": 6713762, "per_episode_reward": -51.45, "episode_reward_trend_value": 0.002858712586134813, "biggest_recent_change": 0.04961584999050217},
{"total_number_of_episodes": 29774, "number_of_timesteps": 6716681, "per_episode_reward": -51.43, "episode_reward_trend_value": 0.0029350802601482446, "biggest_recent_change": 0.04961584999050217},
{"total_number_of_episodes": 29784, "number_of_timesteps": 6721041, "per_episode_reward": -51.41, "episode_reward_trend_value": 0.002875085535944698, "biggest_recent_change": 0.04961584999050217},
{"total_number_of_episodes": 29794, "number_of_timesteps": 6723459, "per_episode_reward": -51.38, "episode_reward_trend_value": 0.002782193605067186, "biggest_recent_change": 0.04961584999050217},
{"total_number_of_episodes": 29804, "number_of_timesteps": 6726501, "per_episode_reward": -51.33, "episode_reward_trend_value": 0.0028021956210925697, "biggest_recent_change": 0.04961584999050217},
{"total_number_of_episodes": 29814, "number_of_timesteps": 6728245, "per_episode_reward": -51.3, "episode_reward_trend_value": 0.0026705978319648853, "biggest_recent_change": 0.04961584999050217},
{"total_number_of_episodes": 29824, "number_of_timesteps": 6730977, "per_episode_reward": -51.25, "episode_reward_trend_value": 0.0026716586989149645, "biggest_recent_change": 0.049711328016009304},
{"total_number_of_episodes": 29834, "number_of_timesteps": 6733035, "per_episode_reward": -51.22, "episode_reward_trend_value": 0.0029530505770722472, "biggest_recent_change": 0.049711328016009304},
{"total_number_of_episodes": 29844, "number_of_timesteps": 6737141, "per_episode_reward": -51.17, "episode_reward_trend_value": 0.003339222186156121, "biggest_recent_change": 0.049711328016009304},
{"total_number_of_episodes": 29854, "number_of_timesteps": 6740207, "per_episode_reward": -51.14, "episode_reward_trend_value": 0.0034594745676942455, "biggest_recent_change": 0.049711328016009304},
{"total_number_of_episodes": 29864, "number_of_timesteps": 6742420, "per_episode_reward": -51.11, "episode_reward_trend_value": 0.003483614266969129, "biggest_recent_change": 0.049711328016009304},
{"total_number_of_episodes": 29874, "number_of_timesteps": 6746112, "per_episode_reward": -51.05, "episode_reward_trend_value": 0.004017359624198255, "biggest_recent_change": 0.06930031614221832},
{"total_number_of_episodes": 29884, "number_of_timesteps": 6748373, "per_episode_reward": -51.02, "episode_reward_trend_value": 0.004047845986723707, "biggest_recent_change": 0.06930031614221832},
{"total_number_of_episodes": 29894, "number_of_timesteps": 6750952, "per_episode_reward": -50.99, "episode_reward_trend_value": 0.0037558234046740956, "biggest_recent_change": 0.06930031614221832},
{"total_number_of_episodes": 29904, "number_of_timesteps": 6754422, "per_episode_reward": -50.96, "episode_reward_trend_value": 0.0037993339142045578, "biggest_recent_change": 0.06930031614221832},
{"total_number_of_episodes": 29914, "number_of_timesteps": 6757240, "per_episode_reward": -50.8, "episode_reward_trend_value": 0.005025329418883552, "biggest_recent_change": 0.1600509234371188},
{"total_number_of_episodes": 29924, "number_of_timesteps": 6758790, "per_episode_reward": -50.77, "episode_reward_trend_value": 0.004990897479878242, "biggest_recent_change": 0.1600509234371188},
{"total_number_of_episodes": 29934, "number_of_timesteps": 6760523, "per_episode_reward": -50.73, "episode_reward_trend_value": 0.004987052584336264, "biggest_recent_change": 0.1600509234371188},
{"total_number_of_episodes": 29944, "number_of_timesteps": 6762394, "per_episode_reward": -50.68, "episode_reward_trend_value": 0.005099526997394498, "biggest_recent_change": 0.1600509234371188},
{"total_number_of_episodes": 29954, "number_of_timesteps": 6765636, "per_episode_reward": -50.66, "episode_reward_trend_value": 0.005000166217782089, "biggest_recent_change": 0.1600509234371188},
{"total_number_of_episodes": 29964, "number_of_timesteps": 6767457, "per_episode_reward": -50.64, "episode_reward_trend_value": 0.004498142619858925, "biggest_recent_change": 0.1600509234371188},
{"total_number_of_episodes": 29974, "number_of_timesteps": 6770712, "per_episode_reward": -50.6, "episode_reward_trend_value": 0.004562150419281133, "biggest_recent_change": 0.1600509234371188},
{"total_number_of_episodes": 29984, "number_of_timesteps": 6773099, "per_episode_reward": -50.56, "episode_reward_trend_value": 0.004830969369305017, "biggest_recent_change": 0.1600509234371188},
{"total_number_of_episodes": 29994, "number_of_timesteps": 6777245, "per_episode_reward": -50.5, "episode_reward_trend_value": 0.005073764944722509, "biggest_recent_change": 0.1600509234371188},
{"total_number_of_episodes": 30004, "number_of_timesteps": 6781093, "per_episode_reward": -50.48, "episode_reward_trend_value": 0.0034988933986491748, "biggest_recent_change": 0.05558627902261293},
{"total_number_of_episodes": 30014, "number_of_timesteps": 6784895, "per_episode_reward": -50.45, "episode_reward_trend_value": 0.0034786579233641625, "biggest_recent_change": 0.05558627902261293},
{"total_number_of_episodes": 30024, "number_of_timesteps": 6787903, "per_episode_reward": -50.43, "episode_reward_trend_value": 0.0033193792498969464, "biggest_recent_change": 0.05558627902261293},
{"total_number_of_episodes": 30034, "number_of_timesteps": 6790440, "per_episode_reward": -50.4, "episode_reward_trend_value": 0.0031448001847964395, "biggest_recent_change": 0.05558627902261293},
{"total_number_of_episodes": 30044, "number_of_timesteps": 6793633, "per_episode_reward": -50.35, "episode_reward_trend_value": 0.0035301297871241227, "biggest_recent_change": 0.05558627902261293},
{"total_number_of_episodes": 30054, "number_of_timesteps": 6796852, "per_episode_reward": -50.29, "episode_reward_trend_value": 0.00385243907541574, "biggest_recent_change": 0.05558627902261293},
{"total_number_of_episodes": 30064, "number_of_timesteps": 6800682, "per_episode_reward": -50.27, "episode_reward_trend_value": 0.003698147219948408, "biggest_recent_change": 0.05558627902261293},
{"total_number_of_episodes": 30074, "number_of_timesteps": 6805691, "per_episode_reward": -50.24, "episode_reward_trend_value": 0.003547646561977618, "biggest_recent_change": 0.05558627902261293},
{"total_number_of_episodes": 30084, "number_of_timesteps": 6809400, "per_episode_reward": -50.21, "episode_reward_trend_value": 0.0032520582494169523, "biggest_recent_change": 0.053126028275379156},
{"total_number_of_episodes": 30094, "number_of_timesteps": 6814250, "per_episode_reward": -50.18, "episode_reward_trend_value": 0.00336147087777129, "biggest_recent_change": 0.053126028275379156},
{"total_number_of_episodes": 30104, "number_of_timesteps": 6818237, "per_episode_reward": -50.15, "episode_reward_trend_value": 0.003376632877289075, "biggest_recent_change": 0.053126028275379156},
{"total_number_of_episodes": 30114, "number_of_timesteps": 6821701, "per_episode_reward": -50.12, "episode_reward_trend_value": 0.0034432764619405512, "biggest_recent_change": 0.053126028275379156},
{"total_number_of_episodes": 30124, "number_of_timesteps": 6824449, "per_episode_reward": -50.08, "episode_reward_trend_value": 0.0035006162022838, "biggest_recent_change": 0.053126028275379156},
{"total_number_of_episodes": 30135, "number_of_timesteps": 6829242, "per_episode_reward": -50.06, "episode_reward_trend_value": 0.003168910717585208, "biggest_recent_change": 0.053126028275379156},
{"total_number_of_episodes": 30145, "number_of_timesteps": 6832470, "per_episode_reward": -50.06, "episode_reward_trend_value": 0.002631096608662078, "biggest_recent_change": 0.034453345463035134},
{"total_number_of_episodes": 30155, "number_of_timesteps": 6837199, "per_episode_reward": -49.99, "episode_reward_trend_value": 0.003126105910263593, "biggest_recent_change": 0.06614951245619238},
{"total_number_of_episodes": 30165, "number_of_timesteps": 6841201, "per_episode_reward": -49.91, "episode_reward_trend_value": 0.003681122136378276, "biggest_recent_change": 0.0824334038860357},
{"total_number_of_episodes": 30175, "number_of_timesteps": 6845244, "per_episode_reward": -49.85, "episode_reward_trend_value": 0.004009202911107382, "biggest_recent_change": 0.0824334038860357},
{"total_number_of_episodes": 30185, "number_of_timesteps": 6850129, "per_episode_reward": -49.8, "episode_reward_trend_value": 0.004281646681806864, "biggest_recent_change": 0.0824334038860357},
{"total_number_of_episodes": 30195, "number_of_timesteps": 6855619, "per_episode_reward": -49.82, "episode_reward_trend_value": 0.003636197184430756, "biggest_recent_change": 0.0824334038860357},
{"total_number_of_episodes": 30205, "number_of_timesteps": 6858443, "per_episode_reward": -49.78, "episode_reward_trend_value": 0.003724161549867628, "biggest_recent_change": 0.0824334038860357},
{"total_number_of_episodes": 30215, "number_of_timesteps": 6861666, "per_episode_reward": -49.76, "episode_reward_trend_value": 0.0036129329389856775, "biggest_recent_change": 0.0824334038860357},
{"total_number_of_episodes": 30225, "number_of_timesteps": 6864562, "per_episode_reward": -49.73, "episode_reward_trend_value": 0.0036694958458895937, "biggest_recent_change": 0.0824334038860357},
{"total_number_of_episodes": 30235, "number_of_timesteps": 6867912, "per_episode_reward": -49.71, "episode_reward_trend_value": 0.0038069588808959847, "biggest_recent_change": 0.0824334038860357},
{"total_number_of_episodes": 30246, "number_of_timesteps": 6870522, "per_episode_reward": -49.69, "episode_reward_trend_value": 0.003379668140375082, "biggest_recent_change": 0.0824334038860357},
{"total_number_of_episodes": 30256, "number_of_timesteps": 6873038, "per_episode_reward": -49.66, "episode_reward_trend_value": 0.0027907328437940747, "biggest_recent_change": 0.05851060061777247},
{"total_number_of_episodes": 30267, "number_of_timesteps": 6876750, "per_episode_reward": -49.62, "episode_reward_trend_value": 0.00259688535003551, "biggest_recent_change": 0.05267956020536246},
{"total_number_of_episodes": 30277, "number_of_timesteps": 6879379, "per_episode_reward": -49.57, "episode_reward_trend_value": 0.002523145392032294, "biggest_recent_change": 0.046042963985073015},
{"total_number_of_episodes": 30287, "number_of_timesteps": 6881466, "per_episode_reward": -49.55, "episode_reward_trend_value": 0.003001904217959448, "biggest_recent_change": 0.046042963985073015},
{"total_number_of_episodes": 30298, "number_of_timesteps": 6884433, "per_episode_reward": -49.51, "episode_reward_trend_value": 0.00307158038977704, "biggest_recent_change": 0.04690510823263594},
{"total_number_of_episodes": 30308, "number_of_timesteps": 6886979, "per_episode_reward": -49.43, "episode_reward_trend_value": 0.0035906931328229226, "biggest_recent_change": 0.07116291735778901},
{"total_number_of_episodes": 30318, "number_of_timesteps": 6889135, "per_episode_reward": -49.38, "episode_reward_trend_value": 0.003941627287964798, "biggest_recent_change": 0.07116291735778901},
{"total_number_of_episodes": 30328, "number_of_timesteps": 6892713, "per_episode_reward": -49.36, "episode_reward_trend_value": 0.003888874956780973, "biggest_recent_change": 0.07116291735778901},
{"total_number_of_episodes": 30338, "number_of_timesteps": 6895773, "per_episode_reward": -49.35, "episode_reward_trend_value": 0.003721075462096874, "biggest_recent_change": 0.07116291735778901},
{"total_number_of_episodes": 30348, "number_of_timesteps": 6900602, "per_episode_reward": -49.33, "episode_reward_trend_value": 0.003578937402671932, "biggest_recent_change": 0.07116291735778901},
{"total_number_of_episodes": 30358, "number_of_timesteps": 6904757, "per_episode_reward": -49.3, "episode_reward_trend_value": 0.003551019462321155, "biggest_recent_change": 0.07116291735778901},
{"total_number_of_episodes": 30368, "number_of_timesteps": 6908644, "per_episode_reward": -49.27, "episode_reward_trend_value": 0.0033515517043130197, "biggest_recent_change": 0.07116291735778901},
{"total_number_of_episodes": 30378, "number_of_timesteps": 6911725, "per_episode_reward": -49.23, "episode_reward_trend_value": 0.0035648030698356573, "biggest_recent_change": 0.07116291735778901},
{"total_number_of_episodes": 30388, "number_of_timesteps": 6915345, "per_episode_reward": -49.16, "episode_reward_trend_value": 0.0038143142552824667, "biggest_recent_change": 0.07116291735778901},
{"total_number_of_episodes": 30398, "number_of_timesteps": 6918499, "per_episode_reward": -49.07, "episode_reward_trend_value": 0.0040883465681710775, "biggest_recent_change": 0.09582582551776397},
{"total_number_of_episodes": 30408, "number_of_timesteps": 6920865, "per_episode_reward": -49.04, "episode_reward_trend_value": 0.0037877062331317128, "biggest_recent_change": 0.09582582551776397},
{"total_number_of_episodes": 30418, "number_of_timesteps": 6922848, "per_episode_reward": -49.0, "episode_reward_trend_value": 0.0040084126113976975, "biggest_recent_change": 0.09582582551776397},
{"total_number_of_episodes": 30428, "number_of_timesteps": 6925340, "per_episode_reward": -48.96, "episode_reward_trend_value": 0.004399046649703959, "biggest_recent_change": 0.09582582551776397},
{"total_number_of_episodes": 30438, "number_of_timesteps": 6928707, "per_episode_reward": -48.9, "episode_reward_trend_value": 0.004884699930817741, "biggest_recent_change": 0.09582582551776397},
{"total_number_of_episodes": 30448, "number_of_timesteps": 6932481, "per_episode_reward": -48.86, "episode_reward_trend_value": 0.004826832761634452, "biggest_recent_change": 0.09582582551776397},
{"total_number_of_episodes": 30458, "number_of_timesteps": 6937271, "per_episode_reward": -48.84, "episode_reward_trend_value": 0.004771614792176453, "biggest_recent_change": 0.09582582551776397},
{"total_number_of_episodes": 30468, "number_of_timesteps": 6940002, "per_episode_reward": -48.8, "episode_reward_trend_value": 0.00474155509981205, "biggest_recent_change": 0.09582582551776397},
{"total_number_of_episodes": 30478, "number_of_timesteps": 6943152, "per_episode_reward": -48.78, "episode_reward_trend_value": 0.004218861032127405, "biggest_recent_change": 0.09582582551776397},
{"total_number_of_episodes": 30488, "number_of_timesteps": 6946307, "per_episode_reward": -48.67, "episode_reward_trend_value": 0.004420672505047128, "biggest_recent_change": 0.11398885808053905},
{"total_number_of_episodes": 30498, "number_of_timesteps": 6949547, "per_episode_reward": -48.64, "episode_reward_trend_value": 0.0044236877091864335, "biggest_recent_change": 0.11398885808053905},
{"total_number_of_episodes": 30508, "number_of_timesteps": 6954189, "per_episode_reward": -48.59, "episode_reward_trend_value": 0.004587333965207721, "biggest_recent_change": 0.11398885808053905},
{"total_number_of_episodes": 30518, "number_of_timesteps": 6957154, "per_episode_reward": -48.55, "episode_reward_trend_value": 0.004556868124187395, "biggest_recent_change": 0.11398885808053905},
{"total_number_of_episodes": 30529, "number_of_timesteps": 6961150, "per_episode_reward": -48.48, "episode_reward_trend_value": 0.004568001353602034, "biggest_recent_change": 0.11398885808053905},
{"total_number_of_episodes": 30540, "number_of_timesteps": 6964743, "per_episode_reward": -48.45, "episode_reward_trend_value": 0.0046071029288687745, "biggest_recent_change": 0.11398885808053905},
{"total_number_of_episodes": 30550, "number_of_timesteps": 6968000, "per_episode_reward": -48.35, "episode_reward_trend_value": 0.0054039094076216545, "biggest_recent_change": 0.11398885808053905},
{"total_number_of_episodes": 30561, "number_of_timesteps": 6970582, "per_episode_reward": -48.33, "episode_reward_trend_value": 0.005295237607141464, "biggest_recent_change": 0.11398885808053905},
{"total_number_of_episodes": 30572, "number_of_timesteps": 6973868, "per_episode_reward": -48.18, "episode_reward_trend_value": 0.006663821604867811, "biggest_recent_change": 0.14549120862660203},
{"total_number_of_episodes": 30582, "number_of_timesteps": 6976852, "per_episode_reward": -48.13, "episode_reward_trend_value": 0.006031909131351654, "biggest_recent_change": 0.14549120862660203},
{"total_number_of_episodes": 30592, "number_of_timesteps": 6980603, "per_episode_reward": -48.11, "episode_reward_trend_value": 0.005812614462883343, "biggest_recent_change": 0.14549120862660203},
{"total_number_of_episodes": 30602, "number_of_timesteps": 6983756, "per_episode_reward": -48.08, "episode_reward_trend_value": 0.005635453761103943, "biggest_recent_change": 0.14549120862660203},
{"total_number_of_episodes": 30612, "number_of_timesteps": 6987167, "per_episode_reward": -48.03, "episode_reward_trend_value": 0.0057417769073140335, "biggest_recent_change": 0.14549120862660203},
{"total_number_of_episodes": 30622, "number_of_timesteps": 6990685, "per_episode_reward": -47.99, "episode_reward_trend_value": 0.005500210837176035, "biggest_recent_change": 0.14549120862660203},

{"total_number_of_episodes": 30632, "number_of_timesteps": 6993548, "per_episode_reward": -47.92, "episode_reward_trend_value": 0.005870607720085511, "biggest_recent_change": 0.14549120862660203},
{"total_number_of_episodes": 30642, "number_of_timesteps": 6996316, "per_episode_reward": -47.9, "episode_reward_trend_value": 0.00507686743635042, "biggest_recent_change": 0.14549120862660203},
{"total_number_of_episodes": 30652, "number_of_timesteps": 6999260, "per_episode_reward": -47.86, "episode_reward_trend_value": 0.005183588753722291, "biggest_recent_change": 0.14549120862660203},
{"total_number_of_episodes": 30662, "number_of_timesteps": 7003145, "per_episode_reward": -47.78, "episode_reward_trend_value": 0.004522921152231874, "biggest_recent_change": 0.08603112449246453},
{"total_number_of_episodes": 30672, "number_of_timesteps": 7007143, "per_episode_reward": -47.74, "episode_reward_trend_value": 0.004305485437463593, "biggest_recent_change": 0.08603112449246453},
{"total_number_of_episodes": 30683, "number_of_timesteps": 7011686, "per_episode_reward": -47.71, "episode_reward_trend_value": 0.004476673896150866, "biggest_recent_change": 0.08603112449246453},
{"total_number_of_episodes": 30693, "number_of_timesteps": 7015597, "per_episode_reward": -47.64, "episode_reward_trend_value": 0.004926968481069909, "biggest_recent_change": 0.08603112449246453},
{"total_number_of_episodes": 30703, "number_of_timesteps": 7020023, "per_episode_reward": -47.62, "episode_reward_trend_value": 0.004575038643477885, "biggest_recent_change": 0.08603112449246453},
{"total_number_of_episodes": 30714, "number_of_timesteps": 7024838, "per_episode_reward": -47.61, "episode_reward_trend_value": 0.004246982761708691, "biggest_recent_change": 0.08603112449246453},
{"total_number_of_episodes": 30724, "number_of_timesteps": 7029066, "per_episode_reward": -47.59, "episode_reward_trend_value": 0.003672765318883759, "biggest_recent_change": 0.08603112449246453},
{"total_number_of_episodes": 30734, "number_of_timesteps": 7032917, "per_episode_reward": -47.55, "episode_reward_trend_value": 0.0038537533952257438, "biggest_recent_change": 0.08603112449246453},
{"total_number_of_episodes": 30744, "number_of_timesteps": 7037014, "per_episode_reward": -47.51, "episode_reward_trend_value": 0.0038586044367770163, "biggest_recent_change": 0.08603112449246453},
{"total_number_of_episodes": 30754, "number_of_timesteps": 7041366, "per_episode_reward": -47.5, "episode_reward_trend_value": 0.003099068270925503, "biggest_recent_change": 0.07152050838475077},
{"total_number_of_episodes": 30764, "number_of_timesteps": 7044177, "per_episode_reward": -47.47, "episode_reward_trend_value": 0.003025560460564394, "biggest_recent_change": 0.07152050838475077},
{"total_number_of_episodes": 30774, "number_of_timesteps": 7046755, "per_episode_reward": -47.45, "episode_reward_trend_value": 0.002896112019141523, "biggest_recent_change": 0.07152050838475077},
{"total_number_of_episodes": 30784, "number_of_timesteps": 7049712, "per_episode_reward": -47.42, "episode_reward_trend_value": 0.0023984932128933503, "biggest_recent_change": 0.039686132935500495},
{"total_number_of_episodes": 30794, "number_of_timesteps": 7053561, "per_episode_reward": -47.36, "episode_reward_trend_value": 0.0028617012343107244, "biggest_recent_change": 0.06459064874666609},
{"total_number_of_episodes": 30804, "number_of_timesteps": 7055772, "per_episode_reward": -47.26, "episode_reward_trend_value": 0.0038029831618716673, "biggest_recent_change": 0.09479698560189576},
{"total_number_of_episodes": 30814, "number_of_timesteps": 7058716, "per_episode_reward": -47.25, "episode_reward_trend_value": 0.003811227843717941, "biggest_recent_change": 0.09479698560189576},
{"total_number_of_episodes": 30824, "number_of_timesteps": 7061417, "per_episode_reward": -47.17, "episode_reward_trend_value": 0.004199885042960085, "biggest_recent_change": 0.09479698560189576},
{"total_number_of_episodes": 30834, "number_of_timesteps": 7064676, "per_episode_reward": -47.11, "episode_reward_trend_value": 0.004456360381049191, "biggest_recent_change": 0.09479698560189576},
{"total_number_of_episodes": 30845, "number_of_timesteps": 7070285, "per_episode_reward": -47.07, "episode_reward_trend_value": 0.004737407151553125, "biggest_recent_change": 0.09479698560189576},

{"total_number_of_episodes": 30855, "number_of_timesteps": 7073535, "per_episode_reward": -47.04, "episode_reward_trend_value": 0.004683833070463095, "biggest_recent_change": 0.09479698560189576},
{"total_number_of_episodes": 30865, "number_of_timesteps": 7076567, "per_episode_reward": -47.02, "episode_reward_trend_value": 0.004778325060526435, "biggest_recent_change": 0.09479698560189576},
{"total_number_of_episodes": 30875, "number_of_timesteps": 7079726, "per_episode_reward": -47.0, "episode_reward_trend_value": 0.004727323665482825, "biggest_recent_change": 0.09479698560189576},

{"total_number_of_episodes": 30885, "number_of_timesteps": 7083633, "per_episode_reward": -46.97, "episode_reward_trend_value": 0.004358781033256617, "biggest_recent_change": 0.09479698560189576},
{"total_number_of_episodes": 30895, "number_of_timesteps": 7087392, "per_episode_reward": -46.93, "episode_reward_trend_value": 0.003726960788371514, "biggest_recent_change": 0.0746652808672934},
{"total_number_of_episodes": 30905, "number_of_timesteps": 7089952, "per_episode_reward": -46.87, "episode_reward_trend_value": 0.0041383576823197325, "biggest_recent_change": 0.0746652808672934},
{"total_number_of_episodes": 30915, "number_of_timesteps": 7093738, "per_episode_reward": -46.84, "episode_reward_trend_value": 0.00372225578854347, "biggest_recent_change": 0.05783510621948551},
{"total_number_of_episodes": 30925, "number_of_timesteps": 7097474, "per_episode_reward": -46.79, "episode_reward_trend_value": 0.003550660085012049, "biggest_recent_change": 0.05628669952455567},
{"total_number_of_episodes": 30935, "number_of_timesteps": 7101412, "per_episode_reward": -46.78, "episode_reward_trend_value": 0.0032153757876998493, "biggest_recent_change": 0.05628669952455567},
{"total_number_of_episodes": 30945, "number_of_timesteps": 7103952, "per_episode_reward": -46.74, "episode_reward_trend_value": 0.003410337023053719, "biggest_recent_change": 0.05628669952455567},
{"total_number_of_episodes": 30955, "number_of_timesteps": 7107303, "per_episode_reward": -46.68, "episode_reward_trend_value": 0.0037638962392660368, "biggest_recent_change": 0.05628669952455567},
{"total_number_of_episodes": 30965, "number_of_timesteps": 7109530, "per_episode_reward": -46.66, "episode_reward_trend_value": 0.003771796107442308, "biggest_recent_change": 0.05628669952455567},
{"total_number_of_episodes": 30975, "number_of_timesteps": 7112214, "per_episode_reward": -46.64, "episode_reward_trend_value": 0.0036451111362607, "biggest_recent_change": 0.05628669952455567},
{"total_number_of_episodes": 30985, "number_of_timesteps": 7114614, "per_episode_reward": -46.59, "episode_reward_trend_value": 0.0037609556888821456, "biggest_recent_change": 0.05628669952455567},
{"total_number_of_episodes": 30995, "number_of_timesteps": 7117633, "per_episode_reward": -46.56, "episode_reward_trend_value": 0.0035155208806814013, "biggest_recent_change": 0.05490853876399626},
{"total_number_of_episodes": 31005, "number_of_timesteps": 7121182, "per_episode_reward": -46.48, "episode_reward_trend_value": 0.003962306915464827, "biggest_recent_change": 0.0774268535579381},
{"total_number_of_episodes": 31015, "number_of_timesteps": 7124259, "per_episode_reward": -46.46, "episode_reward_trend_value": 0.003749420476316345, "biggest_recent_change": 0.0774268535579381},
{"total_number_of_episodes": 31025, "number_of_timesteps": 7127556, "per_episode_reward": -46.38, "episode_reward_trend_value": 0.004434241451477621, "biggest_recent_change": 0.0774268535579381},
{"total_number_of_episodes": 31035, "number_of_timesteps": 7133834, "per_episode_reward": -46.34, "episode_reward_trend_value": 0.004454440960227796, "biggest_recent_change": 0.0774268535579381},
{"total_number_of_episodes": 31045, "number_of_timesteps": 7136985, "per_episode_reward": -46.31, "episode_reward_trend_value": 0.004119516151999155, "biggest_recent_change": 0.0774268535579381},
{"total_number_of_episodes": 31055, "number_of_timesteps": 7142214, "per_episode_reward": -46.29, "episode_reward_trend_value": 0.004056281393029653, "biggest_recent_change": 0.0774268535579381},
{"total_number_of_episodes": 31065, "number_of_timesteps": 7146448, "per_episode_reward": -46.27, "episode_reward_trend_value": 0.004150140534307509, "biggest_recent_change": 0.0774268535579381},
{"total_number_of_episodes": 31075, "number_of_timesteps": 7149736, "per_episode_reward": -46.21, "episode_reward_trend_value": 0.004201549150999915, "biggest_recent_change": 0.0774268535579381},
{"total_number_of_episodes": 31085, "number_of_timesteps": 7154270, "per_episode_reward": -46.17, "episode_reward_trend_value": 0.004265925554692826, "biggest_recent_change": 0.0774268535579381},
{"total_number_of_episodes": 31095, "number_of_timesteps": 7157603, "per_episode_reward": -46.16, "episode_reward_trend_value": 0.003576465883014793, "biggest_recent_change": 0.07442537991759934},
{"total_number_of_episodes": 31105, "number_of_timesteps": 7160032, "per_episode_reward": -46.11, "episode_reward_trend_value": 0.003795258400053964, "biggest_recent_change": 0.07442537991759934},
{"total_number_of_episodes": 31115, "number_of_timesteps": 7163527, "per_episode_reward": -46.09, "episode_reward_trend_value": 0.0032870539683880254, "biggest_recent_change": 0.05298594880048313},
{"total_number_of_episodes": 31125, "number_of_timesteps": 7167636, "per_episode_reward": -46.07, "episode_reward_trend_value": 0.0029968379372576235, "biggest_recent_change": 0.05298594880048313},
{"total_number_of_episodes": 31135, "number_of_timesteps": 7172206, "per_episode_reward": -46.05, "episode_reward_trend_value": 0.0028630874758355336, "biggest_recent_change": 0.05298594880048313},
{"total_number_of_episodes": 31145, "number_of_timesteps": 7176599, "per_episode_reward": -46.02, "episode_reward_trend_value": 0.003018924721477529, "biggest_recent_change": 0.05298594880048313},
{"total_number_of_episodes": 31155, "number_of_timesteps": 7179319, "per_episode_reward": -45.99, "episode_reward_trend_value": 0.0030410795964441835, "biggest_recent_change": 0.05298594880048313},
{"total_number_of_episodes": 31165, "number_of_timesteps": 7181304, "per_episode_reward": -45.95, "episode_reward_trend_value": 0.0029186822888538997, "biggest_recent_change": 0.04292303991181967},
{"total_number_of_episodes": 31175, "number_of_timesteps": 7183832, "per_episode_reward": -45.9, "episode_reward_trend_value": 0.0030621015954724368, "biggest_recent_change": 0.052899180714518934},
{"total_number_of_episodes": 31185, "number_of_timesteps": 7186476, "per_episode_reward": -45.87, "episode_reward_trend_value": 0.0032136736133178403, "biggest_recent_change": 0.052899180714518934},
{"total_number_of_episodes": 31195, "number_of_timesteps": 7191403, "per_episode_reward": -45.82, "episode_reward_trend_value": 0.0032369509653699586, "biggest_recent_change": 0.052899180714518934},
{"total_number_of_episodes": 31205, "number_of_timesteps": 7193806, "per_episode_reward": -45.8, "episode_reward_trend_value": 0.0032075965020339934, "biggest_recent_change": 0.052899180714518934},
{"total_number_of_episodes": 31215, "number_of_timesteps": 7196587, "per_episode_reward": -45.77, "episode_reward_trend_value": 0.0033376700255596053, "biggest_recent_change": 0.052899180714518934},
{"total_number_of_episodes": 31225, "number_of_timesteps": 7199099, "per_episode_reward": -45.74, "episode_reward_trend_value": 0.0034688256529256654, "biggest_recent_change": 0.052899180714518934},
{"total_number_of_episodes": 31235, "number_of_timesteps": 7202513, "per_episode_reward": -45.72, "episode_reward_trend_value": 0.003327362693921208, "biggest_recent_change": 0.052899180714518934},
{"total_number_of_episodes": 31245, "number_of_timesteps": 7204932, "per_episode_reward": -45.66, "episode_reward_trend_value": 0.0036889329860872047, "biggest_recent_change": 0.06300275219690832},
{"total_number_of_episodes": 31255, "number_of_timesteps": 7208796, "per_episode_reward": -45.62, "episode_reward_trend_value": 0.0036538572734023155, "biggest_recent_change": 0.06300275219690832},
{"total_number_of_episodes": 31265, "number_of_timesteps": 7210808, "per_episode_reward": -45.61, "episode_reward_trend_value": 0.0031442273146697944, "biggest_recent_change": 0.06300275219690832},
{"total_number_of_episodes": 31275, "number_of_timesteps": 7213293, "per_episode_reward": -45.61, "episode_reward_trend_value": 0.002911640545537687, "biggest_recent_change": 0.06300275219690832},
{"total_number_of_episodes": 31285, "number_of_timesteps": 7215506, "per_episode_reward": -45.58, "episode_reward_trend_value": 0.0027453339705567083, "biggest_recent_change": 0.06300275219690832},
{"total_number_of_episodes": 31295, "number_of_timesteps": 7219172, "per_episode_reward": -45.56, "episode_reward_trend_value": 0.0026289724215593597, "biggest_recent_change": 0.06300275219690832},
{"total_number_of_episodes": 31306, "number_of_timesteps": 7223007, "per_episode_reward": -45.5, "episode_reward_trend_value": 0.0029277276854139857, "biggest_recent_change": 0.06300275219690832},
{"total_number_of_episodes": 31316, "number_of_timesteps": 7226243, "per_episode_reward": -45.45, "episode_reward_trend_value": 0.0032713413200664517, "biggest_recent_change": 0.06300275219690832},
{"total_number_of_episodes": 31326, "number_of_timesteps": 7228280, "per_episode_reward": -45.4, "episode_reward_trend_value": 0.0036164455042784504, "biggest_recent_change": 0.06300275219690832},
{"total_number_of_episodes": 31337, "number_of_timesteps": 7231571, "per_episode_reward": -45.33, "episode_reward_trend_value": 0.0036912443376336686, "biggest_recent_change": 0.06973464719887801},
{"total_number_of_episodes": 31347, "number_of_timesteps": 7234427, "per_episode_reward": -45.31, "episode_reward_trend_value": 0.0034178570685588576, "biggest_recent_change": 0.06973464719887801},
{"total_number_of_episodes": 31357, "number_of_timesteps": 7236397, "per_episode_reward": -45.28, "episode_reward_trend_value": 0.0036659193066646543, "biggest_recent_change": 0.06973464719887801},
{"total_number_of_episodes": 31367, "number_of_timesteps": 7238953, "per_episode_reward": -45.26, "episode_reward_trend_value": 0.0038810812658485678, "biggest_recent_change": 0.06973464719887801},
{"total_number_of_episodes": 31377, "number_of_timesteps": 7240818, "per_episode_reward": -45.24, "episode_reward_trend_value": 0.0037478644400290285, "biggest_recent_change": 0.06973464719887801},
{"total_number_of_episodes": 31388, "number_of_timesteps": 7243548, "per_episode_reward": -45.23, "episode_reward_trend_value": 0.003714116670840736, "biggest_recent_change": 0.06973464719887801},
{"total_number_of_episodes": 31398, "number_of_timesteps": 7245653, "per_episode_reward": -45.18, "episode_reward_trend_value": 0.003564610085678134, "biggest_recent_change": 0.06973464719887801},
{"total_number_of_episodes": 31408, "number_of_timesteps": 7248140, "per_episode_reward": -45.12, "episode_reward_trend_value": 0.0036600786626506316, "biggest_recent_change": 0.06973464719887801},
{"total_number_of_episodes": 31418, "number_of_timesteps": 7250746, "per_episode_reward": -45.08, "episode_reward_trend_value": 0.0035788791151398574, "biggest_recent_change": 0.06973464719887801},
{"total_number_of_episodes": 31428, "number_of_timesteps": 7252811, "per_episode_reward": -45.03, "episode_reward_trend_value": 0.00326519930463631, "biggest_recent_change": 0.06404917000462262},
{"total_number_of_episodes": 31438, "number_of_timesteps": 7256124, "per_episode_reward": -44.97, "episode_reward_trend_value": 0.003865276342252441, "biggest_recent_change": 0.06821545614443636},
{"total_number_of_episodes": 31448, "number_of_timesteps": 7257952, "per_episode_reward": -44.9, "episode_reward_trend_value": 0.00426025183549691, "biggest_recent_change": 0.06821545614443636},
{"total_number_of_episodes": 31458, "number_of_timesteps": 7260313, "per_episode_reward": -44.87, "episode_reward_trend_value": 0.004309600470880623, "biggest_recent_change": 0.06821545614443636},
{"total_number_of_episodes": 31468, "number_of_timesteps": 7263077, "per_episode_reward": -44.84, "episode_reward_trend_value": 0.00441722515588986, "biggest_recent_change": 0.06821545614443636},
{"total_number_of_episodes": 31478, "number_of_timesteps": 7266963, "per_episode_reward": -44.77, "episode_reward_trend_value": 0.005110277019524842, "biggest_recent_change": 0.07490990845786882},
{"total_number_of_episodes": 31488, "number_of_timesteps": 7270312, "per_episode_reward": -44.73, "episode_reward_trend_value": 0.004990749619810231, "biggest_recent_change": 0.07490990845786882},
{"total_number_of_episodes": 31498, "number_of_timesteps": 7275076, "per_episode_reward": -44.7, "episode_reward_trend_value": 0.004664253143494631, "biggest_recent_change": 0.07490990845786882},
{"total_number_of_episodes": 31508, "number_of_timesteps": 7276854, "per_episode_reward": -44.68, "episode_reward_trend_value": 0.00442672723524598, "biggest_recent_change": 0.07490990845786882},
{"total_number_of_episodes": 31518, "number_of_timesteps": 7278578, "per_episode_reward": -44.65, "episode_reward_trend_value": 0.004247427807144769, "biggest_recent_change": 0.07490990845786882},
{"total_number_of_episodes": 31528, "number_of_timesteps": 7280263, "per_episode_reward": -44.6, "episode_reward_trend_value": 0.004043034994389356, "biggest_recent_change": 0.07490990845786882},
{"total_number_of_episodes": 31538, "number_of_timesteps": 7281890, "per_episode_reward": -44.58, "episode_reward_trend_value": 0.003561531274202739, "biggest_recent_change": 0.07490990845786882},
{"total_number_of_episodes": 31548, "number_of_timesteps": 7285091, "per_episode_reward": -44.52, "episode_reward_trend_value": 0.0038324887441258206, "biggest_recent_change": 0.07490990845786882},
{"total_number_of_episodes": 31558, "number_of_timesteps": 7287849, "per_episode_reward": -44.48, "episode_reward_trend_value": 0.004058852767585661, "biggest_recent_change": 0.07490990845786882},
{"total_number_of_episodes": 31568, "number_of_timesteps": 7290246, "per_episode_reward": -44.43, "episode_reward_trend_value": 0.003741734227941388, "biggest_recent_change": 0.05627628129527551},
{"total_number_of_episodes": 31578, "number_of_timesteps": 7292548, "per_episode_reward": -44.4, "episode_reward_trend_value": 0.003729871448131345, "biggest_recent_change": 0.05627628129527551},
{"total_number_of_episodes": 31588, "number_of_timesteps": 7294368, "per_episode_reward": -44.36, "episode_reward_trend_value": 0.003763978883888244, "biggest_recent_change": 0.05627628129527551},
{"total_number_of_episodes": 31598, "number_of_timesteps": 7296763, "per_episode_reward": -44.29, "episode_reward_trend_value": 0.004338704793185618, "biggest_recent_change": 0.07255765329197317},
{"total_number_of_episodes": 31608, "number_of_timesteps": 7300778, "per_episode_reward": -44.25, "episode_reward_trend_value": 0.004436875370652002, "biggest_recent_change": 0.07255765329197317},
{"total_number_of_episodes": 31618, "number_of_timesteps": 7305103, "per_episode_reward": -44.22, "episode_reward_trend_value": 0.004236749721890397, "biggest_recent_change": 0.07255765329197317},
{"total_number_of_episodes": 31629, "number_of_timesteps": 7308539, "per_episode_reward": -44.19, "episode_reward_trend_value": 0.004324615724636121, "biggest_recent_change": 0.07255765329197317},
{"total_number_of_episodes": 31639, "number_of_timesteps": 7310955, "per_episode_reward": -44.16, "episode_reward_trend_value": 0.0040153154314973155, "biggest_recent_change": 0.07255765329197317},
{"total_number_of_episodes": 31649, "number_of_timesteps": 7315482, "per_episode_reward": -44.15, "episode_reward_trend_value": 0.003629467786916902, "biggest_recent_change": 0.07255765329197317},
{"total_number_of_episodes": 31659, "number_of_timesteps": 7317993, "per_episode_reward": -44.14, "episode_reward_trend_value": 0.003268445286890101, "biggest_recent_change": 0.07255765329197317},
{"total_number_of_episodes": 31669, "number_of_timesteps": 7321871, "per_episode_reward": -44.08, "episode_reward_trend_value": 0.003467306266022677, "biggest_recent_change": 0.07255765329197317},
{"total_number_of_episodes": 31679, "number_of_timesteps": 7324534, "per_episode_reward": -44.04, "episode_reward_trend_value": 0.0035345639207230465, "biggest_recent_change": 0.07255765329197317},
{"total_number_of_episodes": 31689, "number_of_timesteps": 7327193, "per_episode_reward": -44.01, "episode_reward_trend_value": 0.003043342186401945, "biggest_recent_change": 0.050566545236264915},
{"total_number_of_episodes": 31699, "number_of_timesteps": 7329430, "per_episode_reward": -44.0, "episode_reward_trend_value": 0.002838633704780433, "biggest_recent_change": 0.050566545236264915},
{"total_number_of_episodes": 31709, "number_of_timesteps": 7332642, "per_episode_reward": -43.97, "episode_reward_trend_value": 0.0027491997629499093, "biggest_recent_change": 0.050566545236264915},
{"total_number_of_episodes": 31719, "number_of_timesteps": 7338047, "per_episode_reward": -43.96, "episode_reward_trend_value": 0.00255746691603578, "biggest_recent_change": 0.050566545236264915},
{"total_number_of_episodes": 31729, "number_of_timesteps": 7340322, "per_episode_reward": -43.94, "episode_reward_trend_value": 0.00249137429425564, "biggest_recent_change": 0.050566545236264915},
{"total_number_of_episodes": 31739, "number_of_timesteps": 7342483, "per_episode_reward": -43.92, "episode_reward_trend_value": 0.0025216989054730418, "biggest_recent_change": 0.050566545236264915},
{"total_number_of_episodes": 31749, "number_of_timesteps": 7344597, "per_episode_reward": -43.9, "episode_reward_trend_value": 0.0026338804761039114, "biggest_recent_change": 0.050566545236264915},
{"total_number_of_episodes": 31759, "number_of_timesteps": 7349216, "per_episode_reward": -43.88, "episode_reward_trend_value": 0.0022387998127966413, "biggest_recent_change": 0.043787345277372935},
{"total_number_of_episodes": 31769, "number_of_timesteps": 7353223, "per_episode_reward": -43.8, "episode_reward_trend_value": 0.002722691817921212, "biggest_recent_change": 0.08733762573858428},
{"total_number_of_episodes": 31779, "number_of_timesteps": 7356594, "per_episode_reward": -43.77, "episode_reward_trend_value": 0.0027468798144677778, "biggest_recent_change": 0.08733762573858428},
{"total_number_of_episodes": 31789, "number_of_timesteps": 7360124, "per_episode_reward": -43.74, "episode_reward_trend_value": 0.0028546790222613084, "biggest_recent_change": 0.08733762573858428},
{"total_number_of_episodes": 31799, "number_of_timesteps": 7364973, "per_episode_reward": -43.67, "episode_reward_trend_value": 0.0033860818457877744, "biggest_recent_change": 0.08733762573858428},
{"total_number_of_episodes": 31809, "number_of_timesteps": 7367440, "per_episode_reward": -43.6, "episode_reward_trend_value": 0.003984597194119664, "biggest_recent_change": 0.08733762573858428},
{"total_number_of_episodes": 31820, "number_of_timesteps": 7371461, "per_episode_reward": -43.57, "episode_reward_trend_value": 0.0041243469374395636, "biggest_recent_change": 0.08733762573858428},
{"total_number_of_episodes": 31830, "number_of_timesteps": 7374892, "per_episode_reward": -43.51, "episode_reward_trend_value": 0.00459694613245642, "biggest_recent_change": 0.08733762573858428},
{"total_number_of_episodes": 31840, "number_of_timesteps": 7377867, "per_episode_reward": -43.46, "episode_reward_trend_value": 0.0048817326097560475, "biggest_recent_change": 0.08733762573858428},
{"total_number_of_episodes": 31850, "number_of_timesteps": 7382154, "per_episode_reward": -43.44, "episode_reward_trend_value": 0.004960225129536235, "biggest_recent_change": 0.08733762573858428},

{"total_number_of_episodes": 31860, "number_of_timesteps": 7386489, "per_episode_reward": -43.35, "episode_reward_trend_value": 0.004984749590809261, "biggest_recent_change": 0.08954482725315671},
{"total_number_of_episodes": 31870, "number_of_timesteps": 7391155, "per_episode_reward": -43.32, "episode_reward_trend_value": 0.004896174967364667, "biggest_recent_change": 0.08954482725315671},
{"total_number_of_episodes": 31880, "number_of_timesteps": 7394546, "per_episode_reward": -43.32, "episode_reward_trend_value": 0.004690131420471033, "biggest_recent_change": 0.08954482725315671},
{"total_number_of_episodes": 31890, "number_of_timesteps": 7398596, "per_episode_reward": -43.29, "episode_reward_trend_value": 0.0042357007074513495, "biggest_recent_change": 0.08954482725315671},
{"total_number_of_episodes": 31900, "number_of_timesteps": 7402793, "per_episode_reward": -43.25, "episode_reward_trend_value": 0.003913632305934871, "biggest_recent_change": 0.08954482725315671},
{"total_number_of_episodes": 31910, "number_of_timesteps": 7407438, "per_episode_reward": -43.23, "episode_reward_trend_value": 0.0037397533063404527, "biggest_recent_change": 0.08954482725315671},
{"total_number_of_episodes": 31920, "number_of_timesteps": 7413641, "per_episode_reward": -43.21, "episode_reward_trend_value": 0.0032867611518841815, "biggest_recent_change": 0.08954482725315671},
{"total_number_of_episodes": 31930, "number_of_timesteps": 7416866, "per_episode_reward": -43.17, "episode_reward_trend_value": 0.003157840485910965, "biggest_recent_change": 0.08954482725315671},
{"total_number_of_episodes": 31940, "number_of_timesteps": 7421141, "per_episode_reward": -43.15, "episode_reward_trend_value": 0.0031724542389708196, "biggest_recent_change": 0.08954482725315671},
{"total_number_of_episodes": 31950, "number_of_timesteps": 7425005, "per_episode_reward": -43.11, "episode_reward_trend_value": 0.002594594469958464, "biggest_recent_change": 0.0380014792636274},
{"total_number_of_episodes": 31960, "number_of_timesteps": 7428041, "per_episode_reward": -43.07, "episode_reward_trend_value": 0.002866137656080288, "biggest_recent_change": 0.046991787533215756},
{"total_number_of_episodes": 31970, "number_of_timesteps": 7431704, "per_episode_reward": -43.02, "episode_reward_trend_value": 0.0032541692966893106, "biggest_recent_change": 0.046991787533215756},
{"total_number_of_episodes": 31980, "number_of_timesteps": 7434896, "per_episode_reward": -43.0, "episode_reward_trend_value": 0.003236850462866809, "biggest_recent_change": 0.046991787533215756},
{"total_number_of_episodes": 31990, "number_of_timesteps": 7437767, "per_episode_reward": -42.97, "episode_reward_trend_value": 0.003135506357225637, "biggest_recent_change": 0.046991787533215756},
{"total_number_of_episodes": 32000, "number_of_timesteps": 7440496, "per_episode_reward": -42.95, "episode_reward_trend_value": 0.003135453585144177, "biggest_recent_change": 0.046991787533215756},
{"total_number_of_episodes": 32010, "number_of_timesteps": 7443380, "per_episode_reward": -42.93, "episode_reward_trend_value": 0.003171167073841256, "biggest_recent_change": 0.046991787533215756},
{"total_number_of_episodes": 32020, "number_of_timesteps": 7446969, "per_episode_reward": -42.91, "episode_reward_trend_value": 0.002942932665977575, "biggest_recent_change": 0.046991787533215756},
{"total_number_of_episodes": 32030, "number_of_timesteps": 7450601, "per_episode_reward": -42.91, "episode_reward_trend_value": 0.0027207873227096018, "biggest_recent_change": 0.046991787533215756},
{"total_number_of_episodes": 32040, "number_of_timesteps": 7454226, "per_episode_reward": -42.88, "episode_reward_trend_value": 0.0026420021719339103, "biggest_recent_change": 0.046991787533215756},
{"total_number_of_episodes": 32050, "number_of_timesteps": 7457361, "per_episode_reward": -42.85, "episode_reward_trend_value": 0.002448264292473033, "biggest_recent_change": 0.04185896148629098},
{"total_number_of_episodes": 32060, "number_of_timesteps": 7459903, "per_episode_reward": -42.84, "episode_reward_trend_value": 0.002010928912935049, "biggest_recent_change": 0.03044678447223248},
{"total_number_of_episodes": 32070, "number_of_timesteps": 7464157, "per_episode_reward": -42.83, "episode_reward_trend_value": 0.0018462225337213707, "biggest_recent_change": 0.03044678447223248},
{"total_number_of_episodes": 32080, "number_of_timesteps": 7467001, "per_episode_reward": -42.81, "episode_reward_trend_value": 0.0017534468592891983, "biggest_recent_change": 0.03044678447223248},
{"total_number_of_episodes": 32090, "number_of_timesteps": 7473608, "per_episode_reward": -42.79, "episode_reward_trend_value": 0.0017179942618672013, "biggest_recent_change": 0.03044678447223248},
{"total_number_of_episodes": 32100, "number_of_timesteps": 7476490, "per_episode_reward": -42.77, "episode_reward_trend_value": 0.0017861371311941494, "biggest_recent_change": 0.03044678447223248},
{"total_number_of_episodes": 32110, "number_of_timesteps": 7480580, "per_episode_reward": -42.71, "episode_reward_trend_value": 0.0022043783938177812, "biggest_recent_change": 0.055102096192023},
{"total_number_of_episodes": 32120, "number_of_timesteps": 7483494, "per_episode_reward": -42.56, "episode_reward_trend_value": 0.0038244019798291617, "biggest_recent_change": 0.14919789194112099},
{"total_number_of_episodes": 32130, "number_of_timesteps": 7486417, "per_episode_reward": -42.51, "episode_reward_trend_value": 0.004063548604428588, "biggest_recent_change": 0.14919789194112099},
{"total_number_of_episodes": 32140, "number_of_timesteps": 7489386, "per_episode_reward": -42.46, "episode_reward_trend_value": 0.00433601453371845, "biggest_recent_change": 0.14919789194112099},
{"total_number_of_episodes": 32150, "number_of_timesteps": 7492104, "per_episode_reward": -42.39, "episode_reward_trend_value": 0.0050662247699150165, "biggest_recent_change": 0.14919789194112099},
{"total_number_of_episodes": 32160, "number_of_timesteps": 7495061, "per_episode_reward": -42.35, "episode_reward_trend_value": 0.0053315194677741335, "biggest_recent_change": 0.14919789194112099},

{"total_number_of_episodes": 32170, "number_of_timesteps": 7497311, "per_episode_reward": -42.32, "episode_reward_trend_value": 0.005425236911046719, "biggest_recent_change": 0.14919789194112099},
{"total_number_of_episodes": 32180, "number_of_timesteps": 7499791, "per_episode_reward": -42.28, "episode_reward_trend_value": 0.005703969741743561, "biggest_recent_change": 0.14919789194112099},
{"total_number_of_episodes": 32190, "number_of_timesteps": 7503216, "per_episode_reward": -42.22, "episode_reward_trend_value": 0.006034774941774638, "biggest_recent_change": 0.14919789194112099},
{"total_number_of_episodes": 32200, "number_of_timesteps": 7507867, "per_episode_reward": -42.19, "episode_reward_trend_value": 0.0058165159059775816, "biggest_recent_change": 0.14919789194112099},
{"total_number_of_episodes": 32210, "number_of_timesteps": 7510678, "per_episode_reward": -42.15, "episode_reward_trend_value": 0.004613942842464288, "biggest_recent_change": 0.06821769858556337},
{"total_number_of_episodes": 32221, "number_of_timesteps": 7513798, "per_episode_reward": -42.04, "episode_reward_trend_value": 0.00527977196823228, "biggest_recent_change": 0.11189460200530021},
{"total_number_of_episodes": 32231, "number_of_timesteps": 7517187, "per_episode_reward": -42.0, "episode_reward_trend_value": 0.005117553032878814, "biggest_recent_change": 0.11189460200530021},
{"total_number_of_episodes": 32241, "number_of_timesteps": 7523893, "per_episode_reward": -41.98, "episode_reward_trend_value": 0.004480095464279938, "biggest_recent_change": 0.11189460200530021},
{"total_number_of_episodes": 32251, "number_of_timesteps": 7528898, "per_episode_reward": -41.94, "episode_reward_trend_value": 0.004510521467834315, "biggest_recent_change": 0.11189460200530021},
{"total_number_of_episodes": 32261, "number_of_timesteps": 7532527, "per_episode_reward": -41.91, "episode_reward_trend_value": 0.004628790823732723, "biggest_recent_change": 0.11189460200530021},
{"total_number_of_episodes": 32271, "number_of_timesteps": 7536476, "per_episode_reward": -41.89, "episode_reward_trend_value": 0.004286936325363813, "biggest_recent_change": 0.11189460200530021},
{"total_number_of_episodes": 32281, "number_of_timesteps": 7541411, "per_episode_reward": -41.87, "episode_reward_trend_value": 0.00394553551719857, "biggest_recent_change": 0.11189460200530021},
{"total_number_of_episodes": 32291, "number_of_timesteps": 7545000, "per_episode_reward": -41.85, "episode_reward_trend_value": 0.0037614411508161854, "biggest_recent_change": 0.11189460200530021},
{"total_number_of_episodes": 32301, "number_of_timesteps": 7549076, "per_episode_reward": -41.8, "episode_reward_trend_value": 0.003892364663333107, "biggest_recent_change": 0.11189460200530021},
{"total_number_of_episodes": 32311, "number_of_timesteps": 7552811, "per_episode_reward": -41.75, "episode_reward_trend_value": 0.0032164017593543466, "biggest_recent_change": 0.05274943235144747},
{"total_number_of_episodes": 32321, "number_of_timesteps": 7556562, "per_episode_reward": -41.7, "episode_reward_trend_value": 0.0032905098765170573, "biggest_recent_change": 0.05274943235144747},
{"total_number_of_episodes": 32331, "number_of_timesteps": 7560260, "per_episode_reward": -41.64, "episode_reward_trend_value": 0.003878867650574986, "biggest_recent_change": 0.06379871707687812},
{"total_number_of_episodes": 32341, "number_of_timesteps": 7563555, "per_episode_reward": -41.61, "episode_reward_trend_value": 0.0037341451839598646, "biggest_recent_change": 0.06379871707687812},
{"total_number_of_episodes": 32352, "number_of_timesteps": 7567088, "per_episode_reward": -41.6, "episode_reward_trend_value": 0.0034446827305424045, "biggest_recent_change": 0.06379871707687812},
{"total_number_of_episodes": 32362, "number_of_timesteps": 7570706, "per_episode_reward": -41.57, "episode_reward_trend_value": 0.0035569625805919715, "biggest_recent_change": 0.06379871707687812},
{"total_number_of_episodes": 32372, "number_of_timesteps": 7575256, "per_episode_reward": -41.56, "episode_reward_trend_value": 0.0034347568928914203, "biggest_recent_change": 0.06379871707687812},
{"total_number_of_episodes": 32382, "number_of_timesteps": 7580049, "per_episode_reward": -41.5, "episode_reward_trend_value": 0.003912104352670079, "biggest_recent_change": 0.06379871707687812},
{"total_number_of_episodes": 32393, "number_of_timesteps": 7583679, "per_episode_reward": -41.47, "episode_reward_trend_value": 0.0036113069992235102, "biggest_recent_change": 0.06379871707687812},
{"total_number_of_episodes": 32403, "number_of_timesteps": 7586641, "per_episode_reward": -41.44, "episode_reward_trend_value": 0.00340218196937572, "biggest_recent_change": 0.06379871707687812},
{"total_number_of_episodes": 32413, "number_of_timesteps": 7590033, "per_episode_reward": -41.42, "episode_reward_trend_value": 0.003078999806520402, "biggest_recent_change": 0.06379871707687812},
{"total_number_of_episodes": 32423, "number_of_timesteps": 7593911, "per_episode_reward": -41.37, "episode_reward_trend_value": 0.0029835662811526237, "biggest_recent_change": 0.06185156137595271},
{"total_number_of_episodes": 32433, "number_of_timesteps": 7597960, "per_episode_reward": -41.32, "episode_reward_trend_value": 0.0032436151434386004, "biggest_recent_change": 0.06185156137595271},
{"total_number_of_episodes": 32443, "number_of_timesteps": 7601326, "per_episode_reward": -41.29, "episode_reward_trend_value": 0.003364378536394162, "biggest_recent_change": 0.06185156137595271},
{"total_number_of_episodes": 32453, "number_of_timesteps": 7605627, "per_episode_reward": -41.24, "episode_reward_trend_value": 0.003676424428195288, "biggest_recent_change": 0.06185156137595271},
{"total_number_of_episodes": 32463, "number_of_timesteps": 7609951, "per_episode_reward": -41.19, "episode_reward_trend_value": 0.004135627786070412, "biggest_recent_change": 0.06185156137595271},
{"total_number_of_episodes": 32473, "number_of_timesteps": 7612899, "per_episode_reward": -41.16, "episode_reward_trend_value": 0.0037220489567616256, "biggest_recent_change": 0.05661069774026117},
{"total_number_of_episodes": 32483, "number_of_timesteps": 7616428, "per_episode_reward": -41.14, "episode_reward_trend_value": 0.0036334194823972156, "biggest_recent_change": 0.05661069774026117},
{"total_number_of_episodes": 32493, "number_of_timesteps": 7620524, "per_episode_reward": -41.13, "episode_reward_trend_value": 0.003441523104109715, "biggest_recent_change": 0.05661069774026117},
{"total_number_of_episodes": 32504, "number_of_timesteps": 7623770, "per_episode_reward": -41.08, "episode_reward_trend_value": 0.003833979233014083, "biggest_recent_change": 0.05661069774026117},
{"total_number_of_episodes": 32514, "number_of_timesteps": 7626421, "per_episode_reward": -41.01, "episode_reward_trend_value": 0.003972112920591858, "biggest_recent_change": 0.0676417316757778},
{"total_number_of_episodes": 32524, "number_of_timesteps": 7628946, "per_episode_reward": -40.96, "episode_reward_trend_value": 0.0039014400197254578, "biggest_recent_change": 0.0676417316757778},
{"total_number_of_episodes": 32534, "number_of_timesteps": 7632660, "per_episode_reward": -40.9, "episode_reward_trend_value": 0.0044118559638165146, "biggest_recent_change": 0.06946530591696387},
{"total_number_of_episodes": 32544, "number_of_timesteps": 7636215, "per_episode_reward": -40.85, "episode_reward_trend_value": 0.004352430439795461, "biggest_recent_change": 0.06946530591696387},
{"total_number_of_episodes": 32554, "number_of_timesteps": 7639178, "per_episode_reward": -40.81, "episode_reward_trend_value": 0.004204914812739149, "biggest_recent_change": 0.06946530591696387},
{"total_number_of_episodes": 32564, "number_of_timesteps": 7641502, "per_episode_reward": -40.78, "episode_reward_trend_value": 0.004232017248584046, "biggest_recent_change": 0.06946530591696387},
{"total_number_of_episodes": 32574, "number_of_timesteps": 7644146, "per_episode_reward": -40.74, "episode_reward_trend_value": 0.004524040066056282, "biggest_recent_change": 0.06946530591696387},
{"total_number_of_episodes": 32584, "number_of_timesteps": 7648441, "per_episode_reward": -40.68, "episode_reward_trend_value": 0.004953173779104958, "biggest_recent_change": 0.06946530591696387},
{"total_number_of_episodes": 32594, "number_of_timesteps": 7650094, "per_episode_reward": -40.67, "episode_reward_trend_value": 0.004560585566921719, "biggest_recent_change": 0.06946530591696387},
{"total_number_of_episodes": 32604, "number_of_timesteps": 7652788, "per_episode_reward": -40.65, "episode_reward_trend_value": 0.003958944607161561, "biggest_recent_change": 0.06946530591696387},
{"total_number_of_episodes": 32614, "number_of_timesteps": 7654836, "per_episode_reward": -40.65, "episode_reward_trend_value": 0.0035496312350684575, "biggest_recent_change": 0.06946530591696387},
{"total_number_of_episodes": 32624, "number_of_timesteps": 7658230, "per_episode_reward": -40.62, "episode_reward_trend_value": 0.003107970266134351, "biggest_recent_change": 0.05358804808941642},
{"total_number_of_episodes": 32634, "number_of_timesteps": 7660310, "per_episode_reward": -40.6, "episode_reward_trend_value": 0.002839642169920214, "biggest_recent_change": 0.05358804808941642},
{"total_number_of_episodes": 32644, "number_of_timesteps": 7662490, "per_episode_reward": -40.51, "episode_reward_trend_value": 0.0033497343506856702, "biggest_recent_change": 0.0892425875740841},
{"total_number_of_episodes": 32654, "number_of_timesteps": 7665014, "per_episode_reward": -40.47, "episode_reward_trend_value": 0.0034712816044747776, "biggest_recent_change": 0.0892425875740841},
{"total_number_of_episodes": 32665, "number_of_timesteps": 7667083, "per_episode_reward": -40.44, "episode_reward_trend_value": 0.0032829907767952214, "biggest_recent_change": 0.0892425875740841},
{"total_number_of_episodes": 32675, "number_of_timesteps": 7669466, "per_episode_reward": -40.39, "episode_reward_trend_value": 0.0032216673233527613, "biggest_recent_change": 0.0892425875740841},
{"total_number_of_episodes": 32685, "number_of_timesteps": 7671357, "per_episode_reward": -40.37, "episode_reward_trend_value": 0.003303344189185253, "biggest_recent_change": 0.0892425875740841},
{"total_number_of_episodes": 32695, "number_of_timesteps": 7673169, "per_episode_reward": -40.35, "episode_reward_trend_value": 0.0033939248833891925, "biggest_recent_change": 0.0892425875740841},
{"total_number_of_episodes": 32705, "number_of_timesteps": 7674937, "per_episode_reward": -40.29, "episode_reward_trend_value": 0.003937314695813319, "biggest_recent_change": 0.0892425875740841},
{"total_number_of_episodes": 32715, "number_of_timesteps": 7677180, "per_episode_reward": -40.24, "episode_reward_trend_value": 0.004186241191023833, "biggest_recent_change": 0.0892425875740841},
{"total_number_of_episodes": 32725, "number_of_timesteps": 7678967, "per_episode_reward": -40.19, "episode_reward_trend_value": 0.004564211226833158, "biggest_recent_change": 0.0892425875740841},
{"total_number_of_episodes": 32735, "number_of_timesteps": 7680730, "per_episode_reward": -40.15, "episode_reward_trend_value": 0.003935001215731168, "biggest_recent_change": 0.057005517904919145},
{"total_number_of_episodes": 32745, "number_of_timesteps": 7682994, "per_episode_reward": -40.14, "episode_reward_trend_value": 0.0036559234283803873, "biggest_recent_change": 0.057005517904919145},
{"total_number_of_episodes": 32755, "number_of_timesteps": 7684999, "per_episode_reward": -40.07, "episode_reward_trend_value": 0.004115817218423561, "biggest_recent_change": 0.06842733803368617},
{"total_number_of_episodes": 32765, "number_of_timesteps": 7686733, "per_episode_reward": -40.01, "episode_reward_trend_value": 0.004280374361721803, "biggest_recent_change": 0.06842733803368617},
{"total_number_of_episodes": 32775, "number_of_timesteps": 7689372, "per_episode_reward": -39.98, "episode_reward_trend_value": 0.004379012583332316, "biggest_recent_change": 0.06842733803368617},
{"total_number_of_episodes": 32785, "number_of_timesteps": 7690985, "per_episode_reward": -39.92, "episode_reward_trend_value": 0.00479980593278542, "biggest_recent_change": 0.06842733803368617},
{"total_number_of_episodes": 32797, "number_of_timesteps": 7693897, "per_episode_reward": -39.89, "episode_reward_trend_value": 0.004408548134610789, "biggest_recent_change": 0.06842733803368617},
{"total_number_of_episodes": 32807, "number_of_timesteps": 7695589, "per_episode_reward": -39.86, "episode_reward_trend_value": 0.004225343199282921, "biggest_recent_change": 0.06842733803368617},
{"total_number_of_episodes": 32817, "number_of_timesteps": 7697520, "per_episode_reward": -39.83, "episode_reward_trend_value": 0.003983853031730591, "biggest_recent_change": 0.06842733803368617},
{"total_number_of_episodes": 32827, "number_of_timesteps": 7699448, "per_episode_reward": -39.81, "episode_reward_trend_value": 0.0038554837775152686, "biggest_recent_change": 0.06842733803368617},
{"total_number_of_episodes": 32837, "number_of_timesteps": 7701486, "per_episode_reward": -39.79, "episode_reward_trend_value": 0.0038466850595489017, "biggest_recent_change": 0.06842733803368617},
{"total_number_of_episodes": 32847, "number_of_timesteps": 7703334, "per_episode_reward": -39.78, "episode_reward_trend_value": 0.003215846982461793, "biggest_recent_change": 0.06287908017643673},
{"total_number_of_episodes": 32857, "number_of_timesteps": 7705130, "per_episode_reward": -39.75, "episode_reward_trend_value": 0.002841449857973781, "biggest_recent_change": 0.05951770922649757},
{"total_number_of_episodes": 32867, "number_of_timesteps": 7706770, "per_episode_reward": -39.73, "episode_reward_trend_value": 0.00272475617449675, "biggest_recent_change": 0.05951770922649757},
{"total_number_of_episodes": 32877, "number_of_timesteps": 7709693, "per_episode_reward": -39.7, "episode_reward_trend_value": 0.002351180693368033, "biggest_recent_change": 0.03563075910233238},
{"total_number_of_episodes": 32887, "number_of_timesteps": 7712046, "per_episode_reward": -39.67, "episode_reward_trend_value": 0.0025098799275308495, "biggest_recent_change": 0.036075247143855904},
{"total_number_of_episodes": 32897, "number_of_timesteps": 7714084, "per_episode_reward": -39.55, "episode_reward_trend_value": 0.0034608238028496887, "biggest_recent_change": 0.12121570788102787},
{"total_number_of_episodes": 32907, "number_of_timesteps": 7717359, "per_episode_reward": -39.53, "episode_reward_trend_value": 0.003271301095110365, "biggest_recent_change": 0.12121570788102787},
{"total_number_of_episodes": 32917, "number_of_timesteps": 7719706, "per_episode_reward": -39.52, "episode_reward_trend_value": 0.0031237313684984416, "biggest_recent_change": 0.12121570788102787},
{"total_number_of_episodes": 32927, "number_of_timesteps": 7725391, "per_episode_reward": -39.52, "episode_reward_trend_value": 0.003092542433473571, "biggest_recent_change": 0.12121570788102787},
{"total_number_of_episodes": 32937, "number_of_timesteps": 7727300, "per_episode_reward": -39.5, "episode_reward_trend_value": 0.0031224489291191383, "biggest_recent_change": 0.12121570788102787},
{"total_number_of_episodes": 32947, "number_of_timesteps": 7729767, "per_episode_reward": -39.42, "episode_reward_trend_value": 0.003698080405205357, "biggest_recent_change": 0.12121570788102787},
{"total_number_of_episodes": 32957, "number_of_timesteps": 7732692, "per_episode_reward": -39.34, "episode_reward_trend_value": 0.004315019434322901, "biggest_recent_change": 0.12121570788102787},
{"total_number_of_episodes": 32967, "number_of_timesteps": 7735323, "per_episode_reward": -39.33, "episode_reward_trend_value": 0.004182324182645027, "biggest_recent_change": 0.12121570788102787},
{"total_number_of_episodes": 32977, "number_of_timesteps": 7739066, "per_episode_reward": -39.31, "episode_reward_trend_value": 0.003955719222223229, "biggest_recent_change": 0.12121570788102787},
{"total_number_of_episodes": 32987, "number_of_timesteps": 7741879, "per_episode_reward": -39.28, "episode_reward_trend_value": 0.002964295783894657, "biggest_recent_change": 0.08099017182027524},
{"total_number_of_episodes": 32997, "number_of_timesteps": 7744355, "per_episode_reward": -39.25, "episode_reward_trend_value": 0.003086765985498532, "biggest_recent_change": 0.08099017182027524},
{"total_number_of_episodes": 33007, "number_of_timesteps": 7747918, "per_episode_reward": -39.23, "episode_reward_trend_value": 0.003330106049695461, "biggest_recent_change": 0.08099017182027524},
{"total_number_of_episodes": 33017, "number_of_timesteps": 7750753, "per_episode_reward": -39.2, "episode_reward_trend_value": 0.003507128619315994, "biggest_recent_change": 0.08099017182027524},
{"total_number_of_episodes": 33027, "number_of_timesteps": 7754539, "per_episode_reward": -39.18, "episode_reward_trend_value": 0.0035773060363084933, "biggest_recent_change": 0.08099017182027524},
{"total_number_of_episodes": 33037, "number_of_timesteps": 7758038, "per_episode_reward": -39.16, "episode_reward_trend_value": 0.002835769994880306, "biggest_recent_change": 0.07829949520609603},
{"total_number_of_episodes": 33047, "number_of_timesteps": 7761390, "per_episode_reward": -39.14, "episode_reward_trend_value": 0.0022066047016710715, "biggest_recent_change": 0.03198759843145638},
{"total_number_of_episodes": 33057, "number_of_timesteps": 7765875, "per_episode_reward": -39.09, "episode_reward_trend_value": 0.002664399558752548, "biggest_recent_change": 0.05515488041123717},
{"total_number_of_episodes": 33067, "number_of_timesteps": 7767998, "per_episode_reward": -39.05, "episode_reward_trend_value": 0.002919699244454282, "biggest_recent_change": 0.05515488041123717},
{"total_number_of_episodes": 33077, "number_of_timesteps": 7770212, "per_episode_reward": -39.05, "episode_reward_trend_value": 0.0026092985638843263, "biggest_recent_change": 0.05515488041123717},
{"total_number_of_episodes": 33087, "number_of_timesteps": 7773632, "per_episode_reward": -38.97, "episode_reward_trend_value": 0.003189015923358656, "biggest_recent_change": 0.07765736843109039},
{"total_number_of_episodes": 33097, "number_of_timesteps": 7777353, "per_episode_reward": -38.93, "episode_reward_trend_value": 0.003298314854812487, "biggest_recent_change": 0.07765736843109039},
{"total_number_of_episodes": 33107, "number_of_timesteps": 7780951, "per_episode_reward": -38.91, "episode_reward_trend_value": 0.0032224834942270937, "biggest_recent_change": 0.07765736843109039},
{"total_number_of_episodes": 33117, "number_of_timesteps": 7782965, "per_episode_reward": -38.88, "episode_reward_trend_value": 0.003273771115032531, "biggest_recent_change": 0.07765736843109039},
{"total_number_of_episodes": 33127, "number_of_timesteps": 7785914, "per_episode_reward": -38.85, "episode_reward_trend_value": 0.0035126076465229203, "biggest_recent_change": 0.07765736843109039},
{"total_number_of_episodes": 33137, "number_of_timesteps": 7788296, "per_episode_reward": -38.81, "episode_reward_trend_value": 0.003665820023302678, "biggest_recent_change": 0.07765736843109039},
{"total_number_of_episodes": 33147, "number_of_timesteps": 7790213, "per_episode_reward": -38.79, "episode_reward_trend_value": 0.003336860670898526, "biggest_recent_change": 0.07765736843109039},
{"total_number_of_episodes": 33157, "number_of_timesteps": 7794645, "per_episode_reward": -38.77, "episode_reward_trend_value": 0.003077725458014571, "biggest_recent_change": 0.07765736843109039},
{"total_number_of_episodes": 33167, "number_of_timesteps": 7797437, "per_episode_reward": -38.75, "episode_reward_trend_value": 0.003256049526056396, "biggest_recent_change": 0.07765736843109039},
{"total_number_of_episodes": 33177, "number_of_timesteps": 7800318, "per_episode_reward": -38.7, "episode_reward_trend_value": 0.0029974409679436715, "biggest_recent_change": 0.054382598200945154},
{"total_number_of_episodes": 33187, "number_of_timesteps": 7802724, "per_episode_reward": -38.64, "episode_reward_trend_value": 0.0032287714362318016, "biggest_recent_change": 0.06033643005495293},
{"total_number_of_episodes": 33197, "number_of_timesteps": 7805132, "per_episode_reward": -38.63, "episode_reward_trend_value": 0.003087903993537111, "biggest_recent_change": 0.06033643005495293},
{"total_number_of_episodes": 33207, "number_of_timesteps": 7808858, "per_episode_reward": -38.62, "episode_reward_trend_value": 0.0029831169049312537, "biggest_recent_change": 0.06033643005495293},
{"total_number_of_episodes": 33217, "number_of_timesteps": 7811576, "per_episode_reward": -38.57, "episode_reward_trend_value": 0.003062574264999461, "biggest_recent_change": 0.06033643005495293},
{"total_number_of_episodes": 33227, "number_of_timesteps": 7813893, "per_episode_reward": -38.55, "episode_reward_trend_value": 0.002951795814273892, "biggest_recent_change": 0.06033643005495293},
{"total_number_of_episodes": 33237, "number_of_timesteps": 7817403, "per_episode_reward": -38.53, "episode_reward_trend_value": 0.0028957290547689733, "biggest_recent_change": 0.06033643005495293},
{"total_number_of_episodes": 33247, "number_of_timesteps": 7820512, "per_episode_reward": -38.46, "episode_reward_trend_value": 0.003483423045257281, "biggest_recent_change": 0.06822806240344192},
{"total_number_of_episodes": 33257, "number_of_timesteps": 7822819, "per_episode_reward": -38.44, "episode_reward_trend_value": 0.0034957831619859153, "biggest_recent_change": 0.06822806240344192},
{"total_number_of_episodes": 33267, "number_of_timesteps": 7825157, "per_episode_reward": -38.42, "episode_reward_trend_value": 0.0030535287134547673, "biggest_recent_change": 0.06822806240344192},
{"total_number_of_episodes": 33277, "number_of_timesteps": 7828260, "per_episode_reward": -38.4, "episode_reward_trend_value": 0.0026024358926156153, "biggest_recent_change": 0.06822806240344192},
{"total_number_of_episodes": 33287, "number_of_timesteps": 7830275, "per_episode_reward": -38.39, "episode_reward_trend_value": 0.0027138050127278115, "biggest_recent_change": 0.06822806240344192},
{"total_number_of_episodes": 33297, "number_of_timesteps": 7832898, "per_episode_reward": -38.35, "episode_reward_trend_value": 0.002991183132475644, "biggest_recent_change": 0.06822806240344192},
{"total_number_of_episodes": 33307, "number_of_timesteps": 7835363, "per_episode_reward": -38.32, "episode_reward_trend_value": 0.0028408647046051765, "biggest_recent_change": 0.06822806240344192},
{"total_number_of_episodes": 33317, "number_of_timesteps": 7837057, "per_episode_reward": -38.3, "episode_reward_trend_value": 0.002761284328503264, "biggest_recent_change": 0.06822806240344192},
{"total_number_of_episodes": 33327, "number_of_timesteps": 7839396, "per_episode_reward": -38.27, "episode_reward_trend_value": 0.0028419706842185296, "biggest_recent_change": 0.06822806240344192},
{"total_number_of_episodes": 33337, "number_of_timesteps": 7842332, "per_episode_reward": -38.22, "episode_reward_trend_value": 0.0026293887657126273, "biggest_recent_change": 0.049095689737910675},
{"total_number_of_episodes": 33347, "number_of_timesteps": 7844399, "per_episode_reward": -38.17, "episode_reward_trend_value": 0.002981281359830885, "biggest_recent_change": 0.052883447280144935},
{"total_number_of_episodes": 33357, "number_of_timesteps": 7847304, "per_episode_reward": -38.12, "episode_reward_trend_value": 0.0033185202156335294, "biggest_recent_change": 0.052883447280144935},
{"total_number_of_episodes": 33367, "number_of_timesteps": 7849794, "per_episode_reward": -38.12, "episode_reward_trend_value": 0.0031676878552033038, "biggest_recent_change": 0.052883447280144935},
{"total_number_of_episodes": 33377, "number_of_timesteps": 7853331, "per_episode_reward": -38.07, "episode_reward_trend_value": 0.0034742455022235197, "biggest_recent_change": 0.052883447280144935},
{"total_number_of_episodes": 33387, "number_of_timesteps": 7857073, "per_episode_reward": -38.03, "episode_reward_trend_value": 0.003517636715760217, "biggest_recent_change": 0.052883447280144935},
{"total_number_of_episodes": 33397, "number_of_timesteps": 7861210, "per_episode_reward": -38.01, "episode_reward_trend_value": 0.003367634217177419, "biggest_recent_change": 0.052883447280144935},
{"total_number_of_episodes": 33407, "number_of_timesteps": 7863498, "per_episode_reward": -37.98, "episode_reward_trend_value": 0.0035935804397148273, "biggest_recent_change": 0.052883447280144935},
{"total_number_of_episodes": 33417, "number_of_timesteps": 7867023, "per_episode_reward": -37.95, "episode_reward_trend_value": 0.003585901465975875, "biggest_recent_change": 0.052883447280144935},
{"total_number_of_episodes": 33427, "number_of_timesteps": 7871006, "per_episode_reward": -37.91, "episode_reward_trend_value": 0.003441129543819304, "biggest_recent_change": 0.052883447280144935},
{"total_number_of_episodes": 33437, "number_of_timesteps": 7874902, "per_episode_reward": -37.88, "episode_reward_trend_value": 0.003214968052919273, "biggest_recent_change": 0.044931194855379886},
{"total_number_of_episodes": 33447, "number_of_timesteps": 7878204, "per_episode_reward": -37.85, "episode_reward_trend_value": 0.00309962833325904, "biggest_recent_change": 0.04471375112684228},
{"total_number_of_episodes": 33457, "number_of_timesteps": 7882311, "per_episode_reward": -37.82, "episode_reward_trend_value": 0.003312807021336539, "biggest_recent_change": 0.04471375112684228},
{"total_number_of_episodes": 33467, "number_of_timesteps": 7885267, "per_episode_reward": -37.8, "episode_reward_trend_value": 0.0030961012378924917, "biggest_recent_change": 0.04471375112684228},
{"total_number_of_episodes": 33477, "number_of_timesteps": 7888268, "per_episode_reward": -37.77, "episode_reward_trend_value": 0.0028926909281471085, "biggest_recent_change": 0.03866659834133657},
{"total_number_of_episodes": 33487, "number_of_timesteps": 7891521, "per_episode_reward": -37.69, "episode_reward_trend_value": 0.003629488901295256, "biggest_recent_change": 0.08218131253455141},
{"total_number_of_episodes": 33497, "number_of_timesteps": 7894643, "per_episode_reward": -37.63, "episode_reward_trend_value": 0.003847217160363985, "biggest_recent_change": 0.08218131253455141},
{"total_number_of_episodes": 33507, "number_of_timesteps": 7899742, "per_episode_reward": -37.61, "episode_reward_trend_value": 0.003781463592822673, "biggest_recent_change": 0.08218131253455141},
{"total_number_of_episodes": 33517, "number_of_timesteps": 7902731, "per_episode_reward": -37.57, "episode_reward_trend_value": 0.003800609066738995, "biggest_recent_change": 0.08218131253455141},
{"total_number_of_episodes": 33527, "number_of_timesteps": 7904706, "per_episode_reward": -37.54, "episode_reward_trend_value": 0.0037667267529747682, "biggest_recent_change": 0.08218131253455141},
{"total_number_of_episodes": 33537, "number_of_timesteps": 7907588, "per_episode_reward": -37.51, "episode_reward_trend_value": 0.0037423969488863743, "biggest_recent_change": 0.08218131253455141},
{"total_number_of_episodes": 33547, "number_of_timesteps": 7911972, "per_episode_reward": -37.49, "episode_reward_trend_value": 0.0036768991690586004, "biggest_recent_change": 0.08218131253455141},
{"total_number_of_episodes": 33557, "number_of_timesteps": 7916220, "per_episode_reward": -37.46, "episode_reward_trend_value": 0.003766916521890254, "biggest_recent_change": 0.08218131253455141},
{"total_number_of_episodes": 33567, "number_of_timesteps": 7919550, "per_episode_reward": -37.37, "episode_reward_trend_value": 0.004498660078459378, "biggest_recent_change": 0.09226374334097898},
{"total_number_of_episodes": 33577, "number_of_timesteps": 7922832, "per_episode_reward": -37.34, "episode_reward_trend_value": 0.003917558598083638, "biggest_recent_change": 0.09226374334097898},
{"total_number_of_episodes": 33587, "number_of_timesteps": 7926151, "per_episode_reward": -37.32, "episode_reward_trend_value": 0.0034609239137124185, "biggest_recent_change": 0.09226374334097898},
{"total_number_of_episodes": 33597, "number_of_timesteps": 7929133, "per_episode_reward": -37.27, "episode_reward_trend_value": 0.0037503126171012174, "biggest_recent_change": 0.09226374334097898},
{"total_number_of_episodes": 33607, "number_of_timesteps": 7932902, "per_episode_reward": -37.23, "episode_reward_trend_value": 0.003729008660353293, "biggest_recent_change": 0.09226374334097898},
{"total_number_of_episodes": 33617, "number_of_timesteps": 7936534, "per_episode_reward": -37.21, "episode_reward_trend_value": 0.0036807229921107716, "biggest_recent_change": 0.09226374334097898},
{"total_number_of_episodes": 33627, "number_of_timesteps": 7940029, "per_episode_reward": -37.18, "episode_reward_trend_value": 0.00365749764899361, "biggest_recent_change": 0.09226374334097898},
{"total_number_of_episodes": 33637, "number_of_timesteps": 7943116, "per_episode_reward": -37.17, "episode_reward_trend_value": 0.0035880197157682563, "biggest_recent_change": 0.09226374334097898},

{"total_number_of_episodes": 33647, "number_of_timesteps": 7945479, "per_episode_reward": -37.16, "episode_reward_trend_value": 0.003328337130177298, "biggest_recent_change": 0.09226374334097898},
{"total_number_of_episodes": 33657, "number_of_timesteps": 7948906, "per_episode_reward": -37.1, "episode_reward_trend_value": 0.002984272839546678, "biggest_recent_change": 0.06129795718422315},
{"total_number_of_episodes": 33667, "number_of_timesteps": 7952387, "per_episode_reward": -37.05, "episode_reward_trend_value": 0.0032032673587646656, "biggest_recent_change": 0.06129795718422315},
{"total_number_of_episodes": 33677, "number_of_timesteps": 7954652, "per_episode_reward": -37.02, "episode_reward_trend_value": 0.0033133454262378043, "biggest_recent_change": 0.06129795718422315},
{"total_number_of_episodes": 33687, "number_of_timesteps": 7957647, "per_episode_reward": -36.96, "episode_reward_trend_value": 0.0034620280596670563, "biggest_recent_change": 0.06129795718422315},
{"total_number_of_episodes": 33697, "number_of_timesteps": 7962408, "per_episode_reward": -36.91, "episode_reward_trend_value": 0.003557878284501075, "biggest_recent_change": 0.06129795718422315},
{"total_number_of_episodes": 33707, "number_of_timesteps": 7966334, "per_episode_reward": -36.87, "episode_reward_trend_value": 0.003772055956427778, "biggest_recent_change": 0.06129795718422315},
{"total_number_of_episodes": 33717, "number_of_timesteps": 7968249, "per_episode_reward": -36.79, "episode_reward_trend_value": 0.004295796875830228, "biggest_recent_change": 0.0774073395836794},
{"total_number_of_episodes": 33727, "number_of_timesteps": 7970414, "per_episode_reward": -36.77, "episode_reward_trend_value": 0.004348876911271225, "biggest_recent_change": 0.0774073395836794},
{"total_number_of_episodes": 33738, "number_of_timesteps": 7973115, "per_episode_reward": -36.74, "episode_reward_trend_value": 0.004676242530586686, "biggest_recent_change": 0.0774073395836794},
{"total_number_of_episodes": 33748, "number_of_timesteps": 7976024, "per_episode_reward": -36.71, "episode_reward_trend_value": 0.004313097597118798, "biggest_recent_change": 0.0774073395836794},
{"total_number_of_episodes": 33758, "number_of_timesteps": 7978537, "per_episode_reward": -36.68, "episode_reward_trend_value": 0.004085996689350205, "biggest_recent_change": 0.0774073395836794},
{"total_number_of_episodes": 33768, "number_of_timesteps": 7981044, "per_episode_reward": -36.66, "episode_reward_trend_value": 0.003996151457728006, "biggest_recent_change": 0.0774073395836794},
{"total_number_of_episodes": 33778, "number_of_timesteps": 7983822, "per_episode_reward": -36.64, "episode_reward_trend_value": 0.0035178958327912193, "biggest_recent_change": 0.0774073395836794},
{"total_number_of_episodes": 33788, "number_of_timesteps": 7986963, "per_episode_reward": -36.63, "episode_reward_trend_value": 0.0031784185305156936, "biggest_recent_change": 0.0774073395836794},
{"total_number_of_episodes": 33798, "number_of_timesteps": 7989144, "per_episode_reward": -36.6, "episode_reward_trend_value": 0.0029615060126343923, "biggest_recent_change": 0.0774073395836794},
{"total_number_of_episodes": 33808, "number_of_timesteps": 7991727, "per_episode_reward": -36.59, "episode_reward_trend_value": 0.0023064536609464564, "biggest_recent_change": 0.03802411146708806},
{"total_number_of_episodes": 33819, "number_of_timesteps": 7995615, "per_episode_reward": -36.54, "episode_reward_trend_value": 0.0026048510443618038, "biggest_recent_change": 0.04483439918997334},
{"total_number_of_episodes": 33829, "number_of_timesteps": 7998794, "per_episode_reward": -36.51, "episode_reward_trend_value": 0.002501969423782116, "biggest_recent_change": 0.04483439918997334},
{"total_number_of_episodes": 33839, "number_of_timesteps": 8001122, "per_episode_reward": -36.52, "episode_reward_trend_value": 0.0020568437711837363, "biggest_recent_change": 0.04483439918997334},
{"total_number_of_episodes": 33849, "number_of_timesteps": 8003329, "per_episode_reward": -36.48, "episode_reward_trend_value": 0.0021943755689240634, "biggest_recent_change": 0.04483439918997334},
{"total_number_of_episodes": 33859, "number_of_timesteps": 8004688, "per_episode_reward": -36.41, "episode_reward_trend_value": 0.002729695275358937, "biggest_recent_change": 0.06716474886983548},
{"total_number_of_episodes": 33869, "number_of_timesteps": 8007222, "per_episode_reward": -36.4, "episode_reward_trend_value": 0.002726577856159433, "biggest_recent_change": 0.06716474886983548},
{"total_number_of_episodes": 33879, "number_of_timesteps": 8009724, "per_episode_reward": -36.35, "episode_reward_trend_value": 0.0030500396189560145, "biggest_recent_change": 0.06716474886983548},
{"total_number_of_episodes": 33889, "number_of_timesteps": 8012586, "per_episode_reward": -36.32, "episode_reward_trend_value": 0.0031752128447443003, "biggest_recent_change": 0.06716474886983548},

{"total_number_of_episodes": 33899, "number_of_timesteps": 8015658, "per_episode_reward": -36.26, "episode_reward_trend_value": 0.00357484573536916, "biggest_recent_change": 0.06716474886983548},
{"total_number_of_episodes": 33909, "number_of_timesteps": 8018131, "per_episode_reward": -36.22, "episode_reward_trend_value": 0.0035218862270375616, "biggest_recent_change": 0.06716474886983548},
{"total_number_of_episodes": 33919, "number_of_timesteps": 8020782, "per_episode_reward": -36.16, "episode_reward_trend_value": 0.003918430587123822, "biggest_recent_change": 0.06716474886983548},
{"total_number_of_episodes": 33929, "number_of_timesteps": 8023424, "per_episode_reward": -36.11, "episode_reward_trend_value": 0.0045596568448564604, "biggest_recent_change": 0.06716474886983548},
{"total_number_of_episodes": 33939, "number_of_timesteps": 8027590, "per_episode_reward": -36.09, "episode_reward_trend_value": 0.004360742047071082, "biggest_recent_change": 0.06716474886983548},
{"total_number_of_episodes": 33949, "number_of_timesteps": 8031718, "per_episode_reward": -36.05, "episode_reward_trend_value": 0.004012872074311167, "biggest_recent_change": 0.06445375802267961},
{"total_number_of_episodes": 33959, "number_of_timesteps": 8035816, "per_episode_reward": -36.02, "episode_reward_trend_value": 0.004236357657792351, "biggest_recent_change": 0.06445375802267961},
{"total_number_of_episodes": 33970, "number_of_timesteps": 8038641, "per_episode_reward": -35.95, "episode_reward_trend_value": 0.004492422774609079, "biggest_recent_change": 0.06610293548443735},
{"total_number_of_episodes": 33980, "number_of_timesteps": 8041858, "per_episode_reward": -35.93, "episode_reward_trend_value": 0.004279411945311848, "biggest_recent_change": 0.06610293548443735},
{"total_number_of_episodes": 33990, "number_of_timesteps": 8044690, "per_episode_reward": -35.91, "episode_reward_trend_value": 0.003912370070209903, "biggest_recent_change": 0.06610293548443735},
{"total_number_of_episodes": 34001, "number_of_timesteps": 8048724, "per_episode_reward": -35.88, "episode_reward_trend_value": 0.0038502822282724643, "biggest_recent_change": 0.06610293548443735},
{"total_number_of_episodes": 34011, "number_of_timesteps": 8050738, "per_episode_reward": -35.87, "episode_reward_trend_value": 0.0031766216704068504, "biggest_recent_change": 0.06610293548443735},
{"total_number_of_episodes": 34021, "number_of_timesteps": 8052882, "per_episode_reward": -35.85, "episode_reward_trend_value": 0.002933271746793369, "biggest_recent_change": 0.06610293548443735},
{"total_number_of_episodes": 34031, "number_of_timesteps": 8057881, "per_episode_reward": -35.83, "episode_reward_trend_value": 0.0028963966312446922, "biggest_recent_change": 0.06610293548443735},
{"total_number_of_episodes": 34041, "number_of_timesteps": 8059797, "per_episode_reward": -35.78, "episode_reward_trend_value": 0.002997243164862182, "biggest_recent_change": 0.06610293548443735},
{"total_number_of_episodes": 34051, "number_of_timesteps": 8061903, "per_episode_reward": -35.73, "episode_reward_trend_value": 0.003151641499649571, "biggest_recent_change": 0.06610293548443735},
{"total_number_of_episodes": 34062, "number_of_timesteps": 8064219, "per_episode_reward": -35.68, "episode_reward_trend_value": 0.0029568165635106584, "biggest_recent_change": 0.05126777262410087},
{"total_number_of_episodes": 34072, "number_of_timesteps": 8066476, "per_episode_reward": -35.64, "episode_reward_trend_value": 0.0032394585690165437, "biggest_recent_change": 0.05126777262410087},
{"total_number_of_episodes": 34083, "number_of_timesteps": 8069537, "per_episode_reward": -35.59, "episode_reward_trend_value": 0.0036246931596224385, "biggest_recent_change": 0.05605693248335797},
{"total_number_of_episodes": 34093, "number_of_timesteps": 8072022, "per_episode_reward": -35.52, "episode_reward_trend_value": 0.003991403587159681, "biggest_recent_change": 0.06748407614411178},
{"total_number_of_episodes": 34103, "number_of_timesteps": 8074064, "per_episode_reward": -35.48, "episode_reward_trend_value": 0.004368874840160528, "biggest_recent_change": 0.06748407614411178},
{"total_number_of_episodes": 34113, "number_of_timesteps": 8075806, "per_episode_reward": -35.44, "episode_reward_trend_value": 0.00451620833871047, "biggest_recent_change": 0.06748407614411178},
{"total_number_of_episodes": 34123, "number_of_timesteps": 8078075, "per_episode_reward": -35.41, "episode_reward_trend_value": 0.0046312056508361205, "biggest_recent_change": 0.06748407614411178},
{"total_number_of_episodes": 34134, "number_of_timesteps": 8080804, "per_episode_reward": -35.38, "episode_reward_trend_value": 0.004467864903987046, "biggest_recent_change": 0.06748407614411178},
{"total_number_of_episodes": 34144, "number_of_timesteps": 8082795, "per_episode_reward": -35.36, "episode_reward_trend_value": 0.004084006642362286, "biggest_recent_change": 0.06748407614411178},
{"total_number_of_episodes": 34154, "number_of_timesteps": 8084529, "per_episode_reward": -35.35, "episode_reward_trend_value": 0.0037597152841863297, "biggest_recent_change": 0.06748407614411178},
{"total_number_of_episodes": 34164, "number_of_timesteps": 8086732, "per_episode_reward": -35.3, "episode_reward_trend_value": 0.0038306666093537466, "biggest_recent_change": 0.06748407614411178},
{"total_number_of_episodes": 34174, "number_of_timesteps": 8088390, "per_episode_reward": -35.25, "episode_reward_trend_value": 0.003726092142935203, "biggest_recent_change": 0.06748407614411178},
{"total_number_of_episodes": 34185, "number_of_timesteps": 8090861, "per_episode_reward": -35.2, "episode_reward_trend_value": 0.0035080561801438628, "biggest_recent_change": 0.048805674027413204},
{"total_number_of_episodes": 34196, "number_of_timesteps": 8093151, "per_episode_reward": -35.18, "episode_reward_trend_value": 0.0033014109478767435, "biggest_recent_change": 0.048805674027413204},
{"total_number_of_episodes": 34206, "number_of_timesteps": 8095500, "per_episode_reward": -35.11, "episode_reward_trend_value": 0.003680317573354822, "biggest_recent_change": 0.07172408567150512},
{"total_number_of_episodes": 34216, "number_of_timesteps": 8098406, "per_episode_reward": -35.08, "episode_reward_trend_value": 0.0036314122290596468, "biggest_recent_change": 0.07172408567150512},
{"total_number_of_episodes": 34226, "number_of_timesteps": 8101886, "per_episode_reward": -35.06, "episode_reward_trend_value": 0.0035511001568393234, "biggest_recent_change": 0.07172408567150512},
{"total_number_of_episodes": 34236, "number_of_timesteps": 8104827, "per_episode_reward": -35.01, "episode_reward_trend_value": 0.00394173663964297, "biggest_recent_change": 0.07172408567150512},
{"total_number_of_episodes": 34246, "number_of_timesteps": 8108259, "per_episode_reward": -34.96, "episode_reward_trend_value": 0.004331021315863066, "biggest_recent_change": 0.07172408567150512},
{"total_number_of_episodes": 34257, "number_of_timesteps": 8111741, "per_episode_reward": -34.92, "episode_reward_trend_value": 0.004165626795803945, "biggest_recent_change": 0.07172408567150512},
{"total_number_of_episodes": 34267, "number_of_timesteps": 8114230, "per_episode_reward": -34.89, "episode_reward_trend_value": 0.0040412346164338765, "biggest_recent_change": 0.07172408567150512},
{"total_number_of_episodes": 34277, "number_of_timesteps": 8116733, "per_episode_reward": -34.83, "episode_reward_trend_value": 0.0040839646040063985, "biggest_recent_change": 0.07172408567150512},
{"total_number_of_episodes": 34287, "number_of_timesteps": 8119093, "per_episode_reward": -34.8, "episode_reward_trend_value": 0.004264430140391558, "biggest_recent_change": 0.07172408567150512},
{"total_number_of_episodes": 34297, "number_of_timesteps": 8121289, "per_episode_reward": -34.79, "episode_reward_trend_value": 0.0035518461683412598, "biggest_recent_change": 0.05441808985590768},
{"total_number_of_episodes": 34307, "number_of_timesteps": 8123877, "per_episode_reward": -34.77, "episode_reward_trend_value": 0.0034626258015438317, "biggest_recent_change": 0.05441808985590768},
{"total_number_of_episodes": 34317, "number_of_timesteps": 8126925, "per_episode_reward": -34.73, "episode_reward_trend_value": 0.003737703976348586, "biggest_recent_change": 0.05441808985590768},
{"total_number_of_episodes": 34327, "number_of_timesteps": 8129653, "per_episode_reward": -34.57, "episode_reward_trend_value": 0.004875123878989582, "biggest_recent_change": 0.15424560376789032},
{"total_number_of_episodes": 34337, "number_of_timesteps": 8132115, "per_episode_reward": -34.53, "episode_reward_trend_value": 0.004756151909435383, "biggest_recent_change": 0.15424560376789032},
{"total_number_of_episodes": 34347, "number_of_timesteps": 8134486, "per_episode_reward": -34.5, "episode_reward_trend_value": 0.004691795872726819, "biggest_recent_change": 0.15424560376789032},
{"total_number_of_episodes": 34357, "number_of_timesteps": 8136491, "per_episode_reward": -34.45, "episode_reward_trend_value": 0.004867593386293044, "biggest_recent_change": 0.15424560376789032},
{"total_number_of_episodes": 34367, "number_of_timesteps": 8139716, "per_episode_reward": -34.42, "episode_reward_trend_value": 0.004587259038977089, "biggest_recent_change": 0.15424560376789032},
{"total_number_of_episodes": 34377, "number_of_timesteps": 8141443, "per_episode_reward": -34.38, "episode_reward_trend_value": 0.004673143922607102, "biggest_recent_change": 0.15424560376789032},
{"total_number_of_episodes": 34387, "number_of_timesteps": 8143251, "per_episode_reward": -34.3, "episode_reward_trend_value": 0.005422200953766776, "biggest_recent_change": 0.15424560376789032},
{"total_number_of_episodes": 34397, "number_of_timesteps": 8147032, "per_episode_reward": -34.26, "episode_reward_trend_value": 0.00569200419530781, "biggest_recent_change": 0.15424560376789032},
{"total_number_of_episodes": 34407, "number_of_timesteps": 8148944, "per_episode_reward": -34.23, "episode_reward_trend_value": 0.00547515608054291, "biggest_recent_change": 0.15424560376789032},
{"total_number_of_episodes": 34417, "number_of_timesteps": 8152925, "per_episode_reward": -34.17, "episode_reward_trend_value": 0.004409800129528759, "biggest_recent_change": 0.0750066609913489},
{"total_number_of_episodes": 34427, "number_of_timesteps": 8155376, "per_episode_reward": -34.11, "episode_reward_trend_value": 0.00460879616840436, "biggest_recent_change": 0.0750066609913489},
{"total_number_of_episodes": 34437, "number_of_timesteps": 8156966, "per_episode_reward": -34.08, "episode_reward_trend_value": 0.004626879638841943, "biggest_recent_change": 0.0750066609913489},
{"total_number_of_episodes": 34447, "number_of_timesteps": 8160367, "per_episode_reward": -34.05, "episode_reward_trend_value": 0.004394296903148702, "biggest_recent_change": 0.0750066609913489},
{"total_number_of_episodes": 34457, "number_of_timesteps": 8162469, "per_episode_reward": -33.97, "episode_reward_trend_value": 0.005057564526269213, "biggest_recent_change": 0.0861705331968281},
{"total_number_of_episodes": 34467, "number_of_timesteps": 8165363, "per_episode_reward": -33.94, "episode_reward_trend_value": 0.0048923818756410106, "biggest_recent_change": 0.0861705331968281},
{"total_number_of_episodes": 34477, "number_of_timesteps": 8167798, "per_episode_reward": -33.93, "episode_reward_trend_value": 0.004192807856230019, "biggest_recent_change": 0.0861705331968281},
{"total_number_of_episodes": 34487, "number_of_timesteps": 8171025, "per_episode_reward": -33.9, "episode_reward_trend_value": 0.00401124387028086, "biggest_recent_change": 0.0861705331968281},
{"total_number_of_episodes": 34497, "number_of_timesteps": 8173829, "per_episode_reward": -33.88, "episode_reward_trend_value": 0.00391386651797458, "biggest_recent_change": 0.0861705331968281},
{"total_number_of_episodes": 34507, "number_of_timesteps": 8176277, "per_episode_reward": -33.85, "episode_reward_trend_value": 0.0036324215137078395, "biggest_recent_change": 0.0861705331968281},
{"total_number_of_episodes": 34517, "number_of_timesteps": 8179054, "per_episode_reward": -33.82, "episode_reward_trend_value": 0.0032858909203498225, "biggest_recent_change": 0.0861705331968281},
{"total_number_of_episodes": 34527, "number_of_timesteps": 8182032, "per_episode_reward": -33.8, "episode_reward_trend_value": 0.003132397788664084, "biggest_recent_change": 0.0861705331968281},
{"total_number_of_episodes": 34538, "number_of_timesteps": 8184883, "per_episode_reward": -33.76, "episode_reward_trend_value": 0.0032016906980247644, "biggest_recent_change": 0.0861705331968281},
{"total_number_of_episodes": 34548, "number_of_timesteps": 8187829, "per_episode_reward": -33.7, "episode_reward_trend_value": 0.002930620537575932, "biggest_recent_change": 0.061774218756433186},
{"total_number_of_episodes": 34558, "number_of_timesteps": 8190537, "per_episode_reward": -33.66, "episode_reward_trend_value": 0.0030699575676895246, "biggest_recent_change": 0.061774218756433186},
{"total_number_of_episodes": 34568, "number_of_timesteps": 8192966, "per_episode_reward": -33.57, "episode_reward_trend_value": 0.003993904483979014, "biggest_recent_change": 0.09520022171041376},
{"total_number_of_episodes": 34578, "number_of_timesteps": 8194631, "per_episode_reward": -33.52, "episode_reward_trend_value": 0.004227172622396106, "biggest_recent_change": 0.09520022171041376},
{"total_number_of_episodes": 34588, "number_of_timesteps": 8196626, "per_episode_reward": -33.47, "episode_reward_trend_value": 0.004518296216232029, "biggest_recent_change": 0.09520022171041376},
{"total_number_of_episodes": 34598, "number_of_timesteps": 8198885, "per_episode_reward": -33.45, "episode_reward_trend_value": 0.004463805908266888, "biggest_recent_change": 0.09520022171041376},
{"total_number_of_episodes": 34608, "number_of_timesteps": 8202082, "per_episode_reward": -33.39, "episode_reward_trend_value": 0.004793953324538257, "biggest_recent_change": 0.09520022171041376},
{"total_number_of_episodes": 34618, "number_of_timesteps": 8204464, "per_episode_reward": -33.33, "episode_reward_trend_value": 0.005217223607963383, "biggest_recent_change": 0.09520022171041376},
{"total_number_of_episodes": 34628, "number_of_timesteps": 8206688, "per_episode_reward": -33.3, "episode_reward_trend_value": 0.005141709669650791, "biggest_recent_change": 0.09520022171041376},
{"total_number_of_episodes": 34638, "number_of_timesteps": 8208693, "per_episode_reward": -33.26, "episode_reward_trend_value": 0.004933480339905571, "biggest_recent_change": 0.09520022171041376},
{"total_number_of_episodes": 34648, "number_of_timesteps": 8212369, "per_episode_reward": -33.24, "episode_reward_trend_value": 0.004650421704236468, "biggest_recent_change": 0.09520022171041376},
{"total_number_of_episodes": 34658, "number_of_timesteps": 8215394, "per_episode_reward": -33.2, "episode_reward_trend_value": 0.004047517088473995, "biggest_recent_change": 0.06014577015703537},
{"total_number_of_episodes": 34668, "number_of_timesteps": 8217680, "per_episode_reward": -33.16, "episode_reward_trend_value": 0.0039873251372139545, "biggest_recent_change": 0.06014577015703537},
{"total_number_of_episodes": 34678, "number_of_timesteps": 8219864, "per_episode_reward": -33.13, "episode_reward_trend_value": 0.00376598039143098, "biggest_recent_change": 0.06014577015703537},
{"total_number_of_episodes": 34688, "number_of_timesteps": 8221884, "per_episode_reward": -33.1, "episode_reward_trend_value": 0.003883165321034849, "biggest_recent_change": 0.06014577015703537},
{"total_number_of_episodes": 34698, "number_of_timesteps": 8224770, "per_episode_reward": -33.06, "episode_reward_trend_value": 0.0036538253139899745, "biggest_recent_change": 0.0540355799142489},
{"total_number_of_episodes": 34708, "number_of_timesteps": 8228053, "per_episode_reward": -32.99, "episode_reward_trend_value": 0.0038494139298210135, "biggest_recent_change": 0.0716385553390424},
{"total_number_of_episodes": 34718, "number_of_timesteps": 8230902, "per_episode_reward": -32.76, "episode_reward_trend_value": 0.005981871128095722, "biggest_recent_change": 0.22170051961000325},
{"total_number_of_episodes": 34728, "number_of_timesteps": 8234361, "per_episode_reward": -32.72, "episode_reward_trend_value": 0.005935348191169017, "biggest_recent_change": 0.22170051961000325},
{"total_number_of_episodes": 34738, "number_of_timesteps": 8236993, "per_episode_reward": -32.69, "episode_reward_trend_value": 0.006136650136284377, "biggest_recent_change": 0.22170051961000325},
{"total_number_of_episodes": 34748, "number_of_timesteps": 8240575, "per_episode_reward": -32.66, "episode_reward_trend_value": 0.006001433382233993, "biggest_recent_change": 0.22170051961000325},
{"total_number_of_episodes": 34758, "number_of_timesteps": 8243003, "per_episode_reward": -32.64, "episode_reward_trend_value": 0.005763387072786783, "biggest_recent_change": 0.22170051961000325},
{"total_number_of_episodes": 34768, "number_of_timesteps": 8246574, "per_episode_reward": -32.57, "episode_reward_trend_value": 0.006292376673813355, "biggest_recent_change": 0.22170051961000325},
{"total_number_of_episodes": 34779, "number_of_timesteps": 8249602, "per_episode_reward": -32.5, "episode_reward_trend_value": 0.006638792669871425, "biggest_recent_change": 0.22170051961000325},
{"total_number_of_episodes": 34789, "number_of_timesteps": 8253472, "per_episode_reward": -32.45, "episode_reward_trend_value": 0.006789294427108751, "biggest_recent_change": 0.22170051961000325},
{"total_number_of_episodes": 34799, "number_of_timesteps": 8255280, "per_episode_reward": -32.4, "episode_reward_trend_value": 0.006471244822257837, "biggest_recent_change": 0.22170051961000325},
{"total_number_of_episodes": 34809, "number_of_timesteps": 8257758, "per_episode_reward": -32.36, "episode_reward_trend_value": 0.004519700525431366, "biggest_recent_change": 0.07336978974394981},
{"total_number_of_episodes": 34819, "number_of_timesteps": 8259605, "per_episode_reward": -32.33, "episode_reward_trend_value": 0.004333128147050757, "biggest_recent_change": 0.07336978974394981},
{"total_number_of_episodes": 34829, "number_of_timesteps": 8262408, "per_episode_reward": -32.31, "episode_reward_trend_value": 0.004274352187312284, "biggest_recent_change": 0.07336978974394981},
{"total_number_of_episodes": 34839, "number_of_timesteps": 8264277, "per_episode_reward": -32.25, "episode_reward_trend_value": 0.004570445662138904, "biggest_recent_change": 0.07336978974394981},
{"total_number_of_episodes": 34849, "number_of_timesteps": 8267197, "per_episode_reward": -32.21, "episode_reward_trend_value": 0.004788311215667167, "biggest_recent_change": 0.07336978974394981},
{"total_number_of_episodes": 34859, "number_of_timesteps": 8269544, "per_episode_reward": -32.19, "episode_reward_trend_value": 0.004223542616747425, "biggest_recent_change": 0.06985347338532222},
{"total_number_of_episodes": 34869, "number_of_timesteps": 8273195, "per_episode_reward": -32.14, "episode_reward_trend_value": 0.003969939894915342, "biggest_recent_change": 0.055417711161652505},
{"total_number_of_episodes": 34879, "number_of_timesteps": 8277206, "per_episode_reward": -32.15, "episode_reward_trend_value": 0.003239372737833198, "biggest_recent_change": 0.055417711161652505},
{"total_number_of_episodes": 34890, "number_of_timesteps": 8280452, "per_episode_reward": -32.1, "episode_reward_trend_value": 0.0034056693056700262, "biggest_recent_change": 0.05798078200777468},
{"total_number_of_episodes": 34900, "number_of_timesteps": 8284873, "per_episode_reward": -32.08, "episode_reward_trend_value": 0.003070261114981084, "biggest_recent_change": 0.05798078200777468},
{"total_number_of_episodes": 34910, "number_of_timesteps": 8288524, "per_episode_reward": -32.07, "episode_reward_trend_value": 0.002942258270880495, "biggest_recent_change": 0.05798078200777468},
{"total_number_of_episodes": 34920, "number_of_timesteps": 8292006, "per_episode_reward": -32.03, "episode_reward_trend_value": 0.003051554331661461, "biggest_recent_change": 0.05798078200777468},
{"total_number_of_episodes": 34930, "number_of_timesteps": 8294616, "per_episode_reward": -31.95, "episode_reward_trend_value": 0.0033168487395242446, "biggest_recent_change": 0.07929420786930308},
{"total_number_of_episodes": 34940, "number_of_timesteps": 8297385, "per_episode_reward": -31.88, "episode_reward_trend_value": 0.0036821726501375766, "biggest_recent_change": 0.07929420786930308},
{"total_number_of_episodes": 34950, "number_of_timesteps": 8301508, "per_episode_reward": -31.85, "episode_reward_trend_value": 0.003765905009412604, "biggest_recent_change": 0.07929420786930308},
{"total_number_of_episodes": 34960, "number_of_timesteps": 8304577, "per_episode_reward": -31.83, "episode_reward_trend_value": 0.003492734509892001, "biggest_recent_change": 0.07929420786930308},
{"total_number_of_episodes": 34970, "number_of_timesteps": 8307220, "per_episode_reward": -31.81, "episode_reward_trend_value": 0.0038215286590756077, "biggest_recent_change": 0.07929420786930308},
{"total_number_of_episodes": 34980, "number_of_timesteps": 8310855, "per_episode_reward": -31.78, "episode_reward_trend_value": 0.003486154395018796, "biggest_recent_change": 0.07929420786930308},
{"total_number_of_episodes": 34990, "number_of_timesteps": 8314505, "per_episode_reward": -31.72, "episode_reward_trend_value": 0.003993656593436867, "biggest_recent_change": 0.07929420786930308},
{"total_number_of_episodes": 35001, "number_of_timesteps": 8317891, "per_episode_reward": -31.7, "episode_reward_trend_value": 0.004093367633606427, "biggest_recent_change": 0.07929420786930308},
{"total_number_of_episodes": 35011, "number_of_timesteps": 8321661, "per_episode_reward": -31.66, "episode_reward_trend_value": 0.004163903169321199, "biggest_recent_change": 0.07929420786930308},
{"total_number_of_episodes": 35021, "number_of_timesteps": 8324027, "per_episode_reward": -31.63, "episode_reward_trend_value": 0.003625746580743478, "biggest_recent_change": 0.07280909179061723},
{"total_number_of_episodes": 35031, "number_of_timesteps": 8327088, "per_episode_reward": -31.58, "episode_reward_trend_value": 0.0033516987710322773, "biggest_recent_change": 0.06154999359124247},
{"total_number_of_episodes": 35041, "number_of_timesteps": 8330882, "per_episode_reward": -31.56, "episode_reward_trend_value": 0.003177407654718875, "biggest_recent_change": 0.06154999359124247},
{"total_number_of_episodes": 35052, "number_of_timesteps": 8334715, "per_episode_reward": -31.52, "episode_reward_trend_value": 0.003408967578540848, "biggest_recent_change": 0.06154999359124247},
{"total_number_of_episodes": 35062, "number_of_timesteps": 8337624, "per_episode_reward": -31.5, "episode_reward_trend_value": 0.0034724921051963046, "biggest_recent_change": 0.06154999359124247},
{"total_number_of_episodes": 35072, "number_of_timesteps": 8341259, "per_episode_reward": -31.49, "episode_reward_trend_value": 0.0033036052211669817, "biggest_recent_change": 0.06154999359124247},
{"total_number_of_episodes": 35082, "number_of_timesteps": 8344526, "per_episode_reward": -31.46, "episode_reward_trend_value": 0.0029436169822542268, "biggest_recent_change": 0.048144788916609116},
{"total_number_of_episodes": 35092, "number_of_timesteps": 8348552, "per_episode_reward": -31.4, "episode_reward_trend_value": 0.003309483615455101, "biggest_recent_change": 0.05243673533599136},
{"total_number_of_episodes": 35102, "number_of_timesteps": 8352943, "per_episode_reward": -31.34, "episode_reward_trend_value": 0.0034924548212510427, "biggest_recent_change": 0.0608483953158121},
{"total_number_of_episodes": 35112, "number_of_timesteps": 8356294, "per_episode_reward": -31.24, "episode_reward_trend_value": 0.0042578753367824304, "biggest_recent_change": 0.09974796129513308},
{"total_number_of_episodes": 35122, "number_of_timesteps": 8359684, "per_episode_reward": -31.2, "episode_reward_trend_value": 0.004163785598274335, "biggest_recent_change": 0.09974796129513308},
{"total_number_of_episodes": 35132, "number_of_timesteps": 8362726, "per_episode_reward": -31.17, "episode_reward_trend_value": 0.004360793563878415, "biggest_recent_change": 0.09974796129513308},
{"total_number_of_episodes": 35142, "number_of_timesteps": 8365993, "per_episode_reward": -31.08, "episode_reward_trend_value": 0.004853360276120119, "biggest_recent_change": 0.09974796129513308},
{"total_number_of_episodes": 35153, "number_of_timesteps": 8370750, "per_episode_reward": -31.03, "episode_reward_trend_value": 0.0052070849456291686, "biggest_recent_change": 0.09974796129513308},
{"total_number_of_episodes": 35163, "number_of_timesteps": 8373225, "per_episode_reward": -30.97, "episode_reward_trend_value": 0.005745075852756424, "biggest_recent_change": 0.09974796129513308},
{"total_number_of_episodes": 35173, "number_of_timesteps": 8376050, "per_episode_reward": -30.94, "episode_reward_trend_value": 0.005727570477348268, "biggest_recent_change": 0.09974796129513308},
{"total_number_of_episodes": 35183, "number_of_timesteps": 8382120, "per_episode_reward": -30.93, "episode_reward_trend_value": 0.005311362844612333, "biggest_recent_change": 0.09974796129513308},
{"total_number_of_episodes": 35193, "number_of_timesteps": 8387606, "per_episode_reward": -30.89, "episode_reward_trend_value": 0.005049192654613677, "biggest_recent_change": 0.09974796129513308},
{"total_number_of_episodes": 35203, "number_of_timesteps": 8392286, "per_episode_reward": -30.85, "episode_reward_trend_value": 0.004358422352882366, "biggest_recent_change": 0.08761528070931135},
{"total_number_of_episodes": 35213, "number_of_timesteps": 8396291, "per_episode_reward": -30.81, "episode_reward_trend_value": 0.004402857636014288, "biggest_recent_change": 0.08761528070931135},
{"total_number_of_episodes": 35223, "number_of_timesteps": 8400346, "per_episode_reward": -30.79, "episode_reward_trend_value": 0.004251932931000842, "biggest_recent_change": 0.08761528070931135},
{"total_number_of_episodes": 35233, "number_of_timesteps": 8405088, "per_episode_reward": -30.75, "episode_reward_trend_value": 0.003674124111373721, "biggest_recent_change": 0.06101646032147556},
{"total_number_of_episodes": 35243, "number_of_timesteps": 8409570, "per_episode_reward": -30.61, "episode_reward_trend_value": 0.004700733021861699, "biggest_recent_change": 0.14683798656221114},
{"total_number_of_episodes": 35253, "number_of_timesteps": 8413184, "per_episode_reward": -30.59, "episode_reward_trend_value": 0.004251787666183068, "biggest_recent_change": 0.14683798656221114},

{"total_number_of_episodes": 35263, "number_of_timesteps": 8416847, "per_episode_reward": -30.54, "episode_reward_trend_value": 0.004434368060262746, "biggest_recent_change": 0.14683798656221114},
{"total_number_of_episodes": 35273, "number_of_timesteps": 8419641, "per_episode_reward": -30.49, "episode_reward_trend_value": 0.004823853373451215, "biggest_recent_change": 0.14683798656221114},
{"total_number_of_episodes": 35283, "number_of_timesteps": 8422523, "per_episode_reward": -30.47, "episode_reward_trend_value": 0.004610516123911168, "biggest_recent_change": 0.14683798656221114},
{"total_number_of_episodes": 35293, "number_of_timesteps": 8425149, "per_episode_reward": -30.44, "episode_reward_trend_value": 0.00456270284960267, "biggest_recent_change": 0.14683798656221114},
{"total_number_of_episodes": 35304, "number_of_timesteps": 8428178, "per_episode_reward": -30.37, "episode_reward_trend_value": 0.004877373620186671, "biggest_recent_change": 0.14683798656221114},
{"total_number_of_episodes": 35314, "number_of_timesteps": 8431999, "per_episode_reward": -30.35, "episode_reward_trend_value": 0.004837525823509144, "biggest_recent_change": 0.14683798656221114},
{"total_number_of_episodes": 35324, "number_of_timesteps": 8434044, "per_episode_reward": -30.34, "episode_reward_trend_value": 0.0046209479586014224, "biggest_recent_change": 0.14683798656221114},
{"total_number_of_episodes": 35334, "number_of_timesteps": 8437160, "per_episode_reward": -30.32, "episode_reward_trend_value": 0.003168371061326328, "biggest_recent_change": 0.07199625728531345},
{"total_number_of_episodes": 35344, "number_of_timesteps": 8439478, "per_episode_reward": -30.3, "episode_reward_trend_value": 0.0031260482084986855, "biggest_recent_change": 0.07199625728531345},
{"total_number_of_episodes": 35354, "number_of_timesteps": 8441630, "per_episode_reward": -30.29, "episode_reward_trend_value": 0.002844000599340843, "biggest_recent_change": 0.07199625728531345},
{"total_number_of_episodes": 35364, "number_of_timesteps": 8443900, "per_episode_reward": -30.26, "episode_reward_trend_value": 0.002614750959906371, "biggest_recent_change": 0.07199625728531345},
{"total_number_of_episodes": 35374, "number_of_timesteps": 8447439, "per_episode_reward": -30.16, "episode_reward_trend_value": 0.0034961301959374365, "biggest_recent_change": 0.09737685700012477},
{"total_number_of_episodes": 35384, "number_of_timesteps": 8453057, "per_episode_reward": -30.15, "episode_reward_trend_value": 0.003196271456272726, "biggest_recent_change": 0.09737685700012477},
{"total_number_of_episodes": 35394, "number_of_timesteps": 8455956, "per_episode_reward": -30.13, "episode_reward_trend_value": 0.0026990909243098807, "biggest_recent_change": 0.09737685700012477},
{"total_number_of_episodes": 35404, "number_of_timesteps": 8459748, "per_episode_reward": -30.09, "episode_reward_trend_value": 0.0028961134963873844, "biggest_recent_change": 0.09737685700012477},
{"total_number_of_episodes": 35414, "number_of_timesteps": 8463758, "per_episode_reward": -30.05, "episode_reward_trend_value": 0.0031747021439090793, "biggest_recent_change": 0.09737685700012477},
{"total_number_of_episodes": 35424, "number_of_timesteps": 8465974, "per_episode_reward": -30.03, "episode_reward_trend_value": 0.00327256474133431, "biggest_recent_change": 0.09737685700012477},
{"total_number_of_episodes": 35434, "number_of_timesteps": 8468100, "per_episode_reward": -30.0, "episode_reward_trend_value": 0.0033440503474945473, "biggest_recent_change": 0.09737685700012477},
{"total_number_of_episodes": 35444, "number_of_timesteps": 8470969, "per_episode_reward": -29.95, "episode_reward_trend_value": 0.0037587325025437144, "biggest_recent_change": 0.09737685700012477},
{"total_number_of_episodes": 35454, "number_of_timesteps": 8475031, "per_episode_reward": -29.94, "episode_reward_trend_value": 0.003560283493359901, "biggest_recent_change": 0.09737685700012477},
{"total_number_of_episodes": 35464, "number_of_timesteps": 8479001, "per_episode_reward": -29.91, "episode_reward_trend_value": 0.0027684001561005074, "biggest_recent_change": 0.055944912899750676},
{"total_number_of_episodes": 35474, "number_of_timesteps": 8481646, "per_episode_reward": -29.87, "episode_reward_trend_value": 0.0031718881228360294, "biggest_recent_change": 0.055944912899750676},
{"total_number_of_episodes": 35484, "number_of_timesteps": 8484285, "per_episode_reward": -29.83, "episode_reward_trend_value": 0.003249489634483401, "biggest_recent_change": 0.055944912899750676},
{"total_number_of_episodes": 35494, "number_of_timesteps": 8486834, "per_episode_reward": -29.81, "episode_reward_trend_value": 0.003142489281258736, "biggest_recent_change": 0.055944912899750676},
{"total_number_of_episodes": 35504, "number_of_timesteps": 8489578, "per_episode_reward": -29.74, "episode_reward_trend_value": 0.0034035736172861103, "biggest_recent_change": 0.06469104762059175},
{"total_number_of_episodes": 35514, "number_of_timesteps": 8494391, "per_episode_reward": -29.71, "episode_reward_trend_value": 0.0034711126900103377, "biggest_recent_change": 0.06469104762059175},
{"total_number_of_episodes": 35525, "number_of_timesteps": 8497777, "per_episode_reward": -29.68, "episode_reward_trend_value": 0.003552056555696284, "biggest_recent_change": 0.06469104762059175},
{"total_number_of_episodes": 35535, "number_of_timesteps": 8501383, "per_episode_reward": -29.66, "episode_reward_trend_value": 0.0031978987293994426, "biggest_recent_change": 0.06469104762059175},
{"total_number_of_episodes": 35545, "number_of_timesteps": 8503963, "per_episode_reward": -29.63, "episode_reward_trend_value": 0.003357305380397256, "biggest_recent_change": 0.06469104762059175},
{"total_number_of_episodes": 35557, "number_of_timesteps": 8507630, "per_episode_reward": -29.61, "episode_reward_trend_value": 0.0033640489659846813, "biggest_recent_change": 0.06469104762059175},
{"total_number_of_episodes": 35567, "number_of_timesteps": 8511532, "per_episode_reward": -29.6, "episode_reward_trend_value": 0.0029208082644574616, "biggest_recent_change": 0.06469104762059175},
{"total_number_of_episodes": 35577, "number_of_timesteps": 8515447, "per_episode_reward": -29.59, "episode_reward_trend_value": 0.0026533678154351827, "biggest_recent_change": 0.06469104762059175},

{"total_number_of_episodes": 35587, "number_of_timesteps": 8519663, "per_episode_reward": -29.57, "episode_reward_trend_value": 0.002699930514361526, "biggest_recent_change": 0.06469104762059175},
{"total_number_of_episodes": 35597, "number_of_timesteps": 8524247, "per_episode_reward": -29.54, "episode_reward_trend_value": 0.002246658647472641, "biggest_recent_change": 0.03099221612090375},
{"total_number_of_episodes": 35607, "number_of_timesteps": 8527633, "per_episode_reward": -29.52, "episode_reward_trend_value": 0.002108029923165944, "biggest_recent_change": 0.03052097402206755},
{"total_number_of_episodes": 35617, "number_of_timesteps": 8529902, "per_episode_reward": -29.47, "episode_reward_trend_value": 0.00234585015003156, "biggest_recent_change": 0.051924794439973},
{"total_number_of_episodes": 35627, "number_of_timesteps": 8533489, "per_episode_reward": -29.43, "episode_reward_trend_value": 0.002505616637388523, "biggest_recent_change": 0.051924794439973},
{"total_number_of_episodes": 35637, "number_of_timesteps": 8536095, "per_episode_reward": -29.4, "episode_reward_trend_value": 0.0026052476512220266, "biggest_recent_change": 0.051924794439973},
{"total_number_of_episodes": 35647, "number_of_timesteps": 8538005, "per_episode_reward": -29.35, "episode_reward_trend_value": 0.0028375404672024178, "biggest_recent_change": 0.051924794439973},
{"total_number_of_episodes": 35657, "number_of_timesteps": 8540586, "per_episode_reward": -29.31, "episode_reward_trend_value": 0.00322463482621767, "biggest_recent_change": 0.051924794439973},
{"total_number_of_episodes": 35667, "number_of_timesteps": 8542928, "per_episode_reward": -29.27, "episode_reward_trend_value": 0.0036192193542513547, "biggest_recent_change": 0.051924794439973},
{"total_number_of_episodes": 35677, "number_of_timesteps": 8546921, "per_episode_reward": -29.22, "episode_reward_trend_value": 0.0038392259255892783, "biggest_recent_change": 0.051924794439973},
{"total_number_of_episodes": 35687, "number_of_timesteps": 8549680, "per_episode_reward": -29.2, "episode_reward_trend_value": 0.0038326172746941723, "biggest_recent_change": 0.051924794439973},

{"total_number_of_episodes": 35698, "number_of_timesteps": 8552870, "per_episode_reward": -29.17, "episode_reward_trend_value": 0.0039581962098529525, "biggest_recent_change": 0.051924794439973},
{"total_number_of_episodes": 35708, "number_of_timesteps": 8554717, "per_episode_reward": -29.14, "episode_reward_trend_value": 0.0036971777822405413, "biggest_recent_change": 0.047620632787882755},
{"total_number_of_episodes": 35718, "number_of_timesteps": 8557693, "per_episode_reward": -29.12, "episode_reward_trend_value": 0.0035345535779604297, "biggest_recent_change": 0.047620632787882755},
{"total_number_of_episodes": 35729, "number_of_timesteps": 8559875, "per_episode_reward": -29.06, "episode_reward_trend_value": 0.003746179589444646, "biggest_recent_change": 0.05389857906947171},
{"total_number_of_episodes": 35739, "number_of_timesteps": 8563035, "per_episode_reward": -29.04, "episode_reward_trend_value": 0.00341973270495441, "biggest_recent_change": 0.05389857906947171},
{"total_number_of_episodes": 35750, "number_of_timesteps": 8566777, "per_episode_reward": -28.92, "episode_reward_trend_value": 0.004350761271888043, "biggest_recent_change": 0.12134147008587348},
{"total_number_of_episodes": 35760, "number_of_timesteps": 8568786, "per_episode_reward": -28.83, "episode_reward_trend_value": 0.004881000058445059, "biggest_recent_change": 0.12134147008587348},
{"total_number_of_episodes": 35770, "number_of_timesteps": 8570580, "per_episode_reward": -28.81, "episode_reward_trend_value": 0.004552199434176963, "biggest_recent_change": 0.12134147008587348},
{"total_number_of_episodes": 35780, "number_of_timesteps": 8573591, "per_episode_reward": -28.77, "episode_reward_trend_value": 0.004801984588770322, "biggest_recent_change": 0.12134147008587348},
{"total_number_of_episodes": 35790, "number_of_timesteps": 8576238, "per_episode_reward": -28.71, "episode_reward_trend_value": 0.005106693972972446, "biggest_recent_change": 0.12134147008587348},
{"total_number_of_episodes": 35801, "number_of_timesteps": 8580052, "per_episode_reward": -28.66, "episode_reward_trend_value": 0.0053469893395673065, "biggest_recent_change": 0.12134147008587348},
{"total_number_of_episodes": 35812, "number_of_timesteps": 8583405, "per_episode_reward": -28.62, "episode_reward_trend_value": 0.005503158515456303, "biggest_recent_change": 0.12134147008587348},
{"total_number_of_episodes": 35822, "number_of_timesteps": 8587330, "per_episode_reward": -28.61, "episode_reward_trend_value": 0.0049917949901105, "biggest_recent_change": 0.12134147008587348},
{"total_number_of_episodes": 35833, "number_of_timesteps": 8591286, "per_episode_reward": -28.57, "episode_reward_trend_value": 0.005232539221278011, "biggest_recent_change": 0.12134147008587348},
{"total_number_of_episodes": 35843, "number_of_timesteps": 8594309, "per_episode_reward": -28.56, "episode_reward_trend_value": 0.004057890409972526, "biggest_recent_change": 0.0933986033580787},
{"total_number_of_episodes": 35853, "number_of_timesteps": 8596332, "per_episode_reward": -28.52, "episode_reward_trend_value": 0.00345714229641432, "biggest_recent_change": 0.05724157967578236},
{"total_number_of_episodes": 35863, "number_of_timesteps": 8598407, "per_episode_reward": -28.51, "episode_reward_trend_value": 0.0033920635736159, "biggest_recent_change": 0.05724157967578236},
{"total_number_of_episodes": 35873, "number_of_timesteps": 8601839, "per_episode_reward": -28.45, "episode_reward_trend_value": 0.003502881067976244, "biggest_recent_change": 0.05724157967578236},
{"total_number_of_episodes": 35885, "number_of_timesteps": 8604492, "per_episode_reward": -28.37, "episode_reward_trend_value": 0.0037585532771983545, "biggest_recent_change": 0.08025207850577232},
{"total_number_of_episodes": 35896, "number_of_timesteps": 8607151, "per_episode_reward": -28.25, "episode_reward_trend_value": 0.004573660443089583, "biggest_recent_change": 0.12341936387860386},
{"total_number_of_episodes": 35906, "number_of_timesteps": 8609410, "per_episode_reward": -28.15, "episode_reward_trend_value": 0.005245840248189321, "biggest_recent_change": 0.12341936387860386},
{"total_number_of_episodes": 35916, "number_of_timesteps": 8613007, "per_episode_reward": -28.1, "episode_reward_trend_value": 0.005699450242688937, "biggest_recent_change": 0.12341936387860386},
{"total_number_of_episodes": 35926, "number_of_timesteps": 8615983, "per_episode_reward": -28.08, "episode_reward_trend_value": 0.005459724553575837, "biggest_recent_change": 0.12341936387860386},

{"total_number_of_episodes": 35936, "number_of_timesteps": 8619231, "per_episode_reward": -28.05, "episode_reward_trend_value": 0.005613569715136929, "biggest_recent_change": 0.12341936387860386},
{"total_number_of_episodes": 35946, "number_of_timesteps": 8621810, "per_episode_reward": -28.04, "episode_reward_trend_value": 0.00526600063296251, "biggest_recent_change": 0.12341936387860386},
{"total_number_of_episodes": 35956, "number_of_timesteps": 8624176, "per_episode_reward": -28.02, "episode_reward_trend_value": 0.005371994401337569, "biggest_recent_change": 0.12341936387860386},
{"total_number_of_episodes": 35966, "number_of_timesteps": 8627237, "per_episode_reward": -28.0, "episode_reward_trend_value": 0.00500717890125269, "biggest_recent_change": 0.12341936387860386},
{"total_number_of_episodes": 35976, "number_of_timesteps": 8630905, "per_episode_reward": -27.98, "episode_reward_trend_value": 0.00428633704057175, "biggest_recent_change": 0.12341936387860386},
{"total_number_of_episodes": 35986, "number_of_timesteps": 8633733, "per_episode_reward": -27.97, "episode_reward_trend_value": 0.003098593260228376, "biggest_recent_change": 0.09836492229893778},
{"total_number_of_episodes": 35996, "number_of_timesteps": 8635900, "per_episode_reward": -27.93, "episode_reward_trend_value": 0.002470782384089966, "biggest_recent_change": 0.0487007612933148},
{"total_number_of_episodes": 36006, "number_of_timesteps": 8639718, "per_episode_reward": -27.87, "episode_reward_trend_value": 0.00251514456609101, "biggest_recent_change": 0.05269335767340877},
{"total_number_of_episodes": 36016, "number_of_timesteps": 8643717, "per_episode_reward": -27.82, "episode_reward_trend_value": 0.002862044721274554, "biggest_recent_change": 0.05269335767340877},
{"total_number_of_episodes": 36026, "number_of_timesteps": 8648306, "per_episode_reward": -27.78, "episode_reward_trend_value": 0.0030684996585019775, "biggest_recent_change": 0.05269335767340877},
{"total_number_of_episodes": 36036, "number_of_timesteps": 8652946, "per_episode_reward": -27.71, "episode_reward_trend_value": 0.00368171049117206, "biggest_recent_change": 0.06323903068244974},
{"total_number_of_episodes": 36046, "number_of_timesteps": 8656619, "per_episode_reward": -27.7, "episode_reward_trend_value": 0.0035435077860703026, "biggest_recent_change": 0.06323903068244974},
{"total_number_of_episodes": 36056, "number_of_timesteps": 8660302, "per_episode_reward": -27.65, "episode_reward_trend_value": 0.003868369409593697, "biggest_recent_change": 0.06323903068244974},
{"total_number_of_episodes": 36066, "number_of_timesteps": 8662702, "per_episode_reward": -27.64, "episode_reward_trend_value": 0.0038460006154818495, "biggest_recent_change": 0.06323903068244974},
{"total_number_of_episodes": 36076, "number_of_timesteps": 8665039, "per_episode_reward": -27.63, "episode_reward_trend_value": 0.003763110353568698, "biggest_recent_change": 0.06323903068244974},
{"total_number_of_episodes": 36086, "number_of_timesteps": 8668600, "per_episode_reward": -27.61, "episode_reward_trend_value": 0.0034588803060818427, "biggest_recent_change": 0.06323903068244974},
{"total_number_of_episodes": 36096, "number_of_timesteps": 8671533, "per_episode_reward": -27.55, "episode_reward_trend_value": 0.0035698679477513275, "biggest_recent_change": 0.06323903068244974},
{"total_number_of_episodes": 36106, "number_of_timesteps": 8674495, "per_episode_reward": -27.54, "episode_reward_trend_value": 0.003155120794021668, "biggest_recent_change": 0.06323903068244974},
{"total_number_of_episodes": 36116, "number_of_timesteps": 8677840, "per_episode_reward": -27.53, "episode_reward_trend_value": 0.0027014134554312207, "biggest_recent_change": 0.06323903068244974},
{"total_number_of_episodes": 36126, "number_of_timesteps": 8680873, "per_episode_reward": -27.48, "episode_reward_trend_value": 0.002608687265723909, "biggest_recent_change": 0.06268224542366241},
{"total_number_of_episodes": 36136, "number_of_timesteps": 8683548, "per_episode_reward": -27.44, "episode_reward_trend_value": 0.00296530910918891, "biggest_recent_change": 0.06268224542366241},
{"total_number_of_episodes": 36146, "number_of_timesteps": 8686040, "per_episode_reward": -27.4, "episode_reward_trend_value": 0.0027448689442679825, "biggest_recent_change": 0.06268224542366241},
{"total_number_of_episodes": 36156, "number_of_timesteps": 8689697, "per_episode_reward": -27.36, "episode_reward_trend_value": 0.003052697668423221, "biggest_recent_change": 0.06268224542366241},
{"total_number_of_episodes": 36166, "number_of_timesteps": 8692040, "per_episode_reward": -27.32, "episode_reward_trend_value": 0.003418517135181295, "biggest_recent_change": 0.06268224542366241},
{"total_number_of_episodes": 36176, "number_of_timesteps": 8695614, "per_episode_reward": -27.23, "episode_reward_trend_value": 0.004285634035260265, "biggest_recent_change": 0.0925217601797712},
{"total_number_of_episodes": 36186, "number_of_timesteps": 8699375, "per_episode_reward": -27.2, "episode_reward_trend_value": 0.0038745510946471976, "biggest_recent_change": 0.0925217601797712},
{"total_number_of_episodes": 36196, "number_of_timesteps": 8702178, "per_episode_reward": -27.16, "episode_reward_trend_value": 0.004173497508505027, "biggest_recent_change": 0.0925217601797712},
{"total_number_of_episodes": 36206, "number_of_timesteps": 8706189, "per_episode_reward": -27.12, "episode_reward_trend_value": 0.004552045801889193, "biggest_recent_change": 0.0925217601797712},
{"total_number_of_episodes": 36216, "number_of_timesteps": 8709967, "per_episode_reward": -27.02, "episode_reward_trend_value": 0.005049560062582259, "biggest_recent_change": 0.09966995707116766},
{"total_number_of_episodes": 36226, "number_of_timesteps": 8713752, "per_episode_reward": -26.95, "episode_reward_trend_value": 0.005423522066662143, "biggest_recent_change": 0.09966995707116766},
{"total_number_of_episodes": 36236, "number_of_timesteps": 8716509, "per_episode_reward": -26.93, "episode_reward_trend_value": 0.005324031680120219, "biggest_recent_change": 0.09966995707116766},
{"total_number_of_episodes": 36246, "number_of_timesteps": 8719485, "per_episode_reward": -26.9, "episode_reward_trend_value": 0.005179419455234088, "biggest_recent_change": 0.09966995707116766},
{"total_number_of_episodes": 36256, "number_of_timesteps": 8724211, "per_episode_reward": -26.88, "episode_reward_trend_value": 0.004865891015191911, "biggest_recent_change": 0.09966995707116766},
{"total_number_of_episodes": 36266, "number_of_timesteps": 8727039, "per_episode_reward": -26.85, "episode_reward_trend_value": 0.0041897990991103026, "biggest_recent_change": 0.09966995707116766},

{"total_number_of_episodes": 36276, "number_of_timesteps": 8730010, "per_episode_reward": -26.78, "episode_reward_trend_value": 0.004682048086599503, "biggest_recent_change": 0.09966995707116766},
{"total_number_of_episodes": 36286, "number_of_timesteps": 8733785, "per_episode_reward": -26.75, "episode_reward_trend_value": 0.004558121065302759, "biggest_recent_change": 0.09966995707116766},
{"total_number_of_episodes": 36296, "number_of_timesteps": 8736056, "per_episode_reward": -26.74, "episode_reward_trend_value": 0.0042442626554397124, "biggest_recent_change": 0.09966995707116766},
{"total_number_of_episodes": 36308, "number_of_timesteps": 8739469, "per_episode_reward": -26.73, "episode_reward_trend_value": 0.0033095844353404798, "biggest_recent_change": 0.07444935421808907},
{"total_number_of_episodes": 36319, "number_of_timesteps": 8742311, "per_episode_reward": -26.7, "episode_reward_trend_value": 0.0028023733646477924, "biggest_recent_change": 0.06998718964251438},
{"total_number_of_episodes": 36329, "number_of_timesteps": 8744614, "per_episode_reward": -26.67, "episode_reward_trend_value": 0.0028540195533735928, "biggest_recent_change": 0.06998718964251438},
{"total_number_of_episodes": 36339, "number_of_timesteps": 8746910, "per_episode_reward": -26.64, "episode_reward_trend_value": 0.0028762409760088384, "biggest_recent_change": 0.06998718964251438},
{"total_number_of_episodes": 36350, "number_of_timesteps": 8750036, "per_episode_reward": -26.6, "episode_reward_trend_value": 0.003142649847081221, "biggest_recent_change": 0.06998718964251438},
{"total_number_of_episodes": 36361, "number_of_timesteps": 8753160, "per_episode_reward": -26.57, "episode_reward_trend_value": 0.003171781675892957, "biggest_recent_change": 0.06998718964251438},
{"total_number_of_episodes": 36371, "number_of_timesteps": 8755706, "per_episode_reward": -26.53, "episode_reward_trend_value": 0.0028187761161711693, "biggest_recent_change": 0.038216689267553505},
{"total_number_of_episodes": 36381, "number_of_timesteps": 8757970, "per_episode_reward": -26.51, "episode_reward_trend_value": 0.0027080430524177262, "biggest_recent_change": 0.038216689267553505},
{"total_number_of_episodes": 36391, "number_of_timesteps": 8760490, "per_episode_reward": -26.5, "episode_reward_trend_value": 0.0026746720101278026, "biggest_recent_change": 0.038216689267553505},
{"total_number_of_episodes": 36401, "number_of_timesteps": 8763729, "per_episode_reward": -26.48, "episode_reward_trend_value": 0.002768615713658167, "biggest_recent_change": 0.038216689267553505},
{"total_number_of_episodes": 36411, "number_of_timesteps": 8766174, "per_episode_reward": -26.45, "episode_reward_trend_value": 0.002753386919858119, "biggest_recent_change": 0.038216689267553505},
{"total_number_of_episodes": 36421, "number_of_timesteps": 8769099, "per_episode_reward": -26.42, "episode_reward_trend_value": 0.002730127299995999, "biggest_recent_change": 0.038216689267553505},
{"total_number_of_episodes": 36431, "number_of_timesteps": 8772878, "per_episode_reward": -26.38, "episode_reward_trend_value": 0.0028771280904845834, "biggest_recent_change": 0.04328260368978576},
{"total_number_of_episodes": 36441, "number_of_timesteps": 8775828, "per_episode_reward": -26.34, "episode_reward_trend_value": 0.002869653062453479, "biggest_recent_change": 0.04328260368978576},
{"total_number_of_episodes": 36451, "number_of_timesteps": 8779422, "per_episode_reward": -26.29, "episode_reward_trend_value": 0.0030466863445623303, "biggest_recent_change": 0.0502283477152794},
{"total_number_of_episodes": 36461, "number_of_timesteps": 8781814, "per_episode_reward": -26.23, "episode_reward_trend_value": 0.003257720402916596, "biggest_recent_change": 0.05720975451943744},
{"total_number_of_episodes": 36471, "number_of_timesteps": 8784189, "per_episode_reward": -26.2, "episode_reward_trend_value": 0.003418110087914607, "biggest_recent_change": 0.05720975451943744},
{"total_number_of_episodes": 36481, "number_of_timesteps": 8786809, "per_episode_reward": -26.17, "episode_reward_trend_value": 0.0036259804785025948, "biggest_recent_change": 0.05720975451943744},
{"total_number_of_episodes": 36491, "number_of_timesteps": 8790540, "per_episode_reward": -26.13, "episode_reward_trend_value": 0.0038357044219583573, "biggest_recent_change": 0.05720975451943744},
{"total_number_of_episodes": 36501, "number_of_timesteps": 8793331, "per_episode_reward": -26.1, "episode_reward_trend_value": 0.0038292276168101743, "biggest_recent_change": 0.05720975451943744},
{"total_number_of_episodes": 36511, "number_of_timesteps": 8795916, "per_episode_reward": -26.08, "episode_reward_trend_value": 0.00384201449412021, "biggest_recent_change": 0.05720975451943744},

{"total_number_of_episodes": 36521, "number_of_timesteps": 8797914, "per_episode_reward": -26.02, "episode_reward_trend_value": 0.003995844373062754, "biggest_recent_change": 0.05720975451943744},
{"total_number_of_episodes": 36531, "number_of_timesteps": 8800383, "per_episode_reward": -25.99, "episode_reward_trend_value": 0.003870843504261777, "biggest_recent_change": 0.05720975451943744},
{"total_number_of_episodes": 36541, "number_of_timesteps": 8803570, "per_episode_reward": -25.9, "episode_reward_trend_value": 0.004386458118555107, "biggest_recent_change": 0.09663366300167908},
{"total_number_of_episodes": 36551, "number_of_timesteps": 8805482, "per_episode_reward": -25.87, "episode_reward_trend_value": 0.004050478534679295, "biggest_recent_change": 0.09663366300167908},
{"total_number_of_episodes": 36561, "number_of_timesteps": 8808374, "per_episode_reward": -25.84, "episode_reward_trend_value": 0.004041027988097312, "biggest_recent_change": 0.09663366300167908},
{"total_number_of_episodes": 36571, "number_of_timesteps": 8811306, "per_episode_reward": -25.81, "episode_reward_trend_value": 0.004093564471992374, "biggest_recent_change": 0.09663366300167908},
{"total_number_of_episodes": 36581, "number_of_timesteps": 8813660, "per_episode_reward": -25.74, "episode_reward_trend_value": 0.0043518454276194355, "biggest_recent_change": 0.09663366300167908},
{"total_number_of_episodes": 36591, "number_of_timesteps": 8815826, "per_episode_reward": -25.7, "episode_reward_trend_value": 0.004537969057984625, "biggest_recent_change": 0.09663366300167908},
{"total_number_of_episodes": 36601, "number_of_timesteps": 8819401, "per_episode_reward": -25.67, "episode_reward_trend_value": 0.004500508890577453, "biggest_recent_change": 0.09663366300167908},
{"total_number_of_episodes": 36611, "number_of_timesteps": 8821736, "per_episode_reward": -25.65, "episode_reward_trend_value": 0.0040821954381542016, "biggest_recent_change": 0.09663366300167908},
{"total_number_of_episodes": 36621, "number_of_timesteps": 8823816, "per_episode_reward": -25.59, "episode_reward_trend_value": 0.004445068598219888, "biggest_recent_change": 0.09663366300167908},
{"total_number_of_episodes": 36631, "number_of_timesteps": 8826762, "per_episode_reward": -25.54, "episode_reward_trend_value": 0.0039915455650453655, "biggest_recent_change": 0.06612429149742383},
{"total_number_of_episodes": 36641, "number_of_timesteps": 8829580, "per_episode_reward": -25.52, "episode_reward_trend_value": 0.0038795973600335523, "biggest_recent_change": 0.06612429149742383},
{"total_number_of_episodes": 36651, "number_of_timesteps": 8832728, "per_episode_reward": -25.49, "episode_reward_trend_value": 0.003911010355335955, "biggest_recent_change": 0.06612429149742383},
{"total_number_of_episodes": 36662, "number_of_timesteps": 8835572, "per_episode_reward": -25.46, "episode_reward_trend_value": 0.00387334300678693, "biggest_recent_change": 0.06612429149742383},
{"total_number_of_episodes": 36672, "number_of_timesteps": 8837579, "per_episode_reward": -25.36, "episode_reward_trend_value": 0.0042091598829543785, "biggest_recent_change": 0.09634781035249418},
{"total_number_of_episodes": 36682, "number_of_timesteps": 8839418, "per_episode_reward": -25.34, "episode_reward_trend_value": 0.003895976287533287, "biggest_recent_change": 0.09634781035249418},
{"total_number_of_episodes": 36693, "number_of_timesteps": 8841898, "per_episode_reward": -25.33, "episode_reward_trend_value": 0.0038024137140750176, "biggest_recent_change": 0.09634781035249418},
{"total_number_of_episodes": 36703, "number_of_timesteps": 8844599, "per_episode_reward": -25.32, "episode_reward_trend_value": 0.003697707224605848, "biggest_recent_change": 0.09634781035249418},
{"total_number_of_episodes": 36713, "number_of_timesteps": 8847517, "per_episode_reward": -25.31, "episode_reward_trend_value": 0.003146721986745386, "biggest_recent_change": 0.09634781035249418},
{"total_number_of_episodes": 36723, "number_of_timesteps": 8850126, "per_episode_reward": -25.27, "episode_reward_trend_value": 0.003024061070254744, "biggest_recent_change": 0.09634781035249418},
{"total_number_of_episodes": 36733, "number_of_timesteps": 8852485, "per_episode_reward": -25.24, "episode_reward_trend_value": 0.0030865159286282305, "biggest_recent_change": 0.09634781035249418},
{"total_number_of_episodes": 36743, "number_of_timesteps": 8854906, "per_episode_reward": -25.23, "episode_reward_trend_value": 0.002862205657260317, "biggest_recent_change": 0.09634781035249418},
{"total_number_of_episodes": 36753, "number_of_timesteps": 8857179, "per_episode_reward": -25.21, "episode_reward_trend_value": 0.002723187680209528, "biggest_recent_change": 0.09634781035249418},
{"total_number_of_episodes": 36763, "number_of_timesteps": 8858896, "per_episode_reward": -25.18, "episode_reward_trend_value": 0.002003491643669027, "biggest_recent_change": 0.04477710753181441},
{"total_number_of_episodes": 36773, "number_of_timesteps": 8861172, "per_episode_reward": -25.13, "episode_reward_trend_value": 0.0023379514351773876, "biggest_recent_change": 0.045512838331127625},
{"total_number_of_episodes": 36783, "number_of_timesteps": 8864135, "per_episode_reward": -25.11, "episode_reward_trend_value": 0.002427552823621326, "biggest_recent_change": 0.045512838331127625},
{"total_number_of_episodes": 36793, "number_of_timesteps": 8867571, "per_episode_reward": -25.09, "episode_reward_trend_value": 0.0025227922046487175, "biggest_recent_change": 0.045512838331127625},
{"total_number_of_episodes": 36803, "number_of_timesteps": 8869581, "per_episode_reward": -25.06, "episode_reward_trend_value": 0.0027745608648377384, "biggest_recent_change": 0.045512838331127625},
{"total_number_of_episodes": 36813, "number_of_timesteps": 8872462, "per_episode_reward": -25.01, "episode_reward_trend_value": 0.0028749141299986686, "biggest_recent_change": 0.053808901396298126},
{"total_number_of_episodes": 36823, "number_of_timesteps": 8874484, "per_episode_reward": -24.96, "episode_reward_trend_value": 0.0031772196531399286, "biggest_recent_change": 0.053808901396298126},
{"total_number_of_episodes": 36833, "number_of_timesteps": 8876766, "per_episode_reward": -24.92, "episode_reward_trend_value": 0.003405442632583839, "biggest_recent_change": 0.053808901396298126},
{"total_number_of_episodes": 36843, "number_of_timesteps": 8880813, "per_episode_reward": -24.85, "episode_reward_trend_value": 0.004032896937759508, "biggest_recent_change": 0.07404094806231498},

{"total_number_of_episodes": 36853, "number_of_timesteps": 8883831, "per_episode_reward": -24.82, "episode_reward_trend_value": 0.003969451577068858, "biggest_recent_change": 0.07404094806231498},
{"total_number_of_episodes": 36863, "number_of_timesteps": 8887053, "per_episode_reward": -24.76, "episode_reward_trend_value": 0.004193573556954375, "biggest_recent_change": 0.07404094806231498},
{"total_number_of_episodes": 36873, "number_of_timesteps": 8890187, "per_episode_reward": -24.71, "episode_reward_trend_value": 0.004498463858737702, "biggest_recent_change": 0.07404094806231498},
{"total_number_of_episodes": 36883, "number_of_timesteps": 8892678, "per_episode_reward": -24.69, "episode_reward_trend_value": 0.004501836938589953, "biggest_recent_change": 0.07404094806231498},
{"total_number_of_episodes": 36893, "number_of_timesteps": 8895674, "per_episode_reward": -24.67, "episode_reward_trend_value": 0.004366263691352875, "biggest_recent_change": 0.07404094806231498},
{"total_number_of_episodes": 36903, "number_of_timesteps": 8897685, "per_episode_reward": -24.65, "episode_reward_trend_value": 0.0039485677362733895, "biggest_recent_change": 0.07404094806231498},
{"total_number_of_episodes": 36913, "number_of_timesteps": 8899955, "per_episode_reward": -24.64, "episode_reward_trend_value": 0.00355039243074439, "biggest_recent_change": 0.07404094806231498},
{"total_number_of_episodes": 36923, "number_of_timesteps": 8902336, "per_episode_reward": -24.61, "episode_reward_trend_value": 0.003459571360678461, "biggest_recent_change": 0.07404094806231498},
{"total_number_of_episodes": 36933, "number_of_timesteps": 8904923, "per_episode_reward": -24.53, "episode_reward_trend_value": 0.0034915477848505654, "biggest_recent_change": 0.07691882623780444},
{"total_number_of_episodes": 36943, "number_of_timesteps": 8907153, "per_episode_reward": -24.52, "episode_reward_trend_value": 0.0033100625257855795, "biggest_recent_change": 0.07691882623780444},
{"total_number_of_episodes": 36953, "number_of_timesteps": 8909013, "per_episode_reward": -24.5, "episode_reward_trend_value": 0.0028933131242084185, "biggest_recent_change": 0.07691882623780444},
{"total_number_of_episodes": 36963, "number_of_timesteps": 8911648, "per_episode_reward": -24.48, "episode_reward_trend_value": 0.0024989617866795853, "biggest_recent_change": 0.07691882623780444},
{"total_number_of_episodes": 36973, "number_of_timesteps": 8913427, "per_episode_reward": -24.46, "episode_reward_trend_value": 0.0025627572013455337, "biggest_recent_change": 0.07691882623780444},
{"total_number_of_episodes": 36983, "number_of_timesteps": 8916428, "per_episode_reward": -24.43, "episode_reward_trend_value": 0.0026579243258081043, "biggest_recent_change": 0.07691882623780444},
{"total_number_of_episodes": 36994, "number_of_timesteps": 8918422, "per_episode_reward": -24.35, "episode_reward_trend_value": 0.0033762288825424014, "biggest_recent_change": 0.08086367554523122},
{"total_number_of_episodes": 37004, "number_of_timesteps": 8920485, "per_episode_reward": -24.34, "episode_reward_trend_value": 0.0033525883697280217, "biggest_recent_change": 0.08086367554523122},
{"total_number_of_episodes": 37014, "number_of_timesteps": 8922516, "per_episode_reward": -24.32, "episode_reward_trend_value": 0.0032389840147169246, "biggest_recent_change": 0.08086367554523122},
{"total_number_of_episodes": 37024, "number_of_timesteps": 8924330, "per_episode_reward": -24.29, "episode_reward_trend_value": 0.0027456666157820485, "biggest_recent_change": 0.08086367554523122},
{"total_number_of_episodes": 37036, "number_of_timesteps": 8926651, "per_episode_reward": -24.27, "episode_reward_trend_value": 0.002812551576700173, "biggest_recent_change": 0.08086367554523122},
{"total_number_of_episodes": 37046, "number_of_timesteps": 8928387, "per_episode_reward": -24.23, "episode_reward_trend_value": 0.0029946368736465463, "biggest_recent_change": 0.08086367554523122},
{"total_number_of_episodes": 37056, "number_of_timesteps": 8931218, "per_episode_reward": -24.22, "episode_reward_trend_value": 0.002940955234282683, "biggest_recent_change": 0.08086367554523122},
{"total_number_of_episodes": 37066, "number_of_timesteps": 8934379, "per_episode_reward": -24.21, "episode_reward_trend_value": 0.002729188281238532, "biggest_recent_change": 0.08086367554523122},
{"total_number_of_episodes": 37076, "number_of_timesteps": 8937461, "per_episode_reward": -24.14, "episode_reward_trend_value": 0.003155944425409432, "biggest_recent_change": 0.08086367554523122},
{"total_number_of_episodes": 37086, "number_of_timesteps": 8939025, "per_episode_reward": -24.12, "episode_reward_trend_value": 0.002508258717065775, "biggest_recent_change": 0.06632305450273179},
{"total_number_of_episodes": 37096, "number_of_timesteps": 8941122, "per_episode_reward": -24.11, "episode_reward_trend_value": 0.002540194498154354, "biggest_recent_change": 0.06632305450273179},
{"total_number_of_episodes": 37106, "number_of_timesteps": 8943597, "per_episode_reward": -24.09, "episode_reward_trend_value": 0.0025080697217634827, "biggest_recent_change": 0.06632305450273179},
{"total_number_of_episodes": 37116, "number_of_timesteps": 8945652, "per_episode_reward": -24.07, "episode_reward_trend_value": 0.0023900221889593667, "biggest_recent_change": 0.06632305450273179},
{"total_number_of_episodes": 37126, "number_of_timesteps": 8947859, "per_episode_reward": -24.04, "episode_reward_trend_value": 0.0025240118241738924, "biggest_recent_change": 0.06632305450273179},
{"total_number_of_episodes": 37136, "number_of_timesteps": 8950928, "per_episode_reward": -24.02, "episode_reward_trend_value": 0.0022646509856700603, "biggest_recent_change": 0.06632305450273179},
{"total_number_of_episodes": 37146, "number_of_timesteps": 8953340, "per_episode_reward": -23.99, "episode_reward_trend_value": 0.002567139269178319, "biggest_recent_change": 0.06632305450273179},
{"total_number_of_episodes": 37157, "number_of_timesteps": 8956491, "per_episode_reward": -23.97, "episode_reward_trend_value": 0.0026738878188104485, "biggest_recent_change": 0.06632305450273179},
{"total_number_of_episodes": 37167, "number_of_timesteps": 8958677, "per_episode_reward": -23.95, "episode_reward_trend_value": 0.002194594807530513, "biggest_recent_change": 0.037685234097274645},
{"total_number_of_episodes": 37177, "number_of_timesteps": 8960982, "per_episode_reward": -23.91, "episode_reward_trend_value": 0.0023745231457212414, "biggest_recent_change": 0.038765512231467625},
{"total_number_of_episodes": 37187, "number_of_timesteps": 8962839, "per_episode_reward": -23.84, "episode_reward_trend_value": 0.0029778463031722505, "biggest_recent_change": 0.0689345686735372},
{"total_number_of_episodes": 37197, "number_of_timesteps": 8964866, "per_episode_reward": -23.77, "episode_reward_trend_value": 0.0036474805112858472, "biggest_recent_change": 0.07375301805180712},
{"total_number_of_episodes": 37207, "number_of_timesteps": 8967546, "per_episode_reward": -23.72, "episode_reward_trend_value": 0.0038934237815940126, "biggest_recent_change": 0.07375301805180712},
{"total_number_of_episodes": 37217, "number_of_timesteps": 8970216, "per_episode_reward": -23.69, "episode_reward_trend_value": 0.003970809846108341, "biggest_recent_change": 0.07375301805180712},
{"total_number_of_episodes": 37227, "number_of_timesteps": 8972034, "per_episode_reward": -23.65, "episode_reward_trend_value": 0.004130639502942617, "biggest_recent_change": 0.07375301805180712},
{"total_number_of_episodes": 37237, "number_of_timesteps": 8974109, "per_episode_reward": -23.62, "episode_reward_trend_value": 0.004024152943405449, "biggest_recent_change": 0.07375301805180712},
{"total_number_of_episodes": 37247, "number_of_timesteps": 8976016, "per_episode_reward": -23.6, "episode_reward_trend_value": 0.004066168224772563, "biggest_recent_change": 0.07375301805180712},
{"total_number_of_episodes": 37257, "number_of_timesteps": 8977747, "per_episode_reward": -23.57, "episode_reward_trend_value": 0.004214418548318161, "biggest_recent_change": 0.07375301805180712},
{"total_number_of_episodes": 37267, "number_of_timesteps": 8979656, "per_episode_reward": -23.53, "episode_reward_trend_value": 0.004193629832396676, "biggest_recent_change": 0.07375301805180712},
{"total_number_of_episodes": 37277, "number_of_timesteps": 8981679, "per_episode_reward": -23.48, "episode_reward_trend_value": 0.003966749052871737, "biggest_recent_change": 0.07375301805180712},
{"total_number_of_episodes": 37287, "number_of_timesteps": 8983843, "per_episode_reward": -23.43, "episode_reward_trend_value": 0.0036888316299110518, "biggest_recent_change": 0.048740449985345435},
{"total_number_of_episodes": 37297, "number_of_timesteps": 8985917, "per_episode_reward": -23.41, "episode_reward_trend_value": 0.003455773912590527, "biggest_recent_change": 0.048740449985345435},
{"total_number_of_episodes": 37307, "number_of_timesteps": 8988467, "per_episode_reward": -23.39, "episode_reward_trend_value": 0.003291417851197467, "biggest_recent_change": 0.048740449985345435},
{"total_number_of_episodes": 37317, "number_of_timesteps": 8990799, "per_episode_reward": -23.28, "episode_reward_trend_value": 0.004138156895431185, "biggest_recent_change": 0.11181275473482799},
{"total_number_of_episodes": 37327, "number_of_timesteps": 8994037, "per_episode_reward": -23.26, "episode_reward_trend_value": 0.004088761276480449, "biggest_recent_change": 0.11181275473482799},
{"total_number_of_episodes": 37337, "number_of_timesteps": 8995896, "per_episode_reward": -23.21, "episode_reward_trend_value": 0.004327946448857192, "biggest_recent_change": 0.11181275473482799},
{"total_number_of_episodes": 37347, "number_of_timesteps": 8998124, "per_episode_reward": -23.18, "episode_reward_trend_value": 0.004330876482950864, "biggest_recent_change": 0.11181275473482799},
{"total_number_of_episodes": 37357, "number_of_timesteps": 9001551, "per_episode_reward": -23.14, "episode_reward_trend_value": 0.004316300726272991, "biggest_recent_change": 0.11181275473482799},
{"total_number_of_episodes": 37368, "number_of_timesteps": 9004311, "per_episode_reward": -23.11, "episode_reward_trend_value": 0.004099475200495798, "biggest_recent_change": 0.11181275473482799},
{"total_number_of_episodes": 37378, "number_of_timesteps": 9007139, "per_episode_reward": -23.08, "episode_reward_trend_value": 0.003978723700025218, "biggest_recent_change": 0.11181275473482799},
{"total_number_of_episodes": 37388, "number_of_timesteps": 9010176, "per_episode_reward": -23.03, "episode_reward_trend_value": 0.004271096030707177, "biggest_recent_change": 0.11181275473482799},
{"total_number_of_episodes": 37398, "number_of_timesteps": 9014181, "per_episode_reward": -23.0, "episode_reward_trend_value": 0.004390047927404299, "biggest_recent_change": 0.11181275473482799},
{"total_number_of_episodes": 37408, "number_of_timesteps": 9018367, "per_episode_reward": -22.98, "episode_reward_trend_value": 0.0033691716416021063, "biggest_recent_change": 0.049369191911559085},
{"total_number_of_episodes": 37418, "number_of_timesteps": 9021681, "per_episode_reward": -22.95, "episode_reward_trend_value": 0.0034387072479437585, "biggest_recent_change": 0.049369191911559085},
{"total_number_of_episodes": 37428, "number_of_timesteps": 9026037, "per_episode_reward": -22.93, "episode_reward_trend_value": 0.0031809676298389412, "biggest_recent_change": 0.049369191911559085},
{"total_number_of_episodes": 37438, "number_of_timesteps": 9028460, "per_episode_reward": -22.89, "episode_reward_trend_value": 0.0031678035567840055, "biggest_recent_change": 0.049369191911559085},
{"total_number_of_episodes": 37449, "number_of_timesteps": 9031752, "per_episode_reward": -22.79, "episode_reward_trend_value": 0.003948751630561, "biggest_recent_change": 0.1058680363374549},
{"total_number_of_episodes": 37459, "number_of_timesteps": 9034331, "per_episode_reward": -22.77, "episode_reward_trend_value": 0.003853785266465258, "biggest_recent_change": 0.1058680363374549},
{"total_number_of_episodes": 37469, "number_of_timesteps": 9037719, "per_episode_reward": -22.75, "episode_reward_trend_value": 0.0036264214549168922, "biggest_recent_change": 0.1058680363374549},
{"total_number_of_episodes": 37479, "number_of_timesteps": 9041268, "per_episode_reward": -22.71, "episode_reward_trend_value": 0.003560551411998839, "biggest_recent_change": 0.1058680363374549},
{"total_number_of_episodes": 37489, "number_of_timesteps": 9044377, "per_episode_reward": -22.68, "episode_reward_trend_value": 0.0035135460113109055, "biggest_recent_change": 0.1058680363374549},
{"total_number_of_episodes": 37499, "number_of_timesteps": 9046802, "per_episode_reward": -22.66, "episode_reward_trend_value": 0.0034585141360215254, "biggest_recent_change": 0.1058680363374549},
{"total_number_of_episodes": 37510, "number_of_timesteps": 9050117, "per_episode_reward": -22.64, "episode_reward_trend_value": 0.0034032801798051003, "biggest_recent_change": 0.1058680363374549},
{"total_number_of_episodes": 37520, "number_of_timesteps": 9051984, "per_episode_reward": -22.62, "episode_reward_trend_value": 0.0034604036280183456, "biggest_recent_change": 0.1058680363374549},
{"total_number_of_episodes": 37530, "number_of_timesteps": 9054423, "per_episode_reward": -22.6, "episode_reward_trend_value": 0.0032948869492581737, "biggest_recent_change": 0.1058680363374549},
{"total_number_of_episodes": 37540, "number_of_timesteps": 9056753, "per_episode_reward": -22.58, "episode_reward_trend_value": 0.002352271780364785, "biggest_recent_change": 0.04344088804893431},
{"total_number_of_episodes": 37550, "number_of_timesteps": 9059638, "per_episode_reward": -22.53, "episode_reward_trend_value": 0.002646738615639737, "biggest_recent_change": 0.046956043602474296},
{"total_number_of_episodes": 37560, "number_of_timesteps": 9061945, "per_episode_reward": -22.51, "episode_reward_trend_value": 0.002639968929421875, "biggest_recent_change": 0.046956043602474296},
{"total_number_of_episodes": 37570, "number_of_timesteps": 9064452, "per_episode_reward": -22.47, "episode_reward_trend_value": 0.0025951572240584158, "biggest_recent_change": 0.046956043602474296},
{"total_number_of_episodes": 37580, "number_of_timesteps": 9066596, "per_episode_reward": -22.41, "episode_reward_trend_value": 0.00297851490333881, "biggest_recent_change": 0.060760200994756985},
{"total_number_of_episodes": 37590, "number_of_timesteps": 9069552, "per_episode_reward": -22.38, "episode_reward_trend_value": 0.0031386679520669326, "biggest_recent_change": 0.060760200994756985},
{"total_number_of_episodes": 37600, "number_of_timesteps": 9072746, "per_episode_reward": -22.34, "episode_reward_trend_value": 0.003316709047824576, "biggest_recent_change": 0.060760200994756985},
{"total_number_of_episodes": 37610, "number_of_timesteps": 9076367, "per_episode_reward": -22.33, "episode_reward_trend_value": 0.0031437389849090476, "biggest_recent_change": 0.060760200994756985},
{"total_number_of_episodes": 37620, "number_of_timesteps": 9079499, "per_episode_reward": -22.31, "episode_reward_trend_value": 0.003227280020278537, "biggest_recent_change": 0.060760200994756985},

{"total_number_of_episodes": 37630, "number_of_timesteps": 9082129, "per_episode_reward": -22.27, "episode_reward_trend_value": 0.003345465921307936, "biggest_recent_change": 0.060760200994756985},
{"total_number_of_episodes": 37640, "number_of_timesteps": 9085858, "per_episode_reward": -22.25, "episode_reward_trend_value": 0.0031118449693396696, "biggest_recent_change": 0.060760200994756985},
{"total_number_of_episodes": 37650, "number_of_timesteps": 9089062, "per_episode_reward": -22.19, "episode_reward_trend_value": 0.0035879577561777317, "biggest_recent_change": 0.060760200994756985},
{"total_number_of_episodes": 37660, "number_of_timesteps": 9091483, "per_episode_reward": -22.18, "episode_reward_trend_value": 0.0032926815562819437, "biggest_recent_change": 0.060760200994756985},
{"total_number_of_episodes": 37670, "number_of_timesteps": 9094350, "per_episode_reward": -22.14, "episode_reward_trend_value": 0.0030541979390490957, "biggest_recent_change": 0.05965095095945827},
{"total_number_of_episodes": 37680, "number_of_timesteps": 9096791, "per_episode_reward": -22.12, "episode_reward_trend_value": 0.0029229835677200182, "biggest_recent_change": 0.05965095095945827},
{"total_number_of_episodes": 37690, "number_of_timesteps": 9099893, "per_episode_reward": -22.1, "episode_reward_trend_value": 0.0026983856805528382, "biggest_recent_change": 0.05965095095945827},
{"total_number_of_episodes": 37701, "number_of_timesteps": 9103442, "per_episode_reward": -22.07, "episode_reward_trend_value": 0.002934498612735463, "biggest_recent_change": 0.05965095095945827},
{"total_number_of_episodes": 37711, "number_of_timesteps": 9107483, "per_episode_reward": -21.99, "episode_reward_trend_value": 0.003532157139138824, "biggest_recent_change": 0.08201960857126878},
{"total_number_of_episodes": 37721, "number_of_timesteps": 9111367, "per_episode_reward": -21.92, "episode_reward_trend_value": 0.003901953971403868, "biggest_recent_change": 0.08201960857126878},
{"total_number_of_episodes": 37731, "number_of_timesteps": 9113509, "per_episode_reward": -21.87, "episode_reward_trend_value": 0.004167888509654737, "biggest_recent_change": 0.08201960857126878},
{"total_number_of_episodes": 37741, "number_of_timesteps": 9115935, "per_episode_reward": -21.86, "episode_reward_trend_value": 0.003666782362664023, "biggest_recent_change": 0.08201960857126878},
{"total_number_of_episodes": 37751, "number_of_timesteps": 9119045, "per_episode_reward": -21.82, "episode_reward_trend_value": 0.003945554060856043, "biggest_recent_change": 0.08201960857126878},
{"total_number_of_episodes": 37761, "number_of_timesteps": 9121021, "per_episode_reward": -21.79, "episode_reward_trend_value": 0.003901080923397081, "biggest_recent_change": 0.08201960857126878},
{"total_number_of_episodes": 37771, "number_of_timesteps": 9123300, "per_episode_reward": -21.75, "episode_reward_trend_value": 0.004098796042686341, "biggest_recent_change": 0.08201960857126878},
{"total_number_of_episodes": 37782, "number_of_timesteps": 9126106, "per_episode_reward": -21.73, "episode_reward_trend_value": 0.004083811062331301, "biggest_recent_change": 0.08201960857126878},
{"total_number_of_episodes": 37792, "number_of_timesteps": 9128481, "per_episode_reward": -21.71, "episode_reward_trend_value": 0.003997303813067335, "biggest_recent_change": 0.08201960857126878},
{"total_number_of_episodes": 37803, "number_of_timesteps": 9130774, "per_episode_reward": -21.68, "episode_reward_trend_value": 0.003373537575185518, "biggest_recent_change": 0.06495111713354973},
{"total_number_of_episodes": 37813, "number_of_timesteps": 9133600, "per_episode_reward": -21.67, "episode_reward_trend_value": 0.00280243619649604, "biggest_recent_change": 0.04986426636790853},
{"total_number_of_episodes": 37823, "number_of_timesteps": 9135966, "per_episode_reward": -21.66, "episode_reward_trend_value": 0.0024249354335287325, "biggest_recent_change": 0.03792242941288393},
{"total_number_of_episodes": 37833, "number_of_timesteps": 9138341, "per_episode_reward": -21.61, "episode_reward_trend_value": 0.0027571345056303345, "biggest_recent_change": 0.04444931421943821},
{"total_number_of_episodes": 37843, "number_of_timesteps": 9140593, "per_episode_reward": -21.52, "episode_reward_trend_value": 0.0033389244488054555, "biggest_recent_change": 0.09028352429864483},
{"total_number_of_episodes": 37853, "number_of_timesteps": 9143125, "per_episode_reward": -21.47, "episode_reward_trend_value": 0.003517960564526964, "biggest_recent_change": 0.09028352429864483},
{"total_number_of_episodes": 37863, "number_of_timesteps": 9146139, "per_episode_reward": -21.42, "episode_reward_trend_value": 0.0036357923273182594, "biggest_recent_change": 0.09028352429864483},
{"total_number_of_episodes": 37873, "number_of_timesteps": 9148319, "per_episode_reward": -21.38, "episode_reward_trend_value": 0.003920259548508772, "biggest_recent_change": 0.09028352429864483},
{"total_number_of_episodes": 37883, "number_of_timesteps": 9150469, "per_episode_reward": -21.35, "episode_reward_trend_value": 0.004009945909706758, "biggest_recent_change": 0.09028352429864483},
{"total_number_of_episodes": 37893, "number_of_timesteps": 9153487, "per_episode_reward": -21.34, "episode_reward_trend_value": 0.00383156091399732, "biggest_recent_change": 0.09028352429864483},
{"total_number_of_episodes": 37904, "number_of_timesteps": 9155914, "per_episode_reward": -21.32, "episode_reward_trend_value": 0.003845470614014306, "biggest_recent_change": 0.09028352429864483},
{"total_number_of_episodes": 37914, "number_of_timesteps": 9159524, "per_episode_reward": -21.31, "episode_reward_trend_value": 0.0038511172531096117, "biggest_recent_change": 0.09028352429864483},
{"total_number_of_episodes": 37924, "number_of_timesteps": 9161924, "per_episode_reward": -21.28, "episode_reward_trend_value": 0.0036413132053144497, "biggest_recent_change": 0.09028352429864483},
{"total_number_of_episodes": 37934, "number_of_timesteps": 9164885, "per_episode_reward": -21.22, "episode_reward_trend_value": 0.003336936175043527, "biggest_recent_change": 0.06288959157426177},
{"total_number_of_episodes": 37944, "number_of_timesteps": 9167053, "per_episode_reward": -21.2, "episode_reward_trend_value": 0.002956426801133145, "biggest_recent_change": 0.06288959157426177},
{"total_number_of_episodes": 37954, "number_of_timesteps": 9168845, "per_episode_reward": -21.18, "episode_reward_trend_value": 0.0027313555387337768, "biggest_recent_change": 0.06288959157426177},
{"total_number_of_episodes": 37964, "number_of_timesteps": 9170973, "per_episode_reward": -21.07, "episode_reward_trend_value": 0.0034668207586319804, "biggest_recent_change": 0.11119814678380635},
{"total_number_of_episodes": 37974, "number_of_timesteps": 9173744, "per_episode_reward": -21.05, "episode_reward_trend_value": 0.0033185933465098177, "biggest_recent_change": 0.11119814678380635},
{"total_number_of_episodes": 37984, "number_of_timesteps": 9176041, "per_episode_reward": -21.03, "episode_reward_trend_value": 0.003396399642361243, "biggest_recent_change": 0.11119814678380635},
{"total_number_of_episodes": 37994, "number_of_timesteps": 9178966, "per_episode_reward": -20.99, "episode_reward_trend_value": 0.003735757518620591, "biggest_recent_change": 0.11119814678380635},
{"total_number_of_episodes": 38004, "number_of_timesteps": 9180974, "per_episode_reward": -20.97, "episode_reward_trend_value": 0.003782896196015173, "biggest_recent_change": 0.11119814678380635},
{"total_number_of_episodes": 38014, "number_of_timesteps": 9183665, "per_episode_reward": -20.96, "episode_reward_trend_value": 0.003613608531236581, "biggest_recent_change": 0.11119814678380635},
{"total_number_of_episodes": 38024, "number_of_timesteps": 9186091, "per_episode_reward": -20.95, "episode_reward_trend_value": 0.0030150776425822002, "biggest_recent_change": 0.11119814678380635},
{"total_number_of_episodes": 38034, "number_of_timesteps": 9188182, "per_episode_reward": -20.92, "episode_reward_trend_value": 0.0030910786413873522, "biggest_recent_change": 0.11119814678380635},
{"total_number_of_episodes": 38044, "number_of_timesteps": 9190374, "per_episode_reward": -20.9, "episode_reward_trend_value": 0.003027432605397746, "biggest_recent_change": 0.11119814678380635},
{"total_number_of_episodes": 38054, "number_of_timesteps": 9192341, "per_episode_reward": -20.88, "episode_reward_trend_value": 0.0021118136900151385, "biggest_recent_change": 0.045346074916366774},
{"total_number_of_episodes": 38064, "number_of_timesteps": 9195128, "per_episode_reward": -20.85, "episode_reward_trend_value": 0.0022608510089401, "biggest_recent_change": 0.045346074916366774},
{"total_number_of_episodes": 38074, "number_of_timesteps": 9198387, "per_episode_reward": -20.8, "episode_reward_trend_value": 0.0026141555959728496, "biggest_recent_change": 0.048625977007631604},
{"total_number_of_episodes": 38084, "number_of_timesteps": 9202082, "per_episode_reward": -20.78, "episode_reward_trend_value": 0.002368991142755898, "biggest_recent_change": 0.048625977007631604},
{"total_number_of_episodes": 38094, "number_of_timesteps": 9205840, "per_episode_reward": -20.68, "episode_reward_trend_value": 0.003235620143846655, "biggest_recent_change": 0.09863648628310884},
{"total_number_of_episodes": 38104, "number_of_timesteps": 9208924, "per_episode_reward": -20.54, "episode_reward_trend_value": 0.004634677171037972, "biggest_recent_change": 0.1362461925350189},
{"total_number_of_episodes": 38114, "number_of_timesteps": 9211241, "per_episode_reward": -20.52, "episode_reward_trend_value": 0.0047619125097406985, "biggest_recent_change": 0.1362461925350189},
{"total_number_of_episodes": 38124, "number_of_timesteps": 9213699, "per_episode_reward": -20.49, "episode_reward_trend_value": 0.004862800374945112, "biggest_recent_change": 0.1362461925350189},
{"total_number_of_episodes": 38134, "number_of_timesteps": 9215813, "per_episode_reward": -20.48, "episode_reward_trend_value": 0.004773161861353773, "biggest_recent_change": 0.1362461925350189},
{"total_number_of_episodes": 38144, "number_of_timesteps": 9220218, "per_episode_reward": -20.46, "episode_reward_trend_value": 0.004600006255549734, "biggest_recent_change": 0.1362461925350189},
{"total_number_of_episodes": 38154, "number_of_timesteps": 9222764, "per_episode_reward": -20.44, "episode_reward_trend_value": 0.004521337139686369, "biggest_recent_change": 0.1362461925350189},
{"total_number_of_episodes": 38164, "number_of_timesteps": 9225770, "per_episode_reward": -20.42, "episode_reward_trend_value": 0.004172997117668113, "biggest_recent_change": 0.1362461925350189},
{"total_number_of_episodes": 38174, "number_of_timesteps": 9228837, "per_episode_reward": -20.41, "episode_reward_trend_value": 0.004092622755233125, "biggest_recent_change": 0.1362461925350189},
{"total_number_of_episodes": 38184, "number_of_timesteps": 9231492, "per_episode_reward": -20.39, "episode_reward_trend_value": 0.0031975287547765336, "biggest_recent_change": 0.1362461925350189},
{"total_number_of_episodes": 38194, "number_of_timesteps": 9234371, "per_episode_reward": -20.38, "episode_reward_trend_value": 0.0018181031086088398, "biggest_recent_change": 0.03308149759635626},
{"total_number_of_episodes": 38204, "number_of_timesteps": 9236678, "per_episode_reward": -20.35, "episode_reward_trend_value": 0.0018851270491863502, "biggest_recent_change": 0.03308149759635626},
{"total_number_of_episodes": 38214, "number_of_timesteps": 9238752, "per_episode_reward": -20.33, "episode_reward_trend_value": 0.0017235924151817825, "biggest_recent_change": 0.02650514673058879},
{"total_number_of_episodes": 38225, "number_of_timesteps": 9240570, "per_episode_reward": -20.31, "episode_reward_trend_value": 0.0018577713153928323, "biggest_recent_change": 0.02650514673058879},
{"total_number_of_episodes": 38235, "number_of_timesteps": 9243531, "per_episode_reward": -20.25, "episode_reward_trend_value": 0.002365060031329828, "biggest_recent_change": 0.05886442431133787},
{"total_number_of_episodes": 38245, "number_of_timesteps": 9245430, "per_episode_reward": -20.21, "episode_reward_trend_value": 0.0026023644942098105, "biggest_recent_change": 0.05886442431133787},
{"total_number_of_episodes": 38255, "number_of_timesteps": 9247021, "per_episode_reward": -20.19, "episode_reward_trend_value": 0.0026327453151950746, "biggest_recent_change": 0.05886442431133787},
{"total_number_of_episodes": 38266, "number_of_timesteps": 9249418, "per_episode_reward": -20.17, "episode_reward_trend_value": 0.0026249524005947144, "biggest_recent_change": 0.05886442431133787},
{"total_number_of_episodes": 38276, "number_of_timesteps": 9251206, "per_episode_reward": -20.16, "episode_reward_trend_value": 0.0025778254131171565, "biggest_recent_change": 0.05886442431133787},
{"total_number_of_episodes": 38286, "number_of_timesteps": 9253590, "per_episode_reward": -20.13, "episode_reward_trend_value": 0.0027071774471870134, "biggest_recent_change": 0.05886442431133787},
{"total_number_of_episodes": 38296, "number_of_timesteps": 9255503, "per_episode_reward": -20.12, "episode_reward_trend_value": 0.002604242489976332, "biggest_recent_change": 0.05886442431133787},
{"total_number_of_episodes": 38306, "number_of_timesteps": 9257761, "per_episode_reward": -20.08, "episode_reward_trend_value": 0.0027921190027352257, "biggest_recent_change": 0.05886442431133787},
{"total_number_of_episodes": 38317, "number_of_timesteps": 9262433, "per_episode_reward": -20.02, "episode_reward_trend_value": 0.003147005713953198, "biggest_recent_change": 0.05886442431133787},
{"total_number_of_episodes": 38327, "number_of_timesteps": 9265083, "per_episode_reward": -19.98, "episode_reward_trend_value": 0.002963764764572474, "biggest_recent_change": 0.05594860254013412},
{"total_number_of_episodes": 38337, "number_of_timesteps": 9267654, "per_episode_reward": -19.94, "episode_reward_trend_value": 0.002917865700599028, "biggest_recent_change": 0.05594860254013412},
{"total_number_of_episodes": 38347, "number_of_timesteps": 9271460, "per_episode_reward": -19.85, "episode_reward_trend_value": 0.0037221305591447476, "biggest_recent_change": 0.09239348618377718},
{"total_number_of_episodes": 38358, "number_of_timesteps": 9274701, "per_episode_reward": -19.84, "episode_reward_trend_value": 0.003676862903269809, "biggest_recent_change": 0.09239348618377718},
{"total_number_of_episodes": 38368, "number_of_timesteps": 9277299, "per_episode_reward": -19.77, "episode_reward_trend_value": 0.004265788598145706, "biggest_recent_change": 0.09239348618377718},
{"total_number_of_episodes": 38378, "number_of_timesteps": 9280155, "per_episode_reward": -19.75, "episode_reward_trend_value": 0.004290812415432299, "biggest_recent_change": 0.09239348618377718},
{"total_number_of_episodes": 38388, "number_of_timesteps": 9282902, "per_episode_reward": -19.71, "episode_reward_trend_value": 0.004499857205831503, "biggest_recent_change": 0.09239348618377718},
{"total_number_of_episodes": 38398, "number_of_timesteps": 9285619, "per_episode_reward": -19.69, "episode_reward_trend_value": 0.004349214861322616, "biggest_recent_change": 0.09239348618377718},
{"total_number_of_episodes": 38408, "number_of_timesteps": 9289095, "per_episode_reward": -19.67, "episode_reward_trend_value": 0.003925386022531738, "biggest_recent_change": 0.09239348618377718},
{"total_number_of_episodes": 38418, "number_of_timesteps": 9291948, "per_episode_reward": -19.65, "episode_reward_trend_value": 0.0036795414606956454, "biggest_recent_change": 0.09239348618377718},
{"total_number_of_episodes": 38428, "number_of_timesteps": 9294341, "per_episode_reward": -19.63, "episode_reward_trend_value": 0.0035301332613356983, "biggest_recent_change": 0.09239348618377718},
{"total_number_of_episodes": 38438, "number_of_timesteps": 9296599, "per_episode_reward": -19.59, "episode_reward_trend_value": 0.0029155424297746335, "biggest_recent_change": 0.06683990990786626},
{"total_number_of_episodes": 38448, "number_of_timesteps": 9298907, "per_episode_reward": -19.53, "episode_reward_trend_value": 0.003472337441612991, "biggest_recent_change": 0.06683990990786626},
{"total_number_of_episodes": 38458, "number_of_timesteps": 9301249, "per_episode_reward": -19.48, "episode_reward_trend_value": 0.00330605651255406, "biggest_recent_change": 0.061383681230367415},
{"total_number_of_episodes": 38468, "number_of_timesteps": 9303438, "per_episode_reward": -19.46, "episode_reward_trend_value": 0.003195737939358878, "biggest_recent_change": 0.061383681230367415},
{"total_number_of_episodes": 38478, "number_of_timesteps": 9306559, "per_episode_reward": -19.42, "episode_reward_trend_value": 0.0032156798029726965, "biggest_recent_change": 0.061383681230367415},
{"total_number_of_episodes": 38488, "number_of_timesteps": 9308799, "per_episode_reward": -19.32, "episode_reward_trend_value": 0.0041053534990070206, "biggest_recent_change": 0.10196508832153484},
{"total_number_of_episodes": 38498, "number_of_timesteps": 9311484, "per_episode_reward": -19.25, "episode_reward_trend_value": 0.004636296519758156, "biggest_recent_change": 0.10196508832153484},
{"total_number_of_episodes": 38508, "number_of_timesteps": 9314130, "per_episode_reward": -19.23, "episode_reward_trend_value": 0.004662736303846613, "biggest_recent_change": 0.10196508832153484},
{"total_number_of_episodes": 38518, "number_of_timesteps": 9317831, "per_episode_reward": -19.21, "episode_reward_trend_value": 0.004626990487031869, "biggest_recent_change": 0.10196508832153484},

{"total_number_of_episodes": 38528, "number_of_timesteps": 9320928, "per_episode_reward": -19.18, "episode_reward_trend_value": 0.0045353016984821274, "biggest_recent_change": 0.10196508832153484},
{"total_number_of_episodes": 38539, "number_of_timesteps": 9324398, "per_episode_reward": -19.15, "episode_reward_trend_value": 0.004195449623591566, "biggest_recent_change": 0.10196508832153484},
{"total_number_of_episodes": 38550, "number_of_timesteps": 9327108, "per_episode_reward": -19.13, "episode_reward_trend_value": 0.003812995332961025, "biggest_recent_change": 0.10196508832153484},
{"total_number_of_episodes": 38560, "number_of_timesteps": 9329256, "per_episode_reward": -19.1, "episode_reward_trend_value": 0.003987059107041367, "biggest_recent_change": 0.10196508832153484},
{"total_number_of_episodes": 38571, "number_of_timesteps": 9331634, "per_episode_reward": -19.07, "episode_reward_trend_value": 0.003889474373643035, "biggest_recent_change": 0.10196508832153484},
{"total_number_of_episodes": 38581, "number_of_timesteps": 9333430, "per_episode_reward": -19.05, "episode_reward_trend_value": 0.0030491882552507914, "biggest_recent_change": 0.06558887891655729},
{"total_number_of_episodes": 38591, "number_of_timesteps": 9335726, "per_episode_reward": -19.02, "episode_reward_trend_value": 0.002602320351870486, "biggest_recent_change": 0.03172877908167138},
{"total_number_of_episodes": 38601, "number_of_timesteps": 9338272, "per_episode_reward": -18.97, "episode_reward_trend_value": 0.002937024400908446, "biggest_recent_change": 0.052749673283202014},
{"total_number_of_episodes": 38611, "number_of_timesteps": 9341935, "per_episode_reward": -18.93, "episode_reward_trend_value": 0.0031141865592539926, "biggest_recent_change": 0.052749673283202014},
{"total_number_of_episodes": 38621, "number_of_timesteps": 9344447, "per_episode_reward": -18.88, "episode_reward_trend_value": 0.0032988680276282087, "biggest_recent_change": 0.052749673283202014},
{"total_number_of_episodes": 38631, "number_of_timesteps": 9346796, "per_episode_reward": -18.86, "episode_reward_trend_value": 0.0032177174223395216, "biggest_recent_change": 0.052749673283202014},
{"total_number_of_episodes": 38641, "number_of_timesteps": 9348731, "per_episode_reward": -18.83, "episode_reward_trend_value": 0.0033527794952725684, "biggest_recent_change": 0.052749673283202014},
{"total_number_of_episodes": 38651, "number_of_timesteps": 9350710, "per_episode_reward": -18.81, "episode_reward_trend_value": 0.003213595560844911, "biggest_recent_change": 0.052749673283202014},
{"total_number_of_episodes": 38661, "number_of_timesteps": 9352888, "per_episode_reward": -18.8, "episode_reward_trend_value": 0.0030398314315037726, "biggest_recent_change": 0.052749673283202014},
{"total_number_of_episodes": 38671, "number_of_timesteps": 9355721, "per_episode_reward": -18.77, "episode_reward_trend_value": 0.0030538969461426447, "biggest_recent_change": 0.052749673283202014},
{"total_number_of_episodes": 38682, "number_of_timesteps": 9361084, "per_episode_reward": -18.71, "episode_reward_trend_value": 0.003403857634001876, "biggest_recent_change": 0.05686722951966061},
{"total_number_of_episodes": 38692, "number_of_timesteps": 9363161, "per_episode_reward": -18.69, "episode_reward_trend_value": 0.0030330404103791706, "biggest_recent_change": 0.05686722951966061},
{"total_number_of_episodes": 38702, "number_of_timesteps": 9366012, "per_episode_reward": -18.68, "episode_reward_trend_value": 0.0028160238122223705, "biggest_recent_change": 0.05686722951966061},
{"total_number_of_episodes": 38712, "number_of_timesteps": 9369136, "per_episode_reward": -18.63, "episode_reward_trend_value": 0.002793960965098484, "biggest_recent_change": 0.05686722951966061},
{"total_number_of_episodes": 38722, "number_of_timesteps": 9371954, "per_episode_reward": -18.6, "episode_reward_trend_value": 0.0029175071904007097, "biggest_recent_change": 0.05686722951966061},
{"total_number_of_episodes": 38732, "number_of_timesteps": 9374502, "per_episode_reward": -18.56, "episode_reward_trend_value": 0.0029824854939328642, "biggest_recent_change": 0.05686722951966061},
{"total_number_of_episodes": 38742, "number_of_timesteps": 9377651, "per_episode_reward": -18.55, "episode_reward_trend_value": 0.0029416302509563904, "biggest_recent_change": 0.05686722951966061},
{"total_number_of_episodes": 38752, "number_of_timesteps": 9380101, "per_episode_reward": -18.52, "episode_reward_trend_value": 0.003052450524686871, "biggest_recent_change": 0.05686722951966061},
{"total_number_of_episodes": 38762, "number_of_timesteps": 9384798, "per_episode_reward": -18.48, "episode_reward_trend_value": 0.0032345311754981136, "biggest_recent_change": 0.05686722951966061},
{"total_number_of_episodes": 38772, "number_of_timesteps": 9388012, "per_episode_reward": -18.47, "episode_reward_trend_value": 0.002688537155412105, "biggest_recent_change": 0.0439924925567432},
{"total_number_of_episodes": 38782, "number_of_timesteps": 9392412, "per_episode_reward": -18.43, "episode_reward_trend_value": 0.0029548947592949225, "biggest_recent_change": 0.0439924925567432},
{"total_number_of_episodes": 38792, "number_of_timesteps": 9394532, "per_episode_reward": -18.4, "episode_reward_trend_value": 0.0030149491204388727, "biggest_recent_change": 0.0439924925567432},
{"total_number_of_episodes": 38803, "number_of_timesteps": 9399263, "per_episode_reward": -18.38, "episode_reward_trend_value": 0.00285657924007165, "biggest_recent_change": 0.0439924925567432},
{"total_number_of_episodes": 38813, "number_of_timesteps": 9402587, "per_episode_reward": -18.36, "episode_reward_trend_value": 0.0026899172273143535, "biggest_recent_change": 0.0439924925567432},
{"total_number_of_episodes": 38823, "number_of_timesteps": 9405481, "per_episode_reward": -18.32, "episode_reward_trend_value": 0.0026498000649977783, "biggest_recent_change": 0.0439924925567432},
{"total_number_of_episodes": 38833, "number_of_timesteps": 9409215, "per_episode_reward": -18.3, "episode_reward_trend_value": 0.00279142085866104, "biggest_recent_change": 0.0439924925567432},
{"total_number_of_episodes": 38843, "number_of_timesteps": 9412054, "per_episode_reward": -18.28, "episode_reward_trend_value": 0.002703008016574494, "biggest_recent_change": 0.0439924925567432},
{"total_number_of_episodes": 38853, "number_of_timesteps": 9414899, "per_episode_reward": -18.27, "episode_reward_trend_value": 0.002359530075297103, "biggest_recent_change": 0.043348307506612116},
{"total_number_of_episodes": 38863, "number_of_timesteps": 9417755, "per_episode_reward": -18.24, "episode_reward_trend_value": 0.0025409973423496665, "biggest_recent_change": 0.043348307506612116},
{"total_number_of_episodes": 38873, "number_of_timesteps": 9420017, "per_episode_reward": -18.19, "episode_reward_trend_value": 0.002653781135478618, "biggest_recent_change": 0.053498848888217765},
{"total_number_of_episodes": 38883, "number_of_timesteps": 9423081, "per_episode_reward": -18.14, "episode_reward_trend_value": 0.0029233169935460285, "biggest_recent_change": 0.053498848888217765},
{"total_number_of_episodes": 38893, "number_of_timesteps": 9425431, "per_episode_reward": -18.1, "episode_reward_trend_value": 0.0030236644983441846, "biggest_recent_change": 0.053498848888217765},
{"total_number_of_episodes": 38903, "number_of_timesteps": 9429415, "per_episode_reward": -18.06, "episode_reward_trend_value": 0.003253037619756406, "biggest_recent_change": 0.053498848888217765},
{"total_number_of_episodes": 38913, "number_of_timesteps": 9432339, "per_episode_reward": -17.98, "episode_reward_trend_value": 0.0037778390358434973, "biggest_recent_change": 0.07907895685702826},
{"total_number_of_episodes": 38923, "number_of_timesteps": 9434746, "per_episode_reward": -17.91, "episode_reward_trend_value": 0.004278250114561841, "biggest_recent_change": 0.07907895685702826},
{"total_number_of_episodes": 38933, "number_of_timesteps": 9436498, "per_episode_reward": -17.89, "episode_reward_trend_value": 0.0043472667078481835, "biggest_recent_change": 0.07907895685702826},
{"total_number_of_episodes": 38943, "number_of_timesteps": 9438435, "per_episode_reward": -17.85, "episode_reward_trend_value": 0.004588681661163423, "biggest_recent_change": 0.07907895685702826},
{"total_number_of_episodes": 38953, "number_of_timesteps": 9440096, "per_episode_reward": -17.81, "episode_reward_trend_value": 0.004755264494466971, "biggest_recent_change": 0.07907895685702826},
{"total_number_of_episodes": 38963, "number_of_timesteps": 9442723, "per_episode_reward": -17.77, "episode_reward_trend_value": 0.004669104551095534, "biggest_recent_change": 0.07907895685702826},
{"total_number_of_episodes": 38973, "number_of_timesteps": 9444161, "per_episode_reward": -17.73, "episode_reward_trend_value": 0.0046107658311910485, "biggest_recent_change": 0.07907895685702826},
{"total_number_of_episodes": 38983, "number_of_timesteps": 9446578, "per_episode_reward": -17.71, "episode_reward_trend_value": 0.004398141162966201, "biggest_recent_change": 0.07907895685702826},
{"total_number_of_episodes": 38993, "number_of_timesteps": 9449047, "per_episode_reward": -17.68, "episode_reward_trend_value": 0.004260861518021544, "biggest_recent_change": 0.07907895685702826},
{"total_number_of_episodes": 39004, "number_of_timesteps": 9451385, "per_episode_reward": -17.64, "episode_reward_trend_value": 0.003874272704167265, "biggest_recent_change": 0.07330812162964406},
{"total_number_of_episodes": 39014, "number_of_timesteps": 9453338, "per_episode_reward": -17.48, "episode_reward_trend_value": 0.004772364813179743, "biggest_recent_change": 0.15413641144076706},
{"total_number_of_episodes": 39024, "number_of_timesteps": 9455765, "per_episode_reward": -17.42, "episode_reward_trend_value": 0.00518164810660531, "biggest_recent_change": 0.15413641144076706},
{"total_number_of_episodes": 39034, "number_of_timesteps": 9459299, "per_episode_reward": -17.41, "episode_reward_trend_value": 0.004975663119703652, "biggest_recent_change": 0.15413641144076706},
{"total_number_of_episodes": 39044, "number_of_timesteps": 9461674, "per_episode_reward": -17.31, "episode_reward_trend_value": 0.005591263876344854, "biggest_recent_change": 0.15413641144076706},
{"total_number_of_episodes": 39054, "number_of_timesteps": 9464349, "per_episode_reward": -17.3, "episode_reward_trend_value": 0.005221374815279253, "biggest_recent_change": 0.15413641144076706},
{"total_number_of_episodes": 39065, "number_of_timesteps": 9466891, "per_episode_reward": -17.29, "episode_reward_trend_value": 0.004870276766322985, "biggest_recent_change": 0.15413641144076706},
{"total_number_of_episodes": 39075, "number_of_timesteps": 9469102, "per_episode_reward": -17.26, "episode_reward_trend_value": 0.004928623683197328, "biggest_recent_change": 0.15413641144076706},
{"total_number_of_episodes": 39085, "number_of_timesteps": 9471224, "per_episode_reward": -17.23, "episode_reward_trend_value": 0.0050087057760786514, "biggest_recent_change": 0.15413641144076706},
{"total_number_of_episodes": 39095, "number_of_timesteps": 9473188, "per_episode_reward": -17.2, "episode_reward_trend_value": 0.004803186461659534, "biggest_recent_change": 0.15413641144076706},
{"total_number_of_episodes": 39105, "number_of_timesteps": 9476959, "per_episode_reward": -17.19, "episode_reward_trend_value": 0.0032598049758545663, "biggest_recent_change": 0.09445634484167797},
{"total_number_of_episodes": 39115, "number_of_timesteps": 9480451, "per_episode_reward": -17.17, "episode_reward_trend_value": 0.002772122212334654, "biggest_recent_change": 0.09445634484167797},
{"total_number_of_episodes": 39125, "number_of_timesteps": 9482054, "per_episode_reward": -17.17, "episode_reward_trend_value": 0.002637657293134647, "biggest_recent_change": 0.09445634484167797},
{"total_number_of_episodes": 39135, "number_of_timesteps": 9484744, "per_episode_reward": -17.09, "episode_reward_trend_value": 0.0024445215944459402, "biggest_recent_change": 0.07707413195969437},
{"total_number_of_episodes": 39145, "number_of_timesteps": 9486689, "per_episode_reward": -17.06, "episode_reward_trend_value": 0.002702740579033068, "biggest_recent_change": 0.07707413195969437},
{"total_number_of_episodes": 39155, "number_of_timesteps": 9488509, "per_episode_reward": -17.03, "episode_reward_trend_value": 0.002820277063264282, "biggest_recent_change": 0.07707413195969437},
{"total_number_of_episodes": 39165, "number_of_timesteps": 9490526, "per_episode_reward": -16.96, "episode_reward_trend_value": 0.003411233822979298, "biggest_recent_change": 0.07754309323792441},
{"total_number_of_episodes": 39175, "number_of_timesteps": 9492760, "per_episode_reward": -16.94, "episode_reward_trend_value": 0.0031853388094884535, "biggest_recent_change": 0.07754309323792441},
{"total_number_of_episodes": 39185, "number_of_timesteps": 9494549, "per_episode_reward": -16.91, "episode_reward_trend_value": 0.0032119307508501607, "biggest_recent_change": 0.07754309323792441},
{"total_number_of_episodes": 39195, "number_of_timesteps": 9496367, "per_episode_reward": -16.89, "episode_reward_trend_value": 0.0033570324219908006, "biggest_recent_change": 0.07754309323792441},
{"total_number_of_episodes": 39205, "number_of_timesteps": 9498069, "per_episode_reward": -16.87, "episode_reward_trend_value": 0.003416936420105306, "biggest_recent_change": 0.07754309323792441},
{"total_number_of_episodes": 39215, "number_of_timesteps": 9500261, "per_episode_reward": -16.84, "episode_reward_trend_value": 0.0036955579065087187, "biggest_recent_change": 0.07754309323792441},
{"total_number_of_episodes": 39225, "number_of_timesteps": 9503159, "per_episode_reward": -16.81, "episode_reward_trend_value": 0.0031713288738550774, "biggest_recent_change": 0.07754309323792441},
{"total_number_of_episodes": 39235, "number_of_timesteps": 9506259, "per_episode_reward": -16.76, "episode_reward_trend_value": 0.003258994185775342, "biggest_recent_change": 0.07754309323792441},
{"total_number_of_episodes": 39245, "number_of_timesteps": 9509504, "per_episode_reward": -16.74, "episode_reward_trend_value": 0.003308095937167326, "biggest_recent_change": 0.07754309323792441},
{"total_number_of_episodes": 39255, "number_of_timesteps": 9511461, "per_episode_reward": -16.7, "episode_reward_trend_value": 0.0028374111703108836, "biggest_recent_change": 0.04358402517454962},
{"total_number_of_episodes": 39265, "number_of_timesteps": 9514141, "per_episode_reward": -16.66, "episode_reward_trend_value": 0.0031482048134122524, "biggest_recent_change": 0.04358402517454962},
{"total_number_of_episodes": 39275, "number_of_timesteps": 9516434, "per_episode_reward": -16.54, "episode_reward_trend_value": 0.004101703853430215, "biggest_recent_change": 0.11399741363659288},
{"total_number_of_episodes": 39285, "number_of_timesteps": 9518462, "per_episode_reward": -16.53, "episode_reward_trend_value": 0.003916362333993106, "biggest_recent_change": 0.11399741363659288},
{"total_number_of_episodes": 39295, "number_of_timesteps": 9521157, "per_episode_reward": -16.5, "episode_reward_trend_value": 0.0041119191510101336, "biggest_recent_change": 0.11399741363659288},
{"total_number_of_episodes": 39305, "number_of_timesteps": 9523384, "per_episode_reward": -16.48, "episode_reward_trend_value": 0.003979560648047888, "biggest_recent_change": 0.11399741363659288},
{"total_number_of_episodes": 39315, "number_of_timesteps": 9525417, "per_episode_reward": -16.46, "episode_reward_trend_value": 0.003840654327783236, "biggest_recent_change": 0.11399741363659288},
{"total_number_of_episodes": 39327, "number_of_timesteps": 9528346, "per_episode_reward": -16.43, "episode_reward_trend_value": 0.0036856570567088513, "biggest_recent_change": 0.11399741363659288},
{"total_number_of_episodes": 39337, "number_of_timesteps": 9530369, "per_episode_reward": -16.42, "episode_reward_trend_value": 0.003504157823761981, "biggest_recent_change": 0.11399741363659288},
{"total_number_of_episodes": 39347, "number_of_timesteps": 9533074, "per_episode_reward": -16.41, "episode_reward_trend_value": 0.003211715880916996, "biggest_recent_change": 0.11399741363659288},
{"total_number_of_episodes": 39357, "number_of_timesteps": 9535086, "per_episode_reward": -16.4, "episode_reward_trend_value": 0.0028641249811591427, "biggest_recent_change": 0.11399741363659288},
{"total_number_of_episodes": 39367, "number_of_timesteps": 9536587, "per_episode_reward": -16.37, "episode_reward_trend_value": 0.0019058785928932939, "biggest_recent_change": 0.03759208509331913},
{"total_number_of_episodes": 39377, "number_of_timesteps": 9538707, "per_episode_reward": -16.32, "episode_reward_trend_value": 0.002351900995985782, "biggest_recent_change": 0.05175250764996164},
{"total_number_of_episodes": 39387, "number_of_timesteps": 9540594, "per_episode_reward": -16.31, "episode_reward_trend_value": 0.0020067487805281955, "biggest_recent_change": 0.05175250764996164},
{"total_number_of_episodes": 39397, "number_of_timesteps": 9543091, "per_episode_reward": -16.21, "episode_reward_trend_value": 0.0029425223955287707, "biggest_recent_change": 0.10154962595075645},
{"total_number_of_episodes": 39407, "number_of_timesteps": 9545436, "per_episode_reward": -16.2, "episode_reward_trend_value": 0.0029010011312844515, "biggest_recent_change": 0.10154962595075645},
{"total_number_of_episodes": 39418, "number_of_timesteps": 9547901, "per_episode_reward": -16.16, "episode_reward_trend_value": 0.003038810251938923, "biggest_recent_change": 0.10154962595075645},
{"total_number_of_episodes": 39428, "number_of_timesteps": 9549650, "per_episode_reward": -16.02, "episode_reward_trend_value": 0.004509871980200665, "biggest_recent_change": 0.14228238673450733},
{"total_number_of_episodes": 39439, "number_of_timesteps": 9551777, "per_episode_reward": -15.93, "episode_reward_trend_value": 0.005339173959622715, "biggest_recent_change": 0.14228238673450733},
{"total_number_of_episodes": 39449, "number_of_timesteps": 9554127, "per_episode_reward": -15.89, "episode_reward_trend_value": 0.005660153665674134, "biggest_recent_change": 0.14228238673450733},
{"total_number_of_episodes": 39459, "number_of_timesteps": 9555720, "per_episode_reward": -15.84, "episode_reward_trend_value": 0.00589235661100247, "biggest_recent_change": 0.14228238673450733},
{"total_number_of_episodes": 39469, "number_of_timesteps": 9557387, "per_episode_reward": -15.8, "episode_reward_trend_value": 0.005743410895115591, "biggest_recent_change": 0.14228238673450733},
{"total_number_of_episodes": 39479, "number_of_timesteps": 9559096, "per_episode_reward": -15.8, "episode_reward_trend_value": 0.005714180508904497, "biggest_recent_change": 0.14228238673450733},
{"total_number_of_episodes": 39489, "number_of_timesteps": 9561779, "per_episode_reward": -15.78, "episode_reward_trend_value": 0.004845971843066385, "biggest_recent_change": 0.14228238673450733},
{"total_number_of_episodes": 39499, "number_of_timesteps": 9563480, "per_episode_reward": -15.74, "episode_reward_trend_value": 0.005106009591087179, "biggest_recent_change": 0.14228238673450733},
{"total_number_of_episodes": 39509, "number_of_timesteps": 9565831, "per_episode_reward": -15.67, "episode_reward_trend_value": 0.005402984872688954, "biggest_recent_change": 0.14228238673450733},
{"total_number_of_episodes": 39519, "number_of_timesteps": 9568368, "per_episode_reward": -15.61, "episode_reward_trend_value": 0.004532562657694505, "biggest_recent_change": 0.08349886751278035},
{"total_number_of_episodes": 39530, "number_of_timesteps": 9570484, "per_episode_reward": -15.58, "episode_reward_trend_value": 0.0038595698399477344, "biggest_recent_change": 0.0687648669809171},
{"total_number_of_episodes": 39540, "number_of_timesteps": 9573196, "per_episode_reward": -15.57, "episode_reward_trend_value": 0.0035791586279650288, "biggest_recent_change": 0.0687648669809171},
{"total_number_of_episodes": 39550, "number_of_timesteps": 9575232, "per_episode_reward": -15.53, "episode_reward_trend_value": 0.0035000643888123996, "biggest_recent_change": 0.0687648669809171},
{"total_number_of_episodes": 39560, "number_of_timesteps": 9577332, "per_episode_reward": -15.51, "episode_reward_trend_value": 0.0032809394983690115, "biggest_recent_change": 0.0687648669809171},
{"total_number_of_episodes": 39570, "number_of_timesteps": 9579438, "per_episode_reward": -15.46, "episode_reward_trend_value": 0.0037643116371619692, "biggest_recent_change": 0.0687648669809171},
{"total_number_of_episodes": 39580, "number_of_timesteps": 9581421, "per_episode_reward": -15.44, "episode_reward_trend_value": 0.003792350114699339, "biggest_recent_change": 0.0687648669809171},
{"total_number_of_episodes": 39590, "number_of_timesteps": 9583938, "per_episode_reward": -15.42, "episode_reward_trend_value": 0.0035267704282036403, "biggest_recent_change": 0.0687648669809171},
{"total_number_of_episodes": 39600, "number_of_timesteps": 9586188, "per_episode_reward": -15.4, "episode_reward_trend_value": 0.0030299501347623567, "biggest_recent_change": 0.06394438738500696},
{"total_number_of_episodes": 39610, "number_of_timesteps": 9587886, "per_episode_reward": -15.38, "episode_reward_trend_value": 0.00257098727540838, "biggest_recent_change": 0.04740114343450408},
{"total_number_of_episodes": 39620, "number_of_timesteps": 9590628, "per_episode_reward": -15.35, "episode_reward_trend_value": 0.002603246315422858, "biggest_recent_change": 0.04740114343450408},
{"total_number_of_episodes": 39630, "number_of_timesteps": 9592646, "per_episode_reward": -15.3, "episode_reward_trend_value": 0.0029865296858557814, "biggest_recent_change": 0.049613183876566325},
{"total_number_of_episodes": 39640, "number_of_timesteps": 9594920, "per_episode_reward": -15.24, "episode_reward_trend_value": 0.003145392298480646, "biggest_recent_change": 0.055832657384717876},
{"total_number_of_episodes": 39650, "number_of_timesteps": 9598174, "per_episode_reward": -15.24, "episode_reward_trend_value": 0.002974401408769683, "biggest_recent_change": 0.055832657384717876},
{"total_number_of_episodes": 39660, "number_of_timesteps": 9600880, "per_episode_reward": -15.23, "episode_reward_trend_value": 0.0025780624802662386, "biggest_recent_change": 0.055832657384717876},
{"total_number_of_episodes": 39670, "number_of_timesteps": 9603372, "per_episode_reward": -15.2, "episode_reward_trend_value": 0.0025927193627808065, "biggest_recent_change": 0.055832657384717876},
{"total_number_of_episodes": 39680, "number_of_timesteps": 9605979, "per_episode_reward": -15.17, "episode_reward_trend_value": 0.002791796549343258, "biggest_recent_change": 0.055832657384717876},
{"total_number_of_episodes": 39690, "number_of_timesteps": 9608322, "per_episode_reward": -15.09, "episode_reward_trend_value": 0.003433220791841802, "biggest_recent_change": 0.0817792223960705},
{"total_number_of_episodes": 39700, "number_of_timesteps": 9611257, "per_episode_reward": -15.05, "episode_reward_trend_value": 0.0036633106348373406, "biggest_recent_change": 0.0817792223960705},
{"total_number_of_episodes": 39710, "number_of_timesteps": 9613416, "per_episode_reward": -15.02, "episode_reward_trend_value": 0.0036558844020071037, "biggest_recent_change": 0.0817792223960705},
{"total_number_of_episodes": 39720, "number_of_timesteps": 9615328, "per_episode_reward": -15.01, "episode_reward_trend_value": 0.003212314952131459, "biggest_recent_change": 0.0817792223960705},
{"total_number_of_episodes": 39730, "number_of_timesteps": 9617410, "per_episode_reward": -14.98, "episode_reward_trend_value": 0.002971148642298181, "biggest_recent_change": 0.0817792223960705},
{"total_number_of_episodes": 39740, "number_of_timesteps": 9619413, "per_episode_reward": -14.93, "episode_reward_trend_value": 0.0034690290498993587, "biggest_recent_change": 0.0817792223960705},
{"total_number_of_episodes": 39750, "number_of_timesteps": 9622022, "per_episode_reward": -14.9, "episode_reward_trend_value": 0.0036579424427714397, "biggest_recent_change": 0.0817792223960705},
{"total_number_of_episodes": 39761, "number_of_timesteps": 9625164, "per_episode_reward": -14.88, "episode_reward_trend_value": 0.003602356978382737, "biggest_recent_change": 0.0817792223960705},
{"total_number_of_episodes": 39771, "number_of_timesteps": 9628114, "per_episode_reward": -14.84, "episode_reward_trend_value": 0.003725101613850315, "biggest_recent_change": 0.0817792223960705},
{"total_number_of_episodes": 39781, "number_of_timesteps": 9630472, "per_episode_reward": -14.78, "episode_reward_trend_value": 0.0034299567560069216, "biggest_recent_change": 0.055216185190165135},

{"total_number_of_episodes": 39791, "number_of_timesteps": 9632436, "per_episode_reward": -14.74, "episode_reward_trend_value": 0.003407850075782686, "biggest_recent_change": 0.055216185190165135},
{"total_number_of_episodes": 39801, "number_of_timesteps": 9635236, "per_episode_reward": -14.71, "episode_reward_trend_value": 0.0034243830367456005, "biggest_recent_change": 0.055216185190165135},
{"total_number_of_episodes": 39811, "number_of_timesteps": 9638323, "per_episode_reward": -14.67, "episode_reward_trend_value": 0.003766290860085735, "biggest_recent_change": 0.055216185190165135},
{"total_number_of_episodes": 39821, "number_of_timesteps": 9640374, "per_episode_reward": -14.6, "episode_reward_trend_value": 0.00422871917859763, "biggest_recent_change": 0.0757462381657934},
{"total_number_of_episodes": 39831, "number_of_timesteps": 9642620, "per_episode_reward": -14.58, "episode_reward_trend_value": 0.003921613322035, "biggest_recent_change": 0.0757462381657934},
{"total_number_of_episodes": 39841, "number_of_timesteps": 9645448, "per_episode_reward": -14.53, "episode_reward_trend_value": 0.00415208865837163, "biggest_recent_change": 0.0757462381657934},
{"total_number_of_episodes": 39851, "number_of_timesteps": 9647934, "per_episode_reward": -14.49, "episode_reward_trend_value": 0.004275142780454999, "biggest_recent_change": 0.0757462381657934},
{"total_number_of_episodes": 39861, "number_of_timesteps": 9650194, "per_episode_reward": -14.48, "episode_reward_trend_value": 0.003992565024336159, "biggest_recent_change": 0.0757462381657934},
{"total_number_of_episodes": 39871, "number_of_timesteps": 9652979, "per_episode_reward": -14.46, "episode_reward_trend_value": 0.003527351455626418, "biggest_recent_change": 0.0757462381657934},
{"total_number_of_episodes": 39881, "number_of_timesteps": 9656103, "per_episode_reward": -14.41, "episode_reward_trend_value": 0.0036583161123972495, "biggest_recent_change": 0.0757462381657934},
{"total_number_of_episodes": 39891, "number_of_timesteps": 9659265, "per_episode_reward": -14.35, "episode_reward_trend_value": 0.004045404310796643, "biggest_recent_change": 0.0757462381657934},
{"total_number_of_episodes": 39901, "number_of_timesteps": 9662287, "per_episode_reward": -14.31, "episode_reward_trend_value": 0.004072053356956534, "biggest_recent_change": 0.0757462381657934},
{"total_number_of_episodes": 39911, "number_of_timesteps": 9664726, "per_episode_reward": -14.28, "episode_reward_trend_value": 0.003540039147420574, "biggest_recent_change": 0.06149037090476028},
{"total_number_of_episodes": 39921, "number_of_timesteps": 9667403, "per_episode_reward": -14.27, "episode_reward_trend_value": 0.0034518855847595334, "biggest_recent_change": 0.06149037090476028},
{"total_number_of_episodes": 39931, "number_of_timesteps": 9669545, "per_episode_reward": -14.24, "episode_reward_trend_value": 0.003232303440689361, "biggest_recent_change": 0.06149037090476028},
{"total_number_of_episodes": 39941, "number_of_timesteps": 9672021, "per_episode_reward": -14.2, "episode_reward_trend_value": 0.003246686483687533, "biggest_recent_change": 0.06149037090476028},
{"total_number_of_episodes": 39952, "number_of_timesteps": 9674626, "per_episode_reward": -14.17, "episode_reward_trend_value": 0.00341399409168507, "biggest_recent_change": 0.06149037090476028},
{"total_number_of_episodes": 39962, "number_of_timesteps": 9677022, "per_episode_reward": -14.15, "episode_reward_trend_value": 0.003479192159319587, "biggest_recent_change": 0.06149037090476028},
{"total_number_of_episodes": 39972, "number_of_timesteps": 9679551, "per_episode_reward": -14.13, "episode_reward_trend_value": 0.0031431931423422472, "biggest_recent_change": 0.06149037090476028},
{"total_number_of_episodes": 39982, "number_of_timesteps": 9682302, "per_episode_reward": -14.12, "episode_reward_trend_value": 0.0025731481574844195, "biggest_recent_change": 0.04286205164276069},
{"total_number_of_episodes": 39992, "number_of_timesteps": 9684853, "per_episode_reward": -14.01, "episode_reward_trend_value": 0.003322282847302284, "biggest_recent_change": 0.11028417372636845},
exited at update_barrier.wait(): 4, error = 
None
exited at update_barrier.wait(): 5, error = 
None
exited at update_barrier.wait(): 6, error = 
None
exited at all_updated_barrier.wait(): 2, error = 
None
exited at all_updated_barrier.wait(): 1, error = 
None
exited at all_updated_barrier.wait(): 3, error = 
None
[done calling async_.run_async()]
final_eval: {'number_of_steps': 125000, 'number_of_episodes': None, 'mean': 199.74976027726552, 'median': 250.2098016554388, 'stdev': 102.78479453838133}
logs/comparisons/lunar_lander__atk=none__def=ucb.log fitness_value = -71.27742513346853
